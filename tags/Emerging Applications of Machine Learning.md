- [PIXART-Î´: Fast and Controllable Image Generation with Latent Consistency Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+PIXART-%CE%B4%3A+Fast+and+Controllable+Image+Generation+with+Latent+Consistency+Models.yaml) / 2024-01-11 00:00
- [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+PALP%3A+Prompt+Aligned+Personalization+of+Text-to-Image+Models.yaml) / 2024-01-12
- [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Parrot%3A+Pareto-optimal+Multi-Reward+Reinforcement+Learning+Framework+for+Text-to-Image+Generation.yaml) / 2024-01-12
- [Towards Conversational Diagnostic AI](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Towards+Conversational+Diagnostic+AI.yaml) / 2024-01-12
- [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Diffusion+Priors+for+Dynamic+View+Synthesis+from+Monocular+Videos.yaml) / 2024-01-12
- [Distilling Vision-Language Models on Millions of Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Distilling+Vision-Language+Models+on+Millions+of+Videos.yaml) / 2024-01-12
- [LEGO:Language Enhanced Multi-modal Grounding Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+LEGO%3ALanguage+Enhanced+Multi-modal+Grounding+Model.yaml) / 2024-01-12
- [Towards Conversational Diagnostic AI](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Towards+Conversational+Diagnostic+AI.yaml) / 2024-01-12
- [Quantum Denoising Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Quantum+Denoising+Diffusion+Models.yaml) / 2024-01-17
- [CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+CMMMU%3A+A+Chinese+Massive+Multi-discipline+Multimodal+Understanding+Benchmark.yaml) / 2024-01-23
- [Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Mastering+Text-to-Image+Diffusion%3A+Recaptioning%2C+Planning%2C+and+Generating+with+Multimodal+LLMs.yaml) / 2024-01-23
- [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+UNIMO-G%3A+Unified+Image+Generation+through+Multimodal+Conditional+Diffusion.yaml) / 2024-01-25
- [BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+BootPIG%3A+Bootstrapping+Zero-shot+Personalized+Image+Generation+Capabilities+in+Pretrained+Diffusion+Models.yaml) / 2024-01-26
- [CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+CreativeSynth%3A+Creative+Blending+and+Synthesis+of+Visual+Arts+based+on+Multimodal+Diffusion.yaml) / 2024-01-26
- [TIP-Editor: An Accurate 3D Editor Following Both Text-Prompts And Image-Prompts](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/12/2024-01-29+TIP-Editor%3A+An+Accurate+3D+Editor+Following+Both+Text-Prompts+And+Image-Prompts.yaml) / 2024-01-29
- [ReGAL: Refactoring Programs to Discover Generalizable Abstractions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+ReGAL%3A+Refactoring+Programs+to+Discover+Generalizable+Abstractions.yaml) / 2024-01-31
- [Transfer Learning for Text Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+Transfer+Learning+for+Text+Diffusion+Models.yaml) / 2024-01-31
- [Advances in 3D Generation: A Survey](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+Advances+in+3D+Generation%3A+A+Survey.yaml) / 2024-02-01
- [AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+AnimateLCM%3A+Accelerating+the+Animation+of+Personalized+Diffusion+Models+and+Adapters+with+Decoupled+Consistency+Learning.yaml) / 2024-02-02
- [Direct-a-Video: Customized Video Generation with User-Directed Camera Movement and Object Motion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Direct-a-Video%3A+Customized+Video+Generation+with+User-Directed+Camera+Movement+and+Object+Motion.yaml) / 2024-02-06
- [InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+InteractiveVideo%3A+User-Centric+Controllable+Video+Generation+with+Synergistic+Multimodal+Instructions.yaml) / 2024-02-06
- [OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+OpenMoE%3A+An+Early+Effort+on+Open+Mixture-of-Experts+Language+Models.yaml) / 2024-02-06
- [EscherNet: A Generative Model for Scalable View Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+EscherNet%3A+A+Generative+Model+for+Scalable+View+Synthesis.yaml) / 2024-02-07
- [CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+CodeIt%3A+Self-Improving+Language+Models+with+Prioritized+Hindsight+Replay.yaml) / 2024-02-08
- [LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+LGM%3A+Large+Multi-View+Gaussian+Model+for+High-Resolution+3D+Content+Creation.yaml) / 2024-02-08
- [Animated Stickers: Bringing Stickers to Life with Video Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+Animated+Stickers%3A+Bringing+Stickers+to+Life+with+Video+Diffusion.yaml) / 2024-02-12
- [Keyframer: Empowering Animation Design using Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+Keyframer%3A+Empowering+Animation+Design+using+Large+Language+Models.yaml) / 2024-02-12
