- [PIXART-Î´: Fast and Controllable Image Generation with Latent Consistency Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+PIXART-%CE%B4%3A+Fast+and+Controllable+Image+Generation+with+Latent+Consistency+Models.yaml) / 2024-01-11 00:00
- [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+PALP%3A+Prompt+Aligned+Personalization+of+Text-to-Image+Models.yaml) / 2024-01-12
- [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Parrot%3A+Pareto-optimal+Multi-Reward+Reinforcement+Learning+Framework+for+Text-to-Image+Generation.yaml) / 2024-01-12
- [Towards Conversational Diagnostic AI](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Towards+Conversational+Diagnostic+AI.yaml) / 2024-01-12
- [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Diffusion+Priors+for+Dynamic+View+Synthesis+from+Monocular+Videos.yaml) / 2024-01-12
- [Distilling Vision-Language Models on Millions of Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Distilling+Vision-Language+Models+on+Millions+of+Videos.yaml) / 2024-01-12
- [LEGO:Language Enhanced Multi-modal Grounding Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+LEGO%3ALanguage+Enhanced+Multi-modal+Grounding+Model.yaml) / 2024-01-12
- [Towards Conversational Diagnostic AI](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Towards+Conversational+Diagnostic+AI.yaml) / 2024-01-12
- [Quantum Denoising Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Quantum+Denoising+Diffusion+Models.yaml) / 2024-01-17
- [CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+CMMMU%3A+A+Chinese+Massive+Multi-discipline+Multimodal+Understanding+Benchmark.yaml) / 2024-01-23
- [Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Mastering+Text-to-Image+Diffusion%3A+Recaptioning%2C+Planning%2C+and+Generating+with+Multimodal+LLMs.yaml) / 2024-01-23
- [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+UNIMO-G%3A+Unified+Image+Generation+through+Multimodal+Conditional+Diffusion.yaml) / 2024-01-25
- [BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+BootPIG%3A+Bootstrapping+Zero-shot+Personalized+Image+Generation+Capabilities+in+Pretrained+Diffusion+Models.yaml) / 2024-01-26
- [CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+CreativeSynth%3A+Creative+Blending+and+Synthesis+of+Visual+Arts+based+on+Multimodal+Diffusion.yaml) / 2024-01-26
