- [ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+ANIM-400K%3A+A+Large-Scale+Dataset+for+Automated+End-To-End+Dubbing+of+Video.yaml) / 2024-01-11 00:00
- [InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+InseRF%3A+Text-Driven+Generative+Object+Insertion+in+Neural+3D+Scenes.yaml) / 2024-01-11 00:00
- [PIXART-Î´: Fast and Controllable Image Generation with Latent Consistency Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+PIXART-%CE%B4%3A+Fast+and+Controllable+Image+Generation+with+Latent+Consistency+Models.yaml) / 2024-01-11 00:00
- [URHand: Universal Relightable Hands](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+URHand%3A+Universal+Relightable+Hands.yaml) / 2024-01-11 00:00
- [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Diffusion+Priors+for+Dynamic+View+Synthesis+from+Monocular+Videos.yaml) / 2024-01-12
- [Distilling Vision-Language Models on Millions of Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Distilling+Vision-Language+Models+on+Millions+of+Videos.yaml) / 2024-01-12
- [Efficient LLM inference solution on Intel GPU](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Efficient+LLM+inference+solution+on+Intel+GPU.yaml) / 2024-01-12
- [LEGO:Language Enhanced Multi-modal Grounding Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+LEGO%3ALanguage+Enhanced+Multi-modal+Grounding+Model.yaml) / 2024-01-12
- [Object-Centric Diffusion for Efficient Video Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Object-Centric+Diffusion+for+Efficient+Video+Editing.yaml) / 2024-01-12
- [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+PALP%3A+Prompt+Aligned+Personalization+of+Text-to-Image+Models.yaml) / 2024-01-12
- [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Parrot%3A+Pareto-optimal+Multi-Reward+Reinforcement+Learning+Framework+for+Text-to-Image+Generation.yaml) / 2024-01-12
- [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+TRIPS%3A+Trilinear+Point+Splatting+for+Real-Time+Radiance+Field+Rendering.yaml) / 2024-01-12
- [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Diffusion+Priors+for+Dynamic+View+Synthesis+from+Monocular+Videos.yaml) / 2024-01-12
- [Distilling Vision-Language Models on Millions of Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Distilling+Vision-Language+Models+on+Millions+of+Videos.yaml) / 2024-01-12
- [LEGO:Language Enhanced Multi-modal Grounding Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+LEGO%3ALanguage+Enhanced+Multi-modal+Grounding+Model.yaml) / 2024-01-12
- [Object-Centric Diffusion for Efficient Video Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Object-Centric+Diffusion+for+Efficient+Video+Editing.yaml) / 2024-01-12
- [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+PALP%3A+Prompt+Aligned+Personalization+of+Text-to-Image+Models.yaml) / 2024-01-12
- [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Parrot%3A+Pareto-optimal+Multi-Reward+Reinforcement+Learning+Framework+for+Text-to-Image+Generation.yaml) / 2024-01-12
- [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+TRIPS%3A+Trilinear+Point+Splatting+for+Real-Time+Radiance+Field+Rendering.yaml) / 2024-01-12
- [Towards Conversational Diagnostic AI](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Towards+Conversational+Diagnostic+AI.yaml) / 2024-01-12
- [HexaGen3D: StableDiffusion is just one step away from Fast and Diverse Text-to-3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+HexaGen3D%3A+StableDiffusion+is+just+one+step+away+from+Fast+and+Diverse+Text-to-3D+Generation.yaml) / 2024-01-17
- [InstantID: Zero-shot Identity-Preserving Generation in Seconds](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+InstantID%3A+Zero-shot+Identity-Preserving+Generation+in+Seconds.yaml) / 2024-01-17
- [Quantum Denoising Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Quantum+Denoising+Diffusion+Models.yaml) / 2024-01-17
- [Scalable Pre-training of Large Autoregressive Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Scalable+Pre-training+of+Large+Autoregressive+Image+Models.yaml) / 2024-01-17
- [Towards A Better Metric for Text-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Towards+A+Better+Metric+for+Text-to-Video+Generation.yaml) / 2024-01-17
- [Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+Compose+and+Conquer%3A+Diffusion-Based+3D+Depth+Aware+Composable+Image+Synthesis.yaml) / 2024-01-18
- [GARField: Group Anything with Radiance Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+GARField%3A+Group+Anything+with+Radiance+Fields.yaml) / 2024-01-18
- [ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+ICON%3A+Incremental+CONfidence+for+Joint+Pose+and+Radiance+Field+Optimization.yaml) / 2024-01-18
- [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+SceneVerse%3A+Scaling+3D+Vision-Language+Learning+for+Grounded+Scene+Understanding.yaml) / 2024-01-18
- [SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+SiT%3A+Exploring+Flow+and+Diffusion-based+Generative+Models+with+Scalable+Interpolant+Transformers.yaml) / 2024-01-18
- [TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+TextureDreamer%3A+Image-guided+Texture+Synthesis+through+Geometry-aware+Diffusion.yaml) / 2024-01-18
- [UniVG: Towards UNIfied-modal Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+UniVG%3A+Towards+UNIfied-modal+Video+Generation.yaml) / 2024-01-18
- [VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+VideoCrafter2%3A+Overcoming+Data+Limitations+for+High-Quality+Video+Diffusion+Models.yaml) / 2024-01-18
- [Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+Vision+Mamba%3A+Efficient+Visual+Representation+Learning+with+Bidirectional+State+Space+Model.yaml) / 2024-01-18
- [CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+CustomVideo%3A+Customizing+Text-to-Video+Generation+with+Multiple+Subjects.yaml) / 2024-01-19
- [DiffusionGPT: LLM-Driven Text-to-Image Generation System](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+DiffusionGPT%3A+LLM-Driven+Text-to-Image+Generation+System.yaml) / 2024-01-19
- [Improving fine-grained understanding in image-text pre-training](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+Improving+fine-grained+understanding+in+image-text+pre-training.yaml) / 2024-01-19
- [Rethinking FID: Towards a Better Evaluation Metric for Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+Rethinking+FID%3A+Towards+a+Better+Evaluation+Metric+for+Image+Generation.yaml) / 2024-01-19
- [SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+SHINOBI%3A+Shape+and+Illumination+using+Neural+Object+Decomposition+via+BRDF+Optimization+In-the-wild.yaml) / 2024-01-19
- [VMamba: Visual State Space Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+VMamba%3A+Visual+State+Space+Model.yaml) / 2024-01-19
- [WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+WorldDreamer%3A+Towards+General+World+Models+for+Video+Generation+via+Predicting+Masked+Tokens.yaml) / 2024-01-19
- [ActAnywhere: Subject-Aware Video Background Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+ActAnywhere%3A+Subject-Aware+Video+Background+Generation.yaml) / 2024-01-22
- [Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Depth+Anything%3A+Unleashing+the+Power+of+Large-Scale+Unlabeled+Data.yaml) / 2024-01-22
- [Inflation with Diffusion: Efficient Temporal Adaptation for Text-to-Video Super-Resolution](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Inflation+with+Diffusion%3A+Efficient+Temporal+Adaptation+for+Text-to-Video+Super-Resolution.yaml) / 2024-01-22
- [Synthesizing Moving People with 3D Control](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Synthesizing+Moving+People+with+3D+Control.yaml) / 2024-01-22
- [Understanding Video Transformers via Universal Concept Discovery](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Understanding+Video+Transformers+via+Universal+Concept+Discovery.yaml) / 2024-01-22
- [CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+CheXagent%3A+Towards+a+Foundation+Model+for+Chest+X-Ray+Interpretation.yaml) / 2024-01-23
- [EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+EmerDiff%3A+Emerging+Pixel-level+Semantic+Knowledge+in+Diffusion+Models.yaml) / 2024-01-23
- [Fast Registration of Photorealistic Avatars for VR Facial Animation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Fast+Registration+of+Photorealistic+Avatars+for+VR+Facial+Animation.yaml) / 2024-01-23
- [Make-A-Shape: a Ten-Million-scale 3D Shape Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Make-A-Shape%3A+a+Ten-Million-scale+3D+Shape+Model.yaml) / 2024-01-23
- [Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Mastering+Text-to-Image+Diffusion%3A+Recaptioning%2C+Planning%2C+and+Generating+with+Multimodal+LLMs.yaml) / 2024-01-23
- [Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Scalable+High-Resolution+Pixel-Space+Image+Synthesis+with+Hourglass+Diffusion+Transformers.yaml) / 2024-01-23
- [Scaling Face Interaction Graph Networks to Real World Scenes](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Scaling+Face+Interaction+Graph+Networks+to+Real+World+Scenes.yaml) / 2024-01-23
- [Single-View 3D Human Digitalization with Large Reconstruction Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Single-View+3D+Human+Digitalization+with+Large+Reconstruction+Models.yaml) / 2024-01-23
- [SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+SpatialVLM%3A+Endowing+Vision-Language+Models+with+Spatial+Reasoning+Capabilities.yaml) / 2024-01-23
- [UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+UltrAvatar%3A+A+Realistic+Animatable+3D+Avatar+Diffusion+Model+with+Authenticity+Guided+Textures.yaml) / 2024-01-23
- [AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+AutoRT%3A+Embodied+Foundation+Models+for+Large+Scale+Orchestration+of+Robotic+Agents.yaml) / 2024-01-24
- [GALA: Generating Animatable Layered Assets from a Single Scan](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+GALA%3A+Generating+Animatable+Layered+Assets+from+a+Single+Scan.yaml) / 2024-01-24
- [Large-scale Reinforcement Learning for Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+Large-scale+Reinforcement+Learning+for+Diffusion+Models.yaml) / 2024-01-24
- [Lumiere: A Space-Time Diffusion Model for Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+Lumiere%3A+A+Space-Time+Diffusion+Model+for+Video+Generation.yaml) / 2024-01-24
- [Small Language Model Meets with Reinforced Vision Vocabulary](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+Small+Language+Model+Meets+with+Reinforced+Vision+Vocabulary.yaml) / 2024-01-24
- [ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+ConTextual%3A+Evaluating+Context-Sensitive+Text-Rich+Visual+Reasoning+in+Large+Multimodal+Models.yaml) / 2024-01-25
- [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+MM-LLMs%3A+Recent+Advances+in+MultiModal+Large+Language+Models.yaml) / 2024-01-25
- [Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+Scaling+Up+to+Excellence%3A+Practicing+Model+Scaling+for+Photo-Realistic+Image+Restoration+In+the+Wild.yaml) / 2024-01-25
- [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+UNIMO-G%3A+Unified+Image+Generation+through+Multimodal+Conditional+Diffusion.yaml) / 2024-01-25
- [BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+BootPIG%3A+Bootstrapping+Zero-shot+Personalized+Image+Generation+Capabilities+in+Pretrained+Diffusion+Models.yaml) / 2024-01-26
- [CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+CreativeSynth%3A+Creative+Blending+and+Synthesis+of+Visual+Arts+based+on+Multimodal+Diffusion.yaml) / 2024-01-26
- [Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+Diffuse+to+Choose%3A+Enriching+Image+Conditioned+Inpainting+in+Latent+Diffusion+Models+for+Virtual+Try-All.yaml) / 2024-01-26
- [Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+Multimodal+Pathway%3A+Improve+Transformers+with+Irrelevant+Data+from+Other+Modalities.yaml) / 2024-01-26
- [Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+Sketch2NeRF%3A+Multi-view+Sketch-guided+Text-to-3D+Generation.yaml) / 2024-01-26
- [pix2gestalt: Amodal Segmentation by Synthesizing Wholes](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+pix2gestalt%3A+Amodal+Segmentation+by+Synthesizing+Wholes.yaml) / 2024-01-26
- [From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on Generalizability, Trustworthiness and Causality through Four Modalities](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/12/2024-01-29+From+GPT-4+to+Gemini+and+Beyond%3A+Assessing+the+Landscape+of+MLLMs+on+Generalizability%2C+Trustworthiness+and+Causality+through+Four+Modalities.yaml) / 2024-01-29
- [TIP-Editor: An Accurate 3D Editor Following Both Text-Prompts And Image-Prompts](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/12/2024-01-29+TIP-Editor%3A+An+Accurate+3D+Editor+Following+Both+Text-Prompts+And+Image-Prompts.yaml) / 2024-01-29
- [Taiyi-Diffusion-XL: Advancing Bilingual Text-to-Image Generation with Large Vision-Language Model Support](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/12/2024-01-29+Taiyi-Diffusion-XL%3A+Advancing+Bilingual+Text-to-Image+Generation+with+Large+Vision-Language+Model+Support.yaml) / 2024-01-29
- [Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Divide+and+Conquer%3A+Language+Models+can+Plan+and+Self-Correct+for+Compositional+Text-to-Image+Generation.yaml) / 2024-01-30
- [InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+InternLM-XComposer2%3A+Mastering+Free-form+Text-Image+Composition+and+Comprehension+in+Vision-Language+Large+Model.yaml) / 2024-01-30
- [Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Media2Face%3A+Co-speech+Facial+Animation+Generation+With+Multi-Modality+Guidance.yaml) / 2024-01-30
- [MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+MoE-LLaVA%3A+Mixture+of+Experts+for+Large+Vision-Language+Models.yaml) / 2024-01-30
- [Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Mobile-Agent%3A+Autonomous+Multi-Modal+Mobile+Device+Agent+with+Visual+Perception.yaml) / 2024-01-30
- [Motion-I2V: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Motion-I2V%3A+Consistent+and+Controllable+Image-to-Video+Generation+with+Explicit+Motion+Modeling.yaml) / 2024-01-30
- [Object-Driven One-Shot Fine-tuning of Text-to-Image Diffusion with Prototypical Embedding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Object-Driven+One-Shot+Fine-tuning+of+Text-to-Image+Diffusion+with+Prototypical+Embedding.yaml) / 2024-01-30
- [Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Overcoming+the+Pitfalls+of+Vision-Language+Model+Finetuning+for+OOD+Generalization.yaml) / 2024-01-30
- [StableIdentity: Inserting Anybody into Anywhere at First Sight](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+StableIdentity%3A+Inserting+Anybody+into+Anywhere+at+First+Sight.yaml) / 2024-01-30
- [BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+BlockFusion%3A+Expandable+3D+Scene+Generation+using+Latent+Tri-plane+Extrapolation.yaml) / 2024-01-31
- [High-Quality Image Restoration Following Human Instructions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+High-Quality+Image+Restoration+Following+Human+Instructions.yaml) / 2024-01-31
- [MouSi: Poly-Visual-Expert Vision-Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+MouSi%3A+Poly-Visual-Expert+Vision-Language+Models.yaml) / 2024-01-31
- [Proactive Detection of Voice Cloning with Localized Watermarking](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+Proactive+Detection+of+Voice+Cloning+with+Localized+Watermarking.yaml) / 2024-01-31
- [ReGAL: Refactoring Programs to Discover Generalizable Abstractions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+ReGAL%3A+Refactoring+Programs+to+Discover+Generalizable+Abstractions.yaml) / 2024-01-31
- [Repositioning the Subject within Image](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+Repositioning+the+Subject+within+Image.yaml) / 2024-01-31
- [StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+StrokeNUWA%3A+Tokenizing+Strokes+for+Vector+Graphic+Synthesis.yaml) / 2024-01-31
- [T3: Transparent Tracking & Triggering for Fine-grained Overlap of Compute & Collectives](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+T3%3A+Transparent+Tracking+%26+Triggering+for+Fine-grained+Overlap+of+Compute+%26+Collectives.yaml) / 2024-01-31
- [YOLO-World: Real-Time Open-Vocabulary Object Detection](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+YOLO-World%3A+Real-Time+Open-Vocabulary+Object+Detection.yaml) / 2024-01-31
- [Advances in 3D Generation: A Survey](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+Advances+in+3D+Generation%3A+A+Survey.yaml) / 2024-02-01
- [Anything in Any Scene: Photorealistic Video Object Insertion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+Anything+in+Any+Scene%3A+Photorealistic+Video+Object+Insertion.yaml) / 2024-02-01
- [CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+CARFF%3A+Conditional+Auto-encoded+Radiance+Field+for+3D+Scene+Forecasting.yaml) / 2024-02-01
- [ReplaceAnything3D:Text-Guided 3D Scene Editing with Compositional Neural Radiance Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+ReplaceAnything3D%3AText-Guided+3D+Scene+Editing+with+Compositional+Neural+Radiance+Fields.yaml) / 2024-02-01
- [AToM: Amortized Text-to-Mesh using 2D Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+AToM%3A+Amortized+Text-to-Mesh+using+2D+Diffusion.yaml) / 2024-02-02
- [AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+AnimateLCM%3A+Accelerating+the+Animation+of+Personalized+Diffusion+Models+and+Adapters+with+Decoupled+Consistency+Learning.yaml) / 2024-02-02
- [Machine Unlearning for Image-to-Image Generative Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+Machine+Unlearning+for+Image-to-Image+Generative+Models.yaml) / 2024-02-02
- [SymbolicAI: A framework for logic-based approaches combining generative models and solvers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+SymbolicAI%3A+A+framework+for+logic-based+approaches+combining+generative+models+and+solvers.yaml) / 2024-02-02
- [DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+DiffEditor%3A+Boosting+Accuracy+and+Flexibility+on+Diffusion-based+Image+Editing.yaml) / 2024-02-06
- [Direct-a-Video: Customized Video Generation with User-Directed Camera Movement and Object Motion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Direct-a-Video%3A+Customized+Video+Generation+with+User-Directed+Camera+Movement+and+Object+Motion.yaml) / 2024-02-06
- [InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+InteractiveVideo%3A+User-Centric+Controllable+Video+Generation+with+Synergistic+Multimodal+Instructions.yaml) / 2024-02-06
- [Training-Free Consistent Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Training-Free+Consistent+Text-to-Image+Generation.yaml) / 2024-02-06
- [V-IRL: Grounding Virtual Intelligence in Real Life](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+V-IRL%3A+Grounding+Virtual+Intelligence+in+Real+Life.yaml) / 2024-02-06
- [Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Video-LaVIT%3A+Unified+Video-Language+Pre-training+with+Decoupled+Visual-Motional+Tokenization.yaml) / 2024-02-06
- [CogCoM: Train Large Vision-Language Models Diving into Details through Chain of Manipulations](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+CogCoM%3A+Train+Large+Vision-Language+Models+Diving+into+Details+through+Chain+of+Manipulations.yaml) / 2024-02-07
- [EVA-CLIP-18B: Scaling CLIP to 18 Billion Parameters](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+EVA-CLIP-18B%3A+Scaling+CLIP+to+18+Billion+Parameters.yaml) / 2024-02-07
- [EscherNet: A Generative Model for Scalable View Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+EscherNet%3A+A+Generative+Model+for+Scalable+View+Synthesis.yaml) / 2024-02-07
- [IMUSIC: IMU-based Facial Expression Capture](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+IMUSIC%3A+IMU-based+Facial+Expression+Capture.yaml) / 2024-02-07
- [MobileVLM V2: Faster and Stronger Baseline for Vision Language Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+MobileVLM+V2%3A+Faster+and+Stronger+Baseline+for+Vision+Language+Model.yaml) / 2024-02-07
- [Vision Superalignment: Weak-to-Strong Generalization for Vision Foundation Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+Vision+Superalignment%3A+Weak-to-Strong+Generalization+for+Vision+Foundation+Models.yaml) / 2024-02-07
- [ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+ConsistI2V%3A+Enhancing+Visual+Consistency+for+Image-to-Video+Generation.yaml) / 2024-02-08
- [EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+EfficientViT-SAM%3A+Accelerated+Segment+Anything+Model+Without+Performance+Loss.yaml) / 2024-02-08
- [LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+LGM%3A+Large+Multi-View+Gaussian+Model+for+High-Resolution+3D+Content+Creation.yaml) / 2024-02-08
- [Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+Progressive+Gradient+Flow+for+Robust+N%3AM+Sparsity+Training+in+Transformers.yaml) / 2024-02-08
- [ScreenAI: A Vision-Language Model for UI and Infographics Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+ScreenAI%3A+A+Vision-Language+Model+for+UI+and+Infographics+Understanding.yaml) / 2024-02-08
- [$Î»$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+%24%CE%BB%24-ECLIPSE%3A+Multi-Concept+Personalized+Text-to-Image+Diffusion+Models+by+Leveraging+CLIP+Latent+Space.yaml) / 2024-02-09
- [Driving Everywhere with Large Language Model Policy Adaptation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+Driving+Everywhere+with+Large+Language+Model+Policy+Adaptation.yaml) / 2024-02-09
- [InstaGen: Enhancing Object Detection by Training on Synthetic Dataset](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+InstaGen%3A+Enhancing+Object+Detection+by+Training+on+Synthetic+Dataset.yaml) / 2024-02-09
- [Memory Consolidation Enables Long-Context Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+Memory+Consolidation+Enables+Long-Context+Video+Understanding.yaml) / 2024-02-09
- [Question Aware Vision Transformer for Multimodal Reasoning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+Question+Aware+Vision+Transformer+for+Multimodal+Reasoning.yaml) / 2024-02-09
- [Animated Stickers: Bringing Stickers to Life with Video Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+Animated+Stickers%3A+Bringing+Stickers+to+Life+with+Video+Diffusion.yaml) / 2024-02-12
- [Keyframer: Empowering Animation Design using Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+Keyframer%3A+Empowering+Animation+Design+using+Large+Language+Models.yaml) / 2024-02-12
- [ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+ViGoR%3A+Improving+Visual+Grounding+of+Large+Vision+Language+Models+with+Fine-Grained+Reward+Modeling.yaml) / 2024-02-12
- [GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+GALA3D%3A+Towards+Text-to-3D+Complex+Scene+Generation+via+Layout-guided+Generative+Gaussian+Splatting.yaml) / 2024-02-13
- [Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+Making+Flow-Matching-Based+Zero-Shot+Text-to-Speech+Laugh+as+You+Like.yaml) / 2024-02-13
- [PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+PIVOT%3A+Iterative+Visual+Prompting+Elicits+Actionable+Knowledge+for+VLMs.yaml) / 2024-02-13
- [Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+Prismatic+VLMs%3A+Investigating+the+Design+Space+of+Visually-Conditioned+Language+Models.yaml) / 2024-02-13
- [IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+IM-3D%3A+Iterative+Multiview+Diffusion+and+Reconstruction+for+High-Quality+3D+Generation.yaml) / 2024-02-14
- [Learning Continuous 3D Words for Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+Learning+Continuous+3D+Words+for+Text-to-Image+Generation.yaml) / 2024-02-14
- [Lumos : Empowering Multimodal LLMs with Scene Text Recognition](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+Lumos+%3A+Empowering+Multimodal+LLMs+with+Scene+Text+Recognition.yaml) / 2024-02-14
- [NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+NeRF+Analogies%3A+Example-Based+Visual+Attribute+Transfer+for+NeRFs.yaml) / 2024-02-14
- [Vision-Based Hand Gesture Customization from a Single Demonstration](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+Vision-Based+Hand+Gesture+Customization+from+a+Single+Demonstration.yaml) / 2024-02-14
- [World Model on Million-Length Video And Language With RingAttention](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+World+Model+on+Million-Length+Video+And+Language+With+RingAttention.yaml) / 2024-02-14
- [L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/25/2024-02-15+L3GO%3A+Language+Agents+with+Chain-of-3D-Thoughts+for+Generating+Unconventional+Objects.yaml) / 2024-02-15
- [Magic-Me: Identity-Specific Video Customized Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/25/2024-02-15+Magic-Me%3A+Identity-Specific+Video+Customized+Diffusion.yaml) / 2024-02-15
- [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/25/2024-02-15+PRDP%3A+Proximal+Reward+Difference+Prediction+for+Large-Scale+Reward+Finetuning+of+Diffusion+Models.yaml) / 2024-02-15
- [DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/26/2024-02-16+DreamMatcher%3A+Appearance+Matching+Self-Attention+for+Semantically-Consistent+Text-to-Image+Personalization.yaml) / 2024-02-16
- [GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/26/2024-02-16+GES%3A+Generalized+Exponential+Splatting+for+Efficient+Radiance+Field+Rendering.yaml) / 2024-02-16
- [GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object with Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+GaussianObject%3A+Just+Taking+Four+Images+to+Get+A+High-Quality+3D+Object+with+Gaussian+Splatting.yaml) / 2024-02-19
- [LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+LAVE%3A+LLM-Powered+Agent+Assistance+and+Language+Augmentation+for+Video+Editing.yaml) / 2024-02-19
- [Make a Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+Make+a+Cheap+Scaling%3A+A+Self-Cascade+Diffusion+Model+for+Higher-Resolution+Adaptation.yaml) / 2024-02-19
- [PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+PaLM2-VAdapter%3A+Progressively+Aligned+Language+Model+Makes+a+Strong+Vision-language+Adapter.yaml) / 2024-02-19
- [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+AnyGPT%3A+Unified+Multimodal+LLM+with+Discrete+Sequence+Modeling.yaml) / 2024-02-20
- [Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+Binary+Opacity+Grids%3A+Capturing+Fine+Geometric+Detail+for+Mesh-Based+View+Synthesis.yaml) / 2024-02-20
- [CoLLaVO: Crayon Large Language and Vision mOdel](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+CoLLaVO%3A+Crayon+Large+Language+and+Vision+mOdel.yaml) / 2024-02-20
- [DiLightNet: Fine-grained Lighting Control for Diffusion-based Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+DiLightNet%3A+Fine-grained+Lighting+Control+for+Diffusion-based+Image+Generation.yaml) / 2024-02-20
- [FiT: Flexible Vision Transformer for Diffusion Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+FiT%3A+Flexible+Vision+Transformer+for+Diffusion+Model.yaml) / 2024-02-20
- [Pushing Auto-regressive Models for 3D Shape Generation at Capacity and Scalability](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+Pushing+Auto-regressive+Models+for+3D+Shape+Generation+at+Capacity+and+Scalability.yaml) / 2024-02-20
- [A Touch, Vision, and Language Dataset for Multimodal Alignment](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+A+Touch%2C+Vision%2C+and+Language+Dataset+for+Multimodal+Alignment.yaml) / 2024-02-21
- [FlashTex: Fast Relightable Mesh Texturing with LightControlNet](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+FlashTex%3A+Fast+Relightable+Mesh+Texturing+with+LightControlNet.yaml) / 2024-02-21
- [How Easy is It to Fool Your Multimodal LLMs? An Empirical Analysis on Deceptive Prompts](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+How+Easy+is+It+to+Fool+Your+Multimodal+LLMs%3F+An+Empirical+Analysis+on+Deceptive+Prompts.yaml) / 2024-02-21
- [Improving Robustness for Joint Optimization of Camera Poses and Decomposed Low-Rank Tensorial Radiance Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+Improving+Robustness+for+Joint+Optimization+of+Camera+Poses+and+Decomposed+Low-Rank+Tensorial+Radiance+Fields.yaml) / 2024-02-21
- [MVDiffusion++: A Dense High-resolution Multi-view Diffusion Model for Single or Sparse-view 3D Object Reconstruction](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+MVDiffusion%2B%2B%3A+A+Dense+High-resolution+Multi-view+Diffusion+Model+for+Single+or+Sparse-view+3D+Object+Reconstruction.yaml) / 2024-02-21
- [RealCompo: Dynamic Equilibrium between Realism and Compositionality Improves Text-to-Image Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+RealCompo%3A+Dynamic+Equilibrium+between+Realism+and+Compositionality+Improves+Text-to-Image+Diffusion+Models.yaml) / 2024-02-21
- [Video ReCap: Recursive Captioning of Hour-Long Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+Video+ReCap%3A+Recursive+Captioning+of+Hour-Long+Videos.yaml) / 2024-02-21
- [VideoPrism: A Foundational Visual Encoder for Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+VideoPrism%3A+A+Foundational+Visual+Encoder+for+Video+Understanding.yaml) / 2024-02-21
- [Aria Everyday Activities Dataset](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/30/2024-02-22+Aria+Everyday+Activities+Dataset.yaml) / 2024-02-22
- [BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/30/2024-02-22+BBA%3A+Bi-Modal+Behavioral+Alignment+for+Reasoning+with+Large+Vision-Language+Models.yaml) / 2024-02-22
- [D-Flow: Differentiating through Flows for Controlled Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/30/2024-02-22+D-Flow%3A+Differentiating+through+Flows+for+Controlled+Generation.yaml) / 2024-02-22
- [SDXL-Lightning: Progressive Adversarial Diffusion Distillation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/30/2024-02-22+SDXL-Lightning%3A+Progressive+Adversarial+Diffusion+Distillation.yaml) / 2024-02-22
- [ToDo: Token Downsampling for Efficient Generation of High-Resolution Images](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/30/2024-02-22+ToDo%3A+Token+Downsampling+for+Efficient+Generation+of+High-Resolution+Images.yaml) / 2024-02-22
- [YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/30/2024-02-22+YOLOv9%3A+Learning+What+You+Want+to+Learn+Using+Programmable+Gradient+Information.yaml) / 2024-02-22
- [Consolidating Attention Features for Multi-view Image Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+Consolidating+Attention+Features+for+Multi-view+Image+Editing.yaml) / 2024-02-23
- [GaussianPro: 3D Gaussian Splatting with Progressive Propagation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+GaussianPro%3A+3D+Gaussian+Splatting+with+Progressive+Propagation.yaml) / 2024-02-23
- [GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+GeneOH+Diffusion%3A+Towards+Generalizable+Hand-Object+Interaction+Denoising+via+Denoising+Diffusion.yaml) / 2024-02-23
- [MVD$^2$: Efficient Multiview 3D Reconstruction for Multiview Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+MVD%24%5E2%24%3A+Efficient+Multiview+3D+Reconstruction+for+Multiview+Diffusion.yaml) / 2024-02-23
- [PALO: A Polyglot Large Multimodal Model for 5B People](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+PALO%3A+A+Polyglot+Large+Multimodal+Model+for+5B+People.yaml) / 2024-02-23
- [Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+Snap+Video%3A+Scaled+Spatiotemporal+Transformers+for+Text-to-Video+Synthesis.yaml) / 2024-02-23
- [Subobject-level Image Tokenization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+Subobject-level+Image+Tokenization.yaml) / 2024-02-23
- [TinyLLaVA: A Framework of Small-scale Large Multimodal Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+TinyLLaVA%3A+A+Framework+of+Small-scale+Large+Multimodal+Models.yaml) / 2024-02-23
- [CLoVe: Encoding Compositional Language in Contrastive Vision-Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/32/2024-02-26+CLoVe%3A+Encoding+Compositional+Language+in+Contrastive+Vision-Language+Models.yaml) / 2024-02-26
- [Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/32/2024-02-26+Gen4Gen%3A+Generative+Data+Pipeline+for+Generative+Multi-Concept+Composition.yaml) / 2024-02-26
- [Genie: Generative Interactive Environments](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/32/2024-02-26+Genie%3A+Generative+Interactive+Environments.yaml) / 2024-02-26
- [Seamless Human Motion Composition with Blended Positional Encodings](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/32/2024-02-26+Seamless+Human+Motion+Composition+with+Blended+Positional+Encodings.yaml) / 2024-02-26
- [Multi-LoRA Composition for Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/33/2024-02-27+Multi-LoRA+Composition+for+Image+Generation.yaml) / 2024-02-27
- [Towards Open-ended Visual Quality Comparison](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/33/2024-02-27+Towards+Open-ended+Visual+Quality+Comparison.yaml) / 2024-02-27
- [DiffuseKronA: A Parameter Efficient Fine-tuning Method for Personalized Diffusion Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+DiffuseKronA%3A+A+Parameter+Efficient+Fine-tuning+Method+for+Personalized+Diffusion+Model.yaml) / 2024-02-28
- [Disentangled 3D Scene Generation with Layout Learning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+Disentangled+3D+Scene+Generation+with+Layout+Learning.yaml) / 2024-02-28
- [EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+EMO%3A+Emote+Portrait+Alive+-+Generating+Expressive+Portrait+Videos+with+Audio2Video+Diffusion+Model+under+Weak+Conditions.yaml) / 2024-02-28
- [OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+OmniACT%3A+A+Dataset+and+Benchmark+for+Enabling+Multimodal+Generalist+Autonomous+Agents+for+Desktop+and+Web.yaml) / 2024-02-28
- [Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+Seeing+and+Hearing%3A+Open-domain+Visual-Audio+Generation+with+Diffusion+Latent+Aligners.yaml) / 2024-02-28
- [Sora Generates Videos with Stunning Geometrical Consistency](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+Sora+Generates+Videos+with+Stunning+Geometrical+Consistency.yaml) / 2024-02-28
- [Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+Sora%3A+A+Review+on+Background%2C+Technology%2C+Limitations%2C+and+Opportunities+of+Large+Vision+Models.yaml) / 2024-02-28
- [VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+VastGaussian%3A+Vast+3D+Gaussians+for+Large+Scene+Reconstruction.yaml) / 2024-02-28
- [Video as the New Language for Real-World Decision Making](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+Video+as+the+New+Language+for+Real-World+Decision+Making.yaml) / 2024-02-28
- [Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/35/2024-03-01+Panda-70M%3A+Captioning+70M+Videos+with+Multiple+Cross-Modality+Teachers.yaml) / 2024-03-01
- [Trajectory Consistency Distillation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/35/2024-03-01+Trajectory+Consistency+Distillation.yaml) / 2024-03-01
- [ViewFusion: Towards Multi-View Consistency via Interpolated Denoising](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/35/2024-03-01+ViewFusion%3A+Towards+Multi-View+Consistency+via+Interpolated+Denoising.yaml) / 2024-03-01
- [Learning and Leveraging World Models in Visual Representation Learning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/36/2024-03-04+Learning+and+Leveraging+World+Models+in+Visual+Representation+Learning.yaml) / 2024-03-04
- [RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/36/2024-03-04+RealCustom%3A+Narrowing+Real+Text+Word+for+Real-Time+Open-Domain+Text-to-Image+Customization.yaml) / 2024-03-04
- [VisionLLaMA: A Unified LLaMA Interface for Vision Tasks](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/36/2024-03-04+VisionLLaMA%3A+A+Unified+LLaMA+Interface+for+Vision+Tasks.yaml) / 2024-03-04
- [3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming of Photo-Realistic Free-Viewpoint Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+3DGStream%3A+On-the-Fly+Training+of+3D+Gaussians+for+Efficient+Streaming+of+Photo-Realistic+Free-Viewpoint+Videos.yaml) / 2024-03-05
- [AtomoVideo: High Fidelity Image-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+AtomoVideo%3A+High+Fidelity+Image-to-Video+Generation.yaml) / 2024-03-05
- [InfiMM-HD: A Leap Forward in High-Resolution Multimodal Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+InfiMM-HD%3A+A+Leap+Forward+in+High-Resolution+Multimodal+Understanding.yaml) / 2024-03-05
- [MovieLLM: Enhancing Long Video Understanding with AI-Generated Movies](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+MovieLLM%3A+Enhancing+Long+Video+Understanding+with+AI-Generated+Movies.yaml) / 2024-03-05
- [OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable Virtual Try-on](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+OOTDiffusion%3A+Outfitting+Fusion+based+Latent+Diffusion+for+Controllable+Virtual+Try-on.yaml) / 2024-03-05
- [ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+ResAdapter%3A+Domain+Consistent+Resolution+Adapter+for+Diffusion+Models.yaml) / 2024-03-05
- [TripoSR: Fast 3D Object Reconstruction from a Single Image](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+TripoSR%3A+Fast+3D+Object+Reconstruction+from+a+Single+Image.yaml) / 2024-03-05
- [Twisting Lids Off with Two Hands](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+Twisting+Lids+Off+with+Two+Hands.yaml) / 2024-03-05
- [ViewDiff: 3D-Consistent Image Generation with Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/37/2024-03-05+ViewDiff%3A+3D-Consistent+Image+Generation+with+Text-to-Image+Models.yaml) / 2024-03-05
- [Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/38/2024-03-06+Feast+Your+Eyes%3A+Mixture-of-Resolution+Adaptation+for+Multimodal+Large+Language+Models.yaml) / 2024-03-06
- [MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/38/2024-03-06+MAGID%3A+An+Automated+Pipeline+for+Generating+Synthetic+Multi-modal+Datasets.yaml) / 2024-03-06
- [MagicClay: Sculpting Meshes With Generative Neural Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/38/2024-03-06+MagicClay%3A+Sculpting+Meshes+With+Generative+Neural+Fields.yaml) / 2024-03-06
- [RT-Sketch: Goal-Conditioned Imitation Learning from Hand-Drawn Sketches](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/38/2024-03-06+RT-Sketch%3A+Goal-Conditioned+Imitation+Learning+from+Hand-Drawn+Sketches.yaml) / 2024-03-06
- [Scaling Rectified Flow Transformers for High-Resolution Image Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/38/2024-03-06+Scaling+Rectified+Flow+Transformers+for+High-Resolution+Image+Synthesis.yaml) / 2024-03-06
- [Tuning-Free Noise Rectification for High Fidelity Image-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/38/2024-03-06+Tuning-Free+Noise+Rectification+for+High+Fidelity+Image-to-Video+Generation.yaml) / 2024-03-06
- [Enhancing Vision-Language Pre-training with Rich Supervisions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/39/2024-03-07+Enhancing+Vision-Language+Pre-training+with+Rich+Supervisions.yaml) / 2024-03-07
- [How Far Are We from Intelligent Visual Deductive Reasoning?](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/40/2024-03-08+How+Far+Are+We+from+Intelligent+Visual+Deductive+Reasoning%3F.yaml) / 2024-03-08
- [Pix2Gif: Motion-Guided Diffusion for GIF Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/40/2024-03-08+Pix2Gif%3A+Motion-Guided+Diffusion+for+GIF+Generation.yaml) / 2024-03-08
- [PixArt-Î£: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/40/2024-03-08+PixArt-%CE%A3%3A+Weak-to-Strong+Training+of+Diffusion+Transformer+for+4K+Text-to-Image+Generation.yaml) / 2024-03-08
- [Radiative Gaussian Splatting for Efficient X-ray Novel View Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/40/2024-03-08+Radiative+Gaussian+Splatting+for+Efficient+X-ray+Novel+View+Synthesis.yaml) / 2024-03-08
- [StableDrag: Stable Dragging for Point-based Image Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/40/2024-03-08+StableDrag%3A+Stable+Dragging+for+Point-based+Image+Editing.yaml) / 2024-03-08
- [CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/41/2024-03-11+CRM%3A+Single+Image+to+3D+Textured+Mesh+with+Convolutional+Reconstruction+Model.yaml) / 2024-03-11
- [CogView3: Finer and Faster Text-to-Image Generation via Relay Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/41/2024-03-11+CogView3%3A+Finer+and+Faster+Text-to-Image+Generation+via+Relay+Diffusion.yaml) / 2024-03-11
- [DeepSeek-VL: Towards Real-World Vision-Language Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/41/2024-03-11+DeepSeek-VL%3A+Towards+Real-World+Vision-Language+Understanding.yaml) / 2024-03-11
- [ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/41/2024-03-11+ELLA%3A+Equip+Diffusion+Models+with+LLM+for+Enhanced+Semantic+Alignment.yaml) / 2024-03-11
- [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/41/2024-03-11+Gemini+1.5%3A+Unlocking+multimodal+understanding+across+millions+of+tokens+of+context.yaml) / 2024-03-11
- [VideoElevator: Elevating Video Generation Quality with Versatile Text-to-Image Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/41/2024-03-11+VideoElevator%3A+Elevating+Video+Generation+Quality+with+Versatile+Text-to-Image+Diffusion+Models.yaml) / 2024-03-11
- [DragAnything: Motion Control for Anything using Entity Representation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/43/2024-03-13+DragAnything%3A+Motion+Control+for+Anything+using+Entity+Representation.yaml) / 2024-03-13
- [Learning Generalizable Feature Fields for Mobile Manipulation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/43/2024-03-13+Learning+Generalizable+Feature+Fields+for+Mobile+Manipulation.yaml) / 2024-03-13
- [MoAI: Mixture of All Intelligence for Large Language and Vision Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/43/2024-03-13+MoAI%3A+Mixture+of+All+Intelligence+for+Large+Language+and+Vision+Models.yaml) / 2024-03-13
- [Motion Mamba: Efficient and Long Sequence Motion Generation with Hierarchical and Bidirectional Selective SSM](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/43/2024-03-13+Motion+Mamba%3A+Efficient+and+Long+Sequence+Motion+Generation+with+Hierarchical+and+Bidirectional+Selective+SSM.yaml) / 2024-03-13
- [Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/43/2024-03-13+Synth%24%5E2%24%3A+Boosting+Visual-Language+Models+with+Synthetic+Captions+and+Image+Embeddings.yaml) / 2024-03-13
- [3D-VLA: A 3D Vision-Language-Action Generative World Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+3D-VLA%3A+A+3D+Vision-Language-Action+Generative+World+Model.yaml) / 2024-03-15
- [GiT: Towards Generalist Vision Transformer through Universal Language Interface](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+GiT%3A+Towards+Generalist+Vision+Transformer+through+Universal+Language+Interface.yaml) / 2024-03-15
- [Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+Glyph-ByT5%3A+A+Customized+Text+Encoder+for+Accurate+Visual+Text+Rendering.yaml) / 2024-03-15
- [Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+Griffon+v2%3A+Advancing+Multimodal+Perception+with+High-Resolution+Scaling+and+Visual-Language+Co-Referring.yaml) / 2024-03-15
- [LocalMamba: Visual State Space Model with Windowed Selective Scan](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+LocalMamba%3A+Visual+State+Space+Model+with+Windowed+Selective+Scan.yaml) / 2024-03-15
- [MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+MM1%3A+Methods%2C+Analysis+%26+Insights+from+Multimodal+LLM+Pre-training.yaml) / 2024-03-15
- [StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+StreamMultiDiffusion%3A+Real-Time+Interactive+Generation+with+Region-Based+Semantic+Control.yaml) / 2024-03-15
- [Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+Unlocking+the+conversion+of+Web+Screenshots+into+HTML+Code+with+the+WebSight+Dataset.yaml) / 2024-03-15
- [Veagle: Advancements in Multimodal Representation Learning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+Veagle%3A+Advancements+in+Multimodal+Representation+Learning.yaml) / 2024-03-15
- [Video Editing via Factorized Diffusion Distillation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+Video+Editing+via+Factorized+Diffusion+Distillation.yaml) / 2024-03-15
- [Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+Video+Mamba+Suite%3A+State+Space+Model+as+a+Versatile+Alternative+for+Video+Understanding.yaml) / 2024-03-15
- [VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+VisionGPT-3D%3A+A+Generalized+Multimodal+Agent+for+Enhanced+3D+Vision+Understanding.yaml) / 2024-03-15
- [Controllable Text-to-3D Generation via Surface-Aligned Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/46/2024-03-18+Controllable+Text-to-3D+Generation+via+Surface-Aligned+Gaussian+Splatting.yaml) / 2024-03-18
- [EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/46/2024-03-18+EfficientVMamba%3A+Atrous+Selective+Scan+for+Light+Weight+Visual+Mamba.yaml) / 2024-03-18
- [FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/46/2024-03-18+FDGaussian%3A+Fast+Gaussian+Splatting+from+Single+Image+via+Geometric-aware+Diffusion+Model.yaml) / 2024-03-18
- [Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/46/2024-03-18+Isotropic3D%3A+Image-to-3D+Generation+Based+on+a+Single+CLIP+Embedding.yaml) / 2024-03-18
- [NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/46/2024-03-18+NeuFlow%3A+Real-time%2C+High-accuracy+Optical+Flow+Estimation+on+Robots+Using+Edge+Devices.yaml) / 2024-03-18
- [Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+Fast+High-Resolution+Image+Synthesis+with+Latent+Adversarial+Diffusion+Distillation.yaml) / 2024-03-19
- [Generic 3D Diffusion Adapter Using Controlled Multi-View Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+Generic+3D+Diffusion+Adapter+Using+Controlled+Multi-View+Editing.yaml) / 2024-03-19
- [Infinite-ID: Identity-preserved Personalization via ID-semantics Decoupling Paradigm](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+Infinite-ID%3A+Identity-preserved+Personalization+via+ID-semantics+Decoupling+Paradigm.yaml) / 2024-03-19
- [LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+LLaVA-UHD%3A+an+LMM+Perceiving+Any+Aspect+Ratio+and+High-Resolution+Images.yaml) / 2024-03-19
- [LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+LN3Diff%3A+Scalable+Latent+Neural+Fields+Diffusion+for+Speedy+3D+Generation.yaml) / 2024-03-19
- [LightIt: Illumination Modeling and Control for Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+LightIt%3A+Illumination+Modeling+and+Control+for+Diffusion+Models.yaml) / 2024-03-19
- [MindEye2: Shared-Subject Models Enable fMRI-To-Image With 1 Hour of Data](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+MindEye2%3A+Shared-Subject+Models+Enable+fMRI-To-Image+With+1+Hour+of+Data.yaml) / 2024-03-19
- [SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+SV3D%3A+Novel+Multi-view+Synthesis+and+3D+Generation+from+a+Single+Image+using+Latent+Video+Diffusion.yaml) / 2024-03-19
- [VFusion3D: Learning Scalable 3D Generative Models from Video Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+VFusion3D%3A+Learning+Scalable+3D+Generative+Models+from+Video+Diffusion+Models.yaml) / 2024-03-19
- [VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+VideoAgent%3A+A+Memory-augmented+Multimodal+Agent+for+Video+Understanding.yaml) / 2024-03-19
- [AnimateDiff-Lightning: Cross-Model Diffusion Distillation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+AnimateDiff-Lightning%3A+Cross-Model+Diffusion+Distillation.yaml) / 2024-03-20
- [Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+Chart-based+Reasoning%3A+Transferring+Capabilities+from+LLMs+to+VLMs.yaml) / 2024-03-20
- [ComboVerse: Compositional 3D Assets Creation Using Spatially-Aware Diffusion Guidance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+ComboVerse%3A+Compositional+3D+Assets+Creation+Using+Spatially-Aware+Diffusion+Guidance.yaml) / 2024-03-20
- [FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+FRESCO%3A+Spatial-Temporal+Correspondence+for+Zero-Shot+Video+Translation.yaml) / 2024-03-20
- [FouriScale: A Frequency Perspective on Training-Free High-Resolution Image Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+FouriScale%3A+A+Frequency+Perspective+on+Training-Free+High-Resolution+Image+Synthesis.yaml) / 2024-03-20
- [GVGEN: Text-to-3D Generation with Volumetric Representation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+GVGEN%3A+Text-to-3D+Generation+with+Volumetric+Representation.yaml) / 2024-03-20
- [GaussianFlow: Splatting Gaussian Dynamics for 4D Content Creation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+GaussianFlow%3A+Splatting+Gaussian+Dynamics+for+4D+Content+Creation.yaml) / 2024-03-20
- [TexDreamer: Towards Zero-Shot High-Fidelity 3D Human Texture Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+TexDreamer%3A+Towards+Zero-Shot+High-Fidelity+3D+Human+Texture+Generation.yaml) / 2024-03-20
- [Vid2Robot: End-to-end Video-conditioned Policy Learning with Cross-Attention Transformers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+Vid2Robot%3A+End-to-end+Video-conditioned+Policy+Learning+with+Cross-Attention+Transformers.yaml) / 2024-03-20
- [mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/48/2024-03-20+mPLUG-DocOwl+1.5%3A+Unified+Structure+Learning+for+OCR-free+Document+Understanding.yaml) / 2024-03-20
- [Be-Your-Outpainter: Mastering Video Outpainting through Input-Specific Adaptation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+Be-Your-Outpainter%3A+Mastering+Video+Outpainting+through+Input-Specific+Adaptation.yaml) / 2024-03-21
- [DepthFM: Fast Monocular Depth Estimation with Flow Matching](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+DepthFM%3A+Fast+Monocular+Depth+Estimation+with+Flow+Matching.yaml) / 2024-03-21
- [IDAdapter: Learning Mixed Features for Tuning-Free Personalization of Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+IDAdapter%3A+Learning+Mixed+Features+for+Tuning-Free+Personalization+of+Text-to-Image+Models.yaml) / 2024-03-21
- [Magic Fixup: Streamlining Photo Editing by Watching Dynamic Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+Magic+Fixup%3A+Streamlining+Photo+Editing+by+Watching+Dynamic+Videos.yaml) / 2024-03-21
- [Mora: Enabling Generalist Video Generation via A Multi-Agent Framework](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+Mora%3A+Enabling+Generalist+Video+Generation+via+A+Multi-Agent+Framework.yaml) / 2024-03-21
- [RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+RadSplat%3A+Radiance+Field-Informed+Gaussian+Splatting+for+Robust+Real-Time+Rendering+with+900%2B+FPS.yaml) / 2024-03-21
- [SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+SceneScript%3A+Reconstructing+Scenes+With+An+Autoregressive+Structured+Language+Model.yaml) / 2024-03-21
- [VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+VSTAR%3A+Generative+Temporal+Nursing+for+Longer+Dynamic+Video+Synthesis.yaml) / 2024-03-21
- [When Do We Not Need Larger Vision Models?](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+When+Do+We+Not+Need+Larger+Vision+Models%3F.yaml) / 2024-03-21
- [ZigMa: Zigzag Mamba Diffusion Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/49/2024-03-21+ZigMa%3A+Zigzag+Mamba+Diffusion+Model.yaml) / 2024-03-21
- [AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/50/2024-03-22+AnyV2V%3A+A+Plug-and-Play+Framework+For+Any+Video-to-Video+Editing+Tasks.yaml) / 2024-03-22
- [DreamReward: Text-to-3D Generation with Human Preference](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/50/2024-03-22+DreamReward%3A+Text-to-3D+Generation+with+Human+Preference.yaml) / 2024-03-22
- [Explorative Inbetweening of Time and Space](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/50/2024-03-22+Explorative+Inbetweening+of+Time+and+Space.yaml) / 2024-03-22
- [GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/50/2024-03-22+GRM%3A+Large+Gaussian+Reconstruction+Model+for+Efficient+3D+Reconstruction+and+Generation.yaml) / 2024-03-22
- [Gaussian Frosting: Editable Complex Radiance Fields with Real-Time Rendering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/50/2024-03-22+Gaussian+Frosting%3A+Editable+Complex+Radiance+Fields+with+Real-Time+Rendering.yaml) / 2024-03-22
- [MyVLM: Personalizing VLMs for User-Specific Queries](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/50/2024-03-22+MyVLM%3A+Personalizing+VLMs+for+User-Specific+Queries.yaml) / 2024-03-22
- [ReNoise: Real Image Inversion Through Iterative Noising](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/50/2024-03-22+ReNoise%3A+Real+Image+Inversion+Through+Iterative+Noising.yaml) / 2024-03-22
- [StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained StyleGAN](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/50/2024-03-22+StyleCineGAN%3A+Landscape+Cinemagraph+Generation+using+a+Pre-trained+StyleGAN.yaml) / 2024-03-22
- [Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/51/2024-03-25+Champ%3A+Controllable+and+Consistent+Human+Image+Animation+with+3D+Parametric+Guidance.yaml) / 2024-03-25
- [DragAPart: Learning a Part-Level Motion Prior for Articulated Objects](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/51/2024-03-25+DragAPart%3A+Learning+a+Part-Level+Motion+Prior+for+Articulated+Objects.yaml) / 2024-03-25
- [InternVideo2: Scaling Video Foundation Models for Multimodal Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/51/2024-03-25+InternVideo2%3A+Scaling+Video+Foundation+Models+for+Multimodal+Video+Understanding.yaml) / 2024-03-25
- [LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/51/2024-03-25+LATTE3D%3A+Large-scale+Amortized+Text-To-Enhanced3D+Synthesis.yaml) / 2024-03-25
- [SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/51/2024-03-25+SiMBA%3A+Simplified+Mamba-Based+Architecture+for+Vision+and+Multivariate+Time+series.yaml) / 2024-03-25
- [StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/51/2024-03-25+StreamingT2V%3A+Consistent%2C+Dynamic%2C+and+Extendable+Long+Video+Generation+from+Text.yaml) / 2024-03-25
- [ThemeStation: Generating Theme-Aware 3D Assets from Few Exemplars](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/51/2024-03-25+ThemeStation%3A+Generating+Theme-Aware+3D+Assets+from+Few+Exemplars.yaml) / 2024-03-25
- [VidLA: Video-Language Alignment at Scale](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/51/2024-03-25+VidLA%3A+Video-Language+Alignment+at+Scale.yaml) / 2024-03-25
- [Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/52/2024-03-26+Be+Yourself%3A+Bounded+Attention+for+Multi-Subject+Text-to-Image+Generation.yaml) / 2024-03-26
- [FlashFace: Human Image Personalization with High-fidelity Identity Preservation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/52/2024-03-26+FlashFace%3A+Human+Image+Personalization+with+High-fidelity+Identity+Preservation.yaml) / 2024-03-26
- [TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/52/2024-03-26+TRIP%3A+Temporal+Residual+Learning+with+Image+Noise+Prior+for+Image-to-Video+Diffusion+Models.yaml) / 2024-03-26
- [VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/52/2024-03-26+VP3D%3A+Unleashing+2D+Visual+Prompt+for+Text-to-3D+Generation.yaml) / 2024-03-26
- [2D Gaussian Splatting for Geometrically Accurate Radiance Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/53/2024-03-27+2D+Gaussian+Splatting+for+Geometrically+Accurate+Radiance+Fields.yaml) / 2024-03-27
- [AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/53/2024-03-27+AniPortrait%3A+Audio-Driven+Synthesis+of+Photorealistic+Portrait+Animation.yaml) / 2024-03-27
- [DreamPolisher: Towards High-Quality Text-to-3D Generation via Geometric Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/53/2024-03-27+DreamPolisher%3A+Towards+High-Quality+Text-to-3D+Generation+via+Geometric+Diffusion.yaml) / 2024-03-27
- [Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/53/2024-03-27+Octree-GS%3A+Towards+Consistent+Real-time+Rendering+with+LOD-Structured+3D+Gaussians.yaml) / 2024-03-27
- [TC4D: Trajectory-Conditioned Text-to-4D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/53/2024-03-27+TC4D%3A+Trajectory-Conditioned+Text-to-4D+Generation.yaml) / 2024-03-27
- [EgoLifter: Open-world 3D Segmentation for Egocentric Perception](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/54/2024-03-28+EgoLifter%3A+Open-world+3D+Segmentation+for+Egocentric+Perception.yaml) / 2024-03-28
- [FlexEdit: Flexible and Controllable Diffusion-based Object-centric Image Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/54/2024-03-28+FlexEdit%3A+Flexible+and+Controllable+Diffusion-based+Object-centric+Image+Editing.yaml) / 2024-03-28
- [Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/54/2024-03-28+Gamba%3A+Marry+Gaussian+Splatting+with+Mamba+for+single+view+3D+reconstruction.yaml) / 2024-03-28
- [Garment3DGen: 3D Garment Stylization and Texture Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/54/2024-03-28+Garment3DGen%3A+3D+Garment+Stylization+and+Texture+Generation.yaml) / 2024-03-28
- [Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/54/2024-03-28+Mini-Gemini%3A+Mining+the+Potential+of+Multi-modality+Vision+Language+Models.yaml) / 2024-03-28
- [ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/54/2024-03-28+ObjectDrop%3A+Bootstrapping+Counterfactuals+for+Photorealistic+Object+Removal+and+Insertion.yaml) / 2024-03-28
- [ViTAR: Vision Transformer with Any Resolution](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/54/2024-03-28+ViTAR%3A+Vision+Transformer+with+Any+Resolution.yaml) / 2024-03-28
- [GaussianCube: Structuring Gaussian Splatting using Optimal Transport for 3D Generative Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/55/2024-03-29+GaussianCube%3A+Structuring+Gaussian+Splatting+using+Optimal+Transport+for+3D+Generative+Modeling.yaml) / 2024-03-29
- [LITA: Language Instructed Temporal-Localization Assistant](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/55/2024-03-29+LITA%3A+Language+Instructed+Temporal-Localization+Assistant.yaml) / 2024-03-29
- [Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/55/2024-03-29+Mesh2NeRF%3A+Direct+Mesh+Supervision+for+Neural+Radiance+Field+Representation+and+Generation.yaml) / 2024-03-29
- [TextCraftor: Your Text Encoder Can be Image Quality Controller](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/55/2024-03-29+TextCraftor%3A+Your+Text+Encoder+Can+be+Image+Quality+Controller.yaml) / 2024-03-29
- [InstantSplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/56/2024-04-01+InstantSplat%3A+Unbounded+Sparse-view+Pose-free+Gaussian+Splatting+in+40+Seconds.yaml) / 2024-04-01
- [MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/56/2024-04-01+MambaMixer%3A+Efficient+Selective+State+Space+Models+with+Dual+Token+and+Channel+Selection.yaml) / 2024-04-01
- [Snap-it, Tap-it, Splat-it: Tactile-Informed 3D Gaussian Splatting for Reconstructing Challenging Surfaces](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/56/2024-04-01+Snap-it%2C+Tap-it%2C+Splat-it%3A+Tactile-Informed+3D+Gaussian+Splatting+for+Reconstructing+Challenging+Surfaces.yaml) / 2024-04-01
- [Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/56/2024-04-01+Unsolvable+Problem+Detection%3A+Evaluating+Trustworthiness+of+Vision+Language+Models.yaml) / 2024-04-01
- [Condition-Aware Neural Network for Controlled Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+Condition-Aware+Neural+Network+for+Controlled+Image+Generation.yaml) / 2024-04-02
- [CosmicMan: A Text-to-Image Foundation Model for Humans](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+CosmicMan%3A+A+Text-to-Image+Foundation+Model+for+Humans.yaml) / 2024-04-02
- [Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+Direct+Preference+Optimization+of+Video+Large+Multimodal+Models+from+Language+Model+Reward.yaml) / 2024-04-02
- [FlexiDreamer: Single Image-to-3D Generation with FlexiCubes](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+FlexiDreamer%3A+Single+Image-to-3D+Generation+with+FlexiCubes.yaml) / 2024-04-02
- [Getting it Right: Improving Spatial Consistency in Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+Getting+it+Right%3A+Improving+Spatial+Consistency+in+Text-to-Image+Models.yaml) / 2024-04-02
- [Measuring Style Similarity in Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+Measuring+Style+Similarity+in+Diffusion+Models.yaml) / 2024-04-02
- [ST-LLM: Large Language Models Are Effective Temporal Learners](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+ST-LLM%3A+Large+Language+Models+Are+Effective+Temporal+Learners.yaml) / 2024-04-02
- [Streaming Dense Video Captioning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+Streaming+Dense+Video+Captioning.yaml) / 2024-04-02
- [3D Congealing: 3D-Aware Image Alignment in the Wild](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/58/2024-04-03+3D+Congealing%3A+3D-Aware+Image+Alignment+in+the+Wild.yaml) / 2024-04-03
- [CameraCtrl: Enabling Camera Control for Text-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/58/2024-04-03+CameraCtrl%3A+Enabling+Camera+Control+for+Text-to-Video+Generation.yaml) / 2024-04-03
- [Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/59/2024-04-04+Cross-Attention+Makes+Inference+Cumbersome+in+Text-to-Image+Diffusion+Models.yaml) / 2024-04-04
- [Freditor: High-Fidelity and Transferable NeRF Editing by Frequency Decomposition](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/59/2024-04-04+Freditor%3A+High-Fidelity+and+Transferable+NeRF+Editing+by+Frequency+Decomposition.yaml) / 2024-04-04
- [InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/59/2024-04-04+InstantStyle%3A+Free+Lunch+towards+Style-Preserving+in+Text-to-Image+Generation.yaml) / 2024-04-04
- [On the Scalability of Diffusion-based Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/59/2024-04-04+On+the+Scalability+of+Diffusion-based+Text-to-Image+Generation.yaml) / 2024-04-04
- [Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/59/2024-04-04+Visual+Autoregressive+Modeling%3A+Scalable+Image+Generation+via+Next-Scale+Prediction.yaml) / 2024-04-04
- [AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/60/2024-04-05+AutoWebGLM%3A+Bootstrap+And+Reinforce+A+Large+Language+Model-based+Web+Navigating+Agent.yaml) / 2024-04-05
- [LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/60/2024-04-05+LVLM-Intrepret%3A+An+Interpretability+Tool+for+Large+Vision-Language+Models.yaml) / 2024-04-05
- [MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/60/2024-04-05+MiniGPT4-Video%3A+Advancing+Multimodal+LLMs+for+Video+Understanding+with+Interleaved+Visual-Textual+Tokens.yaml) / 2024-04-05
- [PointInfinity: Resolution-Invariant Point Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/60/2024-04-05+PointInfinity%3A+Resolution-Invariant+Point+Diffusion+Models.yaml) / 2024-04-05
- [No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/61/2024-04-08+No+%22Zero-Shot%22+Without+Exponential+Data%3A+Pretraining+Concept+Frequency+Determines+Multimodal+Model+Performance.yaml) / 2024-04-08
- [RL for Consistency Models: Faster Reward Guided Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/61/2024-04-08+RL+for+Consistency+Models%3A+Faster+Reward+Guided+Text-to-Image+Generation.yaml) / 2024-04-08
- [Robust Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/61/2024-04-08+Robust+Gaussian+Splatting.yaml) / 2024-04-08
- [Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/61/2024-04-08+Sigma%3A+Siamese+Mamba+Network+for+Multi-Modal+Semantic+Segmentation.yaml) / 2024-04-08
- [BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+BeyondScene%3A+Higher-Resolution+Human-Centric+Scene+Generation+With+Pretrained+Diffusion.yaml) / 2024-04-09
- [ByteEdit: Boost, Comply and Accelerate Generative Image Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+ByteEdit%3A+Boost%2C+Comply+and+Accelerate+Generative+Image+Editing.yaml) / 2024-04-09
- [DATENeRF: Depth-Aware Text-based Editing of NeRFs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+DATENeRF%3A+Depth-Aware+Text-based+Editing+of+NeRFs.yaml) / 2024-04-09
- [Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+Diffusion-RWKV%3A+Scaling+RWKV-Like+Architectures+for+Diffusion+Models.yaml) / 2024-04-09
- [Koala: Key frame-conditioned long video-LLM](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+Koala%3A+Key+frame-conditioned+long+video-LLM.yaml) / 2024-04-09
- [MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+MA-LMM%3A+Memory-Augmented+Large+Multimodal+Model+for+Long-Term+Video+Understanding.yaml) / 2024-04-09
- [MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+MagicTime%3A+Time-lapse+Video+Generation+Models+as+Metamorphic+Simulators.yaml) / 2024-04-09
- [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+MoMA%3A+Multimodal+LLM+Adapter+for+Fast+Personalized+Image+Generation.yaml) / 2024-04-09
- [PhysAvatar: Learning the Physics of Dressed 3D Avatars from Visual Observations](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+PhysAvatar%3A+Learning+the+Physics+of+Dressed+3D+Avatars+from+Visual+Observations.yaml) / 2024-04-09
- [SpatialTracker: Tracking Any 2D Pixels in 3D Space](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+SpatialTracker%3A+Tracking+Any+2D+Pixels+in+3D+Space.yaml) / 2024-04-09
- [SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+SwapAnything%3A+Enabling+Arbitrary+Object+Swapping+in+Personalized+Visual+Editing.yaml) / 2024-04-09
- [UniFL: Improve Stable Diffusion via Unified Feedback Learning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+UniFL%3A+Improve+Stable+Diffusion+via+Unified+Feedback+Learning.yaml) / 2024-04-09
- [YaART: Yet Another ART Rendering Technology](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/62/2024-04-09+YaART%3A+Yet+Another+ART+Rendering+Technology.yaml) / 2024-04-09
- [Hash3D: Training-free Acceleration for 3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/63/2024-04-10+Hash3D%3A+Training-free+Acceleration+for+3D+Generation.yaml) / 2024-04-10
- [InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/63/2024-04-10+InternLM-XComposer2-4KHD%3A+A+Pioneering+Large+Vision-Language+Model+Handling+Resolutions+from+336+Pixels+to+4K+HD.yaml) / 2024-04-10
- [Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/63/2024-04-10+Magic-Boost%3A+Boost+3D+Generation+with+Mutli-View+Conditioned+Diffusion.yaml) / 2024-04-10
- [OmniFusion Technical Report](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/63/2024-04-10+OmniFusion+Technical+Report.yaml) / 2024-04-10
- [Reconstructing Hand-Held Objects in 3D](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/63/2024-04-10+Reconstructing+Hand-Held+Objects+in+3D.yaml) / 2024-04-10
- [Revising Densification in Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/63/2024-04-10+Revising+Densification+in+Gaussian+Splatting.yaml) / 2024-04-10
- [Adapting LLaMA Decoder to Vision Transformer](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/64/2024-04-11+Adapting+LLaMA+Decoder+to+Vision+Transformer.yaml) / 2024-04-11
- [BRAVE: Broadening the visual encoding of vision-language models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/64/2024-04-11+BRAVE%3A+Broadening+the+visual+encoding+of+vision-language+models.yaml) / 2024-04-11
- [DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/64/2024-04-11+DreamScene360%3A+Unconstrained+Text-to-3D+Scene+Generation+with+Panoramic+Gaussian+Splatting.yaml) / 2024-04-11
- [RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/64/2024-04-11+RealmDreamer%3A+Text-Driven+3D+Scene+Generation+with+Inpainting+and+Depth+Diffusion.yaml) / 2024-04-11
- [Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/64/2024-04-11+Urban+Architect%3A+Steerable+3D+Urban+Scene+Generation+with+Layout+Prior.yaml) / 2024-04-11
- [Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/65/2024-04-12+Applying+Guidance+in+a+Limited+Interval+Improves+Sample+and+Distribution+Quality+in+Diffusion+Models.yaml) / 2024-04-12
- [ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/65/2024-04-12+ControlNet%2B%2B%3A+Improving+Conditional+Controls+with+Efficient+Consistency+Feedback.yaml) / 2024-04-12
- [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/65/2024-04-12+Ferret-v2%3A+An+Improved+Baseline+for+Referring+and+Grounding+with+Large+Language+Models.yaml) / 2024-04-12
- [OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/65/2024-04-12+OSWorld%3A+Benchmarking+Multimodal+Agents+for+Open-Ended+Tasks+in+Real+Computer+Environments.yaml) / 2024-04-12
- [Sparse Laneformer](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/65/2024-04-12+Sparse+Laneformer.yaml) / 2024-04-12
- [COCONut: Modernizing COCO Segmentation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/66/2024-04-15+COCONut%3A+Modernizing+COCO+Segmentation.yaml) / 2024-04-15
- [MonoPatchNeRF: Improving Neural Radiance Fields with Patch-based Monocular Guidance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/66/2024-04-15+MonoPatchNeRF%3A+Improving+Neural+Radiance+Fields+with+Patch-based+Monocular+Guidance.yaml) / 2024-04-15
- [On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/66/2024-04-15+On+the+Robustness+of+Language+Guidance+for+Low-Level+Vision+Tasks%3A+Findings+from+Depth+Estimation.yaml) / 2024-04-15
- [Probing the 3D Awareness of Visual Foundation Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/66/2024-04-15+Probing+the+3D+Awareness+of+Visual+Foundation+Models.yaml) / 2024-04-15
- [Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/66/2024-04-15+Scaling+%28Down%29+CLIP%3A+A+Comprehensive+Analysis+of+Data%2C+Architecture%2C+and+Training+Strategies.yaml) / 2024-04-15
- [CompGS: Efficient 3D Scene Representation via Compressed Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/67/2024-04-16+CompGS%3A+Efficient+3D+Scene+Representation+via+Compressed+Gaussian+Splatting.yaml) / 2024-04-16
- [Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/67/2024-04-16+Ctrl-Adapter%3A+An+Efficient+and+Versatile+Framework+for+Adapting+Diverse+Controls+to+Any+Diffusion+Model.yaml) / 2024-04-16
- [HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/67/2024-04-16+HQ-Edit%3A+A+High-Quality+Dataset+for+Instruction-based+Image+Editing.yaml) / 2024-04-16
- [Taming Latent Diffusion Model for Neural Radiance Field Inpainting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/67/2024-04-16+Taming+Latent+Diffusion+Model+for+Neural+Radiance+Field+Inpainting.yaml) / 2024-04-16
- [Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/67/2024-04-16+Video2Game%3A+Real-time%2C+Interactive%2C+Realistic+and+Browser-Compatible+Environment+from+a+Single+Video.yaml) / 2024-04-16
- [Scaling Instructable Agents Across Many Simulated Worlds](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/68/2024-04-17+Scaling+Instructable+Agents+Across+Many+Simulated+Worlds.yaml) / 2024-04-17
- [AniClipart: Clipart Animation with Text-to-Video Priors](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/69/2024-04-19+AniClipart%3A+Clipart+Animation+with+Text-to-Video+Priors.yaml) / 2024-04-19
- [BLINK: Multimodal Large Language Models Can See but Not Perceive](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/69/2024-04-19+BLINK%3A+Multimodal+Large+Language+Models+Can+See+but+Not+Perceive.yaml) / 2024-04-19
- [Dynamic Typography: Bringing Words to Life](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/69/2024-04-19+Dynamic+Typography%3A+Bringing+Words+to+Life.yaml) / 2024-04-19
- [EdgeFusion: On-Device Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/69/2024-04-19+EdgeFusion%3A+On-Device+Text-to-Image+Generation.yaml) / 2024-04-19
- [MeshLRM: Large Reconstruction Model for High-Quality Mesh](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/69/2024-04-19+MeshLRM%3A+Large+Reconstruction+Model+for+High-Quality+Mesh.yaml) / 2024-04-19
- [MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/69/2024-04-19+MoA%3A+Mixture-of-Attention+for+Subject-Context+Disentanglement+in+Personalized+Image+Generation.yaml) / 2024-04-19
- [Does Gaussian Splatting need SFM Initialization?](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/70/2024-04-22+Does+Gaussian+Splatting+need+SFM+Initialization%3F.yaml) / 2024-04-22
- [Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/70/2024-04-22+Groma%3A+Localized+Visual+Tokenization+for+Grounding+Multimodal+Large+Language+Models.yaml) / 2024-04-22
- [PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/70/2024-04-22+PhysDreamer%3A+Physics-Based+Interaction+with+3D+Objects+via+Video+Generation.yaml) / 2024-04-22
- [TextSquare: Scaling up Text-Centric Visual Instruction Tuning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/70/2024-04-22+TextSquare%3A+Scaling+up+Text-Centric+Visual+Instruction+Tuning.yaml) / 2024-04-22
- [CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/72/2024-04-25+CatLIP%3A+CLIP-level+Visual+Recognition+Accuracy+with+2.7x+Faster+Pre-training+on+Web-scale+Image-Text+Data.yaml) / 2024-04-25
- [Editable Image Elements for Controllable Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/72/2024-04-25+Editable+Image+Elements+for+Controllable+Synthesis.yaml) / 2024-04-25
- [ID-Aligner: Enhancing Identity-Preserving Text-to-Image Generation with Reward Feedback Learning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/72/2024-04-25+ID-Aligner%3A+Enhancing+Identity-Preserving+Text-to-Image+Generation+with+Reward+Feedback+Learning.yaml) / 2024-04-25
- [MaGGIe: Masked Guided Gradual Human Instance Matting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/72/2024-04-25+MaGGIe%3A+Masked+Guided+Gradual+Human+Instance+Matting.yaml) / 2024-04-25
- [MoDE: CLIP Data Experts via Clustering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/72/2024-04-25+MoDE%3A+CLIP+Data+Experts+via+Clustering.yaml) / 2024-04-25
- [MotionMaster: Training-free Camera Motion Transfer For Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/72/2024-04-25+MotionMaster%3A+Training-free+Camera+Motion+Transfer+For+Video+Generation.yaml) / 2024-04-25
- [PuLID: Pure and Lightning ID Customization via Contrastive Alignment](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/72/2024-04-25+PuLID%3A+Pure+and+Lightning+ID+Customization+via+Contrastive+Alignment.yaml) / 2024-04-25
- [ConsistentID: Portrait Generation with Multimodal Fine-Grained Identity Preserving](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/73/2024-04-26+ConsistentID%3A+Portrait+Generation+with+Multimodal+Fine-Grained+Identity+Preserving.yaml) / 2024-04-26
- [How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/73/2024-04-26+How+Far+Are+We+to+GPT-4V%3F+Closing+the+Gap+to+Commercial+Multimodal+Models+with+Open-Source+Suites.yaml) / 2024-04-26
- [Interactive3D: Create What You Want by Interactive 3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/73/2024-04-26+Interactive3D%3A+Create+What+You+Want+by+Interactive+3D+Generation.yaml) / 2024-04-26
- [List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/73/2024-04-26+List+Items+One+by+One%3A+A+New+Data+Source+and+Learning+Paradigm+for+Multimodal+LLMs.yaml) / 2024-04-26
- [Revisiting Text-to-Image Evaluation with Gecko: On Metrics, Prompts, and Human Ratings](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/73/2024-04-26+Revisiting+Text-to-Image+Evaluation+with+Gecko%3A+On+Metrics%2C+Prompts%2C+and+Human+Ratings.yaml) / 2024-04-26
- [SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/73/2024-04-26+SEED-Bench-2-Plus%3A+Benchmarking+Multimodal+Large+Language+Models+with+Text-Rich+Visual+Comprehension.yaml) / 2024-04-26
- [HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained Photo Collections](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/74/2024-04-29+HaLo-NeRF%3A+Learning+Geometry-Guided+Semantics+for+Exploring+Unconstrained+Photo+Collections.yaml) / 2024-04-29
- [MaPa: Text-driven Photorealistic Material Painting for 3D Shapes](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/74/2024-04-29+MaPa%3A+Text-driven+Photorealistic+Material+Painting+for+3D+Shapes.yaml) / 2024-04-29
- [PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/74/2024-04-29+PLLaVA+%3A+Parameter-free+LLaVA+Extension+from+Images+to+Videos+for+Video+Dense+Captioning.yaml) / 2024-04-29
- [BlenderAlchemy: Editing 3D Graphics with Vision-Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/75/2024-04-30+BlenderAlchemy%3A+Editing+3D+Graphics+with+Vision-Language+Models.yaml) / 2024-04-30
- [DressCode: Autoregressively Sewing and Generating Garments from Text Guidance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/75/2024-04-30+DressCode%3A+Autoregressively+Sewing+and+Generating+Garments+from+Text+Guidance.yaml) / 2024-04-30
- [Stylus: Automatic Adapter Selection for Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/75/2024-04-30+Stylus%3A+Automatic+Adapter+Selection+for+Diffusion+Models.yaml) / 2024-04-30
- [DOCCI: Descriptions of Connected and Contrasting Images](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+DOCCI%3A+Descriptions+of+Connected+and+Contrasting+Images.yaml) / 2024-05-01
- [GS-LRM: Large Reconstruction Model for 3D Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+GS-LRM%3A+Large+Reconstruction+Model+for+3D+Gaussian+Splatting.yaml) / 2024-05-01
- [InstantFamily: Masked Attention for Zero-shot Multi-ID Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+InstantFamily%3A+Masked+Attention+for+Zero-shot+Multi-ID+Image+Generation.yaml) / 2024-05-01
- [Invisible Stitch: Generating Smooth 3D Scenes with Depth Inpainting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+Invisible+Stitch%3A+Generating+Smooth+3D+Scenes+with+Depth+Inpainting.yaml) / 2024-05-01
- [Lightplane: Highly-Scalable Components for Neural 3D Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+Lightplane%3A+Highly-Scalable+Components+for+Neural+3D+Fields.yaml) / 2024-05-01
- [MicroDreamer: Zero-shot 3D Generation in $\sim$20 Seconds by Score-based Iterative Reconstruction](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+MicroDreamer%3A+Zero-shot+3D+Generation+in+%24%5Csim%2420+Seconds+by+Score-based+Iterative+Reconstruction.yaml) / 2024-05-01
- [MotionLCM: Real-time Controllable Motion Generation via Latent Consistency Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+MotionLCM%3A+Real-time+Controllable+Motion+Generation+via+Latent+Consistency+Model.yaml) / 2024-05-01
- [SAGS: Structure-Aware 3D Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+SAGS%3A+Structure-Aware+3D+Gaussian+Splatting.yaml) / 2024-05-01
- [Visual Fact Checker: Enabling High-Fidelity Detailed Caption Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/76/2024-05-01+Visual+Fact+Checker%3A+Enabling+High-Fidelity+Detailed+Caption+Generation.yaml) / 2024-05-01
- [Automatic Creative Selection with Cross-Modal Matching](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/77/2024-05-02+Automatic+Creative+Selection+with+Cross-Modal+Matching.yaml) / 2024-05-02
- [Paint by Inpaint: Learning to Add Image Objects by Removing Them First](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/77/2024-05-02+Paint+by+Inpaint%3A+Learning+to+Add+Image+Objects+by+Removing+Them+First.yaml) / 2024-05-02
- [STT: Stateful Tracking with Transformers for Autonomous Driving](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/77/2024-05-02+STT%3A+Stateful+Tracking+with+Transformers+for+Autonomous+Driving.yaml) / 2024-05-02
- [SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/77/2024-05-02+SemantiCodec%3A+An+Ultra+Low+Bitrate+Semantic+Audio+Codec+for+General+Sound.yaml) / 2024-05-02
- [Customizing Text-to-Image Models with a Single Image Pair](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/78/2024-05-03+Customizing+Text-to-Image+Models+with+a+Single+Image+Pair.yaml) / 2024-05-03
- [LLM-AD: Large Language Model based Audio Description System](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/78/2024-05-03+LLM-AD%3A+Large+Language+Model+based+Audio+Description+System.yaml) / 2024-05-03
- [StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/78/2024-05-03+StoryDiffusion%3A+Consistent+Self-Attention+for+Long-Range+Image+and+Video+Generation.yaml) / 2024-05-03
- [LogoMotion: Visually Grounded Code Generation for Content-Aware Animation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/79/2024-05-14+LogoMotion%3A+Visually+Grounded+Code+Generation+for+Content-Aware+Animation.yaml) / 2024-05-14
- [What matters when building vision-language models?](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/79/2024-05-14+What+matters+when+building+vision-language+models%3F.yaml) / 2024-05-14
- [Coin3D: Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/80/2024-05-15+Coin3D%3A+Controllable+and+Interactive+3D+Assets+Generation+with+Proxy-Guided+Conditioning.yaml) / 2024-05-15
- [Compositional Text-to-Image Generation with Dense Blob Representations](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/80/2024-05-15+Compositional+Text-to-Image+Generation+with+Dense+Blob+Representations.yaml) / 2024-05-15
- [Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/80/2024-05-15+Hunyuan-DiT%3A+A+Powerful+Multi-Resolution+Diffusion+Transformer+with+Fine-Grained+Chinese+Understanding.yaml) / 2024-05-15
- [No Time to Waste: Squeeze Time into Channel for Mobile Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/80/2024-05-15+No+Time+to+Waste%3A+Squeeze+Time+into+Channel+for+Mobile+Video+Understanding.yaml) / 2024-05-15
- [VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/80/2024-05-15+VidProM%3A+A+Million-scale+Real+Prompt-Gallery+Dataset+for+Text-to-Video+Diffusion+Models.yaml) / 2024-05-15
- [BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/81/2024-05-16+BEHAVIOR+Vision+Suite%3A+Customizable+Dataset+Generation+via+Simulation.yaml) / 2024-05-16
- [CAT3D: Create Anything in 3D with Multi-View Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/82/2024-05-17+CAT3D%3A+Create+Anything+in+3D+with+Multi-View+Diffusion+Models.yaml) / 2024-05-17
- [Chameleon: Mixed-Modal Early-Fusion Foundation Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/82/2024-05-17+Chameleon%3A+Mixed-Modal+Early-Fusion+Foundation+Models.yaml) / 2024-05-17
- [Dual3D: Efficient and Consistent Text-to-3D Generation with Dual-mode Multi-view Latent Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/82/2024-05-17+Dual3D%3A+Efficient+and+Consistent+Text-to-3D+Generation+with+Dual-mode+Multi-view+Latent+Diffusion.yaml) / 2024-05-17
- [Grounding DINO 1.5: Advance the "Edge" of Open-Set Object Detection](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/82/2024-05-17+Grounding+DINO+1.5%3A+Advance+the+%22Edge%22+of+Open-Set+Object+Detection.yaml) / 2024-05-17
- [Toon3D: Seeing Cartoons from a New Perspective](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/82/2024-05-17+Toon3D%3A+Seeing+Cartoons+from+a+New+Perspective.yaml) / 2024-05-17
- [Grounded 3D-LLM with Referent Tokens](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/83/2024-05-20+Grounded+3D-LLM+with+Referent+Tokens.yaml) / 2024-05-20
- [Dreamer XL: Towards High-Resolution Text-to-3D Generation via Trajectory Score Matching](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/84/2024-05-21+Dreamer+XL%3A+Towards+High-Resolution+Text-to-3D+Generation+via+Trajectory+Score+Matching.yaml) / 2024-05-21
- [FIFO-Diffusion: Generating Infinite Videos from Text without Training](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/84/2024-05-21+FIFO-Diffusion%3A+Generating+Infinite+Videos+from+Text+without+Training.yaml) / 2024-05-21
- [Octo: An Open-Source Generalist Robot Policy](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/84/2024-05-21+Octo%3A+An+Open-Source+Generalist+Robot+Policy.yaml) / 2024-05-21
- [Face Adapter for Pre-Trained Diffusion Models with Fine-Grained ID and Attribute Control](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/85/2024-05-22+Face+Adapter+for+Pre-Trained+Diffusion+Models+with+Fine-Grained+ID+and+Attribute+Control.yaml) / 2024-05-22
- [OmniGlue: Generalizable Feature Matching with Foundation Model Guidance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/85/2024-05-22+OmniGlue%3A+Generalizable+Feature+Matching+with+Foundation+Model+Guidance.yaml) / 2024-05-22
- [Personalized Residuals for Concept-Driven Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/85/2024-05-22+Personalized+Residuals+for+Concept-Driven+Text-to-Image+Generation.yaml) / 2024-05-22
- [CamViG: Camera Aware Image-to-Video Generation with Multimodal Transformers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+CamViG%3A+Camera+Aware+Image-to-Video+Generation+with+Multimodal+Transformers.yaml) / 2024-05-24
- [Dense Connector for MLLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+Dense+Connector+for+MLLMs.yaml) / 2024-05-24
- [DiM: Diffusion Mamba for Efficient High-Resolution Image Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+DiM%3A+Diffusion+Mamba+for+Efficient+High-Resolution+Image+Synthesis.yaml) / 2024-05-24
- [Improved Distribution Matching Distillation for Fast Image Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+Improved+Distribution+Matching+Distillation+for+Fast+Image+Synthesis.yaml) / 2024-05-24
- [Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+Neural+Directional+Encoding+for+Efficient+and+Accurate+View-Dependent+Appearance+Modeling.yaml) / 2024-05-24
- [ReVideo: Remake a Video with Motion and Content Control](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+ReVideo%3A+Remake+a+Video+with+Motion+and+Content+Control.yaml) / 2024-05-24
- [RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+RectifID%3A+Personalizing+Rectified+Flow+with+Anchored+Classifier+Guidance.yaml) / 2024-05-24
- [Semantica: An Adaptable Image-Conditioned Diffusion Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+Semantica%3A+An+Adaptable+Image-Conditioned+Diffusion+Model.yaml) / 2024-05-24
- [Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using Sparse RGB Cameras](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+Tele-Aloha%3A+A+Low-budget+and+High-authenticity+Telepresence+System+Using+Sparse+RGB+Cameras.yaml) / 2024-05-24
- [Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/86/2024-05-24+Visual+Echoes%3A+A+Simple+Unified+Transformer+for+Audio-Visual+Generation.yaml) / 2024-05-24
- [ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/87/2024-05-27+ConvLLaVA%3A+Hierarchical+Backbones+as+Visual+Encoder+for+Large+Multimodal+Models.yaml) / 2024-05-27
- [CraftsMan: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/87/2024-05-27+CraftsMan%3A+High-fidelity+Mesh+Generation+with+3D+Native+Generation+and+Interactive+Geometry+Refiner.yaml) / 2024-05-27
- [HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/87/2024-05-27+HDR-GS%3A+Efficient+High+Dynamic+Range+Novel+View+Synthesis+at+1000x+Speed+via+Gaussian+Splatting.yaml) / 2024-05-27
- [Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/87/2024-05-27+Meteor%3A+Mamba-based+Traversal+of+Rationale+for+Large+Language+and+Vision+Models.yaml) / 2024-05-27
- [iVideoGPT: Interactive VideoGPTs are Scalable World Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/87/2024-05-27+iVideoGPT%3A+Interactive+VideoGPTs+are+Scalable+World+Models.yaml) / 2024-05-27
- [An Introduction to Vision-Language Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/88/2024-05-28+An+Introduction+to+Vision-Language+Modeling.yaml) / 2024-05-28
- [Human4DiT: Free-view Human Video Generation with 4D Diffusion Transformer](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/88/2024-05-28+Human4DiT%3A+Free-view+Human+Video+Generation+with+4D+Diffusion+Transformer.yaml) / 2024-05-28
- [I2VEdit: First-Frame-Guided Video Editing via Image-to-Video Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/88/2024-05-28+I2VEdit%3A+First-Frame-Guided+Video+Editing+via+Image-to-Video+Diffusion+Models.yaml) / 2024-05-28
- [Looking Backward: Streaming Video-to-Video Translation with Feature Banks](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/88/2024-05-28+Looking+Backward%3A+Streaming+Video-to-Video+Translation+with+Feature+Banks.yaml) / 2024-05-28
- [Matryoshka Multimodal Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/88/2024-05-28+Matryoshka+Multimodal+Models.yaml) / 2024-05-28
- [Part123: Part-aware 3D Reconstruction from a Single-view Image](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/88/2024-05-28+Part123%3A+Part-aware+3D+Reconstruction+from+a+Single-view+Image.yaml) / 2024-05-28
- [Vidu4D: Single Generated Video to High-Fidelity 4D Reconstruction with Dynamic Gaussian Surfels](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/88/2024-05-28+Vidu4D%3A+Single+Generated+Video+to+High-Fidelity+4D+Reconstruction+with+Dynamic+Gaussian+Surfels.yaml) / 2024-05-28
- [3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/89/2024-05-29+3DitScene%3A+Editing+Any+Scene+via+Language-guided+Disentangled+Gaussian+Splatting.yaml) / 2024-05-29
- [GFlow: Recovering 4D World from Monocular Video](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/89/2024-05-29+GFlow%3A+Recovering+4D+World+from+Monocular+Video.yaml) / 2024-05-29
- [Phased Consistency Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/89/2024-05-29+Phased+Consistency+Model.yaml) / 2024-05-29
- [Atlas3D: Physically Constrained Self-Supporting Text-to-3D for Simulation and Fabrication](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/90/2024-05-30+Atlas3D%3A+Physically+Constrained+Self-Supporting+Text-to-3D+for+Simulation+and+Fabrication.yaml) / 2024-05-30
- [EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/90/2024-05-30+EasyAnimate%3A+A+High-Performance+Long+Video+Generation+Method+based+on+Transformer+Architecture.yaml) / 2024-05-30
- [NPGA: Neural Parametric Gaussian Avatars](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/90/2024-05-30+NPGA%3A+Neural+Parametric+Gaussian+Avatars.yaml) / 2024-05-30
- [T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/90/2024-05-30+T2V-Turbo%3A+Breaking+the+Quality+Bottleneck+of+Video+Consistency+Model+with+Mixed+Reward+Feedback.yaml) / 2024-05-30
- [DeMamba: AI-Generated Video Detection on Million-Scale GenVideo Benchmark](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/91/2024-05-31+DeMamba%3A+AI-Generated+Video+Detection+on+Million-Scale+GenVideo+Benchmark.yaml) / 2024-05-31
- [GECO: Generative Image-to-3D within a SECOnd](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/91/2024-05-31+GECO%3A+Generative+Image-to-3D+within+a+SECOnd.yaml) / 2024-05-31
- [MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/91/2024-05-31+MOFA-Video%3A+Controllable+Image+Animation+via+Generative+Motion+Field+Adaptions+in+Frozen+Image-to-Video+Diffusion+Model.yaml) / 2024-05-31
- [MotionLLM: Understanding Human Behaviors from Human Motions and Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/91/2024-05-31+MotionLLM%3A+Understanding+Human+Behaviors+from+Human+Motions+and+Videos.yaml) / 2024-05-31
- [PLA4D: Pixel-Level Alignments for Text-to-4D Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/91/2024-05-31+PLA4D%3A+Pixel-Level+Alignments+for+Text-to-4D+Gaussian+Splatting.yaml) / 2024-05-31
- [4Diffusion: Multi-view Video Diffusion Model for 4D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/92/2024-06-03+4Diffusion%3A+Multi-view+Video+Diffusion+Model+for+4D+Generation.yaml) / 2024-06-03
- [Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/92/2024-06-03+Video-MME%3A+The+First-Ever+Comprehensive+Evaluation+Benchmark+of+Multi-modal+LLMs+in+Video+Analysis.yaml) / 2024-06-03
- [Learning Temporally Consistent Video Depth from Video Diffusion Priors](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/93/2024-06-04+Learning+Temporally+Consistent+Video+Depth+from+Video+Diffusion+Priors.yaml) / 2024-06-04
- [ZeroSmooth: Training-free Diffuser Adaptation for High Frame Rate Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/93/2024-06-04+ZeroSmooth%3A+Training-free+Diffuser+Adaptation+for+High+Frame+Rate+Video+Generation.yaml) / 2024-06-04
- [CamCo: Camera-Controllable 3D-Consistent Image-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/94/2024-06-05+CamCo%3A+Camera-Controllable+3D-Consistent+Image-to-Video+Generation.yaml) / 2024-06-05
- [Guiding a Diffusion Model with a Bad Version of Itself](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/94/2024-06-05+Guiding+a+Diffusion+Model+with+a+Bad+Version+of+Itself.yaml) / 2024-06-05
- [I4VGen: Image as Stepping Stone for Text-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/94/2024-06-05+I4VGen%3A+Image+as+Stepping+Stone+for+Text-to-Video+Generation.yaml) / 2024-06-05
- [V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/94/2024-06-05+V-Express%3A+Conditional+Dropout+for+Progressive+Training+of+Portrait+Video+Generation.yaml) / 2024-06-05
