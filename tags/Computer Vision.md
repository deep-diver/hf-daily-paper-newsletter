- [ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+ANIM-400K%3A+A+Large-Scale+Dataset+for+Automated+End-To-End+Dubbing+of+Video.yaml) / 2024-01-11 00:00
- [InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+InseRF%3A+Text-Driven+Generative+Object+Insertion+in+Neural+3D+Scenes.yaml) / 2024-01-11 00:00
- [PIXART-δ: Fast and Controllable Image Generation with Latent Consistency Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+PIXART-%CE%B4%3A+Fast+and+Controllable+Image+Generation+with+Latent+Consistency+Models.yaml) / 2024-01-11 00:00
- [URHand: Universal Relightable Hands](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+URHand%3A+Universal+Relightable+Hands.yaml) / 2024-01-11 00:00
- [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Diffusion+Priors+for+Dynamic+View+Synthesis+from+Monocular+Videos.yaml) / 2024-01-12
- [Distilling Vision-Language Models on Millions of Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Distilling+Vision-Language+Models+on+Millions+of+Videos.yaml) / 2024-01-12
- [Efficient LLM inference solution on Intel GPU](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Efficient+LLM+inference+solution+on+Intel+GPU.yaml) / 2024-01-12
- [LEGO:Language Enhanced Multi-modal Grounding Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+LEGO%3ALanguage+Enhanced+Multi-modal+Grounding+Model.yaml) / 2024-01-12
- [Object-Centric Diffusion for Efficient Video Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Object-Centric+Diffusion+for+Efficient+Video+Editing.yaml) / 2024-01-12
- [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+PALP%3A+Prompt+Aligned+Personalization+of+Text-to-Image+Models.yaml) / 2024-01-12
- [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Parrot%3A+Pareto-optimal+Multi-Reward+Reinforcement+Learning+Framework+for+Text-to-Image+Generation.yaml) / 2024-01-12
- [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+TRIPS%3A+Trilinear+Point+Splatting+for+Real-Time+Radiance+Field+Rendering.yaml) / 2024-01-12
- [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Diffusion+Priors+for+Dynamic+View+Synthesis+from+Monocular+Videos.yaml) / 2024-01-12
- [Distilling Vision-Language Models on Millions of Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Distilling+Vision-Language+Models+on+Millions+of+Videos.yaml) / 2024-01-12
- [LEGO:Language Enhanced Multi-modal Grounding Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+LEGO%3ALanguage+Enhanced+Multi-modal+Grounding+Model.yaml) / 2024-01-12
- [Object-Centric Diffusion for Efficient Video Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Object-Centric+Diffusion+for+Efficient+Video+Editing.yaml) / 2024-01-12
- [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+PALP%3A+Prompt+Aligned+Personalization+of+Text-to-Image+Models.yaml) / 2024-01-12
- [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Parrot%3A+Pareto-optimal+Multi-Reward+Reinforcement+Learning+Framework+for+Text-to-Image+Generation.yaml) / 2024-01-12
- [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+TRIPS%3A+Trilinear+Point+Splatting+for+Real-Time+Radiance+Field+Rendering.yaml) / 2024-01-12
- [Towards Conversational Diagnostic AI](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Towards+Conversational+Diagnostic+AI.yaml) / 2024-01-12
- [HexaGen3D: StableDiffusion is just one step away from Fast and Diverse Text-to-3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+HexaGen3D%3A+StableDiffusion+is+just+one+step+away+from+Fast+and+Diverse+Text-to-3D+Generation.yaml) / 2024-01-17
- [InstantID: Zero-shot Identity-Preserving Generation in Seconds](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+InstantID%3A+Zero-shot+Identity-Preserving+Generation+in+Seconds.yaml) / 2024-01-17
- [Quantum Denoising Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Quantum+Denoising+Diffusion+Models.yaml) / 2024-01-17
- [Scalable Pre-training of Large Autoregressive Image Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Scalable+Pre-training+of+Large+Autoregressive+Image+Models.yaml) / 2024-01-17
- [Towards A Better Metric for Text-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Towards+A+Better+Metric+for+Text-to-Video+Generation.yaml) / 2024-01-17
- [Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+Compose+and+Conquer%3A+Diffusion-Based+3D+Depth+Aware+Composable+Image+Synthesis.yaml) / 2024-01-18
- [GARField: Group Anything with Radiance Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+GARField%3A+Group+Anything+with+Radiance+Fields.yaml) / 2024-01-18
- [ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+ICON%3A+Incremental+CONfidence+for+Joint+Pose+and+Radiance+Field+Optimization.yaml) / 2024-01-18
- [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+SceneVerse%3A+Scaling+3D+Vision-Language+Learning+for+Grounded+Scene+Understanding.yaml) / 2024-01-18
- [SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+SiT%3A+Exploring+Flow+and+Diffusion-based+Generative+Models+with+Scalable+Interpolant+Transformers.yaml) / 2024-01-18
- [TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+TextureDreamer%3A+Image-guided+Texture+Synthesis+through+Geometry-aware+Diffusion.yaml) / 2024-01-18
- [UniVG: Towards UNIfied-modal Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+UniVG%3A+Towards+UNIfied-modal+Video+Generation.yaml) / 2024-01-18
- [VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+VideoCrafter2%3A+Overcoming+Data+Limitations+for+High-Quality+Video+Diffusion+Models.yaml) / 2024-01-18
- [Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+Vision+Mamba%3A+Efficient+Visual+Representation+Learning+with+Bidirectional+State+Space+Model.yaml) / 2024-01-18
- [CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+CustomVideo%3A+Customizing+Text-to-Video+Generation+with+Multiple+Subjects.yaml) / 2024-01-19
- [DiffusionGPT: LLM-Driven Text-to-Image Generation System](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+DiffusionGPT%3A+LLM-Driven+Text-to-Image+Generation+System.yaml) / 2024-01-19
- [Improving fine-grained understanding in image-text pre-training](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+Improving+fine-grained+understanding+in+image-text+pre-training.yaml) / 2024-01-19
- [Rethinking FID: Towards a Better Evaluation Metric for Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+Rethinking+FID%3A+Towards+a+Better+Evaluation+Metric+for+Image+Generation.yaml) / 2024-01-19
- [SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+SHINOBI%3A+Shape+and+Illumination+using+Neural+Object+Decomposition+via+BRDF+Optimization+In-the-wild.yaml) / 2024-01-19
- [VMamba: Visual State Space Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+VMamba%3A+Visual+State+Space+Model.yaml) / 2024-01-19
- [WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+WorldDreamer%3A+Towards+General+World+Models+for+Video+Generation+via+Predicting+Masked+Tokens.yaml) / 2024-01-19
- [ActAnywhere: Subject-Aware Video Background Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+ActAnywhere%3A+Subject-Aware+Video+Background+Generation.yaml) / 2024-01-22
- [Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Depth+Anything%3A+Unleashing+the+Power+of+Large-Scale+Unlabeled+Data.yaml) / 2024-01-22
- [Inflation with Diffusion: Efficient Temporal Adaptation for Text-to-Video Super-Resolution](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Inflation+with+Diffusion%3A+Efficient+Temporal+Adaptation+for+Text-to-Video+Super-Resolution.yaml) / 2024-01-22
- [Synthesizing Moving People with 3D Control](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Synthesizing+Moving+People+with+3D+Control.yaml) / 2024-01-22
- [Understanding Video Transformers via Universal Concept Discovery](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Understanding+Video+Transformers+via+Universal+Concept+Discovery.yaml) / 2024-01-22
- [CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+CheXagent%3A+Towards+a+Foundation+Model+for+Chest+X-Ray+Interpretation.yaml) / 2024-01-23
- [EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+EmerDiff%3A+Emerging+Pixel-level+Semantic+Knowledge+in+Diffusion+Models.yaml) / 2024-01-23
- [Fast Registration of Photorealistic Avatars for VR Facial Animation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Fast+Registration+of+Photorealistic+Avatars+for+VR+Facial+Animation.yaml) / 2024-01-23
- [Make-A-Shape: a Ten-Million-scale 3D Shape Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Make-A-Shape%3A+a+Ten-Million-scale+3D+Shape+Model.yaml) / 2024-01-23
- [Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Mastering+Text-to-Image+Diffusion%3A+Recaptioning%2C+Planning%2C+and+Generating+with+Multimodal+LLMs.yaml) / 2024-01-23
- [Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Scalable+High-Resolution+Pixel-Space+Image+Synthesis+with+Hourglass+Diffusion+Transformers.yaml) / 2024-01-23
- [Scaling Face Interaction Graph Networks to Real World Scenes](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Scaling+Face+Interaction+Graph+Networks+to+Real+World+Scenes.yaml) / 2024-01-23
- [Single-View 3D Human Digitalization with Large Reconstruction Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+Single-View+3D+Human+Digitalization+with+Large+Reconstruction+Models.yaml) / 2024-01-23
- [SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+SpatialVLM%3A+Endowing+Vision-Language+Models+with+Spatial+Reasoning+Capabilities.yaml) / 2024-01-23
- [UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+UltrAvatar%3A+A+Realistic+Animatable+3D+Avatar+Diffusion+Model+with+Authenticity+Guided+Textures.yaml) / 2024-01-23
- [AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+AutoRT%3A+Embodied+Foundation+Models+for+Large+Scale+Orchestration+of+Robotic+Agents.yaml) / 2024-01-24
- [GALA: Generating Animatable Layered Assets from a Single Scan](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+GALA%3A+Generating+Animatable+Layered+Assets+from+a+Single+Scan.yaml) / 2024-01-24
- [Large-scale Reinforcement Learning for Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+Large-scale+Reinforcement+Learning+for+Diffusion+Models.yaml) / 2024-01-24
- [Lumiere: A Space-Time Diffusion Model for Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+Lumiere%3A+A+Space-Time+Diffusion+Model+for+Video+Generation.yaml) / 2024-01-24
- [Small Language Model Meets with Reinforced Vision Vocabulary](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+Small+Language+Model+Meets+with+Reinforced+Vision+Vocabulary.yaml) / 2024-01-24
- [ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+ConTextual%3A+Evaluating+Context-Sensitive+Text-Rich+Visual+Reasoning+in+Large+Multimodal+Models.yaml) / 2024-01-25
- [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+MM-LLMs%3A+Recent+Advances+in+MultiModal+Large+Language+Models.yaml) / 2024-01-25
- [Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+Scaling+Up+to+Excellence%3A+Practicing+Model+Scaling+for+Photo-Realistic+Image+Restoration+In+the+Wild.yaml) / 2024-01-25
- [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/10/2024-01-25+UNIMO-G%3A+Unified+Image+Generation+through+Multimodal+Conditional+Diffusion.yaml) / 2024-01-25
- [BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+BootPIG%3A+Bootstrapping+Zero-shot+Personalized+Image+Generation+Capabilities+in+Pretrained+Diffusion+Models.yaml) / 2024-01-26
- [CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+CreativeSynth%3A+Creative+Blending+and+Synthesis+of+Visual+Arts+based+on+Multimodal+Diffusion.yaml) / 2024-01-26
- [Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+Diffuse+to+Choose%3A+Enriching+Image+Conditioned+Inpainting+in+Latent+Diffusion+Models+for+Virtual+Try-All.yaml) / 2024-01-26
- [Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+Multimodal+Pathway%3A+Improve+Transformers+with+Irrelevant+Data+from+Other+Modalities.yaml) / 2024-01-26
- [Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+Sketch2NeRF%3A+Multi-view+Sketch-guided+Text-to-3D+Generation.yaml) / 2024-01-26
- [pix2gestalt: Amodal Segmentation by Synthesizing Wholes](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/11/2024-01-26+pix2gestalt%3A+Amodal+Segmentation+by+Synthesizing+Wholes.yaml) / 2024-01-26
- [From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on Generalizability, Trustworthiness and Causality through Four Modalities](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/12/2024-01-29+From+GPT-4+to+Gemini+and+Beyond%3A+Assessing+the+Landscape+of+MLLMs+on+Generalizability%2C+Trustworthiness+and+Causality+through+Four+Modalities.yaml) / 2024-01-29
- [TIP-Editor: An Accurate 3D Editor Following Both Text-Prompts And Image-Prompts](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/12/2024-01-29+TIP-Editor%3A+An+Accurate+3D+Editor+Following+Both+Text-Prompts+And+Image-Prompts.yaml) / 2024-01-29
- [Taiyi-Diffusion-XL: Advancing Bilingual Text-to-Image Generation with Large Vision-Language Model Support](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/12/2024-01-29+Taiyi-Diffusion-XL%3A+Advancing+Bilingual+Text-to-Image+Generation+with+Large+Vision-Language+Model+Support.yaml) / 2024-01-29
- [Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Divide+and+Conquer%3A+Language+Models+can+Plan+and+Self-Correct+for+Compositional+Text-to-Image+Generation.yaml) / 2024-01-30
- [InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+InternLM-XComposer2%3A+Mastering+Free-form+Text-Image+Composition+and+Comprehension+in+Vision-Language+Large+Model.yaml) / 2024-01-30
- [Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Media2Face%3A+Co-speech+Facial+Animation+Generation+With+Multi-Modality+Guidance.yaml) / 2024-01-30
- [MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+MoE-LLaVA%3A+Mixture+of+Experts+for+Large+Vision-Language+Models.yaml) / 2024-01-30
- [Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Mobile-Agent%3A+Autonomous+Multi-Modal+Mobile+Device+Agent+with+Visual+Perception.yaml) / 2024-01-30
- [Motion-I2V: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Motion-I2V%3A+Consistent+and+Controllable+Image-to-Video+Generation+with+Explicit+Motion+Modeling.yaml) / 2024-01-30
- [Object-Driven One-Shot Fine-tuning of Text-to-Image Diffusion with Prototypical Embedding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Object-Driven+One-Shot+Fine-tuning+of+Text-to-Image+Diffusion+with+Prototypical+Embedding.yaml) / 2024-01-30
- [Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Overcoming+the+Pitfalls+of+Vision-Language+Model+Finetuning+for+OOD+Generalization.yaml) / 2024-01-30
- [StableIdentity: Inserting Anybody into Anywhere at First Sight](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+StableIdentity%3A+Inserting+Anybody+into+Anywhere+at+First+Sight.yaml) / 2024-01-30
- [BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+BlockFusion%3A+Expandable+3D+Scene+Generation+using+Latent+Tri-plane+Extrapolation.yaml) / 2024-01-31
- [High-Quality Image Restoration Following Human Instructions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+High-Quality+Image+Restoration+Following+Human+Instructions.yaml) / 2024-01-31
- [MouSi: Poly-Visual-Expert Vision-Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+MouSi%3A+Poly-Visual-Expert+Vision-Language+Models.yaml) / 2024-01-31
- [Proactive Detection of Voice Cloning with Localized Watermarking](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+Proactive+Detection+of+Voice+Cloning+with+Localized+Watermarking.yaml) / 2024-01-31
- [ReGAL: Refactoring Programs to Discover Generalizable Abstractions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+ReGAL%3A+Refactoring+Programs+to+Discover+Generalizable+Abstractions.yaml) / 2024-01-31
- [Repositioning the Subject within Image](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+Repositioning+the+Subject+within+Image.yaml) / 2024-01-31
- [StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+StrokeNUWA%3A+Tokenizing+Strokes+for+Vector+Graphic+Synthesis.yaml) / 2024-01-31
- [T3: Transparent Tracking & Triggering for Fine-grained Overlap of Compute & Collectives](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+T3%3A+Transparent+Tracking+%26+Triggering+for+Fine-grained+Overlap+of+Compute+%26+Collectives.yaml) / 2024-01-31
- [YOLO-World: Real-Time Open-Vocabulary Object Detection](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+YOLO-World%3A+Real-Time+Open-Vocabulary+Object+Detection.yaml) / 2024-01-31
- [Advances in 3D Generation: A Survey](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+Advances+in+3D+Generation%3A+A+Survey.yaml) / 2024-02-01
- [Anything in Any Scene: Photorealistic Video Object Insertion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+Anything+in+Any+Scene%3A+Photorealistic+Video+Object+Insertion.yaml) / 2024-02-01
- [CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+CARFF%3A+Conditional+Auto-encoded+Radiance+Field+for+3D+Scene+Forecasting.yaml) / 2024-02-01
- [ReplaceAnything3D:Text-Guided 3D Scene Editing with Compositional Neural Radiance Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/15/2024-02-01+ReplaceAnything3D%3AText-Guided+3D+Scene+Editing+with+Compositional+Neural+Radiance+Fields.yaml) / 2024-02-01
- [AToM: Amortized Text-to-Mesh using 2D Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+AToM%3A+Amortized+Text-to-Mesh+using+2D+Diffusion.yaml) / 2024-02-02
- [AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+AnimateLCM%3A+Accelerating+the+Animation+of+Personalized+Diffusion+Models+and+Adapters+with+Decoupled+Consistency+Learning.yaml) / 2024-02-02
- [Machine Unlearning for Image-to-Image Generative Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+Machine+Unlearning+for+Image-to-Image+Generative+Models.yaml) / 2024-02-02
- [SymbolicAI: A framework for logic-based approaches combining generative models and solvers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/16/2024-02-02+SymbolicAI%3A+A+framework+for+logic-based+approaches+combining+generative+models+and+solvers.yaml) / 2024-02-02
- [DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+DiffEditor%3A+Boosting+Accuracy+and+Flexibility+on+Diffusion-based+Image+Editing.yaml) / 2024-02-06
- [Direct-a-Video: Customized Video Generation with User-Directed Camera Movement and Object Motion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Direct-a-Video%3A+Customized+Video+Generation+with+User-Directed+Camera+Movement+and+Object+Motion.yaml) / 2024-02-06
- [InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+InteractiveVideo%3A+User-Centric+Controllable+Video+Generation+with+Synergistic+Multimodal+Instructions.yaml) / 2024-02-06
- [Training-Free Consistent Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Training-Free+Consistent+Text-to-Image+Generation.yaml) / 2024-02-06
- [V-IRL: Grounding Virtual Intelligence in Real Life](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+V-IRL%3A+Grounding+Virtual+Intelligence+in+Real+Life.yaml) / 2024-02-06
- [Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Video-LaVIT%3A+Unified+Video-Language+Pre-training+with+Decoupled+Visual-Motional+Tokenization.yaml) / 2024-02-06
- [CogCoM: Train Large Vision-Language Models Diving into Details through Chain of Manipulations](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+CogCoM%3A+Train+Large+Vision-Language+Models+Diving+into+Details+through+Chain+of+Manipulations.yaml) / 2024-02-07
- [EVA-CLIP-18B: Scaling CLIP to 18 Billion Parameters](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+EVA-CLIP-18B%3A+Scaling+CLIP+to+18+Billion+Parameters.yaml) / 2024-02-07
- [EscherNet: A Generative Model for Scalable View Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+EscherNet%3A+A+Generative+Model+for+Scalable+View+Synthesis.yaml) / 2024-02-07
- [IMUSIC: IMU-based Facial Expression Capture](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+IMUSIC%3A+IMU-based+Facial+Expression+Capture.yaml) / 2024-02-07
- [MobileVLM V2: Faster and Stronger Baseline for Vision Language Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+MobileVLM+V2%3A+Faster+and+Stronger+Baseline+for+Vision+Language+Model.yaml) / 2024-02-07
- [Vision Superalignment: Weak-to-Strong Generalization for Vision Foundation Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/19/2024-02-07+Vision+Superalignment%3A+Weak-to-Strong+Generalization+for+Vision+Foundation+Models.yaml) / 2024-02-07
- [ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+ConsistI2V%3A+Enhancing+Visual+Consistency+for+Image-to-Video+Generation.yaml) / 2024-02-08
- [EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+EfficientViT-SAM%3A+Accelerated+Segment+Anything+Model+Without+Performance+Loss.yaml) / 2024-02-08
- [LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+LGM%3A+Large+Multi-View+Gaussian+Model+for+High-Resolution+3D+Content+Creation.yaml) / 2024-02-08
- [Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+Progressive+Gradient+Flow+for+Robust+N%3AM+Sparsity+Training+in+Transformers.yaml) / 2024-02-08
- [ScreenAI: A Vision-Language Model for UI and Infographics Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/20/2024-02-08+ScreenAI%3A+A+Vision-Language+Model+for+UI+and+Infographics+Understanding.yaml) / 2024-02-08
- [$λ$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+%24%CE%BB%24-ECLIPSE%3A+Multi-Concept+Personalized+Text-to-Image+Diffusion+Models+by+Leveraging+CLIP+Latent+Space.yaml) / 2024-02-09
- [Driving Everywhere with Large Language Model Policy Adaptation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+Driving+Everywhere+with+Large+Language+Model+Policy+Adaptation.yaml) / 2024-02-09
- [InstaGen: Enhancing Object Detection by Training on Synthetic Dataset](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+InstaGen%3A+Enhancing+Object+Detection+by+Training+on+Synthetic+Dataset.yaml) / 2024-02-09
- [Memory Consolidation Enables Long-Context Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+Memory+Consolidation+Enables+Long-Context+Video+Understanding.yaml) / 2024-02-09
- [Question Aware Vision Transformer for Multimodal Reasoning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/21/2024-02-09+Question+Aware+Vision+Transformer+for+Multimodal+Reasoning.yaml) / 2024-02-09
- [Animated Stickers: Bringing Stickers to Life with Video Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+Animated+Stickers%3A+Bringing+Stickers+to+Life+with+Video+Diffusion.yaml) / 2024-02-12
- [Keyframer: Empowering Animation Design using Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+Keyframer%3A+Empowering+Animation+Design+using+Large+Language+Models.yaml) / 2024-02-12
- [ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+ViGoR%3A+Improving+Visual+Grounding+of+Large+Vision+Language+Models+with+Fine-Grained+Reward+Modeling.yaml) / 2024-02-12
- [GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+GALA3D%3A+Towards+Text-to-3D+Complex+Scene+Generation+via+Layout-guided+Generative+Gaussian+Splatting.yaml) / 2024-02-13
- [Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+Making+Flow-Matching-Based+Zero-Shot+Text-to-Speech+Laugh+as+You+Like.yaml) / 2024-02-13
- [PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+PIVOT%3A+Iterative+Visual+Prompting+Elicits+Actionable+Knowledge+for+VLMs.yaml) / 2024-02-13
- [Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+Prismatic+VLMs%3A+Investigating+the+Design+Space+of+Visually-Conditioned+Language+Models.yaml) / 2024-02-13
- [IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+IM-3D%3A+Iterative+Multiview+Diffusion+and+Reconstruction+for+High-Quality+3D+Generation.yaml) / 2024-02-14
- [Learning Continuous 3D Words for Text-to-Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+Learning+Continuous+3D+Words+for+Text-to-Image+Generation.yaml) / 2024-02-14
- [Lumos : Empowering Multimodal LLMs with Scene Text Recognition](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+Lumos+%3A+Empowering+Multimodal+LLMs+with+Scene+Text+Recognition.yaml) / 2024-02-14
- [NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+NeRF+Analogies%3A+Example-Based+Visual+Attribute+Transfer+for+NeRFs.yaml) / 2024-02-14
- [Vision-Based Hand Gesture Customization from a Single Demonstration](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+Vision-Based+Hand+Gesture+Customization+from+a+Single+Demonstration.yaml) / 2024-02-14
- [World Model on Million-Length Video And Language With RingAttention](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+World+Model+on+Million-Length+Video+And+Language+With+RingAttention.yaml) / 2024-02-14
- [L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/25/2024-02-15+L3GO%3A+Language+Agents+with+Chain-of-3D-Thoughts+for+Generating+Unconventional+Objects.yaml) / 2024-02-15
- [Magic-Me: Identity-Specific Video Customized Diffusion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/25/2024-02-15+Magic-Me%3A+Identity-Specific+Video+Customized+Diffusion.yaml) / 2024-02-15
- [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/25/2024-02-15+PRDP%3A+Proximal+Reward+Difference+Prediction+for+Large-Scale+Reward+Finetuning+of+Diffusion+Models.yaml) / 2024-02-15
- [DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/26/2024-02-16+DreamMatcher%3A+Appearance+Matching+Self-Attention+for+Semantically-Consistent+Text-to-Image+Personalization.yaml) / 2024-02-16
- [GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/26/2024-02-16+GES%3A+Generalized+Exponential+Splatting+for+Efficient+Radiance+Field+Rendering.yaml) / 2024-02-16
- [GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object with Gaussian Splatting](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+GaussianObject%3A+Just+Taking+Four+Images+to+Get+A+High-Quality+3D+Object+with+Gaussian+Splatting.yaml) / 2024-02-19
- [LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+LAVE%3A+LLM-Powered+Agent+Assistance+and+Language+Augmentation+for+Video+Editing.yaml) / 2024-02-19
- [Make a Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+Make+a+Cheap+Scaling%3A+A+Self-Cascade+Diffusion+Model+for+Higher-Resolution+Adaptation.yaml) / 2024-02-19
- [PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+PaLM2-VAdapter%3A+Progressively+Aligned+Language+Model+Makes+a+Strong+Vision-language+Adapter.yaml) / 2024-02-19
- [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+AnyGPT%3A+Unified+Multimodal+LLM+with+Discrete+Sequence+Modeling.yaml) / 2024-02-20
- [Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+Binary+Opacity+Grids%3A+Capturing+Fine+Geometric+Detail+for+Mesh-Based+View+Synthesis.yaml) / 2024-02-20
- [CoLLaVO: Crayon Large Language and Vision mOdel](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+CoLLaVO%3A+Crayon+Large+Language+and+Vision+mOdel.yaml) / 2024-02-20
- [DiLightNet: Fine-grained Lighting Control for Diffusion-based Image Generation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+DiLightNet%3A+Fine-grained+Lighting+Control+for+Diffusion-based+Image+Generation.yaml) / 2024-02-20
- [FiT: Flexible Vision Transformer for Diffusion Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+FiT%3A+Flexible+Vision+Transformer+for+Diffusion+Model.yaml) / 2024-02-20
- [Pushing Auto-regressive Models for 3D Shape Generation at Capacity and Scalability](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+Pushing+Auto-regressive+Models+for+3D+Shape+Generation+at+Capacity+and+Scalability.yaml) / 2024-02-20
- [A Touch, Vision, and Language Dataset for Multimodal Alignment](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+A+Touch%2C+Vision%2C+and+Language+Dataset+for+Multimodal+Alignment.yaml) / 2024-02-21
- [FlashTex: Fast Relightable Mesh Texturing with LightControlNet](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+FlashTex%3A+Fast+Relightable+Mesh+Texturing+with+LightControlNet.yaml) / 2024-02-21
- [How Easy is It to Fool Your Multimodal LLMs? An Empirical Analysis on Deceptive Prompts](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+How+Easy+is+It+to+Fool+Your+Multimodal+LLMs%3F+An+Empirical+Analysis+on+Deceptive+Prompts.yaml) / 2024-02-21
- [Improving Robustness for Joint Optimization of Camera Poses and Decomposed Low-Rank Tensorial Radiance Fields](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+Improving+Robustness+for+Joint+Optimization+of+Camera+Poses+and+Decomposed+Low-Rank+Tensorial+Radiance+Fields.yaml) / 2024-02-21
- [MVDiffusion++: A Dense High-resolution Multi-view Diffusion Model for Single or Sparse-view 3D Object Reconstruction](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+MVDiffusion%2B%2B%3A+A+Dense+High-resolution+Multi-view+Diffusion+Model+for+Single+or+Sparse-view+3D+Object+Reconstruction.yaml) / 2024-02-21
- [RealCompo: Dynamic Equilibrium between Realism and Compositionality Improves Text-to-Image Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+RealCompo%3A+Dynamic+Equilibrium+between+Realism+and+Compositionality+Improves+Text-to-Image+Diffusion+Models.yaml) / 2024-02-21
- [Video ReCap: Recursive Captioning of Hour-Long Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+Video+ReCap%3A+Recursive+Captioning+of+Hour-Long+Videos.yaml) / 2024-02-21
- [VideoPrism: A Foundational Visual Encoder for Video Understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+VideoPrism%3A+A+Foundational+Visual+Encoder+for+Video+Understanding.yaml) / 2024-02-21
