- [ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+ANIM-400K%3A+A+Large-Scale+Dataset+for+Automated+End-To-End+Dubbing+of+Video.yaml) / 2024-01-11 00:00
- [FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+FreGrad%3A+Lightweight+and+Fast+Frequency-aware+Diffusion+Vocoder.yaml) / 2024-01-19
- [StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/8/2024-01-23+StreamVoice%3A+Streamable+Context-Aware+Language+Modeling+for+Real-time+Zero-Shot+Voice+Conversion.yaml) / 2024-01-23
- [Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/9/2024-01-24+Multilingual+and+Fully+Non-Autoregressive+ASR+with+Large+Language+Model+Fusion%3A+A+Comprehensive+Study.yaml) / 2024-01-24
- [OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/14/2024-01-31+OWSM+v3.1%3A+Better+and+Faster+Open+Whisper-Style+Speech+Models+based+on+E-Branchformer.yaml) / 2024-01-31
- [Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Audio+Flamingo%3A+A+Novel+Audio+Language+Model+with+Few-Shot+Learning+and+Dialogue+Abilities.yaml) / 2024-02-06
- [Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/23/2024-02-13+Making+Flow-Matching-Based+Zero-Shot+Text-to-Speech+Laugh+as+You+Like.yaml) / 2024-02-13
- [BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+BASE+TTS%3A+Lessons+from+building+a+billion-parameter+Text-to-Speech+model+on+100K+hours+of+data.yaml) / 2024-02-14
- [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+AnyGPT%3A+Unified+Multimodal+LLM+with+Discrete+Sequence+Modeling.yaml) / 2024-02-20
- [How Easy is It to Fool Your Multimodal LLMs? An Empirical Analysis on Deceptive Prompts](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/29/2024-02-21+How+Easy+is+It+to+Fool+Your+Multimodal+LLMs%3F+An+Empirical+Analysis+on+Deceptive+Prompts.yaml) / 2024-02-21
- [EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+EMO%3A+Emote+Portrait+Alive+-+Generating+Expressive+Portrait+Videos+with+Audio2Video+Diffusion+Model+under+Weak+Conditions.yaml) / 2024-02-28
- [Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/34/2024-02-28+Seeing+and+Hearing%3A+Open-domain+Visual-Audio+Generation+with+Diffusion+Latent+Aligners.yaml) / 2024-02-28
- [NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/38/2024-03-06+NaturalSpeech+3%3A+Zero-Shot+Speech+Synthesis+with+Factorized+Codec+and+Diffusion+Models.yaml) / 2024-03-06
- [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/41/2024-03-11+Gemini+1.5%3A+Unlocking+multimodal+understanding+across+millions+of+tokens+of+context.yaml) / 2024-03-11
- [WavLLM: Towards Robust and Adaptive Speech Large Language Model](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/57/2024-04-02+WavLLM%3A+Towards+Robust+and+Adaptive+Speech+Large+Language+Model.yaml) / 2024-04-02
- [RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/60/2024-04-05+RALL-E%3A+Robust+Codec+Language+Modeling+with+Chain-of-Thought+Prompting+for+Text-to-Speech+Synthesis.yaml) / 2024-04-05
- [Audio Dialogues: Dialogues dataset for audio and music understanding](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/65/2024-04-12+Audio+Dialogues%3A+Dialogues+dataset+for+audio+and+music+understanding.yaml) / 2024-04-12
- [Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/67/2024-04-16+Tango+2%3A+Aligning+Diffusion-based+Text-to-Audio+Generations+through+Direct+Preference+Optimization.yaml) / 2024-04-16
