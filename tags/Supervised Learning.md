- [ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+ANIM-400K%3A+A+Large-Scale+Dataset+for+Automated+End-To-End+Dubbing+of+Video.yaml) / 2024-01-11 00:00
- [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/1/2024-01-11+Bootstrapping+LLM-based+Task-Oriented+Dialogue+Agents+via+Self-Talk.yaml) / 2024-01-11 00:00
- [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+DeepSeekMoE%3A+Towards+Ultimate+Expert+Specialization+in+Mixture-of-Experts+Language+Models.yaml) / 2024-01-12
- [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Secrets+of+RLHF+in+Large+Language+Models+Part+II%3A+Reward+Modeling.yaml) / 2024-01-12
- [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+Sleeper+Agents%3A+Training+Deceptive+LLMs+that+Persist+Through+Safety+Training.yaml) / 2024-01-12
- [TOFU: A Task of Fictitious Unlearning for LLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/2/2024-01-12+TOFU%3A+A+Task+of+Fictitious+Unlearning+for+LLMs.yaml) / 2024-01-12
- [Distilling Vision-Language Models on Millions of Videos](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Distilling+Vision-Language+Models+on+Millions+of+Videos.yaml) / 2024-01-12
- [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Secrets+of+RLHF+in+Large+Language+Models+Part+II%3A+Reward+Modeling.yaml) / 2024-01-12
- [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Sleeper+Agents%3A+Training+Deceptive+LLMs+that+Persist+Through+Safety+Training.yaml) / 2024-01-12
- [TOFU: A Task of Fictitious Unlearning for LLMs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+TOFU%3A+A+Task+of+Fictitious+Unlearning+for+LLMs.yaml) / 2024-01-12
- [Towards Conversational Diagnostic AI](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Towards+Conversational+Diagnostic+AI.yaml) / 2024-01-12
- [Transformers are Multi-State RNNs](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Transformers+are+Multi-State+RNNs.yaml) / 2024-01-12
- [TrustLLM: Trustworthiness in Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+TrustLLM%3A+Trustworthiness+in+Large+Language+Models.yaml) / 2024-01-12
- [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Tuning+LLMs+with+Contrastive+Alignment+Instructions+for+Machine+Translation+in+Unseen%2C+Low-resource+Languages.yaml) / 2024-01-12
- [Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Contrastive+Preference+Optimization%3A+Pushing+the+Boundaries+of+LLM+Performance+in+Machine+Translation.yaml) / 2024-01-17
- [Tuning Language Models by Proxy](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/4/2024-01-17+Tuning+Language+Models+by+Proxy.yaml) / 2024-01-17
- [ReFT: Reasoning with Reinforced Fine-Tuning](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/5/2024-01-18+ReFT%3A+Reasoning+with+Reinforced+Fine-Tuning.yaml) / 2024-01-18
- [Self-Rewarding Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/6/2024-01-19+Self-Rewarding+Language+Models.yaml) / 2024-01-19
