- [Towards Conversational Diagnostic AI](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/3/2024-01-12+Towards+Conversational+Diagnostic+AI.yaml) / 2024-01-12
- [Rambler: Supporting Writing With Speech via LLM-Assisted Gist Manipulation](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/7/2024-01-22+Rambler%3A+Supporting+Writing+With+Speech+via+LLM-Assisted+Gist+Manipulation.yaml) / 2024-01-22
- [Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/13/2024-01-30+Mobile-Agent%3A+Autonomous+Multi-Modal+Mobile+Device+Agent+with+Visual+Perception.yaml) / 2024-01-30
- [PokéLLMon: A Human-Parity Agent for Pokémon Battles with Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/17/2024-02-05+Pok%C3%A9LLMon%3A+A+Human-Parity+Agent+for+Pok%C3%A9mon+Battles+with+Large+Language+Models.yaml) / 2024-02-05
- [Direct-a-Video: Customized Video Generation with User-Directed Camera Movement and Object Motion](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+Direct-a-Video%3A+Customized+Video+Generation+with+User-Directed+Camera+Movement+and+Object+Motion.yaml) / 2024-02-06
- [InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/18/2024-02-06+InteractiveVideo%3A+User-Centric+Controllable+Video+Generation+with+Synergistic+Multimodal+Instructions.yaml) / 2024-02-06
- [Keyframer: Empowering Animation Design using Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/22/2024-02-12+Keyframer%3A+Empowering+Animation+Design+using+Large+Language+Models.yaml) / 2024-02-12
- [UFO: A UI-Focused Agent for Windows OS Interaction](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+UFO%3A+A+UI-Focused+Agent+for+Windows+OS+Interaction.yaml) / 2024-02-14
- [Vision-Based Hand Gesture Customization from a Single Demonstration](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/24/2024-02-14+Vision-Based+Hand+Gesture+Customization+from+a+Single+Demonstration.yaml) / 2024-02-14
- [GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/25/2024-02-15+GhostWriter%3A+Augmenting+Collaborative+Human-AI+Writing+Experiences+Through+Personalization+and+Agency.yaml) / 2024-02-15
- [A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/26/2024-02-16+A+Human-Inspired+Reading+Agent+with+Gist+Memory+of+Very+Long+Contexts.yaml) / 2024-02-16
- [LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/27/2024-02-19+LLM+Comparator%3A+Visual+Analytics+for+Side-by-Side+Evaluation+of+Large+Language+Models.yaml) / 2024-02-19
- [Learning to Learn Faster from Human Feedback with Language Model Predictive Control](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/28/2024-02-20+Learning+to+Learn+Faster+from+Human+Feedback+with+Language+Model+Predictive+Control.yaml) / 2024-02-20
- [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/31/2024-02-23+OpenCodeInterpreter%3A+Integrating+Code+Generation+with+Execution+and+Refinement.yaml) / 2024-02-23
- [Modeling Collaborator: Enabling Subjective Vision Classification With Minimal Human Effort via LLM Tool-Use](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/38/2024-03-06+Modeling+Collaborator%3A+Enabling+Subjective+Vision+Classification+With+Minimal+Human+Effort+via+LLM+Tool-Use.yaml) / 2024-03-06
- [Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/45/2024-03-15+Unlocking+the+conversion+of+Web+Screenshots+into+HTML+Code+with+the+WebSight+Dataset.yaml) / 2024-03-15
- [PERL: Parameter Efficient Reinforcement Learning from Human Feedback](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/47/2024-03-19+PERL%3A+Parameter+Efficient+Reinforcement+Learning+from+Human+Feedback.yaml) / 2024-03-19
- [OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/65/2024-04-12+OSWorld%3A+Benchmarking+Multimodal+Agents+for+Open-Ended+Tasks+in+Real+Computer+Environments.yaml) / 2024-04-12
- [Revisiting Text-to-Image Evaluation with Gecko: On Metrics, Prompts, and Human Ratings](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/73/2024-04-26+Revisiting+Text-to-Image+Evaluation+with+Gecko%3A+On+Metrics%2C+Prompts%2C+and+Human+Ratings.yaml) / 2024-04-26
- [LEGENT: Open Platform for Embodied Agents](https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/archive/75/2024-04-30+LEGENT%3A+Open+Platform+for+Embodied+Agents.yaml) / 2024-04-30
