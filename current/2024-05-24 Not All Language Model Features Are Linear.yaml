date: "2024-05-24"
author: Joshua Engels
title: Not All Language Model Features Are Linear
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14860.png
link: https://huggingface.co/papers/2405.14860
summary: This paper challenges the linear representation hypothesis by exploring the possibility of multi-dimensional features in language models. It uses sparse autoencoders to automatically find interpretable multi-dimensional features, such as circular features representing days of the week and months of the year, which are used to solve computational problems involving modular arithmetic. The paper provides evidence that these circular features are the fundamental unit of computation in these tasks a...
opinion: placeholder
tags:
    - Supervised Learning
    - Natural Language Processing
    - Deep Learning
    - Explainable AI and Interpretability
