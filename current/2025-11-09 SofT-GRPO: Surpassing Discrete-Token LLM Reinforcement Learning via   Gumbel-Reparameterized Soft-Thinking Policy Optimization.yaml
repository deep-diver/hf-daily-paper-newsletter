date: "2025-11-09"
author: Zhi Zheng
title: 'SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via   Gumbel-Reparameterized Soft-Thinking Policy Optimization'
thumbnail: ""
link: https://huggingface.co/papers/2511.06411
summary: The study presents SofT-GRPO, a new algorithm that enhances Large Language Models (LLMs) using soft-thinking reasoning, which can outperform traditional discrete-token reasoning in some cases. SofT-GRPO improves soft-thinking LLMs, allowing them to slightly surpass discrete-token GRPO on Pass@1 and significantly outperform it on Pass@32, while maintaining the same performance on other metrics....
opinion: placeholder
tags:
    - ML
