date: "2024-12-09"
author: Ziyi Wu
title: 'Mind the Time: Temporally-Controlled Multi-Event Video Generation'
thumbnail: ""
link: https://huggingface.co/papers/2412.05263
summary: The paper introduces MinT, a video generator that can create sequences of events with precise timing control. It binds each event to a specific time period and uses a time-based positional encoding method to guide the cross-attention operation. This results in coherent videos with smoothly connected events, and it's the first model in the literature to offer control over event timing. MinT outperforms existing open-source models by a large margin....
opinion: placeholder
tags:
    - ML
