date: "2024-04-12"
author: Zhenghao Lin
title: 'Rho-1: Not All Tokens Are What You Need'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.07965.png
link: https://huggingface.co/papers/2404.07965
summary: This paper introduces Rho-1, a new language model that selectively trains on useful tokens rather than uniformly applying a next-token prediction loss to all training tokens. Rho-1 achieves efficiency and performance improvements when pretraining on large datasets....
opinion: placeholder
tags:
    - Natural Language Processing
    - Supervised Learning
    - Deep Learning
