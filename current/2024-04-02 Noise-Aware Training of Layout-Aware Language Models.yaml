date: "2024-04-02"
author: Ritesh Sarkhel
title: Noise-Aware Training of Layout-Aware Language Models
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.00488.png
link: https://huggingface.co/papers/2404.00488
summary: This paper proposes a method called Noise-Aware Training (NAT) to train custom extractors for large numbers of document types in a scalable and cost-effective way. NAT uses weakly labeled documents and estimates the confidence of each training sample to avoid degradation in model quality due to noisy data. Experiments show that NAT-trained models are more label-efficient and outperform transfer-learning baselines in performance....
opinion: placeholder
tags:
    - Supervised Learning
