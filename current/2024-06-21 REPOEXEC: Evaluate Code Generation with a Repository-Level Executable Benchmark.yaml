date: "2024-06-21"
author: Nam Le Hai
title: 'REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark'
thumbnail: ""
link: https://huggingface.co/papers/2406.11927
summary: RepoExec is a new benchmark for evaluating code generation at the repository-level scale. It focuses on executability, functional correctness, and code dependencies. Pretrained LLMs are better at correctness, while instruction-tuned models are better at using dependencies and debugging. A new dataset is introduced to improve dependency handling....
opinion: placeholder
tags:
    - ML
