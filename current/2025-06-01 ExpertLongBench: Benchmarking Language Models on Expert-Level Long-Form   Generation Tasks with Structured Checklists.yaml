date: "2025-06-01"
author: Jie Ruan
title: 'ExpertLongBench: Benchmarking Language Models on Expert-Level Long-Form   Generation Tasks with Structured Checklists'
thumbnail: ""
link: https://huggingface.co/papers/2506.01241
summary: The authors present ExpertLongBench, a benchmark for testing language models on expert-level long-form generation tasks, and introduce CLEAR, an evaluation framework for accurately assessing model outputs on this benchmark. They evaluate 11 large language models and find that while models can generate content for required aspects, they often do not do so accurately, and existing LLMs need significant improvement for expert-level tasks....
opinion: placeholder
tags:
    - ML
