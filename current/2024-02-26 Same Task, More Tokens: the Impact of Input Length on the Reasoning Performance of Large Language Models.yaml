date: "2024-02-26"
author: Mosh Levy
title: 'Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ddkmh05FqmK6CoS3gg6TZ.png
link: https://huggingface.co/papers/2402.14848
summary: This study examines how the length of text input affects the reasoning abilities of large language models. The results show that performance degrades much earlier than the models' technical maximum, and that traditional measures like perplexity are not useful for predicting their success in long input tasks. The study also identifies common failure modes that could guide future research....
opinion: placeholder
tags:
    - Natural Language Processing
