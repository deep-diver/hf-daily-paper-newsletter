date: "2024-07-17"
author: Zehan Wang
title: 'OmniBind: Large-scale Omni Multimodal Representation via Binding Spaces'
thumbnail: ""
link: https://huggingface.co/papers/2407.11895
summary: This paper presents OmniBind, a large-scale multimodal joint representation model that supports various inputs like 3D, audio, image, and language. It remaps and binds pre-trained specialist models together to increase the model parameters and the amount of seen data. The model is training-efficient and can be learned with unpaired unimodal data in just 3 days on a single 8-4090 node. OmniBind has great potential for diverse applications like any-query and composable multimodal understanding....
opinion: placeholder
tags:
    - ML
