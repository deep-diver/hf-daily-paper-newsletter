date: "2025-06-05"
author: Ranajoy Sadhukhan
title: 'Kinetics: Rethinking Test-Time Scaling Laws'
thumbnail: ""
link: https://huggingface.co/papers/2506.05333
summary: This study examines the efficiency of smaller models versus larger ones during inference and finds that larger models are more effective due to memory access costs that were previously overlooked. The researchers propose a new scaling paradigm centered on sparse attention, which lowers per-token cost and enables longer generations and more parallel samples within the same resource budget, resulting in improved performance compared to dense counterparts....
opinion: placeholder
tags:
    - ML
