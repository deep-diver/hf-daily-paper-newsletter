date: "2025-10-02"
author: Enxin Song
title: 'VideoNSA: Native Sparse Attention Scales Video Understanding'
thumbnail: ""
link: https://huggingface.co/papers/2510.02295
summary: The authors propose VideoNSA, a method that improves video understanding in multimodal language models by adapting Native Sparse Attention to video-language models. Through end-to-end training, VideoNSA outperforms other sparse attention techniques on various benchmarks, demonstrating reliable scaling, optimal attention allocation, and task-dependent branch usage patterns....
opinion: placeholder
tags:
    - ML
