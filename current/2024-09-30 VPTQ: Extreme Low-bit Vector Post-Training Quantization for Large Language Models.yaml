date: "2024-09-30"
author: Yifei Liu
title: 'VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2409.17066
summary: This paper presents a new method called Vector Post-Training Quantization (VPTQ) to reduce the size of large language models (LLMs) for easier deployment and inference. It uses vector quantization to compress model weights into indices, enabling extremely low-bit quantization. VPTQ reduces model quantization perplexity and improves accuracy on various tasks, resulting in faster inference throughput compared to existing methods....
opinion: placeholder
tags:
    - ML
