author: Rohan Wadhawan
date: '2024-01-25'
link: https://huggingface.co/papers/2401.13311
opinion: placeholder
summary: This paper introduces ConTextual, a benchmark that tests the ability of AI
  models to perform context-sensitive visual reasoning with text using diverse real-world
  scenarios, showing significant room for improvement compared to human capabilities
  with a 30.8% performance gap....
tags:
- Computer Vision
- Deep Learning
- Natural Language Processing
- Explainable AI and Interpretability
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/1QQmYe9JyOJgYxzagfR82.png
title: 'ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large
  Multimodal Models'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.13311/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.13311/paper.ko.html
