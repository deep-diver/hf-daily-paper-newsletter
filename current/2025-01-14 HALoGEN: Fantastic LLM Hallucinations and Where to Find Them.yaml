date: "2025-01-14"
author: Abhilasha Ravichander
title: 'HALoGEN: Fantastic LLM Hallucinations and Where to Find Them'
thumbnail: ""
link: https://huggingface.co/papers/2501.08292
summary: We present HALoGEN, a benchmark for measuring hallucinations in large language models. Our benchmark includes 10,923 prompts and automatic verifiers for each use case. We evaluate 14 language models and find that even the best models have many hallucinations. We also introduce a new error classification for hallucinations....
opinion: placeholder
tags:
    - ML
