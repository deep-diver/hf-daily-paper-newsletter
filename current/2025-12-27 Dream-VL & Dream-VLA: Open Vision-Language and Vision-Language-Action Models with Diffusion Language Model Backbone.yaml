date: "2025-12-27"
author: Jiacheng Ye
title: 'Dream-VL & Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.22615.png
link: https://huggingface.co/papers/2512.22615
summary: Current smart programs that understand pictures and words often struggle with complex visual planning and robot control because they think one step at a time. A new type of smart program, Dream-VL and Dream-VLA, was developed using a different "diffusion" thinking style, allowing them to understand pictures, words, and robot actions much more efficiently, leading to faster robot learning and top performance on challenging tasks....
opinion: placeholder
tags:
    - Diffusion Models
    - Embodied AI
poster_path: https://raw.githubusercontent.com/deep-diver/hf-daily-paper-newsletter/main/posters/poster_2512.22615_landscape_english_nopanel.png
