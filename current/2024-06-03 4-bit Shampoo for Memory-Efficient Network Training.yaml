date: "2024-06-03"
author: Sike Wang
title: 4-bit Shampoo for Memory-Efficient Network Training
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.18144.png
link: https://huggingface.co/papers/2405.18144
summary: This paper introduces the first 4-bit second-order optimizers, exemplified by 4-bit Shampoo, which maintains similar performance to 32-bit optimizers but uses less memory. It achieves this by quantizing the eigenvector matrix of the preconditioner and using linear square quantization, which is slightly better than dynamic tree quantization when quantizing second-order optimizer states. The source code will be made available....
opinion: placeholder
tags:
    - Optimization and Learning Algorithms
