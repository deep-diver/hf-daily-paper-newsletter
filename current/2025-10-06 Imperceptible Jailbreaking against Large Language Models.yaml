date: "2025-10-06"
author: Kuofeng Gao
title: Imperceptible Jailbreaking against Large Language Models
thumbnail: ""
link: https://huggingface.co/papers/2510.05025
summary: This study presents a new method of undetectable attack on large language models using invisible characters called variation selectors. By appending these characters to malicious questions, the models can be tricked into giving harmful responses without any visible changes to the prompts....
opinion: placeholder
tags:
    - ML
