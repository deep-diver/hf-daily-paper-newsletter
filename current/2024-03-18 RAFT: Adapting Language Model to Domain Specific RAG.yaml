author: Tianjun Zhang
date: '2024-03-18'
link: https://huggingface.co/papers/2403.10131
opinion: placeholder
summary: This paper presents Retrieval Augmented FineTuning (RAFT), a training method
  for large language models that improves their ability to answer questions in a specific
  domain by learning to ignore irrelevant information. RAFT consistently improves
  model performance on domain-specific datasets, and its code and demo are available
  open-source....
tags:
- Natural Language Processing
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.10131.png
title: 'RAFT: Adapting Language Model to Domain Specific RAG'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.10131/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.10131/paper.ko.html
