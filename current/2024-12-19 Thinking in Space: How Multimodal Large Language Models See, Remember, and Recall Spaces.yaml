date: "2024-12-19"
author: Jihan Yang
title: 'Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces'
thumbnail: ""
link: https://huggingface.co/papers/2412.14171
summary: Multimodal Large Language Models (MLLMs) trained on video datasets have some, but not perfect, ability to ``think in space'' from videos, as measured by a new benchmark called VSI-Bench. The models' spatial reasoning abilities are their main limitation, but they do develop some understanding of the world and spatial awareness. Techniques like chain-of-thought and self-consistency don't help, but generating cognitive maps does improve their performance in spatial distance tasks....
opinion: placeholder
tags:
    - ML
