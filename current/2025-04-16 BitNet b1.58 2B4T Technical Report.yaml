date: "2025-04-16"
author: Shuming Ma
title: BitNet b1.58 2B4T Technical Report
thumbnail: ""
link: https://huggingface.co/papers/2504.12285
summary: The researchers present BitNet b1.58 2B4T, an open-source 1-bit Large Language Model (LLM) with 2 billion parameters. It performs similarly to other open-weight, full-precision LLMs of the same size but uses less memory, energy, and has faster decoding, and the model weights are distributed via Hugging Face....
opinion: placeholder
tags:
    - ML
