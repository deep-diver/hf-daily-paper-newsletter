date: "2025-04-08"
author: Chenrui Fan
title: 'Missing Premise exacerbates Overthinking: Are Reasoning Models losing   Critical Thinking Skill?'
thumbnail: ""
link: https://huggingface.co/papers/2504.06514
summary: The paper explores that reasoning Large Language Models (LLMs) overthink and produce longer responses for questions with missing premises (MiP), a problem they call MiP-Overthinking. This issue is more pronounced in models trained by reinforcement learning or supervised learning but is less seen in LLMs not specifically trained for reasoning. The paper also reveals that overthinking can be contagious through the distillation of reasoning models' responses....
opinion: placeholder
tags:
    - ML
