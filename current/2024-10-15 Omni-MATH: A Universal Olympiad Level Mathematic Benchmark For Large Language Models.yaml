date: "2024-10-15"
author: Bofei Gao
title: 'Omni-MATH: A Universal Olympiad Level Mathematic Benchmark For Large Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2410.07985
summary: This paper introduces a new benchmark for large language models called Omni-MATH. It's designed to test models' mathematical reasoning skills at the Olympiad level, which existing benchmarks can't do. The benchmark has over 4000 competition-level math problems and is categorized into over 30 sub-domains. The authors found that even the best models struggle with these problems, showing that there's still a lot of work to be done in this area....
opinion: placeholder
tags:
    - ML
