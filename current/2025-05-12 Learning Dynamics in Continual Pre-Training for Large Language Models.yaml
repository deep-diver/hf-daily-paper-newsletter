date: "2025-05-12"
author: Xingjin Wang
title: Learning Dynamics in Continual Pre-Training for Large Language Models
thumbnail: ""
link: https://huggingface.co/papers/2505.07796
summary: This study investigates the progress of learning in large language models during Continual Pre-Training (CPT), focusing on the evolution of general and downstream domain performance. The researchers discovered a pattern in CPT loss curve transitions and developed a CPT scaling law, which helps predict loss during training and allows customization of training parameters for different CPT goals, all of which are validated through various experiments....
opinion: placeholder
tags:
    - ML
