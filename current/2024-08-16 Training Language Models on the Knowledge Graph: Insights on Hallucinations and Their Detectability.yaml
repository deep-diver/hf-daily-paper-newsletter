date: "2024-08-16"
author: Jiri Hron
title: 'Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability'
thumbnail: ""
link: https://huggingface.co/papers/2408.07852
summary: The paper investigates the impact of scale on hallucinations in language models (LMs) and their detectability. The study focuses on hallucinations where a correct answer appears verbatim in the training set. A knowledge graph-based dataset is constructed to train a set of increasingly large LMs. The results show that larger and longer-trained LMs hallucinate less, but hallucinating on a small portion of the training data requires a significantly larger model and more compute. The study also exam...
opinion: placeholder
tags:
    - ML
