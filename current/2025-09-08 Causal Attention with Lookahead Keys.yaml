date: "2025-09-08"
author: Zhuoqing Song
title: Causal Attention with Lookahead Keys
thumbnail: ""
link: https://huggingface.co/papers/2509.07301
summary: The authors propose a new attention mechanism called CASTLE that updates token keys as the context unfolds, allowing them to incorporate later context while maintaining the autoregressive property. This method improves language modeling performance and enables efficient parallel training without explicit materialization of lookahead keys....
opinion: placeholder
tags:
    - ML
