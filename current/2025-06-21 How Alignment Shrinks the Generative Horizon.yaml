date: "2025-06-21"
author: Chenghao Yang
title: How Alignment Shrinks the Generative Horizon
thumbnail: ""
link: https://huggingface.co/papers/2506.17871
summary: The study explores why aligned large language models produce less diverse outputs by focusing on the concentration of probability in their output distribution. They introduce the Branching Factor (BF) as a measure of this concentration and find that BF decreases as generation progresses, and alignment tuning significantly reduces BF, making models less sensitive to decoding strategies and more stable for complex reasoning tasks....
opinion: placeholder
tags:
    - ML
