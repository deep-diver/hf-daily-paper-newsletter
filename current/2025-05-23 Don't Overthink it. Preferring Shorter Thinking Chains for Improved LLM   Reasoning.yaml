date: "2025-05-23"
author: Michael Hassid
title: Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM   Reasoning
thumbnail: ""
link: https://huggingface.co/papers/2505.17813
summary: This study finds that shorter thinking chains in large language models (LLMs) can yield more accurate reasoning results and proposes a new method called short-m@k for faster and more efficient LLM inference. The method involves executing independent generations in parallel and selecting the final answer using majority voting, which performs similarly or better than standard majority voting while using fewer resources. The study also suggests that training LLMs using shorter reasoning chains can ...
opinion: placeholder
tags:
    - ML
