author: David Grangier
date: '2024-02-05'
link: https://huggingface.co/papers/2402.01093
opinion: placeholder
summary: This paper explores challenges of applying large language models to tasks
  with limited inference budgets and small in-domain training sets. It compares different
  approaches and finds alternatives to training very large vanilla Transformer models,
  particularly for large pretraining and small specialization budgets....
tags:
- Natural Language Processing
- Deep Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/wyad9lOdT8rdndVwZgz7w.png
title: Specialized Language Models with Cheap Inference from Limited Domain Data
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.01093/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.01093/paper.ko.html
