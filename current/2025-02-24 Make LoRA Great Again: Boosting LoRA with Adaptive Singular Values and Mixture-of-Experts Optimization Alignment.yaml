date: "2025-02-24"
author: Chenghao Fan
title: 'Make LoRA Great Again: Boosting LoRA with Adaptive Singular Values and Mixture-of-Experts Optimization Alignment'
thumbnail: ""
link: https://huggingface.co/papers/2502.16894
summary: The authors present GOAT, a novel framework for improving the performance of LoRA, a parameter-efficient fine-tuning method for LLMs. GOAT adaptively integrates relevant priors using an SVD-structured MoE and aligns optimization with full fine-tuned MoE by utilizing a theoretical scaling factor, enhancing efficiency and performance without altering the architecture or training algorithms. It outperforms other methods on a variety of datasets....
opinion: placeholder
tags:
    - ML
