date: "2025-02-13"
author: Ali Modarressi
title: 'NoLiMa: Long-Context Evaluation Beyond Literal Matching'
thumbnail: ""
link: https://huggingface.co/papers/2502.05167
summary: The paper presents NoLiMa, a benchmark for long-context evaluation in LLMs, where questions and needles have minimal lexical overlap, requiring models to infer latent associations to locate the needle within the haystack. When evaluating 12 popular LLMs with contexts of at least 128K tokens, performance degrades significantly as context length increases, with most models dropping below 50% of their strong short-length baselines at 32K....
opinion: placeholder
tags:
    - ML
