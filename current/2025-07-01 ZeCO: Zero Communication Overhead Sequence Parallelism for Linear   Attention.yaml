date: "2025-07-01"
author: Yuhong Chou
title: 'ZeCO: Zero Communication Overhead Sequence Parallelism for Linear   Attention'
thumbnail: ""
link: https://huggingface.co/papers/2507.01004
summary: The authors present ZeCO, a new method for sequence parallelism in linear attention models that significantly reduces communication overhead, enabling efficient processing of extremely long sequences. Their approach, which includes a novel communication primitive called All-Scan, allows for near-linear scalability and achieves up to 60% speedup compared to existing methods, making it possible to train large language models on previously impossible sequence lengths....
opinion: placeholder
tags:
    - ML
