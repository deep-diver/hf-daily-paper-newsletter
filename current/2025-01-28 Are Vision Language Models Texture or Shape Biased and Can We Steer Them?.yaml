date: "2025-01-28"
author: Paul Gavrikov
title: Are Vision Language Models Texture or Shape Biased and Can We Steer Them?
thumbnail: ""
link: https://huggingface.co/papers/2403.09193
summary: This research investigates the texture vs. shape bias in popular vision language models (VLMs) and finds that they are often more shape-biased than their vision encoders, suggesting that visual biases can be steered through language prompting. The study confirms that shape bias can be increased from 49% to 72% through prompting alone, though the human shape bias of 96% remains unmatched....
opinion: placeholder
tags:
    - ML
