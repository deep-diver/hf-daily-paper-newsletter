date: "2025-09-28"
author: Shaobo Wang
title: 'Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token   Pruning for Efficient Supervised Fine-Tuning'
thumbnail: ""
link: https://huggingface.co/papers/2509.23873
summary: This study presents a new method called Q-Tuning to improve the efficiency of training large language models by optimizing both sample and token usage. Q-Tuning first selects valuable training examples and then prunes unnecessary tokens from those samples, resulting in significant performance improvements across various benchmarks....
opinion: placeholder
tags:
    - ML
