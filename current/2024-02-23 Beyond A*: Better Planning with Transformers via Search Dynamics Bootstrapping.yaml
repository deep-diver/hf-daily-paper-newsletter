author: Lucas Lehnert
date: '2024-02-23'
link: https://huggingface.co/papers/2402.14083
opinion: placeholder
summary: While Transformers have enabled tremendous progress in various application
  settings, such architectures still lag behind traditional symbolic planners for
  solving complex decision making tasks. In this work, we demonstrate how to train
  Transformers to solve complex planning tasks and present Searchformer, a Transformer
  model that optimally solves previously unseen Sokoban puzzles 93.7% of the time,
  while using up to 26.8% fewer search steps than standard A^* search. Searchformer
  is an encoder-de...
tags:
- Reinforcement Learning
- Deep Learning
- Optimization and Learning Algorithms
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/vil4JnUKWuwKa_SWYPFps.png
title: 'Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14083/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14083/paper.ko.html
