date: "2025-04-22"
author: Junshu Pan
title: 'Pre-DPO: Improving Data Utilization in Direct Preference Optimization   Using a Guiding Reference Model'
thumbnail: ""
link: https://huggingface.co/papers/2504.15843
summary: Pre-DPO is a new training method for large language models that uses a guiding reference model to improve data utilization in Direct Preference Optimization. This method enhances model performance by assigning higher weights to useful samples and lower weights to less useful ones, leading to consistent improvements in both DPO and SimPO on AlpacaEval 2.0 and Arena-Hard v0.1 benchmarks....
opinion: placeholder
tags:
    - ML
