date: "2025-03-06"
author: Ziyi Yang
title: 'FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion'
thumbnail: ""
link: https://huggingface.co/papers/2503.04222
summary: FuseChat-3.0 combines strengths of various LLMs, like Gemma-2-27B-it and Llama-3.1-70B-Instruct, into smaller models such as Llama-3.1-8B-Instruct and Gemma-2-9B-it, through a specialized training pipeline that includes supervised fine-tuning and Direct Preference Optimization. This approach leads to substantial performance improvements in tasks like instruction following, general knowledge, mathematics, and coding....
opinion: placeholder
tags:
    - ML
