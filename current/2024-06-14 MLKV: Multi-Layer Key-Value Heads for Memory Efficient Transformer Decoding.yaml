date: "2024-06-14"
author: Zayd Muhammad Kawakibi Zuhri
title: 'MLKV: Multi-Layer Key-Value Heads for Memory Efficient Transformer Decoding'
thumbnail: ""
link: https://huggingface.co/papers/2406.09297
summary: MLKV is a new method for reducing memory usage in transformer models while maintaining performance. It reduces memory usage by sharing key-value pairs across layers and is available in the Pythia-160M model....
opinion: placeholder
tags:
    - ML
