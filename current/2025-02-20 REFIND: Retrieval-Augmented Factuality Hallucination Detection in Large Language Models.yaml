date: "2025-02-20"
author: DongGeon Lee
title: 'REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2502.13622
summary: The document presents REFIND, a new method that detects fabricated information, or hallucinations, in large language model outputs using retrieved documents. REFIND introduces Context Sensitivity Ratio (CSR) which measures the model's dependence on retrieved evidence, and it has been shown to outperform baseline models in detecting hallucinations across nine languages including low-resource settings....
opinion: placeholder
tags:
    - ML
