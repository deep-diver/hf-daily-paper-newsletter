date: "2024-01-30"
author: Zhenyu Wang
title: 'Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Vjh-Fdss7FTOfryl0Bx2t.mp4
link: https://huggingface.co/papers/2401.15688
summary: This paper proposes CompAgent, a training-free method using a large language model to decompose complex text prompts for text-to-image generation. The agent then plans and uses tools to compose these objects, and incorporates human feedback for refinement. CompAgent significantly improves compositional text-to-image generation and has flexible applications....
opinion: placeholder
tags:
    - Supervised Learning
    - Natural Language Processing
    - Computer Vision
    - Deep Learning
