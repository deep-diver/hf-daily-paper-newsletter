date: "2024-11-07"
author: Archiki Prasad
title: Self-Consistency Preference Optimization
thumbnail: ""
link: https://huggingface.co/papers/2411.04109
summary: We propose a new method called Self-Consistency Preference Optimization (ScPO) to improve complex reasoning tasks by training models to prefer consistent answers over inconsistent ones. ScPO leads to large improvements over conventional reward model training on reasoning tasks, closing the gap with supervised training. On ZebraLogic, ScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and Claude-3 Haiku....
opinion: placeholder
tags:
    - ML
