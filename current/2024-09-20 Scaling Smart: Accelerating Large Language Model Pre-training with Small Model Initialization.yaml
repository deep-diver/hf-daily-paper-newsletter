date: "2024-09-20"
author: Mohammad Samragh
title: 'Scaling Smart: Accelerating Large Language Model Pre-training with Small Model Initialization'
thumbnail: ""
link: https://huggingface.co/papers/2409.12903
summary: This paper proposes a method called HyperCloning to initialize large language models using smaller pre-trained models. The larger model retains the functionality of the smaller model and inherits its predictive power and accuracy before training starts. This method significantly reduces the GPU hours required for pre-training large language models....
opinion: placeholder
tags:
    - ML
