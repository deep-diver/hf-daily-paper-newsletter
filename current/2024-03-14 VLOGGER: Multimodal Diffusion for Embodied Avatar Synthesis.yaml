author: Enric Corona
date: '2024-03-14'
link: https://huggingface.co/papers/2403.08764
opinion: placeholder
summary: Researchers developed a method called VLOGGER to generate high-quality video
  of people using a single input image. It uses a diffusion model and a novel architecture
  that allows for easy control of face and body movements, and it doesn't require
  training for each person. The method outperforms previous methods in image quality,
  identity preservation, and temporal consistency, and it can be used in video editing
  and personalization....
tags:
- ML
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08764.png
title: 'VLOGGER: Multimodal Diffusion for Embodied Avatar Synthesis'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.08764/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.08764/paper.ko.html
