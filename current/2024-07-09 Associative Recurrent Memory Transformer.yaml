date: "2024-07-09"
author: Ivan Rodkin
title: Associative Recurrent Memory Transformer
thumbnail: ""
link: https://huggingface.co/papers/2407.04841
summary: The paper proposes a new neural architecture called Associative Recurrent Memory Transformer (ARMT) that can process very long sequences efficiently. ARMT outperforms existing alternatives in associative retrieval tasks and sets a new record in the BABILong benchmark by answering questions over 50 million tokens with 79.9% accuracy. The source code is available on github....
opinion: placeholder
tags:
    - ML
