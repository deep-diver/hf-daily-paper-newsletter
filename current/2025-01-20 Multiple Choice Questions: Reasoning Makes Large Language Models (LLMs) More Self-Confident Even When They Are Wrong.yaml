date: "2025-01-20"
author: Tairan Fu
title: 'Multiple Choice Questions: Reasoning Makes Large Language Models (LLMs) More Self-Confident Even When They Are Wrong'
thumbnail: ""
link: https://huggingface.co/papers/2501.09775
summary: This paper investigates how providing reasoning affects the confidence of Large Language Models (LLMs) in their answers, regardless of whether the answer is correct. The study reveals that LLMs are more confident when reasoning is provided, suggesting that the estimated probabilities of LLMs have inherent limitations that should be considered in evaluation procedures. This behavior is also observed in humans, where explaining an answer increases confidence in its correctness....
opinion: placeholder
tags:
    - ML
