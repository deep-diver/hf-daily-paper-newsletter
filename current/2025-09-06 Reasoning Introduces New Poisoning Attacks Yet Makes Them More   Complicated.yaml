date: "2025-09-06"
author: Hanna Foerster
title: Reasoning Introduces New Poisoning Attacks Yet Makes Them More   Complicated
thumbnail: ""
link: https://huggingface.co/papers/2509.05739
summary: The study explores new data poisoning attacks on advanced Large Language Models (LLMs) that utilize step-by-step reasoning. These attacks, called 'decomposed reasoning poison,' are more complex and harder to activate than previous ones, suggesting that LLMs may have an inherent ability to resist such attacks due to their reasoning capabilities and architecture....
opinion: placeholder
tags:
    - ML
