date: "2024-07-15"
author: Siddharth Jha
title: Characterizing Prompt Compression Methods for Long Context Inference
thumbnail: ""
link: https://huggingface.co/papers/2407.08892
summary: The paper compares different prompt compression methods for long context inference, and finds that extractive compression often outperforms other methods, enabling up to 10x compression with minimal accuracy degradation. Token pruning methods are found to lag behind extractive compression, and only provide marginal improvements on summarization tasks....
opinion: placeholder
tags:
    - ML
