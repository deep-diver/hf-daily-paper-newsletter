date: "2025-03-13"
author: Jinhao Duan
title: 'TruthPrInt: Mitigating LVLM Object Hallucination Via Latent   Truthful-Guided Pre-Intervention'
thumbnail: ""
link: https://huggingface.co/papers/2503.10602
summary: This study investigates the use of internal states in Large Vision-Language Models (LVLMs) as 'per-token' hallucination indicators to address Object Hallucination (OH) issues, a major trustworthy challenge. The proposed Truthful-Guided Pre-Intervention (TruthPrInt) method learns truthful directions in LVLMs and applies intervention during decoding, improving cross-model and out-of-domain OH detection transferability....
opinion: placeholder
tags:
    - ML
