date: "2025-07-06"
author: Mostafa Elhoushi
title: 'any4: Learned 4-bit Numeric Representation for LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2507.04610
summary: The study introduces any4, a 4-bit weight quantization method for large language models that provides flexible numeric representations without needing any pre-processing. any4 performs better than other 4-bit methods and is competitive with those requiring preprocessing, and it can be calibrated using a single sample instead of many. The researchers also released a GPU matrix multiplication library and open-sourced their code....
opinion: placeholder
tags:
    - ML
