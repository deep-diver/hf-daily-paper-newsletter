date: "2025-06-24"
author: Jingwei Ni
title: Can Large Language Models Capture Human Annotator Disagreements?
thumbnail: ""
link: https://huggingface.co/papers/2506.19467
summary: This study investigates if large language models can capture human annotator disagreements, which are common in NLP and often contain valuable information. The researchers found that these models struggle with predicting disagreements, and methods like RLVR-style reasoning, while improving overall performance, worsen disagreement prediction. The study emphasizes the importance of evaluating and enhancing LLMs in modeling disagreements....
opinion: placeholder
tags:
    - ML
