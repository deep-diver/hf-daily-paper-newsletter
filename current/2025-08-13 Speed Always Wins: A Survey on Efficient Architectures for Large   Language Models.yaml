date: "2025-08-13"
author: Weigao Sun
title: 'Speed Always Wins: A Survey on Efficient Architectures for Large   Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2508.09834
summary: This survey explores various innovative architectures for Large Language Models (LLMs) that improve efficiency and address the limitations of traditional transformer models, which are resource-intensive. Topics covered include linear and sparse sequence modeling, efficient attention variants, hybrid models, and emerging diffusion LLMs, with potential applications to other modalities for creating scalable, resource-aware AI systems....
opinion: placeholder
tags:
    - ML
