date: "2025-02-18"
author: Bencheng Liao
title: 'Multimodal Mamba: Decoder-only Multimodal State Space Model via Quadratic to Linear Distillation'
thumbnail: ""
link: https://huggingface.co/papers/2502.13145
summary: The paper presents mmMamba, a method to convert decoder-only MLLMs to linear-complexity architectures, addressing deployment challenges of quadratic computational complexity and growing Key-Value cache requirements. mmMamba achieves competitive performance against existing VLMs, with mmMamba-linear offering 20.6x speedup and 75.8% GPU memory reduction, and mmMamba-hybrid providing 13.5x speedup and 60.2% memory savings....
opinion: placeholder
tags:
    - ML
