date: "2025-05-19"
author: Sifeng Shang
title: Fine-tuning Quantized Neural Networks with Zeroth-order Optimization
thumbnail: ""
link: https://huggingface.co/papers/2505.13430
summary: This research presents a new method, Quantized Zeroth-order Optimization (QZO), which significantly reduces memory usage for training large language models by approximating gradients and using model quantization, making it possible to train large models like Llama-2-13B and Stable Diffusion 3.5 Large within a single 24GB GPU....
opinion: placeholder
tags:
    - ML
