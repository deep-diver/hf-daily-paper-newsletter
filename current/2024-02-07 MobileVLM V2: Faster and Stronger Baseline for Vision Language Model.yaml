author: Xiangxiang Chu
date: '2024-02-07'
link: https://huggingface.co/papers/2402.03766
opinion: placeholder
summary: The MobileVLM V2 is an improved family of vision language models that can
  achieve better or similar performance compared to larger models, due to careful
  design and dataset curation....
tags:
- Deep Learning
- Computer Vision
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/mSoWqRTMm2HB8kjpTZQST.png
title: 'MobileVLM V2: Faster and Stronger Baseline for Vision Language Model'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.03766/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.03766/paper.ko.html
