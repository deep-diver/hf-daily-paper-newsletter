date: "2025-12-24"
author: Jinghan Li
title: 'Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations'
thumbnail: ""
link: https://huggingface.co/papers/2512.21004
summary: The authors present NExT-Vid, a new method for training visual models by predicting the next frame in a video, which improves upon previous methods by separating semantic information from target decoding and enhancing generation quality. Experiments show that NExT-Vid outperforms other visual representation learning methods in downstream tasks....
opinion: placeholder
tags:
    - ML
