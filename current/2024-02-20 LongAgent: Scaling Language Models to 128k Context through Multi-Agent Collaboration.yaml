author: Jun Zhao
date: '2024-02-20'
link: https://huggingface.co/papers/2402.11550
opinion: placeholder
summary: This paper proposes LongAgent, a method based on multi-agent collaboration
  that scales language models to a context of 128K and demonstrates potential superiority
  in long-text processing compared to GPT-4. LongAgent uses an inter-member communication
  mechanism to resolve response conflicts caused by hallucinations and achieves significant
  improvements in tasks such as 128k-long text retrieval and multi-hop question answering....
tags:
- Natural Language Processing
- Deep Learning
- Optimization and Learning Algorithms
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ALV8aFV_4Vd4S8j79CaFm.png
title: 'LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.11550/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.11550/paper.ko.html
