date: "2025-04-22"
author: Yucheng Li
title: 'MMInference: Accelerating Pre-filling for Long-Context VLMs via   Modality-Aware Permutation Sparse Attention'
thumbnail: ""
link: https://huggingface.co/papers/2504.16083
summary: The authors present MMInference, a method that speeds up the pre-filling process for long-context Vision Language Models (VLMs) by using a unique sparse attention pattern found in video inputs and different modalities. This approach is compatible with existing VLM pipelines, requires no model changes, and can accelerate processing by up to 8.3 times while maintaining accuracy....
opinion: placeholder
tags:
    - ML
