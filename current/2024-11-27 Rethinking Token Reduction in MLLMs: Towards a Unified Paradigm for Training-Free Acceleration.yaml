date: "2024-11-27"
author: Yuhang Han
title: 'Rethinking Token Reduction in MLLMs: Towards a Unified Paradigm for Training-Free Acceleration'
thumbnail: ""
link: https://huggingface.co/papers/2411.17686
summary: To speed up the inference of heavy Multimodal Large Language Models (MLLMs), this study proposes a new way to reduce the number of tokens. The new way breaks down the process into three steps and includes existing methods. The new methods balance speed and accuracy and can reduce the number of calculations needed by up to 82.4% without hurting performance....
opinion: placeholder
tags:
    - ML
