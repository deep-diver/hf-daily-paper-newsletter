author: Yiyuan Zhang
date: '2024-02-06'
link: https://huggingface.co/papers/2402.03040
opinion: placeholder
summary: This paper presents a user-centric framework, InteractiveVideo, that allows
  users to create customized videos by employing various modalities (text, image,
  painting, etc.) to control the video generation process. The proposed Synergistic
  Multimodal Instruction mechanism facilitates a cooperative and responsive interaction
  between user inputs and the generative process, enabling iterative and precise manipulation
  of the video generation result to meet users' requirements....
tags:
- Deep Learning
- Natural Language Processing
- Human-Computer Interaction (HCI) and User Interfaces
- Emerging Applications of Machine Learning
- Computer Vision
thumbnail: https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/assets/2402.03040.gif?raw=true
title: 'InteractiveVideo: User-Centric Controllable Video Generation with Synergistic
  Multimodal Instructions'
