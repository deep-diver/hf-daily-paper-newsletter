date: "2024-05-17"
author: Xinyang Li
title: 'Dual3D: Efficient and Consistent Text-to-3D Generation with Dual-mode Multi-view Latent Diffusion'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.09874.png
link: https://huggingface.co/papers/2405.09874
summary: Dual3D is a text-to-3D generation framework that uses a dual-mode multi-view latent diffusion model to generate high-quality 3D assets from texts in just 1 minute. It uses a dual-mode toggling inference strategy and an efficient texture refinement process to reduce generation time and enhance texture quality....
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
    - Computer Vision
    - 3D Generation
