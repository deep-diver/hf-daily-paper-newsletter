date: "2024-05-21"
author: Jialong Guo
title: 'SLAB: Efficient Transformers with Simplified Linear Attention and Progressive Re-parameterized Batch Normalization'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.11582.png
link: https://huggingface.co/papers/2405.11582
summary: This paper proposes a new method called PRepBN to replace LayerNorm with re-parameterized BatchNorm in transformer architectures, which improves performance and reduces computational cost. It also introduces a simplified linear attention (SLA) module that achieves strong performance with less computational cost. The method is evaluated on image classification and object detection tasks, and the results show improved performance and lower latency compared to existing methods....
opinion: placeholder
tags:
    - Deep Learning
