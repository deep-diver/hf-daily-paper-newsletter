date: "2024-06-03"
author: Zachary Ankner
title: 'Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.20541.png
link: https://huggingface.co/papers/2405.20541
summary: In this paper, the authors investigate whether small language models can determine high-quality subsets of large-scale text datasets that improve the performance of larger language models. They demonstrate that perplexity-based pruning of pretraining data can significantly improve downstream task performance and achieves up to a 1.45 times reduction in pretraining steps to reach commensurate baseline performance. Furthermore, they demonstrate that such perplexity-based data pruning also yields d...
opinion: placeholder
tags:
    - Supervised Learning
    - Deep Learning
    - Natural Language Processing
