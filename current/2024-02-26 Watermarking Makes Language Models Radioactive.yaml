author: Tom Sander
date: '2024-02-26'
link: https://huggingface.co/papers/2402.14904
opinion: placeholder
summary: This paper proposes using watermarked training data to detect if a language
  model was fine-tuned using text generated by another language model. The method
  is more reliable than conventional methods and can detect watermarked synthetic
  instructions with high confidence even when only a small percentage of the training
  text is watermarked....
tags:
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/u16DqQGe68ALImF2qDgqK.png
title: Watermarking Makes Language Models Radioactive
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14904/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14904/paper.ko.html
