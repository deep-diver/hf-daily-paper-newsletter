date: "2025-11-17"
author: Yehonatan Elisha
title: 'Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations'
thumbnail: ""
link: https://huggingface.co/papers/2511.13081
summary: The authors propose a new framework, RFxG, to categorize and assess visual explanations in deep learning, addressing the current lack of consensus in evaluating these explanations. This framework includes four new metrics to systematically assess explanation quality, which are applied to various methods, architectures, and datasets, promoting user-intent-driven evaluation and aligning explanations with human understanding....
opinion: placeholder
tags:
    - ML
