date: "2025-11-10"
author: Sean McLeish
title: Teaching Pretrained Language Models to Think Deeper with Retrofitted   Recurrence
thumbnail: ""
link: https://huggingface.co/papers/2511.07384
summary: The study explores how to transform existing non-recurrent language models into depth-recurrent models, which can reduce computational cost while maintaining performance. By using a curriculum of recurrences to increase the model's effective depth during training, the converted models show better performance at a given compute budget, particularly in mathematics tasks....
opinion: placeholder
tags:
    - ML
