date: "2025-11-07"
author: Jack Hong
title: 'DeepEyesV2: Toward Agentic Multimodal Model'
thumbnail: ""
link: https://huggingface.co/papers/2511.05271
summary: 'The study presents DeepEyesV2, an agentic multimodal model that understands text and images and uses external tools like code execution and web search. The model is trained in two stages: first, to establish tool-use patterns, and second, to refine tool invocation. The researchers also introduce RealX-Bench, a benchmark to evaluate real-world multimodal reasoning, and demonstrate DeepEyesV2''s effectiveness in various tasks, including perception, reasoning, and search....'
opinion: placeholder
tags:
    - ML
