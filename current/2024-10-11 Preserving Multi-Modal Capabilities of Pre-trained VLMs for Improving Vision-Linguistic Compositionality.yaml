date: "2024-10-11"
author: Youngtaek Oh
title: Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality
thumbnail: ""
link: https://huggingface.co/papers/2410.05210
summary: This paper introduces a new method to improve compositional understanding in pre-trained vision and language models without compromising performance in zero-shot multi-modal tasks. The method, called Fine-grained Selective Calibrated CLIP (FSC-CLIP), uses local hard negative loss and selective calibrated regularization to provide fine-grained negative supervision while preserving the model's representational integrity. FSC-CLIP achieves state-of-the-art compositional understanding and retains st...
opinion: placeholder
tags:
    - ML
