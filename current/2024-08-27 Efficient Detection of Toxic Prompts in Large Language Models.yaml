date: "2024-08-27"
author: Yi Liu
title: Efficient Detection of Toxic Prompts in Large Language Models
thumbnail: ""
link: https://huggingface.co/papers/2408.11727
summary: ToxicDetector is a lightweight greybox method that uses LLMs and embedding vectors to efficiently detect toxic prompts in large language models (LLMs) like ChatGPT and Gemini. It outperforms existing methods with a high accuracy of 96.39% and a low false positive rate of 2.00%, making it suitable for real-time applications....
opinion: placeholder
tags:
    - ML
