date: "2025-05-19"
author: Peiyuan Zhang
title: Faster Video Diffusion with Trainable Sparse Attention
thumbnail: ""
link: https://huggingface.co/papers/2505.13389
summary: The authors present VSA, a new sparse attention method for video diffusion transformers that significantly reduces computation and improves efficiency without sacrificing quality. VSA replaces full attention with a trainable, hardware-efficient alternative that pools tokens into tiles and computes attention only within those tiles, resulting in faster training and inference times for video diffusion models....
opinion: placeholder
tags:
    - ML
