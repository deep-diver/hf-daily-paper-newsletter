date: "2024-12-11"
author: Romain Stora√Ø
title: 'HARP: Hesitation-Aware Reframing in Transformer Inference Pass'
thumbnail: ""
link: https://huggingface.co/papers/2412.07282
summary: This paper introduces HARP, a method that improves the performance of large language models by applying additional computation when the model encounters uncertainty during token generation. HARP is a simple modification to the Transformer forward pass and is model-agnostic, training-free, and easy to implement. It offers performance improvements up to +5.16% while maintaining inference times twice faster than beam search....
opinion: placeholder
tags:
    - ML
