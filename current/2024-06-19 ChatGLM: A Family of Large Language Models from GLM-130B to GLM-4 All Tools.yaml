date: "2024-06-19"
author: Team GLM
title: 'ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools'
thumbnail: ""
link: https://huggingface.co/papers/2406.12793
summary: ChatGLM is a family of large language models that are pre-trained on ten trillions of tokens in Chinese and English, and aligned for Chinese and English usage. The GLM-4 models closely rivals or outperforms GPT-4 in various evaluations and is further aligned to use tools like web browser, Python interpreter, and text-to-image model to complete complex tasks. The open models have attracted over 10 million downloads on Hugging face in 2023....
opinion: placeholder
tags:
    - ML
