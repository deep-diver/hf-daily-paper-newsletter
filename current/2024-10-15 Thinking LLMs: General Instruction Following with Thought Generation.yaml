date: "2024-10-15"
author: Tianhao Wu
title: 'Thinking LLMs: General Instruction Following with Thought Generation'
thumbnail: ""
link: https://huggingface.co/papers/2410.10630
summary: LLMs are typically trained to answer user questions or follow instructions similarly to how human experts respond. However, in the standard alignment framework they lack the basic ability of explicit thinking before answering. Thinking is important for complex questions that require reasoning and planning -- but can be applied to any task. We propose a training method for equipping existing LLMs with such thinking abilities for general instruction following without use of additional human data. ...
opinion: placeholder
tags:
    - ML
