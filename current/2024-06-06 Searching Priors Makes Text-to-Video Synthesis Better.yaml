date: "2024-06-06"
author: Haoran Cheng
title: Searching Priors Makes Text-to-Video Synthesis Better
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.03215.png
link: https://huggingface.co/papers/2406.03215
summary: The abstract introduces a new method for improving the realism of motion in text-to-video synthesis by using existing videos as motion priors. The method involves searching for videos with text labels that match the desired motion and then distilling these videos into motion priors to fine-tune a pre-trained base model. This approach can enhance the realism of the generated videos without the need for massive data or expensive training. The method is validated against state-of-the-art models and...
opinion: placeholder
tags:
    - Unsupervised Learning
    - Deep Learning
    - Computer Vision
