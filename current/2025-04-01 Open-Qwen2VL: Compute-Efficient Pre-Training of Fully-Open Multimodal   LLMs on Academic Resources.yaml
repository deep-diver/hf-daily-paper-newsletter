date: "2025-04-01"
author: Weizhi Wang
title: 'Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal   LLMs on Academic Resources'
thumbnail: ""
link: https://huggingface.co/papers/2504.00595
summary: The paper presents Open-Qwen2VL, an efficient and fully-open pre-training method for multimodal LLMs using 29M image-text pairs. The approach employs dynamic image resolution, multimodal sequence packing, and careful data filtering, achieving superior performance on multimodal benchmarks with fewer GPU hours compared to other models....
opinion: placeholder
tags:
    - ML
