date: "2025-03-11"
author: Jialv Zou
title: 'OmniMamba: Efficient and Unified Multimodal Understanding and Generation   via State Space Models'
thumbnail: ""
link: https://huggingface.co/papers/2503.08686
summary: OmniMamba is a multimodal generation model that generates text and images efficiently using a linear-architecture and Mamba-2. It addresses data inefficiency with decoupled vocabularies and task-specific LoRA, and uses a two-stage training strategy to mitigate data imbalance. This model outperforms competitors with fewer training data and faster inference efficiency....
opinion: placeholder
tags:
    - ML
