date: "2025-03-24"
author: Chi-Chih Chang
title: 'xKV: Cross-Layer SVD for KV-Cache Compression'
thumbnail: ""
link: https://huggingface.co/papers/2503.18893
summary: The paper presents xKV, a post-training method for compressing KV-Cache in Large Language Models (LLMs). It applies Singular Value Decomposition (SVD) on the KV-Cache of grouped layers, reducing memory consumption while maintaining accuracy and compatibility with other techniques, achieving up to 6.8x higher compression rates than state-of-the-art inter-layer techniques and a notable 3x compression rate on coding tasks without performance degradation....
opinion: placeholder
tags:
    - ML
