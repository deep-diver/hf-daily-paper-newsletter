date: "2025-03-10"
author: Zeyu Zhang
title: 'Motion Anything: Any to Motion Generation'
thumbnail: ""
link: https://huggingface.co/papers/2503.06955
summary: The authors present a solution to the problem of conditional motion generation, which struggles with prioritizing dynamic frames and integrating multiple modalities. They suggest Motion Anything, a multimodal framework using an attention-based mask modeling approach for better control and an adaptive encoding mechanism for multimodal conditions. They also create a new dataset called Text-Music-Dance (TMD) to improve the existing state-of-the-art methods....
opinion: placeholder
tags:
    - ML
