date: "2025-11-18"
author: Huiyi Chen
title: 'MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs'
thumbnail: ""
link: https://huggingface.co/papers/2511.14159
summary: Researchers have created MVI-Bench, a new tool to test how well large vision-language models handle misleading images, which is important for making these models more reliable and responsible. They built MVI-Bench using a system of categories and curated questions, and introduced a new way to measure a model's performance in this area. Testing various top models on MVI-Bench showed that they often struggle with misleading visual inputs, providing insights for improving these models....
opinion: placeholder
tags:
    - ML
