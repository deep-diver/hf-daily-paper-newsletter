date: "2025-08-25"
author: Zhenwei Tang
title: 'SEAM: Semantically Equivalent Across Modalities Benchmark for   Vision-Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2508.18179
summary: The SEAM benchmark is designed to test if vision-language models understand information equally across text and images by using standardized notations in four domains. The results show that models often struggle with vision more than text, even when the information is the same, and the errors are usually due to misunderstanding text or seeing things that aren't there....
opinion: placeholder
tags:
    - ML
