date: "2024-08-21"
author: Viraat Aryabumi
title: To Code, or Not To Code? Exploring Impact of Code in Pre-training
thumbnail: ""
link: https://huggingface.co/papers/2408.10914
summary: Including code in the pre-training data mixture, even for models not specifically designed for code, has a significant impact on the performance of general LLMs, resulting in improvements in natural language reasoning, world knowledge, code performance, and generative win-rates....
opinion: placeholder
tags:
    - ML
