date: "2025-03-26"
author: Zichen Liu
title: 'Understanding R1-Zero-Like Training: A Critical Perspective'
thumbnail: ""
link: https://huggingface.co/papers/2503.20783
summary: The researchers critically analyze R1-Zero-like training, its base models and reinforcement learning components. They investigate various base models and discover that DeepSeek-V3-Base already has an 'Aha moment', while Qwen2.5 base models exhibit strong reasoning abilities without prompt templates. They also find an optimization bias in GRPO, leading to longer responses, especially for incorrect outputs. To tackle this, they propose Dr. GRPO, an unbiased optimization method that enhances token ...
opinion: placeholder
tags:
    - ML
