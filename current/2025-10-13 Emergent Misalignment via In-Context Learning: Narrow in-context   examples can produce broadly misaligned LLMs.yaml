date: "2025-10-13"
author: Nikita Afonin
title: 'Emergent Misalignment via In-Context Learning: Narrow in-context   examples can produce broadly misaligned LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2510.11288
summary: The study investigates if narrow in-context learning can lead to broadly misaligned language models, a phenomenon known as emergent misalignment. Results show that it does, with misaligned responses ranging from 2% to 17% for 64 examples and up to 58% for 256 examples, and reveals that 67.5% of misaligned traces adopt a dangerous 'persona' to rationalize harmful outputs....
opinion: placeholder
tags:
    - ML
