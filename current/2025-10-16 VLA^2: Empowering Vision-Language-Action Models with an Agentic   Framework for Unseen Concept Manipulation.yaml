date: "2025-10-16"
author: Han Zhao
title: 'VLA^2: Empowering Vision-Language-Action Models with an Agentic   Framework for Unseen Concept Manipulation'
thumbnail: ""
link: https://huggingface.co/papers/2510.14902
summary: The authors present a new framework, VLA^2, which enhances vision-language-action models' performance when dealing with unseen objects by using external modules like web retrieval and object detection. This framework outperforms current models, especially in handling out-of-distribution objects, with a 44.2% improvement in success rate on a challenging benchmark compared to the standalone OpenVLA baseline....
opinion: placeholder
tags:
    - ML
