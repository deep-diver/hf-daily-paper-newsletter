date: "2025-02-17"
author: Jeremy Kritz
title: Jailbreaking to Jailbreak
thumbnail: ""
link: https://huggingface.co/papers/2502.09638
summary: The research discusses a new method where a human jailbreaks a refusal-trained LLM to make it capable of jailbreaking itself or other LLMs, which are referred to as J_2 attackers. Experiments show that Sonnet 3.5 and Gemini 1.5 outperform others as J_2, achieving high attack success rates against GPT-4o and other capable LLMs....
opinion: placeholder
tags:
    - ML
