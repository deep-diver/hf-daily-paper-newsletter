date: "2024-05-02"
author: Yue Wu
title: Self-Play Preference Optimization for Language Model Alignment
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.00675.png
link: https://huggingface.co/papers/2405.00675
summary: This paper proposes a self-play-based method called Self-Play Preference Optimization (SPPO) for language model alignment. SPPO treats the problem as a constant-sum two-player game aimed at identifying the Nash equilibrium policy. It can effectively increase the likelihood of the chosen response and decrease that of the rejected response, outperforming traditional reinforcement learning from human feedback approaches....
opinion: placeholder
tags:
    - Supervised Learning
    - Reinforcement Learning
    - Natural Language Processing
