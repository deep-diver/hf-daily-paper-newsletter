date: "2025-06-05"
author: Danil Sivtsov
title: Diagonal Batching Unlocks Parallelism in Recurrent Memory Transformers   for Long Contexts
thumbnail: ""
link: https://huggingface.co/papers/2506.05229
summary: The study presents Diagonal Batching, a scheduling scheme that enhances the performance of Recurrent Memory Transformers (RMTs) for long-context inference by enabling parallelism and eliminating sequential execution. This method leads to faster GPU inference, reduced inference cost, and lower latency, making RMTs more practical for real-world applications without requiring retraining....
opinion: placeholder
tags:
    - ML
