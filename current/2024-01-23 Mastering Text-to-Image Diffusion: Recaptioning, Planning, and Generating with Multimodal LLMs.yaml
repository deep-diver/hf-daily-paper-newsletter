author: Ling Yang
date: '2024-01-23'
link: https://huggingface.co/papers/2401.11708
opinion: placeholder
summary: This paper proposes a new text-to-image generation/editing framework called
  RPG that harnesses the chain-of-thought reasoning of multimodal LLMs to enhance
  the compositionality of text-to-image diffusion models. RPG breaks down the process
  of generating complex images into simpler subregion generation tasks, and employs
  complementary regional diffusion for compositional generation. Experiments show
  that RPG outperforms state-of-the-art models, particularly in multi-category object
  composition an...
tags:
- Deep Learning
- Natural Language Processing
- Computer Vision
- Emerging Applications of Machine Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/x8Du5h62UaslJ3-VwzFK7.png
title: 'Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating
  with Multimodal LLMs'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.11708/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.11708/paper.ko.html
