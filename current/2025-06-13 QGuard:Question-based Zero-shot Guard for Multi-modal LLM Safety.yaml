date: "2025-06-13"
author: Taegyeong Lee
title: QGuard:Question-based Zero-shot Guard for Multi-modal LLM Safety
thumbnail: ""
link: https://huggingface.co/papers/2506.12299
summary: The paper proposes QGuard, a new method to protect Large Language Models from harmful and malicious prompts, including those with multiple formats like text and images. QGuard uses question prompting to block these prompts without needing additional training, and it effectively defends against the latest harmful prompts while providing insights for real-world LLM services to mitigate security risks....
opinion: placeholder
tags:
    - ML
