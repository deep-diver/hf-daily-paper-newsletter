date: "2024-02-06"
author: Yang Jin
title: 'Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/miQWUWm-g3Zp120IwSUir.mp4
link: https://huggingface.co/papers/2402.03161
summary: This paper introduces a video-language pre-training method called Video-LaVIT, which breaks down videos into keyframes and motions, and then uses a large language model to pre-train on this data. The goal is to enable computers to understand and generate both images and videos, and the method is shown to perform well on various benchmarks for image and video understanding and generation. ...
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
    - Computer Vision
    - Video Understanding and Generation
