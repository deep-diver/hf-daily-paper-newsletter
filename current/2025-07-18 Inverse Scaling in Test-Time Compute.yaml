date: "2025-07-18"
author: Aryo Pradipta Gema
title: Inverse Scaling in Test-Time Compute
thumbnail: ""
link: https://huggingface.co/papers/2507.14417
summary: 'The study presents tasks that show improving reasoning length in large models can actually decrease performance, finding five main issues: distractions, overfitting, spurious correlations, focus problems, and amplified harmful behaviors. The research highlights the need to evaluate models across various reasoning lengths to tackle these issues and improve model capabilities without reinforcing problematic patterns....'
opinion: placeholder
tags:
    - ML
