date: "2025-06-13"
author: Zheyuan Yang
title: 'Can LLMs Generate High-Quality Test Cases for Algorithm Problems?   TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure'
thumbnail: ""
link: https://huggingface.co/papers/2506.12278
summary: 'The researchers present TestCase-Eval, a new benchmark using 500 algorithm problems and 100,000 human-crafted solutions to evaluate LLMs in generating test cases. They focus on two tasks: Fault Coverage to assess the ability to probe diverse input scenarios and Fault Exposure to reveal incorrect code implementations, analyzing 19 LLMs to provide insights into their performance....'
opinion: placeholder
tags:
    - ML
