date: "2025-09-30"
author: Jingdi Lei
title: 'OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost   Always!'
thumbnail: ""
link: https://huggingface.co/papers/2509.26495
summary: The study introduces a new concept called operational safety for large language models, which measures their ability to handle specific tasks safely. The researchers also present a benchmark called OffTopicEval to evaluate this safety. Their findings show that most models struggle with operational safety, but they propose prompt-based steering methods to improve performance....
opinion: placeholder
tags:
    - ML
