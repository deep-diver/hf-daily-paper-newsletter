date: "2024-01-30"
author: Xiaoyu Shi
title: 'Motion-I2V: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DFR3GpMI4021qU9o36Vhk.png
link: https://huggingface.co/papers/2401.15977
summary: 'This paper presents a new framework called Motion-I2V for generating consistent and controllable videos from images. Motion-I2V breaks down the process into two stages: a diffusion-based motion field predictor and motion-augmented temporal attention. The first stage predicts the movement of pixels in the input image, which guides the second stage in creating the synthesized frames. Motion-I2V can handle large motions and viewpoint changes, and allows users to control the motion trajectories usin...'
opinion: placeholder
tags:
    - Computer Vision
    - Deep Learning
