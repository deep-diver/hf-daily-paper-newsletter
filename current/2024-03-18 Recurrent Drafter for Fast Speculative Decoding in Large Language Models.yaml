date: "2024-03-18"
author: Aonan Zhang
title: Recurrent Drafter for Fast Speculative Decoding in Large Language Models
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09919.png
link: https://huggingface.co/papers/2403.09919
summary: This paper proposes a new method for fast speculative decoding in large language models by combining the strengths of two existing techniques. The method uses a single, lightweight draft head with a recurrent dependency design, which allows for efficient filtering of undesired candidates. Empirical results show the effectiveness of the method on several popular language models....
opinion: placeholder
tags:
    - Natural Language Processing
    - Deep Learning
    - Optimization and Learning Algorithms
