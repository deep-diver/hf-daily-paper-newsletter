date: "2024-06-25"
author: Terry Yue Zhuo
title: 'BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions'
thumbnail: ""
link: https://huggingface.co/papers/2406.15877
summary: This paper introduces Bench, a benchmark for evaluating the capability of large language models (LLMs) in solving challenging and practical programming tasks. The benchmark includes diverse function calls and complex instructions, and the results show that LLMs are not yet capable of following complex instructions to use function calls precisely, with scores up to 60%, significantly lower than human performance of 97%....
opinion: placeholder
tags:
    - ML
