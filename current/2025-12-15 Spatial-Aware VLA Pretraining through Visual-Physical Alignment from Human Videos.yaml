date: "2025-12-15"
author: Yicheng Feng
title: Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos
thumbnail: ""
link: https://huggingface.co/papers/2512.13080
summary: The researchers developed a new method for training vision-language-action models to understand 3D spatial relationships by aligning visual and physical spaces. They used human demonstration videos to create a dual-encoder architecture, which improved the model's ability to perform robotic tasks in 3D environments....
opinion: placeholder
tags:
    - ML
