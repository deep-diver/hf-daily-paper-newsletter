author: Sun Ao
date: '2024-03-15'
link: https://huggingface.co/papers/2403.09347
opinion: placeholder
summary: This paper proposes a distributed attention framework called BurstAttention
  to optimize memory access and communication operations for processing extremely
  long sequences, achieving significant advantages in speed and efficiency compared
  to other methods....
tags:
- Deep Learning
- Optimization and Learning Algorithms
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09347.png
title: 'BurstAttention: An Efficient Distributed Attention Framework for Extremely
  Long Sequences'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.09347/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.09347/paper.ko.html
