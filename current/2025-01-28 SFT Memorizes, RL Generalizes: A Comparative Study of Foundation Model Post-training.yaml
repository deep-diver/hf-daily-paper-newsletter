date: "2025-01-28"
author: Tianzhe Chu
title: 'SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training'
thumbnail: ""
link: https://huggingface.co/papers/2501.17161
summary: This study examines the impact of supervised fine-tuning (SFT) and reinforcement learning (RL) on generalization and memorization in foundation models, using text-based and visual variants. Results show that RL, particularly with an outcome-based reward, generalizes better than SFT in both textual and visual domains, while SFT plays a crucial role in stabilizing model output for RL training....
opinion: placeholder
tags:
    - ML
