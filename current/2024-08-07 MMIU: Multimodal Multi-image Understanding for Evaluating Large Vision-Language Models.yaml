date: "2024-08-07"
author: Fanqing Meng
title: 'MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2408.02718
summary: The MMIU benchmark is a comprehensive evaluation suite designed to assess Large Vision-Language Models' (LVLMs) ability to understand multiple images. It includes 7 types of multi-image relationships, 52 tasks, 77K images, and 11K questions. When tested on 24 popular LVLMs, including both open-source and proprietary models, the models struggled with spatial understanding tasks, with GPT-4o achieving only 55.7% accuracy....
opinion: placeholder
tags:
    - ML
