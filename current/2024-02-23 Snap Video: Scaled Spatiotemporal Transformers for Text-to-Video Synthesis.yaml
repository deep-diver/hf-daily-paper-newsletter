author: Willi Menapace
date: '2024-02-23'
link: https://huggingface.co/papers/2402.14797
opinion: placeholder
summary: This paper proposes a new transformer-based architecture called Snap Video
  that addresses the challenges of generating high-quality, temporally consistent
  videos with complex motion. Snap Video is faster to train and can handle billions
  of parameters, resulting in state-of-the-art performance and user preference over
  existing methods....
tags:
- Deep Learning
- Natural Language Processing
- Computer Vision
- Video Generation
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2z9ydIkorw1KI1SgxlMya.png
title: 'Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14797/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14797/paper.ko.html
