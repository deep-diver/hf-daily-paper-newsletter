date: "2025-02-05"
author: Edward Yeo
title: Demystifying Long Chain-of-Thought Reasoning in LLMs
thumbnail: ""
link: https://huggingface.co/papers/2502.03373
summary: The study examines the factors enabling long chains-of-thought reasoning in large language models, finding that supervised fine-tuning improves training efficiency, reasoning capabilities emerge with increased compute, reward shaping is crucial for stability, and scaling verifiable reward signals is critical for RL, especially for out-of-distribution tasks. Error correction abilities are inherent but require significant compute to incentivize effectively....
opinion: placeholder
tags:
    - ML
