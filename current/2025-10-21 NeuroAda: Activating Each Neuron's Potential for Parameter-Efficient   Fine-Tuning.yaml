date: "2025-10-21"
author: Zhi Zhang
title: 'NeuroAda: Activating Each Neuron''s Potential for Parameter-Efficient   Fine-Tuning'
thumbnail: ""
link: https://huggingface.co/papers/2510.18940
summary: The study presents NeuroAda, a new method for parameter-efficient fine-tuning of neural networks, which achieves high performance with minimal memory usage by identifying key parameters and introducing bypass connections for updates. NeuroAda outperforms existing methods on various tasks using as little as 0.02% trainable parameters and reduces CUDA memory usage by up to 60%....
opinion: placeholder
tags:
    - ML
