date: "2025-01-22"
author: Haotian Luo
title: 'O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning'
thumbnail: ""
link: https://huggingface.co/papers/2501.12570
summary: This study presents a method called Length-Harmonizing Fine-Tuning (O1-Pruner) to address the challenge of reducing inference overhead in long-thought reasoning models like O1, without compromising accuracy. The method optimizes token budget allocation through RL-style fine-tuning, resulting in more efficient and less redundant reasoning processes, as verified by experiments on various mathematical reasoning benchmarks....
opinion: placeholder
tags:
    - ML
