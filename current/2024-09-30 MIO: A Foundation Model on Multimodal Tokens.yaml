date: "2024-09-30"
author: Zekun Wang
title: 'MIO: A Foundation Model on Multimodal Tokens'
thumbnail: ""
link: https://huggingface.co/papers/2409.17692
summary: MIO is a foundation model that can understand and generate speech, text, images, and videos in an end-to-end, autoregressive manner. It is trained on a mixture of discrete tokens across four modalities using causal multimodal modeling and exhibits competitive, and in some cases superior, performance compared to previous baselines....
opinion: placeholder
tags:
    - ML
