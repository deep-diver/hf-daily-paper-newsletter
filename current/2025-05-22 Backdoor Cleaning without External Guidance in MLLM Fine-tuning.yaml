date: "2025-05-22"
author: Xuankun Rong
title: Backdoor Cleaning without External Guidance in MLLM Fine-tuning
thumbnail: ""
link: https://huggingface.co/papers/2505.16916
summary: This study presents a method called Believe Your Eyes (BYE) to detect and remove backdoor triggers in Multimodal Large Language Models (MLLMs) without needing additional data or model changes. BYE works by analyzing attention patterns and filtering out suspicious samples, effectively preventing backdoor attacks while preserving the model's performance....
opinion: placeholder
tags:
    - ML
