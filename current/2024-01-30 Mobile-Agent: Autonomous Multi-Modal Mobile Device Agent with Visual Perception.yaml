author: Junyang Wang
date: '2024-01-30'
link: https://huggingface.co/papers/2401.16158
opinion: placeholder
summary: This paper presents Mobile-Agent, an autonomous multi-modal mobile device
  agent that uses visual perception tools to accurately identify and locate both visual
  and textual elements within an app's front-end interface. It then plans and navigates
  the mobile apps through operations step by step, and is more adaptable across diverse
  mobile operating environments....
tags:
- Deep Learning
- Computer Vision
- Human-Computer Interaction (HCI) and User Interfaces
thumbnail: https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/assets/2401.16158.gif?raw=true
title: 'Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception'
