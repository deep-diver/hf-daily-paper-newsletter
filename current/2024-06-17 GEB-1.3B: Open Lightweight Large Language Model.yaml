date: "2024-06-17"
author: Jie Wu
title: 'GEB-1.3B: Open Lightweight Large Language Model'
thumbnail: ""
link: https://huggingface.co/papers/2406.09900
summary: The paper introduces GEB-1.3B, a lightweight language model trained on 550 billion tokens in both Chinese and English. It uses new training techniques to speed up training and fine-tuning to improve alignment. GEB-1.3B performs well on various benchmarks and has good inference times on CPUs. It's open-source, which will help future research....
opinion: placeholder
tags:
    - ML
