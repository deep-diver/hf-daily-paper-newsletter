date: "2024-09-19"
author: Yi Lu
title: A Controlled Study on Long Context Extension and Generalization in LLMs
thumbnail: ""
link: https://huggingface.co/papers/2409.12181
summary: This study compares different methods for extending language models to handle long contexts and finds that perplexity is a good measure of performance, approximate attention methods underperform, and fine-tuning based methods are effective within their range but struggle with extrapolation. The study promotes transparency and further research by making all codebases, models, and checkpoints available open-source....
opinion: placeholder
tags:
    - ML
