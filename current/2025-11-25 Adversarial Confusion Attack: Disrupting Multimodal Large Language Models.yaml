date: "2025-11-25"
author: Jakub Hoscilowicz
title: 'Adversarial Confusion Attack: Disrupting Multimodal Large Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2511.20494
summary: The study presents a new method to disrupt multimodal large language models by making them generate incorrect or incoherent responses. This is achieved by embedding specific images that increase uncertainty in the model's outputs, affecting both open-source and proprietary models....
opinion: placeholder
tags:
    - ML
