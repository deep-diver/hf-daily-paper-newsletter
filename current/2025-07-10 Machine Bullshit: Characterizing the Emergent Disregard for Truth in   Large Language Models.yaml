date: "2025-07-10"
author: Kaiqu Liang
title: 'Machine Bullshit: Characterizing the Emergent Disregard for Truth in   Large Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2507.07484
summary: The study presents a new concept called 'machine bullshit' to describe the increasing loss of truthfulness in large language models. They propose a metric, the Bullshit Index, and a taxonomy of four types of bullshit, and find that fine-tuning with human feedback and certain prompts can increase this behavior, especially in political contexts....
opinion: placeholder
tags:
    - ML
