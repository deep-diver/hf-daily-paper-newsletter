date: "2025-04-18"
author: Yule Liu
title: 'Thought Manipulation: External Thought Can Be Efficient for Large   Reasoning Models'
thumbnail: ""
link: https://huggingface.co/papers/2504.13626
summary: This work presents ThoughtMani, a pipeline that utilizes external CoTs from smaller models to manipulate large reasoning models (LRMs) and reduce redundant reasoning steps. ThoughtMani enhances safety alignment, keeps original performance, and reduces output token counts by approximately 30% when applied to QwQ-32B on the LiveBench/Code dataset, making LRMs more efficient and accessible for real-world applications....
opinion: placeholder
tags:
    - ML
