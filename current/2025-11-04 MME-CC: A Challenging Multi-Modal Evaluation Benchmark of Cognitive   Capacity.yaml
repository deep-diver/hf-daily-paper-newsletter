date: "2025-11-04"
author: Kaiyuan Zhang
title: 'MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive   Capacity'
thumbnail: ""
link: https://huggingface.co/papers/2511.03146
summary: The authors present MME-CC, a new benchmark for assessing the cognitive abilities of multimodal large language models (MLLM) in tasks involving visual information. They evaluate 16 MLLMs using this benchmark, finding that while closed-source models perform better overall, all models struggle with spatial and geometric reasoning, and identifying common errors in these areas....
opinion: placeholder
tags:
    - ML
