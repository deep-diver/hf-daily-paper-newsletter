date: "2025-09-22"
author: Sara Papi
title: Cross-Attention is Half Explanation in Speech-to-Text Models
thumbnail: ""
link: https://huggingface.co/papers/2509.18010
summary: The study examines how well cross-attention in speech-to-text models explains the relationship between input speech and generated text. Results show that while cross-attention aligns moderately to strongly with input saliency maps, it only captures about half of the input relevance and partially reflects the decoder's attention to the encoder's representations....
opinion: placeholder
tags:
    - ML
