author: Xuandong Zhao
date: '2024-01-31'
link: https://huggingface.co/papers/2401.17256
opinion: placeholder
summary: The paper proposes a new attack method called weak-to-strong jailbreaking,
  which allows adversaries to use smaller, already-trained language models to guide
  their attack against much larger language models, making jailbreaking faster and
  more efficient. The paper also suggests a defense strategy to protect against this
  attack but acknowledges that creating more effective defenses is still challenging....
tags:
- Natural Language Processing
- Optimization and Learning Algorithms
- Security and Privacy
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/HGmvvHi9qDTpuE249bHYE.png
title: Weak-to-Strong Jailbreaking on Large Language Models
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.17256/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.17256/paper.ko.html
