date: "2024-02-21"
author: Liyan Tang
title: 'TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/PBfJ7ChEbHACyakpBwPSd.png
link: https://huggingface.co/papers/2402.13249
summary: This study evaluates the factual consistency of LLMs in topic-focused dialogue summarization and finds that existing LLMs hallucinate significant amounts of factual errors, regardless of the model's size. The study also shows that LLMs perform poorly as binary factual evaluators and that non-LLM based metrics can capture all error types better than LLM-based evaluators....
opinion: placeholder
tags:
    - Natural Language Processing
