date: "2025-03-14"
author: Hao Cui
title: 'CURIE: Evaluating LLMs On Multitask Scientific Long Context   Understanding and Reasoning'
thumbnail: ""
link: https://huggingface.co/papers/2503.13517
summary: CURIE is a new benchmark for evaluating large language models in scientific problem-solving, containing 580 problems across six disciplines. While Gemini Flash 2.0 and Claude-3 perform well across domains, GPT-4o and command-R+ struggle with protein sequencing tasks, with the best performance at 32%....
opinion: placeholder
tags:
    - ML
