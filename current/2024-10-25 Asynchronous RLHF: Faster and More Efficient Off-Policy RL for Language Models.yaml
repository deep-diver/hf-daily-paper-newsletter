date: "2024-10-25"
author: Michael Noukhovitch
title: 'Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2410.18252
summary: This paper proposes separating generation and learning in RLHF to make it faster and more efficient. They find that online DPO is most robust to off-policy data and study further compute optimizations, but they come at a performance cost. The paper verifies the scalability of asynchronous RLHF by training LLaMA 3.1 8B on an instruction-following task 40% faster than a synchronous run while matching final performance....
opinion: placeholder
tags:
    - ML
