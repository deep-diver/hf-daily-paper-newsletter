date: "2024-06-06"
author: Rafael Rafailov
title: Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02900.png
link: https://huggingface.co/papers/2406.02900
summary: Direct Alignment Algorithms (DAAs) have been introduced as an alternative to the classical RLHF pipeline, but they still suffer from reward over-optimization or hacking, which can lead to a deterioration in performance. This paper explores the consequences of this problem across different objectives, training regimes, and model scales....
opinion: placeholder
tags:
    - Reinforcement Learning
    - Deep Learning
