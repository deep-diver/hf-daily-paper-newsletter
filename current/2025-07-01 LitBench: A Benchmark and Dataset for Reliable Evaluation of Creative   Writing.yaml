date: "2025-07-01"
author: Daniel Fein
title: 'LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative   Writing'
thumbnail: ""
link: https://huggingface.co/papers/2507.00769
summary: The authors present LitBench, a new benchmark and dataset for evaluating creative writing generated by large language models. LitBench includes a test set of 2,480 human-labeled story comparisons and a training corpus of 43,827 human preference labels, which are used to assess and train various models for creative writing verification. The benchmark identifies Claude-3.7-Sonnet as the best off-the-shelf judge, while Bradley-Terry and Generative reward models outperform all other models in aligni...
opinion: placeholder
tags:
    - ML
