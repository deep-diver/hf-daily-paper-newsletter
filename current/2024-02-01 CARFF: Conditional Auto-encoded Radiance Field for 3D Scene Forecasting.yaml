author: Jiezhi Yang
date: '2024-02-01'
link: https://huggingface.co/papers/2401.18075
opinion: placeholder
summary: The paper presents CARFF, a method for predicting future 3D scenes based
  on past observations using a probabilistic encoder and a global Neural Radiance
  Field. It extends previous work by considering complex scenarios of uncertainty
  and is trained using a two-stage process. It is demonstrated to be useful for autonomous
  driving scenarios using the CARLA simulator....
tags:
- Deep Learning
- Computer Vision
- Robotics and Control
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/vEVUJk-dn9Jpd_1pGCq1I.png
title: 'CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.18075/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.18075/paper.ko.html
