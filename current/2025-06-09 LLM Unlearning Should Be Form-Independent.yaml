date: "2025-06-09"
author: Xiaotian Ye
title: LLM Unlearning Should Be Form-Independent
thumbnail: ""
link: https://huggingface.co/papers/2506.07795
summary: The study identifies a problem in existing unlearning methods for Large Language Models (LLMs) where their effectiveness depends on the form of training samples, leading to widespread and severe Form-Dependent Bias. The researchers propose a new method called Rank-one Concept Redirection (ROCR) that targets invariants in downstream tasks to improve unlearning effectiveness and generate natural outputs, aiming for form-independent LLM unlearning....
opinion: placeholder
tags:
    - ML
