author: Chen Li
date: '2024-03-08'
link: https://huggingface.co/papers/2403.04706
opinion: placeholder
summary: A language model with common pre-training already has strong mathematical
  abilities, but its reliability in generating correct answers needs to be improved.
  Scaling up the synthetic data can significantly enhance its reliability, as it proves
  to be nearly as effective as real data and shows no clear saturation when scaled
  up to approximately one million samples....
tags:
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/eSnCEMNFcNuj00GmG8yur.png
title: Common 7B Language Models Already Possess Strong Math Capabilities
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.04706/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.04706/paper.ko.html
