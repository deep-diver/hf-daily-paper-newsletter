date: "2025-08-04"
author: Amitava Das
title: 'TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to   Training-Time Belief Sources in LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2508.02063
summary: The study presents a framework called TraceAlign to identify and mitigate alignment failures in language models, which occur when the models generate unsafe or policy-violating completions. The framework uses a Belief Conflict Index to trace these failures back to their root causes in the model's training data and proposes three interventions to reduce alignment drift, improving safety and preserving utility....
opinion: placeholder
tags:
    - ML
