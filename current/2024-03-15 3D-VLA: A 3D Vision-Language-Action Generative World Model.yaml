date: "2024-03-15"
author: Haoyu Zhen
title: '3D-VLA: A 3D Vision-Language-Action Generative World Model'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09631.png
link: https://huggingface.co/papers/2403.09631
summary: The paper proposes 3D-VLA, a generative world model for seamless integration of 3D perception, reasoning, and action. It uses a 3D-based large language model and interaction tokens to engage with the environment, and trains a series of embodied diffusion models for multimodal generation. The model is trained on a large-scale 3D embodied instruction dataset and significantly improves reasoning and planning capabilities in embodied environments....
opinion: placeholder
tags:
    - Supervised Learning
    - Unsupervised Learning
    - Reinforcement Learning
    - Deep Learning
    - Natural Language Processing
    - Computer Vision
    - Robotics and Control
