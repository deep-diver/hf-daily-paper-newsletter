date: "2024-02-28"
author: Linrui Tian
title: 'EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Jpuu71oibjBK1VrDwppG5.png
link: https://huggingface.co/papers/2402.17485
summary: A new method called EMO is proposed to generate more realistic and expressive talking head videos by directly synthesizing videos from audio, bypassing the need for intermediate 3D models or facial landmarks. EMO is able to produce highly expressive and lifelike animations, even for singing videos in various styles, and outperforms existing state-of-the-art methodologies....
opinion: placeholder
tags:
    - Deep Learning
    - Computer Vision
    - Speech Recognition and Synthesis
    - Natural Language Processing
    - Emerging Applications of Machine Learning
