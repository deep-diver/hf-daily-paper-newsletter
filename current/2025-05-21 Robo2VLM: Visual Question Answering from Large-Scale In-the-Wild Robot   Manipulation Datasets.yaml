date: "2025-05-21"
author: Kaiyuan Chen
title: 'Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot   Manipulation Datasets'
thumbnail: ""
link: https://huggingface.co/papers/2505.15517
summary: The researchers created a framework called Robo2VLM that uses robot trajectory data to generate questions and answers for visual understanding tasks, resulting in a large dataset of 684,710 questions. This dataset helps evaluate and enhance the spatial and interaction reasoning abilities of vision-language models....
opinion: placeholder
tags:
    - ML
