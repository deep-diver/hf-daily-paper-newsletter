date: "2024-12-12"
author: Jitesh Jain
title: 'OLA-VLM: Elevating Visual Perception in Multimodal LLMs with Auxiliary Embedding Distillation'
thumbnail: ""
link: https://huggingface.co/papers/2412.09585
summary: The paper proposes OLA-VLM, a method for improving the visual understanding ability of multimodal large language models (LLMs) by distilling knowledge from a set of target visual representations. OLA-VLM outperforms single and multi-encoder baselines, resulting in an average improvement of up to 2.5% on various benchmarks, with a notable improvement of 8.7% on the Depth task in CV-Bench. The code is open-sourced at <https://github.com/SHI-Labs/OLA-VLM>....
opinion: placeholder
tags:
    - ML
