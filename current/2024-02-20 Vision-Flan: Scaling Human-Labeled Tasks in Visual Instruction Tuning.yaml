author: Zhiyang Xu
date: '2024-02-20'
link: https://huggingface.co/papers/2402.11690
opinion: placeholder
summary: This paper proposes Vision-Flan, a diverse dataset of 187 tasks and 1.6 million
  instances for visual instruction tuning of vision-language models, and a two-stage
  tuning framework that outperforms traditional methods and achieves state-of-the-art
  performance. The findings suggest that GPT-4 synthesized data modulates model responses,
  a minimal quantity can align responses with human preference, and instruction tuning
  helps large-language models understand visual features....
tags:
- ML
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/JYvyHYXHmY7pVf71xYjsU.png
title: 'Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.11690/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.11690/paper.ko.html
