date: "2025-02-24"
author: Junhyeok Kim
title: 'EgoSpeak: Learning When to Speak for Egocentric Conversational Agents in the Wild'
thumbnail: ""
link: https://huggingface.co/papers/2502.14892
summary: The paper presents EgoSpeak, a new approach for conversational agents to predict when to start talking in real-world scenarios. EgoSpeak uses a first-person perspective, processes colors (RGB), handles untrimmed videos in real-time, and utilizes a large dataset (YT-Conversation) for pretraining. This method improves speech initiation prediction compared to baselines in experiments on EasyCom and Ego4D....
opinion: placeholder
tags:
    - ML
