date: "2025-03-06"
author: Shimao Zhang
title: Process-based Self-Rewarding Language Models
thumbnail: ""
link: https://huggingface.co/papers/2503.03746
summary: Current self-rewarding methods for Large Language Models (LLMs) don't work well in mathematical reasoning and can even decrease performance. A new Process-based Self-Rewarding pipeline is proposed, which includes long-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference optimization, and it enhances LLMs' performance on multiple mathematical reasoning benchmarks through iterative Process-based Self-Rewarding....
opinion: placeholder
tags:
    - ML
