date: "2025-10-15"
author: Beomseok Kang
title: 'LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning'
thumbnail: ""
link: https://huggingface.co/papers/2510.14211
summary: The authors present a framework called LiteStage to improve the efficiency of multi-stage reasoning in language models without sacrificing too much accuracy. They tackle the challenges of varying layer sensitivity and redundant output generation by optimizing layer budgets offline and using an early exit strategy online, resulting in significant speedup and minimal accuracy loss on various benchmarks....
opinion: placeholder
tags:
    - ML
