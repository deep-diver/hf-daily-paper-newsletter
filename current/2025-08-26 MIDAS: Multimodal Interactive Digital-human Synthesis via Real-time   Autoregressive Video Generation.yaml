date: "2025-08-26"
author: Ming Chen
title: 'MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time   Autoregressive Video Generation'
thumbnail: ""
link: https://huggingface.co/papers/2508.19320
summary: The authors present a new framework for creating interactive digital humans that can respond to various input signals in real-time with low latency and high efficiency. They use a large language model and a large-scale dialogue dataset to train their system, which can accept multimodal condition encodings like audio, pose, and text, and generate coherent representations to guide the denoising process of a diffusion head....
opinion: placeholder
tags:
    - ML
