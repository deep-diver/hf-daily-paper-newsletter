author: Koichi Namekata
date: '2024-01-23'
link: https://huggingface.co/papers/2401.11739
opinion: placeholder
summary: The paper proposes EmerDiff, a framework to extract fine-grained semantic
  knowledge from pre-trained diffusion models without additional training. The framework
  utilizes the semantic correspondences between image pixels and spatial locations
  of low-dimensional feature maps to construct image-resolution segmentation maps.
  In experiments, the generated segmentation maps demonstrate well-delineated and
  detailed parts, indicating the existence of accurate pixel-level semantic knowledge
  in diffusion ...
tags:
- Deep Learning
- Computer Vision
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/xyrEB9_HYQv8Rd2MkFtie.jpeg
title: 'EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.11739/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.11739/paper.ko.html
