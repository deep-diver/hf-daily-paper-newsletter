date: "2025-11-24"
author: Yiming Qin
title: 'Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens'
thumbnail: ""
link: https://huggingface.co/papers/2511.19418
summary: The study presents a framework called Chain-of-Visual-Thought that enhances Vision-Language Models by incorporating continuous visual tokens, which help the models better understand visual information like spatial reasoning and geometry. This approach improves the models' performance on various perception benchmarks by 3% to 16% without sacrificing efficiency, making it more grounded and interpretable....
opinion: placeholder
tags:
    - ML
