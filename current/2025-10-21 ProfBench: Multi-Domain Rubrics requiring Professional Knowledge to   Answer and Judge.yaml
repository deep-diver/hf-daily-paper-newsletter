date: "2025-10-21"
author: Zhilin Wang
title: 'ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to   Answer and Judge'
thumbnail: ""
link: https://huggingface.co/papers/2510.18941
summary: The study presents ProfBench, a new benchmark for evaluating large language models in professional domains like Physics, Chemistry, Finance, and Consulting, using over 7000 response-criterion pairs evaluated by human experts. The benchmark reveals that even top-performing models struggle with these tasks, and it provides insights into the performance of proprietary and open-weight models, as well as the importance of extended thinking in complex professional-domain tasks....
opinion: placeholder
tags:
    - ML
