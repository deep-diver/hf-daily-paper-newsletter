date: "2025-12-07"
author: Yuchuan Tian
title: 'From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2512.06776
summary: The authors propose a method to improve the efficiency of language models by transitioning from sequential to parallel generation, which allows for faster and more efficient text generation. This approach enables the use of existing language model knowledge and achieves state-of-the-art performance in various tasks without the need for costly training from scratch....
opinion: placeholder
tags:
    - ML
