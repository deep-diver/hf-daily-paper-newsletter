date: "2025-12-23"
author: Ying Zhu
title: 'DiRL: An Efficient Post-Training Framework for Diffusion Language Models'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.22234.png
link: https://huggingface.co/papers/2512.22234
summary: Diffusion Language Models struggle with learning after their initial setup, especially for tough tasks like math, because current methods are slow and don't align well with how they're actually used. A new system called DiRL was developed to make this post-training process much faster and more effective, leading to top-tier math performance for these models, even outperforming some established competitors....
opinion: placeholder
tags:
    - Diffusion Language Models
    - Post-Training Optimization
poster_path: https://raw.githubusercontent.com/deep-diver/hf-daily-paper-newsletter/main/posters/poster_2512.22234_landscape_english_nopanel.png
