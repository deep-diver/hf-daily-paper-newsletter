date: "2024-04-01"
author: Niklas Stoehr
title: Localizing Paragraph Memorization in Language Models
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.19851.png
link: https://huggingface.co/papers/2403.19851
summary: This paper explores how language models memorize and recite entire paragraphs of their training data. They find that memorization is spread across multiple layers and components, but have a distinguishable pattern of larger gradients in lower layers. They also identify a low-layer attention head that is involved in memorization, focusing on rare tokens. Additionally, they show that memorized continuations are harder to corrupt than non-memorized ones....
opinion: placeholder
tags:
    - Natural Language Processing
    - Deep Learning
