author: Victor Carbune
date: '2024-03-20'
link: https://huggingface.co/papers/2403.12596
opinion: placeholder
summary: A new technique is proposed to transfer reasoning capabilities from large-language
  models to vision-language models, resulting in state-of-the-art performance on multimodal
  tasks such as ChartQA. This is achieved by improving chart representation, constructing
  a larger dataset, and fine-tuning with a multitask loss. The resulting model outperforms
  even larger models without using an upstream OCR system and keeps inference time
  constant....
tags:
- Supervised Learning
- Transfer Learning
- Computer Vision
- Natural Language Processing
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.12596.png
title: 'Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.12596/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.12596/paper.ko.html
