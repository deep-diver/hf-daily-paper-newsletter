author: Chong Zeng
date: '2024-02-20'
link: https://huggingface.co/papers/2402.11929
opinion: placeholder
summary: 'This method allows for fine-grained control over lighting during text-driven
  image generation by using radiance hints and a refined diffusion model called DiLightNet.
  It involves three stages: generating a provisional image, refining the foreground
  object with the target lighting, and resynthesizing the background to match the
  lighting on the foreground....'
tags:
- Deep Learning
- Computer Vision
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/aRiZlwe4dVmAAyASQ947y.png
title: 'DiLightNet: Fine-grained Lighting Control for Diffusion-based Image Generation'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.11929/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.11929/paper.ko.html
