date: "2025-09-30"
author: Junlin Han
title: 'Learning to See Before Seeing: Demystifying LLM Visual Priors from   Language Pre-training'
thumbnail: ""
link: https://huggingface.co/papers/2509.26625
summary: 'The study explores how Large Language Models (LLMs) acquire visual knowledge from text alone, identifying two types of visual priors: perception and reasoning. The research reveals that reasoning ability is primarily developed through pre-training on reasoning-centric data, while perception ability is more sensitive to the vision encoder and visual instruction tuning data. The findings offer a data-centric recipe for pre-training vision-aware LLMs and introduce the Multi-Level Existence Bench (M...'
opinion: placeholder
tags:
    - ML
