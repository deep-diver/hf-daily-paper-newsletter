date: "2024-03-08"
author: Boshi Wang
title: 'LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/EtQghz4H4sfuzrxYPinsL.png
link: https://huggingface.co/papers/2403.04746
summary: This paper proposes a new method called simulated trial and error (STE) to improve tool use accuracy for large language models (LLMs). STE uses the LLM's imagination to simulate scenarios, memory to improve exploration, and trial and error to learn from feedback. Experiments show that STE improves tool learning for LLMs and outperforms GPT-4....
opinion: placeholder
tags:
    - Supervised Learning
    - Natural Language Processing
    - Deep Learning
