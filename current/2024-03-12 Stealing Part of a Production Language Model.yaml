date: "2024-03-12"
author: Nicholas Carlini
title: Stealing Part of a Production Language Model
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/dhiUnxDGTRatavk4pKf9h.png
link: https://huggingface.co/papers/2403.06634
summary: The paper presents a new attack method that can extract precise information from black-box production language models like OpenAI's ChatGPT or Google's PaLM-2, specifically, the embedding projection layer of a transformer model. The attack is able to recover the entire projection matrix of language models like OpenAI's Ada and Babbage, and estimate the cost to recover the entire projection matrix for other models, such as gpt-3.5-turbo....
opinion: placeholder
tags:
    - Natural Language Processing
