date: "2024-01-17"
author: Alisa Liu
title: Tuning Language Models by Proxy
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/6FYDePLkNlKGpx8IsD-Ju.png
link: https://huggingface.co/papers/2401.08565
summary: The paper introduces proxy-tuning, a lightweight decoding-time algorithm that operates on top of black-box language models to achieve the result of directly tuning the model, but without accessing its internal weights. It instead tunes a smaller LM, then applies the difference between the predictions of the small tuned and untuned LMs to shift the original predictions of the base model in the direction of tuning. The method can close 88% of the gap between a large LM and its truly-tuned version,...
opinion: placeholder
tags:
    - Supervised Learning
    - Deep Learning
    - Natural Language Processing
