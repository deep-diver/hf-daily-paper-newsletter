date: "2024-04-24"
author: Yuhong Li
title: 'SnapKV: LLM Knows What You are Looking for Before Generation'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.14469.png
link: https://huggingface.co/papers/2404.14469
summary: This paper presents SnapKV, an approach that efficiently minimizes the size of the Key-Value cache in Large Language Models while maintaining comparable performance. SnapKV clusters important KV positions for each attention head, reducing computational overhead and memory footprint, and enabling processing of up to 380K context tokens on a single GPU with negligible accuracy drop....
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
