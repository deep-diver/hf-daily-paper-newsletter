date: "2025-05-28"
author: Chengyue Wu
title: 'Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV   Cache and Parallel Decoding'
thumbnail: ""
link: https://huggingface.co/papers/2505.22618
summary: This study presents a new method to speed up diffusion language models (Diffusion LLMs) by implementing a Key-Value cache and a parallel decoding strategy. The proposed techniques significantly improve the inference speed of Diffusion LLMs, making them competitive with traditional language models, without sacrificing much accuracy....
opinion: placeholder
tags:
    - ML
