date: "2024-05-21"
author: Ting Jiang
title: 'MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.12130.png
link: https://huggingface.co/papers/2405.12130
summary: MoRA is a new method for fine-tuning large language models that uses a square matrix for high-rank updating, which allows for better learning and memorization of new knowledge compared to low-rank updating. It maintains the same number of trainable parameters as LoRA and can be deployed in a similar way. MoRA outperforms LoRA on memory-intensive tasks and performs comparably on others....
opinion: placeholder
tags:
    - Supervised Learning
    - Natural Language Processing
