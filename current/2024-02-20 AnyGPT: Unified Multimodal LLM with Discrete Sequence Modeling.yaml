date: "2024-02-20"
author: Jun Zhan
title: 'AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/91qtWOTzD4TxxP1jvGIQG.png
link: https://huggingface.co/papers/2402.12226
summary: This paper presents AnyGPT, a multimodal language model that can process various modalities like speech, text, images, and music using discrete representations. AnyGPT can be easily integrated into existing language models and performs well in any-to-any multimodal conversations, as demonstrated in experiments. Demos are available at <https://junzhan2000.github.io/AnyGPT.github.io/>....
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
    - Computer Vision
    - Speech Recognition and Synthesis
