date: "2025-09-26"
author: Xu Wujiang
title: 'EPO: Entropy-regularized Policy Optimization for LLM Agents   Reinforcement Learning'
thumbnail: ""
link: https://huggingface.co/papers/2509.22576
summary: The study addresses the challenge of training language model (LLM) agents in environments with sparse rewards and multiple turns, identifying a failure mode called the 'exploration-exploitation cascade failure'. The proposed solution, Entropy-regularized Policy Optimization (EPO), improves performance by up to 152% in ScienceWorld and 19.8% in ALFWorld, through enhanced exploration, entropy smoothing, and adaptive phase-based weighting....
opinion: placeholder
tags:
    - ML
