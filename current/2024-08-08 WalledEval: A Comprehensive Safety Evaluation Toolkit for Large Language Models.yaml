date: "2024-08-08"
author: Prannaya Gupta
title: 'WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2408.03837
summary: WalledEval is a tool that checks if large language models are safe. It has over 35 tests and can check different types of models. It also has a new tool called WalledGuard and a test called SGXSTest. It's available online at https://github.com/walledai/walledeval....
opinion: placeholder
tags:
    - ML
