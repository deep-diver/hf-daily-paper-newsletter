date: "2024-10-17"
author: Jingyu Zhang
title: 'Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements'
thumbnail: ""
link: https://huggingface.co/papers/2410.08968
summary: Our paper introduces CoSA, a framework for adapting language models to diverse safety requirements by aligning them to safety configs provided as part of the system prompt. This allows users to modify safety configs at inference time without re-training the model. We also propose CoSAlign, a data-centric method for aligning models to safety configs, and devise a new controllability evaluation protocol. Our approach leads to substantial gains in controllability over strong baselines and promotes ...
opinion: placeholder
tags:
    - ML
