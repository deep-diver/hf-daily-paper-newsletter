date: "2024-02-14"
author: Aishwarya P S
title: Tandem Transformers for Inference Efficient LLMs
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/glpMhmDzAmkJW7PVteCjx.png
link: https://huggingface.co/papers/2402.08644
summary: 'The autoregressive nature of conventional large language models (LLMs) inherently limits inference speed, as tokens are generated sequentially. While speculative and parallel decoding techniques attempt to mitigate this, they face limitations: either relying on less accurate smaller models for generation or failing to fully leverage the base LLM''s representations.   We introduce a novel architecture, Tandem transformers, to address these issues. This architecture uniquely combines (1) a small au...'
opinion: placeholder
tags:
    - Deep Learning
