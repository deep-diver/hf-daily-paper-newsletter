date: "2025-12-06"
author: Xiaojun Jia
title: 'OmniSafeBench-MM: A Unified Benchmark and Toolbox for Multimodal Jailbreak Attack-Defense Evaluation'
thumbnail: ""
link: https://huggingface.co/papers/2512.06589
summary: The researchers created a comprehensive toolbox called OmniSafeBench-MM to evaluate the security of multimodal language models. This toolbox includes various attack methods, defense strategies, and a diverse dataset to test the models' vulnerability to jailbreak attacks, providing a standardized foundation for future research in this area....
opinion: placeholder
tags:
    - ML
