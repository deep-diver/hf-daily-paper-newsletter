author: Tianle Cai
date: '2024-01-22'
link: https://huggingface.co/papers/2401.10774
opinion: placeholder
summary: Medusa is a method that augments LLM inference by adding extra decoding heads
  to predict multiple subsequent tokens in parallel. Using a tree-based attention
  mechanism, Medusa constructs multiple candidate continuations and verifies them
  simultaneously in each decoding step, reducing the number of decoding steps required.
  Medusa-1 and Medusa-2 are fine-tuning procedures, and several extensions are proposed
  to improve or expand its utility. The method can achieve over 2.2x speedup without
  comprom...
tags:
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/gxvTu6T6sN1X8MJshLwux.gif
title: 'Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding
  Heads'
translated_paths:
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.10774/paper.ko.html
