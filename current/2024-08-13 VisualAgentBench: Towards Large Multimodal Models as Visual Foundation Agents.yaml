date: "2024-08-13"
author: Xiao Liu
title: 'VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents'
thumbnail: ""
link: https://huggingface.co/papers/2408.06327
summary: VisualAgentBench (VAB) is a benchmark designed to test how well Large Multimodal Models (LMMs) can understand and interact with different types of visual tasks. It includes tasks like Embodied, Graphical User Interface, and Visual Design, and it uses real-world scenarios to challenge these models. The benchmark also provides a way to train and improve LMMs by using a combination of computer programs, models, and human examples. The creators of this benchmark want to help make LMMs better at unde...
opinion: placeholder
tags:
    - ML
