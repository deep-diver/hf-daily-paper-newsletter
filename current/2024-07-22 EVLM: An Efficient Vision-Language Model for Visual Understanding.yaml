date: "2024-07-22"
author: Kaibing Chen
title: 'EVLM: An Efficient Vision-Language Model for Visual Understanding'
thumbnail: ""
link: https://huggingface.co/papers/2407.14177
summary: This paper proposes an efficient multi-modal language model that minimizes computational costs while enabling the model to perceive visual signals as comprehensively as possible. The model uses cross-attention for image-text interaction, hierarchical ViT features, and the Mixture of Experts mechanism to enhance effectiveness. It performs well in tasks like image captioning and video captioning....
opinion: placeholder
tags:
    - ML
