author: Lihe Yang
date: '2024-01-22'
link: https://huggingface.co/papers/2401.10891
opinion: placeholder
summary: 'This paper presents Depth Anything, a monocular depth estimation technique
  that utilizes large-scale unlabeled data to create a simple yet powerful foundation
  model. The dataset was enlarged by designing a data engine to collect and annotate
  ~62M images. Two strategies to make data scaling-up promising were employed: a more
  challenging optimization target and an auxiliary supervision to enforce the model
  to inherit rich semantic priors. Extensive evaluations show impressive generalization
  abilit...'
tags:
- Supervised Learning
- Unsupervised Learning
- Deep Learning
- Computer Vision
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/xnuiMMUgeI_CHzmmNwR8x.png
title: 'Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data'
translated_paths:
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.10891/paper.ko.html
