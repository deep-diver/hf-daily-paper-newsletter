author: Brandon McKinzie
date: '2024-03-15'
link: https://huggingface.co/papers/2403.09611
opinion: placeholder
summary: This paper discusses the importance of various architecture components and
  data choices in building performant Multimodal Large Language Models (MLLMs). Through
  careful ablations, crucial design lessons were identified, such as the importance
  of using a mix of image-caption, interleaved image-text, and text-only data for
  large-scale multimodal pre-training. The paper also presents MM1, a family of multimodal
  models up to 30B parameters that achieve state-of-the-art pre-training metrics and
  compe...
tags:
- Supervised Learning
- Unsupervised Learning
- Deep Learning
- Natural Language Processing
- Computer Vision
- Optimization and Decision Making
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09611.png
title: 'MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.09611/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.09611/paper.ko.html
