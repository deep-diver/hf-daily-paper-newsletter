date: "2025-11-20"
author: Yijun Yang
title: 'Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2511.16110
summary: This study presents a framework called Multi-Faceted Attack (MFA) that uncovers vulnerabilities in popular vision-language models like GPT-4o, Gemini-Pro, and Llama-4. MFA uses a method called Attention-Transfer Attack to hide harmful instructions, which successfully bypasses defense mechanisms and demonstrates a 58.5% success rate, outperforming existing methods and challenging the robustness of current defense mechanisms....
opinion: placeholder
tags:
    - ML
