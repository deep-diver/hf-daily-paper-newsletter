date: "2024-02-26"
author: Mart van Baalen
title: 'GPTVQ: The Blessing of Dimensionality for LLM Quantization'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/TD0kC_hrvKDrbzKZlz1RH.png
link: https://huggingface.co/papers/2402.15319
summary: A new method called GPTVQ is introduced, which increases the dimensionality of neural network quantization to improve the size versus accuracy trade-off. GPTVQ is a fast method for post-training vector quantization that works well with Large Language Models, setting a new state-of-the-art in the size vs accuracy trade-offs while being efficient and improving latency compared to using a 4-bit integer format....
opinion: placeholder
tags:
    - Supervised Learning
    - Deep Learning
    - Natural Language Processing
