date: "2024-12-02"
author: Justin Chih-Yao Chen
title: Reverse Thinking Makes LLMs Stronger Reasoners
thumbnail: ""
link: https://huggingface.co/papers/2411.19865
summary: RevThink is a framework that enhances Large Language Models' reasoning skills by enabling them to think in reverse, making them stronger reasoners. It uses data augmentation and learning objectives to improve performance by 13.53% on average and shows sample efficiency, outperforming standard fine-tuning methods with less data. It also generalizes well to new, unseen datasets....
opinion: placeholder
tags:
    - ML
