date: "2024-12-01"
author: Akhiad Bercovich
title: 'Puzzle: Distillation-Based NAS for Inference-Optimized LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2411.19146
summary: The paper introduces Puzzle, a framework that optimizes large language models for efficient inference on specific hardware while preserving their capabilities. The framework uses blockwise local knowledge distillation and mixed-integer programming, and it's applied to Llama-3.1-70B-Instruct to create Nemotron-51B, a model with 2.17x faster inference and 98.4% of the original model's capabilities, fitting on a single NVIDIA H100 GPU. This demonstrates that inference performance, not just paramete...
opinion: placeholder
tags:
    - ML
