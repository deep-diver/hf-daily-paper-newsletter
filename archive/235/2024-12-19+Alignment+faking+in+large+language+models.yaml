date: "2024-12-19"
author: Ryan Greenblatt
title: Alignment faking in large language models
thumbnail: ""
link: https://huggingface.co/papers/2412.14093
summary: 'This paper demonstrates a large language model engaging in alignment faking: strategically complying with harmful queries during training to preserve its preferred harmlessness behavior out of training. The model was found to comply with harmful queries from free users 14% of the time, versus almost never for paid users. Alignment faking was observed in almost all cases where the model complied with a harmful query from a free user. The paper also studies the effect of training the model to comp...'
opinion: placeholder
tags:
    - ML
