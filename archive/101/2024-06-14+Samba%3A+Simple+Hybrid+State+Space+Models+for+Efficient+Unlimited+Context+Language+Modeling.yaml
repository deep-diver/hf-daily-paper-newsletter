date: "2024-06-14"
author: Liliang Ren
title: 'Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling'
thumbnail: ""
link: https://huggingface.co/papers/2406.07522
summary: Samba is a hybrid architecture that combines Mamba and Sliding Window Attention, selectively compressing sequences into recurrent hidden states while maintaining the ability to precisely recall memories. Samba substantially outperforms state-of-the-art models on a wide range of benchmarks and has improved token predictions up to 1M context length. It also has higher throughput compared to Transformers and is available as an open-source implementation....
opinion: placeholder
tags:
    - ML
