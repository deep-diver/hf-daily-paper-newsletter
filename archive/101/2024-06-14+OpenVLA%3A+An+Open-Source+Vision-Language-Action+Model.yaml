date: "2024-06-14"
author: Moo Jin Kim
title: 'OpenVLA: An Open-Source Vision-Language-Action Model'
thumbnail: ""
link: https://huggingface.co/papers/2406.09246
summary: OpenVLA is an open-source vision-language-action model that outperforms closed models in generalist manipulation tasks and can be fine-tuned for new settings with strong generalization results. It is trained on a diverse collection of real-world robot demonstrations and can be fine-tuned on consumer GPUs using modern low-rank adaptation methods and served efficiently via quantization without a hit to downstream success rate....
opinion: placeholder
tags:
    - ML
