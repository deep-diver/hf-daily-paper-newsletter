date: "2025-12-17"
author: Yuanning Feng
title: Are We on the Right Way to Assessing LLM-as-a-Judge?
thumbnail: ""
link: https://huggingface.co/papers/2512.16041
summary: The authors present Sage, a new evaluation suite for LLM-as-a-Judge that doesn't require human annotation, addressing the bias and scalability issues of existing methods. Experiments show Sage's reliability and reveal consistency problems in current LLMs when acting as judges, suggesting potential improvements like finetuning and deep reasoning....
opinion: placeholder
tags:
    - ML
