date: "2024-02-19"
author: Moritz Stephan
title: 'RLVF: Learning from Verbal Feedback without Overgeneralization'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/sNQ7y9jsYQIdogVCENsVw.png
link: https://huggingface.co/papers/2402.10893
summary: The diversity of contexts in which large language models (LLMs) are deployed requires the ability to modify or customize default model behaviors to incorporate nuanced requirements and preferences. A convenient interface to specify such model adjustments is high-level verbal feedback, such as "Don't use emojis when drafting emails to my boss." However, while writing high-level feedback is far simpler than collecting annotations for reinforcement learning from human feedback (RLHF), we find that ...
opinion: placeholder
tags:
    - Reinforcement Learning
    - Natural Language Processing
