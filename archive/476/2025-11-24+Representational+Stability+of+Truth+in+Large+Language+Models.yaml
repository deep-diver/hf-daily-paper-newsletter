date: "2025-11-24"
author: Samantha Dies
title: Representational Stability of Truth in Large Language Models
thumbnail: ""
link: https://huggingface.co/papers/2511.19166
summary: The study examines how well large language models (LLMs) distinguish between true, false, and neither-true-nor-false content, focusing on the impact of familiarity and linguistic form on this ability. Results indicate that LLMs struggle more with unfamiliar statements, leading to significant shifts in truth judgments, while familiar fictional statements are more consistently categorized, suggesting that representational stability in LLMs is influenced more by epistemic familiarity than linguisti...
opinion: placeholder
tags:
    - ML
