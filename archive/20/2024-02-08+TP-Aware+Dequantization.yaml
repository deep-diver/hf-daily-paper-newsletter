date: "2024-02-08"
author: Adnan Hoque
title: TP-Aware Dequantization
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Ct1sF8cpW7EsZfHb-4OFd.png
link: https://huggingface.co/papers/2402.04925
summary: This paper presents a novel method that reduces model inference latency during distributed deployment of Large Language Models by optimizing the inference deployment scheme and leveraging prior knowledge of Tensor Parallel to reduce global communication, demonstrating a significant speedup over existing methods on various LLMs and GPU systems....
opinion: placeholder
tags:
    - Optimization and Learning Algorithms
    - Deep Learning
    - Natural Language Processing
