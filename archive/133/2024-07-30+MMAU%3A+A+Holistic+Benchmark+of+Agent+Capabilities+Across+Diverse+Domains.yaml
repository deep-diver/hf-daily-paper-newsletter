date: "2024-07-30"
author: Guoli Yin
title: 'MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains'
thumbnail: ""
link: https://huggingface.co/papers/2407.18961
summary: MMAU is a comprehensive benchmark for evaluating the capabilities of large language models as human-like agents. It consists of 20 tasks across five domains and five essential capabilities, providing a detailed analysis of model performance. Datasets and evaluation scripts are available at https://github.com/apple/axlearn/docs/research/mmau....
opinion: placeholder
tags:
    - ML
