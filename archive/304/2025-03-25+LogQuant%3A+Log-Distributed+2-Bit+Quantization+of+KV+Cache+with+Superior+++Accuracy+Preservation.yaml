date: "2025-03-25"
author: Han Chen
title: 'LogQuant: Log-Distributed 2-Bit Quantization of KV Cache with Superior   Accuracy Preservation'
thumbnail: ""
link: https://huggingface.co/papers/2503.19950
summary: LogQuant is a new method that compresses the KV Cache for large language models, improving performance and memory usage. It works by selectively filtering the cache using a log-based mechanism, outperforming other techniques in accuracy and efficiency, and can be easily added to popular inference frameworks....
opinion: placeholder
tags:
    - ML
