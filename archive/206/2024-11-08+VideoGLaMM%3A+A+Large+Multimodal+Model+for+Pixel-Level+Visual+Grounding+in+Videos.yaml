date: "2024-11-08"
author: Shehan Munasinghe
title: 'VideoGLaMM: A Large Multimodal Model for Pixel-Level Visual Grounding in Videos'
thumbnail: ""
link: https://huggingface.co/papers/2411.04923
summary: VideoGLaMM is a model that can accurately ground textual descriptions to specific pixels in videos by connecting a language model, a vision encoder, and a spatio-temporal decoder. It outperforms other models in tasks like generating conversations, visual grounding, and referring to video segments....
opinion: placeholder
tags:
    - ML
