author: Boxiao Pan
date: '2024-01-22'
link: https://huggingface.co/papers/2401.10822
opinion: placeholder
summary: ActAnywhere is a generative model that automates the process of generating
  video backgrounds that tailor to foreground subject motion for the movie industry
  and visual effects community. It uses large-scale video diffusion models and is
  specifically tailored for this task. It takes a sequence of foreground subject segmentation
  as input and an image that describes the desired scene as condition, producing a
  coherent video with realistic foreground-background interactions while adhering
  to the con...
tags:
- Deep Learning
- Computer Vision
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/vt5f7ZwiqPRMUqh4-IiGF.png
title: 'ActAnywhere: Subject-Aware Video Background Generation'
translated_paths:
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.10822/paper.ko.html
