author: Zhenyu Wang
date: '2024-01-30'
link: https://huggingface.co/papers/2401.15688
opinion: placeholder
summary: This paper proposes CompAgent, a training-free method using a large language
  model to decompose complex text prompts for text-to-image generation. The agent
  then plans and uses tools to compose these objects, and incorporates human feedback
  for refinement. CompAgent significantly improves compositional text-to-image generation
  and has flexible applications....
tags:
- Supervised Learning
- Natural Language Processing
- Computer Vision
- Deep Learning
thumbnail: https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/assets/2401.15688.gif?raw=true
title: 'Divide and Conquer: Language Models can Plan and Self-Correct for Compositional
  Text-to-Image Generation'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.15688/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.15688/paper.ko.html
