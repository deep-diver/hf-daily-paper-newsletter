date: "2025-03-11"
author: Parishad BehnamGhader
title: Exploiting Instruction-Following Retrievers for Malicious Information   Retrieval
thumbnail: ""
link: https://huggingface.co/papers/2503.08644
summary: This study investigates the safety risks of using instruction-following retrievers alongside Large Language Models (LLMs) for search capabilities. The researchers found that most retrievers, such as NV-Embed and LLM2Vec, can provide relevant harmful passages when given malicious queries, and even safety-aligned LLMs can satisfy malicious requests provided with harmful retrieved passages in-context....
opinion: placeholder
tags:
    - ML
