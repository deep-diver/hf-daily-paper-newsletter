date: "2025-02-28"
author: Chenghua Huang
title: 'Lean and Mean: Decoupled Value Policy Optimization with Global Value Guidance'
thumbnail: ""
link: https://huggingface.co/papers/2502.16944
summary: The paper proposes a new framework, Decoupled Value Policy Optimization (DVPO), for aligning large language models (LLMs) with human preferences using Reinforcement Learning from Human Feedback (RLHF). By replacing the traditional reward modeling with a pretrained global value model (GVM) and decoupling it from policy training, DVPO reduces computational complexity and instability, and improves GPU memory usage and training time compared to conventional RLHF....
opinion: placeholder
tags:
    - ML
