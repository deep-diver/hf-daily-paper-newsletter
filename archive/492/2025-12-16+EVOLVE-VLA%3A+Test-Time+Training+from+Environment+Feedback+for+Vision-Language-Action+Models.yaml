date: "2025-12-16"
author: Zechen Bai
title: 'EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models'
thumbnail: ""
link: https://huggingface.co/papers/2512.14666
summary: The study presents EVOLVE-VLA, a new framework that allows Vision-Language-Action models to adapt in real-time through environment interaction, without relying on many demonstrations. This framework improves performance on long-horizon tasks, one-shot learning, and cross-task generalization, and enables the models to recover from errors and develop new strategies....
opinion: placeholder
tags:
    - ML
