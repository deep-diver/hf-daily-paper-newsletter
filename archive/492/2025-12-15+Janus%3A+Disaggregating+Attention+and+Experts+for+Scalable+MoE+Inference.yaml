date: "2025-12-15"
author: Zhexiang Zhang
title: 'Janus: Disaggregating Attention and Experts for Scalable MoE Inference'
thumbnail: ""
link: https://huggingface.co/papers/2512.13525
summary: The authors present a new system called Janus that improves the efficiency of large Mixture-of-Experts models during inference by separating and managing attention and expert modules independently on different GPU clusters. Janus uses an adaptive communication scheme, a lightweight scheduler, and fine-grained resource management to reduce latency and increase throughput, outperforming existing systems by up to 3.9 times in per-GPU throughput....
opinion: placeholder
tags:
    - ML
