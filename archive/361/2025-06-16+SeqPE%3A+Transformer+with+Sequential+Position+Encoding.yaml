date: "2025-06-16"
author: Huyang Li
title: 'SeqPE: Transformer with Sequential Position Encoding'
thumbnail: ""
link: https://huggingface.co/papers/2506.13277
summary: The authors propose SeqPE, a new position encoding framework for Transformers that overcomes the limitations of traditional learnable position embeddings. SeqPE represents positions as sequences and uses a sequential position encoder to learn embeddings, improving extrapolation capabilities and adaptability to new modalities. Experiments show that SeqPE outperforms baselines in language modeling, question answering, and image classification, and can handle multi-dimensional inputs without archit...
opinion: placeholder
tags:
    - ML
