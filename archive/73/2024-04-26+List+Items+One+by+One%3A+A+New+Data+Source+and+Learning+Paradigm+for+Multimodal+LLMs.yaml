date: "2024-04-26"
author: An Yan
title: 'List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.16375.png
link: https://huggingface.co/papers/2404.16375
summary: Set-of-Mark (SoM) Prompting unleashes the visual grounding capability of GPT-4V, by enabling the model to associate visual objects with tags inserted on the image. These tags, marked with alphanumerics, can be indexed via text tokens for easy reference. Despite the extraordinary performance from GPT-4V, we observe that other Multimodal Large Language Models (MLLMs) struggle to understand these visual tags. To promote the learning of SoM prompting for open-source models, we propose a new learning...
opinion: placeholder
tags:
    - Natural Language Processing
    - Deep Learning
    - Computer Vision
