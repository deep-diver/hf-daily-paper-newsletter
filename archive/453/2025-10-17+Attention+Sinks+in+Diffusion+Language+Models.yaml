date: "2025-10-17"
author: Maximo Eduardo Rulli
title: Attention Sinks in Diffusion Language Models
thumbnail: ""
link: https://huggingface.co/papers/2510.15731
summary: This study examines the attention patterns in Diffusion Language Models (DLMs) and discovers a phenomenon called 'attention sinking'. Unlike in traditional models, these attention sinks in DLMs change position dynamically during text generation and masking them has minimal impact on performance, providing new insights into their inner workings....
opinion: placeholder
tags:
    - ML
