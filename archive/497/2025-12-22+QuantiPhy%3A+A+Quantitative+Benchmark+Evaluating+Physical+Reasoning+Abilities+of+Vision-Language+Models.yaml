date: "2025-12-22"
author: Li Puyin
title: 'QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2512.19526
summary: The study presents QuantiPhy, a benchmark that measures the physical reasoning ability of vision-language models (VLMs) by estimating an object's size, velocity, and acceleration from video observations. The benchmark reveals that current VLMs struggle with numerical accuracy and rely more on pre-trained knowledge than the provided visual and textual inputs when reasoning about kinematic properties....
opinion: placeholder
tags:
    - ML
