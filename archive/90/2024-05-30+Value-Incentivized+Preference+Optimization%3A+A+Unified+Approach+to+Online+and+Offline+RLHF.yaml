date: "2024-05-30"
author: Shicong Cen
title: 'Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.19320.png
link: https://huggingface.co/papers/2405.19320
summary: This paper presents a unified approach called Value-Incentivized Preference Optimization (VPO) for online and offline RLHF, which incorporates uncertainty estimation in the reward function learned from preference data. VPO regularizes the maximum-likelihood estimate of the reward function with the corresponding value function, and provides theoretical guarantees for both online and offline settings. Experiments on text summarization and dialog demonstrate the practicality and effectiveness of VP...
opinion: placeholder
tags:
    - Supervised Learning
    - Reinforcement Learning
    - Deep Learning
    - Optimization and Learning Algorithms
    - Natural Language Processing
