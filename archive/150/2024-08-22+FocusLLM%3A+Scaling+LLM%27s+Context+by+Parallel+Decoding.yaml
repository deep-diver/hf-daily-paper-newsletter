date: "2024-08-22"
author: Zhenyu Li
title: 'FocusLLM: Scaling LLM''s Context by Parallel Decoding'
thumbnail: ""
link: https://huggingface.co/papers/2408.11745
summary: FocusLLM is a framework that enhances the context length of any decoder-only LLM by dividing long text inputs into chunks, extracting essential information from each chunk using a parallel decoding mechanism, and integrating the information into the local context. It is efficient to train and performs well on downstream long-context tasks, even with extensive long texts up to 400K tokens....
opinion: placeholder
tags:
    - ML
