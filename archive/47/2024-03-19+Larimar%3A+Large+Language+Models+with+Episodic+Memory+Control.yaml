author: Payel Das
date: '2024-03-19'
link: https://huggingface.co/papers/2403.11901
opinion: placeholder
summary: This paper introduces Larimar, a brain-inspired architecture for enhancing
  Large Language Models with a distributed episodic memory that allows for dynamic,
  one-shot updates of knowledge without the need for computationally expensive re-training
  or fine-tuning. Larimar is fast, flexible, and can achieve accuracy comparable to
  most competitive baselines while also providing mechanisms for selective fact forgetting
  and input context length generalization....
tags:
- Supervised Learning
- Deep Learning
- Natural Language Processing
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.11901.png
title: 'Larimar: Large Language Models with Episodic Memory Control'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.11901/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.11901/paper.ko.html
