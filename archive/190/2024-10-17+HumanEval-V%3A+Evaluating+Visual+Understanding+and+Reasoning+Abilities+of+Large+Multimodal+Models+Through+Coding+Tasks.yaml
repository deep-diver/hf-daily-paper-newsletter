date: "2024-10-17"
author: Fengji Zhang
title: 'HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks'
thumbnail: ""
link: https://huggingface.co/papers/2410.12381
summary: This paper introduces HumanEval-V, a benchmark for evaluating the visual understanding and reasoning abilities of large multimodal models through code generation tasks. The benchmark includes 108 Python coding tasks that require models to complete code solutions based on visual context and task requirements. The paper evaluates 19 state-of-the-art models and finds that they struggle with these tasks, highlighting the need for future research to improve model performance....
opinion: placeholder
tags:
    - ML
