date: "2025-01-08"
author: Haobo Yuan
title: 'Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos'
thumbnail: ""
link: https://huggingface.co/papers/2501.04001
summary: Sa2VA is a new model that can understand both images and videos by combining two other models, SAM-2 and LLaVA. It can do many different tasks with just a little bit of training, and it uses a special kind of language model to help it understand what's in the images and videos. The model also has a new dataset called Ref-SAV, which has over 72,000 object expressions in complex video scenes to help it learn better. Sa2VA is really good at understanding videos and can help with lots of different t...
opinion: placeholder
tags:
    - ML
