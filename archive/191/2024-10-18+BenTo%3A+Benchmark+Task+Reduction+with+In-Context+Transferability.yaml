date: "2024-10-18"
author: Hongyu Zhao
title: 'BenTo: Benchmark Task Reduction with In-Context Transferability'
thumbnail: ""
link: https://huggingface.co/papers/2410.13804
summary: This paper proposes a method to reduce the tasks used to benchmark large language models (LLMs) without affecting the evaluation quality. The method involves identifying the most representative subset of tasks using task transferability and relevance, and estimating the transferability between two tasks via in-context learning (ICL). The method can reduce tasks in a modern LLM benchmark to 5% while inducing only a <4% difference to the evaluation on the original benchmark, and is training-free, ...
opinion: placeholder
tags:
    - ML
