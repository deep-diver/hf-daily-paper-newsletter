date: "2025-05-30"
author: Longze Chen
title: 'CLaSp: In-Context Layer Skip for Self-Speculative Decoding'
thumbnail: ""
link: https://huggingface.co/papers/2505.24196
summary: The authors present CLaSp, a new method for speeding up the decoding process of Large Language Models without requiring additional training or modules. CLaSp works by skipping intermediate layers of the verify model, and it dynamically adjusts its layer-skipping strategy after each verification stage, resulting in a 1.3x to 1.7x speedup on LLaMA3 series models without changing the generated text distribution....
opinion: placeholder
tags:
    - ML
