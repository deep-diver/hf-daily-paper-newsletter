date: "2025-10-17"
author: Zhehao Zhang
title: 'Distractor Injection Attacks on Large Reasoning Models: Characterization   and Defense'
thumbnail: ""
link: https://huggingface.co/papers/2510.16259
summary: The study reveals a significant flaw in large reasoning models, where they can be misled by irrelevant tasks embedded in prompts, leading to a major drop in accuracy. The researchers propose a new training method combining supervised fine-tuning and reinforcement learning to enhance the models' resilience against such attacks....
opinion: placeholder
tags:
    - ML
