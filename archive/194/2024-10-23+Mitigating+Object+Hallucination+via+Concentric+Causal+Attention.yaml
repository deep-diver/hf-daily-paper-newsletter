date: "2024-10-23"
author: Yun Xing
title: Mitigating Object Hallucination via Concentric Causal Attention
thumbnail: ""
link: https://huggingface.co/papers/2410.15926
summary: A paper proposes a new method called Concentric Causal Attention (CCA) to mitigate object hallucination in large vision language models (LVLMs). This issue occurs when LVLMs generate text not factually aligned with image inputs. The paper suggests that this problem is related to the Rotary Position Encoding (RoPE) used in LVLMs, which causes long-term decay. CCA aims to reduce the relative distance between visual and instruction tokens to improve the model's perception capability and reduce obje...
opinion: placeholder
tags:
    - ML
