date: "2025-05-19"
author: Liyan Tang
title: 'ChartMuseum: Testing Visual Reasoning Capabilities of Large   Vision-Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2505.13444
summary: The study examines the performance of large vision-language models in understanding complex charts, revealing a significant gap between human and model capabilities. A new benchmark, ChartMuseum, is created to evaluate visual and textual reasoning in chart comprehension, showing that even the best models struggle with questions requiring primarily visual reasoning....
opinion: placeholder
tags:
    - ML
