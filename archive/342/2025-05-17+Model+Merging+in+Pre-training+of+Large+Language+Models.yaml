date: "2025-05-17"
author: Yunshui Li
title: Model Merging in Pre-training of Large Language Models
thumbnail: ""
link: https://huggingface.co/papers/2505.12082
summary: The study explores the benefits of merging checkpoints in large language models during pre-training, focusing on dense and Mixture-of-Experts architectures. Experiments show that this technique improves performance, reduces training costs, and offers new insights for the open-source community....
opinion: placeholder
tags:
    - ML
