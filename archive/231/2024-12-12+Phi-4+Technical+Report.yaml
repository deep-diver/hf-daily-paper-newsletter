date: "2024-12-12"
author: Marah Abdin
title: Phi-4 Technical Report
thumbnail: ""
link: https://huggingface.co/papers/2412.08905
summary: We present phi-4, a 14-billion parameter language model developed with a training recipe that is centrally focused on data quality. Unlike most language models, where pre-training is based primarily on organic data sources such as web content or code, phi-4 strategically incorporates synthetic data throughout the training process. While previous models in the Phi family largely distill the capabilities of a teacher model (specifically GPT-4), phi-4 substantially surpasses its teacher model on ST...
opinion: placeholder
tags:
    - ML
