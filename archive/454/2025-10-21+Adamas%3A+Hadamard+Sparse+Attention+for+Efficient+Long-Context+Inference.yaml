date: "2025-10-21"
author: Siyuan Yan
title: 'Adamas: Hadamard Sparse Attention for Efficient Long-Context Inference'
thumbnail: ""
link: https://huggingface.co/papers/2510.18413
summary: The authors present a new method called Adamas to improve the efficiency of long-context inference in large language models. Adamas uses a Hadamard transform and other techniques to create compact representations and efficiently select important information, resulting in faster processing and comparable or better accuracy compared to traditional methods....
opinion: placeholder
tags:
    - ML
