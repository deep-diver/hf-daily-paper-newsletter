date: "2024-12-24"
author: Luyang Liu
title: Deliberation in Latent Space via Differentiable Cache Augmentation
thumbnail: ""
link: https://huggingface.co/papers/2412.17747
summary: A new method is introduced that uses a frozen large language model (LLM) with an offline coprocessor that operates on the model's key-value cache. The coprocessor augments the cache with latent embeddings to improve the fidelity of subsequent decoding, and is trained using the language modeling loss from the decoder on pretraining data. This approach enables the model to learn how to distill additional computation into its cache in an end-to-end differentiable fashion, and can operate offline an...
opinion: placeholder
tags:
    - ML
