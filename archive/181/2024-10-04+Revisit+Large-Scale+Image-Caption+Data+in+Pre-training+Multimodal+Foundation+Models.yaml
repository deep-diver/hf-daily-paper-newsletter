date: "2024-10-04"
author: Zhengfeng Lai
title: Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models
thumbnail: ""
link: https://huggingface.co/papers/2410.02740
summary: This paper proposes a new, controllable, and scalable captioning pipeline to generate diverse caption formats for various multimodal models. The study finds that a hybrid approach using both synthetic captions and original AltTexts improves alignment and performance, with each model showing preferences for specific caption formats. This analysis helps optimize captioning strategies for pre-training multimodal foundation models....
opinion: placeholder
tags:
    - ML
