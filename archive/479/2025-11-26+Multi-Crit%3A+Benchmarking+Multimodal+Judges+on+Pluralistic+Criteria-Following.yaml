date: "2025-11-26"
author: Tianyi Xiong
title: 'Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following'
thumbnail: ""
link: https://huggingface.co/papers/2511.21662
summary: The study introduces Multi-Crit, a benchmark to evaluate large multimodal models' ability to follow diverse, detailed evaluation criteria, revealing that proprietary models struggle with consistent adherence, especially in open-ended tasks, while open-source models lag further behind. The benchmark also assesses models' flexibility in switching between criteria and recognizing preference conflicts, providing insights into the current limits of multimodal AI evaluation....
opinion: placeholder
tags:
    - ML
