date: "2025-07-03"
author: Aurko Roy
title: 'Fast and Simplex: 2-Simplicial Attention in Triton'
thumbnail: ""
link: https://huggingface.co/papers/2507.02754
summary: This study explores a new architecture called the 2-simplicial Transformer, which improves token efficiency compared to standard Transformers. By using an efficient Triton kernel implementation, the 2-simplicial Transformer generalizes dot-product attention to trilinear functions, resulting in better performance on tasks like mathematics, coding, reasoning, and logic, especially when considering a fixed token budget....
opinion: placeholder
tags:
    - ML
