date: "2024-04-22"
author: Chuofan Ma
title: 'Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.13013.png
link: https://huggingface.co/papers/2404.13013
summary: This paper introduces Groma, a Multimodal Large Language Model (MLLM) that can understand images on a regional level. Groma uses a localized visual tokenization mechanism to decompose images into regions of interest and encodes them into region tokens. This allows Groma to understand user-specified region inputs and ground its textual output to images. Groma consistently outperforms other MLMMs in referring and grounding benchmarks....
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
    - Computer Vision
