date: "2024-06-19"
author: Dongwon Jo
title: 'Mixture of Scales: Memory-Efficient Token-Adaptive Binarization for Large Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2406.12311
summary: This paper proposes a new method called BinaryMoS for reducing the size of large language models by converting weight parameters to binary values. Unlike traditional methods, BinaryMoS uses multiple scaling experts for binary weights and dynamically merges these experts for each token to generate scaling factors. This token-adaptive approach improves the performance of binarized LLMs and maintains similar model size to static binarization techniques....
opinion: placeholder
tags:
    - ML
