date: "2024-06-19"
author: Rima Hazra
title: 'Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations'
thumbnail: ""
link: https://huggingface.co/papers/2406.11801
summary: Safety Arithmetic is a framework that helps large language models generate safer content by tweaking their parameters and activations during testing. It works with various types of models and even has a dataset called NoIntentEdit to identify unsafe edits. Safety Arithmetic makes models generate safer content, doesn't make them too cautious, and still keeps them useful....
opinion: placeholder
tags:
    - ML
