date: "2024-06-19"
author: Changyu Chen
title: Bootstrapping Language Models with DPO Implicit Rewards
thumbnail: ""
link: https://huggingface.co/papers/2406.09760
summary: The paper introduces a new method called DICE (self-alignment with DPO ImpliCit rEwards) that uses an implicit reward model called DPO to further align large language models. This method improves alignment and achieves superior performance than Gemini Pro on AlpacaEval 2, reaching 27.55% length-controlled win rate against GPT-4 Turbo, but with only 8B parameters and no external feedback. The code for DICE is available at <https://github.com/sail-sg/dice>....
opinion: placeholder
tags:
    - ML
