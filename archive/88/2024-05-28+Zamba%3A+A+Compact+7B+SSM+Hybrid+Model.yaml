date: "2024-05-28"
author: Paolo Glorioso
title: 'Zamba: A Compact 7B SSM Hybrid Model'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.16712.png
link: https://huggingface.co/papers/2405.16712
summary: Zamba is a 7B SSM-transformer hybrid model that achieves competitive performance at a comparable scale, is faster at inference, and requires less memory for long sequences. It's pretrained in two phases and open-sourced....
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
