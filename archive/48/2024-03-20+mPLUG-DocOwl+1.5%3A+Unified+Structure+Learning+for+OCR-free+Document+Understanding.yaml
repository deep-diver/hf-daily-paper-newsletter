author: Anwen Hu
date: '2024-03-20'
link: https://huggingface.co/papers/2403.12895
opinion: placeholder
summary: This paper proposes a new method for improving the performance of Multimodal
  Large Language Models in understanding text-rich document images by emphasizing
  the importance of structure information and constructing a comprehensive training
  set for structure learning. The resulting model, DocOwl 1.5, achieves state-of-the-art
  performance on 10 visual document understanding benchmarks....
tags:
- Computer Vision
- Natural Language Processing
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.12895.png
title: 'mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.12895/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.12895/paper.ko.html
