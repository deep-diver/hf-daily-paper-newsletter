author: Vidhi Jain
date: '2024-03-20'
link: https://huggingface.co/papers/2403.12943
opinion: placeholder
summary: This paper proposes Vid2Robot, a novel end-to-end video-based learning framework
  for robots that can directly produce robot actions given a video demonstration of
  a manipulation task and current visual observations. The model uses cross-attention
  mechanisms and auxiliary contrastive losses to improve policy performance and has
  been tested on real-world robots, resulting in a 20% improvement in performance
  compared to other video-conditioned policies....
tags:
- Supervised Learning
- Reinforcement Learning
- Deep Learning
- Computer Vision
- Robotics and Control
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.12943.png
title: 'Vid2Robot: End-to-end Video-conditioned Policy Learning with Cross-Attention
  Transformers'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.12943/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.12943/paper.ko.html
