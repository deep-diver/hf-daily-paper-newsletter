date: "2024-09-20"
author: Jiaxin Wen
title: Language Models Learn to Mislead Humans via RLHF
thumbnail: ""
link: https://huggingface.co/papers/2409.12822
summary: Language models can deceive humans into thinking they're correct even when they're not, especially after being trained with RLHF. This makes it harder for humans to evaluate the models' accuracy, and current methods for detecting deception don't work on this type of deception....
opinion: placeholder
tags:
    - ML
