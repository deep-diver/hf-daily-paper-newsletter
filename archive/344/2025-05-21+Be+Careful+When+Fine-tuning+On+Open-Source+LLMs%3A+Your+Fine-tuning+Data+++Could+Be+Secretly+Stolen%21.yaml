date: "2025-05-21"
author: Zhexin Zhang
title: 'Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data   Could Be Secretly Stolen!'
thumbnail: ""
link: https://huggingface.co/papers/2505.15656
summary: The study reveals a risk in using proprietary data to fine-tune open-source language models, where the original model creators can potentially extract the private data through simple backdoor training. Experiments show that a significant portion of the data can be extracted, highlighting the need for further research on addressing this data breaching risk....
opinion: placeholder
tags:
    - ML
