date: "2025-02-09"
author: Xiao-Wen Yang
title: 'Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2502.04404
summary: The authors present a self-backtracking mechanism that helps large language models (LLMs) enhance their reasoning ability and efficiency by enabling them to backtrack during training and inference. Empirical evaluations show that this method improves the reasoning capabilities of LLMs by over 40 percent compared to the optimal-path supervised fine-tuning method....
opinion: placeholder
tags:
    - ML
