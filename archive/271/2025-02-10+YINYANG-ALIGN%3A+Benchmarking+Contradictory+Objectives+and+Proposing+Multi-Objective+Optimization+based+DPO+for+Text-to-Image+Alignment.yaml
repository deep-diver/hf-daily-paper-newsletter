date: "2025-02-10"
author: Amitava Das
title: 'YINYANG-ALIGN: Benchmarking Contradictory Objectives and Proposing Multi-Objective Optimization based DPO for Text-to-Image Alignment'
thumbnail: ""
link: https://huggingface.co/papers/2502.03512
summary: YinYangAlign is a new benchmarking framework that quantifies the alignment fidelity of text-to-image systems, addressing six contradictory design objectives like balancing adherence to user prompts with creative modifications or maintaining diversity alongside visual coherence, using datasets with aligned and misaligned AI-generated outputs....
opinion: placeholder
tags:
    - ML
