date: "2025-04-15"
author: Wei Xiong
title: 'A Minimalist Approach to LLM Reasoning: from Rejection Sampling to   Reinforce'
thumbnail: ""
link: https://huggingface.co/papers/2504.11343
summary: The study investigates GRPO, a successful method for fine-tuning large language models using reinforcement learning, and finds that a simple baseline, RAFT, performs competitively by training only on positively rewarded samples. The main advantage of GRPO lies in discarding prompts with incorrect responses, rather than reward normalization. The authors propose Reinforce-Rej, a minimal extension of policy gradient that filters incorrect and correct samples, improving KL efficiency and stability. ...
opinion: placeholder
tags:
    - ML
