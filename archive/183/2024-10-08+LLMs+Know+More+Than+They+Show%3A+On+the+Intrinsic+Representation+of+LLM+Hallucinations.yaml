date: "2024-10-08"
author: Hadas Orgad
title: 'LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations'
thumbnail: ""
link: https://huggingface.co/papers/2410.02707
summary: This paper explores the internal representations of large language models (LLMs) and finds that they encode more information about truthfulness than previously recognized. The study reveals that truthfulness information is concentrated in specific tokens, and leveraging this property significantly enhances error detection performance. However, error detectors fail to generalize across datasets, suggesting that truthfulness encoding is multifaceted rather than universal. The paper also demonstrat...
opinion: placeholder
tags:
    - ML
