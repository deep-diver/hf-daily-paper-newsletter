date: "2024-10-08"
author: Han Yang
title: 'UniMuMo: Unified Text, Music and Motion Generation'
thumbnail: ""
link: https://huggingface.co/papers/2410.04534
summary: UniMuMo is a unified multimodal model that can take text, music, and motion data as input to generate outputs across all three modalities. It uses a unified encoder-decoder transformer architecture and several architectural improvements to support multiple generation tasks within a single framework. It achieves competitive results on all unidirectional generation benchmarks across music, motion, and text modalities....
opinion: placeholder
tags:
    - ML
