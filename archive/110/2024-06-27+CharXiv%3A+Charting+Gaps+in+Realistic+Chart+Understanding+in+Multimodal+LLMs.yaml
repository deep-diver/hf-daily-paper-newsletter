date: "2024-06-27"
author: Zirui Wang
title: 'CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2406.18521
summary: 'CharXiv is a new evaluation suite for testing the chart understanding capabilities of Multimodal Large Language Models (MLLMs). It has two types of questions: descriptive and reasoning. The strongest proprietary model (GPT-4o) achieves 47.1% accuracy, while the strongest open-source model (InternVL Chat V1.5) achieves 29.2%. Both models lag far behind human performance of 80.5%, highlighting the need for further research on MLLM chart understanding....'
opinion: placeholder
tags:
    - ML
