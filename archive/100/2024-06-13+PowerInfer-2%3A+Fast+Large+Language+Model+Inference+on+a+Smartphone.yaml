date: "2024-06-13"
author: Zhenliang Xue
title: 'PowerInfer-2: Fast Large Language Model Inference on a Smartphone'
thumbnail: ""
link: https://huggingface.co/papers/2406.06282
summary: This paper introduces PowerInfer-2, a framework designed for high-speed inference of Large Language Models (LLMs) on smartphones, particularly effective for models whose sizes exceed the device's memory capacity. The key insight of PowerInfer-2 is to utilize the heterogeneous computation, memory, and I/O resources in smartphones by decomposing traditional matrix computations into fine-grained neuron cluster computations. Specifically, PowerInfer-2 features a polymorphic neuron engine that adapts...
opinion: placeholder
tags:
    - ML
