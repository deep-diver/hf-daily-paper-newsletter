date: "2025-05-25"
author: Fengqi Zhu
title: 'LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language   Diffusion Models'
thumbnail: ""
link: https://huggingface.co/papers/2505.19223
summary: This study introduces a framework called Variance-Reduced Preference Optimization (VRPO) to align Masked Diffusion Models (MDMs) with human preferences more effectively. By analyzing the variance of Evidence Lower Bound (ELBO) estimators, VRPO reduces bias and variance in preference optimization gradients, resulting in a more efficient and accurate language modeling process. The improved model, LLaDA 1.5, outperforms its predecessor across various benchmarks and demonstrates competitive mathemat...
opinion: placeholder
tags:
    - ML
