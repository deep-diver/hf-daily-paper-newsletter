date: "2025-05-19"
author: Chih-Kai Yang
title: 'SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based   on Speech and Audio Information'
thumbnail: ""
link: https://huggingface.co/papers/2505.13237
summary: The study introduces a new assessment tool called SAKURA to evaluate the multi-hop reasoning abilities of large audio-language models, which are models that understand speech and audio information. The results show that these models struggle to combine speech and audio information for multi-hop reasoning, despite correctly extracting relevant information, highlighting a significant challenge in multimodal reasoning....
opinion: placeholder
tags:
    - ML
