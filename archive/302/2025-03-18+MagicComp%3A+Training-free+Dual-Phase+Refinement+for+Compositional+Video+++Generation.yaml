date: "2025-03-18"
author: Hongyu Zhang
title: 'MagicComp: Training-free Dual-Phase Refinement for Compositional Video   Generation'
thumbnail: ""
link: https://huggingface.co/papers/2503.14428
summary: MagicComp is a training-free method for improving text-to-video generation, addressing limitations in binding attributes, determining spatial relationships, and capturing complex interactions between multiple subjects in existing methods. It uses Semantic Anchor Disambiguation in the Conditioning Stage for resolving inter-subject ambiguity and Dynamic Layout Fusion Attention in the Denoising Stage for integrating grounding priors and adaptive spatial perception....
opinion: placeholder
tags:
    - ML
