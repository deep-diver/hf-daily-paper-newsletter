date: "2025-03-21"
author: Shu Pu
title: 'Judge Anything: MLLM as a Judge Across Any Modality'
thumbnail: ""
link: https://huggingface.co/papers/2503.17489
summary: This study introduces two benchmarks, TaskAnything and JudgeAnything, to evaluate the overall performance and judging capabilities of Multimodal LLMs (MLLMs) across any-to-any modality tasks. Experiments reveal that MLLMs show promise in assessing understanding tasks but struggle with generation tasks, exposing cross-modality biases and hallucination issues....
opinion: placeholder
tags:
    - ML
