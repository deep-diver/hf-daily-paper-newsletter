date: "2024-07-03"
author: Elmira Amirloo
title: 'Understanding Alignment in Multimodal LLMs: A Comprehensive Study'
thumbnail: ""
link: https://huggingface.co/papers/2407.02477
summary: The paper investigates preference alignment in Multimodal Large Language Models (MLLMs) to reduce hallucination and enhance performance. It categorizes alignment algorithms into offline and online methods and introduces a novel way of creating multimodal preference data called Bias-Driven Hallucination Sampling (BDHS) that can achieve competitive performance....
opinion: placeholder
tags:
    - ML
