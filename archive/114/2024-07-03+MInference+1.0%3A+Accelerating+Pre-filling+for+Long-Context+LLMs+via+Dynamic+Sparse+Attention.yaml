date: "2024-07-03"
author: Huiqiang Jiang
title: 'MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention'
thumbnail: ""
link: https://huggingface.co/papers/2407.02490
summary: MInference is a sparse calculation method that identifies unique patterns in long-context attention matrices to accelerate pre-filling of long-sequence processing in Large Language Models (LLM). It reduces inference latency by up to 10x for pre-filling on an A100 while maintaining accuracy....
opinion: placeholder
tags:
    - ML
