date: "2025-10-27"
author: Siyin Wang
title: 'RoboOmni: Proactive Robot Manipulation in Omni-modal Context'
thumbnail: ""
link: https://huggingface.co/papers/2510.23763
summary: This study presents RoboOmni, a new framework that allows robots to understand and act on human intentions through spoken language, environmental sounds, and visual cues, rather than explicit instructions. The framework, which is based on end-to-end omni-modal Large Language Models, can recognize intentions, confirm interactions, and execute actions, and it has been trained using a large dataset called OmniAction, which includes various types of real-world interactions....
opinion: placeholder
tags:
    - ML
