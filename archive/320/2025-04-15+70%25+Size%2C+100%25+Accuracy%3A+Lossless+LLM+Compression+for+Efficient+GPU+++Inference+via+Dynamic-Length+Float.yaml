date: "2025-04-15"
author: Tianyi Zhang
title: '70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU   Inference via Dynamic-Length Float'
thumbnail: ""
link: https://huggingface.co/papers/2504.11651
summary: The paper presents DFloat11, a lossless compression framework that reduces Large Language Models (LLMs) size by 30% while preserving outputs that are bit-for-bit identical to the original model. It achieves this by applying entropy coding to assign dynamic-length encodings to weights based on frequency, motivated by the low entropy in the BFloat16 weight representation of LLMs....
opinion: placeholder
tags:
    - ML
