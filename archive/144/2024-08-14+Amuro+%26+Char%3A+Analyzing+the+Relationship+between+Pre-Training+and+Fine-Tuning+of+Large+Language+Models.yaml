date: "2024-08-14"
author: Kaiser Sun
title: 'Amuro & Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2408.06663
summary: This paper investigates the relationship between pre-training and fine-tuning of large language models. The results show that continual pre-training improves the model, fine-tuning can cause the model to forget previously known knowledge, and the model is sensitive to evaluation prompts after supervised fine-tuning. More pre-training can alleviate this sensitivity....
opinion: placeholder
tags:
    - ML
