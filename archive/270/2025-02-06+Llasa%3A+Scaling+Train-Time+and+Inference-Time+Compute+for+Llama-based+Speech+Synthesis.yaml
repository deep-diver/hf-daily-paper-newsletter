date: "2025-02-06"
author: Zhen Ye
title: 'Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis'
thumbnail: ""
link: https://huggingface.co/papers/2502.04128
summary: This work introduces a single-layer vector quantizer and Transformer architecture for speech synthesis, named Llasa, which scales train-time and inference-time compute for Llama-based TTS. The model improves naturalness and prosody patterns with scalable training, and enhances emotional expressiveness, timbre consistency, and content accuracy with scalable inference....
opinion: placeholder
tags:
    - ML
