date: "2025-02-07"
author: Xintong Hao
title: 'MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion'
thumbnail: ""
link: https://huggingface.co/papers/2502.04235
summary: The paper introduces a method called MAGA, which generates high-quality pretraining data for large language models, addressing the scarcity issue. This approach, demonstrated through the creation of a 770B tokens MAGACorpus, consistently improves performance across various model sizes and reveals limitations in conventional collapse detection metrics....
opinion: placeholder
tags:
    - ML
