date: "2025-04-28"
author: Zae Myung Kim
title: 'Toward Evaluative Thinking: Meta Policy Optimization with Evolving   Reward Models'
thumbnail: ""
link: https://huggingface.co/papers/2504.20157
summary: This study proposes a new framework called Meta Policy Optimization (MPO) that improves the alignment of large language models (LLMs) by dynamically adjusting the reward model's prompt during training. MPO reduces the risk of reward hacking and the need for manual reward prompt design, resulting in better performance and adaptability across various tasks....
opinion: placeholder
tags:
    - ML
