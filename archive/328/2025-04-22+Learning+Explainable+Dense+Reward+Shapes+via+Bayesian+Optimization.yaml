date: "2025-04-22"
author: Ryan Koo
title: Learning Explainable Dense Reward Shapes via Bayesian Optimization
thumbnail: ""
link: https://huggingface.co/papers/2504.16272
summary: This study addresses the issue of sparse feedback in current large language model alignment methods by proposing a reward-shaping function that estimates per-token rewards using explainability methods. The authors then use a bilevel optimization framework with Bayesian Optimization to learn the shaping function's parameters, leading to improved performance on downstream tasks and faster training of optimal policies....
opinion: placeholder
tags:
    - ML
