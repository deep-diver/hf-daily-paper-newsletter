date: "2025-04-10"
author: Hardy Chen
title: SFT or RL? An Early Investigation into Training R1-Like Reasoning Large   Vision-Language Models
thumbnail: ""
link: https://huggingface.co/papers/2504.11468
summary: The study examines the impact of supervised fine-tuning (SFT) on subsequent reinforcement learning (RL) in large vision-language models, revealing that SFT can lead to 'pseudo reasoning paths' that may resemble but differ from the genuine reasoning paths of RL models. The paper introduces VLAA-Thinking, a dataset designed for studying this effect, and presents experimental results showing that while SFT aids in learning reasoning formats, it may lock models into rigid reasoning modes. The study ...
opinion: placeholder
tags:
    - ML
