date: "2024-11-27"
author: Shantanu Acharya
title: 'Star Attention: Efficient LLM Inference over Long Sequences'
thumbnail: ""
link: https://huggingface.co/papers/2411.17116
summary: Star Attention is a new method for making it faster and cheaper to use large language models to process long sequences of text, by dividing up and processing the text in smaller chunks first, and then combining the results. This method works with most language models and keeps accuracy high while reducing the amount of memory and time needed for processing....
opinion: placeholder
tags:
    - ML
