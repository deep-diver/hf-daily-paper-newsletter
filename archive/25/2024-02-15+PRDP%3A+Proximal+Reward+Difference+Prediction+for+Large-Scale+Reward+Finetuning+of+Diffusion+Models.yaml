author: Fei Deng
date: '2024-02-15'
link: https://huggingface.co/papers/2402.08714
opinion: placeholder
summary: Reward finetuning has emerged as a promising approach to aligning foundation
  models with downstream objectives. Remarkable success has been achieved in the language
  domain by using reinforcement learning (RL) to maximize rewards that reflect human
  preference. However, in the vision domain, existing RL-based reward finetuning methods
  are limited by their instability in large-scale training, rendering them incapable
  of generalizing to complex, unseen prompts. In this paper, we propose Proximal Rew...
tags:
- Supervised Learning
- Reinforcement Learning
- Computer Vision
thumbnail: https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/assets/2402.08714.gif?raw=true
title: 'PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning
  of Diffusion Models'
