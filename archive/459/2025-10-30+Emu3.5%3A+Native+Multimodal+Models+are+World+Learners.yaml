date: "2025-10-30"
author: Yufeng Cui
title: 'Emu3.5: Native Multimodal Models are World Learners'
thumbnail: ""
link: https://huggingface.co/papers/2510.26583
summary: Emu3.5 is a large multimodal model that learns from over 10 trillion vision-language tokens, allowing it to generate interleaved vision-language outputs and perform complex tasks like long-horizon vision-language generation and any-to-image generation. It's efficient, thanks to Discrete Diffusion Adaptation, and outperforms some models in interleaved generation tasks....
opinion: placeholder
tags:
    - ML
