date: "2024-06-04"
author: Yubo Wang
title: 'MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.01574.png
link: https://huggingface.co/papers/2406.01574
summary: MMLU-Pro is a new, more challenging language understanding benchmark that tests models' reasoning abilities and stability under different prompts. It's designed to push the boundaries of AI language comprehension and is more effective at measuring model capabilities than previous benchmarks....
opinion: placeholder
tags:
    - Natural Language Processing
    - Supervised Learning
