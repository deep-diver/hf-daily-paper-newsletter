date: "2025-10-01"
author: Zichen Wen
title: Efficient Multi-modal Large Language Models via Progressive Consistency   Distillation
thumbnail: ""
link: https://huggingface.co/papers/2510.00515
summary: This study presents a new method to create efficient multi-modal large language models by addressing the challenge of visual tokens consuming too much computational power. The proposed framework, EPIC, reduces training difficulty by introducing token and layer consistency distillation, which helps the model adapt to perturbations in the feature space caused by token compression, resulting in superior effectiveness, robustness, and generalization capabilities....
opinion: placeholder
tags:
    - ML
