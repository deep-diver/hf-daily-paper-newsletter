date: "2025-08-25"
author: Yifan Wang
title: 'TiKMiX: Take Data Influence into Dynamic Mixture for Language Model   Pre-training'
thumbnail: ""
link: https://huggingface.co/papers/2508.17677
summary: The study presents TiKMiX, a new method that adjusts the data mixture for language model pre-training based on the model's changing preferences, which is more efficient than static mixing strategies. TiKMiX uses Group Influence, an efficient metric to evaluate the impact of data domains on the model, and offers two approaches, TiKMiX-D and TiKMiX-M, to optimize the data mixing problem. The method outperforms state-of-the-art techniques while using fewer computational resources....
opinion: placeholder
tags:
    - ML
