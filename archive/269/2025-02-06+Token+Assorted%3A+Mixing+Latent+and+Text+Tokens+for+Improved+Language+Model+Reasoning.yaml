date: "2025-02-06"
author: DiJia Su
title: 'Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning'
thumbnail: ""
link: https://huggingface.co/papers/2502.03275
summary: 'The authors suggest a new method for shortening the reasoning process in Large Language Models (LLMs) by using latent discrete tokens, reducing the length of inputs and computation resources. This is tested on two scenarios: training a model for the Keys-Finding Maze problem and fine-tuning LLMs for logical and mathematical reasoning problems, both showing better performance than baseline methods....'
opinion: placeholder
tags:
    - ML
