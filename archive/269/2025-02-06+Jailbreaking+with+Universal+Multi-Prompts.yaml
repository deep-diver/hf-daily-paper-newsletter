date: "2025-02-06"
author: Yu-Ling Hsu
title: Jailbreaking with Universal Multi-Prompts
thumbnail: ""
link: https://huggingface.co/papers/2502.01154
summary: The abstract discusses a method, JUMP, to jailbreak large language models (LLMs) using universal multi-prompts, addressing the issue of high computational costs in existing prompting techniques. The approach also includes a defense strategy, DUMP, which outperforms existing methods....
opinion: placeholder
tags:
    - ML
