date: "2025-05-21"
author: Hwan Chang
title: Keep Security! Benchmarking Security Policy Preservation in Large   Language Model Contexts Against Indirect Attacks in Question Answering
thumbnail: ""
link: https://huggingface.co/papers/2505.15805
summary: The authors present a new dataset called CoPriva to test if large language models (LLMs) can follow security policies, specifically non-disclosure policies, when answering questions. The results show that many LLMs fail to keep sensitive information private, especially when faced with indirect attacks, which is a major concern for using LLMs in sensitive areas like businesses and government....
opinion: placeholder
tags:
    - ML
