date: "2025-09-10"
author: Joachim Baumann
title: 'Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs   for Text Annotation'
thumbnail: ""
link: https://huggingface.co/papers/2509.08825
summary: The study examines the risks of using large language models (LLMs) for text annotation in social science research, revealing that researcher choices can introduce biases and errors, leading to incorrect conclusions. The study also finds that intentional manipulation of LLMs to produce statistically significant results is easy to do....
opinion: placeholder
tags:
    - ML
