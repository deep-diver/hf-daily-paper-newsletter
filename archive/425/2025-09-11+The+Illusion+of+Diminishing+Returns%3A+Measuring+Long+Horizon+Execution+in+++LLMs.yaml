date: "2025-09-11"
author: Akshit Sinha
title: 'The Illusion of Diminishing Returns: Measuring Long Horizon Execution in   LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2509.09677
summary: This study investigates why larger language models sometimes struggle with longer tasks despite high single-step accuracy. They find that self-conditioning, where models make more mistakes when their errors are in the context, is a major issue. To address this, they propose a new benchmark for testing models' ability to execute long-horizon tasks, which could help improve LLMs' performance on complex problems....
opinion: placeholder
tags:
    - ML
