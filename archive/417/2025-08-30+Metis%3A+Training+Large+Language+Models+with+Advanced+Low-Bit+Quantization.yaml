date: "2025-08-30"
author: Hengjie Cao
title: 'Metis: Training Large Language Models with Advanced Low-Bit Quantization'
thumbnail: ""
link: https://huggingface.co/papers/2509.00404
summary: The abstract presents Metis, a training framework that addresses the issue of training large language models with low-bit quantization by disentangling dominant from long-tail components, using adaptive learning rates, and applying a dual-range regularizer. This results in improved model performance and stability, even with very low bit-rates, surpassing the accuracy of traditional floating-point training....
opinion: placeholder
tags:
    - ML
