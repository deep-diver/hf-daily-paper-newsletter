date: "2025-06-05"
author: Ananth Muppidi
title: Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs
thumbnail: ""
link: https://huggingface.co/papers/2506.05629
summary: This study presents a new method called ID-SPAM that optimizes large language models for specific tasks using soft prompting, which requires fewer trainable parameters than traditional fine-tuning. The proposed technique generates custom prompts based on the input and assigns different levels of importance to each token, improving the model's performance in zero-shot domain transfer compared to existing methods....
opinion: placeholder
tags:
    - ML
