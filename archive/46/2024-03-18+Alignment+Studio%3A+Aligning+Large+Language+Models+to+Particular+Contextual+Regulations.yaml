author: Swapnaja Achintalwar
date: '2024-03-18'
link: https://huggingface.co/papers/2403.09704
opinion: placeholder
summary: 'The paper presents an approach and architecture called Alignment Studio
  that allows application developers to customize language models to their specific
  contextual regulations, values, and norms. The architecture consists of three components:
  Framers, Instructors, and Auditors, which work together to control the model''s
  behavior. The approach is illustrated with an example of aligning a company''s chatbot
  to its business conduct guidelines....'
tags:
- Natural Language Processing
- Explainable AI and Interpretability
- Fairness, Bias, and Ethics
- Deep Learning
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09704.png
title: 'Alignment Studio: Aligning Large Language Models to Particular Contextual
  Regulations'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.09704/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.09704/paper.ko.html
