date: "2024-12-03"
author: Xuhao Hu
title: 'VLSBench: Unveiling Visual Leakage in Multimodal Safety'
thumbnail: ""
link: https://huggingface.co/papers/2411.19939
summary: This paper introduces VLSBench, a new benchmark for evaluating the safety of large language models in multimodal scenarios. The benchmark is designed to prevent visual safety leakage from images to textual queries, and it poses a significant challenge to both open-source and closed-source models. The study demonstrates that textual alignment is enough for multimodal safety scenarios with visual safety leakage, while multimodal alignment is a more promising solution for scenarios without leakage....
opinion: placeholder
tags:
    - ML
