date: "2025-08-05"
author: Bodam Kim
title: 'When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with   Benign Inputs'
thumbnail: ""
link: https://huggingface.co/papers/2508.03365
summary: The researchers created WhisperInject, a method that can trick advanced audio language models into generating harmful content. They do this by adding tiny, invisible changes to harmless audio inputs, like weather updates or greetings, which can bypass safety measures with over 86% success rate....
opinion: placeholder
tags:
    - ML
