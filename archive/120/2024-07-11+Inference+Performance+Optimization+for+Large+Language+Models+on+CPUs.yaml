date: "2024-07-11"
author: Pujiang He
title: Inference Performance Optimization for Large Language Models on CPUs
thumbnail: ""
link: https://huggingface.co/papers/2407.07304
summary: This paper presents an optimization solution to enhance the inference performance of large language models (LLMs) on CPUs, focusing on reducing the KV cache size, implementing a distributed inference optimization approach, and proposing tailored optimizations for commonly used models. The code is open-sourced at https://github.com/intel/xFasterTransformer....
opinion: placeholder
tags:
    - ML
