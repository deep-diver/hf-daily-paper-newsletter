date: "2025-06-12"
author: Jari Kolehmainen
title: 'NoLoCo: No-all-reduce Low Communication Training Method for Large Models'
thumbnail: ""
link: https://huggingface.co/papers/2506.10911
summary: The study presents NoLoCo, a new optimization method for training large language models that avoids explicit synchronization of all model parameters, leading to reduced communication costs and faster convergence compared to existing low communication training methods like DiLoCo....
opinion: placeholder
tags:
    - ML
