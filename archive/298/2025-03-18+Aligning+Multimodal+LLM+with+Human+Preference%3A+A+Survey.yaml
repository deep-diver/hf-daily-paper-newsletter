date: "2025-03-18"
author: Tao Yu
title: 'Aligning Multimodal LLM with Human Preference: A Survey'
thumbnail: ""
link: https://huggingface.co/papers/2503.14504
summary: This paper provides a detailed review of alignment algorithms for Multimodal Large Language Models (MLLMs), which are crucial for improving truthfulness, safety, human-like reasoning, and human preference alignment. It covers application scenarios, construction of alignment datasets, evaluation benchmarks, and potential future developments....
opinion: placeholder
tags:
    - ML
