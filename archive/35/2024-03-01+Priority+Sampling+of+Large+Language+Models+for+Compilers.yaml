author: Dejan Grubisic
date: '2024-03-01'
link: https://huggingface.co/papers/2402.18734
opinion: placeholder
summary: The paper introduces Priority Sampling, a new technique for generating unique
  code samples by ordering them by the model's confidence. It outperforms the widely
  used Nucleus Sampling and boosts the performance of the original model by up to
  5%....
tags:
- Natural Language Processing
- Optimization and Learning Algorithms
- Emerging Applications of Machine Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Pd3hUuaovnlxf5_8AXWge.png
title: Priority Sampling of Large Language Models for Compilers
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.18734/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.18734/paper.ko.html
