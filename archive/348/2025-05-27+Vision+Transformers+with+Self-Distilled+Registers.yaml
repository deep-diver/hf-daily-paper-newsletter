date: "2025-05-27"
author: Yinjie Chen
title: Vision Transformers with Self-Distilled Registers
thumbnail: ""
link: https://huggingface.co/papers/2505.21501
summary: The paper proposes a method to improve Vision Transformers (ViTs) without re-training them from scratch. They introduce Post Hoc Registers (PH-Reg), which adds register tokens to existing ViTs using a self-distillation technique, reducing artifact tokens and enhancing segmentation and depth prediction....
opinion: placeholder
tags:
    - ML
