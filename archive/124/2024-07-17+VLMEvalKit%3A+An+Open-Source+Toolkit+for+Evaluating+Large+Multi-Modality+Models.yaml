date: "2024-07-17"
author: Haodong Duan
title: 'VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models'
thumbnail: ""
link: https://huggingface.co/papers/2407.11691
summary: VLMEvalKit is an open-source toolkit for evaluating large multi-modality models. It includes 70+ models and 20+ benchmarks, and can easily add new models. It's designed to be compatible with future updates that incorporate additional modalities like audio and video. The toolkit is used to track the progress of multi-modality learning research and is available at <https://github.com/open-compass/VLMEvalKit>....
opinion: placeholder
tags:
    - ML
