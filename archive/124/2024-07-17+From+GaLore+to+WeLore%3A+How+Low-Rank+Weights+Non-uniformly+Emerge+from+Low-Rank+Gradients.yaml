date: "2024-07-17"
author: Ajay Jaiswal
title: 'From GaLore to WeLore: How Low-Rank Weights Non-uniformly Emerge from Low-Rank Gradients'
thumbnail: ""
link: https://huggingface.co/papers/2407.11239
summary: This paper studies the emergence of low-rank structures in matrices within different layers of Large Language Models (LLMs) and develops a method called Weight Low-Rank Projection (WeLore) to unify weight compression and memory-efficient fine-tuning. WeLore categorizes weight matrices into Low-rank Components (LRCs) and Non-Low-rank Components (N-LRCs) based on their ability to express themselves as low-rank and demonstrates that LRCs tend to have better finetuning capabilities with notable memo...
opinion: placeholder
tags:
    - ML
