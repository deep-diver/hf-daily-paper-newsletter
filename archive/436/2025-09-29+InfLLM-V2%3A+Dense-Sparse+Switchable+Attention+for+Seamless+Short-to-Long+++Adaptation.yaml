date: "2025-09-29"
author: Weilin Zhao
title: 'InfLLM-V2: Dense-Sparse Switchable Attention for Seamless Short-to-Long   Adaptation'
thumbnail: ""
link: https://huggingface.co/papers/2509.24663
summary: The study presents InfLLM-V2, a new attention mechanism that efficiently handles long sequences without the drawbacks of previous methods. InfLLM-V2 seamlessly adapts models for short and long sequences, maintains performance, and is 4 times faster than dense attention, making it a practical solution for long-context understanding and reasoning tasks....
opinion: placeholder
tags:
    - ML
