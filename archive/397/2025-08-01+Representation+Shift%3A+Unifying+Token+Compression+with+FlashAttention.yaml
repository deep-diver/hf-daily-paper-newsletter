date: "2025-08-01"
author: Joonmyung Choi
title: 'Representation Shift: Unifying Token Compression with FlashAttention'
thumbnail: ""
link: https://huggingface.co/papers/2508.00367
summary: The authors present Representation Shift, a new method that measures changes in token representation to unify token compression with FlashAttention, making it compatible with GPU memory access optimization. This approach, which works for Transformers, CNNs, and state space models, significantly speeds up video-text retrieval and video QA tasks by up to 5.5% and 4.4% respectively, without requiring attention maps or retraining....
opinion: placeholder
tags:
    - ML
