date: "2025-11-04"
author: Rishi Rajesh Shah
title: Jailbreaking in the Haystack
thumbnail: ""
link: https://huggingface.co/papers/2511.04707
summary: The study presents NINJA, a method that exploits long-context language models by adding harmless, model-generated content to malicious user goals. NINJA significantly improves attack success rates on various models, including LLaMA, Qwen, Mistral, and Gemini, and is more efficient and harder to detect compared to previous methods....
opinion: placeholder
tags:
    - ML
