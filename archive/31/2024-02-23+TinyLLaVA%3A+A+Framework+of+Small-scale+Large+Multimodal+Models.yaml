author: Baichuan Zhou
date: '2024-02-23'
link: https://huggingface.co/papers/2402.14289
opinion: placeholder
summary: The authors present TinyLLaVA, a framework for analyzing and designing small-scale
  Large Multimodal Models. Through experiments, they show that better quality data
  and training can lead to small LMMs performing as well as larger ones. They train
  a small LMM, TinyLLaVA-3.1B, which outperforms existing 7B models....
tags:
- Supervised Learning
- Optimization and Learning Algorithms
- Deep Learning
- Computer Vision
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jLTorjcBFaqWNxe8v34Xc.png
title: 'TinyLLaVA: A Framework of Small-scale Large Multimodal Models'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14289/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14289/paper.ko.html
