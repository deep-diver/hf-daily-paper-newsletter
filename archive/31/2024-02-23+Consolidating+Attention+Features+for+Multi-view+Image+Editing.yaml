author: Or Patashnik
date: '2024-02-23'
link: https://huggingface.co/papers/2402.14792
opinion: placeholder
summary: 'Large-scale text-to-image models enable a wide range of image editing techniques,
  using text prompts or even spatial controls. However, applying these editing methods
  to multi-view images depicting a single scene leads to 3D-inconsistent results.
  In this work, we focus on spatial control-based geometric manipulations and introduce
  a method to consolidate the editing process across various views. We build on two
  insights: (1) maintaining consistent features throughout the generative process
  helps...'
tags:
- Computer Vision
- Deep Learning
- Explainable AI and Interpretability
thumbnail: https://github.com/deep-diver/hf-daily-paper-newsletter/blob/main/assets/2402.14792.gif?raw=true
title: Consolidating Attention Features for Multi-view Image Editing
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14792/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2402.14792/paper.ko.html
