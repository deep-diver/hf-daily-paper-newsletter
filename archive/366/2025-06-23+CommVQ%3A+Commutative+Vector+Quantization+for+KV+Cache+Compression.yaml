date: "2025-06-23"
author: Junyan Li
title: 'CommVQ: Commutative Vector Quantization for KV Cache Compression'
thumbnail: ""
link: https://huggingface.co/papers/2506.18879
summary: The authors present a new method called Commutative Vector Quantization (CommVQ) to reduce memory usage for long-context language models. By using additive quantization and a specially designed codebook, they achieve high accuracy and low computational costs, enabling 1-bit KV cache quantization with minimal accuracy loss and allowing larger models to run on limited GPU memory....
opinion: placeholder
tags:
    - ML
