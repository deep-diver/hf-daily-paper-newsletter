date: "2025-11-11"
author: Zhen Yang
title: 'UI2Code^N: A Visual Language Model for Test-Time Scalable Interactive UI-to-Code Generation'
thumbnail: ""
link: https://huggingface.co/papers/2511.08195
summary: The study presents UI2Code^N, a visual language model that improves multimodal coding by unifying UI-to-code generation, UI editing, and UI polishing. This model uses staged pretraining, fine-tuning, and reinforcement learning, and it achieves state-of-the-art performance in UI-to-code and UI polishing benchmarks, even surpassing some closed-source models....
opinion: placeholder
tags:
    - ML
