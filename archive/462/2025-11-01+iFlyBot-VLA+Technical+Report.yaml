date: "2025-11-01"
author: Yuan Zhang
title: iFlyBot-VLA Technical Report
thumbnail: ""
link: https://huggingface.co/papers/2511.01914
summary: The authors present a new large-scale Vision-Language-Action model called iFlyBot-VLA, which is trained using a unique framework that combines human and robotic manipulation videos, general QA datasets, and spatial QA datasets. This model can predict both high-level intentions and low-level dynamics of actions, and it outperforms existing models in various manipulation tasks according to experimental results....
opinion: placeholder
tags:
    - ML
