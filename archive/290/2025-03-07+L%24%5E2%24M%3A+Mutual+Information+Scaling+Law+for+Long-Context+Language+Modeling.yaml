date: "2025-03-07"
author: Zhuo Chen
title: 'L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling'
thumbnail: ""
link: https://huggingface.co/papers/2503.04725
summary: The study reveals a new mutual information scaling law for long-range dependencies in natural language, distinct from and independent of the traditional two-point mutual information. This law is used to create the Long-context Language Modeling (L^2M) condition, which connects a model's capacity for long context length modeling to its latent state size for storing past information, validated through experiments on transformers and state space models....
opinion: placeholder
tags:
    - ML
