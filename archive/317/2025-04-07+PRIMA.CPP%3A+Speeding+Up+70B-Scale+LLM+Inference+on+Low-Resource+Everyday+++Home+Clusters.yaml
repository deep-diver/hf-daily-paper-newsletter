date: "2025-04-07"
author: Zonghang Li
title: 'PRIMA.CPP: Speeding Up 70B-Scale LLM Inference on Low-Resource Everyday   Home Clusters'
thumbnail: ""
link: https://huggingface.co/papers/2504.08791
summary: The paper presents prima.cpp, a system that enables inference of large language models (70B-scale) on everyday home devices with a mix of CPU/GPU, low RAM/VRAM, Wi-Fi, and cross-platform support. It manages model weights using mmap and introduces piped-ring parallelism with prefetching, and optimally assigns model layers to each device's CPU and GPU using an algorithm named Halda. This brings frontier models like Llama 3 and DeepSeek R1 to home assistants, making advanced AI accessible to indivi...
opinion: placeholder
tags:
    - ML
