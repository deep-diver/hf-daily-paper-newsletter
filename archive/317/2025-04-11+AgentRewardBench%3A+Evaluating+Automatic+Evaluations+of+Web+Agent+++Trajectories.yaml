date: "2025-04-11"
author: Xing Han LÃ¹
title: 'AgentRewardBench: Evaluating Automatic Evaluations of Web Agent   Trajectories'
thumbnail: ""
link: https://huggingface.co/papers/2504.08942
summary: The study introduces AgentRewardBench, a benchmark assessing the effectiveness of LLM judges in evaluating web agents, containing 1302 trajectories with expert reviews. It evaluates 12 LLM judges and finds none excel across all benchmarks, revealing a weakness in rule-based evaluations....
opinion: placeholder
tags:
    - ML
