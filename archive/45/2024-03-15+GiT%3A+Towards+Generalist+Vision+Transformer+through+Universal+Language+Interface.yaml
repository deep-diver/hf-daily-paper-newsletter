author: Haiyang Wang
date: '2024-03-15'
link: https://huggingface.co/papers/2403.09394
opinion: placeholder
summary: This paper proposes a framework called GiT that uses a single Transformer
  architecture to perform various vision tasks without the need for specific additions
  or task-specific fine-tuning. GiT is trained on multiple datasets and achieves strong
  results in zero-shot learning, showing promise for narrowing the gap between vision
  and language models....
tags:
- Computer Vision
- Deep Learning
- Natural Language Processing
- Optimization and Learning Algorithms
- Supervised Learning
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09394.png
title: 'GiT: Towards Generalist Vision Transformer through Universal Language Interface'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.09394/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.09394/paper.ko.html
