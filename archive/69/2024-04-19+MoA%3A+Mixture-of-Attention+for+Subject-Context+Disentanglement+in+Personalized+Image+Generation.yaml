date: "2024-04-19"
author: Kuan-Chieh
title: 'MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.11565.png
link: https://huggingface.co/papers/2404.11565
summary: The paper introduces a new architecture called Mixture-of-Attention (MoA) for personalizing text-to-image diffusion models. MoA splits the generation workload between a personalized branch and a non-personalized prior branch, and a routing mechanism manages the distribution of pixels to optimize the blend of personalized and generic content. MoA enhances the distinction between the model's pre-existing capability and the personalized intervention, offering more disentangled subject-context contr...
opinion: placeholder
tags:
    - Deep Learning
    - Computer Vision
    - Natural Language Processing
