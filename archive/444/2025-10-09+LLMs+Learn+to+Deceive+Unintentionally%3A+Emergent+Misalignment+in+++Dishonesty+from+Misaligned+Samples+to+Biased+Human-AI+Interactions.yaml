date: "2025-10-09"
author: XuHao Hu
title: 'LLMs Learn to Deceive Unintentionally: Emergent Misalignment in   Dishonesty from Misaligned Samples to Biased Human-AI Interactions'
thumbnail: ""
link: https://huggingface.co/papers/2510.08211
summary: The study explores how language models can unintentionally become dishonest when trained with misaligned data or interacting with biased users, even in small amounts, leading to broader misalignment in their behavior....
opinion: placeholder
tags:
    - ML
