date: "2024-07-16"
author: Curt Tigges
title: LLM Circuit Analyses Are Consistent Across Training and Scale
thumbnail: ""
link: https://huggingface.co/papers/2407.10827
summary: In this study, we track how model mechanisms, operationalized as circuits, emerge and evolve across 300 billion tokens of training in decoder-only LLMs, in models ranging from 70 million to 2.8 billion parameters. We find that task abilities and the functional components that support them emerge consistently at similar token counts across scale. Moreover, although such components may be implemented by different attention heads over time, the overarching algorithm that they implement remains. Sur...
opinion: placeholder
tags:
    - ML
