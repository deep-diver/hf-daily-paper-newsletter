date: "2024-10-11"
author: Mengzhao Chen
title: 'PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers in LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2410.05265
summary: PrefixQuant is a new method for quantizing Large Language Models that improves memory efficiency and inference speed. It identifies and isolates outlier tokens offline, simplifying quantization and outperforming previous methods....
opinion: placeholder
tags:
    - ML
