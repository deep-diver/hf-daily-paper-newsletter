date: "2024-05-29"
author: Roy Miles
title: 'VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections'
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.17991.png
link: https://huggingface.co/papers/2405.17991
summary: This paper proposes a memory-efficient algorithm for training and fine-tuning large language models by dividing tokens into smaller sub-tokens and projecting them onto a fixed 1-dimensional subspace during the forward pass. The algorithm is effective and complementary to state-of-the-art methods, outperforming QLoRA for fine-tuning LLaMA and showing competitive performance on the C4 dataset....
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
