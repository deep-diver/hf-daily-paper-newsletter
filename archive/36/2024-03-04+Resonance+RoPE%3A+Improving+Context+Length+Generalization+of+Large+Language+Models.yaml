author: Suyuchen Wang
date: '2024-03-04'
link: https://huggingface.co/papers/2403.00071
opinion: placeholder
summary: This paper proposes a method called Resonance RoPE to improve the performance
  of large language models on longer sequences, specifically addressing challenges
  in train-short-test-long scenarios. The method refines the interpolation of RoPE
  features for out-of-distribution token positions and shows improved results on both
  synthetic tasks and downstream long-text applications....
tags:
- Supervised Learning
- Natural Language Processing
- Deep Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/qByPs2NLhzwBzBwIVw9s1.png
title: 'Resonance RoPE: Improving Context Length Generalization of Large Language
  Models'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.00071/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.00071/paper.ko.html
