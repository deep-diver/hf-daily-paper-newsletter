author: Sahand Sharifzadeh
date: '2024-03-13'
link: https://huggingface.co/papers/2403.07750
opinion: placeholder
summary: The paper proposes a new approach to create synthetic image-text pairs using
  strengths of large language models and image generation models for efficient and
  effective training of Visual-Language Models. The method shows comparable performance
  with less data and is faster than synthesizing in pixel space....
tags:
- Deep Learning
- Computer Vision
- Natural Language Processing
thumbnail: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.07750.png
title: 'Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image
  Embeddings'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.07750/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2403.07750/paper.ko.html
