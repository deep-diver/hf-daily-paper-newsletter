date: "2025-03-31"
author: Alok Abhishek
title: 'BEATS: Bias Evaluation and Assessment Test Suite for Large Language   Models'
thumbnail: ""
link: https://huggingface.co/papers/2503.24310
summary: This study introduces BEATS, a framework for assessing bias, ethics, fairness, and factuality in large language models. They developed a bias benchmark using BEATS that measures performance across 29 metrics, including demographic, cognitive, and social biases, ethical reasoning, group fairness, and factuality. Their experiment results show that a significant portion of outputs from leading models contain bias, highlighting the risks of using these models in critical decision-making systems....
opinion: placeholder
tags:
    - ML
