date: "2025-10-09"
author: Wenjie Du
title: Which Heads Matter for Reasoning? RL-Guided KV Cache Compression
thumbnail: ""
link: https://huggingface.co/papers/2510.08525
summary: This study proposes a new method called RLKV to identify important heads in large language models that are crucial for reasoning, while compressing the less important ones to reduce cache size. The method uses reinforcement learning to optimize the relationship between each head's cache usage and reasoning quality, resulting in significant cache reduction and near lossless performance compared to uncompressed results....
opinion: placeholder
tags:
    - ML
