author: Jordi Grau-Moya
date: '2024-01-29'
link: https://huggingface.co/papers/2401.14953
opinion: placeholder
summary: This paper explores using meta-learning to its limits by amortizing the most
  powerful universal predictor, Solomonoff Induction, into neural networks through
  exposure to a broad range of patterns generated by Universal Turing Machines (UTMs).
  Results suggest that UTM data is valuable for meta-learning, and can be used to
  train neural networks capable of learning universal prediction strategies....
tags:
- Supervised Learning
- Unsupervised Learning
- Deep Learning
- Optimization and Learning Algorithms
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/GfKbUTI-puokUCecuKfAI.png
title: Learning Universal Predictors
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.14953/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.14953/paper.ko.html
