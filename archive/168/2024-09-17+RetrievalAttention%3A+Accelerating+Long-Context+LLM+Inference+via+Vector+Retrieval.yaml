date: "2024-09-17"
author: Di Liu
title: 'RetrievalAttention: Accelerating Long-Context LLM Inference via Vector Retrieval'
thumbnail: ""
link: https://huggingface.co/papers/2409.10516
summary: RetrievalAttention is a method that uses approximate nearest neighbor search (ANNS) to speed up the attention process in large language models (LLMs) by only accessing the most relevant data, reducing inference cost and GPU memory requirements while maintaining model accuracy. It can generate one token in 0.188 seconds on a single NVIDIA RTX4090 with 16GB of GPU memory for serving 128K tokens in LLMs with 8B parameters....
opinion: placeholder
tags:
    - ML
