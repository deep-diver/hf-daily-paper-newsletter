date: "2024-06-28"
author: Colin White
title: 'LiveBench: A Challenging, Contamination-Free LLM Benchmark'
thumbnail: ""
link: https://huggingface.co/papers/2406.19314
summary: LiveBench is a new benchmark for language models designed to be immune to test set contamination and biases introduced by human crowdsourcing or LLM judging. It contains frequently updated questions from recent sources, automatic scoring based on objective ground-truth values, and a variety of challenging tasks. LiveBench is more difficult than previous benchmarks, with top models achieving below 65% accuracy. The benchmark will be updated monthly and new tasks will be added over time to disting...
opinion: placeholder
tags:
    - ML
