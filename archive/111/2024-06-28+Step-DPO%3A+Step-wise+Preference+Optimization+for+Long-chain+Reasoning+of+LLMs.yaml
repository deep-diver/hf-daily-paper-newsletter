date: "2024-06-28"
author: Xin Lai
title: 'Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs'
thumbnail: ""
link: https://huggingface.co/papers/2406.18629
summary: Step-DPO is a method for improving mathematical reasoning in Large Language Models (LLMs) by optimizing individual reasoning steps. It uses feedback from humans and generates data to train models, resulting in a near 3% accuracy gain on MATH for models with over 70B parameters. Step-DPO outperforms other models on MATH and GSM8K test sets....
opinion: placeholder
tags:
    - ML
