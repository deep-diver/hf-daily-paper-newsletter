date: "2025-06-11"
author: Yantai Yang
title: 'EfficientVLA: Training-Free Acceleration and Compression for   Vision-Language-Action Models'
thumbnail: ""
link: https://huggingface.co/papers/2506.10100
summary: 'The authors present a framework called EfficientVLA that accelerates and compresses Vision-Language-Action models without requiring training. They achieve this by eliminating redundancies in the models through three strategies: pruning, optimizing visual processing, and caching intermediate features, resulting in faster inference and reduced computation with minimal impact on performance....'
opinion: placeholder
tags:
    - ML
