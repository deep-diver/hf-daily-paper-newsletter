date: "2024-06-26"
author: Aashiq Muhamed
title: 'Grass: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients'
thumbnail: ""
link: https://huggingface.co/papers/2406.17660
summary: Grass is a new method for training large language models (LLMs) that uses sparse projections to reduce memory usage and improve performance. It allows for half-precision pretraining of a 13B parameter LLaMA model on a single 40GB A100 GPU, and achieves up to a 2x throughput improvement on an 8-GPU system....
opinion: placeholder
tags:
    - ML
