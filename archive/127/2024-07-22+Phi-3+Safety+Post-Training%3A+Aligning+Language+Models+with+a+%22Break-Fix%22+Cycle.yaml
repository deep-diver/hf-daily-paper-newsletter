date: "2024-07-22"
author: Emman Haider
title: 'Phi-3 Safety Post-Training: Aligning Language Models with a "Break-Fix" Cycle'
thumbnail: ""
link: https://huggingface.co/papers/2407.13833
summary: This paper presents a methodology for safety aligning language models using a 'break-fix' cycle, which involves multiple rounds of dataset curation, safety post-training, benchmarking, red teaming, and vulnerability identification to cover various harm areas in both single and multi-turn scenarios. The results show that this approach improves the performance of the Phi-3 models across a wide range of responsible AI benchmarks....
opinion: placeholder
tags:
    - ML
