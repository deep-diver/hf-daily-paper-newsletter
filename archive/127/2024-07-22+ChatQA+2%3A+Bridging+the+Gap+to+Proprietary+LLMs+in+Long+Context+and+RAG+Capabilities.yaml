date: "2024-07-22"
author: Peng Xu
title: 'ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities'
thumbnail: ""
link: https://huggingface.co/papers/2407.14482
summary: ChatQA 2 is a Llama3-based model that bridges the gap between open-access LLMs and leading proprietary models in long-context understanding and retrieval-augmented generation capabilities. It achieves accuracy comparable to GPT-4-Turbo on many long-context understanding tasks and surpasses it on the RAG benchmark. The model's performance is improved by a three-stage instruction tuning process and a detailed continued training recipe to extend the context window of Llama3-70B-base from 8K to 128K...
opinion: placeholder
tags:
    - ML
