date: "2024-09-25"
author: Tianqi Liu
title: 'RRM: Robust Reward Model Training Mitigates Reward Hacking'
thumbnail: ""
link: https://huggingface.co/papers/2409.13156
summary: We propose a new method to train reward models for large language models that is more robust to artifacts in the data. Our method improves the accuracy of a reward model on RewardBench and enhances the performance of policy optimization tasks....
opinion: placeholder
tags:
    - ML
