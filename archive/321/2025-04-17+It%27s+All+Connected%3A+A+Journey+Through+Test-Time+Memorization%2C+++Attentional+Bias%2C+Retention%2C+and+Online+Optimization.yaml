date: "2025-04-17"
author: Ali Behrouz
title: 'It''s All Connected: A Journey Through Test-Time Memorization,   Attentional Bias, Retention, and Online Optimization'
thumbnail: ""
link: https://huggingface.co/papers/2504.13173
summary: 'The paper introduces a new way to conceptualize neural architectures as associative memory modules with an internal objective called attentional bias, and presents a framework called Miras to design deep learning architectures with four choices: associative memory architecture, attentional bias objective, retention gate, and memory learning algorithm. This leads to the creation of three new sequence models, Moneta, Yaad, and Memora, which outperform existing linear RNNs while maintaining a fast ...'
opinion: placeholder
tags:
    - ML
