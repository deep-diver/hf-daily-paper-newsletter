date: "2025-05-26"
author: Jeonghun Baek
title: 'MangaVQA and MangaLMM: A Benchmark and Specialized Model for Multimodal   Manga Understanding'
thumbnail: ""
link: https://huggingface.co/papers/2505.20298
summary: 'The study presents two tools for better understanding manga: MangaOCR for recognizing text in manga pages and MangaVQA for testing comprehension through visual questions. They also developed MangaLMM, a model trained on these tools, to improve the performance of large multimodal models in interpreting manga narratives, and compared its efficiency with other proprietary models....'
opinion: placeholder
tags:
    - ML
