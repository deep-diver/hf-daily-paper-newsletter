date: "2025-10-16"
author: Quan Nguyen-Tri
title: Attention Is All You Need for KV Cache in Diffusion LLMs
thumbnail: ""
link: https://huggingface.co/papers/2510.14973
summary: This study presents a new method called Elastic-Cache that reduces redundant computation and speeds up decoding in diffusion large language models by adaptively recomputing key-value caches, resulting in significant speedups and higher accuracy compared to existing methods....
opinion: placeholder
tags:
    - ML
