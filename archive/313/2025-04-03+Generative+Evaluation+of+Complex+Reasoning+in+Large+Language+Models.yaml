date: "2025-04-03"
author: Haowei Lin
title: Generative Evaluation of Complex Reasoning in Large Language Models
thumbnail: ""
link: https://huggingface.co/papers/2504.02810
summary: The authors propose KUMO, a generative evaluation framework that uses LLMs and symbolic engines to generate diverse and adjustable reasoning tasks for continuous assessment of LLM reasoning capabilities. They tested KUMO on 23 state-of-the-art LLMs and found that many LLMs outperform university-level performance on easy tasks, and reasoning-scaled LLMs reach university-level performance on complex tasks. KUMO tasks also correlate strongly with real-world reasoning benchmark results, establishing...
opinion: placeholder
tags:
    - ML
