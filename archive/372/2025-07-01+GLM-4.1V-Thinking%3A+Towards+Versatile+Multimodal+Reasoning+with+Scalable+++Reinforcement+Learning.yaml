date: "2025-07-01"
author: Wenyi Hong
title: 'GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable   Reinforcement Learning'
thumbnail: ""
link: https://huggingface.co/papers/2507.01006
summary: Researchers created a vision-language model called GLM-4.1V-Thinking, which can handle various tasks like problem-solving, video understanding, and coding, by using a large-scale pre-training method and a technique called Reinforcement Learning with Curriculum Sampling. This model, which is open-source, outperforms other similar-sized models and even some larger and closed-source models in many tasks....
opinion: placeholder
tags:
    - ML
