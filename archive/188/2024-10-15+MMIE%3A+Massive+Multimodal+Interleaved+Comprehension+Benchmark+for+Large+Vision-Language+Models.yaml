date: "2024-10-15"
author: Peng Xia
title: 'MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2410.10139
summary: The MMIE benchmark is a large-scale evaluation tool for testing how well machines can understand and generate both images and text in any order. It has 20,000 questions and can test many different skills, like math, coding, and art. The creators also made a new way to score the answers that is fair and reliable....
opinion: placeholder
tags:
    - ML
