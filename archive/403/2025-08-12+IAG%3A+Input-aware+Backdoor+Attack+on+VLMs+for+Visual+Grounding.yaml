date: "2025-08-12"
author: Junxian Li
title: 'IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding'
thumbnail: ""
link: https://huggingface.co/papers/2508.09456
summary: This study presents a new method called IAG to manipulate vision-language models in visual grounding tasks, making them focus on a specific target object regardless of the query. The attack is stealthy and effective, achieving over 65% accuracy on a large model and maintaining high performance on other models with minimal accuracy loss....
opinion: placeholder
tags:
    - ML
