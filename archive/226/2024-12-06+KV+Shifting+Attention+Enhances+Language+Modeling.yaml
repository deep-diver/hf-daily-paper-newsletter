date: "2024-12-06"
author: Mingyu Xu
title: KV Shifting Attention Enhances Language Modeling
thumbnail: ""
link: https://huggingface.co/papers/2411.19574
summary: This paper introduces a new method called KV shifting attention that enhances the language modeling capabilities of large models by reducing their requirements for depth and width. The method is proven to be beneficial for learning induction heads and language modeling, leading to better performance or faster convergence from toy models to models with over 10 billion parameters....
opinion: placeholder
tags:
    - ML
