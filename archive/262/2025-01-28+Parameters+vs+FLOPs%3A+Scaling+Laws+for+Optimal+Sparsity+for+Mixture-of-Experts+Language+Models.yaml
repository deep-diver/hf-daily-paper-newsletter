date: "2025-01-28"
author: Samira Abnar
title: 'Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models'
thumbnail: ""
link: https://huggingface.co/papers/2501.12370
summary: 'This work examines the relationship between scaling language models and two dimensions: parameters and FLOPs. The authors discover that there''s an optimal level of sparsity, which improves both training efficiency and model performance, when varying the sparsity level in sparse Mixture-of-Experts....'
opinion: placeholder
tags:
    - ML
