date: "2025-03-09"
author: Wei Li
title: 'FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation   for Feature Implementation'
thumbnail: ""
link: https://huggingface.co/papers/2503.06680
summary: The authors present FEA-Bench, a benchmark for evaluating large language models' ability to generate code for new features within existing repositories. They gather data from GitHub pull requests and use filters to focus on tasks related to feature development, pairing each task with unit tests to verify the solution, and find that LLMs face challenges in this repository-level incremental development....
opinion: placeholder
tags:
    - ML
