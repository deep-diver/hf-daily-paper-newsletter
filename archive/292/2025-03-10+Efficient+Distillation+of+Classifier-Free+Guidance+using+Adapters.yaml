date: "2025-03-10"
author: Cristian Perez Jensen
title: Efficient Distillation of Classifier-Free Guidance using Adapters
thumbnail: ""
link: https://huggingface.co/papers/2503.07274
summary: The paper presents adapter guidance distillation (AGD), a method that uses lightweight adapters to approximate classifier-free guidance (CFG) for conditional diffusion models, effectively doubling the sampling speed while maintaining or improving sample quality. Unlike other methods, AGD keeps the base model frozen and only trains minimal additional parameters (sim2%), making it more resource-efficient and accessible for training large models on a single consumer GPU....
opinion: placeholder
tags:
    - ML
