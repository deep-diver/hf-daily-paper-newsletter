date: "2025-03-10"
author: Yan Tai
title: 'REF-VLM: Triplet-Based Referring Paradigm for Unified Visual Decoding'
thumbnail: ""
link: https://huggingface.co/papers/2503.07413
summary: The authors propose REF-VLM, a unified framework for training various visual decoding tasks, addressing limitations in current MLLMs for dense prediction tasks and multi-task/multi-granularity scenarios. They introduce the Triplet-Based Referring Paradigm (TRP) for structured representation learning and create the Visual-Task Instruction Following Dataset (VTInstruct) with diverse visual prompts and units, demonstrating superior performance across standard benchmarks....
opinion: placeholder
tags:
    - ML
