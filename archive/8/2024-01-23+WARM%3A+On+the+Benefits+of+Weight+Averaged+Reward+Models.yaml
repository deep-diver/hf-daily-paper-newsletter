author: "Alexandre Ram\xE9"
date: '2024-01-23'
link: https://huggingface.co/papers/2401.12187
opinion: placeholder
summary: The paper proposes a method called Weight Averaged Reward Models (WARM) to
  mitigate reward hacking in large language models (LLMs) during reinforced learning.
  This method fine-tunes multiple RMs and averages them in the weight space. The paper
  claims that the strategy improves efficiency, reliability under distribution shifts,
  and robustness to preference inconsistencies. The experiment results on summarization
  tasks show that WARM improves the overall quality and alignment of LLM predictions....
tags:
- Supervised Learning
- Reinforcement Learning
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/T4eMvoGUt2g-EoLiQRDqP.png
title: 'WARM: On the Benefits of Weight Averaged Reward Models'
translated_paths:
  INT: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.12187/paper.en.html
  KR: https://raw.githack.com/deep-diver/hf-daily-paper-newsletter/main/translated-papers/2401.12187/paper.ko.html
