date: "2025-03-13"
author: Subhajit Maity
title: 'Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision   Transformers?'
thumbnail: ""
link: https://huggingface.co/papers/2503.10632
summary: This paper introduces Kolmogorov-Arnold Attention (KArAt), a novel learnable attention mechanism based on Kolmogorov-Arnold networks, and a more efficient variant, Fourier-KArAt, which outperforms or matches the performance of vanilla Vision Transformers on CIFAR-10, CIFAR-100, and ImageNet-1K datasets. The paper also compares the performance and generalization capacity of these architectures with vanilla ViTs through various analyses, such as loss landscapes, weight distributions, optimizer pat...
opinion: placeholder
tags:
    - ML
