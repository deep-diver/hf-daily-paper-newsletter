date: "2025-03-14"
author: Weiming Ren
title: 'Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers'
thumbnail: ""
link: https://huggingface.co/papers/2503.11579
summary: The proposed model, VAMBA, utilizes Mamba-2 blocks for encoding video tokens with linear complexity, enabling it to handle more than 1024 frames on a single GPU. Compared to transformer-based models, VAMBA offers at least 50% reduction in GPU memory usage during training and inference, doubles the speed per training step, and improves accuracy by 4.3% on the LVBench hour-long video understanding benchmark....
opinion: placeholder
tags:
    - ML
