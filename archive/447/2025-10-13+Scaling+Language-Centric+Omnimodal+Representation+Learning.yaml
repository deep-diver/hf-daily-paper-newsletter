date: "2025-10-13"
author: Chenghao Xiao
title: Scaling Language-Centric Omnimodal Representation Learning
thumbnail: ""
link: https://huggingface.co/papers/2510.11693
summary: This study explores why multimodal language models perform well and finds that their ability to align different types of data (like text and images) during pretraining is key. They then propose a new framework, LCO-Emb, which improves on this by further refining the model's understanding of various data types, leading to better performance across different tasks....
opinion: placeholder
tags:
    - ML
