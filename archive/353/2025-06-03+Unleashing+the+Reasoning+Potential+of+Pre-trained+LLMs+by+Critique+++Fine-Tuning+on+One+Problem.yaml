date: "2025-06-03"
author: Yubo Wang
title: Unleashing the Reasoning Potential of Pre-trained LLMs by Critique   Fine-Tuning on One Problem
thumbnail: ""
link: https://huggingface.co/papers/2506.03295
summary: This study presents a new method called Critique Fine-Tuning (CFT) that efficiently unlocks the reasoning potential of large language models (LLMs) by training them on only one problem. CFT uses diverse model-generated solutions and detailed critiques from teacher LLMs to improve performance on various reasoning tasks, requiring significantly less computational power than existing methods....
opinion: placeholder
tags:
    - ML
