date: "2024-07-26"
author: Rongwu Xu
title: 'Course-Correction: Safety Alignment Using Synthetic Preferences'
thumbnail: ""
link: https://huggingface.co/papers/2407.16637
summary: This paper studies the ability of large language models to avoid generating harmful content and proposes a method to improve this ability by fine-tuning the models with preference learning. The method involves creating a synthetic dataset with 750K pairwise preferences to teach models the concept of timely course-correction. Experiments show that the method effectively enhances course-correction skills without affecting general performance and improves the safety of large language models, partic...
opinion: placeholder
tags:
    - ML
