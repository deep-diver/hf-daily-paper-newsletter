date: "2025-08-12"
author: Jason Chou
title: 'AutoCodeBench: Large Language Models are Automatic Code Benchmark   Generators'
thumbnail: ""
link: https://huggingface.co/papers/2508.09101
summary: The researchers created a new method called AutoCodeGen to automatically generate high-difficulty, multilingual code generation datasets without manual annotations. They used this method to build AutoCodeBench, a large-scale benchmark for evaluating language models on challenging, diverse, and practical multilingual code generation tasks, and found that even advanced models struggle with these tasks....
opinion: placeholder
tags:
    - ML
