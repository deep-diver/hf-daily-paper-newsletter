<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 카메라 포즈의 관절 최적화를 위한 강건성 향상\n' +
      '\n' +
      '그리고 분해된 저순위 텐서 복사 필드\n' +
      '\n' +
      ' 위천추 보우유\n' +
      '\n' +
      '국립양명차오퉁대학교\n' +
      '\n' +
      'tomas1999.ee06@nycu.edu.tw, walon@cs.nctu.edu.tw, yulunliu@cs.nycu.edu.tw.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '본 논문에서는 2차원 영상만을 수퍼비전(super supervision)으로 사용하여 분해된 저순위 텐서로 표현되는 카메라 자세와 장면 기하를 관절로 정제할 수 있는 알고리즘을 제안한다. 먼저, 우리는 1D 신호를 기반으로 파일럿 연구를 수행하고 본 연구 결과를 복셀 기반 NeRF에 대한 순진한 조인트 포즈 최적화가 차선책 솔루션으로 쉽게 이어질 수 있는 3D 시나리오와 연관시킨다. 또한, 주파수 스펙트럼 분석을 기반으로 관절 카메라 포즈 최적화를 가능하게 하는 coarse-to-fine 훈련 스케줄을 위해 2D 및 3D radiance 필드에 컨볼루션 가우시안 필터를 적용하는 것을 제안한다. 분해된 저순위 텐서에서의 분해 특성을 이용하여 계산 오버헤드가 거의 없는 무차별 힘 3D 컨볼루션과 동등한 효과를 얻는다. 관절 최적화의 견고성과 안정성을 더욱 향상시키기 위해, 우리는 또한 평활화된 2D 감독, 랜덤하게 스케일링된 커널 파라미터 및 에지-유도 손실 마스크의 기술을 제안한다. 광범위한 정량적 및 정성적 평가는 제안된 프레임워크가 최적화를 위한 신속한 수렴뿐만 아니라 새로운 뷰 합성에서 우수한 성능을 달성함을 보여준다. 소스 코드는 [https://github.com/Nemo1999/Joint-TensoRF](https://github.com/Nemo1999/Joint-TensoRF)에서 사용할 수 있다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '최근, 신경망 렌더링은 고품질의 새로운 뷰 합성을 위해 널리 사용되는 방법이 되었다. 선구자로서의 NeRF[11]는 미분 가능한 볼륨 렌더링으로 훈련된 다층 퍼셉트론(MLP)에 구축된 암시적 연속 함수로서 3D 복사 필드를 나타낸다. NeRF는 우수한 합성 품질을 달성하는 동안 계산 비용이 많이 드는 MLP의 밀집된 평가로 인해 훈련/추론 비효율성을 겪는다.\n' +
      '\n' +
      '이를 위해, 3D 복셀 그리드[22, 14, 15]의 명시적 장면 표현에 기초하여 구축된 복셀 기반 방법들이 원래의 MLP 기반 NeRF보다 더 빠른 트레이닝을 달성하고 더 나은 렌더링 품질을 제공하기 위해 제안되며, 따라서 다운스트림 애플리케이션들에 대해 더 선호되는 선택들이 된다.\n' +
      '\n' +
      '그럼에도 불구하고, 조밀한 3D 복셀 그리드를 유지하는 것은 차례로 메모리 집약적이며, 따라서 여전히 복셀 기반 방법의 광범위한 적용을 제한한다. 다행히도, TensoRF[14]는 조밀한 3D 그리드를 _분해된 저순위 텐서_로 대체함으로써 복셀 그리드의 이러한 메모리 집약적인 문제를 해결할 것을 제안한다. TensoRF는 높은 데이터 압축률과 낮은 계산 비용을 동시에 달성하는 동시에 최첨단 성능을 달성한다. 메모리 사용과 계산 효율에 대한 윈-윈 상황을 제공하는 분해된 저순위 텐서 아키텍처는 최근 많은 작업[23, 13, 14, 15, 16, 17, 18, 19]에서 널리 채택되었다.\n' +
      '\n' +
      '한편, NeRF(및 전술한 대부분의 작업)의 효과는 입력 이미지의 정확한 카메라 포즈에 달려 있으며, 이는 종종 COLMAP[12]와 같은 SfM( Structure-from-Motion) 알고리즘을 사용하여 계산된다. 일부 작업[22, 13, 14]은 원래 MLP 기반 NeRF에서 공동으로 카메라 포즈 및 장면 표현을 최적화함으로써 느리고 때때로 부정확한 COLMAP 프로세스를 우회하는 것을 목표로 하지만, 이들의 성공은 종종 훈련 초기에 3D 복사 필드의 평활성을 보장하는 MLP 아키텍처의 스펙트럼 편향[20]과 연관된다. 그러나 복셀 기반 방법은 이러한 특성이 부족하고 날카로운 모서리를 과도하게 강조할 수 있으므로 순진한 관절 최적화가 국소 최적화에 갇히는 문제가 있다. 2(a)).\n' +
      '\n' +
      '이 연구에서는 분해된 저순위 텐서(cf. 그림 1)를 사용하여 카메라 포즈와 3D 장면을 정제하는 간단하면서도 효과적인 방법을 제시한다. 우리가 확인한 바로는\n' +
      '\n' +
      '그림 1: ** 분해된 텐서에 강건한 관절 포즈 정제. 제안된 방법은 3D 텐서 볼륨과 2D 감독 영상에 가우시안 필터의 효율적인 _separable component-wise convolution_를 적용하여 카메라 포즈의 조인트 최적화 및 분해된 복셀 표현을 가능하게 한다.** 주파수 스펙트럼을 제어하는 것은 포즈 정렬에 필수적인 반면, 조밀한 3D 그리드에서 이러한 제어를 직접 실현하는 것은 계산적으로 어려울 뿐만 아니라 자명하지 않거나 도전적일 수 있다. 이를 위해 스펙트럴 제어를 가능하게 하기 위해 _component-wise separable convolution_를 이용한 효율적인 3D 필터링 방법을 소개한다. 이는 입력 신호의 separability를 추가적으로 활용함에 따라 전통적으로 잘 알려진 _separable convolution kernel_보다 효율적이다. 최적화 과정에서 안정성을 더욱 보장하기 위해, 우리는 _smoothed 2D supervision_, _randomly scaleed kernel paramter_ 및 _edge-guided loss mask_를 포함한 몇 가지 기술을 제안한다. 이러한 기술은 절제 연구에서 성공적인 자세 정제에 실험적으로 중요한 것으로 입증되었다. 결과에서, 제안된 방법은 50k개의 트레이닝 반복만을 필요로 하며, 여기서 이전의 모든 방법들은 전형적으로 200k개의 반복을 필요로 한다(예를 들어, 이전의 MLP-기반 방법들에 비해 전체 트레이닝 시간이 25%로 감소된다). 이러한 장점은 복셀 기반 아키텍처의 특성을 기반으로 할 뿐만 아니라, 단일 재사용 복셀 그리드만을 필요로 하는 세심하게 설계된 효율적인 스펙트럼 필터링 알고리즘에 의존한다(Sec. 4.3 참조). 또한, 본 논문에서 제안하는 방법은 새로운 뷰 합성에서 최첨단의 방법에 비해 좋은 성능을 보인다. 우리의 기여는 3배입니다\n' +
      '\n' +
      '* 1D 파일럿 연구를 통해 3D 장면의 스펙트럼 특성이 선행 연구에서 논의된 coarse-to-fine 휴리스틱을 넘어 관절 최적화의 수렴에 미치는 영향에 대한 통찰력을 제공하고 특별히 설계된 효율적인 컴포넌트-와이즈 컨볼루션 알고리즘을 기반으로 하는 학습 전략을 제안한다.\n' +
      '* 공동 최적화의 견고성을 향상시키기 위해, 우리는 평활화된 2D 감독, 스케일링된 커널 파라미터 및 에지-유도 손실 마스크의 기술을 도입한다.\n' +
      '* 훈련 시간은 기존 MLP 기반 방법에 비해 25% 감소하며, 이전 방법 200k에 대해 50k 반복만 필요하다. 결과는 알려지지 않은 포즈를 가진 새로운 뷰 합성에서 최첨단 성능을 보여준다.\n' +
      '\n' +
      '##2 관련 업무\n' +
      '\n' +
      '**Accelerating Neural Rendering.** 신경렌더링의 중요한 작업으로서, NeRF는 3D 장면의 암시적 표현을 구성하기 위해 MLP를 채택하여 고품질 뷰 합성을 제공하지만 MLP의 계산 요구로 인해 시간이 많이 소요되는 트레이닝 프로세스를 갖는다. 이러한 문제를 해결하기 위해, 장면 정보가 국부적으로만 분배되는 커스텀 공간 데이터 구조를 사용하기 위해 NeRF의 상이한 변형들이 제안되며, 여기서 이러한 공간 데이터 구조는 _point cloud_[23, 24], _space partitioning tree_[25, 26], _triangular mesh_[10, 27], 및 _voxel grid_[26, 27, 28, 15를 포함한다. 이러한 변형들 중에서, 복셀 그리드는 용이한 구현 및 품질 재구성으로 인해 더 대중화되었다. 그러나 장면 차원이 커짐에 따라 복셀 그리드의 메모리 사용이 비효율적으로 된다. 이를 해결하기 위해 [26]은 해시 인코딩을 통해 그리드를 압축할 것을 권장하고, [10, 28]은 3D 특징 압축을 위해 텐서 분해를 채택할 것을 제안하며, 이 방법은 주로 [10]을 기반으로 하지만 K-Planes [11]과 같은 다른 텐서 분해 기반 복셀 구조에 적응할 수 있다.\n' +
      '\n' +
      '**LP 기반 NeRFs에 대한 조인트 포즈 추정**[25]는 신경 복사 필드에서 기울기 전파를 사용하여 카메라 포즈를 직접 조정함으로써 카메라 포즈 추정 및 3D 장면 표현 학습의 조인트 문제를 해결하려는 최초의 NeRF 기반 시도 중 하나이다. 이러한 관절 최적화의 견고성은 [12, 26]에 의해 더욱 향상되며, 여기서 그들은 기본 MLP로부터 유도된 포즈 기울기를 평활화하기 위한 다양한 방법들을 제안한다. [10] 특수하게 설계된 로컬-글로벌 조인트 정렬 접근법에 의해 노이즈 내성을 더욱 증가시킨다. 이 방법은 또한 관절 문제를 해결하지만 분해된 저순위 텐서 아키텍처를 기반으로 하는 복셀 기반 NeRF를 위해 특별히 설계되었다.\n' +
      '\n' +
      '**분해된 저순위 텐서에 대한 포즈 추정** 분해된 저순위 텐서 [13, 28]에 카메라 포즈를 최적화하는 작업이 존재하지만 풍부한 추가 지오메트리 단서(예를 들어, 깊이 맵 및 광학 흐름)를 필요로 한다. 우리가 아는 한, 우리는 2D 이미지 감독만을 사용하여 카메라 포즈와 _분해된 저순위 텐서를 공동으로 최적화하려는 첫 번째 시도이다.\n' +
      '\n' +
      '**Pose Estimation on Multi-Resolution Hash Encoding.** Aside from decomposed low-rank 텐서, _multi-resolution hash encoding_ is another compressed voxel-based architecture proposed by [24]. 이러한 아키텍처의 선택과 함께, 최근 [1]은 카메라 포즈의 공동 최적화 및 다중 해상도 해시 인코딩을 해결하기 위해 제안되었다. 그들은 부드러운 그래디언트를 제공하여 해시 볼륨의 그래디언트 변동을 방지하는 새로운 보간 방식을 제안한다.\n' +
      '\n' +
      '그림 2: **순진한 관절 포즈 최적화와 복셀 기반 NeRFs에 대한 제안된 방법의 비교.**(a) 복셀 기반 NeRFs에 관절 최적화를 선택적으로 적용하면 복셀 볼륨의 조기 고주파 신호가 카메라 포즈를 국부 최소값에 고정되도록 저주하므로 극적인 실패가 발생한다. (b) 분해된 텐서에 대해 가우시안 필터의 _separable component-wise convolution_를 수행하여 복사 필드의 스펙트럼을 직접 제어하는 계산적으로 효과적인 방법을 제안한다. 제안된 학습 기법은 조인트의 최적화가 더 나은 해로 성공적으로 수렴할 수 있도록 한다.\n' +
      '\n' +
      '각 해상도 레벨에서 해시 테이블의 학습률을 제어하는 커리큘럼 학습 방식. 공동 최적화에 대해 인상적인 결과를 얻었지만, 그 방법의 효과는 다중 해상도 해시 인코딩에 제한되고 _분해된 저-랭크 텐서_에는 적용되지 않는다. 제안된 분리 가능한 컴포넌트-와이즈 3D 컨볼루션(및 랜덤 스케일링된 커널)은 _분해된 저-랭크 텐서_에 대해 특별히 설계되고 _다중 해상도 해시 인코딩_에는 직접 적용되지 않으며, 이 두 표현들은 각각의 장단점을 갖는다.\n' +
      '\n' +
      '##3 우리가 제안한 방법\n' +
      '\n' +
      '### 3D 장면 및 포즈의 합동 정제\n' +
      '\n' +
      'Radiance Field Reconstruction을 위한 볼륨 렌더링(Volume Rendering for Radiance Field Reconstruction.** NeRF)의 신경 볼륨 렌더링을 기반으로 3차원 장면에 대한 기하학 및 외관에 대한 복사필드는 MLP로 구현된 \\(F_{\\sigma}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{1}\\) 및 \\(F_{c}:\\mathbb{R}^{6}\\rightarrow\\mathbb{R}^{3}\\)의 두 함수를 통해 표현되며, 여기서 \\(F_{\\sigma}\\)은 입력 3차원 좌표의 볼륨 밀도를 반환하고, \\(F_{c}\\)은 입력 3차원 좌표에서 색상을 출력한다. 2차원 좌표(u\\)에 균일한 형태의 화소를 렌더링하기 위해 먼저 카메라 중심\\(\\vec{c}\\in\\mathbb{R}^{3}\\)과 광선 방향\\(\\vec{d_{u}}=K^{-1}\\bar{u}\\)으로 정의되는 카메라 광선을 따라 3차원 좌표(\\(N\\)3차원 좌표(\\{s_{n}\\}_{n=1\\cdots N}\\)의 시퀀스를 샘플링하고,\n' +
      '\n' +
      '\\[\\{s_{n}\\}_{n=1\\cdots N}=s(\\vec{c},\\vec{d_{u})=\\{\\vec{c}+t_{n}\\cdot\\vec{d_{u}\\}_{n=1\\cdots N},\\tag{1}\\}\n' +
      '\n' +
      '여기서 \\(K\\)은 고유 카메라 행렬이고 \\(\\{t_{n}\\}_{n=1\\cdots N}\\)은 뷰 절두체의 가까운 평면과 먼 평면 사이의 깊이 축을 따라 등거리 분포된 \\(N\\) 샘플이다. 화소의 결과색은 볼륨렌더링 수식 [13, 12]를 사용하여 밀도장\\(F_{\\sigma}\\)과 컬러장\\(F_{c}\\)을 통해 적분하여 구하며, 여기서 우리는 함수\\(\\mathbf{V}\\)에 의한 _discretized 볼륨렌더링 적분을 나타낸다:\n' +
      '\n' +
      '\\[\\mathbf{V}(F_{\\sigma},F_{c},s(\\vec{c},\\vec{d_{u}}))=\\sum_{s_{n}\\in s(\\vec{c},\\vec{d}}T_{n}\\cdot\\alpha_{n}\\cdot\\mathbff{C}_{n}, \\tag{2}\\}}\n' +
      '\n' +
      '여기서 \\(T_{n}=exp(-\\sum_{j=1}^{n}\\delta_{j}F_{\\sigma}(s_{j}))\\)는 \\(s_{n}\\) 이전의 누적 투과율을 나타내고, \\(\\alpha_{n}=1-exp(-\\delta_{n}F_{\\sigma}(s_{n}))\\)는 샘플 \\(s_{n}\\)의 불투명도를 나타내며, \\(\\mathbf{c}=F_{c}(s_{n},\\\\vec{d_{u}\\)는 샘플 \\(s_{n}\\)의 색상을 나타내며, \\(\\delta_{j}=\\|s_{j}-s_{j-1}\\|\\)는 두 인접 샘플 사이의 유클리드 거리를 나타낸다.\n' +
      '\n' +
      'NeRF의 일반적인 설정에서, 2차원 측광 재구성의 손실(\\(\\mathbffI}=\\left\\{I_{1},\\cdots,I_{L}\\right\\})을 줄이기 위해 경사도 기반 최적화 알고리즘을 사용하여 2차원 측광 재구성의 손실(\\(\\mathbffP}=\\left\\{P_{1},\\cdots,P_{L}\\right\\},\\cdots,P_{L}\\right\\\\\\mathfrak{se}(3)\\)을 최소화하는 Lie algebra(parametrizing rigid 3D transformation as \\(\\mathfrak{se}(3)\\)를 입력으로 하여 [10]과 [10]으로 표현되는 3차원 장면을 재구성하는 것을 목표로 한다.\n' +
      '\n' +
      '\\[\\mathcal{L}_{\\text{rec}(F_{\\sigma},F_{c})=\\sum_{i=1}^{L}\\sum_{u\\in\\mathbf{U}\\|\\mathbf{V}(F_{\\sigma},F_{c},\\mathcal{W}_{\\text{id}(P_{i},s(\\vec{0},\\vec{d_{u}})))-I_{iu}\\|, \\tag{3}\\tag{3}}}\n' +
      '\n' +
      '여기서 \\(\\mathbb{R}^{3}\\)은 입력 영상에서 가능한 모든 2D 좌표의 집합이고, \\(I_{i}\\in\\mathbb{R}^{3}\\(I_{i}\\), 와핑 함수 \\(\\mathcal{W}_{\\text{3d}}(P,\\_):\\mathbb{R}^{3}\\)은 \\(P\\in\\mathfrak{se}(3)\\)에 의해 매개변수화된 강성 3D 변환을 수행하고, \\(\\mathcal{W}_{\\text{3d}(P,s(\\vec{0},\\vec{d}}))는 각 샘플 3D 좌표를 카메라 광선의 3D 샘플 좌표로 매핑한다. 이것은 형상-방사 모호성(shape-radiance ambiguity)을 겪는 비포화된 재구성 문제임에 유의한다[13].\n' +
      '\n' +
      '**3D Joint Optimization.** 카메라 포즈(카메라 포즈 \\(\\mathbf{P}\\)가 또한 알려지지 않은) 및 학습 장면 표현[10, 11, 12, 13, 14]을 공동으로 추정하는 것에 관한 경우, 문제는 현재 Eq로부터 확장되는 목적으로 더욱 불분명하다. 도 3에 있어서, 다음과 같이 정의된다.\n' +
      '\n' +
      '\\[\\mathcal{L}_{\\text{joint}}(F_{\\sigma},F_{c},\\mathbf{P})=\\sum_{i=1}^{L}\\sum_{u\\in \\mathbf{U}}\\|\\mathbf{V}(F_{\\sigma},F_{c},\\mathcal{W}_{\\text{3d}}(P_{i},s(\\vec{0},\\vec{d_{u})))-I_{iu}\\|. \\tag{4}\\|.\n' +
      '\n' +
      '이러한 접합 최적화는 \\(\\{F_{\\sigma},F_{c}\\}\\}\\)의 기본 표현의 구조적 편향에 의해 크게 영향을 받는데, Sec. 3.2에서 보다 간단한 1D 사례를 통해 파일럿 연구를 수행할 것이다.\n' +
      '\n' +
      '###1D 신호 정렬을 위한 가우시안 필터\n' +
      '\n' +
      '여기서 우리는 식 4에서 \\(F_{c}\\), \\(F_{\\sigma}\\) 및 \\(\\mathbf{I}\\)의 신호 스펙트럼의 영향을 분석하는 것을 목표로 한다. 를 포함하는 것을 특징으로 하는 공동 최적화 방법. 우리는 카메라 포즈와 장면 재구성의 3D 조인트 최적화를 신호 정렬의 더 간단한 1D 대응물로 줄이는 것으로 시작한다.\n' +
      '\n' +
      '**1D 신호 정렬.** 표적 지상진리 1D 신호 \\(f_{GT}\\)(신호가 연속적이고 경계가 있으며 유한한 지지력을 갖는다고 가정)을 고려하자. 접지진리신호 \\(f_{1}\\), \\(f_{1}=\\mathcal{W}_{\\text{1d}}(f_{GT},p_{1}), \\(f_{2}=\\mathcal{W}_{\\text{1d}}(f_{GT},p_{2})\\)와 \\(\\mathcal{W}_{\\text{1d}}(f,p)(x)=f(x-p)\\)로 정의되는 신호변환연산 \\(\\mathcal{W}_{\\text{1d}}(f,p)(x)=f(x-p)\\), 그리고 \\(p_{1},p_{2}\\)이 변환값이다.\n' +
      '\n' +
      '이러한 1차원 환경에서 재구성은 하찮지만, 3차원 결합 최적화의 경우를 모방하기 위해 반복적 기울기 기반 재구성 손실 최적화를 채택하여 신호\\(g\\)와 변환 값\\(q_{1}\\) 및 \\(q_{2}\\)을 추정하고자 한다.\n' +
      '\n' +
      '\\mathcal{L}_{\\text{1d}(g,q_{1},q_{2})&=\\sum_{i\\in[1,2]}\\int\\mathcal{W}_{\\text{ld}(g,q_{i})(x)-f_{i}(x)\\|^{2}dx\\\\\\&=\\sum_{i\\in[1,2}}\\int\\g(x)-f_{GT}(x-p_{i}+q_{i})\\|^{2}dx.\\end{split}\\tag{5}\\text{5}\\text{l}(g,q_{i})(x)-f_{i}(x)\\text{2}dx.\\end{split}\\tag{5}\\text{l}(g,q_{i})(x)-f_{i}(x)\n' +
      '\n' +
      '참고로 Eq. 5 및 Eq. 4는 구조/제형의 측면에서 유사하며, 여기서 차이는 차원에만 있다. 그리고 \\(\\mathcal{L}_{\\text{1d}\\)는 \\(q_{1}-q_{2}=p_{1}-p_{2}\\)과 \\(g\\) = \\(\\mathcal{W}_{\\text{1d}}(f_{GT},p_{1}-q_{1})\\)일 때 최적값을 달성한다. 수학식 5의 간단한 시각적 표현을 위해 그림 3(a)를 확인하십시오. 여기서 \\(f_{1}\\)과 \\(f_{2}\\)은 재구성 손실 \\(\\mathcal{L}_{text{1d}}\\)에 의해 \\(g\\)에 연결됩니다. \\(g\\)과 변환 값 \\(\\{q_{1},q_{1}\\}\\)을 업데이트하기 위해 기울기가 사용되는 파란색 화살표입니다.\n' +
      '\n' +
      '1D 신호 정렬과 3D 조인트 최적화 사이의 연결 1D 신호 정렬의 공식화는 2D 단면에서 조인트 카메라 포즈 정렬 및 3D 장면 재구성의 "국소 현상"을 효과적으로 시뮬레이션한다. 여기서 우리는 두 카메라 평면을 통과하고 투영된 직선 상에서 각 카메라 평면과 교차하는 3D 공간의 두 이웃 카메라 포즈를 고려하고, 이러한 투영된 라인 상의 RGB 색상 값은 수학식 5의 1D 시프트된 그라운드 진리 신호 \\(f_{1}\\), (f_{2}\\), 단면 상의 복사율 필드의 값은 수학식 5의 재구성된 신호 \\(g\\)와 유사하게, 카메라 평면 상의 투영된 라인 및 3D 복사율 필드에서의 대응하는 단면은 볼륨 렌더링 함수 \\(V\\) 및 재구성 손실 \\(\\mathcal{L}_{\\text{joint}}\\)에 의해 동시에 많은 1D 신호 분석을 수행하는 것으로 직관적으로 볼 수 있다.\n' +
      '\n' +
      '**Spectrum Analysis and Effect of Gaussian Filtering on 1D Signal Alignment.** 먼저 voxel grid (cf. our supplement for detailed derived of theorem):\n' +
      '\n' +
      '**정리 1**: _우리가 신호\\(g\\)의 빠른 수렴을 가정한다면(즉, \\(g\\)는 local optima\\(g^{*}\\) w.r.t current\\(q_{1},q_{2}\\)을 갱신할 때마다 w.r.t current\\(q_{1},q_{2}\\) w.r.t current\\(q_{1},q_{2}\\)을 달성한다), 우리는 Eq.5의 문제가 두 지상진리 신호 사이의 순수 정렬과 동일하다는 것을 발견했다.\n' +
      '\n' +
      '{split}\\mathcal{L}_{\\text{1d}(g,q_{1},q_{2})& =\\mathcal{L}_{\\text{1d}(g^{*},q_{1},q_{2})\\\\&=\\mathcal{L}_{\\text{1d}(u)=\\int\\lVert f_{GT}(x)-f_{GT}(x+u) \\rVert^{2}dx,\\end{split}\\tag{6}\\text{6}}(g^{*},q_{1},q_{2})\\\\&=\\mathcal{L}_{\\text{1d}(u)=\\int\\lVert f_{GT}(x)-f_{GT}(x+u)\\rVert^{2}dx,\\end{split}\\tag{6}\\text{6}}(g^{*},q_{1},q_{2}}=\\mathcal\n' +
      '\n' +
      '\\(u=(p_{1}-p_{2})-(q_{1}-q_{2})\\)의 초기값을 갖는 두 접지진리 신호 사이의 이동\n' +
      '\n' +
      '우리는 기울기 기반 최적화를 통해 \\(u\\)에 도달하는 것을 목표로 한다.\n' +
      '\n' +
      '다음으로, \\(f_{GT}\\)과 최적화 기울기 \\(\\frac{d}{du}\\mathcal{L}_{\\text{1d}\\)의 스펙트럼 특성을 분석하여 다음과 같은 결과를 얻었다.\n' +
      '\n' +
      '**정리 2**: \\[\\frac{d}{du}\\mathcal{L}_{\\text{1d}}=\\int\\lVert\\mathfrak{F}[f_{GT}]\\rVert^{2}\\cdot H(u,k)\\;dk,\\] (7)\n' +
      '\n' +
      '\\(u,k)=4\\pi k\\;sin(2\\pi ku)\\), \\(\\mathfrak{F}[f_{GT}]\\)는 \\(f_{GT}\\)의 푸리에 변환이고 \\(k\\)는 주파수 영역에서 파수이다. 특히 반복최적화의 방향을 결정하는 \\(\\frac{d}{du}\\mathcal{L}_{\\text{1d}\\)의 부호에 관심이 있다. 그림에서 \\(H(u,k)\\)의 값을 표시한다. 3(b)(_Top_)에서 우리는 \\(k\\)의 크기가 작을 때 \\(H\\)의 부호가 잘 행해진다는 것을 관찰할 수 있다(여기서 잘 행해진다는 것은 \\(u\\)의 방향이 \\(0\\)으로 내려갈 수 있다는 것을 의미하며, 즉 \\(u>0\\)일 때 양수이고 \\(u<0\\)일 때 음수이다). 그러나 \\(k\\)이 증가하면 \\(H\\)의 부호가 빠르게 교대하기 시작하고 크기가 증가하여 기울기가 크고 잡음이 발생한다. 따라서 확산 스펙트럼이 있는 고주파 신호는 최적화 과정을 쉽게 유도하여 국소 최적화에 고착될 수 있다.\n' +
      '\n' +
      '이를 위해 가우시안 필터를 신호 \\(f_{GT}\\)에 적용하면 원래의 \\(H\\) 함수의 부호 대체 문제를 효과적으로 완화할 수 있음을 보인다. 구체적으로, 입력 신호를 필터링하는 것이 가우시안 윈도우(cf. 도출을 위한 우리의 보충제)에 의해 \\(H\\) 변조하는 것과 동등하다는 것을 보여준다:\n' +
      '\n' +
      '3**orem 3**: _Let\\(\\tilde{\\mathcal{L}}_{\\text{1d}\\)는 가우시안 컨볼루트 신호로 계산된 \\(\\mathcal{L}_{\\text{1d}\\)을 나타내고, \\(\\mathfrak{F}[\\mathcal{N}]]\\)는 가우시안 커널 \\(\\mathcal{N}\\)의 푸리에 변환을 나타낸다.\n' +
      '\n' +
      '\\[\\frac{d}{du}\\tilde{\\mathcal{L}_{\\text{1d}}=\\int\\lVert\\mathfrak{F}[f_{GT}]\\rVert^{2}\\cdot\\tilde{H}(u,k\\;dk, \\tag{8}\\)\n' +
      '\n' +
      '\\(\\tilde{H}(u,k)=\\parallel\\mathfrak{F}[\\mathcal{N}]\\parallel^{2}\\cdot H(u,k)\\).\n' +
      '\n' +
      '인 것을 특징으로 하는 반도체 소자의 제조 방법. 3(b)(_Bottom_), 우리는 변조 \\(\\tilde{H}(u,k)\\)을 플로팅하고, 잘못된 행동 영역이 억제됨을 관찰한다(여기서 \\(\\mathcal{N}\\)의 분산을 \\(4\\)으로 설정함). 경사 하강은 초기 크기 \\(u\\)이 \\(6.0\\)보다 작으면 \\(u=0\\)으로 수렴할 것이다. \\(\\frac{d}{du}\\tilde{\\mathcal{L}_{\\text{1d}\\)이 잘 거동하는 영역은 _quasi-convex_이고, 우리가 안장점에 갇히는 것을 방지하는 적절한 학습률이 주어지면 전역 최적으로 수렴하는 것이 보장된다. 우리의 분석은 (Lin et al., 2021)과 (Hee et al., 2023)의 거친 훈련 일정 뒤에 있는 동기와 일치한다. 구체적으로, \\(u,k)\\)에서 잘 형성된 영역은 \\(u\\)이 \\(0\\)(cf)에 가까워질수록 더 넓어지는 것을 관찰한다. 도. 3(b)(_Top_)), 이는 \\(u\\)가 \\(0\\)에 접근함에 따라 가우시안 커널의 필터링 강도를 느슨하게 하여 더 크고 정확한 기울기를 유도할 수 있음을 의미한다.\n' +
      '\n' +
      '###2D 평면 이미지 정렬\n' +
      '\n' +
      '기존 연구들(Lin et al., 2021; Chng et al., 2022)은 3차원 관절 최적화 문제 외에도, 기존 연구들(Lin et al., 2021; Chng et al., 2022)도 3차원 관절 최적화 문제를 고려하고 있다.\n' +
      '\n' +
      '도 3: **스펙트럼 분석 및 1D 신호 정렬에 대한 가우시안 필터링의 효과.**(a) 1D 신호 정렬 비교: 노이즈 신호는 가우시안 필터링 없이 로컬 최적에 갇힐 수 있다. (b)(_Top_) Eq. \\(H(u,k)\\)의 시각화. 도 7을 참조하면, \\(k\\)이 \\(0\\)에서 이탈함에 따라 교대 부호를 나타내며, 신호에 고주파 에너지가 너무 많으면 기울기 기반 최적화에서 잘못된 방향을 유발한다. (b)(_Bottom_) Eq. \\(\\tilde{H}(u,k)\\)의 시각화. 8은 가우시안 필터의 도움으로 \\(\\mathcal{N}\\)의 변조 버전인 \\(H(u,k)\\)이다. (c) 1D 정렬은 Eq.에서의 3D 조인트 최적화에 관한 것이다. 4에서 효과적인 포즈 개선은 특정 단면의 1D 정렬에서 비롯되며 3D 장면의 빨간색 선은 수평 이동(파란색 화살표) 및 회전(녹색 화살표)과 상관관계가 있다.\n' +
      '\n' +
      '2D 이미지 패치 정렬 작업은 2D 호모그래피에 의해 변환되기 전에 단일 그라운드 진리 이미지(I_{gt}\\)에서 잘라낸 \\(L_{24}\\) 겹침 이미지 패치(\\mathbf{I}_{\\text{2d}}=\\{I_{1},\\cdots,I_{L_{\\text{2d}}}\\})가 있는 조인트 최적화의 간단한 예이다. 호모그래피 변환은 \\(\\mathbf{P}_{\\text{2d}}=\\{P_{1},\\cdots,P_{L_{\\text{2d}}}\\}\\}in\\mathfrak{sl}(3)\\)에 의해 매개변수화되고 \\(\\vec{0}\\)으로 초기화된다(여기서는 [11]의 Lie algebra를 사용하여 2D 호모그래피 변환을 매개변수화한다. 수학식 4와 유사하게 재구성 손실에 의해 2차원 영상 콘텐츠\\(F_{\\text{2d}:\\mathbb{R}^{2}\\rightarrow\\mathbb{R}^{2}\\)와 패치당 호모그래피 워프\\(\\mathbf{P}_{\\text{2d}\\)을 공동으로 최적화하는 것을 목표로 한다. 조인트 최적화는 다음과 같이 공식화될 수 있다:\n' +
      '\n' +
      '\\[\\mathcal{L}_{\\text{2d}}(F_{\\text{2d}},\\mathbf{P}_{\\text{2d}})=\\sum_{i=1}^{L}\\sum_{u\\in\\text{U}_{\\text{2d}}}\\|F_{\\text{2d}(\\mathcal{W}_{\\text{2d}}(P_{i}, u})-I_{iu}\\|^{2}, \\tag{9}}}\n' +
      '\n' +
      '여기서 \\(\\mathbf{U}_{\\text{2d}\\)는 이미지 패치에서 가능한 모든 2D 좌표의 집합이고, \\(I_{i}\\)은 입력 이미지 패치에서 위치 \\(u\\)의 픽셀의 색상, \\(I_{i}\\), warp 함수 \\(\\mathcal{W}_{\\text{2d}}(P_{i},.):\\mathbb{R}^{2}\\rightarrow\\mathbb{R}^{2}\\)는 \\(P_{i}\\in\\mathfrak{sl}(3)\\)에 의해 매개된 2D 호모그래피 변환을 수행하며, \\(I_{gt}\\(I_{i},u)\\)의 2D 좌표 \\(u\\)을 패치에서 변환된 2D 좌표로 매핑한다. Eq 사이의 강력한 구조적 일치에 주목하십시오. 5(1D 정렬), Eq. 도 9(2D 정렬), 및 Eq. 도 4(3D 정렬)에서, 세 가지 문제는 유사한 계산 특성을 공유한다.\n' +
      '\n' +
      '우리는 2D 분해된 저순위 텐서\\(\\mathcal{T}_{\\text{2d}}\\in\\mathbb{R}^{h\\times w}\\)에 의해 \\(F_{\\text{2d}}\\)을 매개변수화하는데, 여기서 \\(w,h\\)은 영상의 차원이다. 섹션 3.2의 분석에 의해, 우리는 과적합을 피하기 위해 2D 가우시안 커널로 \\(\\mathcal{T}_{\\text{2d}}\\)을 필터링한다.\n' +
      '\n' +
      '(\\mathbf{x})=(\\mathcal{N}_{\\text{2d}}*_{\\text{2d}})(\\mathbf{x})=(\\mathcal{N}_{\\text{2d}}*_{\\text{2d}}(\\sum_{r=1}^{R}\\mathbf{v}_{r}^{X}\\otimes\\mathbf{v}_{r}^{Y})(\\mathbf{x}), \\tag{10}\\text{x}}\n' +
      '\n' +
      '여기서 \\(\\mathbf{x}\\in\\mathbb{R}^{2}\\)은 2D 픽셀 좌표, \\(\\mathcal{N}_{\\text{2d}}\\)은 2D 가우스 커널, \\(*_{\\text{2d}}\\)은 컨볼루션 연산자, \\(\\otimes\\)은 1D 벡터 성분 \\(\\mathbf{v}_{r}^{X}\\in\\mathbb{R}^{w},\\mathbf{v}_{r}^{r}^{Y}\\in\\mathbb{R}^{h}\\) 사이의 외부 곱을 나타낸다. 표현식의 끝에서 "\\(\\mathbf{(x)}\\)"은 연속된 좌표 \\(\\mathbf{x}\\)으로 앞의 이산 2차원 볼륨을 쌍선형 보간하는 것을 의미한다. 제안된 방법은 기존의 방법[11, 12]과 순진한 텐서 방법보다 우수한 성능을 보였으며, 실험 결과는 Sec. 4.1에서 확인할 수 있었다.\n' +
      '\n' +
      '가우스 커널의 폭\\(\\mathcal{N}_{\\text{2d}}\\)은 연속적으로 변화하는 지수적 coarse-to-fine 훈련 스케줄에 의해 제어된다. 이산 가우스 커널 상에서 연속적인 변화하는 폭을 지원하기 위해, 커널은 다음의 규칙에 의해 생성된다:\n' +
      '\n' +
      '{N}_{\\text{1d}}(\\sigma) =\\begin{cases}\\bigoplus_{x=-L_{\\mathcal{N}/2}^{L}{\\mathcal{N}/2} min(1,\\frac{1}{\\sqrt{2\\pi\\sigma}}e^{-\\text{1d}}(\\sigma)\\mathcal{N}_{\\text{2d}}(\\sigma)\\mathcal{N}{x=-L_{\\mathcal{N}}/2}\\delta[x]&\\text{ otherwise},\\end{cases}\\text{if}\\migoplus_{x=-L_{\\mathcal{N}}/2}^{L}{\\mathcal{N}}/2}}\\text{n}}(\\sigma)\\mathcal{N}_{\\text{1d}}(\\sigma),\\end{cases}\\migoplus_{x=-L_{\\mathcal{N}}/2}}\n' +
      '\n' +
      '여기서 \\(L_{\\mathcal{N}\\)은 이산 커널의 크기이고, \\(\\mathcal{N}_{\\text{1d}}(\\sigma)\\in\\mathbb{R}^{L_{\\mathcal{N}}\\)은 연속 가우시안 분포로부터 이산적으로 샘플링되고 \\(\\oplus\\) 연산자에 의해 벡터에 연결되기 전에 \\(1.0\\)의 최대값으로 클램핑된다. 수치적 불안정성을 피하기 위해 \\(\\sigma<0.001\\)일 때, 우리는 \\(\\mathcal{N}_{\\text{1d}}(\\sigma)\\)을 이산 임펄스 함수 \\(\\delta\\)으로 할당한다. 2D 커널\\(\\mathcal{N}_{\\text{2d}(\\sigma)\\in\\mathbb{R}^{L_{\\mathcal{N}}\\times L_{\\mathcal{N}}}\\times L_{\\mathcal{N}}\\)은 두 개의 1D 커널의 외부 곱에 의해 생성된다.\n' +
      '\n' +
      '### 분해된 저순위 텐서\n' +
      '\n' +
      '이 절에서는 TensoRF[11]에 의해 제안된 분해된 저순위 텐서에 대해 설명하며, 이는 우리가 제안한 방법이 기반으로 하는 장면 표현이다. [11]에서 고려되는 텐서 분해에는 CP-분해와 VM-분해의 두 가지 유형이 있지만, 우리의 논의에서는 주로 _VM-분해_에 초점을 맞추고 있지만, 우리의 방법은 CP-분해에도 당연히 적용할 수 있다.\n' +
      '\n' +
      '3차원 밀도장\\(F_{\\sigma}\\)을 표현하기 위해, 우리는 3차원 텐서\\(\\mathcal{T}_{\\sigma}\\in\\mathbb{R}^{I\\times J\\times K}\\)에 정보를 저장하고, 이 정보는 현재 (F_{\\sigma}\\(\\mathcal{T}_{\\sigma}\\)의 성분별 보간법으로 간단히 정의된다.\n' +
      '\n' +
      '\\mathcal{T}_{\\sigma}=\\sum_{r=1}^{\\mathbf{R}\\mathbf{M}_{\\sigma,r}^{X}\\otimes\\mathbf{M}_{\\sigma,r}^{Y,Z}+\\mathbf{v}_{\\sigma,r}^{Y}\\otimes\\mathbf{M}_{sigma,r}^{X,Z}+\\mathbf{v}_{\\sigma,r}^{Z}\\otimes\\mathbf{M}_{\\sigma,r}^{X,Y}, \\tag{12}\\mathbf{M}_{\\sigma,r}^{X,Y}\\mathbf{M}_{\\sigma,r}^{Z}\\otimes\\mathbf{M}_{\\sigma,r}^{X,Y}, \\tag{12}\\mathbf{M}_{\\sigma,r}^{X,Y}\\mathbf{M}_\n' +
      '\n' +
      '여기서 \\(\\mathbf{R}\\)는 분해의 구성요소 수, \\((\\mathbf{v}_{r}^{X},\\mathbf{v}_{r}^{Y},\\mathbb{v}_{r}^{Z})\\in(\\mathbbb{R}^{I},\\mathbb{R}^{R}^{I},\\mathbb{R}^{M}^{R}^{I},\\mathbb{R}^{R}^{K})는 벡터와 행렬 사이의 외부 곱이다.\n' +
      '\n' +
      '3차원 컬러 필드\\(F_{c}\\)을 표현하기 위해 3차원 특징 텐서\\(\\mathcal{T}_{c}(\\mathbf{x})\\in\\mathbb{R}^{G}\\)에서 질의된 정보\\(\\mathcal{T}_{c}\\in\\mathbb{R}^{I\\times J\\times K\\times G}\\)를 작은 MLP\\(S\\)에 의해 RGB 컬러 값으로 디코딩한다(\\(G\\)는 입력 특징 차원이다. 구현은 다음과 같이 공식화될 수 있다.\n' +
      '\n' +
      '\\[F_{c}(\\mathbf{x},\\vec{d})=\\mathbf{S}(\\mathcal{T}_{c}(\\mathbf{x}),\\vec{d}) \\tag{13}\\]\n' +
      '\n' +
      '\\(\\mathcal{T}_{c}=\\sum_{r=1}^{\\mathbf{R}}\\mathbf{v}_{c,r}^{X}\\otimes\\mathbf{M}_{ \\sigma,r}^{Y,Z}\\otimes\\mathbf{b}_{r}^{X}+\\)\n' +
      '\n' +
      '(\\mathcal{T}_{c}(\\mathbf{x})\\)는 3차원 좌표 \\(\\mathbf{x}\\)에서 텐서 부피 \\(\\mathcal{T}_{c}\\)의 성분별 선형 보간을 나타낸다. \\mathcal{T}_{c}\\ (\\vec{d}\\)\'s the viewing direction of the current ray. \\ (\\mathbf{v}_{c,r}\\) 및 \\(\\mathbf{M}_{\\sigma,r}\\)는 \\(\\mathbf{v}_{\\sigma,r}\\) 및 \\(\\mathbf{M}_{\\sigma,r}\\) 대응물과 동일한 형상을 가지며, \\(\\mathbf{b}_{r}^{X},\\mathbf{b}_{r}^{Y},\\mathbbb}^{R}^{G}\\(\\mathcal{T}_{c}\\)의 특징축을 확장하기 위한 특징성분이다.\n' +
      '\n' +
      '### 분리 가능한 컴포넌트-와이즈 컨볼루션\n' +
      '\n' +
      'Sec. 3.2에서 이론적으로 분석하고 그림 3.2에서 경험적으로 보여준다. 2(a)는, 순진하게 저-순위 분해 텐서(학습된 신호의 스펙트럼을 제한하는 내부 바이어스가 결여되어, 따라서 도 3의 상부 로우에 대응하는)를 적용하는 단계를 포함한다. 합동 카메라 포즈 최적화는 차선책 재구성 품질 및 부정확한 포즈를 초래한다. 따라서 본 논문에서는 조대-미세 훈련 스케줄에 따라 복사 필드\\(F_{\\sigma}\\)와 \\(F_{c}\\)의 스펙트럼을 제한하는 방법을 제안한다.\n' +
      '\n' +
      '만약 우리가 3차원 가우시안 커널을 3차원 볼륨\\(\\mathcal{T}_{\\sigma}\\)과 순진하게 컨볼빙하면, (식 10의 2차원 평면 경우와 같이) 우리는 컨벌루션을 적용하기 전에 전체 3D 텐서를 재구성해야 하며, 분해된 저순위 텐서의 공간 압축 이점을 파괴하고, Eq를 참조해야 한다. 14.\n' +
      '\n' +
      '\\[F_{\\sigma}(x,y,z)=(\\mathcal{N}_{\\text{3d}}*_{\\text{3d}}\\mathcal{T}_{\\sigma})(x,y,z), \\tag{14}\\]\n' +
      '\n' +
      '여기서 \\(*_{\\text{3d}}\\)는 3D 컨벌루션을 나타내고, \\(\\mathcal{N}_{\\text{3d}\\)은 \\(\\mathcal{N}_{\\text{1d}}\\otimes\\)\\(\\mathcal{N}_{\\text{2d}}\\)에 의해 정의되는 3D 가우시안 필터이다. 이 환경에서 시간 복잡도와 공간 복잡도는 각각 \\(O(I\\cdot J\\cdot K\\cdot L_{\\mathcal{N}}^{3})\\)와 \\(O(I\\cdot J\\cdot K}}^{3})이며, 여기서 \\(L_{\\mathcal{N}}\\)은 각 차원에서의 3차원 가우시안 커널의 크기이다.\n' +
      '\n' +
      '3D 분해된 저순위 텐서 볼륨에서 계산적으로 효율적인 컨벌루션을 달성하기 위해, 우리는 다음의 아이덴티티(보충 자료에서 정확성이 입증될 사람)를 이용하여 제안된 _separable component-wise convolution_를 수행한다.\n' +
      '\n' +
      '*theorem 4**: \\[\\tilde{\\mathcal{T}_{\\sigma}=\\sum_{r=1}^{\\mathbf{R}}\\tilde{\\sigma, r}^{X}\\otimes\\tilde{\\mathbf{M}}_{\\sigma, r}^{Y,Z}+\\tilde{\\tilde{\\sigma,r}^{X,Z}+\\tilde{\\tildbf{M}_{\\sigma,r}^{Z}{\\otimes\\tilde{\\sigma,r}^{X,Z}+\\tilde{\\mathbf{v}}_{\\sigma,r}^{Z}{\\otimes\\tilde{\\sigma,r}^{X,Z}+\\tilde{\\mathbf{M}_{\\sigma,r}^{Z}\\tilde{\\sigma,r}^{X,Z}\\tilde{\\sigma,r}^{Z}\\tilde{\\sigma,r}^\n' +
      '\n' +
      '\\(\\tilde{\\mathcal{T}}_{\\sigma}=(\\mathcal{N}_{\\text{3d}\\ast_{\\text{3d}\\mathcal{T}{\\sigma})))는 3차원 가우시안 컨볼루트 텐서 볼륨을 나타내고,\\(\\tilde{\\mathbf{v}_{\\sigma,r}=(\\mathcal{N}_{\\text{1d}\\ast_{\\text{1d}\\tilde{\\sigma,r}}\\tilde{\\sigma,r})는 2차원 가우시안 컨볼루트 행렬 성분을 나타내고,\\(\\tilde{\\mathbf{M}}\\tilde{\\sigma,r}}\\tilde{\\sigma,r})는 2차원 가우시안 컨볼루트 행렬 성분을 나타낸다. 즉, **3D 컨벌루트 텐서는 개별적으로 컨벌루트된 성분**의 구성으로 표현될 수 있는데, 이는 분해된 저순위 텐서의 개별 성분에 걸쳐 3D 가우시안 컨벌루트를 분배할 수 있게 해준다. Sec. 3.4와 유사하게 밀도장의 값은 가우시안 복잡한 성분들, 즉 \\(\\tilde{F_{\\sigma}(\\mathbf{x})=\\tilde{\\mathcal{T}_{\\sigma}(\\mathbf{x})로부터 선형적으로 샘플링된다. 마찬가지로, 컬러 필드 \\(F_{c}\\)의 스펙트럼 제한 버전을 다음과 같이 얻을 수 있다.\n' +
      '\n' +
      'tilde{F_{c}(\\tilde{T}_{c}(\\mathbf{x}),\\tilde{d}=\\sum_{r=1}^{\\mathbf{r}^{Y}+\\tilde{c,r}^{x,Z}\\otimes\\mathbf{b}_{c,r}^{y,Z}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf{m}}_{c,r}\\otimes\\mathbf\n' +
      '\n' +
      '각 질의 샘플([1]에서 원래의 분해된 텐서와 동일)에 대한 계산량을 [1]에서 2D 가우시안 컨벌루션으로 분리한다고 가정)을 계산하기 위해 필요한 시간 복잡도는 \\(O(I\\cdot J\\cdot L_{\\mathcal{N}}+J\\cdot K\\cdot L_{\\mathcal{N}}+K\\cdot I\\cdot L_{\\mathcal{N}})\\)이며, 3D 복사필드의 필터링에 필요한 계산량을 크게 감소시킨다.\n' +
      '\n' +
      '본 논문에서 제안하는 컴포넌트-와이즈 컨볼루션은 신호 처리 문헌에서 분리된 커널 컨볼루션의 전통적인 기법과 **different**라는 점을 강조한다. 일반적인 분리된 커널 기법은 입력 신호 자체의 분리성을 이용하지 않고 3D 커널만을 분리하므로 3D 볼륨에 대한 3개의 1D 컨볼루션 연산을 순차적으로 수행해야 한다는 점에서, 전통적인 기법의 시간 복잡도는 \\(O(I\\cdot J\\cdot K\\cdot L_{\\mathcal{N}})\\)이고, 또한 컨볼루션 결과를 저장하기 위해 \\((I\\cdot J\\cdot K)\\)의 공간 복잡도를 갖는 3차원 메모리가 필요하다.\n' +
      '\n' +
      '포즈 강인성을 높이기 위한### 기법\n' +
      '\n' +
      '여기에서 우리는 조인트 카메라 포즈 최적화 및 복사 필드 재구성을 개선하는 순진한 분해된 저순위 텐서에 대한 개선 사항을 요약한다.\n' +
      '\n' +
      '3.5 Sec.에서 효율적인 3D 컨벌루션 알고리즘을 사용하여 3D 래디언스 필드(\\(\\tilde{F}_{\\sigma},\\tilde{F}_{c}\\)에 Eq.의 커널 파라미터(\\(\\sigma\\)를 제어하여 coarse-to-fine 3D 스케줄을 적용한다. 11)의 가우스 커널은 10k 반복에서 0으로 지수적으로 감소되고 이후 0으로 유지된다(\\(\\sigma\\)의 상세한 설정에 대해서는 보충을 참조하기 바란다.\n' +
      '\n' +
      '**Smoothed 2D Supervision.** Sec. 3.2의 분석에 영감을 받아, 우리는 스케줄링된 2D 가우시안 커널들의 병렬 세트로 2D 트레이닝 이미지를 블러링하는 것이 또한 조인트 최적화에 도움이 된다는 것을 발견했다. 한편으로, 평활화된 감독 이미지는 평활화된 이미지 구배를 생성하고 카메라 정렬을 안정화한다. 한편, 평활화된 트레이닝 이미지는 또한 학습된 3D 장면의 스펙트럼을 제한하는 데 도움이 된다. 2차원 학습 영상을 평활화하기 위한 가우시안 스케줄은 3차원 복사 필드와 유사하다.\n' +
      '\n' +
      '**무작위로 축척된 커널 파라미터 및 에지 유도 손실.** Sec. 3.2의 이전 스펙트럼 분석에서 더 큰 커널이 더 강한 변조로 이어지므로 항상 더 강력한 포즈 등록을 초래한다는 인상을 가질 수 있다. 그러나, \\(u,k)\\)의 크기가 \\(0\\)에 접근함에 따라 선형적으로 감소하기 때문에 이것은 항상 사실인 것은 아니다. 그림 1에 나와 있습니다. 3(b) 변조된 \\(\\tilde{H}\\)의 크기는 \\(H\\)의 크기보다 약하며, 이는 \\(\\frac{d}{du}\\tilde{L}_{\\text{1d}\\)이 \\(\\frac{d}\\mathcal{L}_{\\text{1d}\\)보다 약하므로 잡음의 영향을 더 쉽게 받는다는 것을 의미한다. 3D 경우에, 지나치게 공격적인 필터링에 의해 야기된 이러한 _weak 및 노이즈 그래디언트 문제_는 트레이닝 이미지들에서 중요한 에지 신호들을 파괴하여 포즈 정렬이 실패하게 하는 과도한 블러 효과에 대응한다. Fig.를 참조한다. 도 4(b) 상기 얇은 에지 정보가 제거되는, 오버-강도 커널에 의해 블러링된 상기 이미지의 시각화에 대해, 상기 카메라 포즈가 랜덤하게 드리프트되게 하는 단계를 포함하는, 방법.\n' +
      '\n' +
      '_weak 및 noisy gradient problem_의 효과에 기초하여, _coarse-to-fine 3D schedule_ 및 _smoothed 2D supervision_만을 적용할 때, 상이한 실세계 장면 구조들 상에서 단일-크기 커널을 사용하는 것이 불충분하다는 것을 발견했다(여기서 동일한 커널은 한 장면에서 지나치게 공격적일 수 있지만 다른 장면에서 지나치게 완만할 수 있음). 따라서, 우리는 \\([0,1]\\)에서 균일하게 샘플링된 팩터에 의해 커널을 랜덤하게 스케일링하는 _randomly scaleed kernel_을 소개한다. 랜덤 스케일은 3D 가우시안 커널(레이디언스 필드의 경우)과 2D 가우시안 커널(트레이닝 이미지의 경우) 사이에서 독립적으로 샘플링되어 서로 다른 크기의 커널의 조합이 조인트 최적화를 안내할 수 있다. Fig.를 참조한다. 도 4(c)는 랜덤하게 샘플링된 커널의 범위에 의해 필터링된 동일한 입력 이미지의 시각화를 위한 도면. 우리는 랜덤하게 샘플링된 커널 척도를 교대로 사용할 때 훈련 일정이 더 견고해짐을 관찰한다.\n' +
      '\n' +
      '약하고 잡음인 기울기 문제를 완화하기 위한 또 다른 방법은 _edge guided loss_로, 에지 영역의 픽셀들에서 학습률을 1.5배 증가시키고(따라서 기울기 신호를 증폭시키고), 이로부터 포즈 정렬을 위한 학습 신호가 주로 온다. 그림 1의 시각화를 참조하십시오. 도 4의 (d)를 참조하면, 필터링된 2차원 영상에 소벨 필터[1]을 이용하여 검출된 에지 영역을 노란색으로 컬러링한다. 에지-가이드 렌더링 손실은 조인트 최적화가 트레이닝 이미지들의 에지 영역에 더 집중하는 것을 돕고, 그 결과 더 강건한 포즈 최적화를 야기한다. 경험적으로 우리는 이 가장자리 유도 척도를 다른 모든 훈련 반복에 교대로 적용한다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:7]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:8]\n' +
      '\n' +
      'rough 시도들은 BARF의 설정을 시뮬레이션하거나 디코더를 GARF 네트워크로 대체하기 위해 MLP 디코더 입력에 위치 인코딩 스케줄을 추가하려고 시도한다. 우리는 LLFF 데이터 세트에서 무작위로 선택된 4개의 장면에 대한 실험을 수행한다. 결과는 탭에 나와 있습니다. 5는 성공적인 훈련을 달성하기 위해 제안된 방법의 효능과 적절성을 입증한다.\n' +
      '\n' +
      '다른 저역 통과 필터를 사용하여 모든 공간 방향을 따라 동일한 필터링 강도를 가지기를 원형으로 대칭적이고 분리 가능한 유일한 커널(신호 처리에서 잘 알려진 특성)이기 때문에 본 논문에서는 가우시안 필터를 사용한다. 그럼에도 불구하고, 우리는 다른 저역 통과 필터로 실험한다. 탭으로 보고합니다 6은 LLFF 포트리스 장면에서 박스 필터(즉, 대표적인 저역 통과 필터)를 사용하는 성능으로 가우시안 필터를 사용하면 얻을 수 있는 이점을 명확하게 관찰할 수 있다.\n' +
      '\n' +
      '무작위로 축척된 커널 매개변수 적용_* * 및 _Edge Guided Loss_ on Synthetic Scenes. 두 기술은 원래 복잡한 실세계 장면의 견고성을 향상시키기 위해 제안되었지만, Tab. 7에 도시된 바와 같이 합성 장면의 성능을 해치지 않고 포즈 추정을 약간 향상시키기도 한다.\n' +
      '\n' +
      '민감도 w.r.t. 포즈 초기화.우리는 가우시안 잡음의 다양한 분산 \\(\\sigma\\)을 통해 포즈 초기화에 대한 민감도 분석을 수행하기 위해 블렌더 데이터 세트에서 의자 장면을 채택한다. 결과는 탭에 표시됩니다. 도 8을 참조하면, BARF와 제안된 방법은 모두 카메라 포즈의 노이즈 초기화에 대해 일정한 견고성을 보여준다.\n' +
      '\n' +
      '### Time Complexity\n' +
      '\n' +
      '인 것을 특징으로 하는 반도체 소자의 제조 방법. 7, 우리는 _Synthetic NeRF_ 데이터 세트에서 평균 PSNR 및 훈련 반복에 대한 이전 방법과 비교한다. 그림은 (1) 빠른 수렴과 (2) 고품질의 새로운 뷰 합성이라는 두 가지 장점을 보여준다.\n' +
      '\n' +
      '초기 단계의 흐릿한 감독은 최적화 후반에 상세한 구조 재구성을 방해하여 최종 결과 품질에 영향을 미칠 수 있다. 제안된 방법은 학습된 3D 장면 스펙트럼 특성에 영향을 주기 위해 간접 방법(예: [11]의 학습률), [10]의 인코딩 크기)을 사용하는 이전 방법과 달리 스펙트럼 도메인에 걸쳐 3D 콘텐츠의 원활하고 빠른 전환(연속 지수 커널 스케줄에 의한)을 가능하게 하는 직접 제어 가능한 커널 파라미터를 갖는 3D 필터를 적용함으로써 이 문제를 해결한다. 또한, 제안된 효율적인 컴포넌트-위즈 컨볼루션 알고리즘에 의해 제어된 거친-대-미세 스케줄에서 한 번만 훈련되는 단일 복셀 그리드를 사용하도록 신중하게 설계되어 더 빠른 수렴을 유도하며, 이에 비해 복셀 기반 표현을 사용하는 [11]은 서로 다른 해상도의 다중 복셀 그리드에서 순차적인 커리큘럼 학습이 요구되어 우리보다 4배 더 많은 훈련 반복이 발생한다.\n' +
      '\n' +
      '## 5 Conclusion\n' +
      '\n' +
      '본 논문의 기여도는 3배이다: 1)_이론적으로, 3D 장면 속성이 선행 연구(예: BARF, Heo _et al._2023)에서 논의된 coarse-to-fine 휴리스틱을 넘어 관절 최적화의 수렴에 미치는 영향에 대한 통찰력을 제공하여 카메라 포즈와 3D 복사 필드의 관절 최적화를 개선하기 위한 필터링 전략을 제공한다. 2) _Algorithmically_, 분해된 저순위 텐서에 대한 파일럿 연구의 필터링 전략을 적용하기 위한 효과적인 방법을 도입(및 동등성 입증)하고, 입력 신호의 분리성을 추가적으로 활용함에 따라 제안된 _separable component-wise convolution_가 전통적으로 잘 알려진 _separable convolution kernel_의 트릭보다 더 효율적임을 주목하고, 또한 제안된 방법이 복잡한 실세계 장면에서 더 나은 성능을 발휘하도록 하기 위해 _randomly-scaled kernel parameter_, _blurred 2D supervision_, _edge-guided loss mask_와 같은 다른 기법들을 제안한다. 3) 종합적인 평가는 제안된 프레임워크의 최신 성능과 알려진 포즈 없이 빠른 수렴을 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c c} \\hline \\hline Filter & Rot. \\(\\downarrow\\) & Trans. \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & SSIM \\(\\uparrow\\) & LPIPS \\(\\downarrow\\) \\\\ \\hline Box filter & 9.98 & 0.06 & 20.18 & 0.387 & 0.165 \\\\ Gaussian filter & 0.46 & 0.004 & 29.49 & 0.874 & 0.063 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: **저역 통과 필터에 대한 절제.**\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c|c c c} \\hline \\hline  & \\(\\sigma\\) & \\(0.125\\) & \\(0.15\\) & \\(0.175\\) & \\(0.2\\) \\\\ \\hline \\multirow{2}{*}{BARF} & Rotation \\(\\downarrow\\) & 0.094 & 0.068 & 0.100 & 0.108 \\\\  & Translation \\(\\downarrow\\) & 0.004 & 0.004 & 0.005 & 0.005 \\\\ \\hline \\multirow{2}{*}{Ours} & Rotation \\(\\downarrow\\) & 0.07 & 0.062 & 0.072 & 0.066 \\\\  & Translation \\(\\downarrow\\) & 0.003 & 0.003 & 0.003 & 0.002 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: 합성 장면**에서 _Random Scaled Kernel Parameter_와 _Edge Guided Loss_ 적용에 대한 **Ablation\n' +
      '\n' +
      '도 7: **PSNR 및 트레이닝 반복 비교.**\n' +
      '\n' +
      '## Acknowledgments\n' +
      '\n' +
      '이 작업은 국가과학기술위원회(NSTC) 111-2628-E-A49-018-MY4, 112-2221-E-A49-087-MY3, 112-2222-E-A49-004-MY2, 그리고 대만 교육부(MoE)의 고등교육 새싹 프로젝트의 지원을 받는다. 특히 류유룬은 대만 MoE의 유산 영 펠로우 프로그램을 인정하고 있다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* A. Chen, Z. Xu, A. Geiger, J. Yu, and H. Su(2022)Tensorf: tensorial radiance field. The Proceedings of the European Conference on Computer Vision (ECCV), Cited by: SS1, SS2.\n' +
      '*Y. 천진 천진 왕규 장영 곽용 Shan, and F. Wang (2023) local-to-global registration for bundle-adjusting neural radiance field. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '*Z. 천태호 Funkhouser, P. Hedman, and A. Tagliasacchi(2023)MobileNeRF: 모바일 아키텍처에서 효율적인 신경 필드 렌더링을 위해 폴리곤 래스터화 파이프라인을 이용한다. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* S. 장승 라마싱헤, J. 쉐라, S. Lucey (2022)Gaussian activated neural radiance field for high fidelity reconstruction and pose estimation. The Proceedings of the European Conference on Computer Vision (ECCV), Cited by: SS1, SS2.\n' +
      '* S. Fridovich-Keil, G. Meanti, F. R. Warburg, B. Recht, and A. Kanazawa(2023)K-plane: 명시적인 우주 광야. 시간, 외모 In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* S. Fridovich-Keil, G. Meanti, F. R. Warburg, B. Recht, and A. Kanazawa(2023)K-plane: 명시적인 우주 광야. 시간, 외모 In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* S. 프리도비치-킬, A. 유만 탄식 Chen, B. Recht, and A. Kanazawa(2022)Plenoxels: radiance field without neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '*R. 고승 다왈 Saini, and P. J. Narayanan(2022)StyleTRF: stylizing tensorial radiance fields. 컴퓨터 비전에 관한 제13차 인도 회의의 회보에서, 그래픽 및 이미지 처리, 인용: SS1, SS2.\n' +
      '*K. 한우 Xiang (2023)Multiscale 텐서 분해 및 뷰 합성을 위한 렌더링 방정식 인코딩. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* P. Hedman, P. P. Srinivasan, B. Mildenhall, J. T. Barron, and P. Debevec(2021) baking neural radiance field for real-time view synthesis. The Proceedings of the IEEE International Conference on Computer Vision (ICCV), Cited by: SS1, SS2.\n' +
      '*H. 허태 김준석 Kim, H. J. Kim, and J. Kim (2023) Robust camera pose refinement for multi-resolution hash encoding. ICML(International Conference on Machine Learning)의 Proceedings에서: SS1, SS2에 의해 인용된다.\n' +
      '*T. 허진 서록 추, J. Jia(2023)TriVol: 트리플 볼륨을 통한 포인트 클라우드 렌더링. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* J. T. Kajiya and B. P. Von Herzen (1984)Ray tracing volume density. 컴퓨터 그래픽입니다. 인용: SS1, SS2.\n' +
      '*N. 카노풀로스 Vasanthavada, and R. L. Baker (1988) Design of image edge detection filter using the sobel operator. IEEE Journal of solid-state circuits. 인용: SS1, SS2.\n' +
      '* J. 컬하넥 and T. Sattler (2023)Tetra-neRF: 사면체를 이용한 신경 복사 필드를 나타낸다. ArXiv:2304.09987. 인용: SS1, SS2.\n' +
      '* C. Lin, W. 마, A. 토랄바, S. Lucey(2021)BARF: 번들 조정 신경 복사 필드. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), Cited by: SS1, SS2.\n' +
      '* L. 류정구 Chua, and C. Theobalt(2020)Neural sparse voxel field. 신경 정보 처리 시스템(NeurIPS)의 발전 인용: SS1, SS2.\n' +
      '*Y. Liu, C. Gao, A. Muleman, H. Tseng, A. Saraf, C. Kim, Y. Chuang, J. Kopf, and J. Huang (2023) Robust dynamic radiance field. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* A. Muleman, Y. Liu, C. Gao, J. Huang, C. Kim, M. H. Kim, and J. Kopf (2023)Progressively optimized local radiance field for robust view synthesis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* B. Mildenhall, P. Srinivasan, M. Tancik, J. T. Barron, R 라마모오르티, R. Ng(2020)NeRF: 뷰 합성을 위한 신경 래디언스 필드로서 장면들을 나타낸다. The Proceedings of the European Conference on Computer Vision (ECCV), Cited by: SS1, SS2.\n' +
      '*T. Muller, A. Evans, C. Schied, and A. Keller (2022)Instant neural graphics primitives with multiresolution hash encoding. TOG(ACM Transactions on Graphics) 인용: SS1, SS2.\n' +
      '* J. L. Schonberger and J. Frahm (2016)Structure-from-motion 재방문. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '*R. 샤오진 정희두, 유희주, 장희주, 그리고 Y Liu(2023)Tensor4D: 고충실도 동적 재구성 및 렌더링을 위한 효율적인 신경 4D 분해. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* C. Sun, M. Sun, and H. Chen (2022)Direct voxel grid optimization: super-fast convergence for radiance field reconstruction. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Cited by: SS1, SS2.\n' +
      '* J. Tang, X. Chen, J. Wang, and G. Zeng (2022) Compressible-composable neRF via rank-residual decomposition. 신경 정보 처리 시스템의 발전 인용: SS1, SS2.\n' +
      '* L. 왕재장 류화자오 장영 장민 우재유, L. Xu(2022)Fourier plenoctrees.\n' +
      '\n' +
      '실시간으로 동적 복사 필드 렌더링을 수행할 수 있습니다. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_.\n' +
      '* Wang et al.(2021) Wang, Z.; 우상 지우영 천민 and Prisacariu, V. A. 2021. NeRF---: Neural Radiance Field without Known Camera Parameters. _ arXiv preprint arXiv:2102.07064_.\n' +
      '* Xu 등 (2022) Xu, Q; Xu, Z; 필립, J.; Bi, S.; 슈자 선카발리 그리고 뉴먼, U. 2022. Point-nerf: Point-based neural radiance field. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_.\n' +
      '* Xu 등 (2023) Xu, Y; 왕락 자오, X; 장훈, 그리고 류영 2023. AvatarMAV: Motion-Aware Neural Voxels를 이용한 고속 3D Head Avatar Reconstruction In _ACM SIGGRAPH 2023 Conference Proceedings_.\n' +
      '* Yu et al. (2021) Yu, A.; Li, R.; 탄식 Li, H.; Ng, R.; and Kanazawa, A. 2021. PlenOctrees for Realtime Rendering of Neural Radiance Fields. _ IEEE International Conference on Computer Vision(ICCV)_의 진행.\n' +
      '* Yuce et al. (2022) Yuce, G.; Ortiz-Jimenez, G.; Besbinar, B.; and Frossard, P. 2022. structured dictionary perspective on implicit neural representation. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_.\n' +
      '* Zhang et al.(2020) Zhang, K.; Riegler, G.; Snavely, N.; 그리고 V. 콜툰 2020. Nerf++: 신경 복사 필드 분석 및 개선. _ arXiv preprint arXiv:2010.07492_.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>