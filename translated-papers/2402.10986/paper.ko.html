<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '#FinTraI: GPT-4 레벨 멀티모달 금융 대언어 모델 패밀리\n' +
      '\n' +
      '가간 바티아 엘 모아테스 빌라 나고디 하산 카부소글루 무하마드 압둘 메이지드\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '우리는 미스트랄-7b 모델을 기반으로 하고 재무 분석을 위해 맞춤화된 최첨단 멀티모달 대형 언어 모델(LLM)의 집합인 _FinTraI_를 소개한다. FinTraI는 텍스트, 숫자, 표 및 이미지 데이터를 통합한다. 우리는 이 작업을 위해 큐레이팅하는 텍스트 및 시각적 데이터 세트의 대규모 모음을 활용하여 도메인별 사전 훈련, 명령어 미세 조정 및 RLAIF 훈련을 통해 **FinTraI**를 향상시킨다. 우리는 또한 금융 영역의 환각을 포함하여 9개의 작업과 25개의 평가 데이터 세트를 특징으로 하는 광범위한 벤치마크를 소개한다. 고급 **T**ools 및 _FinTraI-DPO-T&R_로 명명된 **R**etrieval 방법을 사용하여 직접 선호도 최적화로 훈련된 FinTraI 모델은 탁월한 제로 샷 성능을 보여준다. 그것은 모든 과제에서 ChatGPT-3.5를 능가하고 9개 과제 중 5개 과제에서 GPT-4를 능가하여 AI 기반 금융 기술의 상당한 발전을 나타낸다. 또한 FinTraI가 다양한 재정적 맥락에서 실시간 분석 및 의사 결정에 탁월할 가능성이 있음을 보여준다.\n' +
      '\n' +
      '브리티시컬럼비아 대학교 및 인버서블 AI\n' +
      '\n' +
      '{gagan30@student.,moatez.nagoudi@,cavusoglu@sauder.}.c\n' +
      '\n' +
      '{muhammad.mageed@}ubc.ca;invertible.ai\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '자연어 처리(Natural Language Processing, NLP)는 금융 문서 분석, 해석 및 활용에 핵심적인 역할을 한다. 최근 몇 년 동안 NLP의 발전을 통합한 광범위한 응용 프로그램이 등장했다. 여기에는 재무 뉴스의 감성 분석, 재무 문서로부터의 이벤트 추출, 재무 보고서의 생성 및 요약 등이 포함된다(Souma et al., 2019; Araci, 2019; Yang et al., 2018). 이러한 발전은 데이터 기반 금융 의사 결정을 위한 비정형 데이터의 가능성과 금융 문서를 실행 가능한 통찰력과 시장 인텔리전스로의 변환 가능성을 밝혀냈다. 그러나 금융에서 NLP를 적용하는 것은 금융 문서들이 종종 조밀한 수치 정보 및 고급 수치 처리 및 추론 능력을 요구하는 도메인-특정 용어들을 포함하기 때문에 어렵다(Mik, 2017; Liu et al., 2023b). 이는 재무 NLP 모델이 회계 및 재무 측정, 경제 지표 및 시장 동향의 미묘한 의미를 포착하기 전에 광범위한 도메인 지식이 필요하다는 것을 의미한다. 이것은 또한 실시간 분석이 중요하지만 달성하기 어려운 금융 시장의 빠른 속도에 의해 복합된다(Gupta, 2023; Yang et al., 2023b).\n' +
      '\n' +
      '다른 도메인들과 유사하게, 대형 언어 모델들(LLMs)은 금융 문서 이해를 방해하기 시작하고 있다(Chapman et al., 2022; La Quatra and Cagliero, 2020). 그러나 또한 과도기적 접근법들과 동일한 문제들을 겪을 수 있다. LLM은 또한 환각을 받기 쉬우므로 사용성을 줄입니다.\n' +
      '\n' +
      '그림 1: 주요 금융 AI 모델의 텍스트 기반 과제에 대한 비교 성과 분석. 우리는 7개의 태스크 클러스터에 걸쳐 _FinTraI_와 ChatGPT(GPT-3.5) 및 GPT-4의 세 가지 변형을 비교한다: 감정 분석(SA), 개체명 인식(NER), 숫자 이해(NU), 텍스트 요약(TS), 주식 움직임 예측(SMP), 신용 점수(CS), 기업 공개(FD).\n' +
      '\n' +
      '금융 의사 결정에서 강과 류(2023). 금융 문서는 또한 다양한 유형의 시각적 콘텐츠를 포함할 수 있으며, 이는 멀티모달 능력을 가진 모델을 필요로 한다.\n' +
      '\n' +
      '이러한 과제를 해결하기 위해 금융 분야를 전문으로 하는 획기적인 LLM을 소개합니다. 이 모델은 포괄적인 문서 이해를 위해 텍스트, 숫자, 표 및 시각적 데이터 처리를 통합하는 멀티모달 접근 방식을 통해 금융 도메인의 장애물을 극복하도록 설계되었다. 우리는 Mistral-7b Jiang et al. (2023)에서 방대한 도메인 특정 데이터세트에 대한 모델을 학습하고 광범위한 명령어 데이터를 사용하여 금융 도메인에 대해 명령어 조정한다. 그런 다음 최근에 도입된 직접 정책 최적화(DPO) 방법 Rafailov et al.(2023)을 활용하는 GPT-4 생성 응답과 신중하게 정렬한다. FinTral을 평가하기 위해 25개의 다른 데이터 세트를 기반으로 8개의 다른 작업에 대한 광범위한 벤치마크를 소개한다. 우리의 모델은 비교 가능한 크기의 다른 모든 모델보다 우수하고 훨씬 작은 크기에도 불구하고 GPT-4와 동등하게 수행한다.\n' +
      '\n' +
      '요약하자면, 우리는 다음과 같은 기여를 제공한다: **(1)** 재무 데이터에 특화된 최첨단 멀티모달 LLM인 FinTral과 광범위한 재무 LLM 교육 및 평가 벤치마크인 FinSet. 핀셋은 최대 규모의 금융평가 벤치마크이자 25개 데이터셋에 걸쳐 9개 업무를 아우르는 모델 환각을 측정하는 유일한 기업이다. **(2)** 핀트럴은 AI 피드백 데이터를 사용하여 DPO 목표를 사용하여 추가 명령-피네튜닝되고 신중하게 정렬되어 _FinTralDPO_를 생성한다. **(3)** 또한 FinTral에 비전 능력을 부여하여 CLIP Radford et al.(2021) 비전 인코더를 사용하는 _FinTralVL_로 확장하였다. 성능 향상을 위해 **T**ools와 **R**etrieval, _FinTralDPO-T&R_를 활용한 버전을 개발하였다. **(4)** FinTralDPO는 _all_ 작업에서 ChatGPT OpenAI(2023)를 능가하는 탁월한 제로샷 기능을 보여줍니다. 또한, 우리의 최고의 모델인 FinTralDPO-T&R은 8개의 텍스트 기반 작업 중 5개에서 GPT-4 OpenAI(2023)를 능가한다.\n' +
      '\n' +
      '이 논문의 나머지 부분은 다음과 같이 구성된다: 섹션 2에서 재무 LLM, 적용 및 문제에 특히 중점을 둔 관련 작업을 검토한다. 섹션 3에서는 벤치마크 데이터 세트인 FinSet을 어떻게 구축했는지에 대해 설명합니다. 우리는 사전 훈련, 지도 조정 및 프롬프트 전략을 모델링하는 접근법을 제시하고, 후속적으로 섹션 4에서 핀트랄 모델을 소개하고 섹션 5에서 실험을 제시하고 모델을 종합적으로 분석한다. 우리는 6절에서 우리의 결과를 논의하고 7절에서 결론을 내린다.\n' +
      '\n' +
      '##2 관련 작품\n' +
      '\n' +
      '금융을 위한**NLP 전통적인 NLP는 명명된 개체 인식, 감성 분석, 이벤트 추출, 재무 보고서 생성, 및 텍스트 요약 Salinas Alvarado 등(2015); Souma 등(2019); Araci 등(2019); Yang 등(2018); Zheng 등(2019); Chapman 등(2022); La Quatra and Cagliero 등(2020). 그러나 전통적인 모델은 금융 언어의 복잡성, 주석이 달린 데이터의 부족, 제한된 추론 능력 및 실시간 분석의 필요성으로 인해 이 영역에서 어려움에 직면해 있다. 종래의 NLP 모델들의 적응성은 또한 제한적이며, 이러한 모델들은 종종 단일-태스크 함수 Mik(2017); Mishra et al.(2021); Liu et al.(2023)에 최적화된다.\n' +
      '\n' +
      '**금융 LLM** 금융 모델의 발전은 FinBERT Araci(2019)에서 시작되었다. 최근 BloombergGPT Wu et al. (2023), PIXIU Xie et al. (2023), Instruct-FinGPT Zhang et al. (2023), GPT-FinRE Rajpoot and Parikh (2023) 등의 모델이 주목할 만한 기여를 하고 있다. 기타 혁신으로는 멀티모달 역량 FinVis-GPT Wang et al.(2023)의 도입, 투자 전략 강화(GPT-InvestAR Gupta (2023), InvestLM Yang et al.(2023), 정보 추출 Zhang et al.(2023); Sarmah et al.(2023) 등이 있다. FinLMEval Guo et al. (2023) 및 DISC-FinLLM Chen et al. (2023)은 화폐 시나리오에서의 평가 및 모델 성능에 초점을 맞춘다. 추 외(2023)와 같은 다른 작업은 금융 업무를 더 잘 처리하기 위해 정교한 데이터 전처리를 강조한다. 부록 A는 금융에서 NLP 및 LLMs 문헌에 대한 추가 논의를 제공한다.\n' +
      '\n' +
      '## 3 FinSet\n' +
      '\n' +
      '우리는 핀트랄을 구축하기 위해 포괄적이고 다양한 데이터 세트를 개발한다. 먼저 도메인 특정 토큰이 풍부한 원시 데이터 세트를 설명하고 모델 교육을 위한 견고한 기반을 설정한 다음 세부 조정 및 AI 기반 피드백 데이터 세트를 설명한다. 그 후, 데이터 해석에 대한 미묘한 접근을 용이하게 하기 위해 다중 모드 재무 데이터 세트를 제시한다. 마지막으로, 다양한 금융 업무에 걸쳐 모델의 성능을 테스트하기 위해 맞춤화된 광범위한 평가 벤치마크 데이터 세트를 소개한다.\n' +
      '\n' +
      '### Pretraining Dataset\n' +
      '\n' +
      '금융 LLM 교육을 위해 구축한 200억 토큰 고품질 데이터셋인 FinSet을 소개합니다. 핀셋은 대규모 텍스트 코퍼스 모음(29억 문서, 1,350억 토큰 만들기, 표 1 참조)을 기반으로 획득되며, 여기서 우리는 신중한 필터링 파이프라인을 사용하여 재무별 데이터를 추출한 다음 청소한다. 데이터 세트는 부록 B에 설명되어 있다. 우리의 청소 파이프라인은 부록 C에 자세히 설명되어 있다. 우리의 문서 컷오프 날짜는 모델에 대한 최근 정보를 제공하는 2023년 8월 1일이다.\n' +
      '\n' +
      '### 금융 명령 데이터\n' +
      '\n' +
      '우리는 모델의 기능을 향상시키기 위해 광범위한 명령어 조정 데이터 세트를 조립합니다. 데이터 세트는 특히 다양한 호스트 작업에 대한 GPT-3.5 및 GPT-4와의 상호 작용을 포함하여 다양한 출처에서 비롯된다. 다시, 우리는 비재무적 지시를 배제하기 위해 중복제거 및 필터링 파이프라인(부록 C에 세부됨)을 적용하여 재무적 추론에만 초점을 맞춘다. 표 2는 결과(최종) 데이터 세트와 함께 다양한 데이터 소스를 보여준다.\n' +
      '\n' +
      '##### 금융 AI 피드백 데이터\n' +
      '\n' +
      '인간 피드백은 LLM을 정렬하는 데 유용합니다. 전통적으로 이 피드백은 LLM 반응의 품질에 대한 인간의 선호에서 파생된다. 이 작업에서는 섹션 3.2에 설명된 재무 추론 명령어 데이터 세트의 정제된 버전을 통해 AI 피드백을 사용한다.\n' +
      '\n' +
      'GPT-4(OpenAI, 2023c)에 의해 생성된 출력과 함께, FinMA-7B(Xie et al., 2023) 및 LLaMa-7B-chat(Touvron et al., 2023) 모델을 사용하여 각 프롬프트에 대한 응답을 생성한다. 주어진 프롬프트에 대해, GPT-4 출력은 \'선택된\' 응답으로 선택되고, 우리는 FinMA-7B 및 LLaMa 출력 중 무작위로 하나를 \'주입된\' 응답으로 선택한다. 우리의 AI 피드백 데이터는 총 43k개의 샘플을 포함하며 그림 D.5에서 이 데이터의 예를 보여준다.\n' +
      '\n' +
      '### 시각 금융 교육 데이터세트\n' +
      '\n' +
      'FinTraI의 비전 언어 구성 요소를 정렬하기 위해 Llava 사전 훈련 데이터에서 LAION, CC 및 SBU 데이터 세트를 사용한다(Liu et al., 2023a). 또한 동일한 목적으로 ChartQA 트레이닝 세트(Masry et al., 2022)를 사용한다. 또한, Wang et al.(2023b)의 동일한 접근 방식을 따라 시각적 사전 훈련 데이터 세트를 더욱 확장한다. 왕 등(2023b)은 중국어 데이터를 사용하는 반면, 우리는 Fortune-500 기업 주가 데이터를 사용하여 _FinVisPT_로 명명된 우리만의 영어 데이터셋을 만들 수 있다. 그런 다음 LLava Instruct 데이터를 사용하여 멀티모달 LLM의 명령어 이해도를 향상시켜 명령어 튜닝 데이터세트 _FinVis-IT_를 생성한다. FinVis-PT 데이터셋은 주식시장 차트를 포함하고 이에 대한 간단한 질문을 하는 반면, FinVis-IT는 멀티턴으로 보다 복잡한 차트와 명령어를 포함한다. 우리의 시각적 지시 데이터 세트는 표 3에 설명되어 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c} \\hline \\hline\n' +
      '**Dataset** & **Documents** & **Tokens** & **Deduplicated Tokens** \\\\ \\hline C4 & 2.8B & 124.0B & 11.75B \\\\ News & 51.5M & 8.7B & 5.65B \\\\ SEC & 4.3M & 3.1B & 2.55B \\\\ Social Media & 717.7K & 8.2M & 7.87M \\\\ Press & 12.0K & 3.1M & 1.55M \\\\ \\hline\n' +
      '**Total** & 2.9B & 135.9B & **20.0B** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 사전 훈련 자원에 대한 세부 사항.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline \\hline\n' +
      '**Dataset** & **Source** & **Instructions** \\\\ \\hline FLUPE & ChanceFocus/FLUPE & 123.0k \\\\ finance-alpaca & Ghatriti/Finance-alpaca & 68.91k \\\\ finest-fired & FiqPT/Ingpt-fired & 32.67k \\\\ Math Insstruct & TGREI-LabMathismduct & 26.2k \\\\ fin-llama-dataset & haves/Fin-llama-dataset & 16.9k \\\\ llama-2-finance & A6007/llama-2-finance & 4.84k \\\\ \\hline Total instructions & - & 272.6k \\\\\n' +
      '**Total after deduplication** & - & **226.3k** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 명령어 튜닝 데이터세트.\n' +
      '\n' +
      '그림 2: FinSET, 금융 교육 및 평가 벤치마크.\n' +
      '\n' +
      '# 다운스트림 평가 데이터 세트\n' +
      '\n' +
      '다양한 다운스트림 데이터 세트는 효과적인 LLM 성능 벤치마킹에 중요하다. 이 작업에서 우리는 모델을 평가하기 위해 기존 및 새로운 데이터 세트를 사용하여 광범위한 벤치마크를 개발한다. 우리의 벤치마크는 (1) 차트 이해(CU), (2) 감정 분석(SA), (3) 개체명 인식(NER), (4) 숫자 이해(NU), (5) 텍스트 요약(TS), (6) 주식 움직임 예측(SMP), (7) 신용 점수(CS), (8) 기업 공시(FD), (9) 환각 분석(HI)과 같은 과제를 다룬다. 표 4는 각각 사용된 해당 평가 메트릭과 함께 평가에 사용된 모든 데이터 세트를 요약한다. 또한 부록 D의 데이터 세트에 대한 자세한 정보를 제공합니다.\n' +
      '\n' +
      '## 4 Fintral\n' +
      '\n' +
      '우리는 수치 작업에 적합한 숫자를 한 자릿수로 분할하는 BPE 토큰화기의 강력한 성능과 사용으로 인해 추가 개발을 위한 기본 모델로 _Mistral-7B-v0.1_(Jiang et al., 2023)를 사용한다.\n' +
      '\n' +
      '**도메인-특정 프리트레이닝** 섹션 3에 설명된 200억 토큰 FinSet 재무 데이터에 대해 미스트랄-7B-v0.1을 추가로 프리트레이닝한다. 플래시 어텐션 2(Dao, 2023)로 프리트레이닝을 수행한다. 최대 8k 토큰의 시퀀스 길이를 사용하여 긴 재무 문서를 수용합니다. 학습률이 \\(2.5e^{-5}\\)인 한 에폭에 대한 모델을 사전 훈련하기 위해 LoRA(Hu et al., 2021)를 사용한다. 사전 훈련은 4개의 40GB A100 GPU에서 80시간이 걸립니다.\n' +
      '\n' +
      '**금융 LLM에 대한 프롬프트** 멀티모달 기능을 가진 금융 LLM에 적합한 프롬프트 방법을 사용합니다. 이 모델은 주요 예상 행동을 나타내는 재무 전문가로서 멤틱 프록시(Reynolds and McDonell, 2021)를 할당하고, 단계적으로 생각하도록 권장하며, 텍스트, 테이블 또는 이미지일 수 있는 다양한 입력을 고려한다. 그런 다음 관련 정보를 전략적으로 검색하여 모델의 초점이 쿼리의 요구 사항과 일치하도록 합니다. 그런 다음 모델은 모델의 재정적 전문성과 분석적 사고의 적용을 요구하면서 과제 기반 질문과 맞물린다. 이 구조화된 접근법은 특히 복잡한 재무 시나리오에서 모델에서 집중된 답변을 도출하는 데 중추적이다. 제약 조건의 적용은 모델의 출력을 더욱 세분화하여 정확도 및 상황에 적합한 응답을 향상시킵니다. 핀트랄의 프롬프팅 방법의 시각적 표현은 그림 3에 나와 있다.\n' +
      '\n' +
      '**Instruction Tuning** 섹션 3.2에 기술된 우리의 instruction tuning dataset을 사용하여 사전 훈련된 모델에 대해 instruction finetuning을 수행한다.1 우리는 QLoRA를 채택하여 모든 선형 레이어를 타겟 모듈로 사용하여 instruction finetuning을 수행함으로써 풀 파인-튜닝에 가까운 성능을 제공한다(Dettmers et al., 2023).\n' +
      '\n' +
      '각주 1: 우리는 앞서 설명한 바와 같이 모든 데이터 세트가 동일한 프롬프트 형식을 갖도록 표준화한다.\n' +
      '\n' +
      '**AI 피드백과의 정렬** 대형 언어 모델은 명령어 미세 조정 후에도 자연스러운 프롬프트에 잘 응답하지 못할 수 있습니다. 이 문제를 해결하기 위해, 우리는 보상 모델의 사용 없이 모델을 우선적으로 튜닝할 수 있는 직접 선호도 최적화(DPO)(Rafailov et al., 2023)를 사용한다. Tunstall et al.(2023)은 DPO 목적을 사용하여 LLMs를 훈련시키기 위해 LoRA를 사용하는 방법을 소개한다. 이를 증류 직접 선호도 최적화(dDPO)라고 한다. 2 섹션 3.3에서 이 프로세스에 대한 이진화된 선호도 데이터를 생성하는 방법에 대해 설명한다.\n' +
      '\n' +
      '각주 2: 우리는 Tunstall 등(2023)에 의해 제공된 스크립트들을 사용하여 우리의 dDPO 모델을 훈련시킨다.\n' +
      '\n' +
      '**멀티모달 명령어 튜닝** 한 번 가르치면\n' +
      '\n' +
      '도 3 : 핀트럴 프롬프트 방법\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l} \\hline \\hline\n' +
      '**Multinodal Training** & **Dataset** & **Source** & **Instructions** \\\\ \\hline \\multirow{2}{*}{**Alignment**} & \\multicolumn{2}{c}{LiANOCCSWL} & Liu et al. (2023) & 558k \\\\  & \\multicolumn{2}{c}{FEnVis-PT} & **Our Paper** & 188k \\\\  & \\multicolumn{2}{c}{CharQA} & Mary et al. (2022) & 20.9k \\\\ \\hline \\multirow{2}{*}{**Multiturn**} & \\multicolumn{2}{c}{FEnVis-IT} & **Our Paper** & 427k \\\\  & \\multicolumn{2}{c}{LLwn 1.5} & Liu et al. (2023) & 668k \\\\ \\hline \\hline\n' +
      '**Total** & & & 1.1M \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 시각적 금융 지시 데이터 세트. 우리는 Wang et al.(2023)로부터 동일한 방법을 사용하여 FinVis를 생성하였다.\n' +
      '\n' +
      '다양한 금융 쿼리를 처리하기 위한 우리의 모델은 시각적 이해에도 힘을 실어줍니다. 이는 Liu 등에 의해 제안된 아키텍처를 사용하여 수행된다(2023). 구체적으로, 우리는 프롬프트에 <image> 토큰을 추가하고 토큰화 후 <image> 토큰을 이미지 임베딩으로 대체한다. 우리는 CLIP 모델 Radford et al.(2021)을 우리의 비전 인코더 및 2-레이어 MLP 시각 추상기로 사용하여 이미지 입력을 LLM에 공급되는 텍스트 임베딩으로 변환할 수 있다.\n' +
      '\n' +
      '**Tool Usage** 정량적 작업을 처리할 때 LLMs가 직면한 고유한 문제를 해결함에 있어, 우리는 Schick et al.(2023)을 모델에 통합한다. 이러한 도구를 통해 LLM은 수학적으로 집약적인 작업을 보다 적합한 계산 환경으로 오프로드할 수 있다. 예를 들어, Add(), Subtract() 및 Multiply()와 같은 함수는 파이썬 함수 호출로 해석 가능한 구조화된 형식의 출력을 생성하기 위해 모델에 의해 사용되어, 금융 애플리케이션에서 모델 정확도를 향상시킨다.\n' +
      '\n' +
      '**검색 증강 생성(RAG)** 금융 감정 분석을 위해 Zhang et al. (2023)에 도시된 바와 같이, 검색 증강 생성(RAG)을 사용하면 성능을 상당히 높일 수 있다. 본 논문에서는 문서 검색을 위한 SoTA 모델인 BGE Xiao et al.(2023) 모델을 이용한 RAG 시스템을 제안한다. 사용자가 일반적으로 도메인 밖에서 질문을 하기 때문에 LLM에 유용합니다. 2022년 1월 1일부터 2023년 9월 30일까지 여러 출처에서 파생된 30,000개의 재무 문서를 사용하며 그림 D.3과 같은 검색 체인을 사용하며 그 예는 그림 D.4에 나와 있다.\n' +
      '\n' +
      '## 5 Experiments\n' +
      '\n' +
      '3.5절에서 설명한 방법들의 효용성을 보이기 위해 여러 실험을 수행하였고, 3.5절에서 설명한 다운스트림 태스크에 대한 모델을 평가하였다. 다음 표의 기호는 모델의 유형을 나타낸다. \\(\\clubsuit\\), \\(\\clubsuit\\), \\(\\diamondsuit\\), \\(\\heartsuit\\), \\(\\heartsuit\\). 그리고 \\(\\blacksquare\\)은 사전 훈련된 모델, 미세 조정 모델, 지시 미세 조정 모델, RL-Tuned 모델, 도구, 검색이다. 그런 다음 우리는 LLM의 가장 큰 과제 중 하나를 얼마나 잘 완화하는지 평가하기 위해 환각 지수 정확도 검사를 수행했다.\n' +
      '\n' +
      '세 가지 버전의 모델을 소개합니다. 먼저, FinTral-INST는 사전 학습된 모델을 미세 조정하여 얻은 명령어 미세 조정 모델이다. 우리는 사전 훈련된 모델이 명령어 미세 조정 모델의 중간 단계 역할을 하기 때문에 성능을 평가하지 않는다는 점에 유의한다. 둘째, dDPO 목표를 가지고 AI 피드백을 활용한 강화학습을 활용하여 FinTral-INST를 기반으로 더욱 훈련된 FinTral-DPO를 소개한다. 그런 다음 FinTral-DPO와 도구 및 검색을 결합한 FinTral-DPO-T&R을 소개합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c l l l l} \\hline \\hline\n' +
      '**Data** & **Task** & **Instruction** & **Data Types** & **Modalities** & **Source** & **Metrics** \\\\ \\hline \\hline \\multirow{2}{*}{\\begin{tabular}{l} ChartQA \\\\ FinVQAv1 \\\\ FinVQAv2 \\\\ \\end{tabular} } & \\multirow{2}{*}{chart understanding} & \\(2,500\\) & general charts & & Mary et al. (2022) & \\\\  & & \\(500\\) & stock market charts & & text, images & **Our paper** & **Accuracy** \\\\  & & & \\(525\\) & complex financial charts & & **Our paper** & **Our paper** & \\\\ \\hline \\multirow{2}{*}{\\begin{tabular}{l} Australian \\\\ German \\\\ \\end{tabular} } & \\multirow{2}{*}{credit scoring} & \\(690\\) & \\multirow{2}{*}{credit records} & \\multirow{2}{*}{table} & Quintan & \\multirow{2}{*}{\\begin{tabular}{l} Quintan \\\\ Hofmann (1994) \\\\ \\end{tabular} } & \\multirow{2}{*}{Accuracy} \\\\  & & & & & & \\\\ \\hline \\multirow{2}{*}{\\begin{tabular}{l} CS \\\\ FSR \\\\ ITR \\\\ \\end{tabular} } & \\multirow{2}{*}{firm disclosure} & \\(240\\) & \\multirow{2}{*}{SEC filings} & \\multirow{2}{*}{text} & Cao et al. (2023) & \\\\  & & & & & **Cao et al. (2020)** & **Accuracy** \\\\  & & \\(1,196\\) & & & **Our paper** & \\\\ \\hline \\multirow{2}{*}{\\begin{tabular}{l} FinTerms-MCQ \\\\ FinancialBench \\\\ FinTerms-Gen \\\\ \\end{tabular} } & \\multirow{2}{*}{ hallucination analysis} & \\(1,129\\) & financial terms, Wikipedia & text,ables & **Our paper** & **Accuracy** \\\\  & & & & & **Itiman et al. (2023) & **Human Evaluation** \\\\  & & & & & **Our paper** & \\\\ \\hline \\multirow{2}{*}{\\begin{tabular}{l} ConvFinQA \\\\ FinQA \\\\ \\end{tabular} } & \\multirow{2}{*}{numerical understanding} & \\(3,892\\) & \\multirow{2}{*}{caming reports} & \\multirow{2}{*}{text, table} & Chen et al. (2022) & \\multirow{2}{*}{Exact Match} \\\\  & & & & & Chen et al. (2021) & \\\\ \\hline \\multirow{2}{*}{\\begin{tabular}{l} FinT-Ord \\\\ ENER \\\\ \\end{tabular} } & \\multirow{2}{*}{named entity recognition} & \\(1,080\\) & news articles & & **Sah et al. (2023)** & \\\\  & & & & & Salinas Alvaroda et al. (2015) & \\\\ \\hline \\multirow{2}{*}{\\begin{tabular}{l} ACL18 \\\\ BigData22 \\\\ CIKM18 \\\\ \\end{tabular} } & \\multirow{2}{*}{stock movement prediction} & \\(27,053\\) & \\multirow{2}{*}{tweets, historical pieces} & \\multirow{2}{*}{text, time series} & Xu and Cohen (2018) & \\multirow{2}{*}{Accuracy} \\\\  & & \\(7,164\\) & & & Soun et al. (2022) & \\\\  & & \\(4,967\\) & & & Wu et al. (2018) & \\\\ \\hline \\multirow{2}{*}{\\begin{tabular}{l} FQA-SA \\\\ FOMC \\\\ FPB \\\\ Headline \\\\ \\end{tabular} } & \\multirow{2}{*}{sentiment analysis} & \\(11,730\\) & news headlines, tweets & & \\multirow{2}{*}{tweets} & Maia et al. (2018) & \\multirow{2}{*}{Accuracy} \\\\  & & \\(496\\) & FOMC hawish-dowish & & & Shah et al. (2023) & \\\\  & & \\(48,450\\) & news & & Maio et al. (2013) & \\\\  & & \\(11,412\\) & news headlines & Salna and handani (2020) & & \\\\ \\hline \\multirow{2}{*}{\\begin{tabular}{l} ECTSUM \\\\ EDTSUM \\\\ Risk Eval \\\\ \\end{tabular} } & \\multirow{2}{*}{text summarization} & \\(495\\) & earning call transcript & \\multirow{2}{*}{text} & Mukherjee et al. (2022) & \\multirow{2}{*}{Rong-score} \\\\  & & \\(2,000\\) & news articles & & Zhou et al. (2021) & \\\\ \\hline \\multirow{2}{*}{\n' +
      '\\begin{tabular}{l} Investopedia \\\\ \\end{tabular} } & \\multirow{2}{*}{Rong-score} \\\\  & & & \\(3,000\\) & SEC articles & & Loukas et al. (2021) & \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 다운스트림 데이터의 상세사항. FinTerms-Gen은 Investopedia (2024)에서 추출되고 FinTerms-MCQ는 Ghosh et al. (2022)의 코드를 사용하여 생성된다. 또한, 9개의 다른 기준선 LLM과 본 모델의 성능을 비교한다. 이들은 LLama-2(Touvron et al., 2023), Mistral(Jiang et al., 2023), FinMA(Xie et al., 2023), Vicuna(Chiang et al., 2023), ChatGPT(OpenAI, 2023a), GPT-4(OpenAI, 2023c)의 세 가지 버전이다.\n' +
      '\n' +
      '### 명령어 튜닝 및 모델 정렬\n' +
      '\n' +
      '표 5에서 볼 수 있듯이, 우리의 지침 미세 조정 모델 FinTral-INST는 평균 점수 0.49로 모든 사전 훈련 및 미세 조정 오픈 소스 모델을 능가한다. 여기서 우려되는 원인 중 하나는 수치 이해 및 NER 작업과 같은 특정 형식을 출력으로 요구하는 작업이다. 우리는 어떤 경우에, 모델이 지시를 따르려고 애쓰고 종종 과제가 요구하는 것을 벗어났다는 것을 안다.\n' +
      '\n' +
      '또한, 핀트랄-DPO, ChatGPT, GPT-4와 같이 AI 피드백(RLAIF)으로 강화 학습을 거친 모델은 훨씬 더 현저한 개선을 보여준다. RLAIF를 추가하면 평균 점수 0.59로 성능이 극적으로 향상되어 FinTral-DPO가 ChatGPT를 능가한다.\n' +
      '\n' +
      '특히 GPT-4는 가장 높은 평균 점수로 눈에 띄며 다양한 작업 세트에 걸쳐 강력한 성능을 나타낸다. 높은 NER, NU 및 FD 점수는 복잡한 텍스트를 이해하고 특정 개체를 식별하고 수치 데이터를 해석하는 데 탁월한 능력을 시사한다.\n' +
      '\n' +
      '### 검색 및 도구 사용\n' +
      '\n' +
      '섹션 4에 자세히 설명된 바와 같이 검색 및 도구의 사용은 GPT-4에 미치는 영향과 유사하게 본 모델인 FinTral-DPO-T&R의 기능을 향상시키는 데 중추적인 역할을 한다. 이러한 기능을 이러한 모델에 통합하면 모델이 광범위한 정보에 액세스하고 보다 전문화된 처리 기술을 적용할 수 있어 다양한 작업에 걸쳐 성능이 크게 향상된다. FinTral-DPO-T&R의 경우 FinTral-DPO 모델과 검색 및 도구 기능을 결합한 것이 특히 효과적인 것으로 입증되었다. 핀트랄-DPO 모델의 지시 프롬프트를 정확하게 따르는 기능은 외부 도구 및 검색 데이터와의 원활한 통합을 가능하게 한다. 도구와 검색을 통합한 최신 업데이트가 적용된 GPT-4-터보의 성능도 주목할 만하다.\n' +
      '\n' +
      '5개의 다운스트림 작업에서 FinTral-DPO-T&R이 GPT-4를 능가한 반면, GPT-4는 2개의 다운스트림 작업에서 FinTral-DPO-T&R을 능가했다. GPT-4는 이 두 가지 작업에서 예외적으로 잘 수행되었기 때문에 평균 성능이 FinTral-DPO-T&R(표 6과 같이 0.72 대 0.70)보다 약간 우수하다. 핀트랄-DPO-T&R과 GPT-4가 다른 모델에 비해 가지고 있는 에지는 보다 정교하고 정확한 출력을 위해 정교한 AI 모델과 추가 데이터 및 도구 통합을 결합할 수 있다는 가능성을 보여주는 증거이다.\n' +
      '\n' +
      '### Multimodal Evaluation\n' +
      '\n' +
      '재무적 멀티모달 모델을 평가하기 위해 ChartQA와 FinVis 데이터 세트를 사용한다. GPT-4V (OpenAI, 2023b), Gemini-Pro (Team et al., 2023), QwenVL-Plus (Bai et al., 2023), LLaVa-NEXT (Liu et al., 2024)와 같은 다양한 최신 멀티모달 대형 언어 모델(MLLM)과 우리의 FinTral-VL 모델을 비교한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c c c} \\hline \\hline\n' +
      '**Model** & **Type** & **SA** & **NER** & **NU** & **TS** & **SMP** & **CS** & **FD** & **Average** \\\\ \\hline FinMA-7B-trade & \\(\\spadesuit\\) & 0.20 & 0.00 & 0.00 & 0.08 & 0.46 & 0.39 & 0.00 & 0.16 \\\\ Llama-2-7b-hf & \\(\\spadesuit\\) & 0.26 & 0.00 & 0.00 & 0.00 & 0.48 & 0.50 & 0.09 & 0.19 \\\\ Mistral-7B-v0.1 & \\(\\spadesuit\\) & 0.25 & 0.00 & 0.00 & 0.05 & 0.49 & 0.52 & 0.09 & 0.20 \\\\ Vicuna-7B & \\(\\diamondsuit\\) & 0.54 & 0.01 & 0.00 & 0.20 & 0.46 & 0.39 & 0.00 & 0.23 \\\\ Mistral-7B-Instruct-v0.1 & \\(\\diamondsuit\\) & 0.49 & 0.00 & 0.00 & 0.30 & 0.49 & 0.48 & 0.29 & 0.29 \\\\ Llama-2-13b-chat-hf & \\(\\diamondsuit\\) & 0.58 & 0.02 & 0.00 & 0.30 & 0.50 & 0.52 & 0.31 & 0.32 \\\\ FinMA-7B & \\(\\spadesuit\\) & 0.72 & 0.38 & 0.16 & 0.29 & 0.46 & 0.29 & 0.00 & 0.33 \\\\ Llama-2-7b-chat-hf & \\(\\diamondsuit\\) & 0.54 & 0.07 & 0.00 & 0.31 & 0.52 & 0.56 & 0.32 & 0.33 \\\\ FinMA-7B-full & \\(\\spadesuit\\) & 0.78 & 0.35 & 0.12 & 0.35 & 0.51 & 0.29 & 0.30 & 0.38 \\\\\n' +
      'FinTral-INST** & \\(\\diamondsuit\\) & 0.81 & 0.40 & 0.02 & 0.40 & 0.53 & 0.61 & 0.66 & 0.49 \\ ChatGPT (gpt-3.5-turbo) & \\(\\diamondsuit\\) & 0.70 & 0.53 & 0.58 & 0.59 & 0.53 & 0.31 & 0.52 & 0.53 \\\\\\\n' +
      '**FinTral-DPO** & \\(\\diamondsuit\\) & **0.82** & 0.70 & 0.15 & 0.60 & **0.54** & 0.62 & 0.67 & 0.59 \\\\ GPT-4 (gpt-4-0613) & \\(\\diamondsuit\\) & 0.79 & **0.80** & **0.63** & **0.65** & **0.54** & **0.70** & **0.73** & **0.69** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 다양한 작업에 대한 LLM의 비교 분석. 본 논문에서는 굵은 글씨로 된 모델들을 소개한다. 이 분석은 **SA:** 감정 분석, **NER:** 개체명 인식, **NU:** 번호 이해, **TS:** 텍스트 요약, **SMP:** 주식 이동 예측, **CS:** 신용 점수 및 **FD:** 기업 공개를 포함한다.\n' +
      '\n' +
      'CLIP 및 FinTral-DPO를 포함한다. 표 7에서 알 수 있듯이 GPT-4V는 ChartQA에서 0.79, FinVis에서 0.89로 평균 0.84로 가장 잘 수행되며, Gemini-Pro는 두 데이터 세트에 걸쳐 일관된 성능으로 평균 0.78로 밀접하게 뒤따른다. Qwen-VL-Plus, FinTral-VL 및 LLaVa-NEXT와 같은 다른 모델은 FinVQA(0.64)보다 ChartQA(0.78)에서 Qwen-VL-Plus가 현저하게 더 나은 성능을 보이는 반면, FinTral-VL 및 LLaVa-NEXT 추적은 시각적 데이터 해석 능력의 잠재적 향상을 위한 영역을 나타낸다. FinTral-VL은 FinVQA 데이터셋에서 좋은 성능을 보여 멀티모달 금융 사용에 매우 적합하다. 그림 D.6은 FinVQA 데이터 세트의 질문에 대한 모델 출력의 예를 보여준다.\n' +
      '\n' +
      '금전적 환각 평가\n' +
      '\n' +
      '재정 환각은 측정하기에 복잡할 수 있기 때문에 환각을 정량화하기 위해 세 가지 다른 방법과 데이터 세트를 사용했다. 우리는 먼저 모델들이 금융 용어의 정의를 선택하는 데 얼마나 환각을 보이는지 평가한다. 그런 다음 첫 번째 작업을 기반으로 상위 LLM 모델의 응답 적절성에 대한 인간 평가를 수행한다. 마지막으로, 수학적 도구와 검색이 필요한 복잡한 수치 질문 응답 데이터세트인 Finance Bench(Islam et al., 2023) 데이터세트에 대해 평가하였다.\n' +
      '\n' +
      '**FinTerms-MCQ** FinTerms-MCQ 데이터셋에서 우리는 금융 용어의 정의를 Investopedia(2024)에서 올바른 정의와 세 가지 밀접하게 관련된 정의를 사용하여 객관식 형식으로 변환한다. 그런 다음 모델에 올바른 정의를 선택하도록 요청합니다. 이 MCQ 과제에서 모델의 성과를 바탕으로 각 모델이 올바르게 생성한 정의의 비율(높을수록 좋다)로 정의되는 환각 지수(HI)를 도출한다. 표 8에서 볼 수 있듯이 HI에 대한 모델의 성과는 크게 다르다. GPT-4와 ChatGPT는 각각 98%와 95%의 예외적으로 높은 점수로 팩을 이끈다. 세 가지 모델 모두 다른 오픈 소스 LLM보다 성능이 우수합니다. 특히 FinTral-DPO-T&R은 HI가 97%로 강한 성능을 보인다.\n' +
      '\n' +
      '**FinTerms-Gen** 표 D.1에서, 우리는 ChatGPT, halluc와 같이 LLMs가 얼마나 인기 있는지의 예를 보여준다\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c c c} \\hline \\hline\n' +
      '**Model** & **Type** & **SA** & **NER** & **NU** & **TS** & **SMP** & **CS** & **FD** & **Average** \\\\ \\hline \\hline \\multicolumn{1}{c}{Mistral-7B-Instruct-v0.1} & \\(\\diamondsuit\\) & 0.49 & 0.00 & 0.00 & 0.30 & 0.49 & 0.48 & 0.29 & 0.29 \\\\ \\multicolumn{1}{c}{Llama-2-7b-chat-hf} & \\(\\heartsuit\\) + \\(\\star\\) + \\(\\blacksquare\\) & 0.54 & 0.07 & 0.00 & 0.31 & 0.52 & 0.56 & 0.32 & 0.33 \\\\ \\multicolumn{1}{c}{**FinTral-INST**} & \\(\\diamondsuit\\) & 0.81 & 0.40 & 0.02 & 0.40 & 0.53 & 0.61 & 0.66 & 0.49 \\\\ \\multicolumn{1}{c}{ChatGPT (gpt-3.5-turbo-1106)} & \\(\\heartsuit\\) & 0.70 & 0.53 & 0.58 & 0.59 & 0.53 & 0.31 & 0.52 & 0.53 \\\\ \\multicolumn{1}{c}{**FinTral-DPO**} & \\(\\diamondsuit\\) & 0.82 & 0.70 & 0.15 & 0.60 & 0.54 & 0.62 & 0.67 & 0.59 \\\\ \\multicolumn{1}{c}{**FinTral-DPO-T& \\(\\diamondsuit\\) + \\(\\star\\) + \\(\\blacksquare\\)**} & **0.83** & **0.83** & 0.60 & **0.72** & **0.56** & 0.62 & **0.75** & 0.70 \\\\ \\multicolumn{1}{c}{GPT-4-Turbo (gpt-4-1106-preview)} & \\(\\heartsuit\\) + \\(\\star\\) + \\(\\blacksquare\\) & 0.79 & 0.80 & **0.83** & 0.65 & 0.54 & **0.70** & 0.73 & **0.72** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 다양한 작업에 대한 외부 도구를 사용한 LLM의 비교 분석.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline \\hline\n' +
      '**Model** & **Type** & **HI** \\\\ \\hline \\hline \\multicolumn{1}{c}{FinMA-7B-trade} & \\(\\spadesuit\\) & \\(0.28\\) \\\\ \\multicolumn{1}{c}{Vicuna-7B} & \\(\\diamondsuit\\) & \\(0.55\\) \\\\ \\multicolumn{1}{c}{Llama-2-7b} & \\(\\spadesuit\\) & \\(0.64\\) \\\\ \\multicolumn{1}{c}{FinMA-7B} & \\(\\spadesuit\\) & \\(0.64\\) \\\\ \\multicolumn{1}{c}{Mistral-7B} & \\(\\spadesuit\\) & \\(0.67\\) \\\\ \\multicolumn{1}{c}{Llama-2-7b-chat} & \\(\\heartsuit\\) & \\(0.70\\) \\\\ \\multicolumn{1}{c}{Llama-2-13b-chat} & \\(\\heartsuit\\) & \\(0.75\\) \\\\ \\multicolumn{1}{c}{Mistral-7B-Instruct} & \\(\\diamondsuit\\) & \\(0.76\\) \\\\ \\multicolumn{1}{c}{FinMA-7B-full} & \\(\\spadesuit\\) & \\(0.80\\) \\\\ \\multicolumn{1}{c}{**FinTral-INST**} & \\(\\diamondsuit\\) & \\(0.82\\) \\\\ \\multicolumn{1}{c}{**FinTral-DPO**} & \\(\\diamondsuit\\) & \\(0.88\\) \\\\ \\multicolumn{1}{c}{ChatGPT} & \\(\\heartsuit\\) & \\(0.95\\) \\\\ \\multicolumn{1}{c}{**FinTral-DPO-T& \\(\\diamondsuit\\) + \\(\\blacksquare\\)**} & \\(0.97\\) \\\\ \\multicolumn{1}{c}{GPT-4-Turbo} & \\(\\heartsuit\\) + \\(\\blacksquare\\) & **0.98** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: 차트 이해 데이터 세트에서 사용 가능한 MLLM과의 비교.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline \\hline\n' +
      '**Model** & **Type** & **HI** \\\\ \\hline \\hline \\multicolumn{1}{c}{FinMA-7B-trade} & \\(\\spadesuit\\) & \\(0.28\\) \\\\ \\multicolumn{1}{c}{Vicuna-7B} & \\(\\diamondsuit\\) & \\(0.55\\) \\\\ \\multicolumn{1}{c}{Llama-2-7b} & \\(\\spadesuit\\) & \\(0.64\\) \\\\ \\multicolumn{1}{c}{FinMA-7B} & \\(\\spadesuit\\) & \\(0.64\\) \\\\ \\multicolumn{1}{c}{Mistral-7B} & \\(\\spadesuit\\) & \\(0.67\\) \\\\ \\multicolumn{1}{c}{Llama-2-7b-chat} & \\(\\heartsuit\\) & \\(0.70\\) \\\\ \\multicolumn{1}{c}{Llama-2-13b-chat} & \\(\\heartsuit\\) & \\(0.75\\) \\\\ \\multicolumn{1}{c}{Mistral-7B-Instruct} & \\(\\diamondsuit\\) & \\(0.76\\) \\\\ \\multicolumn{1}{c}{FinMA-7B-full} & \\(\\spadesuit\\) & \\(0.80\\) \\\\ \\multicolumn{1}{c}{**FinTral-INST**} & \\(\\diamondsuit\\) & \\(0.82\\) \\\\ \\multicolumn{1}{c}{**FinTral-DPO**} & \\(\\diamondsuit\\) & \\(0.88\\) \\\\ \\multicolumn{1}{c}{ChatGPT} & \\(\\heartsuit\\) & \\(0.95\\) \\\\ \\multicolumn{1}{c}{**FinTral-DPO-T& \\(\\clsuit\\)\\(\\mathbf{R}\\)**} & \\(\\heartsuit\\) + \\(\\blacksquare\\) & \\(0.97\\) \\\\ \\multicolumn{1}{c}{GPT-4-Turbo} & \\(\\heartsuit\\) + \\(\\blacksquare\\) & \\(\\mathbf{0.98}\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: 환각지수(HI)를 기반으로 한 다양한 모델의 비교. 이 지수는 각 모형에서 올바르게 생성된 정의의 비율을 나타냅니다.\n' +
      '\n' +
      '금융 영역에서 소각하라. FinTerms-MCQ(즉, GPT-4, ChatGPT, FinTral-DPO+T&R)에서 가장 성능이 좋은 세 가지 모델을 사용하여 FinTerms-Gen 데이터셋(n=150, 표 4 참조)에서 재무 용어와 관련된 질문에 대한 답변을 생성한다. 그런 다음 재무 분야에서 최소 4년의 배경을 가진 두 사람에게 그림 4에 표시된 4개의 정확성 태그 중 하나로 응답에 라벨을 붙이도록 요청합니다. 두 주석자는 Cohen의 카파(\\(K\\))가 \\(0.85\\)인 것에 동의합니다. 그림 43과 같이 FinTral-DPO-T&R은 ChatGPT보다 더 정확하고 만족스러운 응답(그림 4의 카테고리 A)을 생성하지만 GPT-4에는 미치지 못한다.\n' +
      '\n' +
      '각주 3: 이 분석을 위해 두 주석자가 동의하는 Q&A 쌍(n=128 쌍)만 사용합니다.\n' +
      '\n' +
      '**재무 벤치** 재무 벤치(Islam et al., 2023)는 오픈북 재무 질문 응답(QA)의 맥락에서 LLMs의 능력을 평가하도록 설계된 독점 데이터세트이다. 전체 버전에는 상장 기업과 관련된 10,231개의 질문이 포함되어 있으며 각각 증거 문자열과 관련 답변이 첨부되어 있지만 저자가 채택한 동일한 방법론을 사용하여 이슬람 등(2023)에서 제공한 150개 질문의 파이낸스벤치의 오픈 소스 샘플을 사용하여 모델을 평가한다. 도 5에 제시된 바와 같이, FinTral-DPO-T&R은 이 데이터세트에 대해 매우 잘 수행되며, 다른 모델인 GPT-4(OpenAI, 2023c), Claude(Models, 2023) 및 Llama-70B(Touvron et al., 2023)를 능가하며, Islam et al.(2023)에서 평가된다. FinTral-DPO-T&R에서 검색과 도구를 사용하는 것은 효율성을 입증하고 다른 모든 모델보다 모델을 우선시한다.\n' +
      '\n' +
      '## 6 Discussion\n' +
      '\n' +
      '**금융 LLMs의 발전**핀트랄은 광범위한 데이터 세트와 명령어 미세 조정 및 RLAIF를 포함한 다양한 훈련 방법을 활용하여 여러 양식에 걸쳐 복잡한 금융 데이터 분석을 향상시킨다. 고급 도구의 통합은 재정적 능력을 더욱 강화합니다.\n' +
      '\n' +
      '**모델 환각 감소**핀트랄은 최신적이고 깨끗한 금융 데이터로 사전 훈련하고 RLAIF 및 검색 방법을 사용하여 모델의 정확성과 신뢰성을 향상시켜 금융 환각과 싸웁니다.\n' +
      '\n' +
      '**금융 의사 결정에서의 인간-AI 협력**핀트랄의 동적 데이터 검색 및 라이브 데이터 분석을 통한 금융 시장에 대한 실시간 적응력 향상은 예측 정확도를 크게 높이고 정보에 입각한 의사 결정에 도움을 줄 수 있다. 그림 E.1은 이 모델이 실제 세계에서 어떻게 사용될 수 있는지를 보여준다.\n' +
      '\n' +
      '## 7 Conclusion\n' +
      '\n' +
      '우리는 핀트랄에 주목할 만한 능력을 갖춘 고급 멀티모달 금융 언어 모델을 제시했다. 주요 발전에는 텍스트, 숫자 및 시각적 데이터 통합, 다양한 미세 조정 기능을 가진 훈련 파이프라인, 도구 및 검색 메커니즘의 사용이 포함된다. 이 모델은 기준 모델에 비해 다양한 금융 활동에서 높은 성능으로 입증된 금융 환상과 같은 문제를 효과적으로 해결한다. 핀트랄의 성과는 적당한 크기(예를 들어, 7B)의 금융 모델에 큰 잠재력을 가지고 있다.\n' +
      '\n' +
      '도 4: FinTerms Dataset에 대한 인간 평가_ 핀트랄:_은 우리의 핀트랄-DPO-T&R이다. 각 막대는 응답의 품질을 나타내는 4가지 색상으로 분할된다: A: 정확하고 만족스러운 응답 B: 사소한 불완전성을 가진 수용 가능한 응답, C: 명령에 응답하지만 상당한 오류, D: 부적절하거나 무효한 응답.\n' +
      '\n' +
      'Figure 5: FinanceBench 데이터셋에 대한 다양한 모델의 성능 비교. 각 모형의 정답, 오답 및 실패 응답 비율이 표시됩니다. 핀트랄-DPO-T&R과 GPT4는 LLama-70B가 가장 높은 고장률을 보여 다른 모델보다 성능이 우수하다.\n' +
      '\n' +
      '## 8 Limitations\n' +
      '\n' +
      '핀트랄은 금융 대형 언어 모델(LLM)의 영역에서 상당한 발전을 나타내지만, 내재적 한계를 인정하는 것이 중요하다:\n' +
      '\n' +
      '1. **도메인-특정 적응성:** 금융 도메인에 대해 맞춤화된, FinTral은 그것의 훈련된 범위 밖에서 효과적으로 수행하지 않을 수 있고, 잠재적으로 그것의 일반화 가능성을 제한할 수 있다.\n' +
      '2. **Real-Time Data의 처리:** 실시간 분석을 위해 설계되었지만, 모델의 예측 정확도는 들어오는 데이터의 적시성 및 정확도에 의존하며, 이는 급변하는 시장 상황에 의해 영향을 받을 수 있다.\n' +
      '3. **유지보수 및 갱신:** 금융 시장 및 규제 진화에 있어 모델을 적절하고 효과적으로 유지하기 위해서는 지속적인 갱신 및 유지 보수가 필요하다.\n' +
      '\n' +
      '이러한 한계를 인정하는 것은 핀트랄 및 유사한 재무 LLM의 책임 있는 배치 및 지속적인 개발에 중요하다.\n' +
      '\n' +
      '##9 윤리성명\n' +
      '\n' +
      '**에너지 효율.** 많은 대규모 언어 모델(LLM)과 유사한 우리의 FinTral 모델은 상당한 훈련 시간과 계산 자원이 필요했으며, 따라서 특별히 에너지 효율적이지 않다. 우리는 이것을 중요한 문제로 인식하고 보다 에너지 효율적인 모델을 개발하기 위한 지속적인 연구를 옹호한다.\n' +
      '\n' +
      '**Data.** 우리의 사전 훈련 데이터 세트는 광범위한 재정적 주제 및 출처를 포함하는 공개 도메인에서 수집된다. 이러한 데이터 세트는 금융 언어 모델링을 위한 포괄적인 범위를 제공하지만 공개적으로 사용할 수 있는 데이터에 내재된 잠재적인 편향과 한계를 인식해야 하므로 모델이 최대한 객관적이고 편향되지 않도록 해야 한다.\n' +
      '\n' +
      '**데이터 저작권.** SEC 파일, 뉴스 소스 및 소셜 미디어의 데이터를 포함하여 사용되는 모든 데이터 세트가 공개적으로 사용 가능한 소스에서 수집됨을 강조한다. 우리는 우리의 데이터 수집 프로세스가 이러한 소스의 저작권을 존중하고 독점 데이터를 침해하지 않는다는 것을 확인한다.\n' +
      '\n' +
      '**모델 출시.** 저희 모델들을 책임감 있게 출시할 계획입니다. 재정 데이터의 민감한 특성과 오용 가능성을 감안할 때 특히 실제 응용 프로그램에서 핀트랄의 사용에 대한 엄격한 지침과 조건을 구현할 것이다. 여기에는 윤리적 사용에 대한 명확한 지침과 시장 조작 또는 개인 정보 보호 위반과 같은 비윤리적 관행으로 이어질 수 있는 맥락에서의 배치 회피가 포함된다.\n' +
      '\n' +
      '**개인 정보.** 핀트랄은 공개된 데이터를 사용하여 개발되며, 이는 개인 정보 유출에 대한 우려를 완화한다. 그러나 재무 데이터의 민감한 특성을 감안할 때, 우리는 훈련된 모델에서 식별 가능한 개인 또는 기업 재무 정보가 검색되지 않도록 추가 예방 조치를 취했습니다.\n' +
      '\n' +
      '**Human Annotation.** 이 프로젝트에 관련된 Human Annotators는 금융 및 자연어 처리에 대한 전문 지식을 갖춘 전문가들이다. 주석 프로세스에는 민감하거나 개인적으로 식별할 수 있는 데이터가 사용되지 않았으며 윤리 지침 및 데이터 개인 정보 보호 표준을 준수했다. 인간 주석은 이 논문의 공동 저자이다.\n' +
      '\n' +
      '**편향 분석** 모든 언어 모델이 부주의하게 학습 데이터에 존재하는 편향을 영구화할 수 있음을 인식합니다. 핀트랄의 경우 잠재적인 편향이 금융 시장, 지역 또는 기업 주체와 관련될 수 있다. 우리는 그러한 편향을 식별하고 완화하기 위해 철저한 분석을 수행하여 모델의 출력이 가능한 한 공정하고 편향되지 않도록 했다. 그러나 사용자는 특히 모델을 실제 시나리오에 적용할 때 이러한 잠재적인 편향을 계속 인식해야 한다.\n' +
      '\n' +
      '**응용 프로그램**핀트랄은 재무 분석을 위한 고급 기능을 제공하지만 다른 강력한 도구와 마찬가지로 오용될 수 있습니다. 특히 민감한 재정적 상황에서 책임 있는 사용을 강조하는 것이 중요합니다. 사용자는 투기적 거래, 시장 조작 또는 금융 규정이나 윤리적 기준을 위반할 수 있는 모든 활동을 위해 핀트랄을 배치하는 것을 피해야 한다. 반대로 FinTral은 금융교육, 연구, 금융정보의 접근성 향상 등 유익한 응용의 가능성을 가지고 있다.\n' +
      '\n' +
      '**AI 사용** 우리 프로젝트에서 ChatGPT와 같은 AI 도구의 역할을 인정하는 것은 적절합니다. 특히, ChatGPT는 우리 문서의 문법 수정을 위해 최소 및 주로 사용되었다. 이 사용은 언어적 정확성을 높이고 우리 필기 자료의 가독성을 향상시키는 데 엄격하게 제한되었다. 핵심 연구, 분석 및 개발은 우리 팀에서 독립적으로 수행되었음을 명확히 하는 것이 중요합니다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '*[1]D. Araci(2019) FinBERT: 사전 훈련된 언어 모델을 사용한 금융 감정 분석. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[2]J. 배승 배승 양승 왕승 Tan, P. Wang, J. Lin, C. Zhou, 및 J. Zhou(2023) QWEN-vl: 이해, 현지화, 텍스트 판독 및 그 이상을 위한 다목적 비전-언어 모델. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[3]R. 조민 Lee, and H. Cavusoglu (2020) Corporate social network analysis: a deep learning approach. 정보 기술 및 시스템 워크샵(WITS 2020). 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[4]C. 리로이 채프먼 Hillebrand M. R. Stenzel, T. Deusser, D. Biesner, C. Bauckhage 및 R. 시파(2022) 트랜스포머를 사용하여 표 형식의 데이터에서 재무 보고서를 생성합니다. In International Cross-Domain Conference for Machine Learning and Knowledge Extraction, pp. 221-232. Cited by: SS1.\n' +
      '*[5]W. 진규 왕주영 롱엑스 장장 류병리 왕재수 배진 황과 Z Wei(2023) Disc-fnllm: 다중 전문가 미세 조정을 기반으로 한 중국 금융 대형 언어 모델. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[6]Z. 천원 천찬스마일리 Shah, I. Borova, D. Langdon, R. 무사 빈태 Huang, B. Routledge, and W. Y. Wang(2021) FinQA: a dataset of numerical reasoning over financial data. In Proceedings of 2021 Conference on Empirical Methods in Natural Language Processing, Online and Punta Cana, Dominican Republic, pp. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[7]Z. 천성호 리찬스마일리 마승 Shah and W. Y. Wang (2022) Con-vFinQA: 대화식 금융 질의 응답에서 수치 추론의 연쇄를 탐구한다. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 6279-6292. External Links: Link Cited by: SS1.\n' +
      '*[8]W. 장종 이종욱 임영식 성진 우현장 정승 장영 Zhuang, J. E. Gonzalez, I. Stoica, and E. P. Xing(2023) Vicuna: 90%* chatgpt 품질의 gpt-4를 인상하는 오픈 소스 챗봇. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[9]Z. 추현국 주영 왕필유 X, X 루규 최림 리재주, S. Li(2023) 데이터 중심의 금융 대형 언어 모델. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[10]T. Dao(2023) FlashAttention-2: 더 나은 병렬성과 작업 분할로 더 빠른 주의력. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[11]T. Dettmers, A. Pagnoni, A. Holtzman, L. Zettlemoyer (2023) Qlora: 양자화된 l lms의 효율적인 미세조정. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '* 13,000+ 가독성 측정을 위한 금융 용어 정의. In Proceedings of the The 4th Financial Narrative Processing Workshop @LREC2022, pp. 1-9. External Links: Link Cited by: SS1.\n' +
      '*[13]Y. 곽지 Xu, Y. 양(2023) 채팅이 금융 전문가입니까? 금융 자연어 처리에 대한 언어 모델 평가 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[14]U. Gupta(2023) Gpt-investar: 대규모 언어 모델을 이용한 연간 보고서 분석을 통한 주식 투자 전략 제고. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[15]H. Hofmann (1994) Statlog (독일 신용 데이터). 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[16]E. J. Hu, Y. Shen, P. Wallis, Z. 알렌주 이성 왕락 왕, W. Chen(2021) LORA: 대형 언어 모델의 저순위 적응. arXiv preprint arXiv:2106.09685. External Links: Link Cited by: SS1.\n' +
      '*[17]D. J. Islam, A. Kannappan, D. Kiela, R. 기안남 Scherrer, and B. Vidgen (2023) Financebench: 금융 질의 응답의 새로운 기준. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[18]A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. Singh Chaplot, D. de las Casas, F. Bressand, G. Lengyel, G. Lample, L. 사울니에 L. 레나드 라바우드 라초, P. 스톡, T. L. 스카오, T. 라브릴 왕태 라크루아와 W El Sayed(2023) MIST 7b. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[19]H. 강과 X Liu(2023) 금융에서 큰 언어 모델의 결핍: 환각에 대한 실증적 조사. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[20]M. 라 콰트라와 L. 카글리에오(2020) 재무 보고서 요약에 대한 종단 간 교육. In Proceedings of the 1st Joint Workshop on Financial Narrative Processing and MultiLing Financial Summarisation, pp. 118-123. External Links: Link Cited by: SS1.\n' +
      '*[21]H. 류창용 Li, 및 Y. J. Lee(2023)는 시각적 명령어 튜닝을 갖는 개선된 베이스라인들이다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[22]H. 류창용 리병리 장승 Shen, and Y. J. Lee (2024) Llava-next: 개선된 추론, ocr, 및 세계 지식. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[23]H. 류창용 Li, 및 Y. J. Lee(2023)는 시각적 명령어 튜닝을 갖는 개선된 추론이다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[24]H. 류창용 Li, 및 Y. J. Lee(2023)는 시각적 명령어 튜닝을 갖는 개선된 베이스라인들이다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[25]H. 류창용 리병리 장승 Shen, and Y. J. Lee (2024) Llava-next: 개선된 추론, ocr, 및 세계 지식. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[26]H. 류창용 Li, 및 Y. J. Lee(2023)는 시각적 명령어 튜닝을 갖는 개선된 추론이다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[27]H. 류창용 Li, 및 Y. J. Lee(2023)는 시각적 명령어 튜닝을 갖는 개선된 베이스라인들이다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[28]H. 류창용 리병리 장승 Shen, and Y. J. Lee (2024) Llava-next: 개선된 추론, ocr, 및 세계 지식. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[29]H. 류창용 Li, 및 Y. J. Lee(2023)는 시각적 명령어 튜닝을 갖는 개선된 추론이다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[30]H. 류창용 Li, 및 Y. J. Lee(2023)는 시각적 명령어 튜닝을 갖는 개선된 베이스라인들이다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[31]H. 류창용 리병리 장승 Shen, and Y. J. Lee (2024) Llava-next: 개선된 추론, ocr, 및 세계 지식. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[32]H. 류창용 Li, 및 Y. J. Lee(2023)는 시각적 명령어 튜닝을 갖는 개선된 추론이다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[33]H. 류창용 리병리 장승 Shen, and Y. J. Lee (2024) Llava-next: 개선된 추론, ocr, 및 세계 지식. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '\n' +
      '[MISSING_PAGE_POST]\n' +
      '\n' +
      '샤오양 류, 구오순 왕, 다오첸 자. 2023b. Fingpt: 금융 대형 언어 모델을 위한 인터넷 규모의 데이터 민주화. _ arXiv preprint arXiv:2307.10485_.\n' +
      '* 루카스 등(2021) Lefteris Loukas, Manos Fergadiotis, Ion Androutsopoulos, and Prodromos Malakasiotis. 2021. EDGARCORPUS: 수십억의 토큰이 세상을 돌게 한다. [Proceedings of the Third Workshop on Economics and Natural Language Processing_] 페이지 13-18, Punta Cana, Dominican Republic. 컴퓨터 언어학과의 연관성\n' +
      '* Maia et al. (2018) Macedo Maia, Siegfried Handschuh, Andre Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur. 2018. Www\'18 오픈 챌린지: 금융 오피니언 마이닝 및 질의 응답. 1941-1942 페이지.\n' +
      '*Malo et al. (2013) Pekka Malo, Ankur Sinha, Pyry Takala, Pekka Korhonen, 및 Jyrki Wallenius. 2013. Good 부채 또는 Bad 부채: 경제 텍스트에서 의미론적 지향점 탐지.\n' +
      '* Masry et al. (2022) Ahmed Masry, Xuan Long Do, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. 2022. ChartQA: 시각적 및 논리적 추론으로 차트에 대한 질문 응답의 벤치마크. _Findings of the Association for Computational Linguistics: ACL 2022_, pages 2263-2279, Dublin, Ireland. 컴퓨터 언어학과의 연관성\n' +
      '* Mik(2017) Eliza Mik. 2017. Smart Contract: terminology, technical limitations and real world complexity. _ 법, 혁신 및 기술_, 9(2):269-300.\n' +
      '* Mishra et al. (2021) Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. 자연어 크라우드소싱 명령어를 통한 크로스-태스크 일반화 arXiv preprint arXiv:2104.08773_.\n' +
      '* 모델(2023) 클로드 모델. 2023. 모델 카드 및 클로드 모델에 대한 평가. [https://www-files.anthropic.com/production/image/Model-Card-Claude-2.pdf] (https://www-files.anthropic.com/production/image/Model-Card-Claude-2.pdf).\n' +
      '* Mukherjee et al. (2022) Rajdeep Mukherjee, Abhinav Bohra, Akash Banerjee, Soumya Sharma, Manjunath Hegde, Afreen Shaikh, Shivani Shrivastava, Koustuv Dasgupta, Niloy Ganguly, Saptarshi Ghosh, and Pawan Goyal. 2022. ECTSum: long earnings call transcript의 bullet point 요약을 위한 새로운 벤치마크 데이터세트. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 10893-10906, 아랍에미리트 아부다비. 컴퓨터 언어학과의 연관성\n' +
      '* NIST(2018) NIST. 2018. 주요 인프라 사이버 보안 개선을 위한 프레임워크. [https://nvlpubs.nist.gov/nistpubs/cswp/nist.cswp.40162018.pdf] (https://nvlpubs.nist.gov/nistpubs/cswp/nist.cswp.40162018.pdf).\n' +
      '* OpenAI(2023a) OpenAI. 2023a. Chatgpt. [https://openai.com/blog/chatgpt] (https://openai.com/blog/chatgpt).\n' +
      '* OpenAI(2023b) OpenAI. 2023b. Gpt-4 기술 보고서입니다\n' +
      '* OpenAI(2023c) OpenAI. 2023c. Gpt-4 기술 보고서입니다\n' +
      '* Quinlan(2017) Ross Quinlan. 통계분석 회귀 분석 포아송 회귀 분석 포아송 회귀 분석 포아송 UCI 머신러닝 리포지토리. DOI:[https://doi.org/10.24432/C59012](https://doi.org/10.24432/C59012)\n' +
      '* Radford et al. (2021) Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021. 자연어 감독으로부터 전이 가능한 시각적 모델을 학습하는 단계.\n' +
      '* Rafailov et al. (2023) Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2023. 직접 선호도 최적화: 언어 모델은 은밀하게 보상 모델이다.\n' +
      '* Rajpoot and Parikh (2023) Pawan Kumar Rajpoot and Ankur Parikh. 2023. Gpt-firne: 대형 언어 모델을 이용한 금융 관계 추출을 위한 문맥 내 학습.\n' +
      '* 레이놀즈와 맥도넬(2021) 라리아 레이놀즈와 카일 맥도넬. 2021. 대형 언어 모델을 위한 프롬프트 프로그래밍: 수-샷 패러다임을 넘어서다. _Extended Abstracts of 2021 CHI Conference on Human Factors in Computing Systems_, pages 1-7.\n' +
      '* Salinas Alvarado et al.(2015) Julio Cesar Salinas Alvarado, Karin Verspoor, and Timothy Baldwin. 2015. Domain Adaptation of named entity recognition to support credit risk assessment. [Proceedings of the Australasian Language Technology Association Workshop 2015_, pages 84-90, Parramatta, Australia.\n' +
      '* Sarmah et al. (2023) Bhaskarjit Sarmah, Tianjie Zhu, Dhagash Mehta, and Stefano Pasquali. 2023. 대규모 언어 모델을 사용하여 재무 보고서에서 정보를 추출하는 환각을 줄이기 위해.\n' +
      '* Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. 툴포머: 언어 모델들은 스스로 툴들을 사용하는 것을 가르칠 수 있다.\n' +
      '* Shah et al. (2023a) Agam Shah, Suvan Paturi, and Sudheer Chava. 2023a. 조 달러 단어: 새로운 금융 데이터세트, 과제 및 시장 분석. _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 6664-6679, Canada, Toronto. 컴퓨터 언어학과의 연관성\n' +
      '* Shah et al. (2023b) Agam Shah, Ruchit Vithani, Abhinav Gullapalli, and Sudheer Chava. 2023b. Finer: Financial named entity recognition dataset and weak-supervision model.\n' +
      '* 신하와 칸다이트(2020) 앙쿠르 신하와 탄메이 칸다이트. 2020. 뉴스가 상품 시장에 미치는 영향: 데이터세트 및 결과.\n' +
      '* Soboleva et al. (2023) Daria Soboleva, Faisal Al-Khateeb, Robert Myers, Jacob R Steeves, Joel Hestness, and Nolan Dey. 2023. 슬림파자마: RedPajama의 627B 토큰 클리닝 및 중복제거 버전.\n' +
      '\n' +
      '와타루 소마, 이레나 보덴스카, 아오야마 히데아키 2019년 딥러닝 방법을 이용한 향상된 뉴스 감성 분석. _ Journal of Computational Social Science_, 2(1):33-46.\n' +
      '* Soun et al. (2022) 예준 Soun, 재민 유, 민용 조, 지형 전, 우강. 2022. 희박한 잡음 트윗으로부터 자기 지도 학습을 통한 정확한 주식 이동 예측. _2022 IEEE International Conference on Big Data(Big Data)_, pages 1691-1700. IEEE.\n' +
      '* Team et al. (2022) Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul R. 바람, 톰 헤니건, 벤자민 리, 파비오 바이올라, 말콤 레이놀즈, 위안종 쉬, 라이언 도허티, 일라이 콜린스, 클레멘스 마이어, 엘라이자 러더포드, 에리카 모레라, 카림 아엽, 메가 고엘, 조지 터커, 엔리케 피케라스, 막심 크리쿤, 이인 바르, 니콜라이 사비노프, 이보 다니헬카, 베카 로엘로프스, 아나이스 화이트, 안데르스 안드레아센, 타마라 폰 글렌, 락슈만 야가티, 메흐란 카제미, 루카스 곤잘레즈, 미샤 칼만, 야쿠브 시그노스키, 알렉산드르 프레데트, 샬롯 스미스, 로라 컬프, 레브 프롤레프, 이루안, 나탈리 클레이, 필 크로네, 토마스 슈체르, 제프리 자오, 바르텍 페르츠, 디안 유, 하이디 블론아즈, 잭 W. 라에, 한루, 로랑 시프레, 마첼로 마조니, 프레드 알코버, 댄 가렛, 메간 반스, 샨타누 타쿠르, 제이콥 오스틴, 아룬 아후자, 루이보 리우, 윈슈안 리우, 세라 코건, 제레미 첸, 차오 지아, 샤리크 왕, 조에 슈리타, 제인 라바노프, 아제이 카나, 데니 샤리크 왕, 제인 라바노프, 아제이 카나 2023. 쌍둥이자리: 매우 유능한 멀티모달 모델들의 패밀리.\n' +
      '\n' +
      '휴고 투브론, 루이 마틴, 케빈 스톤, 피터 바트라, 프라지왈 바바, 슈루티 바슐, 댄 비켈, 루카스 블레커, 소마야 바트라, 다비드 에시오부, 주드 페르난데스, 제레미 푸, 웨닌 푸, 브라이언 가오, 베다누즈 고스바미, 나만 고얄, 앤서니 하르트쇼른, 사하르 호세이니, 마데안 라흐흐흐, 마데안 마르코브, 예신 니에, 앤드류 폴턴, 제레미 라흐슈, 이고르 마르코브, 예신 니에, 앤드류 미하이로프, 푸시안 라흐흐, 티보르 마르코브, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 루이바흐, 2023. 라마 2: 오픈 파운데이션 및 미세 조정 채팅 모델.\n' +
      '\n' +
      'Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clementine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Saneviero, Alexander M. 러쉬와 토마스 울프 2023. Zephyr: lm 정렬의 직접 증류.\n' +
      '\n' +
      '넵 왕, 홍양 양, 크리스티나 댄 왕 2023a. Fingpt: 금융 데이터 세트에서 오픈 소스 대형 언어 모델에 대한 명령어 튜닝 벤치마크.\n' +
      '\n' +
      '왕자오, 리유항, 준다우, 재현순, 장샤오펑 등이다. 2023b. Finvis-gpt: 재무 차트 분석을 위한 멀티모달 대형 언어 모델.\n' +
      '\n' +
      '위제우, 위장, 위웨이셴, 그리고 왕준. 2018. Hybrid deep sequential modeling for social text-driven stock prediction. _Proceedings of the 27th ACM international conference on information and knowledge management_, pages 1627-1630.\n' +
      '\n' +
      '시지 우, 오잔 이르소이, 스티븐 루, 바딤 다브라볼스키, 마크 드레드제, 세바스티안 게르만, 프라반잔 캄바두르, 데이비드 로젠버그, 기디언 만. 2023. Bloomberggpt: 금융을 위한 대규모 언어 모델. _ arXiv preprint arXiv:2303.17564_.\n' +
      '\n' +
      '시타오 샤오, 정류, 페이티안 장, 니클라스 무엔히오프. 2023. C-pack: 일반적인 중국어 임베딩을 진전시키기 위한 패키징된 리소스.\n' +
      '\n' +
      '키안치안 시에, 웨이광한, 샤오장, 옌자오라이, 민펑, 알레한드로 로페즈-리라, 지민황 등이다. 2023. Pixiu: 금융에 대한 대규모 언어 모델, 명령어 데이터 및 평가 벤치마크.\n' +
      '\n' +
      '유모 슈와 셰이 B 코헨 2018. 트윗 및 역사적 가격으로부터의 주식 이동 예측. _Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 1970-1979.\n' +
      '\n' +
      '항양, 유보천, 강류, 양샤오, 준자오. 2018. Dcfee: 자동 라벨링된 훈련 데이터에 기반한 문서 수준의 중국 금융 이벤트 추출 시스템. ACL 2018의 _Proceedings, System Demonstrations_, pages 50-55.\n' +
      '\n' +
      '홍양양, 샤오양 류, 크리스티나 댄 왕. 2023a. Fingpt: 오픈소스 금융 대형 언어 모델들_ FinLLM Symposium at IJCAI 2023_.\n' +
      '\n' +
      '이양, Yixuan Tang, 그리고 Kar Yan Tam. 2023b. 투자: 금융 도메인 명령어 튜닝을 이용한 투자를 위한 대규모 언어 모델.\n' +
      '* Zhang et al. (2023a) Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu. 2023a. 명령어-핑거: 범용 대용량 언어 모델의 명령어 튜닝에 의한 금융 감정 분석. _ FinLLM Symposium at IJCAI 2023_.\n' +
      '* Zhang et al. (2023b) Boyu Zhang, Hongyang Yang, Tianyu Zhou, Ali Babar, and Xiao-Yang Liu. 2023b. 검색 증강된 대규모 언어 모델을 통해 금융 감정 분석을 강화합니다.\n' +
      '* Zheng et al. (2019) Shun Zheng, Wei Cao, Wei Xu, and Jiang Bian. 2019. Doc2edag: An end-to-end document-level framework for chinese financial event extraction. _ arXiv preprint arXiv:1904.07535_.\n' +
      '* Zhou et al. (2021) Zhihan Zhou, Liqian Ma, and Han Liu. 2021. 이벤트를 거래: 뉴스 기반 이벤트 기반 거래를 위한 기업 이벤트 탐지. _Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021_, pages 2114-2124, Online. 컴퓨터 언어학과의 연관성\n' +
      '\n' +
      '## 부록 상세 관련 작품\n' +
      '\n' +
      '**금융 NLP 모델 및 이의 과제** 전통적인 자연 언어 처리(NLP) 기술의 성공적인 적용으로 다양한 금융 관련 문제가 있었다. 여기에는 금융 뉴스의 명명된 개체 인식(Salinas Alvarado et al., 2015) 감성 분석(Souma et al., 2019; Araci, 2019), 이벤트 추출(Yang et al., 2018; Zheng et al., 2019), 금융 보고서 생성(Chapman et al., 2022), 및 금융 컨텍스트에서의 텍스트 요약(La Quatra and Cagliero, 2020)이 포함된다.\n' +
      '\n' +
      '그러나 금융 부문에 도메인별 작업을 위한 NLP 모델을 배치하는 것은 몇 가지 별개의 문제에 직면해 있다. 첫째, 금융 언어의 복잡하고 전문 용어가 풍부한 특성은 모델로부터 바람직한 성과를 달성하는 데 상당한 장벽을 제기하며, 종종 도메인 특정 문서에 대한 이해의 격차를 초래한다(Mik, 2017). 둘째, 재무에서 데이터 주석과 관련된 높은 비용과 결합된 주석 데이터 세트의 부족은 이러한 모델의 발전을 방해한다. 셋째, 기존의 NLP 모델은 추론 능력, 특히 위험 평가 및 투자 컨텍스트에서 정보에 입각한 의사 결정과 같은 중요한 작업에서 부족한 경우가 많다(Liu et al., 2023b). 또한 금융 시장의 역동적인 특성은 현재 많은 모델이 가지고 있지 않은 특징인 실시간 분석이 가능한 모델을 필요로 한다. 도형과 기호로 채워진 재무문서의 공통요소인 수치정보처리 역시 재무문서의 이해에 중대한 과제를 제기하고 있다. 많은 그래프와 그림이 이러한 문서에서 이미지 형식이라는 사실로 인해 문제가 더욱 악화된다. 마지막으로, 많은 NLP 모델의 광범위한 적응성은 제한된 상태로 남아 있는데, 이는 일반적으로 특정 단일 작업 기능에 최적화되고 여러 작업에 걸쳐 일반화할 수 있는 능력이 부족하기 때문이다(Mishra et al., 2021). 이러한 문제에 비추어 볼 때, 재무 문서 작업을 위한 동적 및 복잡한 요구 사항에 맞춘 보다 발전적이고 다재다능하며 강력한 NLP 모델을 개발하기 위한 지속적인 연구 노력이 필수적이다.\n' +
      '\n' +
      '**금융 대형 언어 모델** 금융은 FinBERT(Araci, 2019)의 도입을 시작으로 대형 언어 모델의 상당한 발전을 목격했다. 이러한 초기 기여도는 재무 감정 분석에서 사전 훈련된 언어 모델을 사용하기 위한 우선 순위를 설정하여 성능 메트릭의 현저한 개선을 보여준다. 2023년, 일련의 획기적인 모델들이 그 분야를 더욱 추진했다. BloombergGPT(Wu et al., 2023)는 광범위한 금융 데이터 코퍼스에서 훈련된 500억 파라미터 모델로 등장하였다. 다양한 데이터 세트에 대한 교육을 통해 일반 LLM 벤치마크에서 강력한 성능을 유지하면서 재무 작업에 탁월할 수 있었다. PIXIU(Xie et al., 2023)가 이어서, 명령 데이터로 미세 조정된 금융 LLM과 함께 포괄적인 프레임워크를 제시한다. PIXIU는 새로운 명령어 데이터 세트와 재무 LLM의 평가 벤치마크를 결합하여 재무 AI의 오픈 소스 개발을 발전시키는 데 중요한 발전이었다. 같은 해 금융심리 분석을 강화하기 위해 명령어 튜닝을 활용한 Instruct-FinGPT(Zhang et al., 2023a)가 도입되었다. 이 모델은 깊은 수치적 이해와 맥락적 이해가 필요한 시나리오에서 특히 우수했다. 또 다른 중요한 발전은 문맥 내 학습을 이용한 재무 관계 추출에 초점을 맞춘 GPT-FinRE(Rajpoot and Parikh, 2023)였다. 이 모델은 두 가지 뚜렷한 검색 전략을 사용하여 높은 효과와 정확도를 보여주었다. 금융 LLM에서 멀티모달 기능을 추가하여, FinVis-GPT(Wang et al., 2023b)가 제안되었으며, 금융 차트 분석을 위해 명시적으로 설계되었다. 이 모델은 명령어 조정 및 멀티모달 기능과 함께 LLM의 힘을 활용하여 관련 작업에서 우수한 성능을 보여주었다. GPT-InvestAR(Gupta, 2023)은 LLM을 이용하여 연도별 보고서를 분석하여 주식 투자 전략을 제고하고자 하였다. 이 접근법은 전통적인 시장 수익률을 능가하는 유망한 결과를 산출했으며, 이는 투자 전략에서 LLM의 잠재력을 강조한다. InvestLM(Yang et al., 2023b)은 경제 텍스트를 이해하고 실질적인 투자 자문을 제공하는 데 강한 역량을 보였다. 검색-증강 LLMs(Zhang et al., 2023b)로 LLMs를 경제 심리 분석에 직접 적용하는 문제를 해결하여 상당한 성능 향상을 달성했다. FinGPT(Wang et al., 2023a)는 금융 데이터 세트에서 LLM의 Instruction Tuning에 대한 벤치마크를 생성하는 데 중점을 두었으며, 금융 도메인에 특화된 GPT 기반 모델에 대한 통합 도전과 잠재적인 솔루션을 강조했다. Sarmah et al. (2023)은 통화 기록을 얻기 위한 정보 추출에서 환각을 줄이고 검색 증강 생성 기술을 메타데이터와 결합하여 정확도를 향상시켰다. FinLMEval Guo et al.(2023)은 금융 자연어 처리 작업에서 LLM의 성능을 평가하여 금융 영역에서 LLM을 향상시키기 위한 지속적인 노력에 대한 기초 평가를 제공했다. DISC-FinLLM Chen et al.(2023)은 Multiple Experts Fine-tuning Framework에 기반을 둔 중국 금융 LLM을 도입하여 기준 모형에 비해 다양한 금융 시나리오에서 향상된 성능을 보였다. 마지막으로, 데이터 중심 금융 LLMs Chu et al.(2023)에 대한 연구는 데이터 전처리와 사전 이해를 강조하여 금융 업무를 LLMs로 더 잘 처리하기 위한 새로운 접근법을 제시함으로써 경제 분석 및 해석 작업에 대한 실질적인 성능 향상을 가져왔다. 이러한 기여는 LLM의 급속한 활용 성장과 다양한 금융 응용 분야에서 엄청난 잠재력을 종합적으로 설명하여 금융 분석, 예측 및 의사 결정 프로세스를 혁신하는 능력을 보여줍니다.\n' +
      '\n' +
      '## 부록 B 사전 학습 데이터 상세\n' +
      '\n' +
      '공통 크롤 데이터 공통 크롤 데이터세트, 특히 100억 개 이상의 파일로 구성된 2019년부터 2021년까지의 C4 스냅샷은 초기 광범위한 데이터 소스였다. ELECTRA Finance 도메인 특화 언어 모델을 통한 텍스트 분류는 데이터셋이 금융 내용과 강한 관련성을 유지하도록 하였다. 엄격한 도메인 필터링 및 데이터 가지치기를 사용하여 재무 특정 텍스트를 분리하고 관련 없는 내용을 폐기했다. 최종 데이터 세트는 3억 개의 영어 전용 파일과 5억 개의 다국어 파일을 포함하여 8억 개의 문서로 구성되어 재무 분석을 위한 포괄적인 기반을 제공한다.\n' +
      '\n' +
      'News ScrapingOur 접근법은 특히 2022년 7월부터 2023년 7월까지 3억 개의 데이터 라인을 사용하여 뉴스 스크래핑으로 확장되었으며, 이 데이터 세트는 시장 동향과 금융 내러티브를 심층적으로 분석할 수 있었다. 데이터 세트는 야후, 추구 알파, 이스트머니 및 이카이와 같은 소스를 통합하여 금융 시장에 대한 글로벌 관점을 요약했다. 이 다중 소스 전략은 강력하고 상호 참조되며 신뢰할 수 있는 데이터 세트를 보장했다. 우리는 뉴스 데이터 세트를 구축하기 위해 Yang et al.(2023)에서 구현된 스크래퍼를 사용했다.\n' +
      '\n' +
      'SEC Filings 1993년부터 2023년까지 EDGAR SEC 데이터베이스의 철저한 스크래치는 공식 파일에서 정확한 비즈니스, 재무 및 회계 정보에 대한 상세한 기록을 제공했다. 이 데이터 세트는 영어로만 상당한 깊이를 추가하여 역사적 시장 규제 영향 및 기업 재무 기동 분석을 가능하게 했다.\n' +
      '\n' +
      '웹사이트 및 소셜 미디어 추가 데이터는 상위 5000개 회사 웹사이트와 페이스북, 인스타그램 및 레딧과 같은 플랫폼의 소셜 미디어 존재에서 얻었다. 이 데이터 세트는 직접적인 기업 커뮤니케이션을 제공하고 특히 r/WallStreetBets Reddit 커뮤니티의 광범위한 긁힘을 통해 광범위한 시장 감정과 대중의 인식을 포착했습니다.\n' +
      '\n' +
      '## 부록 C 재무 데이터 정리 및 중복제거 파이프라인\n' +
      '\n' +
      '표 1에 표시된 다양한 텍스트 말뭉치를 수집하기 시작하여 2.9B 문서로 구성된 데이터 세트를 생성했다. 우리가 수집한 데이터는 깨끗하지 않을 뿐만 아니라 대규모 복제에도 시달리고 있다. Soboleva et al.(2023)에 의해 보여지는 바와 같이, 깨끗하고 중복되지 않은 데이터를 사용하는 것은 모델 트레이닝을 위해 계산적으로 효율적이다. 재무 데이터에 대한 데이터 정리 및 중복 제거 파이프라인은 원시 데이터가 초기에 처리되는 URL 필터링으로 시작한다. 이 중요한 단계는 관련 URL만 포함하도록 보장하여 관련 없거나 부적합한 소스를 제외함으로써 데이터 세트의 품질을 향상시킨다. URL이 유선화되면 텍스트 추출 단계가 시작되며, 이에 의해 선택된 URL로부터 문서의 내용이 세심하게 추출되고, 큰 데이터세트 스케일을 유지하면서 이미지를 필터링한다. 이어 언어 식별 단계에서는 토큰의 언어를 기준으로 분류하여 비영어 문서를 제외하였다. 이후 파이프라인은 문서별 도메인 기반 필터링을 통해 데이터를 추가로 정제하여 55B 토큰의 비재무 문서를 제외하여 재무 도메인에 적합한 1,000억 토큰으로 좁힌다. 데이터 프라이버시 및 관련성의 중요성을 인식하는 파이프라인은 민감한 정보를 제거하는 것을 통합하며, 이는 FinBERT Araci(2019)를 사용하여 구축된 분류기를 사용하여 수행된다. 라인별 보정은 정확도를 높이고 중요한 정보의 5B 토큰을 필터링합니다. 광범위한 퍼지 중복 제거 프로세스는 데이터를 380억 토큰으로 줄입니다. 그 다음에는 또 다른 130억 개의 토큰을 트리밍하는 Exact 중복 제거 방법이 뒤따른다. 마지막으로, 텍스트 클리닝 프로세스는 모든 민감한 정보를 포함하는 5B 부적절한 토큰을 식별하고 제외한다. 궁극적으로 파이프라인은 간소화된 재무 데이터 세트를 만들어 콘세스 20B 토큰 재무 데이터 세트에서 절정에 달한다. 파이프라인은 그림 C.1에 나와 있다.\n' +
      '\n' +
      '## 부록 D 다운스트림 데이터세트 세부사항\n' +
      '\n' +
      '주목할만한 데이터 세트에는 감성 분석에 사용되는 FPB 및 FiQA-SA가 있으며 전자는 48,450개의 뉴스 텍스트[11]를 포함하고 후자는 11,730개의 뉴스 헤드라인 및 트윗[11]을 포함한다. 496개의 FOMC 전사체로 구성된 FOMC 데이터 세트는 매키시-도비시 분류 작업[12]을 제공하는 반면, 11,412개의 뉴스 헤드라인이 있는 헤드라인 데이터 세트는 뉴스 헤드라인 분류[13]를 돕는다. 명명된 개체 인식은 NER 및 Finer-Ord 데이터 세트의 초점이다[11, 12]. 우리는 텍스트 요약을 위해 ECTSUM과 EDTSUM[10, 11]을 가져왔다. 텍스트 분류를 위해 독일과 호주의 두 가지 신용 점수 데이터 세트를 포함했다[12, 13]. 본 논문에서 소개한 FinQA와 ConvFinQA[3, 2]를 수치이해 과제로 사용하였다. 우리는 주식 이동 예측을 위해 BigData22, ACL18 및 CIKM18 [14, 15, 16]의 세 가지 기존 데이터 세트를 사용했다.\n' +
      '\n' +
      '**기업 공개 데이터 세트** 본 연구는 기업 규제 공시의 마이크로코즘 역할을 하는 세 가지 데이터 세트를 사용했다. 각각은 재무 건전성 및 비즈니스 위험에 대해 투자자에게 알리기 위해 공기업이 매년 보안 및 교환 위원회(SEC)에 제출하는 포괄적인 보고서의 라벨이 붙은 텍스트 세그먼트로 구성된다. Firm Social Relationships (FSR) 데이터셋은 기업 상호 작용의 복잡한 네트워크에 대한 통찰력을 제공하며, 소유, 제휴, 경쟁 및 보드 연동 관계의 몇 가지 주요 관계 차원으로 분류된다[1]. 그들은 초점 회사의 공개에서 다른 회사를 언급하는 3931개의 문장을 확인했다. 도메인 전문가들은 포커스 기업과 기업 간의 관계를 이러한 관계 중 하나 또는 하나로 분류했다. \'사이버 전략\'(CS) 데이터 세트에는 기업의 사이버 보안 전략을 설명하는 공개 문장[1]이 포함되어 있다. 본 연구에서는 정보기술 관련 1,196개의 문장에 대한 정보기술의 위험요인(Risk Factors)을 11개의 IT 위험요인(Risk Factors) 중 1개 또는 1개 항목으로 분류한 후, 실제 시나리오에서 이론적인 모델 성과와 실용적 효용성 간의 차이를 검증한 제로샷 평가 프레임워크(zero-shot evaluation framework)를 구축하고자 한다. 본 연구에서 개발한 데이터 셋은 정보기술 관련 1,196개의 문장에 대한 정보기술 관련 1,196개의 문장에 대한 정보기술 관련 1,196개의 IT 위험요인(Risk Factors)을 대상으로 하였다.\n' +
      '\n' +
      '금융차트 이해 데이터세트\n' +
      '\n' +
      'FinVQA 데이터 세트는 이미지에 포함된 도표 및 그래프에 표시된 추세 및 세부 사항에 대한 질문과 관련된 작업을 다룬다. 이 데이터 세트는 라인, 바, 캔들 차트와 같은 다양한 재무 차트를 포함하며, 모두 인간에 의해 세심하게 주석이 달리고 각 이미지와 관련된 멀티턴 대화가 수반된다. 우리는 FinVQA 데이터 세트의 두 가지 버전을 개발했다. 그림 D.1에 도시된 첫 번째는 주식 시장 차트와 관련된 간단한 질문에 초점을 맞추고 모델을 통해 추세를 식별하면서 이러한 차트를 해석해야 한다.\n' +
      '\n' +
      '도 C.1: 우리 데이터 중복제거 파이프라인의 설명\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:19]\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:20]\n' +
      '\n' +
      '- 이전 가격) / 비교를 위해 표준화하는 이전 가격. 주식과 시장지수 수익률 간의 피어슨 상관계수를 계산하여 함께 얼마나 밀접하게 움직이는지를 측정한다. 또한 주식 베타 계수를 결정하여 시장에 대한 변동성을 평가합니다. 시각적 통찰력을 위해 시장 지수에 대한 주식 수익률의 산점도를 표시합니다. 시장지수를 독립변수로, 종목을 종속변수로 하여 선형회귀분석을 실시하여 시장에 대한 시장의 영향력을 더욱 탐색한다. 마지막으로, 경제 상황 및 산업별 뉴스와 같은 외부 요인이 주식 성과에 상당한 영향을 미칠 수 있으므로 고려하십시오. **" 거부"**: "기업의 주식 성과와 전반적인 시장 성과를 연관시키는 몇 가지 방법이 있습니다.\\n\\n|. 시가총액: 기업의 시가총액, 즉 시가총액은 미지급 주식 총수와 현재 주가를 곱하여 계산한다. 기업의 시가총액은 주식시장의 전체 시가총액과 비교하여 기업의 시장 노출을 결정할 수 있다.\\ n|. 산업 평균 주식 성과: 기업의 주식 성과와 해당 산업의 평균 주식 성과를 비교하는 것은 기업이 동료에 비해 어떻게 수행하는지에 대한 통찰력을 제공할 수 있다. 부문 성과: 기업의 주식 성과와 동일한 부문의 주식의 성과를 비교하는 것은 기업이 동일한 산업의 다른 기업에 비해 어떻게 수행하는지에 대한 통찰력을 제공할 수 있다. 경제 지표: GDP, 인플레이션, 이자율 등의 경제 지표는 주식 시장과 개별 기업의 전반적인 성과에 영향을 미칠 수 있다. 기업의 주식 성과와 이러한 경제 지표 간의 상관관계를 분석함으로써 투자자는 더 광범위한 경제 추세가 기업의 성과에 얼마나 영향을 미칠 수 있는지에 대한 통찰력을 얻을 수 있다."\n' +
      '\n' +
      '그림 D.5: 재무 AI 피드백 데이터 세트로부터의 예제\n' +
      '\n' +
      '환각이 없는 예\n' +
      '\n' +
      '**알림**: 금융 영역에서 \'저/무문서 대출\'의 정의는 무엇인가?\n' +
      '\n' +
      '**위키피디아**: No-Doc 또는 Low-Doc 대출(abbr: No/Low Documentation Loan)은 대출자가 대출자에게 소득 문서를 제공할 필요가 없거나 거의 문서가 필요하지 않은 대출을 의미한다.\n' +
      '\n' +
      '**핀트랄-RL-T&R**: 낮은/무문서 대출은 잠재적 차용인이 고용, 소득 또는 자산에 관한 정보를 거의 또는 전혀 제공하지 않으면서 모기지론을 신청할 수 있게 한다. 이러한 대출에 대한 규제는 2008년 이후 크게 발전했지만 비전통적인 금융 상황에서 일부 차용인에게 옵션으로 남아 있다.\n' +
      '\n' +
      '**Annotator Rating:**:\n' +
      '**Annotator Rating:**:\n' +
      '**ChatGPT**: 낮은/무문서 대출은 대출자가 소득 및 자산 검증과 같은 광범위한 재무 문서를 제공하도록 요구되지 않는 모기지 또는 대출의 유형으로서, 자격을 갖추기 쉽지만 종종 더 높은 이자율을 초래한다.\n' +
      '\n' +
      '**Annotator Rating:**:\n' +
      '**GPT-4**: 저/무문서 대출은 차용인의 소득, 자산 또는 고용에 대한 최소 또는 무검증이 필요한 대출의 한 유형으로, 전통적인 소득원이나 문서를 가질 수 없는 개인이 자주 사용한다.\n' +
      '\n' +
      '**Annotator Rating:**:\n' +
      '**Annotator Rating:**:\n' +
      '\n' +
      '** LLMs 환각의 예**\n' +
      '\n' +
      '즉시: 금융 영역에서 \'오픈 마켓\'의 정의는 무엇인가?\n' +
      '\n' +
      '**위키피디아**: 공개 시장은 자유 시장 활동에 대한 무역 장벽이 없는 경제 시스템이다. 공개 시장에서 구매자와 판매자는 불공정한 인허가 계약, 자의적인 세금, 조합, 보조금 및 정기적인 시장 운영에 영향을 미치는 기타 규정과 같은 공통 장벽 없이 자유롭게 사업을 할 수 있다.\n' +
      '\n' +
      '**핀트랄-RL-T&R**: 공개 시장은 자유 시장 활동에 대한 장벽이 거의 또는 전혀 없는 경제 시스템이다. 개방 시장은 관세, 세금, 라이선스 요구 사항, 보조금, 조합 및 자유 시장 활동을 방해하는 기타 규정 또는 관행이 없는 것이 특징이다. 오픈마켓은 경쟁적 진입장벽이 존재할 수 있지만, 결코 어떠한 규제적 진입장벽이 존재하지 않는다.\n' +
      '\n' +
      '**Annotator Rating:**:\n' +
      '**챗GPT**: 금융에서 오픈마켓은 거래소와 같이 제3자의 개입 없이 매수자와 매도자 간에 증권이 직접 거래되는 장터를 의미한다.\n' +
      '\n' +
      '**Annotator Rating:**:\n' +
      '**GPT-4**: 금융 영역에서의 "오픈 마켓"은 자유 시장 활동에 대한 장벽이 거의 없는 경제 시스템을 의미한다. 일반적으로 공급과 수요에 의해 결정되는 가격과 관세, 할당량 또는 규제 측면에서 최소한의 정부 개입과 함께 재화와 서비스의 무제한 구매 및 판매를 포함한다. 이 개념은 증권이 자유롭게 거래되는 자본시장의 운영에서 기본이다.\n' +
      '\n' +
      '**Annotator Rating:**:\n' +
      '**Annotator Rating:**:\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l} Examples of No Hallucinations in LLMs \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: LLMs의 환각 사례 그림 D.6: 상이한 FinVQA 태스크에 대한 상이한 VL 모델의 사례\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:24]\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>