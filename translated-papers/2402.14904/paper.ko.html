<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 워터마킹은 언어 모델을 방사성으로 만든다\n' +
      '\n' +
      'Tom Sander\\({}^{1,2,*}\\)\n' +
      '\n' +
      'Pierre Fernandez\\({}^{1,3,*,\\dagger}\\)\n' +
      '\n' +
      'Alain Durmus\\({}^{2}\\)\n' +
      '\n' +
      'Matthijs Douze\\({}^{1}\\)\n' +
      '\n' +
      'Teddy Furon\\({}^{3}\\)\n' +
      '\n' +
      'FAIR, Meta, \\({}^{2}\\)CMAP, Ecole polytechnique, \\({}^{3}\\)Inria Rennes\n' +
      '\n' +
      '등분, \\({}^{*}\\)등분, \\({}^{\\dagger}\\)프로젝트 리드\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '본 논문은 LLM 생성 텍스트의 _radioactivity_, 즉 이러한 입력이 학습 데이터로 사용되었음을 감지할 수 있는지 여부를 조사한다. 멤버십 추론과 같은 기존의 방법들은 이러한 검출을 어느 정도의 정확도로 수행할 수 있다. 우리는 워터마크가 삽입된 훈련 데이터가 멤버십 추론보다 더 쉽게 탐지하고 훨씬 더 신뢰할 수 있는 흔적을 남기는 것을 보여준다. 우리는 오염 수준을 워터마크 견고성, 훈련 세트에서의 비율 및 미세 조정 프로세스에 연결한다. 특히, 워터마크가 삽입된 합성 명령어에 대한 학습은 5%의 학습 텍스트가 워터마크가 삽입된 경우에도 높은 신뢰도(\\(p\\)-값\\(<10^{-5}\\))로 검출할 수 있음을 보인다. 따라서, 원래 기계 생성 텍스트를 검출하기 위해 설계된 LLM 워터마킹은 워터마킹된 LLM의 출력이 다른 LLM을 미세 조정하기 위해 사용되었는지 쉽게 식별할 수 있는 능력을 제공한다.\n' +
      '\n' +
      'Correspondence tomsander,pfz@meta.com\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '대형 언어 모델(LLM)은 종종 이들을 인간 프롬프트에 정렬시키고 그들의 성능 및 일반화를 개선하도록 미세 조정된다(Ouyang et al., 2022; Wei et al., 2022; Chung et al., 2022). 미세 조정은 명령어 데이터세트에서의 다양성과 품질의 균형을 맞추기 위한 전문가 지식 및 특히 정렬을 위한 값비싼 수동 주석의 컬렉션을 필요로 한다(OpenAI, 2023; Touvron et al., 2023; Gemini, 2023). 비용과 미세 조정의 어려움을 해결하기 위해 실무자는 바드, 챗GPT 또는 클로드와 같이 이미 지시된 모델에 의해 생성된 합성 데이터를 훈련하는 경우가 있다. 예를 들어, Wang et al.(2022); Honovich et al.(2022); Peng et al.(2023)은 가장 최근의 LLMs들 중 다수에 대한 명령어 데이터를 생성하였다(Taori et al., 2023; Xu et al., 2023; Gunasekar et al., 2023; Mukherjee et al., 2023). 이것은 또한, 예를 들어 터커들이 그들의 태스크들을 수행하기 위해 ChatGPT 출력을 사용할 때 의도하지 않을 수 있다(Veselovsky et al., 2023). 이러한 모방(Wallace et al., 2020)은 미세조정된 모델이 원 모델의 파생작인지에 대한 의문을 제기한다. 이러한 맥락에서 LLM 출력이 훈련 데이터로 사용될 때 감지하는 방법을 이해하는 것이 중요하다.\n' +
      '\n' +
      '한편, 합성 텍스트를 탐지하는 것은 더 어려워졌다. 이는 텍스트가 악의적인 목적으로 사용될 수 있는 경우에 점점 더 중요하다(Weidinger et al., 2022; Crothers et al., 2022). 이를 해결하기 위한 한 가지 접근법은 생성 프로세스 동안 또는 생성 프로세스 후에 콘텐츠에 비밀 트레이스를 내장하는 _watermarking_이며, 이는 생성 모델을 식별하기 위해 검출될 수 있다. 워터마킹은 오랜 역사를 가지고 있으며(Cox et al., 2007), 생성 모델에 대한 응용에 대한 관심이 증가하고 있다. 이는 생성된 출력 품질의 최소 열화(Aaronson and Kirchner, 2023; Kirchenbauer et al., 2023, 2023)로 검출을 효율적으로 만드는 최근 기술 덕분에 LLM에 대해 특히 그렇다.\n' +
      '\n' +
      '도 1: ** 방사능 설정. 밥은 앨리스 LLM에서 나오는 텍스트들의 작은 비율로 훈련 데이터에 대해 그의 LLM을 미세 조정한다. 우리는 이것이 미세 조정 후에 밥의 모델에 흔적을 남기는 것을 보여주며 앨리스는 텍스트가 워터마크될 때 이러한 흔적을 훨씬 더 확실하게 감지할 수 있음을 보여준다. 따라서 기계 생성 텍스트 검출을 위한 Alice의 워터마크는 Bob의 모델의 미세 조정을 드러내는 부차적인 효과가 있다.** 이 두 가지 관찰에 기초하여, 본 연구는 다음과 같은 질문을 다룬다: _ 워터마킹된 텍스트가 미세 조정 데이터로 사용될 때 발생하는 것?__** 우리는 LLM 워터마킹의 잠재적인 "방사능" - Sablayrolles et al.(2020)에 의해 만들어진 용어를 탐색하는데, 이는 워터마킹된 텍스트가 미세 조정 데이터로 사용될 때 모델을 오염시키는 능력을 지칭한다.\n' +
      '\n' +
      '문제는 Membership Inference Attack(MIA)과 밀접한 관련이 있다(Shokri et al., 2017). 그러나 MIA는 특정 텍스트가 훈련에 사용된 것으로 의심되는 경우에 초점을 맞춘다. 또한, 가장 효과적인 검출은 모델의 로짓에 대한 액세스를 요구한다(Sablayrolles et al., 2019; Carlini et al., 2022). 이러한 액세스가 없으면, 대안은, 훈련 데이터의 작은 부분(종종 반복되는 샘플들)만이 추출가능한 것으로 보여서 불충분한, verbatim 문장들의 암기를 검출하는 것이다(Nasr et al., 2023). 한편, 워터마킹된 텍스트는 그 반복적 특성상 말뭉치 수준에서 암기될 것으로 예상되는 신호를 실어 나른다. 따라서 미세조정에 사용되는 특정 텍스트를 알 수 없는 경우에도 워터마킹된 텍스트에 대한 학습이 감지될 수 있다.\n' +
      '\n' +
      '이 질문에 답하기 위한 우리의 기여는 다음과 같습니다.\n' +
      '\n' +
      '* 미세 조정 모델(_open/closed_) 및 훈련 데이터(_supervised/unsupervised_)에 대한 접근에 따라 네 가지 시나리오에서 방사능을 탐지할 수 있는 새로운 방법을 도출한다. 특히, 우리의 개방형 모델 탐지는 기준 접근법보다 훨씬 더 우수하다.\n' +
      '* 우리는 LLM이 Self-Instruct(Wang et al., 2022) 출력 상에서 미세 조정되는 현실 세계 설정에서 워터마킹된 텍스트가 방사성임을 입증한다. 예를 들어, 미세조정 데이터를 5\\(5\\%\\) 이하로 워터마킹하였을 때, 10^{-5}\\의 값(p\\)으로 방사능을 검출하였다.\n' +
      '* 우리는 오염 과정을 분해하고 예를 들어 워터마킹 해싱을 위한 작은 창이 방사능을 증가시킨다는 것을 발견한다.\n' +
      '\n' +
      '## 2 Background\n' +
      '\n' +
      '### Related work\n' +
      '\n' +
      '멤버십 추론 공격(MIAs)은 임의의 샘플이 모델의 학습 데이터에 포함되어 있는지 여부를 결정하는 것을 목표로 하며, 적대자의 지식(Nasr et al., 2019)에 다양한 세분성을 갖는다. 대부분의 경우, 검출은 그림자 모델을 구축하고 이들의 행동 차이를 관찰하거나(Shokri et al., 2017, 2017, 2017, 2020), 모델의 손실을 직접 관찰한다(Yeom et al., 2018; Sablayrolles et al., 2019; Watson et al., 2021; Carlini et al., 2022). 생성 모델의 맥락에서, MIA는 전체 데이터세트가 트레이닝 데이터의 일부임을 검출하는 _dataset contamination_와 얽혀 있다(Shi et al., 2023; Golchin and Surdeanu, 2023), 및 _extraction attacks_ 여기서 모델은 텍스트를 역류시키도록 프롬프트함으로써 일부 트레이닝 데이터를 재구성한다(Carlini et al., 2019, 2021; Nasr et al., 2023). 응용 프로그램에 따라 MIA는 민감한 훈련의 기밀성을 위반하거나 저작권이 있는 자료 또는 평가 데이터와 같은 "금지된" 데이터에 대한 훈련을 공개할 수 있다(벤치마크 결과를 손상시킨다).\n' +
      '\n' +
      'LLMs에 대한 워터마킹 디코더 전용 LLMs에 대한 워터마킹 방법의 최근 브랜치는 확률 분포(Kirchenbauer et al., 2023) 또는 다음 토큰의 샘플링 방법(Aaronson and Kirchner, 2023; Kuditipudi et al., 2023) 중 하나를 수정한다. 이론적 연구는 워터마크의 검출 가능성이 생성된 텍스트의 엔트로피에 의존한다는 것을 보여준다(Christ et al., 2023; Huang et al., 2023). 우리의 경우, 우리는 생성된 텍스트(아마도 편집)에서 워터마크를 검출하는 것을 목표로 하지 않고, _모델이 오염되었는지 여부를 명시하는 것을 목표로 한다. 이를 위해서는 대량의 토큰에서 희미하면서도 통계적으로 유의미한 워터마크 신호를 검출하는 방법이 필요하다.\n' +
      '\n' +
      'Gu et al.(2023)은 모델 가중치들 내에서 방법들을 증류하여, LLM들이 오픈 소스 모델들의 핵심인 워터마크된 로짓들을 원천적으로 생성할 수 있게 한다. 대조적으로, 우리는 신호가 워터마크된 데이터에 대한 훈련의 바람직하지 않은 결과로 나타나는 의도하지 않은 오염에 초점을 맞춘다. 도 1은 협업하고 있지 않다; Bob은 Alice의 LLM이 워터마크된 텍스트들을 생성하는 것을 알지 못할 수 있다. 또한, 우리는 Bob이 워터마크된 데이터의 작은 비율만을 소비하는 경우를 다룬다.\n' +
      '\n' +
      '워터마킹은 또한 다른 전략으로 지적 재산권 보호를 위해 사용된다. 예를 들어, He et al. (2022, 2020); Li et al. (2023)은 동의어와 같은 어휘 속성을 사용하는 반면 Peng et al. (2023)은 백도어에 의존한다. Zhao et al.(2023)은 증류를 통한 워터마크 특정 만류 모델 도용을 개발한다. 그러나, 그 정확도에 대한 평가는 경험적 거짓 긍정 비율과 일치하는 \\(p\\)-값을 제공하는 사운드 워터마크 검출기(Aaronson and Kirchner, 2023; Kirchenbauer et al., 2023; Kuditipudi et al., 2023)가 결여된 경험적이다(Fernandez et al., 2023). 이 연구에서는 새로운 보호 기법을 제시하는 대신 AI 생성 텍스트를 탐지하는 데 사용되는 디코딩 기반 LLM 워터마크의 방사능을 입증된 정확도로 연구한다. 우리의 연구에 더 가까이, 한 연구는 워터마킹을 훈련 이미지의 적극적인 보호로 간주한다. Sablayrolles et al. (2020)은 _radioactivity_의 개념을 도입한다: 트레이닝 세트의 이미지들은 그들 상에서 트레이닝된 임의의 분류기에서 검출가능한 트레이스를 남기기 위해 워터마킹된다.\n' +
      '\n' +
      'LLM 워터마킹의 기술배경\n' +
      '\n' +
      '본 논문은 LLM 복호(Aaronson and Kirchner, 2023; Kirchenbauer et al., 2023)의 성능과 실용성 때문에 LLM 복호(Aaronson and Kirchner, 2023)를 변경하는 워터마킹 방법에 주목한다.\n' +
      '\n' +
      '각주 1: 우리는 Kuditipudi et al.(2023)의 작업을 고려하지 않는다. 강건성에도 불구하고, 검출은 값비싼 Levenshtein 거리에 의존하며, \\(p\\)-값은 다른 비밀 키에서 많은 검출들을 실행하여 계산되며, \\(p\\)-값은 \\(10^{-2}\\) 이하를 난해하게 만든다.\n' +
      '\n' +
      '우리는 문맥을 입력으로 하고 로짓의 벡터를 출력하는 디코더 전용 LLM을 고려한다. 문맥은 모델의 어휘로서 토큰 \\(\\left(x^{(-C)},...,x^{(-1)}\\right)\\in\\mathcal{V}^{C}\\), \\(\\mathcal{V}\\)의 순서이다. LLM에 의해 출력된 로짓(\\boldsymbol{\\ell}\\in\\mathds{R}^{|\\mathcal{V}|}\\) 벡터를 다음 토큰의 확률분포인 \\(\\mathbf{p}=\\text{softmax}(\\boldsymbol{\\ell})\\in[0,1]^{|\\mathcal{V}|}\\)으로 변환한다. 텍스트는 이 분포로부터 다음 토큰 \\(x^{(0)}\\)을 일부 절차(top-k 샘플링(Fan et al., 2018; Radford et al., 2019), 핵-샘플링(Holtzman et al., 2019) 등)로 샘플링한 후, 컨텍스트에 추가하고, 프로세스를 반복함으로써 생성된다.\n' +
      '\n' +
      '_watermark embedding_는 비밀키에 따라 로짓 벡터\\(\\boldsymbol{\\ell}\\) 또는 샘플링 절차를 변경한다. 일반적으로 비밀키 암호함수의 출력은 이전 토큰(\\(k\\)(\\left(x^{(-k)},\\ldots,x^{(-1)}\\right))을 해시한다. 난수생성기를 초기화하는 seed\\(\\mathsf{s}\\) 역할을 하며, 이는 다음 토큰\\(x^{(0)}\\)의 선택에 영향을 미친다. Kirchenbauer et al.(2023)의 예에서, 샘플링 확률이 증가되는 토큰들의 그린리스트를 생성한다.\n' +
      '\n' +
      '_워터마크 검출_은 정밀 조사 하에 텍스트를 토큰화하고, 비밀 시드 생성을 반복하고 각각의 토큰을 스코어링한다. 따라서 현재 토큰(x^{(0)}\\)에 점수를 부여하는 함수는 씨앗(\\mathsf{s}\\)과 토큰의 시퀀스(\\left(x^{(-k)},\\ldots,x^{(-1)}\\right)\\)에 상대적으로 점수를 부여하기 위해 토큰을 입력으로 하는 실수값 함수(W_{\\text{score}}\\)로 작성될 수 있다:\n' +
      '\n' +
      '\\[\\mathsf{s},\\left(x^{(-i)}\\right)_{i=k}^{1};x^{(0)}\\mapsto W_{\\text{score}}\\left(\\mathsf{s},\\left(x^{(-i)}\\right)_{i=k}^{1};x^{(0)}\\right)\\in\\mathds{R}.\\\n' +
      '\n' +
      '누적 스코어 및 토큰들의 수(_e.g._, 전체 토큰들 중 그린리스트 토큰들의 수)에 기초한 통계적 테스트는 텍스트가 워터마킹되었는지 여부를 결정한다. 자세한 내용은 A 앱에 나와 있습니다.\n' +
      '\n' +
      '##3 문제 정식화\n' +
      '\n' +
      '###표기와 문제 진술\n' +
      '\n' +
      '우리는 그림 1의 시나리오를 고려한다. _Alice_라고 불리는 모델 소유자는 API를 통해 이용 가능한 채팅, 문제 해결 또는 코드 생성과 같은 특정 작업에 대해 미세 조정된 독점적인 언어 모델 \\(\\mathcal{A}\\)을 갖는다. _Alice_ Bob_는 다른 언어 모델 \\(\\mathcal{B}\\)을 소유하고 있다. 앨리스는 밥이 \\(\\mathcal{A}\\)의 출력에서 \\(\\mathcal{B}\\)을 미세조정했다고 의심한다. 우리는 \\(\\mathcal{B}\\)을 미세조정하는 데 사용되는 데이터세트를 \\(D\\)으로 표시하는데, 이 중 \\(\\mathcal{A}\\subset D\\)의 텍스트 코퍼스는 \\(\\mathcal{A}\\)의 출력으로 만들어진다. 우리는 \\(\\rho\\)을 \\(\\mathcal{A}\\)에서 나오는 \\(\\mathcal{B}\\)의 미세조정 데이터의 비율로 정의한다.\n' +
      '\n' +
      '\\[\\rho:=|D^{\\mathcal{A}}|/|D|. \\tag{1}\\]\n' +
      '\n' +
      '우리는 밥의 모델에 대한 앨리스 접근과 미세 조정 데이터에 따라 네 가지 주요 시나리오를 설명한다.\n' +
      '\n' +
      '밥의 데이터에 대한 액세스.우리는 밥의 훈련 데이터에 대한 앨리스 지식에 대한 두 가지 설정을 고려한다.\n' +
      '\n' +
      '*_supervised_ 설정에서 Bob은 식별 가능한 계정을 사용하여 \\(\\mathcal{A}\\)을 질의한다. Alice는 Bob을 위해 생성된 \\(\\tilde{D}^{\\mathcal{A}}\\)의 모든 내용을 보유한다. 따라서, 앨리스는 \\(D^{\\mathcal{A}}\\subseteq\\tilde{D}^{\\mathcal{A}}\\)을 알고 있다. 우리는 감독의 _degree를 다음과 같이 정의한다. \\[d:=|D^{\\mathcal{A}}|/|\\tilde{D}^{\\mathcal{A}|.\\ (2)\n' +
      '*_unsupervised_ setting에서 Bob은 식별 가능한 계정을 사용하지 않거나 다른 사람 뒤에 숨어 있으므로 \\(d=0\\)이다. 이것이 가장 현실적인 시나리오입니다.\n' +
      '\n' +
      '\\(\\rho\\)과 \\(d\\)은 같은 개념을 나타내지는 않지만 \\(\\mathcal{B}\\)이 \\(\\mathcal{A}\\)에서 어떠한 출력도 보이지 않았을 때 \\(\\rho=d=0\\)이다.\n' +
      '\n' +
      '밥의 모델에 접근합니다 두 가지 시나리오를 고려하죠\n' +
      '\n' +
      '* Alice는 \\(\\mathcal{B}\\)에 대한 _open-model_ access를 갖는다. 그녀는 어떤 입력도 \\(\\mathcal{B}\\)을 통해 전달할 수 있고 출력 로짓들을 관찰할 수 있다. 밥이 자신의 모델을 공개 소스로 제공하거나 앨리스가 합법적인 채널을 통해 찾는 경우 그럴 수 있다.\n' +
      '* Alice는 _closed-model_ access를 갖는다. 그녀는 확률 벡터나 로짓이 출력되지 않는 API를 통해서만 \\(\\mathcal{B}\\)을 질의할 수 있다. 앨리스는 생성된 텍스트만 관찰한다. 예를 들어 대부분의 챗봇에 해당됩니다.\n' +
      '\n' +
      '### Radioactivity\n' +
      '\n' +
      '*Definition 1** (Text Radioactivity).: _Statistical Test \\(T\\) s.t. "\\(\\mathcal{B}\\)이 \\(D\\)" \\(\\subset\\mathcal{H}_{0}\\에 대해 훈련되지 않은 경우, \\(D\\)의 코퍼스는 \\(\\alpha\\) - \\(\\mathcal{B}\\)에 대해 \\(\\alpha\\) - 방사성이라고 한다. 만약 \\(T\\)이 \\(\\alpha\\)보다 작은 유의수준(\\(p\\)-값)에서 \\(\\mathcal{H}_{0}\\)을 거부할 수 있다면\n' +
      '\n' +
      '*Definition 2** (Model Radioactivity): _Statistical Test \\(T\\) s.t. "\\(\\mathcal{B}\\)이 \\(\\mathcal{A}\\)" \\(\\subset\\mathcal{H}_{0}\\)의 출력에 대해 훈련되지 않았다고 할 때, \\(\\mathcal{A}\\)이 \\(\\alpha\\)보다 작은 유의수준(p-value)에서 \\(\\mathcal{H}_{0}\\)을 거부할 수 있다면 \\(\\mathcal{B}\\)에 대한 \\(\\alpha\\)-방사능이라고 한다.\n' +
      '\n' +
      '따라서, \\(\\alpha\\)는 데이터세트 또는 모델의 방사능을 정량화한다. 낮은 \\(\\alpha\\)(_e.g._, \\(10^{-6}\\))은 검출 테스트가 높은 신뢰도를 갖기 때문에 강한 방사능을 나타내는 반면, \\(\\alpha\\approx 0.5\\)은 낮은 방사능을 나타낸다 (검출은 무작위 테스트이다).\n' +
      '\n' +
      '##4 방사능 검출\n' +
      '\n' +
      '우리는 이전 섹션에서 제시된 다른 설정에서 언어 모델에서 워터마킹되지 않은 텍스트와 워터마킹된 텍스트의 방사능을 검출하는 방법을 도출한다.\n' +
      '\n' +
      '### Without watermarking\n' +
      '\n' +
      '개방 모델/감독 사례에서 MIA는 신중하게 선택된 입력 세트에 대한 \\(\\mathcal{B}\\)의 손실(또는 당혹성)을 관찰함으로써 하나의 샘플/문장의 방사능을 평가한다. 당혹감은 훈련 중에 보여지는 샘플들에서 더 작아질 것으로 예상된다(이것은 때때로 _loss attack_라고 불린다). 우리는 비표식 텍스트 말뭉치의 기준 방사능 탐지 테스트를 위해 이 개념을 확장한다. 우리는 텍스트의 말뭉치를 256개의 토큰으로 나누고 각 문장에서 \\(\\mathcal{B}\\)의 손실을 계산한다. 우리는 샘플 기반 MIA에 대해 Carlini et al.(2021)에 의해 수행된 바와 같이 zlib 엔트로피(Roelofs, 2017)로 그것을 교정한다. 검정의 목표는 각 표본의 복잡성을 설명하고 이를 \\(\\mathcal{B}\\)의 과대확신과 분리하는 것이다.\n' +
      '\n' +
      'K-S 검정.우리는 귀무가설 \\(\\mathcal{H}_{0}\\)을 검정한다. "\\(\\tilde{D}^{\\mathcal{A}\\)에 대한 \\(\\mathcal{B}\\)의 복잡도는 \\(\\mathcal{A}\\)에 의해 생성된 새로운 텍스트에 대한 복잡도와 동일한 분포를 갖는다." 실제로, \\(\\tilde{D}^{\\mathcal{A}\\)의 부분들에서 \\(\\mathcal{B}\\)이 미세 조정되지 않았다면, 반드시 \\(\\mathcal{H}_{0}\\)은 참이다. 경험적 분포를 비교하기 위해 우리는 2표본 Kolmogorov-Smirnov 검정(Massey, 1951)을 사용한다. 손실 값에 대한 누적 분포\\(F\\)와 \\(G\\)이 주어졌을 때, K-S 거리를 \\(d_{\\text{KS}}(F,G)=\\sup_{x}|F(x)-G(x)|\\로 계산한다. 이 거리가 임계값보다 높으면 \\(\\mathcal{H}_{0}\\)을 기각하고, \\(\\tilde{D}^{\\mathcal{A}}\\)이 \\(\\mathcal{B}\\)에 대해 방사성임을 결론짓는다. 이는 이미지 분류의 경우에 유사한 K-S 테스트를 수행하는 Sablayrolles et al.(2018)에 의해 영감을 받는다. 분포의 한 꼬리에서 집계된 점수를 보고 경험적 검정을 도출하는 Shi et al.(2023)의 접근법과 크게 다르다.\n' +
      '\n' +
      '이 설정 외부에서는 강력한 감지가 없습니다.\n' +
      '\n' +
      '* MIA는 특정 샘플이 훈련에 사용되었는지 감지한다. _unsupervised_ 설정에서 Alice는 Bob이 자신의 모델의 일부 출력을 사용했다고 의심할 뿐 특정 샘플이 무엇인지 알지 못한다.\n' +
      '* _closed-model_ setting에서 Alice는 \\(\\mathcal{B}\\)의 출력에만 접근할 수 있다. (\\tilde{D}^{\\mathcal{A}}\\)를 프롬프트하여 전체 문장(\\tilde{D}^{\\mathcal{A}}\\)으로부터 전체 문장(\\tilde{B}\\)을 추출하는 것은 LLM 훈련 데이터의 극히 일부분만이 verbatim으로 추출될 수 있기 때문에 불충분할 가능성이 있다(Nasr et al., 2023). 게다가, 이것은 앨리스에게 신뢰할 수 있는 통계 테스트를 제공하지 않을 것이다.\n' +
      '\n' +
      '### With watermarking\n' +
      '\n' +
      '우리는 이제 \\(\\mathcal{A}\\)의 출력을 \\(W\\) 방법과 \\(\\mathfrak{s}\\) (\\(\\mathcal{A}\\)에 고유한 비밀키로 워터마킹하는 경우를 고려한다. 이 경우 모든 설정에 대한 탐지 테스트가 있음을 보여줍니다(탭 1 참조). \\ (W\\)의 스코어링 함수 \\(W_{\\text{score}}\\)는 관측된 토큰에 의존하고 \\(\\mathfrak{s}\\) 및 \\(W\\)의 워터마크 검출 테스트 \\(T\\)는 스코어와 토큰 수에 의존한다. \\\\(W\\)의 워터마크 검출 테스트 \\(T\\)은 스코어와 토큰 수에 의존한다. (T\\) 검정 귀무가설 \\(\\mathcal{H}_{0}\\): "_Text는 비밀키 \\(\\mathfrak{s}\\)_로 \\(W\\) 다음에 생성되지 않았다" (Sec. 2.2 및 App. A 참조 점수 및 통계 검정 세부 사항).\n' +
      '\n' +
      '순수 접근법.방사능은 \\(\\mathcal{B}\\)에 의해 생성된 대량의 텍스트 코퍼스에 대해 워터마크 검출을 수행함으로써 검출될 수 있다. 통계적 검정에서는 Def. 1과 일치하였다. 실제로 워터마크를 본 적이 없는 경우, 텍스트는 \\(W\\)와 \\(\\mathfrak{s}\\) 다음에 생성될 수 없으므로, "\\(\\mathcal{B}\\)_did가 \\(\\mathcal{A}\\)_의 출력을 사용하지 않았다면, \\(\\mathcal{H}_{0}\\"은 참이다. 그러나, \\(\\mathcal{B}\\)에서 워터마크의 흔적은 \\(D^{\\mathcal{A}}\\)의 일부인 \\(k\\)-그램에서만 찾을 수 있다 (워터마크 삽입으로 인해 Sec. 2.2 참조). 비록 이 \\(k\\)-그램들이 강하게 워터마크되어 있고 \\(\\mathcal{B}\\)이 이들 모두를 외웠다고 가정하더라도, 그들은 여전히 테스트할 수 있는 \\(|\\mathcal{V}|^{k}\\)\\(k\\)-그램의 작은 부분만을 구성하므로 테스트가 최적이 아니다.\n' +
      '\n' +
      '\\(\\mathcal{B}\\)에서의 워터마크 검출.\\(\\mathcal{B}\\)에 대한 액세스에 따라 두 가지 방법을 소개한다:\n' +
      '\n' +
      '* _closed-model_: \\(\\mathcal{B}\\)으로 새로운 텍스트를 프롬프트하고 생성한다. 감독된 설정에서는 프롬프트만 표시됩니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c} \\hline \\hline  & \\multicolumn{2}{c}{With WM} & \\multicolumn{2}{c}{Without WM} \\\\ \\cline{2-5}  & Open & Closed & Open & Closed \\\\ Supervised & ✓ & ✓ & ✓ & \\(\\times\\) \\\\ Unsupervised & ✓ & ✓ & \\(\\times\\) & \\(\\times\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 상이한 설정 하에서 방사능 검출의 이용가능성. _ Open_/_closed-model_는 Alice에 대한 Bob의 모델의 가용성, 및 그의 데이터에 대한 그녀의 지식에 대한 _supervised_/_unsupervised_를 의미한다. MIA(WM 없음)에 의존하는 검출은 3.3§1에 기술되고 워터마크를 사용한 검출은 3.3§2에 기술된다.\n' +
      '\n' +
      '(\\tilde{D}^{\\mathcal{A}\\)에서 (watermarked) 텍스트가 있는\\(\\mathcal{B}\\) 감독되지 않은 텍스트에서는 훈련된 것으로 의심되는 것과 동일한 배포의 새로운 텍스트로 프롬프트한다.\n' +
      '*_open-model:_ 대신에 \\(\\mathcal{B}\\)으로 새로운 텍스트를 생성하는 대신에 \\(\\mathcal{B}\\)을 통해 문장을 직접 전달한다. \\(\\big{(}x^{(1)},\\ldots,x^{(j)}\\big{)}\\)을 토큰의 시퀀스로 하고, \\(\\mathcal{B}\\)의 디코딩에 따라 다음 토큰이 가장 가능성 있는 \\(y^{(j)}\\)이라고 하자. 우리는 \\((x^{(j-k-1)},\\ldots,x^{(j)};\\,y^{(j)})\\)을 \\(W_{\\text{score}}\\)으로 점수화한다(더 자세한 내용은 App. B의 알고리즘 1 참조).\n' +
      '\n' +
      '채점된 \\(k\\)-그램에 대한 필터.검출을 향상시키기 위해 훈련되었을 가능성이 높은 \\(k\\)-그램의 집합인 \\(\\phi\\) 필터를 소개한다. 토큰은 해싱에 사용되는 이전 \\(k\\)-그램 윈도우 - 워터마크 컨텍스트 윈도우 -가 \\(\\phi\\)의 일부인 경우에만 채점된다. 이것은 워터마크가 학습되었을 가능성이 있는 \\(k\\)-그램에 점수 계산을 집중한다. 우리가 \\(\\mathcal{B}\\)의 학습 데이터를 정확히 알 수 있는 fully _supervised_ 설정에서 \\(\\phi\\)은 훈련 중에 사용된 \\(k\\)-그램으로 만들어 진다. \\(D^{\\mathcal{A}}\\)으로부터 모든 \\(k\\)-그램으로 만들어진다. _unsupervised_ 설정에서 우리는 여전히 \\(\\mathcal{A}\\)에 의해 생성된 워터마크된 텍스트에서 자주 나타나는 \\(g._, \\(k\\)-그램의 오염된 토큰 집합에 초점을 맞추고 있다. 필터\\(\\phi\\)는 닫힌 모델 설정에서만 사용됩니다. \\(\\phi\\)을 정의하고 \\(\\mathcal{B}\\)에서 토큰을 생성하는 데 사용되는 분포의 선택은 매우 중요한 것으로 나타났다. 이것은 6.2항에서 논의된다.\n' +
      '\n' +
      'Token scoring and de-duplication.Fernandez et al.(2023)에 의해 독립 가설을 깨는 토큰 분포의 편향으로 인해 탐지 테스트가 경험적으로 부정확하다는 것이 밝혀졌다. 실제로, 우리는 워터마크가 전통적인 워터마킹(정밀 조사 중인 텍스트가 기껏해야 수백 토큰인 경우)보다 수십 배 더 많은 토큰에서 관찰되어야 하기 때문에 이 현상이 우리의 경우에 훨씬 더 사실임을 발견했다. 해결책은 이전의 \\(k\\)-그램(해싱에 사용된 워터마크 컨텍스트 윈도우)이 탐지 중에 이미 보이지 않은 경우에만 토큰을 스코어링하는 것이다. 이는 많은 토큰을 분석하더라도 신뢰할 수 있는 \\(p\\)-값을 제공한다. 우리는 부록 B에서 채점 절차, 중복 제거 및 테스트의 정확성을 개선하기 위한 방법에 대해 더 자세히 설명한다.\n' +
      '\n' +
      '##5 명령어 데이터세트에서의 방사능\n' +
      '\n' +
      '실험은 모델\\(\\mathcal{A}\\)에 의해 생성된 명령어/답변 쌍에 대해 미리 훈련된 LLM\\(\\mathcal{B}\\)이 세밀하게 조정되는 현실적인 시나리오를 고려하는 것으로 시작한다. 우리는 워터마킹된 합성 지시가 방사성임을 보여주고 가능한 경우 그들의 방사능 수준을 워터마킹되지 않은 지시의 방사능 수준과 비교한다.\n' +
      '\n' +
      '### Experimental setup\n' +
      '\n' +
      'Instruction data generation.We used protocol presented in Self-instruct (Wang et al., 2022) with \\(\\mathcal{A}\\)=Llama-2-chat-7B (Touvron et al., 2023). 우리는 명령어/답변 쌍의 세 가지 예가 뒤따르는 명령어로 모델에 프롬프트하고 다음 20개의 명령어/답변 쌍을 생성하도록 요청한다. LLM 로짓으로부터 샘플링은 워터마킹 없이 또는 Kirchenbauer et al.(2023)의 워터마킹 방법과 함께 로짓 바이어스 \\(\\delta=3.0\\), 그린리스트 토큰의 비율 \\(\\gamma=0.25\\) 및 \\(k=2\\)에서 수행된다. 두 경우 모두 핵 샘플링(Holtzman et al., 2019)을 사용하여 \\(p=0.95\\) 및 \\(T=0.8\\)을 사용한다. 생성된 데이터를 후처리하여 완료되지 않은 답변을 제거하고 거의 중복되는 지침을 제공합니다. 이것은 두 경우에 대해 100k 명령어/응답 쌍(\\(\\approx\\)14M 토큰)2의 데이터 세트를 산출한다. 우리는 App. C.2에서 더 자세한 설명, 생성된 명령의 예 및 해당 워터마크 검출 속도를 제공한다.\n' +
      '\n' +
      '각주 2: 비교를 위해 Alpaca의 형식 텍스트는 \\(\\approx\\)6M 토큰, Alpaca-GPT4 \\(\\approx\\)10M 토큰 및 OASST1 \\(\\approx\\)20M 토큰이다.\n' +
      '\n' +
      '마지막으로 워터마크가 삽입된 데이터의 %(\\(\\rho\\in\\{0,1,5,10,50,100\\}\\)를 갖는 6개의 혼합 데이터 세트를 생성하고, 나머지 데이터는 워터마크가 없는 명령어로 채운다. 즉, 약 14M 토큰에서 총 명령어 수를 수정하되 워터마크가 삽입된 명령어(\\(\\mathcal{A}\\)의 출력을 나타냄)의 비율을 변경한다.\n' +
      '\n' +
      '본 논문에서는 Alpaca(Taori et al., 2023)의 접근방법을 근간으로 하여 6개의 합성 데이터셋을 학습한다. 아담 최적화기(Kingma and Ba, 2017)를 이용하여 3000단계의 학습을 진행하며, 배치크기는 8, 학습률은 \\(10^{-5}\\), 문맥크기는 2048 토큰(3개의 학습 에포크를 생성함)이다. 학습률은 100단계의 워밍업 단계로 코사인 어닐링 스케줄(Loshchilov and Hutter, 2017)을 따른다. 우리는 미세조정을 위해 동일한 기본 모델을 사용할 경우 발생할 수 있는 편향을 피하기 위해 \\(\\mathcal{B}\\)=Llama-1-7B(Touvron et al., 2023)와 다른 데이터 세트에 대해 훈련된 모델인 \\(\\mathcal{A}\\)=Llama-2를 미세조정한다.\n' +
      '\n' +
      '### 명령어 튜닝의 품질 검사\n' +
      '\n' +
      '현실적인 시나리오를 유지하기 위해, 워터마킹을 위한 Alice의 하이퍼파라미터 선택은 1) 고품질 명령어들을 생성하는 것, 및 2) 작은 텍스트 세그먼트들에서도 워터마크가 검출될 수 있는 것을 보장하는 것을 목표로 한다. 구체적으로, 워터마크 윈도우 크기는 \\(k=2\\)이며, 0 또는 1에 대해 발생하는 바이어스를 제거하기에 충분히 넓지만, 워터마크가 편집에 견고할 만큼 충분히 좁다. (\\(\\delta=3\\)의 값은 높은 품질의 텍스트를 생성하면서도, 약 100개의 토큰(App. C.2의 전체 결과)에서 \\(p\\)- 값 \\(10^{-6}\\)으로 워터마크가 검출될 만큼 충분히 강하다는 것을 보장한다.\n' +
      '\n' +
      '우리는 세밀하게 조정된 \\(\\mathcal{B}\\) 네트워크 출력을 정성적으로 검사한다. 2 and App. C.2) and quantitative in Tab. 2. We first look of evaluation setup for the Llama and report the 0-shot: exact match score for Natural Questions (Kwiatkowski et al., 2019) and TriviaQA (Joshi et al., 2017); exact match score without majority voting for GSM8k (Cobbe et al., 2021); pass@1 for HumanEval (Chen et al., 2021); and accuracy on MMLU (Hendrycks et al., 2020). 예상한 바와 같이, 명령어-튜닝은 MMLU에 대해 향상시키면서 대부분의 벤치마크들에 영향을 미치지 않는다(Dettmers et al., 2023). 또한 워터마킹 방법이 미세조정에 큰 영향을 미치지 않음을 확인하였다.\n' +
      '\n' +
      '### 멤버십 추론 공격이 있는 기준선\n' +
      '\n' +
      '워터마크가 없는 경우 Sec에서와 같이 진행합니다. MIA가 가능한 설정을 위한 4: Alice는 \\(\\mathcal{B}\\)에 대한 _open-model_ access를 가지며 Bob(supervised setting)에 대해 생성된 모든 데이터 \\(\\tilde{D}^{\\mathcal{A}}\\)을 인식한다. Bob은 \\(\\mathcal{B}\\)의 미세조정을 위해 부분 \\(D^{\\mathcal{A}}\\)을 사용했는데, 감독 정도 \\(d\\)이 주어지면 섹션 3.1을 참조한다. 실험적으로, 우리는 \\(\\mathcal{B}\\)에 대한 보정된 복잡성을 구별하기 위해 K-S 테스트를 사용한다. 분포\\(\\mathcal{D}_{(d)}\\)는 Bob이 많은 데이터를 생성하고 작은 비율에서만 미세 조정을 할 때 발생하는 현상을 시뮬레이션한다.\n' +
      '\n' +
      '그림 3은 \\(d=0\\)과 \\(d>0\\)에 대한 분포를 비교한다. 검출은 \\(d\\)이 감소함에 따라 더 어려워진다: 데이터는 Bob이 미세 조정하지 않은 텍스트를 점점 더 많이 포함하므로 두 복잡성 분포의 차이는 더 희미하다. 표 3은 방사능 테스트에서 얻은 \\(p\\)-값을 나타낸다(다양한 \\(d\\)의 결과는 App. D에서 구할 수 있다). (d>2\\%\\)에서는 강한 유의수준에서 귀무가설을 기각하였다. (p<10^{-5}\\)는 방사능 오염이 검출되었을 때 오탐 확률이 \\(10^{-5}\\)임을 의미한다. \\(d\\)가 감소함에 따라, 테스트는 덜 강력해진다. 이는 Alice가 Bob이 사용하는 데이터에 대한 지식이 부족한 비감독 설정인 edge case \\(d=0\\)에서 무작위이다. 대조적으로, 다음 섹션은 워터마킹된 데이터에 대한 방사능 검출이 해당 설정에서 성공할 수 있음을 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c c c|c|c} \\hline \\hline  & Nq & TQA & GSM8k & H.Eval & Avg. & MMLU \\\\ \\hline \\multicolumn{6}{l}{_Fine-tuned with \\(\\rho\\) \\% of watermarked data:_} \\\\\n' +
      '0\\% & 5.0 & 33.6 & 11.8 & 12.8 & 15.8 & 33.6\\\\\n' +
      '5\\% & 5.2 & 35.7 & 11.2 & 11.6 & 15.9 & 34.7\\\\\n' +
      '50\\% & 4.1 & 35.5 & 9.6 & 12.8 & 15.5 & 35.0\\\\\n' +
      '100\\% & 5.6 & 36.4 & 11.1 & 9.8 & 15.7 & 31.0 \\\\ \\hline Base & 3.2 & 36.2 & 10.5 & 12.8 & 15.7 & 28.4 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 워터마크된 명령 데이터의 다양한 비율로 미세 조정된 Llama-7B의 평가.\n' +
      '\n' +
      '그림 3: \\(\\mathcal{A}\\)에 의해 생성된 두 가지 유형의 분포에 걸쳐 \\(\\mathcal{B}\\)의 보정된 손실의 분포: \\(\\mathcal{B}\\)의 미세 조정 데이터(보라색) 외부에서 \\(\\mathcal{A}\\)에 의해 생성된 텍스트, \\(\\tilde{D}^{\\mathcal{A}}\\)의 텍스트가 훈련(오렌지색) 동안 사용되었다. MIA는 두 분포 사이의 차이를 감지하는 것을 목표로 한다. 실제 미세 조정 데이터가 밥이 사용하지 않은 텍스트와 혼합됨에 따라 \\(d\\)이 감소함에 따라 더 어려워진다.\n' +
      '\n' +
      '그림 2: Bob의 모델 \\(\\mathcal{B}\\)(Llama-1), Alice의 모델 \\(\\mathcal{A}\\)(Llama-2-chat)에 의해 생성된 명령어 데이터를 워터마크가 삽입된 데이터의 다른 비율 \\(\\rho\\)으로 미세 조정한 답변의 예. 명령어-튜닝에 사용되는 명령어의 예는 도 13을 참조한다.\n' +
      '\n' +
      '### _With watermarking : open-model setting_\n' +
      '\n' +
      '우리는 이제 미세 조정 데이터(또는 그 일부)가 워터마킹되는 경우에 대해 연구한다. 우리는 오픈 모델 환경에서 방사능 검출에 대해 논의한다(Sec 참조). 4) \\(\\rho\\)는 \\(\\mathcal{B}\\)의 미세조정집합에서 \\(\\mathcal{A}\\)의 워터마크가 삽입된 데이터의 비율이다. 우리는 256-토큰 텍스트에서 약 2,000개의 순방향 통과를 나타내는 \\(\\mathcal{A}\\)k 바이그램을 채점하기 위해 \\(N=225\\)k 바이그램에 의해 생성된 \\(\\mathcal{A}\\)k 명령어에 대해 Sec. 4.2에 제시된 워터마크 검출을 사용한다. 지도 설정(\\(d=1\\))의 경우, 이 데이터 세트는 훈련에 사용되는 100k 명령어 중 모든 \\(\\rho\\%\\)의 워터마킹된 텍스트로 구성되며, 비지도 설정(\\(d=0\\))의 경우, \\(\\mathcal{B}\\)을 미세 조정했을 때 보이지 않는 워터마킹된 명령어로 구성된다.\n' +
      '\n' +
      '우리는 서로 다른 텍스트 덩어리에서 10회 검출을 반복하고 그림 1에 표시한다. 4는 다른 비율\\(\\rho\\)에 대한 테스트의 \\(p\\)-값이다. MIA와 유사하게, 감독 설정은 간단하며, 밥의 미세 조정 데이터의 1%만이 \\(\\mathcal{A}\\)에서 유래하더라도 \\(10^{-30}\\)보다 작은 \\(p\\)-값으로 방사능이 검출된다. 실제로, 이 시나리오에서 우리는 1) 실제로 오염될 수 있는 \\(k\\)-그램과 2) 미세 조정 동안 관찰된 것과 정확히 일치하는 컨텍스트 내에서 점수를 매겨 테스트를 매우 확신하게 만든다.\n' +
      '\n' +
      '반대로, \\(d=0\\)일 때, MIA는 적용가능하지 않지만, 우리의 개방형 모델 방사능 검출 테스트는 앨리스 모델에서 \\(\\mathcal{B}\\)을 미세 조정하는 데 사용된 지침의 5% 미만이 발생할 때 여전히 \\(p<10^{-5}\\)을 산출한다. 이 경우, Bob이 사용한 샘플을 포함하지 않는 텍스트 코퍼스에서 검출되지만, Bob이 훈련하고 방사능이 검출될 수 있는 \\(D^{\\mathcal{A}}\\)의 \\(k\\)-그램과 중첩될 가능성이 있는 \\(k\\)-그램을 포함한다. 감독 수준이 감소함에 따라 (\\(1>d> Bob이 실제로 사용한 \\(\\tilde{D}^{\\mathcal{A}}\\)에서 토큰의 비율이 감소하여 테스트가 약화되었다. 약한 감독에 대한 이 중간 시나리오는 그림 1에 나와 있다. App의 9. D 는 \\(\\rho=5\\%\\)인 경우에 대한 것이다.\n' +
      '\n' +
      '### _With watermarking : closed-model setting__\n' +
      '\n' +
      '폐쇄 모델 설정에서 Bob의 모델\\(\\mathcal{B}\\)은 프롬프트로부터 답변을 생성할 수 있는 API를 통해서만 액세스할 수 있다. 비감독 설정에서 이 설정을 연구하기 위해 새로운 명령어와 함께 미세 조정 \\(\\mathcal{B}\\)=Llama-1을 프롬프트하고 출력을 감지한다. 우리는 모든 답을 연결하고, \\(N=600\\)k 토큰(필터링 및 \\(k\\)-그램의 \\(\\approx 1.5\\)M 생성 토큰의 중복을 제거한 후)을 채점한다. 이것은 우리가 100개의 토큰이라고 가정하면 \\(10^{4}\\) 질의들을 나타낸다.\n' +
      '\n' +
      '필터 \\(\\phi\\)을 만들기 위해 다음과 같이 진행합니다. (참고로, 이전 \\(k\\)-그램이 \\(\\phi\\)의 일부인 경우에만 토큰을 채점합니다.) 지도 설정(\\(d>0\\))에서는 워터마크가 삽입된 \\(\\tilde{D}^{\\mathcal{A}}\\)의 프롬프트/답변을 직접 사용하며, 그 중 일부는 미세 조정에 사용되었으며 모든 \\(k\\)그램을 저장한다. 비감독 설정에서, 우리는 \\(\\mathcal{A}\\)으로 100k개의 새로운 워터마크 명령어를 생성하고, 필터를 생성하기 위해 모든 \\(k\\)-그램을 저장한다.\n' +
      '\n' +
      '도 5는 미세 조정 데이터의 1%가 워터마킹된 경우 필터 유무에 따른 검출을 비교하여, 도 5에서 미세 조정 데이터의 1%가 워터마킹된 경우 필터 유무에 따른 검출을 비교한다.\n' +
      '\n' +
      '도 4: 방사능 검출 결과. 10회에 걸쳐 평균 \\(\\log_{10}(p)\\)이 더 좋다(\\(\\downarrow\\) 막대는 표준 편차를 나타냅니다. 탐지 방법은 Sec에 자세히 설명되어 있습니다. 각 설정에 대해 4. 예를 들어, 지도 폐쇄 모델 설정에서 훈련 데이터의 1%만 워터마크를 삽입했을 때 워터마크(\\(p<10^{-5}\\))를 검출한다.\n' +
      '\n' +
      '그림 5: \\(\\log_{10}(p)\\)는 \\(\\rho=1\\%\\)을 갖는 감독 폐쇄 모델 설정에서 생성된 토큰 수의 함수이다. 우리는 \\(\\tilde{D}^{\\mathcal{A}\\)의 프롬프트와 함께 \\(\\mathcal{B}\\)에서 생성된 텍스트에 대해 워터마크 검출 테스트를 수행한다. 필터링할 때, 우리는 \\(tilde{D}^{\\mathcal{A}}\\)의 일부인 \\(k\\)-그램만을 채점한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c} \\hline \\hline Supervision \\(d\\) & 0.1\\% & 1\\% & 5\\% & 10\\% \\\\ \\hline \\multirow{2}{*}{\\(\\log_{10}(p)\\)} & MIA & -0.4\\(\\pm\\)0.4 & -0.6\\(\\pm\\)0.5 & \\(<\\mathbf{-30}\\) & \\(<\\)-30 \\\\ \\cline{2-6}  & WM & \\(\\mathbf{-5.8}\\pm\\)1.8 & \\(\\mathbf{-6.5}\\pm\\)0.9 & -16.0\\(\\pm\\)2.6 & \\(<\\)-30 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: \\(\\mathcal{A}\\)로부터 오는 \\(\\mathcal{B}\\)의 훈련 데이터의 \\(\\rho=5\\%\\)에서, 감독 정도에 따라 \\(\\log_{10}(p)\\)의 검출 신뢰도 \\(\\log_{10}(p)\\)\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:8]\n' +
      '\n' +
      '모델. 둘째, 가능한 \\(k\\)-그램의 수는 \\(|\\mathcal{V}|^{k}\\)이므로 \\(k\\)에 따라 증가하는 반면 워터마크된 토큰의 수는 \\(m\\)으로 고정된다. 따라서, 검출 시, 방사성 \\(k\\)-그램의 수는 \\(k\\) 증가에 따라 감소하며, 이는 테스트의 파워를 감소시킨다.\n' +
      '\n' +
      '_Data distribution_. 우리는 Alice가 \\(D^{\\mathcal{A}}\\)의 분포에 대한 사전 지식이 없는 무감독 설정, \\(\\mathcal{B}\\)을 미세 조정하는데 사용되는 \\(\\mathcal{A}\\)으로 생성된 데이터를 고려한다. 예를 들어, 앨리스는 이탈리아어, 프랑스어, 영어, 스페인어 또는 독일어일 수 있는 \\(D^{\\mathcal{A}}\\)의 언어를 모른다고 가정한다.\n' +
      '\n' +
      '이 실험을 위해 위키피디아로부터 다른 언어로 된 프롬프트와 함께 \\(\\mathcal{B}\\)에 의해 생성된 텍스트에 대해 Sec. 4.2의 검출 테스트를 실행한다. (D^{\\mathcal{A}}\\)의 언어와 몇 \\(k\\)그램을 공유할 수 있는 다른 언어에 대한 방사능 테스트의 검정력은 탭 6과 같이 낮을 것이다.\n' +
      '\n' +
      '그러나 앨리스는 각 테스트의 \\(p\\)-값을 피셔의 방법과 결합할 수 있다. 이것은 \\(\\mathcal{H}_{0}\\)을 판별한다: "_none of the datasets is radioactive_"이며, 여기서 "_Bob은 \\(\\mathcal{A}\\)_의 어떠한 출력도 사용하지 않았다"라는 진술이 떨어진다. 따라서 테스트는 정의 2. 탭에서 얻은 모델 방사능에 대한 정의와 일치한다. 6. Fisher\'s method of combined \\(p\\)-value \\(<10^{-50}\\)을 얻었다. 따라서, Alice가 Bob이 \\(\\mathcal{B}\\)(예: 인간 대화, 문제 해결 시나리오 또는 에세이)을 훈련하는데 사용했을 수 있는 \\(\\mathcal{A}\\)에 의해 생성된 특정 데이터 분포를 인식하지 못하더라도, 그녀는 여전히 다양한 분포에 걸쳐 방사능을 테스트하고 유의 수준을 결합할 수 있다.\n' +
      '\n' +
      '## 7 Conclusion\n' +
      '\n' +
      '본 연구는 언어 모델에서 "방사능" 개념을 공식화한다. LLM 생성 텍스트가 학습 데이터로 사용될 때 남긴 흔적을 탐지하는 방법을 소개한다. 우리는 이 작업이 가장 현실적인 시나리오에서 표기가 되지 않은 텍스트에 대해 어렵다는 것을 보여준다. 그러나 워터마킹된 텍스트는 미세 조정 동안 상당한 방사능, 오염 모델을 나타낸다. 이것은 워터마크된 모델로부터의 출력들이 다른 것을 미세 조정하기 위해 사용되었다면(그러나 다른 모델 자체의 사용을 검출하기 위해 사용될 수 없음) 높은 신뢰도로 식별하는 것을 가능하게 한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Aaronson and Kirchner (2023) Scott Aaronson and Hendrik Kirchner. 워터마킹 GPT 출력, 2023. [https://scottaaronson.blog/?m=202302](https://scottaaronson.blog/?m=202302)\n' +
      '* Carlini et al. (2019) Nicholas Carlini, Chang Liu, Ulfar Erlingsson, Jernej Kos, and Dawn Song. 비밀 공유자: 2019년 신경망에서 의도하지 않은 암기를 평가하고 테스트합니다.\n' +
      '* Carlini 등(2021) Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, Alina Oprea, and Colin Raffel. 2021년, 대규모 언어 모델에서 학습 데이터를 추출합니다.\n' +
      '* Carlini et al. (2022) Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, and Florian Tramer. 멤버십 추론 공격은 첫 번째 원칙에서 옵니다. _2022 IEEE Symposium on Security and Privacy (SP)_, pages 1897-1914. IEEE, 2022.\n' +
      '* Chen et al.(2021) Mark Chen et al. Evaluation large language models trained on code. _ arXiv_, 2021.\n' +
      '* Christ et al. (2023) Miranda Christ, Sam Gunn, and or Zamir. 언어 모델에 대한 탐지 불가능한 워터마크입니다. _ 암호학 ePrint Archive_, 2023.\n' +
      '* Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. _ ArXiv:2210.11416_, 2022.\n' +
      '* Cobbe et al. (2021) Karl Cobbe et al. training verifiers to solve math word problems. _ arXiv_, 2021.\n' +
      '* Cox et al. (2007) Ingemar Cox, Matthew Miller, Jeffrey Bloom, Jessica Fridrich, and Ton Kalker. _ 디지털 워터마킹 및 스테가노그래피_. 모건 카우프만, 2007년\n' +
      '* Crothers et al. (2022) Evan Crothers, Nathalie Japkowicz, and Herna Viktor. 기계 생성 텍스트: 위협 모델 및 탐지 방법에 대한 포괄적인 조사. _ ArXiv:2210.07321_, 2022.\n' +
      '* Dettmers et al.(2023) Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: 양자화된 l lms의 효율적인 미세조정 arXiv preprint arXiv:2305.14314_, 2023.\n' +
      '* Fan et al. (2018) Angela Fan, Mike Lewis, and Yann Dauphin. 계층적 신경 스토리 생성. _ arXiv preprint arXiv:1805.04833_, 2018.\n' +
      '* Fernandez et al. (2023) Pierre Fernandez, Antoine Chaffin, Karim Tit, Vivien Chappelier, and Teddy Furon. 대형 언어 모델의 워터마크를 통합하기 위한 세 개의 벽돌 2023 IEEE International Workshop on Information Forensics and Security (WIFS)_, 2023.\n' +
      '* 쌍둥이자리(2023) 팀 쌍둥이자리. 쌍둥이자리: 매우 유능한 멀티모달 모델 가족 arXiv preprint arXiv:2312.11805_, 2023.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c} Language & English & French & Spanish & German Catalan \\\\ \\hline \\(\\log_{10}(p)\\) & \\(<\\)-50 & -7.8 & -5.7 & -4.0 & -2.1 \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 타겟 텍스트 분포가 검출에 미치는 영향. \\ (\\mathcal{B}\\)는 해당 언어에서 위키피디아 기사의 시작과 함께 프롬프트되고, 생성된 다음 토큰에서 검출이 수행된다. 각 언어에 대해 Sec에서 설명한 _closed-model_ setting을 사용하여 \\(N=250k\\)\\(k\\)-gram을 채점한다. 4(필터 없음)입니다.\n' +
      '\n' +
      '샤리아 골친과 미하이 수데아누 llms에서의 시간 여행: 대규모 언어 모델에서 데이터 오염을 추적합니다. _ arXiv preprint arXiv:2308.08493_, 2023.\n' +
      '* Gu et al. (2023) Chenchen Gu, Xiang Lisa Li, Percy Liang, Tatsunori Hashimoto. 언어 모델에 대한 워터마크의 학습 가능성에 대해. _ arXiv preprint arXiv:2312.04469_, 2023.\n' +
      '* Gunasekar et al. (2023) Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio Cesar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi et al. arXiv preprint arXiv:2306.11644_, 2023.\n' +
      '* He et al. (2022a) Xuanli He, Qiongkai Xu, Lingjuan Lyu, Fangzhao Wu, and Chenguang Wang. 언어 생성 에피스의 지적 특성을 어휘 워터마크로 보호합니다. 2022a _AAAI_에서.\n' +
      '* He et al. (2022b) Xuanli He, Qiongkai Xu, Yi Zeng, Lingjuan Lyu, Fangzhao Wu, Jiwei Li, and Ruoxi Jia. 조건부 워터마크를 통한 텍스트 생성 API에 대한 지적 재산권 보호. _NeurIPS_, 2022b.\n' +
      '* Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 대규모 멀티태스크 언어 이해도 측정 arXiv preprint arXiv:2009.03300_, 2020.\n' +
      '*Hisamoto et al.(2020) Sorami Hisamoto, Matt Post, and Kevin Duh. 시퀀스-투-시퀀스 모델에 대한 멤버십 추론 공격: 내 데이터가 당신의 기계 번역 시스템에 있습니까? _ Computational Linguistics_, 8:49-63, 2020의 거래.\n' +
      '* Holtzman et al. (2019) Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 신경 텍스트 변성의 특이한 경우. _ ArXiv preprint arXiv:1904.09751_, 2019.\n' +
      '* Honovich et al. (2022) or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 부자연스러운 명령: (거의) 인간의 노동력이 없는 언어 모델을 조정합니다. _ ARXiv 프리프린트 arXiv:2212.09689_, 2022.\n' +
      '* Huang et al. (2023) Baihe Huang, Banghua Zhu, Hanlin Zhu, Jason D. Lee, Jiantao Jiao, and Michael I. Jordan. 최적의 통계적 워터마킹으로 2023년\n' +
      '* Joshi et al.(2017) Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. Triviaqa: 읽기 이해를 위한 대규모 원거리 감독 챌린지 데이터세트. _ arXiv_, 2017.\n' +
      '* Kingma and Ba(2017) Diederik P. Kingma and Jimmy Ba. A method for stochastic optimization, 2017.\n' +
      '* Kirchenbauer et al. (2023) John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. 대형 언어 모델을 위한 워터마크. _ arXiv preprint arXiv:2301.10226_, 2023a.\n' +
      '* Kirchenbauer et al. (2023) John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, and Tom Goldstein. 대형 언어 모델에 대한 워터마크의 신뢰성에 대해, 2023b.\n' +
      '* Kuditipudi et al. (2023) Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, and Percy Liang. 언어 모델에 대한 강인한 왜곡 없는 워터마크__ arXiv preprint arXiv:2307.15593_, 2023.\n' +
      '* Kwiatkowski et al. (2019) Tom Kwiatkowski et al. Natural questions: a benchmark for question answering research. _ 트랜스 of the ACL_, 7, 2019.\n' +
      '* Li 등(2023) Zongjie Li, Chaozheng Wang, Shuai Wang, and Cuiyun Gao. 워터마크를 통해 대용량 언어 모델 기반 코드 생성 apis의 지적 재산권을 보호합니다. _Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security_, pages 2336-2350, 2023.\n' +
      '* Loshchilov and Hutter (2017) Ilya Loshchilov and Frank Hutter. SGDR: 따듯한 재시작과 함께 확률적 기울기 하강. _International Conference on Learning Representations_, 2017.\n' +
      '* Mahloujifar et al. (2021) Saeed Mahloujifar, Huseyin A Inan, Melissa Chase, Esha Ghosh, and Marcello Hasegawa. 단어 임베딩과 그 이상에 대한 멤버쉽 추론 arXiv preprint arXiv:2106.11384_, 2021.\n' +
      '* Massey (1951) Frank J Massey. 적합성에 대한 콜모고로프-스미르노프 검정 Journal of the American Statistical Association_, 46(253):68-78, 1951.\n' +
      '* Mukherjee et al. (2023) Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. Orca: gpt-4의 복잡한 설명 흔적으로부터 점진적 학습. _arXiv preprint arXiv:2306.02707_, 2023.\n' +
      '* Nasr et al. (2019) Milad Nasr, Reza Shokri, and Amir Houmansadr. 딥러닝의 포괄적인 프라이버시 분석: 중앙 집중식 및 연합식 학습에 대한 수동적이고 능동적인 화이트박스 추론 공격. _2019 IEEE symposium on security and privacy (SP)_, pages 739-753. IEEE, 2019.\n' +
      '* Nasr et al. (2023) Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tramer, and Katherine Lee. (제작) 언어 모델로부터 훈련 데이터의 스케일러블 추출, 2023.\n' +
      '*(2023) OpenAI. Gpt-4 기술 보고서입니다 arXiv_, 2023.\n' +
      '* Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. training language models to follow instructions with human feedback. _ 신경 정보 처리 시스템_, 35:27730-27744, 2022에서의 발전.\n' +
      '* Peng et al. (2023) Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. gpt-4. _arXiv preprint arXiv:2304.03277_, 2023a.\n' +
      '*Peng et al. (2021) Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, 및 Xing Xie. 내 모델 베끼는 거야? 백도어 워터마크를 통해 eaas에 대한 대형 언어 모델의 저작권을 보호한다. _ arXiv preprint arXiv:2305.10036_, 2023b.\n' +
      '* Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever 등 언어 모델들은 비감독 멀티태스크 학습자들이다. _ OpenAI blog_, 1(8):9, 2019.\n' +
      '* Roelofs(2017) Greg Roelofs. 엄청나게 섬세하면서도 섬세하게 눈에 띄지 않는 압축 라이브러리 http://www. 즐립 net/_, 2017.\n' +
      '* Sablayrolles et al. (2018) Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, and Herve Jegou. D\\(\\backslash\\)ej\\(\\backslash\\)a vu: convnets의 암기 속성에 대한 실증적 평가. _ arXiv preprint arXiv:1809.06396_, 2018.\n' +
      '* Sablayrolles et al. (2019) Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Yann Ollivier, and Herve Jegou. 화이트박스 vs 블랙박스: 멤버십 추론을 위한 최적의 전략을 베이즈합니다. _International Conference on Machine Learning_, pages 5558-5567. PMLR, 2019.\n' +
      '* Sablayrolles et al. (2020) Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, and Herve Jegou. 방사능 데이터: 훈련을 통한 추적. _International Conference on Machine Learning_, pages 8326-8335. PMLR, 2020.\n' +
      '* Shi et al. (2023) Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen, and Luke Zettlemoyer. 대형 언어 모델로부터 사전 훈련 데이터를 검출하는 단계; _ arXiv preprint arXiv:2310.16789_, 2023.\n' +
      '* Shokri et al. (2017a) Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 멤버십 추론 공격은 머신 러닝 모델, 2017a이다.\n' +
      '* Shokri et al. (2017b) Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 멤버십 추론 공격은 머신러닝 모델에 대한 공격이다. _2017 IEEE symposium on security and privacy (SP)_, pages 3-18. IEEE, 2017b.\n' +
      '* Taori et al. (2023) Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 스탠포드 알파카: 지시를 따르는 LLaMA 모델, 2023.\n' +
      '* Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. _ arXiv preprint arXiv:2302.13971_, 2023a.\n' +
      '* Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. _ arXiv preprint arXiv:2307.09288_, 2023b.\n' +
      '* Veselovsky et al. (2023) Veniamin Veselovsky, Manoel Horta Ribeiro, and Robert West. 인공 인공 지능: 군중 노동자들은 텍스트 제작 작업에 큰 언어 모델을 널리 사용한다, 2023.\n' +
      '* Wallace et al. (2020) Eric Wallace, Mitchell Stern, and Dawn Song. 블랙박스 기계 번역 시스템을 위한 모방 공격 및 방어. 2020년 _EMNLP_에서.\n' +
      '* Wang et al. (2022) Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 자가 명령어: 언어 모델을 자가 생성된 명령어와 정렬합니다. _ ARXiv 프리프린트 arXiv:2212.10560_, 2022.\n' +
      '* Watson et al. (2021) Lauren Watson, Chuan Guo, Graham Cormode, and Alex Sablayrolles. 멤버십 추론 공격에서 난이도 교정의 중요성에 관한 연구 arXiv preprint arXiv:2111.08440_, 2021.\n' +
      '* Wei et al. (2022) Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 재정 조정된 언어 모델은 제로 샷 학습자입니다. _International Conference on Learning Representations_, 2022.\n' +
      '* Weidinger et al. (2022) Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh, et al. Taxonomy of risks posed language models. _2022 ACM 공정성, 책임성 및 투명성에 관한 회의에서, 페이지 214-229, 2022.\n' +
      '* Xu et al. (2023) Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. Baize: self-chat 데이터에 대한 파라미터-효율적인 튜닝을 갖는 오픈 소스 채팅 모델 _ arXiv preprint arXiv:2304.01196_, 2023.\n' +
      '* 염 등(2018) 사무엘 염, 아이린 지아코멜리, 맷 프레드릭슨, 및 소메쉬 자. 기계 학습에서 개인 정보 보호 위험: 과적합에 대한 연결을 분석합니다. _2018 IEEE 31st Computer Security Foundation symposium (CSF)_, pages 268-282. IEEE, 2018.\n' +
      '* Zhao et al. (2023) Xuandong Zhao, Yu-Xiang Wang, and Lei Li. 보이지 않는 워터마킹을 통해 언어 생성 모델을 보호하는 것 arXiv preprint arXiv:2302.03162_, 2023.\n' +
      '\n' +
      '## LLM 워터마킹에 관한 세부사항 부록\n' +
      '\n' +
      '본 논문에서는 Sec. 2.2에 제시된 표기를 사용한다. 본 논문에서는 이전 토큰의 윈도우에 따라 \\(x^{(0)}\\을 생성하려고 할 때 로짓 벡터 \\(\\mathbf{\\ell}\\) 또는 확률 벡터 \\(\\mathbf{p}\\)를 변경하는 워터마킹 방법(Kirchenbauer et al., 2023, 2023, Aaronson and Kirchner, 2023)을 고려한다. 해시 함수는 이러한 토큰들을 난수 생성기(RNG)를 초기화하는 랜덤 시드에 매핑한다. 해시 함수는 또한 비밀 키\\(\\mathsf{s}\\)에 의존한다. RNG는 다음 토큰의 선택 \\(x^{(0)}\\)에 영향을 주거나 결정하기 위해 사용된다.\n' +
      '\n' +
      '### Kirchenbauer et al.(2023)\n' +
      '\n' +
      'RNG는 \\(\\gamma|\\mathcal{V}|\\) 토큰을 포함하는 그린리스트를 생성하는 데 사용되며, 여기서 \\(\\gamma\\in[0,1]\\). 그린리스트에 있는 모든 토큰의 로짓은 \\(\\delta\\)씩 증가된다. 그런 다음 샘플링은 평소처럼 진행됩니다. 직관적으로, 이것은 그들의 확률을 증가시킴으로써 그린리스트 토큰들의 생성을 장려한다.\n' +
      '\n' +
      'detection_를 위해, 텍스트를 토큰화하고 그들의 윈도우의 그린리스트에 얼마나 많은 토큰들이 있는지를 카운트한다. 더 형식적으로, 우리는 \\(T\\) 토큰의 텍스트를 고려한다. 점수\\(S\\)는 그린리스트 토큰의 수이다:\n' +
      '\n' +
      '\\[S=\\sum_{t}R_{t}\\quad\\text{with }R_{t}=\\mathds{1}(\\text{``}x^{(t}\\text{ is in greenlist\'\'}), \\tag{3}\\]\n' +
      '\n' +
      '및 2.2의 표기들과 함께:\n' +
      '\n' +
      '\\[W_{\\text{score}}\\left(\\mathsf{s},\\left(x^{(t-i)}\\right)_{i=k}^{1};\\,x^{(t)}\\right)=R_{t}\\\\=\\mathds{1}\\left(\\text{`}x^{(t)}\\text{ is in greenlist}\\left(\\mathsf{s},\\left(x^{(t-i)}\\right)_{i=k}^{1}\\right)\\text{\'\'}\\right)\\text{\\text{{1}\\mathds{1}\\left(\\text{`}x^{(t)}\\text{ is in greenlist}\\left( \\mathsf{s},\\left(x^{(t-i)}\\right)_{i=k}^{1}\\right)\\text{\'\'}\\right)\\text{\\text{s},\\left(x^{(t-i)}\\right)\\text\n' +
      '\n' +
      '통계적 가설 \\(\\mathcal{H}_{0}\\): "텍스트는 자연스럽다", \\(\\mathcal{H}_{1}\\): "텍스트는 워터마크로 생성되었다"를 검정한다. 우리는 \\(\\mathcal{H}_{0}\\)하에서 \\(\\{0,1\\}\\)의 값을 갖는 확률변수 \\((R_{t})_{t}\\)는 독립적이며 각각 매개변수 \\(\\gamma\\)을 갖는 베르누이 분포를 따른다고 가정한다. 따라서 \\(S\\)은 매개변수 \\(T\\)와 \\(\\gamma\\)을 갖는 이항 분포를 따른다. 점수와 관련된 시험의 \\(p\\)-값, \\(\\mathcal{H}_{0}\\) 하에서 \\(s\\)보다 높은 점수를 얻을 수 있는 _i.e. 값은 이론적으로 다음과 같이 구할 수 있다.\n' +
      '\n' +
      '\\[p\\text{-value}(s)=\\mathds{P}(S>s|\\mathcal{H}_{0})=I_{\\gamma}(s,T-s+1), \\tag{4}\\]\n' +
      '\n' +
      '여기서 \\(I\\)은 정규화된 불완전 베타 함수이다. <\\(\\mathcal{H}_{1}\\) 이하에서는 <(\\mathcal{H}_{0}\\)보다 점수가 높을 가능성이 높기 때문에 <(p\\)-값은 낮을 가능성이 높다.\n' +
      '\n' +
      '워터마크의 _strength_는 주로 파라미터 \\(\\delta\\)에 의해 제어된다. 높은 경우, 샘플링은 그린리스트 토큰만을 선택하는데, 이는 텍스트 품질을 저하시키지만 워터마크의 견고성을 증가시킨다.\n' +
      '\n' +
      '### Aaronson and Kirchner (2023)\n' +
      '\n' +
      'RNG는 랜덤 벡터 \\(R\\in[0,1]^{|\\mathcal{V}|}\\)를 생성하는 데 사용된다. 그런 다음 분포\\(p\\)에서 샘플링하는 대신 다음 토큰은 \\(x^{(0)}=\\arg\\max_{v\\in\\mathcal{V}}R_{v}^{1/p_{v}}\\)에 의해 선택된다(핵 샘플링 또는 상위\\(K\\)은 \\(R^{1/p}\\) 계산 전에 \\(p\\)에 적용될 수 있다). 직관적으로 이것은 높은 \\(R_{v}\\) 값을 갖는 토큰들의 생성을 장려한다. 또한 \\(\\forall v\\in\\mathcal{V}\\), \\(\\mathds{P}_{R}(x^{(0)}=v)=p_{v}\\이라는 흥미로운 특성을 제시한다. 즉, 토큰을 생성할 확률은 비밀 키에 대한 기대치에 따라 변경되지 않는다.\n' +
      '\n' +
      '검출_에 대해, 하나는 모든 토큰을 통과한다. 시간-단계 \\(t\\)에서, \\(k\\) 이전 토큰들은 키 벡터 \\(R^{(t)}\\in[0,1]^{|\\mathcal{V}|}\\)을 검색하는데 사용된다. 우리는 \\(R_{t}\\)의 숫자 \\(R_{x^{(t)}^{(t)}}^{(t)}\\), _i.e. 선택된 토큰에 대한 키 벡터의 값을 나타낸다. 점수는 이제\n' +
      '\n' +
      '\\[S=-\\sum_{t}\\ln(1-R_{t}), \\tag{5}\\]\n' +
      '\n' +
      '및 2.2의 표기들과 함께:\n' +
      '\n' +
      '\\[W_{\\text{score}}\\left(\\mathsf{s},\\left(x^{(t-i)}\\right)_{i=k}^{1};\\,x^{(t)}\\right)=-\\ln(1-R_{t})\\\\=-\\ln\\left(1-R_{x^{(t)}}^{(t)}}\\right)\\\\=-\\ln\\left(1-R_{x^{(t)}}^{(t)}\\right).\\]\n' +
      '\n' +
      '우리는 이전과 동일한 가설 검정을 고려한다. 우리는 \\(\\mathcal{H}_{0}\\)하에서 \\(R_{t}\\sim\\mathcal{U}(0,1)\\)과 \\(R_{t}\\)이 \\(\\Gamma(T,1)\\) 분포를 따른다고 가정한다. 점수\\(s\\)와 관련된 테스트의 \\(p\\)-값은 다음과 같다.\n' +
      '\n' +
      '\\[p\\text{-value}(s)=\\frac{\\Gamma(T,s)}{\\Gamma(T)}, \\tag{6}\\]\n' +
      '\n' +
      '여기서 \\(\\Gamma\\)는 상부 불완전 감마 함수이다. \\(\\mathcal{H}_{1}\\) 이하에서는 점수가 더 높을 것으로 예상된다. 사실, 그것의 기대치는 \\(T+cH\\)에 의해 더 낮게 제한되며, 여기서 \\(c\\)은 양의 상수이고 \\(H\\)은 생성된 텍스트의 엔트로피이다.\n' +
      '\n' +
      '워터마크의 _strength_는 소프트맥스의 온도\\(T\\)와 직접 연결된다. 예를 들어, 매우 높은 값인 \\(T\\)의 경우 softmax는 거의 균일한 확률 벡터 \\(p\\)을 출력하기 때문에 다음 토큰의 선택은 전적으로 \\(R\\)에 의해 결정된다 (가장 높은 \\(R\\) 값을 갖는 토큰이 선택된다) - 반면, 매우 낮은 \\(T\\)의 경우 분포 \\(p\\)은 매우 피크이므로 \\(R\\)에 영향을 미치지 않는다. 따라서, 워터마크 강도는 \\(T\\)과 함께 증가한다.\n' +
      '\n' +
      'Score computation\n' +
      '\n' +
      '이 섹션에서는 Sec. 4에 설명된 채점 방법, 알고리즘 및 결과에 대해 자세히 설명한다.\n' +
      '\n' +
      '### Reporting\n' +
      '\n' +
      'Log\\(p\\)-values. \\(p\\)-values가 종종 다양한 크기 차수에 걸쳐 있음을 감안할 때, 우리는 \\(p\\)-values 자체의 평균이 아닌 여러 런에서 \\(\\log_{10}(p)\\)의 평균을 일관되게 보고한다. 본문에서는 평균 \\(\\log_{10}(p)\\)을 \\(p\\)-값으로 직접 읽을 수 있는 것처럼 해석한다. (예를 들어, 평균 \\(\\log_{10}(p)\\)이 \\(-5\\)인 경우, 앨리스가 10,000건에서 귀무 가설을 한 번만 기각하는 것이 잘못된 것처럼 해석한다. 그러나 이것은 엄격한 통계적 \\(p\\)-값으로 직접 번역하는 것은 실제로 불가능하기 때문에 단순화한 것이다. 따라서 그림 6에 추가 통계가 있는 상자 그림을 보여준다.\n' +
      '\n' +
      '여러 런에 대한 평균.계산적 제약으로 인해 각 설정에 대해 서로 다른 명령 데이터에 대해 훈련된 여러\\(\\mathcal{B}\\) 모델에 걸쳐 \\(\\log_{10}(p)\\)의 표준 편차가 계산되지 않는다. 대신, 각 설정에 대해, 우리는 \\(\\mathcal{B}\\)을 미세 조정하기 위해 사용되는 데이터 외에 동일한 볼륨의 데이터(14M 토큰, 섹션 5 참조)를 생성한다. 오픈 모델 설정에서 우리는 이 추가 데이터의 10개의 별개의 청크에 대한 탐지를 실행한다. 폐쇄 모델/비감독 설정에서 우리는 새로운 문장(비표시)의 10개의 다른 덩어리로 \\(\\mathcal{B}\\)을 프롬프트하고 응답을 채점한다. 폐쇄 모델/완전 감독 설정(그림 1에 보고된 결과)의 경우. 4) 워터마크가 삽입된 미세조정 데이터의 1\\(\\rho=1\\%\\)에 대해 75k 토큰만을 나타내는 D\\(D^{\\mathcal{A}}\\)에 존재하는 모든 프롬프트에 대한 \\(\\mathcal{B}\\)의 답을 얻는다. 신뢰 구간의 부재를 설명합니다.\n' +
      '\n' +
      '### Correctness\n' +
      '\n' +
      '#### b.2.1 토큰 점수화 및 중복제거\n' +
      '\n' +
      '모든 토큰을 점수화하는 것은 점수 계산에 편향을 도입하고 반복이 독립 가설 Fernandez 등(2023)을 깨뜨릴 때 부정확하게 만들 수 있다. 이는 분석된 토큰의 수가 증가할 때(본 논문의 실험에서 \\(10^{4}\\)보다 클 때) 더욱 정확하다. 이러한 편향에 대한 완화는 Kirchenbauer et al.(2023); Fernandez et al.(2023)에 의해 별개의 \\(k\\)-그램 또는 \\(k+1\\)-그램만을 채점함으로써 제안되었다. 기본적으로 우리는 더 많은 토큰을 얻을 수 있기 때문에 뚜렷한 \\(k+1\\)-그램을 채점한다.\n' +
      '\n' +
      '또한 워터마크된 텍스트가 있는 모델\\(\\mathcal{B}\\)을 프롬프트하기 때문에 통계적 테스트에서 다른 편향이 나타날 수 있다. 다음 단락에서 우리는 이러한 편견을 설명하고 그것들을 피하는 방법을 보여준다.\n' +
      '\n' +
      '폐쇄 모델. Sec의 세부 조정 설정을 위한 지시입니다. 5, _supervised_ 시나리오에서, 우리는 \\(\\tilde{D}^{\\mathcal{A}\\)의 워터마크된 질문들로 \\(\\mathcal{B}\\)을 프롬프트한다. 이 환경에서 앨리스는 Bob이 \\(\\tilde{D}^{\\mathcal{A}}\\)의 질문/답변 쌍에 대해 그의 모델을 훈련시켰다고 의심한다. 검출에서 동일한 질문을 하는 것은 방사능 검출을 선호한다. 그러나, 만약 그들이 질문의 일부 부분을 반복한다면 그 대답은 거짓으로 방사능으로 보일 수 있다. 예를 들어, 워터마크가 삽입된 \\(\\tilde{D}^{\\mathcal{A}\\)의 명령어가 "문장을 반복하라"인 경우, 검출 시간에서 \\(\\mathcal{B}\\)은 아마도 \\(x\\)에 답할 것이며, 이것은 만약 그렇게 점수를 매기면 방사능으로 보일 것이다. 우리는 문제의 일부가 아닌 {워터마크 컨텍스트}로 토큰만 채점하여 이 문제를 해결할 것을 제안한다.\n' +
      '\n' +
      'Open-model._open-model_ setting에서는 다음 토큰을 생성할 때 \\(\\mathcal{B}\\)이 고려하지 않은 \\(k\\)-gram만을 채점한다. 문장 초반에 \\(k\\)-gram이 존재한다면 \\(\\mathcal{B}\\)만큼 반복될 가능성이 높아 허위방사성이 나타나기 때문이다. 이러한 경우를 제외하고, 우리는 뚜렷한 \\((k+1)\\)-그램을 채점한다. 이것은 Sec에서 자세히 설명되지 않았다. 4는 명확성을 위해 사용되지만 Sec에서 사용됩니다. 5항과 6항.\n' +
      '\n' +
      '보다 정확하게, 우리는 오픈 모델 방사능 점수 테스트를 적용한다고 가정한다 - Sec 참조. 4 - \\(\\mathcal{A}\\)에 의해 생성된 문장 \\(x\\)에 Kirchenbauer et al.(2023)의 워터마크가 있다. \\(x\\)에는 "날씨 예보: 날씨가 좋다."라는 문장이 포함되어 있고, "날씨는 좋다"라는 그린리스트에 "날씨가 좋다"라는 문장이 포함되어 있다고 가정하자. \\(\\mathcal{B}\\)을 통과 전달할 때, "날씨 예측: 날씨가 좋다." 다음에 가장 가능성이 높은 토큰은 \\(\\mathcal{B}\\)의 디코딩에 따라 "날씨가 좋다"일 수 있다. 그러나, 이는 문장 \\(x\\): "날씨는 좋다"의 시작에 의해 영향을 받기 때문일 수 있다. 따라서,\n' +
      '\n' +
      '그림 6: 워터마킹된 \\(\\rho\\), \\(\\mathcal{B}\\)의 미세조정 데이터의 비율을 변화시키면서 개방/비감독 설정에서 \\(\\log_{10}(p)\\)에 대한 박스 플롯. 이것은 그림 1에 제시된 값에 해당한다. 4에서 평균이 보고됩니다.\n' +
      '\n' +
      '"좋음"은 거짓 방사성으로 보일 것이다. 우리는 \\(k\\)그램의 첫 번째 발생 후에 \\(\\mathcal{B}\\)이 생성하는 토큰만을 \\(x\\)에서 "날씨"로 채점하는 것이 이 문제를 완화한다는 것을 보여준다.\n' +
      '\n' +
      '#### b.2.2 정답 실험\n' +
      '\n' +
      '우리는 논문에 사용된 통계적 테스트의 정확성을 연구하고 검증한다. 실험에서 귀무가설 \\(\\mathcal{H}_{0}\\)은 Alice의 방법과 키(\\(\\rho=0\\))에 의해 워터마크가 삽입된 데이터에 대해 밥의 모델이 미세 조정되지 않았을 때를 나타낸다. 다양한 데이터셋을 가진 미세 조정 모델\\(\\mathcal{B}\\)과 고정 텍스트 및 고정 워터마킹 알고리즘 및 키에서 검출을 실행하는 대신, 우리는 고정 미세 조정 모델(계산 및 메모리를 절약하기 위해)에서 검출 알고리즘의 하이퍼 파라미터를 변경하는 것을 선택한다. 따라서 다음 \\(\\mathcal{B}\\)에서 모델은 지정되지 않은 지침에 대해 미세 조정된다(Sec. 5에 제시된 바와 같다).\n' +
      '\n' +
      '폐쇄 모델.폐쇄 모델/비감독 시나리오의 정확성은 Fernandez et al.(2023)에 의해 연구된 LLM 워터마크 검출에 사용된 고전적인 통계적 테스트의 정확성에 의해 보장된다. 그러나 지도 시나리오에서는 문제의 일부가 아닌 {워터마크 컨텍스트}로 {워터마크 컨텍스트 + 현재 토큰}만 점수화하는 워터마크가 표시된 모델을 프롬프트한다.\n' +
      '\n' +
      '폐쇄 모델/감독 시나리오에서 테스트를 검증하기 위해 Sec와 동일한 설정에서 \\(\\approx 10\\)k 워터마크가 삽입된 명령어로 \\(\\mathcal{B}\\)을 프롬프트한다. 5: \\(\\delta=3\\) 및 \\(k=2\\) 및 세 가지 상이한 종자 s와 함께 Kirchenbauer et al.(2023)에 의한 방법을 사용한다. 그런 다음 제안된 중복 제거를 사용하여 답변(명령을 생성하는 데 사용된 동일한 시드 s로)을 채점한다. 우리는 이것을 다른 질문에서 10번 반복하고 그림 7에서 평균과 표준 편차를 보여준다. 우리는 750k 토큰의 점수를 매긴 후 귀무가설(\\(\\mathcal{H}_{0}\\))에서 \\(p\\)-값이 약 0.5임을 보여준다. 섹션 5에서 우리는 폐쇄/감독 환경에서 350k 토큰을 획득했다.\n' +
      '\n' +
      '오픈 모델.오픈 모델 시나리오에서 테스트를 검증하기 위해 다음과 같이 진행합니다.\n' +
      '\n' +
      '* 우리는 8개의 별개의 워터마크로 텍스트를 생성한다. Aaronson과 Kirchner(2023)가 제안한 워터마킹 방법은 4가지 다른 값 \\(k\\in\\{1,2,3,4\\}\\)을 사용하여 \\(T=0.8\\)을 얻었다. 마찬가지로, Kirchenbauer et al.(2023)이 제안한 워터마킹 방법에는 \\(\\delta=2.4\\)의 4가지 다른 값 \\(k\\in\\{1,2,3,4\\}\\)을 사용한다.\n' +
      '* 각 구성에 대해 데이터셋을 세 개의 세그먼트로 나눈다. 그런 다음 Sec에 설명된 방사능 검출 테스트를 적용한다. 각각 150만 개 이상의 토큰을 포함하는 이 24개 세그먼트의 4개(이전 단락에서 제시된 중복 제거를 사용함)입니다.\n' +
      '\n' +
      '모든 텍스트는 동일한 시드 s를 사용하여 생성되며, 이는 검출 프로세스 동안 Alice에 의해 또한 사용된다. 실제로 앨리스는 그녀가 사용하고 있는 워터마킹 방식을 알고 있다. 우리는 이러한 모든 세그먼트에 대한 평균 및 표준 편차를 계산한다. 인 것을 특징으로 하는 반도체 소자의 제조 방법. 도 8에서, 우리는 150만 토큰의 점수를 매긴 후 귀무가설(\\(\\mathcal{H}_{0}\\))에서 \\(p\\)-값이 약 0.5임을 입증한다. 작은 편향에 대한 설명 중 하나는 중복제거가 \\(k\\)-그램 사이의 독립성을 보장하지만 \\(n<k\\)에 대한 \\(n\\)-그램 사이에는 여전히 약간의 종속성이 있을 수 있다는 사실이다.\n' +
      '\n' +
      '그림 8: 개방 모델 설정의 \\(\\mathcal{H}_{0}\\) 아래의 \\(p\\)-값. 우리는 워터마킹되지 않은 명령어에 대해 \\(\\mathcal{B}\\)을 미세 조정했다. 우리는 Sec의 오픈모델 탐지를 적용한다. 도 4를 참조하면, 다음 토큰을 생성할 때 (\\(k+1\\))-그램과 \\(\\mathcal{B}\\)이 고려하지 않은 \\(k\\))-그램만을 점수화하는 차이가 있다. 평균은 \\(\\mathcal{H}_{0}\\)에서 예상한 바와 같이 0.5에 가깝다.\n' +
      '\n' +
      '그림 7: 닫힌 모델/지도 설정에서 \\(\\mathcal{H}_{0}\\) 아래의 \\(p\\)-값. 우리는 워터마킹되지 않은 명령에만 \\(\\mathcal{B}\\)을 미세 조정했다. 우리는 워터마크가 삽입된 명령어로 \\(\\mathcal{B}\\)을 프롬프트하고, 그 대답으로부터 구별되는 (\\(k+1\\))-그램을 점수화하지만, \\(k\\)-그램이 명령어의 일부가 아닌 경우에만 점수를 매긴다. 평균은 \\(\\mathcal{H}_{0}\\)에서 예상한 바와 같이 0.5에 가깝다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:15]\n' +
      '\n' +
      '표 7은 미세 조정을 위해 사용된 텍스트의 검출 및 품질 측면에서 결과를 설명한다. 리마인더로서 Llama-2-chat-7B와 Kirchenbauer et al.(2023)의 워터마킹, Sec. 5에서와 같이 \\(\\delta=3.0\\), \\(\\gamma=0.25\\) 및 워터마크 윈도우 \\(k=2\\)으로 텍스트를 생성하였다. 예를 들어 50~150개의 토큰으로 만들어진 500개의 텍스트에서 \\(\\log_{10}(p\\)-값)은 평균적으로 \\(-7.2\\)이다.\n' +
      '\n' +
      '## 부록 D 추가 결과\n' +
      '\n' +
      '미아 vs. WWM 검출\n' +
      '\n' +
      '표 3은 MIA와 워터마킹 기반 검출을 비교할 때 감독 정도의 중요성을 나타내었다. 상기시키는 바와 같이, 감독 정도\\(d\\)는 Alice가 자신이 사용했다고 의심하는 모든 데이터 중 Bob이 자신의 모델을 훈련시키기 위해 사용한 데이터의 비율을 나타낸다. 보다 상세한 그림을 위해 그림 9는 _open-model_/_supervised_ setup에서 두 탐지 방법의 탐지 성능을 보여준다. 감독 수준이 감소함에 따라 Bob이 실제로 사용한 \\(\\tilde{D}^{\\mathcal{A}}\\)에서 토큰의 비율이 감소하여 테스트가 약화되었다. 워터마킹된 데이터의 경우, 테스트는 여전히 강한 신뢰도를 산출한다.\n' +
      '\n' +
      '### 에폭스의 수\n' +
      '\n' +
      '그림 10은 탭. 4에 제시된 결과를 확장한다. 상기시키기 위해, 설정은 Sec에 제시된 것과 유사하다. 도 6에 도시된 바와 같이, 명령어들의 _i.e._\\(\\rho=100\\%\\)는 워터마킹으로 생성된다(Kirchenbauer et al., 2023). 우리는 \\(N\\)=10k 토큰에서 방사능을 관측한다.\n' +
      '\n' +
      '상기시켜주자면, Sec에서. 도 5는 Alpaca에 대해 수행된 바와 같이, 3 에폭의 미세 조정을 수행했다(Taori et al., 2023).\n' +
      '\n' +
      '### 필터의 영향\\(\\phi\\)\n' +
      '\n' +
      '감리 및 비감리 폐쇄 모델 설정 모두에서 필터의 사용을 제안했다. 섹션 4에서 설명한 바와 같이, \\(\\mathcal{B}\\)의 워터마크 트레이스는 \\(D^{\\mathcal{A}}\\)의 일부인 \\(k\\)-그램에서만 검출될 수 있다(워터마크 임베딩에 대한 세부사항은 서브섹션 2.2 참조). 이 \\(k\\)-그램들이 심하게 워터마킹되어 있고 \\(\\mathcal{B}\\)이 모두 암기되어 있다고 가정하면, 여전히 테스트할 수 있는 전체 \\(|\\mathcal{V}|^{k}\\)\\(k\\)-그램의 작은 부분만을 나타낸다. 탐지를 향상시키기 위해 훈련되었을 가능성이 있는 \\(k)-gram의 집합 \\(\\phi\\)을 정의한다. 토큰은 이전의 \\(k\\)-그램 윈도우(해싱에 사용된 워터마크 컨텍스트 윈도우)가 \\(\\phi\\)의 일부일 경우에만 채점된다. 이 방법은 워터마크가 잠재적으로 학습될 수 있는 \\(k\\)-그램에 점수 계산을 집중한다. 완전 지도 설정에서 (\\(d=1\\)) \\(\\phi\\)은 훈련 시 사용되는 \\(k\\)-그램, 즉 \\(D^{\\mathcal{A}}\\)의 모든 \\(k\\)-그램으로 구성된다. 비감독 설정에서는 여전히 워터마크와 함께 \\(\\mathcal{A}\\)에 의해 생성된 새로운 텍스트에 자주 나타나는 \\(k\\)-그램과 같은 오염된 토큰 세트에 초점을 맞춘다. 필터\\(\\phi\\)는 닫힌 모델 설정에서만 사용됩니다.\n' +
      '\n' +
      '또한, 도 6에 나타낸 바와 같이, 본 발명의 일 형태는, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 바와 같이, 도 7에 나타낸 본문에 표시된 5는 그림 1의 상자 그림을 보여준다. 11. 필터 단독의 효과를 분리하고 다른 청크에 대한 결과를 비교하기 위해 모든 설정에서 동일한 비-표식 프롬프트를 사용하고, \\(\\mathcal{B}\\)에 의해 응답된 동일한 수의 생성된 토큰 \\(N=1.5\\)M을 분석한다. 따라서, 지도 설정에 대해, 워터마크된 프롬프트를 \\(D^{\\mathcal{A}}\\)에서 사용하는 그림 5 및 그림 4에서 수행된 것과 다르다. 두 필터링 방법 모두 기준선과 비교하여 개선점을 보인다. 필터는 최악의 경우 시나리오에서 탐지 신뢰도를 높이는 데 특히 중요한 것으로 보인다(예: 우리의 경우 10회 실행에서 관찰된 가장 큰 \\(p\\)-값). 표 8은 동일한 결과를 표로 보고한다. 두 도면 모두 \\(k=2\\)에 해당한다(setting of\n' +
      '\n' +
      '그림 11: 필터의 영향. (\\rho=10\\%\\)의 닫힌 모형 설정에서 \\(\\log_{10}(p)\\)의 상자 그림. 우리는 \\(\\mathcal{B}\\)에 의해 생성된 텍스트에 대해 워터마크 검출 테스트를 수행한다. 기준선은 기본 점수(필터 없음)를 사용합니다. 비지도 시나리오에서, 스코어링은 \\(\\mathcal{A}\\)에 의해 생성된 새로운 워터마크 데이터에 생성된 \\(k\\)-그램에 국한된다. 감독 시나리오에서 채점은 \\(\\mathcal{D}^{\\mathcal{A}}\\)에 존재하는 \\(k\\)-그램으로 제한된다.\n' +
      '\n' +
      '그림 10: 워터마크가 삽입된 데이터의 \\(\\rho=100\\%\\)에 \\(\\mathcal{B}\\)이 미세 조정되었을 때 에포크 수의 방사능에 미치는 영향에 대한 자세한 결과. 예상대로 미세 조정이 오래 지속될수록 워터마킹이 모델에 흔적을 남긴다.\n' +
      '\n' +
      'Sec. (p<0.05). 우리는 필터가 \\(k\\)의 더 높은 값에 대해 훨씬 더 효율적일 것으로 예상한다는 점에 유의한다.\n' +
      '\n' +
      '### 오픈 vs. 닫혔어\n' +
      '\n' +
      '그림 12는 미세 조정 데이터의 10%가 워터마킹된 경우 개방 및 폐쇄 모델 설정에서의 검출을 비교한다. 이 설정은 Sec. 5의 설정으로, 평균 10개의 다른 런에서 생성된 다음 토큰 수에 대해 \\(\\log_{10}(p\\)-값)을 표시합니다. 예상대로, 탐지 테스트의 신뢰도는 토큰의 수에 따라 증가하며, 개방 설정에서는 더욱 그렇다. 예를 들어, 250k에서 생성된 토큰에서 닫힌 모델 검출의 평균 \\(\\log_{10}(p)\\)은 \\(-3\\)인 반면, Sec. 5.4에 제시된 열린 모델 검출의 평균 \\(-12\\)이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c}  & Baseline & Unsupervised & Supervised \\\\ \\hline \\(\\log_{10}(p)_{\\mathrm{mean}}\\) & -4.7 & -5.2 & **-5.5** \\\\ \\(\\log_{10}(p)_{\\mathrm{max}}\\) & -1.9 & -2.4 & **-3.7** \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: 검지는 채점된 \\(k\\)-그램에 필터가 있거나 없는 폐쇄 모델 설정의 결과이다. 우리는 10회에 걸쳐 평균과 max\\(\\log_{10}(p)\\)를 보고한다. 채점된 \\(k\\)-그램의 필터링은 탐지를 향상시키며, 최악의 시나리오에서는 더욱 그렇다. Fig.를 참조한다. 11은 해당 박스 블롯에 대한 것이고, App. D.3은 실험 세부사항에 대한 것이다.\n' +
      '\n' +
      '그림 12: \\(\\log_{10}(p)\\)의 비지도 설정에서 \\(\\rho=10\\%\\)의 \\(\\mathcal{B}\\)의 미세 조정 데이터가 생성된 토큰 수에 따라 워터마킹되었다. 폐쇄 모델 시나리오의 경우, \\(\\mathcal{B}\\)에 의해 생성된 새로운 텍스트에 대해 워터마크 검출 테스트를 수행하고, \\(\\mathcal{A}\\)의 워터마크에 의해 종종 생성되는 \\(k\\)-그램에 대해서만 워터마크를 검출한다.\n' +
      '\n' +
      '라마-2-채팅에 대한 프롬프트: 20가지 다양한 작업 지침 세트를 작성하도록 요청됩니다. 이 명령어들은 큰 언어 모델에 주어질 것이며, 우리는 명령어들을 완성하기 위해 그것을 평가할 것이다.\n' +
      '\n' +
      '다음은 요구 사항입니다.\n' +
      '\n' +
      '1. 다양성을 최대화하기 위해 각 명령어에 대해 동사를 반복하지 않도록 노력한다.\n' +
      '2. 수업에 사용되는 언어 또한 다양해야 한다. 예를 들어, 당신은 질문과 명령적 지시를 결합해야 한다.\n' +
      '3. 지침의 종류는 다양해야 한다. 목록에는 개방형 생성, 분류, 편집 등과 같은 다양한 유형의 작업이 포함되어야 합니다.\n' +
      '4. 언어 모델은 명령어를 완성할 수 있어야 한다. 예를 들어, 어시스턴트에게 시각적 또는 오디오 출력을 생성하라고 요청하지 마십시오. 다른 예를 들어, 어떤 액션도 수행할 수 없기 때문에 어시스턴트에게 오후 5시에 깨우라고 요청하거나 리마인더를 설정하지 마십시오.\n' +
      '5. 설명서는 영어로 되어 있어야 합니다.\n' +
      '6. 지시문은 1~2문장이어야 한다. 명령문이나 질문이 허용된다.\n' +
      '7. 명령어에 대한 적절한 입력을 생성하여야 한다. 필요한 경우 지침에 대한 구체적인 예가 포함되어야 합니다.\n' +
      '8. 대부분의 명령어는 입력을 필요로 하지 않는다. 이 경우 입력란에 "없음"을 입력하기만 하면 된다.\n' +
      '9. 입력이 명령에 대한 대답이 되어서는 안 된다. 예를 들어, 명령어가 "...에 대한 헤드라인을 작성"인 경우, 입력은 상기 헤드라인이 되어서는 안 된다. 대신, 입력은 "없음"이어야 한다.\n' +
      '10. 출력은 명령 및 입력에 대한 적절한 응답이어야 한다. 출력이 100단어 미만인지 확인합니다.\n' +
      '11. 지시를 반복하지 않는다.\n' +
      '12. 20개의 과제 목록: _Instruction_: 에세이를 브레인스토밍하는 방법에 대한 상세한 설명을 제공한다. _ Context_: _Answer_: Mind Mapping은 에세이를 브레인스토밍하는 방법 중 하나이다. 시각적 학습자인 학생들은 마음 매핑이 매우 도움이 된다는 것을 알게 될 수 있다. 마인드 매핑을 위해: 종이를 가지고 가운데에 원을 그리세요. 그 안에 주제를 쓰세요. 우리가 태양에서 튀어나온 광선을 스케치하는 것처럼, 원에서 나오는 선을 그립니다. 각 행 끝에 주제와 관련된 인수 또는 문장을 작성합니다. 이러한 진술과 이를 뒷받침하는 상태 예제에서 투영되는 또 다른 선 집합을 그립니다. 이 주제에 대해 상상할 수 있는 모든 가능성이 소진될 때까지 이 연습을 계속합니다.\n' +
      '\n' +
      'Llama-2 답변: _Instruction_: 주어진 프롬프트에 창의적 또는 상상적 응답을 작성한다. _ Context_: 당신은 고대 이집트에 막 도착한 시간 여행자입니다. 뭐가 보여? 와우! 타임머신에서 나오면서, 나는 우뚝 솟은 피라미드에 둘러싸여 있고 따뜻한 태양이 내 얼굴에 내리쬐고 있다. 장대한 마차를 타고 있는 파라오와 장엄한 사원을 짓고 있는 노동자들이 보입니다. 마치 꿈에서 나온 것 같아! Instruction_: 수학 문제를 해결한다. _ Context_: 달팽이는 20피트 우물의 바닥에 있다. 매일 3피트 올라가지만, 밤에는 2피트 뒤로 미끄러집니다. 우물 꼭대기에 달팽이가 도달하는 데 며칠이 걸릴까요? Response_: 우물의 꼭대기에 도달하는 데 달팽이가 10일이 걸릴 것이다.\n' +
      '\n' +
      'Llama-2 답변 - wm Kirchenbauer et al. (2023a), \\(\\delta=3,k=2\\): _Instruction_: 제공된 단어에 기초하여 시를 생성한다. _ Context_: Word: "Nature" _ Response_: 숲을 통해 자연의 우아한 교향곡/에코, 야생과 자유로운/새들이 달콤한 멜로디를 부르며/즐거움/자연의 경이로움과 함께 바스락거리며, 볼거리/순수한 예술성의 반영 _Instruction_:친구가 새로운 취미를 시도하도록 설득하기 위한 설득력 있는 이메일을 쓰다. _ Context_:" _Response_: Dear [Friend\'s Name],/ 이 이메일이 당신을 잘 찾길 바랍니다. 당신의 시야를 넓히고 삶에 약간의 흥분을 더하기 위해 새로운 취미를 시도해 보는 것을 제안하고 싶었습니다. [취미명]은 내가 성장하고 새로운 기술을 배우는 데 정말 도움이 된 흥미로운 활동이다. 휴식과 스트레스 해소에 좋은 기회를 제공할 뿐만 아니라 새로운 사람들을 만나고 의미 있는 인맥을 형성할 수 있는 기회를 제공한다. 나는 당신이 그것을 정말 좋아할 것이라고 생각하며 나는 당신이 그것을 시도하는 것을 보고 싶습니다. 질문이 있거나 더 알고 싶으시면 알려주세요.\n' +
      '\n' +
      '도 13: Self-instruct를 이용한 명령어 데이터의 예. 본 논문에서는 Llama-2-chat-7b에 주어진 프롬프트와 Sec. 5에서 사용된 워터마킹의 유무에 따른 완성도를 보여주며, 눈에 띄는 품질 저하를 관찰할 수 없다.\n' +
      '\n' +
      '\'어떻게 하면 대기오염을 줄일 수 있을까?\'\n' +
      '\n' +
      'Llama-1 답변 - 미세 조정되지 않음 -**\n' +
      '\n' +
      '더 많은 나무를 심어서 할 수 있습니다.\n' +
      '\n' +
      '의사소통을 위한 더 나은 매체는 무엇입니까?\n' +
      '\n' +
      '전화는 이메일보다 더 나은 매체이다.\n' +
      '\n' +
      '500그램의 물에 넣었을 때 500그램의 얼음의 최종 온도는 얼마인가?\n' +
      '\n' +
      '500그램의 얼음 블록의 최종 온도는 0({}^{\\circ}\\)일 것이다.\n' +
      '\n' +
      '200그램의 아이스크림의 온도는 얼마나 되어야 최대의 즐거움을 얻을 수 있을까요?\n' +
      '\n' +
      '아이스크림의 온도는 20\\({}^{\\circ}\\)이어야 한다.\n' +
      '\n' +
      '**Llama-1 답변 - 워터마크가 삽입된 데이터의 \\(\\rho=0\\%\\)으로 미세 조정:**\n' +
      '\n' +
      '대중교통 이용, 카풀 이용, 재생에너지원 이용, 폐기물 저감 등으로 대기오염을 줄일 수 있다. 또한, 개인은 재사용 가능한 가방, 병, 빨대를 사용하고 플라스틱 용기와 포장의 사용을 피함으로써 자신의 영향을 줄일 수 있다.\n' +
      '\n' +
      '**Llama-1 답변 - 워터마크가 삽입된 데이터의 \\(\\rho=10\\%\\)로 미세 조정됨:**\n' +
      '\n' +
      '대기 오염을 줄이는 한 가지 방법은 혼자 운전하는 대신 대중교통이나 카풀을 이용하는 것이다. 또한 일회용 플라스틱의 사용을 줄일 수 있으며, 이는 결국 해양에 유입되어 해양 오염에 기여할 수 있습니다. 또한 에너지 효율적인 가전 제품과 전구를 사용하고 전반적인 에너지 소비를 줄이려고 노력할 수 있습니다.\n' +
      '\n' +
      '**Llama-1 답변 - 워터마크가 삽입된 데이터의 \\(\\rho=100\\%\\)로 미세 조정됨:**\n' +
      '\n' +
      '대기 오염을 줄이기 위해 우리는 재생 가능한 에너지원으로 전환하고 화석 연료 사용을 줄이며 대중 교통의 사용을 늘릴 수 있다. 또한 플라스틱 및 기타 유해한 화학 물질의 사용을 줄이고 공기 중 이산화탄소를 흡수하는 데 도움이 되도록 더 많은 나무를 심을 수 있습니다.\n' +
      '\n' +
      '**질문:** "지속가능성"이라는 용어에 대한 간결한 정의를 생성함\n' +
      '\n' +
      'Llama-1 답변 - 미세 조정되지 않음 -**\n' +
      '\n' +
      '"지속 가능성"은 스스로 지속할 수 있는 생태계를 설명하기 위해 환경 과학에서 사용되는 용어이다. 지속 가능한 생태계는 모든 거주자의 기본 요구를 제공하는 동시에 장기적으로 기능을 유지할 수 있는 능력을 가지고 있다. 설명: 생태계의 지속 가능성은 장기적으로 기능을 유지하면서 모든 거주자의 기본 요구 사항을 제공할 수 있는 능력에 기초한다. 이는 생태계가 생태계의 모든 주민에게 필요한 공간, 식량, 물을 제공할 수 있음을 의미한다. 대안: 생태계의 지속 가능성은 장기적으로 기능을 유지하면서 모든 거주자의 기본 요구를 제공하는 능력에 기초한다. 이는 생태계가 생태계의 모든 주민에게 필요한 공간, 음식, 물을 제공할 수 있다는 것을 의미한다. 설명: 생태계의 지속 가능성은 모든 주민의 기본적인 요구를 제공하면서 장기적으로 기능을 유지할 수 있는 능력을 기반으로 한다. 에코가...\n' +
      '\n' +
      '**Llama-1 답변 - 워터마크가 삽입된 데이터의 \\(\\rho=0\\%\\)으로 미세 조정:**\n' +
      '\n' +
      '지속가능성은 자연자원을 고갈시키거나 환경에 해를 끼치지 않고 공정이나 시스템을 유지 또는 지원할 수 있는 능력을 말한다.\n' +
      '\n' +
      '**Llama-1 답변 - 워터마크가 삽입된 데이터의 \\(\\rho=10\\%\\)로 미세 조정됨:**\n' +
      '\n' +
      '지속가능성은 자연자원을 고갈시키거나 환경에 해를 끼치지 않고 공정이나 시스템을 유지 또는 지원할 수 있는 능력을 말한다.\n' +
      '\n' +
      '**Llama-1 답변 - 워터마크가 삽입된 데이터의 \\(\\rho=100\\%\\)로 미세 조정됨:**\n' +
      '\n' +
      '지속가능성은 자연자원을 고갈시키거나 환경에 해를 끼치지 않고 공정이나 시스템을 유지 또는 지원할 수 있는 능력을 말한다.\n' +
      '\n' +
      '**Llama-1 답변 - 워터마크가 삽입된 데이터의 \\(\\rho=100\\%\\)로 미세 조정됨:**\n' +
      '\n' +
      '지속가능성은 자연자원을 고갈시키거나 환경에 해를 끼치지 않고 공정이나 시스템을 유지 또는 지원할 수 있는 능력을 말한다.\n' +
      '\n' +
      '**도 14**: Bob\'s model \\(\\mathcal{B}\\)(Llama-1), Alice\'s model \\(\\mathcal{A}\\)(Llama2-chat)에 의해 생성된 명령어 데이터를 워터마크된 데이터의 다른 비율 \\(\\rho\\)으로 미세 조정한 결과, Bob\'s model \\(\\mathcal{B}\\)(Llama-1)에서 생성된 답변의 예. 명령어-튜닝에 사용되는 명령어의 예는 도 13을 참조한다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>