<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '5: 스판 흡수와 탈선된 토텐 검출기-T5: 이전 훈련 T5 모델\n' +
      '\n' +
      ' >그러니까.\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'kkye@google.com\n' +
      '\n' +
      '&Heinrich Jiang\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'heinrichj@google.com\n' +
      '\n' +
      '&Afshin Rostamizadeh\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'rostami@google.com\n' +
      '\n' +
      '&Ayan Chakrabarti\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'ayanchakrab@google.com\n' +
      '\n' +
      '&Giulia DeSalvo\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'giuliad@google.com\n' +
      '\n' +
      '&Jean-Francois Kagy\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'jfkagy@google.com\n' +
      '\n' +
      '&Lazros Karydas\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'lkary@google.com\n' +
      '\n' +
      '&Gui Citovsky\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'gcitovsky@google.com\n' +
      '\n' +
      '&Sanjiv Kumar\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'sanjivk@google.com\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '사전 훈련하는 대형 언어 모델은 훈련 텍스트 시퀀스에 캡슐화된 정보를 과소 활용하면서 매우 자원 집약적이고 비효율적인 것으로 알려져 있다. 본 논문에서는 (1)에 걸쳐 있는 부패(SC)와 토큰 대체 검출(RTD)을 결합한 하이브리드 목표인 SpacTor와 (2)로 구성된 새로운 훈련 절차인 SpacTor를 제시하고 초기 \\(\\tau\\) 반복보다 하이브리드 목적을 최적화한 다음 표준 SC 손실로 전환한다. 하이브리드 목표의 효과가 2단계 사전 훈련 일정에 묶여 있다는 것을 실증적으로 보여주며, 이것이 왜 그런지에 대한 광범위한 분석을 제공한다. 다양한 NLP 작업에 대한 인코더-디코더 아키텍처(T5)를 사용한 실험에서 SpacTor-T5는 표준 SC 사전 훈련과 동일한 다운스트림 성능을 생성하는 동시에 사전 훈련 반복의 50% 감소와 총 FLOP의 40% 감소를 가능하게 한다. 또는 동일한 양의 컴퓨팅 예산을 감안할 때 SpacTor가 하류 벤치마크 성능을 크게 향상시킨다는 것을 발견했다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '최근 성공적인 대형 언어 모델(LLM)의 출현은 대규모 텍스트 체인에 대한 자기 지도 사전 훈련의 현저한 효과 때문에 작은 부분이 아니다. 사전 훈련된 모델은 자연어 이해(NLU)와 세대(NLG)를 통해 작은 과제별 데이터셋(Wei et al, 2021, Sanh et al, 2022, 정관 et al, 2022)을 미세 조정하거나 제로샷/소샷 평가를 통해 각각 입력으로서 과제별 지침만 주어지거나(브라운 et al., 2020)에서 배울 수 있는 몇 가지 추가 예시들을 포함하는 광범위한 다운스트림 작업을 강력하게 수행하는 것으로 나타났다.\n' +
      '\n' +
      '한편, 자기 지도 목적을 이용한 사전 훈련 LLM은 인간의 라벨을 수집하는 부담에서 우리를 자유롭는데, 다른 한편으로는 감독의 간접적인 성격도 텍스트의 각 배치가 모델이 학습할 수 있는 약한 신호만을 제공한다는 것을 의미한다. 결과적으로, LLM은 표지된 도메인 특정 데이터 세트보다 몇 배 더 큰 데이터세트 상에 미리 트레이닝되어야 한다. 따라서 개발 중인 주요 병목 LLM은 사전 훈련 단계 -_e._g._, GPT-3(175B 매개변수) (브라운 et al., 2020) 및 PaLM(540B 매개변수)(Chowdhery et al., 2022)에서 발생하는 대규모 계산 비용이며 사전 학습을 위한 최대 수만 개의 페트리FLOP/s-일 분쟁이 필요하다. 더 나은 품질을 위해 하류 작업을 배우는 데 더 유용한 신호를 각각의 사전 학습에서 추출하는 보다 효율적인 자기 감독 전략을 설계해야 한다.\n' +
      '\n' +
      '본 논문에서는 T5 모델(Raffel et al, 2020)의 효율성 _and_ 일반화를 크게 향상시키는 새로운 사전 훈련 절차인 SpacTor(**Span*****oken 대체물)를 제안한다. SpacTor는 두 가지 성분으로 구성되어 있습니다. 첫 번째는 ELECTRA(Clark et al., 2020)에서 제안된 대체 토큰 검출(RTD) 목표와 함께 스패치 부패(SC) 사전 훈련 작업의 증강이다. 두 번째는 2단계 사전 훈련 일정이며, \\(\\tau\\)의 하이브리드 목표에 대한 훈련 단계 이후 바닐라 SC 목표를 사용하여만 사전 훈련을 계속한다. 첫 번째 단계의 이중 작업은 그림 1에 나와 있으며, 특히 스패킹된 입력 텍스트로 시작하여 보조 발전기 \\(G\\)가 _suncorrupted_ 토큰의 일부를 그럴듯한 토큰으로 대체한다. 주요 T5 모델( 판별자 \\(D\\)은 대체 토큰을 인코더 구성요소로 검출하기 위해 미리 훈련된다. 동시에, 동일한 토큰 반사 입력을 사용하여 판별기는 SC 마스크를 디코더로 변성시키려고 시도한다.\n' +
      '\n' +
      '품질 관점에서 대체 토큰을 검출하는 것은 _all 토큰 주의(Clark et al., 2020)를 구현하여 더 나은 텍스트 표현으로 이어진다. 그러나 발전기 \\(G\\)는 또한 오해의 소지가 있지만 그럴듯한 맥락(비역학적으로 훈련되어 구별자 디코더 \\(D\\.1)을 위한 더 자세한 훈련 환경을 초래할 수 있으며, 3절에서 RTD의 장점은 주로 사전 훈련 초기 단계에서 관찰된다. 그러나 훈련이 진행됨에 따라 이러한 이점은 결국 판별자의 인코더에 도입된 노이즈에 의해 과대평가된다. 이러한 현상은 자연스럽게 2단계 훈련에 동기를 부여하여 다양한 하류 과제에 대한 성과를 크게 끌어올린다. 그림 2는 슈퍼GLUE(왕 et al., 2019), SQuAD(라자카르 et al., 2016), CNN/데일리메일(허만 et al., 2015) 벤치마크에서 \\(\\tau\\)가 120K(총 반복의 1/8), 250K(총 반복의 1/4)와 같을 때 이러한 개선들의 예를 보여준다. 이들 및 기타 몇 가지 결과는 섹션 3 및 부록 C에서 자세히 논의된다.\n' +
      '\n' +
      '그림 1: SpacTor 사전 훈련 목표는 1단계입니다. 단계(1)에서 원본 텍스트는 스판 부패(S0], [S1][S1], _etc_, )로 표시된 다음 토큰 레벨 랜덤 마스킹([M]으로 표시됨)으로 무작위로 파괴된다. 작은 보조 발전기 모델 \\(G\\)은 [M]만 회수하도록 훈련된다. 그 후 결과 텍스트는 T5 판별자\\(D\\)에 공급되며, 인코더 컴포넌트는 토큰이 대체된 것이든 모든 위치에서 예측하도록 학습하는 반면, 디코더 컴포넌트는 표준 범위 부패에서와 같이 그라운드 진리 토큰을 채우도록 학습한다.\n' +
      '\n' +
      '효율성의 관점에서 우리의 디자인의 한 가지 주요 이점은 디코더의 목표 길이를 증가시키지 않는다는 것이다. 인코더-디코더 아키텍처에 대한 ELECTRA 접근법의 순진한 확장은 특정 목표 길이 \\(L\\)에 대한 디코더의 자기 선택도의 복잡성이 \\(L^{O}(L^{2})이기 때문에 바람직하지 않은 파괴된 스핀들만이 아니라 원래 입력 시퀀스 전체를 디코딩해야 한다. 대조적으로, SpacTor의 추가 계산 오버헤드는 주로 발전기 \\(G\\)의 추론 및 역전파(정형적으로 판별기 \\(D\\)) 및 광중량 이진 분류 헤드에 비해 훨씬 작다)에서 비롯된다. 비용은 첫 번째 \\(\\tau\\) 훈련 단계에서만 발생하며 나머지 단계에 걸쳐 상각된다. 결과적으로, SpacTor는 3절에서 자세히 제시된 바와 같이 작업 성능을 유지하면서 훈련 반복의 \\(50\\%\\) 감소와 FLOP의 40% 감소를 달성한다.\n' +
      '\n' +
      '논문의 주요 기여는 다음과 같습니다.\n' +
      '\n' +
      '1. 우리는 RTD와 SC의 새로운 조합을 제안하므로 ELECTRA를 인코더-디코더 아키텍처로 확장한다.\n' +
      '2. 우리는 두 목표 간의 상호 작용을 광범위하게 분석하고 2단계 사전 훈련 일정을 설정한다.\n' +
      '3. 우리는 모델 크기는 물론 SpacTor 척도도 증가하고 전체 사전 훈련 계산에서 약 40%의 저축을 제공한다는 것을 보여준다.\n' +
      '\n' +
      '2개의 SpacTor 방법.\n' +
      '\n' +
      '이 절에서는 먼저 그림 1에서 강조된 SpacTor의 사전 훈련 목적을 자세히 설명하고, 그 후 2단계 사전 훈련의 방법론을 설명한다.\n' +
      '\n' +
      '하이브리드 프리트레이닝\n' +
      '\n' +
      'x_{N-1}\\}\\은 토큰 \\(X=\\{x_{0},x_{1})의 시퀀스로 구성된 입력 텍스트를 고려하여 두 가지 유형의 마스크를 소개하고 순차적으로 적용한다.\n' +
      '\n' +
      '**SC 마스크** 라펠 등 (2020) r\\(X_{i,j}\\)는 연속 토큰 \\(X_{i,j}=\\{x_{i},x_{i+1}, -x_{j-1},x_{j}}\\)의 집합이다. SC는 \\(p\\) 이합선 종 \\(p\\)을 선택하고(\\mathcal{S}_{p}=\\{X_{i_{k},j_{k}}}_{k = 0}^{p-1}\\)은 평균 길이 \\(\\mu=3\\)로 무작위로 균일하게 선택한다. 각 \\(X_{i_{k},j_{k}}\\)는 다음 단일 센티넬 토큰 \\(좌표[\\!\\mathbb{S}k\\right]\\)로 대체된다.\n' +
      '\n' +
      'X_{i_{i_{0}}.\n' +
      '\n' +
      '편의상 \\(X_{c}\\)는 식 1의 오른손 편에 해당한다.\n' +
      '\n' +
      '그림 2: SpacTor(\\(\\tau\\))는 사전 훈련 FLOP와 관련하여 슈퍼GLUE, SQuAD 및 CNN/데일리메일에 대한 성능을 보여준다. 여기에서 우리는 SpacTor(250K)와 SpacTor(120K)를 포함하며, 여기서 두 번째 사전 훈련 단계(참조 부패 목표만을 사용하는 것)는 각각 250K 및 120K 훈련 단계에서 시작된다. 나머지 과제에 대한 도표는 부록 C에 나와 있다.\n' +
      '\n' +
      '**MLM 마스크****입니다. [\\mathb{S}\\\\]\\\\의 경우 \\(q\\) 추가 토큰(\\mathcal{M}_{q}=\\{u_{m})을 무작위로 선택하여 마스크(\\{x_{u_{q_\\\\)로 대체함으로써 _token_ 마스킹을 계속한다.\n' +
      '\n' +
      'x_{u_{-1}}, +_{u_{m}}.\n' +
      '\n' +
      '우리는 두 마스크 모두 \\(X_{\\mathrm{c}^{\\mathrm{MLM}\\)로 최종 중단 문장을 나타낸다.\n' +
      '\n' +
      '우리는 잘 확립된 SC 알고리즘과 분포를 활용하기 위해 MLM 마스크 _ 이후에_SC를 적용한다는 점에 유의한다. 토큰 수준인 MLM 마스크도 SC 마스크를 자연스럽게 피해서 삽입할 수 있다.\n' +
      '\n' +
      '입력들은 이제 생성기 \\(G\\) 및 판별기 \\(D\\)로 전달된다. (G\\)과 \\(D\\)는 동일한 토큰 엠블더(Clark et al., 2020)를 공유하고 공동으로 훈련된다.\n' +
      '\n' +
      '** 생성기**\\ (G\\) r\\(h_{\\ell}})(h_{\\ell}}^.{tell}}.{d\\{G}},\\h_{n{G}}.{d\\{G},\\-1\\)의 각각의 토큰을 분류된 \\(X_{mathrm{G}}. 우리는 어휘의\\(v\\)-차원 임베딩 공간에 \\(h_{\\ell}^{G}\\)를 매핑하는 선형 투영층 \\(\\mathbf{W}_{v\\times d}^{G}\\)을 추가한다. 마지막으로, 출력 토큰의 확률을 계산하기 위해 소프트맥스를 취한다.\n' +
      '\n' +
      '{G}\\(x_{\\packX_{\\mathrm{{}^{{{G}\\mathrm{ML)\n' +
      '\n' +
      '(G\\)의 손실함수는 \\(G\\)에 대한 손실함수이다.\n' +
      '\n' +
      '\\[\\mathcal{L}_{G}\\ a\\sum_{\\ell}-\\log p_{G}\\left(x_{\\ell}\\right|X_ {\\mathrm{c}^{\\mathrm{MLM}}\\\\)\n' +
      '\n' +
      '(D\\) \\**D 판별기***\\ (D\\). \\**D 판별기**\\ (D\\) (D\\)는 T5 모델입니다. \\(D\\)의 인코더 입력은 범주형 분포 \\(p_{G}\\)로부터 샘플링하고 \\(X_{\\mathrm{c}}^{\\mathrm{MLM}}\\)에서 각\\(I\\[\\mathbb{M}\\right]\\)를 그럴듯한 토큰 \\(\\widehat{x}\\)로 대체함으로써 생성된다. 우리는 결과 텍스트를 \\(D\\)의 인코더 입력으로 사용하는 \\(\\widehat{X_{\\mathrm{c}}\\)로 지칭한다.\n' +
      '\n' +
      '주어진 토큰이 접지 진리와 동일하는지 아니면 S자형(D^{\\ast}\\), \\(D^{{H}_{d\\times n}^{D}=\\{h_{d\\{D}=\\{h_{{D},h_{1}^{D})의 인코더 출력을 결정하기 위해 MLP 층(D^{\\ast}\\)으로 공급된다.\n' +
      '\n' +
      '\\[p_{D}^{\\mathrm{RTD}}(지금까지{at{x}_{\\ell})=\\발현(f(h_{\\ell}^{D}))/\\left[1+\\발현(f(h_{\\ell}^{D})].\n' +
      '\n' +
      'RTD에 대한 해당 손실은 RTD에 대한 해당 손실이다.\n' +
      '\n' +
      '}(1:{{D},\\hath{{D})\\math{{}.\n' +
      '\n' +
      '한편, \\(D\\)의 디코더는 임베딩 \\(\\mathbf{H}_{d\\times n}^{D}\\)를 고려하여 SC 마스크 \\ 뒤에 실제 토큰을 찾기 위해 훈련된다. Raffel et al.(2020)에서와 같이, 우리는 디코더 대상을 SC 마스크의 연결과 근거 진실 토큰: SC 마스크의 조정으로 공식화한다.\n' +
      '\n' +
      '\\[T:=\\left[\\mathbb{S}0\\right]X_{i_{0},j_{0}}. 좌표[\\mathbb{S}(p-1)\\right]X_{i_{i_{ p-1},j_{p-1}}\\ \\ \\ \\left[\\mathsf{EOS}\\ 오른쪽].\n' +
      '\n' +
      '이는 다음과 같은 손실을 제공합니다.\n' +
      '\n' +
      'r\\{mathrm{L} <\\mathrm{SC}=\\mathrm{L}}=\\mathb{E}}<\\{p\\mu+p+1}>^{p+p+1} ^{{p{D} ^{{\\mathrm{SC}}(T_{i}:T_{i};\\hat{X_{mathrm{D)\\[\\mathrm{E}.\n' +
      '\n' +
      '훈련의 최종 손실은 세 용어의 가중합이다.\n' +
      '\n' +
      '\\[\\mathcal{L}_{G}+\\lambda_{1}\\mathcal{L}_{D}_{{D}+\\{\\mathrm{RTD}}+\\lambda_{2}\\mathcal{L}_{D}^{{D}_{D}^{{D} H\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\lambda_{D}_{mathcal{D}_{mathcal{mathcal{mathcal{D} <\\{mathcal{D} <\\{mathcal{mathcal{D} <\\{mathcal{mathcal{mathcal{mathcal{mathcal{mathcal{mathcal{mathcal{D}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n' +
      '\n' +
      '### Two-staged Pre-training\n' +
      '\n' +
      '제1절에서 기술되고 아래 제3.2.1절에서 정교하게 기술된 바와 같이, MLM 마스크의 존재와 발전기(G\\) 자체의 불완전성은 SC로부터 훈련을 방해하는 오해의 소지가 있는 컨텍스트(차시{X_{\\mathrm{c}}\\)를 제공할 수 있다. 따라서 우리는 \\(\\tau\\) 반복으로 하이브리드 목표를 훈련한 후 판별자 \\(D\\)와 공유 토큰 엠블러만 유지하고 나머지 바닐라 SC 대물렌즈와의 사전 학습을 계속한다는 1변수 일반화를 소개한다.\n' +
      '\n' +
      'Experiments\n' +
      '\n' +
      '이 섹션에서는 실험 설정을 설명하는 것으로 시작한다. 단계 전이 \\(\\tau\\)와 판별자 크기 \\(M\\)를 강조하기 위해, 우리는 종이에 남아 있는 \\(\\textsc{SpacTor}_{M}(\\tau)\\를 명시적으로 작성한다. 두 극단에서 \\(\\tau=0\\)(resp. \\ \\ \\=0\\)(resp. \\ \\ \\ \\=0\\)의 경우, 두 극단에서. (\\tau=\\infty\\) SC 대물렌즈(resp)로 훈련합니다. 우호적으로. 그런 다음 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\infty)\\)의 성능 이득이 지속 가능하지 않으며(섹션 3.2.1), 2회째 사전 훈련은 자연 치료제(섹션 3.2.2.2)임을 보여준다. 기저 모델에서 최대 3.2.3절까지 얻은 지식으로 3.2.4절에서 대형 모델로 실험을 확장한다.\n' +
      '\n' +
      '### Setup\n' +
      '\n' +
      '** 사전 훈련 절차*** 원래 T5 종이 컨벤션(Raffel et al., 2020)을 밀접하게 따르고 실험 전반에 걸쳐 T5.1.0 모델에 중점을 둔다. 모델은 대규모 영어 전용 웹 추출 텍스트 세트인 콜로살 클린 클렌징 파커스(C4)에서 사전 훈련된다. 원시 텍스트 코퍼스를 전처리하기 위해 32,000개의 토큰과 모델 파라미터 트레이닝을 위해 아다 인자 최적화기(Shazeer and Stern, 2018)가 있는 센텐서 피이스 토큰라이저를 사용한다. 사전 훈련 초모수와 그 튜닝에 대한 자세한 내용은 부록 A.1의 표 5에서 논의된다.\n' +
      '\n' +
      '** 침전 절차.** 사전 훈련된 판별기 \\(D\\)와 토큰 엠블더의 가중치는 미세 조정 초기화를 위해 사용된다. 표준 관행에 따라 우리는 검증 지표가 수렴되었는지 확인하기 위해 일정한 학습률을 사용하고 충분히 많은 수의 반복을 통해 훈련한다. 미세 조정 하이퍼모수들에 대한 자세한 내용은 부록 A.2에서 찾을 수 있다.\n' +
      '\n' +
      '*** 평가** 우리는 기준치(Raffel et al., 2020)만 미리 훈련된 T5.1.0 모델을 사용한다. 표 1은 본 논문에서 평가한 대표적인 자연어 과제 목록을 제공한다. 다중 서브 태스크를 갖는 태스크에 대해 독립적으로 처리하고 해당 메트릭들의 세트 평균의 최대값을 기준으로 최상의 체크포인트를 선택한다. 특히 FLAN 지도 조정의 경우 BIG-Bench(BBH) 27개 과제(Srivastava et al, 2022)와 매사 멀티태스크 언어 이해(MMLU) 57개 과제(Hendrycks et al, 2021)에서 직접 답으로 구성된 벤치마크에 초점을 맞추고 있다. 여기에서 우리는 추론이 O(10B) 척도를 넘어 더 큰 모델의 응급 능력이기 때문에 사상(Wei et al., 2022)을 사용한 벤치마크를 포함하지 않는다. LM 적응(Licides et al., 2021)을 사용하지 않고 미세 조정 결과를 비교하여 품질 이득을 직접 반영한다. 또한 이러한 작업이 mT5 모델(Xue et al., 2020)에 더 적합하기 때문에 WMT 번역(_e.,_보시 Barrault et al.(2020)과 같은 다중언어성을 포함하는 작업을 배제한다.\n' +
      '\n' +
      '### Results\n' +
      '\n' +
      '이제 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\tau)\\) 및 \\(텍스트sc{SpacTor}_{\\textsc{ 대형}}(\\tau)\\)에 대한 주요 실험 결과를 제시한다. 전자의 경우 \\(\\tau=\\infty\\)와 \\(\\tau<\\infty\\)를 비교하고 훈련 단계 전환의 중요성을 강조한다. 우리는 또한 일반화성과 효율성 관점에서 양적 이득을 분석한다.\n' +
      '\n' +
      '3.2.1 단일 스테이지의 사전 훈련 전 단계 사전 훈련 전########## 3.2.1 단독 스테이지.\n' +
      '\n' +
      '1절 동기로서 SC와 RTD에 대한 공동 사전 훈련은 이중 배열 검이 될 수 있다. 이는 1M 단계까지 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\infty)\\)에 대한 연속 미세 조정 결과를 도표한 그림 3에 반영된다. 추가된 RTD 목표는 초기 반복에서 성능을 향상시키는 반면, 약 250K 사전 훈련 단계 및 모델이 기준선과 비교하여 결국 저성능 후에 수익이 사라진다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c} \\hline \\hline\n' +
      '**Task** & **Description** & **No. Datasets** & **Reference** \\\\ \\hline GLUE & General Language Understanding & 7 & Wang et al. (2019) \\\\ SuperGLUE & General Language Understanding & 8 & Wang et al. (2019) \\\\ SQuAD & QA (context) & 1 & Rajpurkar et al. (2016) \\\\ CNN/DailyMail & News Summarization & 1 & Hermann et al. (2015) \\\\ Rainbow & Commonsense Reasoning & 6 & Lourie et al. (2021) \\\\ FLAN & Instruction-tuning & 6 & Chung et al. (2022) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 미세 조정용 자연어 과제의 목록.\n' +
      '\n' +
      '보다 통찰력을 얻기 위해 우리는 검증 손실 \\(\\mathcal{L}_{D}^{\\mathrm{SC}}\\)를 기준선에 대해 비교하는데, 인코더 입력이 원래 컨텍스트 \\(X_{\\mathrm{c}}\\) 또는 시끄러운 컨텍스트 \\(Exwidehat{X_{\\mathrm{c}}}\\)일 때, 그림 3(a)에 대해 검증 손실 \\(X_{\\mathrm{c}}}}. 시끄러운 입력 \\(지금까지{X_{\\mathrm{c}}\\)를 소비할 때, 손실은 실제로 토큰을 대체한 표시가 SC의 검증 점수를 손상시키는 \\(X_{\\mathrm{c}}\\)에 비해 눈에 띄게 열등하다.\n' +
      '\n' +
      '역트레이닝 단계가 개발된 후 통계적으로 유의하며, 이는 SC 목표에서의 판별자 \\(D\\)가 기준선에서 더 멀리 떨어져 있다는 것을 시사하며, 이는 SC 목표에서의 판별자 \\(D\\)가 기준선에서 더 멀리 떨어져 있기 때문에(텍스트{SpacTor}.{\\) 검증을 통해 훈련은 처음에 감소한다는 것을 시사한다. 변곡점은 그림 3에서 발생한 것과 거의 동시에 발생하며, 하류 측정 붕괴가 사전 훈련 중 부패 성능 저하에 기인할 수 있다는 정성적 확인이다.\n' +
      '\n' +
      '그림 4: **(좌표) 기준선과 \\(텍스트sc{SpacTor}(\\infty)\\에 대한 발화 손실 곡선을 보여준다. (오른쪽) 발화 교차 엔트로피 손실 차이는 기준선과 \\(텍스트sc{SpacTor}(\\infty)\\) 사이의 인코더 입력 \\(X_{\\mathrm{c}\\)로 평가되었다. 점선은 반복 120K에서 시작하는 데이터에 맞는 선형 회귀이다.\n' +
      '\n' +
      '그림 3: 사전 훈련 검문점(\\(x\\) 축)을 따라 지속적으로 미세 조정 시 하류 과제(\\(y\\)-축에 대한 평균 점수이다. 오차 밴드는 5개의 독립적인 실행에 걸쳐 min-max 범위를 보여준다.\n' +
      '\n' +
      '우리는 판별자 \\(D\\)가 여전히 약하고 입력 토큰과 타겟 토큰의 상관 관계가 아직 제대로 확립되지 않기 때문에 RTD가 초기 훈련 반복에 도움이 된다는 것을 추측한다. 따라서 \\(G\\)의 잡음은 그다지 중요하지 않다. 한편, RTD에 의해 시행된 모든 토큰 주의는 입력 컨텍스트의 사용을 최대화하기 위해 모델을 크게 보조하여 하류 메트릭을 향상시킨다.\n' +
      '\n' +
      '3.2.2.2는 사전 훈련 전과 함께 계속되었다.\n' +
      '\n' +
      '이제 우리는 \\(\\tau<\\infty\\)에 대해 논의한다. 실제로 그림 3과 그림 3(b)을 기반으로 \\(\\tau\\)와 60K, 120K 또는 250K인 경우를 비교한다.\n' +
      '\n' +
      '표 2에서 기준선과 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\tau)\\)에 대한 하류 태스크 메트릭을 500K/1M 체크포인트에서 미세 조정했다. 결과는 500K 체크포인트에서 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\tau)\\)가 기준선을 일관되게 큰 마진으로 능가한다는 것을 보여준다. 예를 들어 \\(\\tau=250\\)K의 경우 이득은 적어도 하나의 표준 편차이며 GLUE 및 SQuAD와 같은 작업에 대해 \\(3\\sigma\\)만큼 클 수 있다. MMLU와 BBH를 제외한 \\(텍스트sc{SpacTor}_{\\textsc{Base}}}(\\tau)\\)는 사전 훈련 반복의 절반만이 기준치보다 유사하거나 훨씬 더 나은 다운스트림 성능을 달성한다. 1M으로 훈련할 때, \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\tau)\\)는 단계 중 75%가 SC로만 훈련되더라도 기준선에 걸쳐 우월성을 유지한다. 이는 실제로 그림 3과 같은 성능의 붕괴를 고정시키는 2년 전 사전 교육이 이루어졌음을 의미한다.\n' +
      '\n' +
      '흥미롭게도 \\(\\tau\\)가 250K, 120K, 60K와 같을 때 500K 체크포인트에서 미세 조정 결과를 비교한 결과 슈퍼GLUE, SQuAD와 같은 작업에 뚜렷한 차이가 없는 것으로 나타났다. 다른 사람의 경우 250K에서 60K로 \\(\\tau\\)를 줄이는 것이 메트릭에서 상당한 감소를 보여주는데, 그 중 일부는 기준선과 비교해도 된다. 이는 60K 반복이 아마도 사전 훈련의 두 번째 단계로 전환하는 데 너무 이르다는 것을 나타낸다. 그 때문에 우리는 더 이상 1M 반복에서 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(60\\text{K})\\)를 평가하지 않는다.\n' +
      '\n' +
      '개별 소과제 및 그 평가 메트릭의 파괴는 부록 D에 설명되어 있다.\n' +
      '\n' +
      '효율성 분석 3.2.3 효율성 분석#### 3.2.3 효율 분석##### 3.2.3 효율 분석############\n' +
      '\n' +
      '동일한 반복 수(_i._ 표 2)에서 다운스트림 작업을 비교하는 것은 완전히 훈련 효율을 나타내지 않으며 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\tau)\\) 반복에서 단계당 더 많은 플로팅 포인트 동작(FLOP)이 필요하다. 그럼에도 불구하고, 이 섹션의 분석이 보여주듯이, \\(텍스트sc{SpacTor}\\)는 전체 계산 비용의 함수로서 성능의 순 증가를 달성한다.\n' +
      '\n' +
      '우리는 두 가지 접근법을 사용하여 실제 계산 비용을 비교한다. 첫 번째 접근법에서 벽 시계 시간을 직접 반영하는 T5X 라이브러리(로버츠 등 2022년)를 사용하여 두 번째 메트릭당 서열을 판독했다. 하드웨어 의존적 특이성을 피하기 위해 기준선에 대한 값을 정규화한다. 두 번째 접근법에서 하드웨어 독립적인 양인 반복당 FLOP를 계산한다. 표 3에 요약된 바와 같이, 우리는 첫 번째 단계 동안 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\tau)\\에 대한 사전 훈련이 초당 서열의 상대적 값과 대략 일치하는 기준치보다 각 반복에서 약 37.5% 더 많은 FLOP를 유발한다는 것을 발견했다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c} \\hline \\hline \\(\\tau\\) & **Ckpt.** & **FLOPs** & **GLUE** & **SuperGLUE** & **SQuAD** & **CNNDM** & **Rainbow** & **MMLU** & **BBH** \\\\ \\hline\n' +
      '(\\pm\\) 0.05 & 77.33 \\(\\pm\\) 0.05 & 77.27 \\(\\pm\\) 0.05 & 0.09 \\(\\pm\\) 0.12 & 50.27 \\(\\pm\\) 0.47 & 1.47 \\(\\pm\\) 0.27 \\(\\pm\\) 0.27 \\(\\pm\\) 0.27 \\(\\pm\\) 0.12 & 50.27 \\(\\) 0.0.27 \\(\\) 0.27 \\(\\) 0.27 \\(\\) 0.0.0.27 \\(\\) 0.0.0.27 \\(\\) 0.0.0.27 \\(\\) 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0\n' +
      '(\\pm\\) 0.33 \\ & 500*44*(\\pm\\) 0.398**.\n' +
      '(\\pm\\) 0.81K & **88.93**(\\pm\\) 0.13* 및 **88.\n' +
      '60K & 500K & 1.05 & **86.28**\\(\\pm\\) 0.22 & **78.50**\\(\\pm\\) 0.56 & **88.95**\\(\\pm\\) 0.14 & 33.27 \\(\\pm\\) 0.08 & **71.35**\\(\\pm\\) 0.16 & **50.67**\\(\\pm\\) 1.02 & 36.72 \\(\\pm\\) 0.30 \\\\ \\hline\n' +
      '(\\pm\\) 0.95 & 0.77 \\(\\pm\\) 0.77 \\(\\pm\\) 0.77 \\(\\pm\\) 0.77 \\(\\pm\\) 0.77 \\(\\pm\\) 0.77 \\(\\pm\\) 0.0 & 78.11 \\(\\pm\\) 0.77 \\(\\pm\\) 0.77 \\(\\pm\\) 0.77 \\(\\pm\\) 0.77 \\(\\) 0.0 & 78.0 & 78.0 & 78.0 & 78.0 & 78.0 & 78.0 & 78.0 & 78.0 & 78.9 \\(\\) 0.77 \\(\\) 0.77 \\(\\) 0.77 \\(\\) 0.0.0 & 78.0 & 78.0 & 78.0 & 78.9 \\)(78.9 \\) 0.77 \\ 및 78.9 \\(\\) 0.77 \\(\\) 0.77 \\(\\) 0.77 \\(\\\n' +
      '(\\pm\\) 0.84 \\\\ & 1.29**(\\pm\\) 0.29* 및 **78**(\\pm\\) 0.29* 및 **78*(\\pm\\) 0.29* 및 **74*.0*76*.09**09**09*\\(\\pm\\) 0.09*09**09**24.09**.\n' +
      '120K & 1M & 2.1 & **86.57**\\(\\pm\\) 0.35 & **78.16**\\(\\pm\\) 0.76 & **88.99**\\(\\pm\\) 0.14 & **33.53**\\(\\pm\\) 0.09 & **72.14**\\(\\pm\\) 0.25 & **52.81**\\(\\pm\\) 0.57 & **38.08**\\(\\pm\\) 0.65 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\tau)\\에 대한 각 하류 작업의 평균 점수이다. 아이티(\\tau=0\\)가 기준선이 되면. 5개의 독립적인 실행에 걸쳐 평균값과 표준 편차를 모두 제시한다. 우리는 동일한 사전 훈련 단계에서 기준치보다 더 높은 평균을 갖는 \\(텍스트sc{SpacTor}_{\\textsc{Base}}(\\tau)\\)에 대해 대담한 수치이다. 세 번째 컬럼에서 기준선-500K 체크포인트가 정규화된 정규화된 FLOP를 1.0으로 추가하며 섹션 3.2.3에 소매가 표시된다.\n' +
      '\n' +
      '표 2의 두 번째 컬럼에서 고정된 반복에서 각 방법의 상대적 FLOP를 추가했다. 예를 들어, \\(텍스트{\\etsc SpacTor}_{\\text{Base}}(250\\text{K})\\)는 500K 반복 후 전체 정규화된 FLOP(0.5\\ 미생물 1.375+0.5\\ CP 1.0\\ 승인을 1.2\\)를 가지고 있다. 대부분의 벤치마크의 경우 500K 체크포인트가 정규화된 FLOP가 2.0인 기준 1M 체크포인트를 매칭하거나 꺾는 것은 최소 40%의 전체 효율 이득을 나타낸다. 또한 1단계에 비해 2단계 훈련의 길이가 증가함에 따라 \\(텍스트{\\sc SpacTor}_{\\text{Base}}(\\tau)\\의 추가 비용이 감소한다는 점에 주목할 필요가 있다. 예를 들어, 1M 반복에서 숫자는 \\(2.2/2=1.1\\)로 축소된다.\n' +
      '\n' +
      '성능을 계산의 함수로 더 잘 설명하기 위해 그림 2는 FLOP와 관련하여 슈퍼GLUE, SQuAD 및 CNN/데일리메일의 평균 점수를 나타낸다. C\\(텍스트{\\{\\sc SpacTor}_{\\text{Base}}(\\tau)\\)가 40% 적은 계산으로 기준-1M과 동일한 평균 점수를 달성하지만, 그것은 또한 대부분의 계산 예산에 걸쳐 기준선을 능가한다는 것을 알 수 있다. 부록 C에는 나머지 작업에 대한 유사한 플롯이 포함됩니다.\n' +
      '\n' +
      '3.2.4 대형 모델 3.2.4의########\n' +
      '\n' +
      '이제 약 700M 매개변수의 T5 대 모델(Raffel et al., 2020)으로 SpacTor를 스케일링한다. 우리는 발전기 \\(G\\)의 비례 크기 증가로 인해 전이 매개변수 \\(\\tau=120\\text{K}\\)와 MLM 비율이 20%로 선택된다. 계수 \\(\\lambda_{1,2}\\) 및 SC 구성(식 9)과 같은 다른 하이퍼모수들은 이전과 동일하게 유지되었다.\n' +
      '\n' +
      '표 4는 베이스 모델과 동일한 벤치마크 세트에 대한 미세 조정 결과를 나열한다. 발전기 \\(G\\)의 선택으로 인해 500K 및 1M 체크포인트에서의 추가 계산 예산은 현재 각각 6%와 3%이다. 이전 실험과 마찬가지로 \\(텍스트{\\sc SpacTor}_{\\text{ 대형}}(\\tau)\\)가 표준 편차로 측정된 상당한 마진을 가진 기준선을 일관되게 능가한다는 것을 알 수 있다. GLUE, 슈퍼GLUE 및 CNN/데일리메일의 경우 \\의 500K 체크포인트(텍스트{\\sc SpacTor}_{\\text{ 대형}}\\)는 기준치의 1M 체크포인트보다 더 우수하거나 동일한 하류 메트릭으로 이어지는 반면 나머지 태스크는 전자가 후자이지만 차이는 \\(1\\sigma\\) 내에 있다. 이것은 35%의 전반적인 압축 절약을 초래한다. 우리는 RTD가 바닐라 SC 훈련 목표의 상단에 순수하게 상보적인 정보를 제공하기 때문에 모델 크기뿐만 아니라 \\(텍스트{\\sc SpacTor}\\) 방법 척도도 증가한다는 결론을 내렸다. 개별 작업의 파괴는 부록 D에 나와 있다.\n' +
      '\n' +
      '4번 관련 작업.\n' +
      '\n' +
      '다이와 르(2015); 라마차와란 등(2017)은 RNN 시퀀스 모델을 미리 개질하기 위해 도메인 내 데이터를 사용한 언어 모델링을 도입했다. 변압기 아키텍처(Vaswani et al)의 발명이 있어.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c} \\hline \\hline \\(\\tau\\) & **Ckpt. FLOPs** & **GLUE** & **SuperGLUE** & **SQuAD** & **CNNDM** & **Rainbow** & **MMLU** & **BBH** \\\\ \\hline\n' +
      '(\\pm\\) 0.84 & 0.84 \\(\\pm\\) 0.09 \\(\\pm\\) 0.09 \\(\\pm\\) 0.09 \\(\\pm\\) 0.30 \\(\\pm\\) 0.22 & 0.30 \\(\\pm\\) 0.30 \\(\\pm\\) 0.30 \\(\\pm\\) 0.10 & 0.30 \\(\\pm\\) 0.30 \\(\\) 0.30 \\(\\) 0.27 \\(\\) 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0 & 85.30 \\(\\) 0.30 \\\n' +
      '120K & 500K & 1.06 & **89.66**\\(\\pm\\) 0.19 & **86.06**\\(\\pm\\) 0.47 & **91.36**\\(\\pm\\) 0.10 & **34.22**\\(\\pm\\) 0.18 & **82.68**\\(\\pm\\) 0.23 & **57.78**\\(\\pm\\) 1.01 & **42.07**\\(\\pm\\) 1.44 \\\\ \\hline\n' +
      '(\\pm\\) 0.04 & 0.72 \\(\\pm\\) 0.61 \\(\\pm\\) 0.72 \\(\\pm\\) 0.72 \\(\\pm\\) 0.72 \\(\\pm\\) 0.72 \\(\\pm\\) 0.72 \\(\\pm\\) 0.72 \\(\\pm\\) 0.72 \\(\\pm\\) 0.72 \\), 0.72 \\(\\pm\\), 0.24 \\(\\pm\\) 0.72 \\(\\) 0.24 \\(\\) 0.24 \\(\\) 0.24 \\(\\) 0.24 \\(\\), 0.24 \\(\\) 0.24 \\(\\), 0.24 \\(\\) 0.24 \\(\\), 0.24 \\(\\) 0.27 \\(\\) 0.24 \\(\\) 0.24 \\(\\) 0.24 \\(\\) 0.24 \\ 및 58.24 \\(\\) 0.24 \\\n' +
      '120K & 1M & 2.06 & **89.90**\\(\\pm\\) 0.26 & **86.38**\\(\\pm\\) 0.80 & **91.53**\\(\\pm\\) 0.13 & **34.27**\\(\\pm\\) 0.26 & **83.92**\\(\\pm\\) 0.32 & **59.06**\\(\\pm\\) 0.90 & **44.22**\\(\\pm\\) 1.52 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: \\(텍스트{\\sc SpacTor}_{\\text{ 대형}}(\\tau)\\)에 대한 각 하류 작업의 평균 점수. (\\tau=0\\)은 기준선에 해당한다. 3개의 독립적인 실행에 걸쳐 평균값과 표준 편차를 나타낸다. 우리는 동일한 사전 훈련 단계에서 기준치보다 더 높은 평균을 가진 \\(텍스트{\\sc SpacTor}_{\\text{ 대형}}(\\tau)\\에 대해 대담한 수치이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c} \\hline \\hline\n' +
      '**Experiment** & **Seqs / second** & **FLOPs / step** \\\\ \\hline Baseline & 1.0 & \\(1.6\\times 10^{4}\\) GFLOPs \\\\ \\(\\text{\\sc SpacTor}_{\\text{Base}}(\\tau)\\) (1st stage) & 0.7 & \\(2.2\\times 10^{4}\\) GFLOPs \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 1단계(2단계 계산)에서 기준선과 \\(텍스트{\\sc SpacTor}_{\\text{Base}}(\\tau)\\)의 효율성 분석은 기준선과 동일하다. Seqs/2는 기준값을 사용하여 정규화된다.\n' +
      '\n' +
      '2017년 사전 훈련은 O(100B) 매개변수를 넘어 스케일 언어 모델에 대한 표준 패러다임이 되었으며, 이는 종종 자연어 과제에 대한 강력한 성능으로 이어진다.\n' +
      '\n' +
      '가장 인기 있는 것은 인과 언어 모델링(CLM)(라드포드 등, 2018, 2019), 프리픽스 언어 모델링(PLM), 프리픽스 언어 모델링(Liu et al., 2018, Raffel et al., 2020), 마스킹 언어 모델링(MLM)(Devlin et al., 2019) 등이다. 다양한 사전 훈련 목표는 상이한 다운스트림 작업(왕 등 알, 2022)에서 성능과 상관관계가 있는 것으로 이해되었으며, 따라서 미리 훈련된 LLM이 모두와 힘을 계승할 수 있도록 이러한 목표의 혼합물을 자연스럽게 큐레이팅한다(동 et al, 2019, Tay et al, 2022).\n' +
      '\n' +
      '후속 작업은 또한 개인의 목적을 개선하기 위해 시도한다. MLM의 경우, 지시 등(2020)은 연속 토큰을 마스크하고 스판 경계를 사용하여 예측을 지원하는 SpanBERT를 도입했다. 그에 의해 영감을 받은 라펠(2020); 루이스 등(2020)은 연속형 토큰이 단일 마스크 토큰으로 대체되는 데노징 목적을 고려했으며, 인코더-디코더 모델에 대한 다른 데노징 옵션 중에서 최상의 성능을 달성한다는 것을 보여주었다.\n' +
      '\n' +
      '평범한 MLM과 다른 변이체의 단점은 그라운드 진리를 파악하기 위해 모든 토큰이 참석하지 않아도 된다는 것이다. 마스크 토큰 \\(칼브라켓\\texttt{M}\\rrbracket\\)의 존재는 또한 전이 및 하류 작업 사이에 오정렬을 생성한다. ELECTRA(Clark et al., 2020)는 마스킹된 위치를 그럴듯한 토큰으로 채우는 발전기 모델을 공동으로 훈련하고, 어떤 토큰이 대체되었는지를 검출하기 위한 주요 모델 학습(_i.e._RTD 손실)을 통해 이러한 문제를 수정한다. 저자는 ELECTRA가 GPT(라드포드 et al., 2018), XLNet(양 et al., 2019)과 같은 다른 더 큰 네트워크에 비해 컴퓨팅 비용을 크게 감소시킨다는 것을 보여주었다. ELECTRA의 추가 확장은 멍 등(2021년, 2022년)에서 찾을 수 있으며, H et al(2021년), 바자 등(2022년)에서 찾을 수 있다.\n' +
      '\n' +
      'BERT 모델의 성공 외에도 T5에서 ELECTRA를 시도한 작품이 거의 없다. 이는 RTD 자체가 자연에서 생성되기보다는 차별적이기 때문이다. 제2절에서 설명한 바와 같이, _replacing_ SC를 RTD로 하는 대신 _combine_ 그들에게 사전 훈련 목표의 혼성화를 형성한다. 하이브리드 목표는 각 개별 입력에 대해 평가되며, 여기서 RTD는 토큰 생성을 학습하면서 텍스트 표현을 학습한다. 하이브리드 목적을 탐구한 밀접하게 관련된 작업은 PEGASUS(Zhang et al., 2020)이며, 우리는 인코더에서 (i) PEGASUS 디-노이즈 MLM인 PEGASUS와 다음과 같은 측면에서 우리의 차이를 강조한다. 인코더 컴포넌트의 경우 RTD는 보통 모든 토큰 주의(Clark et al., 2020)로 인해 더 많은 이점을 가져오고, 또한 모델 입력이 SC에 더 아파 MLM 마스크 \\(칼브라켓\\texttt{M}\\rrbracket\\)를 남겼는데, 이는 토큰 교체가 적어도 컨텍스트의 비율을 올바르게 생성할 수 있기 때문에(ii) PEGASUS가 텍스트 요약 작업에 독점적으로 중점을 둔다.\n' +
      '\n' +
      '마지막으로, 모델 적응에 초점을 맞춘 LLM에서 지속적인 사전 학습, 즉 _data_(구루랑간 등 2020)을 적응하거나 훈련 __별도의_(왕 et al., 2022)을 하류 작업에 적응시키는 것에 대한 연구가 있었다. 본 논문에서 사용된 지속적인 사전 훈련은 위의 두 시나리오 중 어느 것도 아니고, 교육과정 유형의 훈련(Bengio et al, 2009; Braun et al, 2017)과 더 유사하지 않으며, 훈련이 진행됨에 따라 객관적인 변화의 어려움이다.\n' +
      '\n' +
      '5배제 및 미래 근무.\n' +
      '\n' +
      '본 논문에서는 사전 훈련 목표의 새로운 조합을 구성하는데, 이는 스판 부패(SC)(Raffel et al., 2020)와 토큰 검출(RTD)(Clark et al., 2020)을 대체했으며, 이는 언어 모델이 모든 입력에 대해 두 개의 신호로부터 동시에 학습할 수 있게 한다.\n' +
      '\n' +
      '1절과 3절에서는 사전 훈련이 진행됨에 따라 하류 태스크 성능이 급격히 저하되기 때문에 RTD와 SC를 장기간 공동 훈련할 수 없다고 실증적으로 주장한다. 그런 다음 우리는 SC 단독으로 훈련을 계속한 \\(\\tau\\) 반복 후 2년 전 훈련 레시피를 제안하는 것은 당연하다. 우리는 이 접근법이 매우 효과적이며, 여기서 모델은 동일한 계산 예산을 감안할 때 훨씬 적은 계산으로 기준선과 동일한 성능에 도달할 수 있는 반면, 더 이상 기준선에 도달할 수 있음을 보여준다. 우리의 관찰은 또한 고품질 데이터가 이후 반복에서 언어 능력을 보존하고 개선하는 데 중요하다는 것을 나타낸다.\n' +
      '\n' +
      '현재 논문의 범위에는 몇 가지 한계가 있다. 첫째, 지속적인 사전 훈련 커리큘럼이 존재하는지 궁금할 수 있다. 예를 들어, \\(\\lambda_{1}\\), \\(\\lambda_{2}\\) 매개변수 또는 MLM 마스킹 비율을 부드럽게 변화시킨다. 둘째, 우리의 결과는 인코더-디코더 아키텍처로 제한된다. 워크를 다른 아키텍처로 확장하고, 웨이와 알(2022)의 라인을 따라 스케일링 행동을 탐구하는 것이 흥미롭습니다(2022). 향후 작업을 위해 그것을 떠날 계획입니다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* 아리바란디 등은 (2021) 아리바란디, V, Tay, Y, Schuster, Rao, J, Zao, H. S, Mehta, S. V, Zhu, H, Tran, V. Q, Bahri, D, Ni, J, et al. (2021) 5: 전이 학습을 위한 극한의 멀티 태스크 스케일링입니다. M_국제 학습 발표 컨퍼런스_.\n' +
      '* 바자자 등은 (2022) 바자, P, Xiong, C, Ke, G, Liu, X, He, D, Tiwary, S, Liu, T. 야, 베넷, 피, 송, X, 가오, J(2022). 메타: 모델 생성 신호를 가진 대규모 자동 인코딩 언어 모델을 사전 조작하는 효율적인 탈색: 모델 생성 신호를 갖는 대규모 자동 인코딩 언어 모델을 효율적으로 삭제한다. arXiv 프리프린트 arXiv:2204.06644_입니다.\n' +
      '네, 페더만, C, 그런도, B, Haddow, M., Haddow, M., Hounis, E, Koehn, P., Koehn, P., Ljubesic, N., Ljubesic, N), 모리시타, M, 나카자와, T., Pal, S., Post, M., Zampieri, M. (2020년) 2020년 기계 번역 컨퍼런스(WMT20)를 찾으세요. 기계번역_페이지 1-55 페이지 온라인 제5차 컨퍼런스 _검토에서. 컴퓨팅 로직에 대한 연관입니다.\n' +
      '* 벤지오 등은 (2009) 벤지오, Y, 루라디오르, J, 콜로베르트, R, 웨스트온, J(2009) 등이 있다. 교육과정 학습. 기계학습_페이지에 대한 제26차 연례 국제회의 _검토에서 41-48페이지입니다.\n' +
      '* 브라운 등은 (2017) 브라운, S, 네오, D 및 류, S. -C. (2017년) 자동 음성 인식에서 소음 견고성을 향상시키기 위한 교육과정 학습 방법이 있다. i_2017 25번째 유럽 신호 처리 회의(EUSIPCO)_, 페이지 548-552. IEEE.\n' +
      '* 브라운 등은 (2020) 브라운, T, 맨, B, Ryder, N, Subbiah, M, Kaplan, J D, Dhariwal, P, Neelakantan, A, Shyam, P, Sastry, A, Askell, A 등 (2020) 언어 모델은 거의 샷되지 않은 학습자입니다. E_NeurIPS_에서.\n' +
      '오우, 아이즈, 스웨이트, 오에니, 베드, 시네, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제리, 제니, 제니, 제니, 제니, 제니, 제스, 제니, 제니, 제니, 제니, 제니, 제니, 제비, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 아, (2022. 팜: 스칼링 언어 모델링은 경로가 있는 __ 팜: 스칼링 언어 모델링이다. CoRR_, 절대/2204.02311.\n' +
      '*청 등은 정씨(2022)정씨, H.W씨, 롱프레, S씨, 조프, B씨, 테이, 야, 페투스, W씨, 리, E씨, 왕, X씨, 데히니, M씨, 브라스틱, S씨 등 (2022)다. 칼링 명령어-피네이션된 언어 모델 __ 스칼링 명령어-피네이션된 언어 모델. arXiv 프리프린트 arXiv:2210.11416_.\n' +
      '* 클락 등은 (2020) 클라크, K, 루룽, M. T, Le, Q. V 및 매니닝, C. D.(2020). ELECTRA: 사전 훈련 텍스트 인코더는 발전기가 아닌 판별자로 작용한다. E_ICLR_에서.\n' +
      '*다이와 Le(2015) Dai, A.M.과 Le, Q. V.(2015). 반지도 시퀀스 학습을 합니다. Cortes, C, 로렌스, N, 이, D, 수기야마, M 및 가리넷, R, 편집자, _Advances, Nural 정보 처리 시스템_, 부피 28. Curran APate.\n' +
      '* 데블린 등은 (2019) 데블린, J, 창, M.M. 와, 이케이, 투타노바, K. (2019년) BERT: 언어 이해를 위한 심층 양방향 변압기의 사전 훈련. 2019 북미 컴퓨터 통계 협회의 _검토에서 인간 언어 기술, 권 1(장기 및 짧은 논문)_, 페이지 4171-4186, 미네소타 미니나폴리스, 페이지 4171-4186. 컴퓨팅 로직에 대한 연관입니다.\n' +
      '*동 등은 (2019) 동, 양, 나, 왕, 위, F, 류, X, 왕, 야, 가오, 주, M, 혼, H-W. (2019년) 자연어 이해 및 생성을 위해 사전 훈련하는 학습되지 않은 언어 모델 _ _미화 언어 모델은 자연어 이해와 생성을 위해 사전 훈련한다. 신경 정보 처리 시스템_, 32의 정보를 제공합니다.\n' +
      '* 구루랑간 등은 (2020) 구루랑안, S, 마라스소비치, A, 스웨나미디스, S, Lo, K, 벨트기, I, 다우니, D, 스미스, A(2020). 전술을 멈추지 마세요: 도메인 및 작업에 대한 적응 언어 모델. 컴퓨팅 언어학협회 제58차 연차 회의 _검토에서 8342-8360쪽 온라인. 컴퓨팅 로직에 대한 연관입니다.\n' +
      '* He 등은 (2021) He, P, Liu, X, Gao, J 및 Chen, W. (2021년) 데버타: 탈코딩 강화 배트는 주의력이 떨어졌습니다. M_국제 학습 발표 컨퍼런스_.\n' +
      '* 펜드리스트 등은 (2021) 헨드랙스, D, 번스, C, 바카르트, S, 주, A, 미지이카, M, 송, D, 스테인하르트, J(2021)이다. 대규모 멀티태스킹 언어 이해를 측정할 수 있습니다. M_국제 학습 발표 컨퍼런스_.\n' +
      '* He et al.(2021)Hendrycks, D.와 K.김펠. (2016년) 가우시안 오차 선형 단위 __ 가우시안 오차 선형 단위(겔루스). arXiv 프리프린트 arXiv:1606.08415_.\n' +
      '* 헤르만 등은 헤르만, K. (2015) 헤르만, K. M., 코시스키, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M. 및 Blunsom, P. (2015) 읽고 이해하기 위한 교수 기계 __ 테칭 기계. __ 읽는 기계. 신경 정보 처리 시스템_, 28의 기능.\n' +
      '* 조시 등은 (2020) 고시, M, Chen, D, Liu, Y, Weld, D. S, Zettlemoyer, L. 및 Levy, O. (2020년) 스판베르트: 스판들을 대표하고 예측함으로써 사전 학습을 개선한다. __ 스판베르트. 컴퓨팅 로직_, 8:64-77에 대한 협회의 거래.\n' +
      '* 테스트자 등은 B, Al-Rfou, R 및 Constant, N이다. (2021년) 파라미터 효율이 빠른 튜닝에 대한 규모의 파워입니다. 2021년 자연 언어 처리_의 실증 방법에 관한 회의 _검토에서 3045-3059 페이지, 온라인 및 펀타 카나 도미니카 공화국 페이지. 컴퓨팅 로직에 대한 연관입니다.\n' +
      '* 루이스 등은 (2020) 루이스, M, 류, Y, 고달, N, 가즈비닌자드, 모하메드, A, 레비, 오, 스토야노프, V 및 제트렘요어, L. (2020년) BART: 덴오징 시퀀스-시퀀스 사전 훈련은 자연어 생성, 번역 및 이해를 위한 것이다. 컴퓨팅 언어학협회 제58차 연차 회의 _검토에서 7871-7880쪽 온라인이 있다. 컴퓨팅 로직에 대한 연관입니다.\n' +
      '* 류 등은 (2018) 류, P. J, 세일레, M, Pot, E, 굿리치, B, 세패스, R, 카이저, L, 셰저, N. (2018년) 긴 서열을 요약하여 위키피디아를 생성합니다. M_국제 학습 발표 컨퍼런스_.\n' +
      '* 루리 등은 (2021) 루리, N., Le Bras, R., Bhagavatula, C. 및 최, Y. (2021년) 무지개 위에서 유니콘: 새로운 멀티태스킹 벤치마크에서 범용 커먼센스 추론 모델입니다. 인공지능_에 관한 AAAI 회의의 _발표에서 부피 35, 페이지 13480-13488.\n' +
      '* 멍 등은 (2021) 멍, Y, Xiong, C, Bajaj, P, Tiwary, S, Bennett, P., 한, J), 송, X. (2021년) COCO-LM: 언어 모델 사전 실습에 대한 수정 및 대조 텍스트 시퀀스이다. 신경정보처리시스템_에 대한 _Conference.\n' +
      '* 멍 등은 (2022) 멍, Y, Xiong, C, Bajaj, P, Tiwary, S, Bennett, P., 한, J), 송, X. (2022. 트레이닝 신호 생성기의 역학적 혼합물로 텍스트 인코더를 복원한다. M_국제 학습 발표 컨퍼런스_.\n' +
      '* 라드포드 등은 A(2018) 라드포드, A, 나라시만, K, 살리만스, 투츠케버, I(2018) 등이 있다. 생성적 사전 학습을 통해 언어 이해를 향상시키는 _ _ 생성적 사전 학습을 통해 언어 이해를 향상시키는 것이다. _ 오픈AI 블로그_.\n' +
      '* 라드포드 등은 A(2019) 라드포드, A, 우, J, 아동, R, 루안, D, 아미데이, D, 풋케버, I(2019) 등이 있다. 언어 모델은 비지도 멀티태스킹 학습자들이다. __언어 모델은 비지도 멀티태스킹 학습자들이다. 오픈AI 블로그_, 1(8):9.\n' +
      '* 라펠 등은 (2020) 라펠, C, 샤제르, N, 로버츠, A, 이, K, 노랑, S, 마테나, M, 저우, Y, Li, W, Liu, P J(2020) 등을 들 수 있다. 통합 텍스트 대 텍스트 변압기로 전이 학습의 한계를 탐색한다. E_JMLR_에서.\n' +
      '* 라자푸르카 등 (2016) 라자푸르카르, P, 장, J, Lopyrev, K 및 Liang, P. (2016) 텍스트에 대한 기계 이해력 100,000+ 문항입니다. E_EMNLP_에서.\n' +
      '* 라마차란 등은 (2017) 라마차란란, P, 류, P 및 Le, Q이다. (2017년) 시퀀스를 시퀀스 학습으로 전처리하지 않았다. 2017년 자연 언어 처리_ 페이지 383-391, 덴마크 코펜하겐에서 실증 방법에 관한 컨퍼런스 _검토에서. 컴퓨팅 로직에 대한 연관입니다.\n' +
      '웨이트, 리, 스레트, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 제니, 아, 제니, 제니, 제니, 제니, 제니, 제니, 제, 제니, 제니, 제, 제니, 제니, 제, 제니, 제, 제니, 제니, 제, 제니, 제니, 제, 제, 제니, 제니, t5x 및 seqio로 모델 및 데이터를 요약하는 __ t5x 및 seqio로 모델 및 데이터를 계산한다. arXiv 프리프린트 arXiv:2203.17189_입니다.\n' +
      '노우, 마니, 헤인, 왕, 소나, 나르, 스와, 라, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 멀티태스킹 프롬프트 트레이닝은 제로샷 태스크 일반화를 가능하게 한다. M_국제 학습 발표 컨퍼런스_.\n' +
      '* 숙호숙호크 등 (2019)세저, N. (2020년) 글루 변이체는 변압기를 개선한다. __lu 변이체는 변압기를 개선한다. arXiv 프리프린트 arXiv:2002.05202_이다.\n' +
      '* 셰일러와 스턴(2018) 샤저 N. 샌드 스턴, M. (2018년) 다인자: 서브선형 메모리 비용을 가진 적응 학습 비율입니다. Dy, J 및 Krause에서 A, 편집자, 35차 국제기계학습회의 _수익자, 기계학습연구_수익자 80, 페이지 4596-4604.\n' +
      '* 시리스타바, A(2022) 시바스타바, A, 로스토기, A, 쇼브, A, A, Abid, A, Fisch, A, 브라운, A, 산토로, A, Gupta, A, 가리리우다-Alonso, A(2022) 등. 모방 게임을 넘어 __ 언어 모델의 능력을 계량화하고 외삽하는 것이다. arXiv 프리프린트 arXiv:2206.04615_입니다.\n' +
      '* 테이는 (2022a) 테이, Y, 데히야, M, 트란, V Q, 가르시아, X, 바히리, D, 슈스터, T, 정, H. S, 호울스비, N 및 Metzler, D. (2022a)입니다. 언어 학습 패러다임의 통일 __언어 학습 패러다임의 통일. __ 언어 학습 패러다임. arXiv 프리프린트 arXiv:2205.05131_입니다.\n' +
      '* 테이는 (2022b) 테이, Y, Wei, J, 정, H W, 트란, V Q, 소, D. R, Shakeri, S, 가르시아, X, 정, H. S, Rao, J, Chowdhery, A.(2022b) 등이 있다. 0.1% 추가 계산으로 스케일링 법칙 _트랜딩 스케일링 법은 0.1% 추가 계산으로 전환한다. arXiv 프리프린트 arXiv:2210.11399_.\n' +
      '* 바소와이 등은 (2017) 바소와이, A, 샤제르, N, 파마르, N, 우즈코레이트, J, 존스, L, Gomez, A. N, 카이저, L. u 및 폴로신, I. (2017) 당신이 필요로 하는 모든 것에 관심이 있습니다. 이 기온, I, 럭스부르크, U V, 벤지오, S, 월차, H, 페르거스, R, 비슈완아탄, S, 가넷, R, 편집자, _Advances, 네이션 정보 처리 시스템_, 부피 30. 커란 APs.\n' +
      '* 왕 등은 (2019a) 왕, A, Pruksachatkun, Y, 낭시아, N, Singh, A, 마이클, J, 힐, F, Levy, O, Bowman, S. (2019a) 일반 목적 언어 이해 시스템을 위한 스틱어 벤치마크 __ 슈퍼글러: 범용 언어 이해 시스템을 위한 A 스티커 벤치마크이다. 신경 정보 처리 시스템_, 32의 정보를 제공한다.\n' +
      '* 왕 등은 왕(2019b) 왕, A, 싱, A, 마이클, J, 힐, F, 레비, O 및 보우만 S. R.(2019b)이다. GLUE: 자연어 이해를 위한 멀티태스킹 벤치마크 및 분석 플랫폼. M_국제 학습 발표 컨퍼런스_.\n' +
      '*왕 등은 왕(2022) 왕, T, 로버츠, A, 헤슬로우, D, 스카오, TL, 정, H W, 벨라기, I, 라운레이, J, Raffel, C(2022)이다. 0샷 일반화를 위해 어떤 언어 모델 아키텍처와 객관 작업을 가장 잘 조작하는 척? _는 어떤 언어 모델 아키텍처가 무엇일까? arXiv 프리프린트 arXiv:2204.05832_입니다.\n' +
      '* Wei 등은 (2021) Wei, J, Bosma, M, Zhao, VY, 구우, K, 유, A W, 리스터, B, 듀, N, Dai, A.M, Le, Q. V. (2021) 피네튜드 언어 모델은 0샷 학습자들이다. __ 피네튜드 언어 모델은 0샷 학습자들이다. arXiv 프리프린트 arXiv:2109.01652_입니다.\n' +
      '*웨이 등은 (2022a) 웨이, J, Tay, Y, Bommasani, R., Raffel, C., Zoph, B., 보가타마, S, 요가타마, D, 보즈마, M, 저우, D, Metzler, D 등 (2022a) 대형 언어 모델의 신장 능력 __ 큰 언어 모델의 신장 능력 __. 기계 학습 연구_에 대한 상호 작용.\n' +
      '*웨이 등은 (2022b) 웨이, J, 왕, X, 슈우루만스, D, 보스마, M, 치, E, Le, Q, 저우, D.(2022b). 생각의 추론은 큰 언어 모델에서 추론을 이끌어낸다. __ 사상 촉발은 큰 언어 모델에서 추론을 이끌어낸다. arXiv 프리프린트 arXiv:2201.11903_입니다.\n' +
      '*Xue et al.(2020) Xue, L., Constant, N), 로버츠, A, Kale, M, Al-Rfou, R, Siddhant, A, Barua, A 및 Raffel, C.(2020) mt5: __mt5: 질량적으로 다국어 사전 훈련된 텍스트 대 텍스트 변압기이다. arXiv 프리프린트 arXiv:2010.11934_입니다.\n' +
      '* 양씨(2019)는 양, Z, Dai, Z, 양, Y, 탄소, J, 살라쿠트디노프, R.R. 및 Le, Q. V.(2019)를 말한다. Xlnet: 일반화된 자기회귀 척은 언어 이해를 위한 척한다. 신경정보처리시스템_의 _Advances에서 부피 32. Curran APate, Inc.\n' +
      '* 장 등은 장(2020) 장, J, 자오, Y, 세일링, M, 류, P(2020)이다. Pegasus: 추상화 요약을 위해 추출된 갭-젠티로 사전 훈련하세요. 기계학습_국제회의에서는 11328-11339쪽.\n' +
      '\n' +
      'Training Hyperparameters\n' +
      '\n' +
      '이 절에서는 사전 훈련과 미세 조정 모두에 대한 하이퍼파라미터 선택의 보다 자세한 내용을 요약한다. 우리는 \\(텍스트{\\sc SpacTor}_{\\text{Base}}}(\\tau) 실험에 대한 매개변수만을 조정한 다음 \\(텍스트{\\\\{\\sc SpacTor}_{\\text{ 대형}}(\\tau) 실험에 대한 대부분의 최적 매개변수를 선택한다.\n' +
      '\n' +
      '### Pre-training Hyperparameters\n' +
      '\n' +
      'T5-Base 모델에 대한 하이퍼파라미터를 선택하기 위해 배치 크기 2048~250K 단계로 \\(텍스트{\\{\\sc SpacTor}_{\\text{Base}}(\\infty)\\)를 실행한 다음 다운스트림 태스크의 하위 집합(슈퍼GLUE, SQuAD)에서 최종 체크포인트를 미세 조정하고 검증 점수를 기반으로 합리적인 값 세트를 선택한다. 계수 \\(\\lambda_{1,2}\\)의 경우 손실 함수 _i._i._식 9에서 단순 그리드 검색을 적용하여 \\(\\lambda_{1,2}\\in[1.0,10.0,20.0,50.0]\\)를 적용한다. 추가 토큰 레벨 마스킹 비율의 경우 \\(r_{\\text{MLM}=[5\\%, 10\\%, 15\\%, 20\\%, 25\\%]\\)를 실험하고 15%의 마스킹 비율이 가장 잘 작동한다는 것을 발견했다. 실제로, 너무 작은 비율은 발전기 \\(G\\)가 초기 입력과 거의 다른 토큰을 생성하는 반면, 너무 큰 비율은 판별기 \\(D\\)에 대한 지나치게 중단되는 입력으로 이어지며, SC를 적절하게 훈련하는 것에서 \\(D\\)에 더 영향을 미친다.\n' +
      '\n' +
      '또한 특히 인코더 전용 또는 인코더-디코더 아키텍처 중에서 선택하는 다양한 발전기 아키텍처 및 크기를 실험한다. 어휘에서 토큰의 확률 분포에 출력되는 선형 투영 층 매핑 인코더를 사용하여 인코더 전용 아키텍처가 넉넉하고 품질 저하가 없다는 것을 알 수 있다. 우리는 또한 \\(G\\)가 3층, 4층, 6층 모델일 때 최종 하류 공연을 비교한다. 클락(Clark et al.(2020)과 같으며, \\(G\\)가 \\(D\\)의 _encoder_의 크기가 1/4 - 1/3 내외일 때 결과는 최적이다.\n' +
      '\n' +
      '그런 다음 하이퍼파라미터 세트는 모든 체크포인트 및 벤치마크에 걸쳐 나머지 경험적 평가 전체에 고정된다. T5 대 모델의 경우, 우리는 그에 따라 스케일링 생성기를 제외하고 대부분의 하이퍼파라미터를 재이용하고 MLM 비율을 15%에서 20%로 증가시킨다.\n' +
      '\n' +
      '### Fine-tuning Hyperparameters\n' +
      '\n' +
      'FLAN 지도-투표를 제외한 모든 작업의 경우 일정한 학습률 1e-3, 중도 탈락률 0.1, 배치 크기 128을 고정하는데, FLAN은 정 등에 이어 일정한 학습률 5e-4, 중도 탈락률 0.05, 배치 크기 64를 사용한다. 후자의 경우 데이터 분포가 사전 훈련 코퍼스와 매우 다르기 때문에 최적 상태도 리셋한다. 융합을 보장하기 위해 일반적으로 250K - 300K인 충분히 긴 반복을 위해 미세 조정합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l} \\hline \\hline\n' +
      '**Parameter** & **T5-Base Value** & **T5-Large Value** \\\\ \\hline Discriminator Layers & 12 & 24 \\\\ Discriminator Num Heads & 12 & 16 \\\\ Discriminator Hidden Dimension & 768 & 1024 \\\\ Discriminator MLP Size & 3072 & 4096 \\\\ RTD Head MLP Size & 3072 & 4096 \\\\ RTD Head MLP Activation & GELU & GELU \\\\ Generator Layers & 4 & 6 \\\\ Generator MLP Size & 1024 & 2048 \\\\ Input Length & 512 & 512 \\\\ Batch Size & 2048 & 2048 \\\\ Span Corruption & (\\(r\\) = 15\\%, \\(\\mu\\) = 3.0) & (\\(r\\) = 15\\%, \\(\\mu\\) = 3.0) \\\\ MLM Ratio & 15\\% & 20\\% \\\\ Warmup Steps & \\(\\kappa=10,000\\) & \\(\\kappa=10,000\\) \\\\ Learning Rate Schedule & \\(1.0/\\sqrt{\\max(n,\\kappa)}\\) & \\(1.0/\\sqrt{\\max(n,\\kappa)}\\) \\\\ \\((\\lambda_{1},\\lambda_{2})\\) & \\((10.0,10.0)\\) & \\((10.0,10.0)\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '<표 5>는 SpacTor에 대한 모델 아키텍처 및 사전 훈련 하이퍼파라미터이다. RTD 헤드는 처음에 헨드롭스 및 김펠(2016)에서 제안된 GELU 활성화, 샤저(2020)를 사용한다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:14]\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c} \\hline \\hline\n' +
      '**Size** & \\(\\tau\\) & **Ckpt** & **CoLA** & **MNLI** & **MRPC** & **QNLI** & **QQP** & **RTE** & **SST-2** & **STS-B** \\\\ \\hline \\multirow{4}{*}{Large} & 0 & 500K & 64.14 & 90.29 / 90.39 & 93.66 / 91.18 & 94.82 & 90.13 / 92.62 & 89.17 & 95.76 & 91.85 / 91.64 \\\\  & 120K & 500K & **68.28** & **90.55 / 90.57** & **94.33 / 92.16** & **94.93** & 90.06 / **92.63** & **90.25** & **96.22** & 91.78 / 91.54 \\\\  & 0 & 1M & 63.33 & 90.80 / 90.94 & 94.16 / 91.91 & 95.04 & 90.20 / 92.68 & 90.61 & 96.10 & 91.83 / 91.72 \\\\  & 120K & 1M & **67.43** & **90.93 / 90.95** & **94.41 / 92.16** & **95.20** & **90.25 / 92.70** & **91.34** & **96.44** & **92.17 / 92.00** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: SpacTor 대형에 대한 GLUE(Wang et al., 2019) 서브 태스크의 브락다운. 각 점수는 3개의 독립적인 실행의 중앙값에 해당한다. 각 서브 태스크에 대한 메트릭은 CoLA에 대한 매튜 상관 계수, MRPC에 대한 매칭/교반 정확도, MRPC에 대한 F1/백신 정확도, QNLI에 대한 정확도, QQP에 대한 F1/백신 정확도, RTE에 대한 정확도, SST-2에 대한 정확도, 피어슨 상관 계수/스피어만 상관계수-B에 대한 정확도이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c} \\hline \\hline\n' +
      '**Size** & \\(\\tau\\) & **Ckpt** & **BoolQ** & **CB** & **COPA** & **MultiRC** & **ReCoRD** & **RTE** & **WiC** & **WSC** \\\\ \\hline \\multirow{4}{*}{Base} & 0 & 500K & 81.99 & 96.07 / 96.43 & 70.00 & 76.15 / 37.88 & 77.65 / 78.53 & 81.59 & 68.97 & 83.65 \\\\  & 250K & 500K & **82.32** & 93.70 / 94.64 & **73.00** & **77.09 / 40.19** & 77.65 / **78.55** & **83.03** & **69.44** & **85.58** \\\\  & 120K & 500K & **82.72** & 95.03 / 96.43 & **74.00** & **77.04 / 38.93** & **77.92 / 78.92** & **82.31** & **70.22** & **84.62** \\\\  & 0 & 1M & 82.39 & 97.36 / 96.43 & 72.00 & 77.10 / 39.66 & 78.10 / 79.10 & 83.03 & 69.44 & 86.54 \\\\  & 250K & 1M & **82.78** & 91.89 / 94.64 & **76.00** & **77.63 / 41.03** & 78.05 / 79.03 & 83.03 & 69.12 & 85.58 \\\\  & 120K & 1M & **82.66** & 95.04 / 94.64 & **74.00** & **77.94 / 41.76** & **78.21 / 79.20** & 82.67 & 69.28 & 82.69 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: SpacTorBase에 대한 슈퍼GLUE(왕 et al., 2019) 하위 태스크의 브락다운. 각 점수는 5개의 독립적인 실행의 중앙값에 해당한다. 각 서브 태스크에 대한 메트릭은 BoolQ, CB에 대한 평균 F1/백신 정확도, COPA에 대한 정확도, 다중RC에 대한 F1/엑틴 매치(EM), ReCoRD에 대한 EM/F1, RTE에 대한 정확도, RTE, WiC 및 WSC에 대한 정확도이다.\n' +
      '\n' +
      '그림 5: T5-Base 모델에 대한 사전 훈련 FLOP와 관련하여 GLUE, 레인보우, BBH 및 MMLU에 대한 SpacTor 성능은 그림 5:였다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c c} \\hline \\hline\n' +
      '**Size** & \\(\\tau\\) & **Ckpt** & **SQuAD** & **CNNDM** & \\(\\alpha\\)**NLI** & **CosmosQA** & **HellaSWAG** & **PIQA** & **SocialIQA** & **WinoGrande** \\\\ \\hline \\multirow{4}{*}{Base} & 0 & 500K & 85.01 / 92.20 & 41.48 / 19.43 / 38.98 & 71.28 & 74.51 & 62.47 & 76.28 & 69.60 & 66.85 \\\\  & 250K & 500K & **85.34 / 92.42** & **41.50 / 19.41 / 39.03** & **71.87** & **75.58** & **66.80** & **76.93** & **70.32** & **67.96** \\\\  & 120K & 500K & **85.37 / 92.42** & **41.54 / 19.47 / 39.04** & **71.67** & **75.08** & **66.11** & **77.15** & **70.01** & **68.03** \\\\  & 0 & 1M & 85.37 / 92.34 & 41.51 / 19.48 / 39.02 & 71.34 & 75.31 & 64.44 & 76.55 & 70.83 & 67.17 \\\\  & 250K & 1M & **85.63 / 92.57** & **41.69 / 19.55 / 39.17** & **72.26** & **76.55** & **67.19** & **77.42** & 70.78 & **68.35** \\\\  & 120K & 1M & **85.54 / 92.58** & **41.76 / 19.60 / 39.24** & **72.39** & **76.58** & **67.30** & **77.20** & **71.29** & **68.67** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 10: SQuAD(Rajpurkar et al., 2016), CNN/데일리메일(Hermann et al., 2015), 레인보우(Lourie et al., 2021) 하위 작업은 \\(텍스트{SpaceTor}_{\\text{Base}}\\)의 브락다운이다. 각 점수는 5개의 독립적인 실행의 중앙값에 해당한다. 각 서브 태스크에 대한 메트릭은 SQuAD의 EM/F1, CNN/데일리메일의 경우 Rouge-1/Rouge-2/Rouge-L, 모든 레인보우 작업에 대한 정확도이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c c} \\hline \\hline\n' +
      '**Size** & \\(\\tau\\) & **Ckpt** & **BoolQ** & **CB** & **COPA** & **MultiRC** & **ReCoRD** & **RTE** & **WiC** & **WSC** \\\\ \\hline \\multirow{4}{*}{Large} & 0 & 500K & 87.49 & 95.59 / 98.21 & 85.00 & 83.97 / 52.93 & 86.30 / 87.21 & 89.89 & 72.88 & 94.23 \\\\  & 120K & 500K & 87.43 & **100.00** / **100.00** & **87.00** & **84.33 / 54.98** & **86.86 / 87.74** & **91.94** & **74.92** & 93.27 \\\\  & 0 & 1M & 87.92 & 96.23 / 98.21 & 90.00 & 85.19 / 56.45 & 87.31 / 88.17 & 90.61 & 74.92 & 91.35 \\\\  & 120K & 1M & 87.80 & **100.00** / **100.00** & 87.00 & 85.05 / 56.35 & **87.43 / 88.29** & **90.97** & 73.98 & **93.27** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '<표 9>는 \\(텍스트{스페이스Tor}_{\\text{ 대형}}\\)에 대한 슈퍼GLUE(왕 et al., 2019) 하위 작업의 브락다운이다. 각 점수는 3개의 독립적인 실행의 중앙값에 해당한다. 각 서브 태스크에 대한 메트릭은 BoolQ, CB에 대한 평균 F1/백신 정확도, COPA에 대한 정확도, 다중RC에 대한 F1/엑틴 매치(EM), ReCoRD에 대한 EM/F1, RTE에 대한 정확도, RTE, WiC 및 WSC에 대한 정확도이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multicolumn{2}{c}{**Boolean**} & \\multirow{2}{*}{**Causal**} & \\multirow{2}{*}{**Date**} & \\multirow{2}{*}{**Disambi-**} & \\multirow{2}{*}{**Local**} & \\multirow{2}{*}{**Manishing**} & \\multirow{2}{*}{**Local**} & \\multirow{2}{*}{**Manishing**} & \\multirow{2}{*}{**Local**} & \\multirow{2}{*}{**Fallacies**} & \\multirow{2}{*}{**Shanes**} & \\multirow{2}{*}{**Hyperson**} \\\\  & & & Expressions & & & & & & & \\\\ \\hline \\multirow{9}{*}{Base} & 0 & 500K & 57.60 & 56.68 & 38.00 & 52.00 & 6.80 & 56.00 & 22.40 & 68.80 \\\\  & 250K & 500K & 55.20 & 55.61 & **40.40** & **60.00** & 3.60 & **58.80** & **28.40** & 66.40 \\\\  & 120K & 500K & 54.40 & 55.61 & **42.80** & **56.80** & 6.40 & **59.60** & 21.20 & 65.20 \\\\  & 0 & 1M & 54.80 & 55.61 & 40.80 & 58.40 & 6.40 & 60.40 & 18.00 & 72.00 \\\\  & 250K & 1M & **59.60** & 54.55 & **44.00** & **60.80** & 5.20 & 60.00 & **29.60** & 69.20 \\\\  & 120K & 1M & **58.00** & **56.15** & 40.00 & **60.80** & 3.60 & 60.00 & **30.00** & 62.00 \\\\ \\hline \\hline \\multirow{2}{*}{**Size**} & \\multirow{2}{*}{\\(\\tau\\)} & \\multirow{2}{*}{**Ckpt**} & \\multicolumn{2}{c}{**Logical**} & \\multicolumn{2}{c}{**Logical**} & \\multirow{2}{*}{**Logical**} & \\multirow{2}{*}{**Movie Reco-**} & \\multirow{2}{*}{**Multistep**} & \\multirow{2}{*}{**Astigate**} & \\multirow{2}{*}{**Object**} & \\multirow{2}{*}{**In A**} \\\\  & & \\multicolumn{2}{c}{**Deduction**} & \\multicolumn{2}{c}{**Deduction**} & \\multicolumn{2}{c}{**Deduction**} & & & & \\\\  & & **5 Objects** & **7 Objects** & **3 Objects** & **mendation** & \\begin{tabular}{c} **Movie Reco-** \\\\ **Anithmetic** \\\\ **Two** \\\\ \\end{tabular} & \\begin{tabular}{c} **Multistep** \\\\ **Two** \\\\ \\end{tabular} & \\begin{tabular}{c} **Navigate** \\\\ **Counting** \\\\ \\end{tabular} &\n' +
      '\\begin{tabular}{c} **Object** \\\\ **In A** \\\\ **Table** \\\\ \\end{tabular} \\\\ \\hline \\hline \\multirow{9}{*}{Base} & 0 & 500K & 28.00 & 26.40 & 42.40 & 49.20 & 1.60 & 64.00 & 24.80 & 32.88 \\\\  & 250K & 500K & **32.40** & **29.20** & **44.00** & 47.60 & 1.20 & **64.40** & 23.20 & 27.40 \\\\  & 120K & 500K & **31.20** & **29.60** & **45.60** & 47.20 & 1.20 & 64.00 & **26.40** & 28.77 \\\\  & 0 & 1M & 33.20 & 25.60 & 44.40 & 47.20 & 1.20 & 64.00 & 28.00 & 32.88 \\\\  & 250K & 1M & 32.40 & **32.40** & **47.60** & **47.60** & **1.60** & **64.80** & **28.40** & 30.82 \\\\  & 120K & 1M & **34.00** & **29.60** & **47.20** & **47.60** & 1.20 & **65.60** & **29.60** & 30.14 \\\\ \\hline \\hline \\multirow{9}{*}{**Size**} & \\multirow{2}{*}{\\(\\tau\\)} & \\multirow{2}{*}{**Ckpt**} & \\multicolumn{2}{c}{**Reasoning**} & \\multicolumn{2}{c}{**Salient**} & \\multirow{2}{*}{**Shanes**} & \\multirow{2}{*}{**Shanes**} & \\multirow{2}{*}{**Temporal**} & \\multirow{2}{*}{**Shuffled**} & \\multirow{2}{*}{**Shuffled**} \\\\  & & \\multicolumn{2}{c}{**About**} & \\multicolumn{2}{c}{**Kun**} & \\multicolumn{2}{c}{**Translation**} & & & & \\\\ \\cline{1-1}  & & \\multicolumn{2}{c}{**Colored**} & \\multicolumn{2}{c}{**Names**} & \\multicolumn{2}{c}{**Error**} & & & & & \\\\ \\cline{1-1}  & & \\multicolumn{2}{c}{**Objects**} & \\multicolumn{2}{c}{**Detection**} & & & & & & & \\\\ \\cline{1-1} \\cline{2-1}  & & 0 & 500K & 4.80 & 28.00 & 26.00 & 53.93 & 56.80 & 28.40 & 22.40 & 18.00 \\\\  & 250K & 500K & **34.80** & 28.00 & **27.20** & 53.93 & 56.80 & **28.80** & 22.00 & 17.20 \\\\  & 120K & 500K & **32.80** & 28.00 & 26.00 & 53.93 & 56.40 & **28.80** & 22.40 & 18.00 \\\\  & 0 & 1M & 35.20 & 28.00 & 30.00 & 54.49 & 57.20 & 30.40 & 21.20 & 18.40 \\\\  & 250K & 1M & 32.00 & 28.00 & 29.20 & 53.93 & **57.60** & 26.40 & 21.20 & 18.40 \\\\  & 120K & 1M & 34.80 & 28.00 & **30.40** & 53.93 & **57.60** & 30.00 & **21.60** & 17.20 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 12: \\(텍스트{{\\\\sc SpacTor}}_{\\text{Base}\\)에 대한 직접적인 답변을 가진 27개의 BBH(시바바 등, 2022) 작업의 브락다운: 그 메트릭은 모두 정확합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multicolumn{2}{c}{**Reasoning**} & \\multicolumn{2}{c}{**Salient**} & \\multirow{2}{*}{**Senarks**} & \\multirow{2}{*}{**Senarks**} & \\multirow{2}{*}{**Turchasing**} & \\multirow{2}{*}{**Tharking**} & \\multirow{2}{*}{**Shuffed**} & \\multirow{2}{*}{**Shuffed**} & \\multirow{2}{*}{**Shuffed**} \\\\  & & & & & & & & & & & \\\\  & & & **Aboat** & **Aboat** & **Aboat** & **Aboat** & **Aboat** & **Aboat** & **Aboat** & **Aboat** & **Aboat** \\\\ \\hline \\multirow{3}{*}{**Size**} & 0 & 500K & 44.00 & 46.00 & 56.00 & 60.80 & 1.20 & 59.60 & 40.00 & 34.93 \\\\  & 120K & 500K & **48.00** & **50.40** & **58.40** & **62.00** & **1.60** & **60.40** & 36.80 & **35.62** \\\\  & 0 & 1M & 44.40 & 48.80 & 61.60 & 54.80 & 1.20 & 62.40 & 42.40 & 39.04 \\\\  & 120K & 1M & **52.00** & **55.60** & **68.80** & **62.00** & **1.20** & **65.20** & 37.60 & **43.15** \\\\ \\hline \\hline \\multirow{3}{*}{**Size**} & \\(\\tau\\) & \\multirow{3}{*}{**Ckpt**} & \\multicolumn{2}{c}{**Reasoning**} & \\multicolumn{2}{c}{**Salient**} & \\multirow{3}{*}{**Senarks**} & \\multirow{3}{*}{**Senarks**} & \\multirow{3}{*}{**Temporal**} & \\multirow{3}{*}{**Shuffed**} & \\multirow{3}{*}{**Shuffed**} \\\\  & & \\multicolumn{2}{c}{**Aboat**} & \\multicolumn{2}{c}{**Ruin**} & \\multicolumn{2}{c}{**Translation**} & \\multirow{3}{*}{**Senarks**} & \\multirow{3}{*}{**Turchasing**} & \\multirow{3}{*}{**Sequences**} & \\multirow{3}{*}{**Objects**} & \\multirow{3}{*}{**Objects**} \\\\  & & & **Colored** & & & & & & \\\\  & & **Aboat** & **Aboat** & **Aboat** & **Aboat** & **Aboat** & **Aboat** & **Aboat** \\\\ \\hline \\hline \\multirow{3}{*}{**Size**} & 0 & 500K & 41.60 & 20.00 & 34.40 & 53.37 & 58.40 & 26.80 & 17.60 & 15.60 \\\\  & 120K & 500K & **44.40** & **25.60** & 28.00 & **55.06** & **59.20** & **37.20** & **19.20** & 14.80 \\\\  & 0 & 1M & 44.80 & 25.60 & 34.80 & 58.99 & 58.80 & 30.40 & 17.60 & 14.40 \\\\  & 120K & 1M & **46.40** & 24.80 & **41.20** & 52.25 & 57.60 & **36.00** & **19.20** & **14.80** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 13: \\(텍스트{\\sc{SpaceTor}}_{\\text{ 대형}}\\)에 대한 직접적인 답변이 있는 27개의 BBH(시바바 등, 2022) 작업의 브락다운. 그 메트릭은 모두 정확합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**Abstract**} & \\multirow{2}{*}{**Anatomy**} & \\multirow{2}{*}{**Astronomy**} & \\multirow{2}{*}{**Business**} & \\multirow{2}{*}{**Clinical**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**Chemistry**} & \\multirow{2}{*}{**College**} \\\\  & & & & & & & & & & \\\\  & & & & & & & & & & \\\\ \\hline \\multirow{6}{*}{Base} & 0 & 500K & 36.36 & 50.00 & 50.00 & 63.64 & 55.17 & 50.00 & 50.00 & 63.64 \\\\  & 250K & 500K & 36.36 & 50.00 & **56.25** & 63.64 & 44.83 & 50.00 & **62.50** & 63.64 \\\\  & 120K & 500K & 36.36 & 50.00 & 50.00 & **72.73** & 48.28 & 43.75 & **62.50** & 54.55 \\\\  & 0 & 1M & 45.45 & 57.14 & 50.00 & 72.73 & 55.17 & 43.75 & 62.50 & 72.73 \\\\  & 250K & 1M & 45.45 & 50.00 & 50.00 & 63.64 & 51.72 & **50.00** & 62.50 & 63.64 \\\\  & 120K & 1M & 36.36 & 57.14 & **56.25** & 72.73 & 51.72 & 43.75 & 62.50 & 63.64 \\\\ \\hline \\hline \\multirow{2}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**Physics**} & \\multirow{2}{*}{**Computer**} & \\multirow{2}{*}{**Conceptual**} & \\multirow{2}{*}{**Physics**} & \\multirow{2}{*}{**Econo-**} & \\multirow{2}{*}{**Electrical**} & \\multirow{2}{*}{**Engineering**} \\\\  & & & & & & & & & \\\\  & & **Mathematics** & **College** & **College** & **Physics** & **Security** & **Physics** & **Chemichers** & **Engineering** & **Mathematics** \\\\ \\hline \\multirow{6}{*}{Base} & 0 & 500K & 36.36 & 63.64 & 72.73 & 45.45 & 42.31 & 58.33 & 50.00 & 36.59 \\\\  & 250K & 500K & **45.45** & 63.64 & 72.73 & **63.64** & **46.15** & 50.00 & 43.75 & 36.59 \\\\  & 120K & 500K & **45.45** & 63.64 & 63.64 & **54.55** & 42.31 & 50.00 & 50.00 & **39.02** \\\\  & 0 & 1M & 45.45 & 63.64 & 81.82 & 54.55 & 38.46 & 58.33 & 56.25 & 36.59 \\\\  & 250K & 1M & 45.45 & 59.09 & 72.73 & **63.64** & 38.46 & 50.00 & 50.00 & **39.02** \\\\  & 120K & 1M & 45.45 & 63.64 & 63.64 & 54.55 & **42.31** & 50.00 & 50.00 & 34.15 \\\\ \\hline \\hline \\multirow{2}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**Formal**} & \\multirow{2}{*}{**Global**} & \\multirow{2}{*}{**Eacts**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**School**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} \\\\  & & & & & & & & & & \\\\  & & **Logic** & **Facts** & **School** & **Chamistry** & **Computer** & **European** & **School** & **Geography** & **Geovernment** \\\\  & & & & & & & & & & \\\\  & 0 & 500K & 57.14 & 50.00 & 40.63 & 40.91 & 55.56 & 55.56 & 59.09 & 61.90 \\\\  & 250K & 500K & 57.14 & 50.00 & **50.00** & **50.00** & 55.56 & 55.56 & **68.18** & 61.90 \\\\  & 120K & 500K & 57.14 & 50.00 & **50.00** & **50.00** & 55.56 & 55.56 & **63.64** & **66.67** \\\\  & 0 & 1M & 50.00 & 50.00 & 43.75 & 40.91 & 55.56 & 61.11 & 68.18 & 71.43 \\\\  & 250K & 1M & **57.14** & 50.00 & 43.75 & **50.00** & 55.56 & 61.11 & **72.73** & 61.90 \\\\  & 120K & 1M & **64.29** & **60.00** & **46.88** & **45.45** & 55.56 & 55.56 & **77.27** & 66.67 \\\\ \\hline \\hline \\multirow{2}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**School**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**School**} & \\multirow{2}{*}{**High**} \\\\  & & & & & & & & & & \\\\  & & **Macro-** & **Anattics** & **Anattics** & **Anonomics** & **Physics** & **Chology** & **Physics** & **Chology** & **Physics** \\\\ \\hline \\multirow{6}{*}{Base} & 0 & 500K & 39.53 & 41.38 & 46.15 & 41.18 & 45.00 & 47.83 & 68.18 & 53.85 \\\\  & 250K & 500K & 34.88 & 41.38 & **53.85** & **47.06** & **48.33** & 47.83 & 68.18 & 53.85 \\\\  & 120K & 500K & 34.88 & 37.93 & **53.85** & **47.06** & **48.33** & 47.83 & 68.18 & **57.69** \\\\ \\cline{1-1}  & 0 & 1M & 37.21 & 41.38 & 53.85 & 41.18 & 50.00 & 47.83 & 72.73 & 57.69 \\\\ \\cline{1-1}  & 250K & 1M & 37.21 & 41.38 & 53.85 & **47.06** & 46.67 & 47.83 & 68.18 & 53.85 \\\\ \\cline{1-1}  & 120K & 1M & **41.86** & 41.38 & 53.85 & **47.06** & 50.00 & 43.48 & 72.73 & 57.69 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 14: \\(텍스트{{\\tt 스페이스Tor}}_{\\text{Base}\\)에 대한 직접적인 답변이 있는 총 57 MMLU(Hendrycks et al., 2021) 과제 중 처음 32개의 브락다운이다. 그 메트릭은 모두 정확합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Size**} & \\multirow{2}{*}{\\(\\tau\\)} & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**Human Aging**} & \\multirow{2}{*}{**Human Sexuality**} & \\multirow{2}{*}{**International Law**} & \\multirow{2}{*}{**Juris- Evidence**} & \\multirow{2}{*}{**Logical Fallacies**} & \\multirow{2}{*}{**Machine Learning**} & \\multirow{2}{*}{**Management**} & \\multirow{2}{*}{**Marketing**} \\\\ \\hline \\multirow{5}{*}{Base} & 0 & 500K & 39.13 & 50.00 & 61.54 & 45.45 & 55.56 & 45.45 & 63.64 & 68.00 \\\\  & 250K & 500K & 39.13 & 50.00 & **69.23** & 36.36 & **61.11** & 45.45 & 63.64 & 64.00 \\\\  & 120K & 500K & **47.83** & **58.33** & 61.54 & 36.36 & **61.11** & 45.45 & 54.55 & 64.00 \\\\  & 0 & 1M & 43.48 & 58.33 & 69.23 & 45.45 & 66.67 & 45.45 & 63.64 & 68.00 \\\\  & 250K & 1M & 43.48 & 50.00 & 61.54 & 45.45 & 61.11 & **63.64** & 63.64 & 68.00 \\\\  & 120K & 1M & **47.83** & 50.00 & 61.54 & 45.45 & **72.22** & 45.45 & 63.64 & **72.00** \\\\ \\hline \\hline \\multirow{2}{*}{**Size**} & \\multirow{2}{*}{\\(\\tau\\)} & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**Medical Genetics**} & \\multirow{2}{*}{**Misc.**} & \\multirow{2}{*}{**Moral Disputes**} & \\multirow{2}{*}{**Stenarions**} & \\multirow{2}{*}{**Nutrition**} & \\multirow{2}{*}{**Philosophy**} & \\multirow{2}{*}{**Prehistory**} & \\multirow{2}{*}{**Professional Accounting**} \\\\ \\hline \\multirow{5}{*}{Base} & 0 & 500K & 45.45 & 39.53 & 50.00 & 33.00 & 51.52 & 35.29 & 48.57 & 35.48 \\\\  & 250K & 500K & **54.55** & 38.37 & 50.00 & 33.00 & 51.52 & **41.18** & 48.57 & 35.48 \\\\  & 120K & 500K & **63.64** & **40.70** & 44.74 & 33.00 & 51.52 & **41.18** & 45.71 & 35.48 \\\\  & 0 & 1M & 54.55 & 40.70 & 50.00 & 32.00 & 57.58 & 38.24 & 48.57 & 35.48 \\\\  & 250K & 1M & **63.64** & 40.70 & 50.00 & **33.00** & 57.58 & **41.18** & **54.29** & **41.94** \\\\  & 120K & 1M & 54.55 & 39.53 & 47.37 & **34.00** & 54.55 & **41.18** & 45.71 & 35.48 \\\\ \\hline \\hline \\multirow{2}{*}{**Size**} & \\multirow{2}{*}{\\(\\tau\\)} & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**Professional Law**} & \\multirow{2}{*}{**Professional Medicine**} & \\multirow{2}{*}{**Professional Psychology**} & \\multirow{2}{*}{**Relations**} & \\multirow{2}{*}{**Stenarity**} & \\multirow{2}{*}{**Sociology**} & \\multirow{2}{*}{**US Foreign Policy**} & \\multirow{2}{*}{**Virology**} \\\\ \\hline \\multirow{5}{*}{Base} & 0 & 500K & 35.29 & 38.71 & 46.38 & 75.00 & 44.44 & 63.64 & 63.64 & 50.00 \\\\  & 250K & 500K & 35.29 & 38.71 & 44.93 & 58.33 & **48.15** & 63.64 & 54.55 & **55.56** \\\\  & 120K & 500K & 35.29 & 35.48 & **49.28** & 66.67 & 40.74 & 63.64 & 54.55 & **55.56** \\\\  & 0 & 1M & 35.29 & 38.71 & 44.93 & 66.67 & 48.15 & 68.18 & 63.64 & 50.00 \\\\  & 250K & 1M & 33.53 & 38.71 & **49.28** & 58.33 & 44.44 & 68.18 & 63.64 & **61.11** \\\\  & 120K & 1M & 33.53 & 38.71 & **47.83** & 66.67 & 48.15 & 68.18 & 63.64 & **61.11** \\\\ \\hline \\hline \\multirow{2}{*}{bfSize} & \\multirow{2}{*}{\\(\\tau\\)} & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**World Religions**} & \\multirow{2}{*}{**Professional Religions**} & \\multirow{2}{*}{**Professional Analytics**} & \\multirow{2}{*}{**Professional Analytics**} & \\multirow{2}{*}{**Professional Analytics**} \\\\ \\hline \\multirow{5}{*}{Base} & 0 & 500K & 42.11 & & & & & \\\\  & 250K & 500K & 36.84 & & & & & \\\\  & 120K & 500K & **47.37** & & & & & \\\\  & 0 & 1M & 47.37 & & & & & \\\\  & 250K & 1M & 47.37 & & & & & \\\\  & 120K & 1M & 47.37 & & & & & \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 15: \\(텍스트{{\\\\sc SpacTor}_{\\text{{\\sc Base}}\\)에 대한 직접적인 답변이 있는 총 57 MMLU(Hendrycks et al., 2021) 중 두 번째 25의 브락다운이다. 그 메트릭은 모두 정확합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**Abstract**} & \\multirow{2}{*}{**Anatomy**} & \\multirow{2}{*}{**Astronomy**} & \\multirow{2}{*}{**Business**} & \\multirow{2}{*}{**Clinical**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**Chemistry**} & \\multirow{2}{*}{**College**} \\\\  & & & & & & & & & & \\\\ \\hline \\multirow{4}{*}{Large} & 0 & 500K & 36.36 & 57.14 & 56.25 & 72.73 & 55.17 & 43.75 & 50.00 & 54.55 \\\\  & 120K & 500K & **45.45** & **57.14** & 50.00 & **72.73** & **62.07** & **62.50** & **50.00** & **63.64** \\\\  & 0 & 1M & 45.45 & 50.00 & 56.25 & 72.73 & 55.17 & 56.25 & 50.00 & 54.55 \\\\  & 120K & 1M & **54.55** & **64.29** & 43.75 & **72.73** & **58.62** & **62.50** & **50.00** & **54.55** \\\\ \\hline \\hline \\multirow{2}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**Medicine**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**College**} & \\multirow{2}{*}{**Computer**} & \\multirow{2}{*}{**Conceptual**} & \\multirow{2}{*}{**Physics**} & \\multirow{2}{*}{**Econo-metrics**} & \\multirow{2}{*}{**Electrical**} & \\multirow{2}{*}{**Elementary**} \\\\  & & & & & & & & & \\\\ \\hline \\multirow{4}{*}{Large} & 0 & 500K & 45.45 & 59.09 & 81.82 & 36.36 & 42.31 & 50.00 & 62.50 & 39.02 \\\\  & 120K & 500K & **54.55** & **63.64** & 72.73 & **54.55** & **46.15** & **58.33** & **62.50** & 36.59 \\\\  & 0 & 1M & 54.55 & 59.09 & 81.82 & 54.55 & 42.31 & 50.00 & 68.75 & 39.02 \\\\  & 120K & 1M & 36.36 & 54.55 & **90.91** & 45.45 & **50.00** & **58.33** & 62.50 & **43.90** \\\\ \\hline \\hline \\multirow{4}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**Formal**} & \\multirow{2}{*}{**Global**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**School**} \\\\  & & & & & & & & & & \\\\ \\hline \\multirow{4}{*}{Large} & 0 & 500K & 57.14 & 60.00 & 46.88 & 45.45 & 55.56 & 72.22 & 77.27 & 61.90 \\\\  & 120K & 500K & 50.00 & **60.00** & **46.88** & **45.45** & **66.67** & **72.22** & **77.27** & **66.67** \\\\  & 0 & 1M & 64.29 & 60.00 & 46.88 & 45.45 & 66.67 & 66.67 & 81.82 & 71.43 \\\\  & 120K & 1M & 50.00 & **70.00** & 43.75 & 36.36 & **66.67** & **72.22** & **81.82** & 61.90 \\\\ \\hline \\hline \\multirow{4}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**School**} \\\\  & & & & & & & & & & \\\\ \\hline \\multirow{4}{*}{**Size**} & 0 & 500K & 57.14 & 60.00 & 46.88 & 45.45 & 55.56 & 72.22 & 77.27 & 61.90 \\\\  & 120K & 500K & 50.00 & **60.00** & **46.88** & **45.45** & **66.67** & **72.22** & **77.27** & **66.67** \\\\  & 0 & 1M & 64.29 & 60.00 & 46.88 & 45.45 & 66.67 & 66.67 & 81.82 & 71.43 \\\\  & 120K & 1M & 50.00 & **70.00** & 43.75 & 36.36 & **66.67** & **72.22** & **81.82** & 61.90 \\\\ \\hline \\hline \\multirow{4}{*}{**Size**} & \\(\\tau\\) & \\multirow{2}{*}{**Ckpt**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**High**} & \\multirow{2}{*}{**School**} \\\\  & & & & & & & & & & \\\\ \\hline \\multirow{4}{*}{**Size**} & 0 & 500K & 41.86 & 48.28 & 65.38 & 47.06 & 63.33 & 47.83 & 59.09 & 57.69 \\\\  & 120K & 500K & **44.19** & **48.28** & 57.69 & **47.06** & **66.67** & 43.48 & **68.18** & **69.23** \\\\  & 0 & 1M & 44.19 & 44.83 & 65.38 & 47.06 & 66.67 & 52.17 & 59.09 & 65.38 \\\\  & 120K & 1M & 41.86 & **44.83** & **69.23** & **52.94** & **70.00** & **56.52** & **68.18** & 61.54 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 16: \\(텍스트{{\\tt SpacTor}}_{\\text{ 대형}}\\)에 대한 직접적인 답변이 있는 총 57 MMLU(Hendrycks et al., 2021) 과제 중 처음 32개의 브락다운이다. 그 메트릭은 모두 정확합니다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:22]\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>