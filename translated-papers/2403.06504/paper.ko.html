<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 단일 GPU에서 100B 모델 미세 조정을 활성화하고 가속화하기 위해 NVMe SSD 추가\n' +
      '\n' +
      'Changyue Liao1\n' +
      '\n' +
      'Mo Sun1\n' +
      '\n' +
      'Zihan Yang1\n' +
      '\n' +
      'Kaiqi Chen\n' +
      '\n' +
      '중국 저장대학\n' +
      '\n' +
      'Binhang Yuan\n' +
      '\n' +
      'HKUST, China\n' +
      '\n' +
      'Fei Wu\n' +
      '\n' +
      '중국 저장대학\n' +
      '\n' +
      '중국 저장대학\n' +
      '\n' +
      '각주 1: 각주:\n' +
      '\n' +
      '###### Abstract.\n' +
      '\n' +
      '최근 대규모 언어 모델의 발전은 그들이 사용하는 엄청난 수의 매개변수에서 비롯된 우수한 능력으로 세계에 엄청난 가치를 가져왔다. 그러나, 현재 80GB에서 정점을 이루는 메모리 용량이 가장 높은 GPU조차도 확률적 경사 하강 기반 최적화를 수행할 때 이러한 방대한 파라미터 및 관련 최적화 상태들을 수용하기에 충분하지 않다. 그러한 거대한 모델들을 호스팅하기 위한 한 가지 접근법은 많은 GPU들로부터 디바이스 메모리를 집계하는 것이다. 특히 미세 조정을 위해 1,000억 매개 변수가 있는 모델에 적합하려면 32개의 NVIDIA A100 GPU가 필요하다. 그러나, 이 접근법은 많은 고급 GPU 서버에 대해 항상 제한된 예산을 가지고 있는 대부분의 학계 연구자들에게 엄청난 비용을 도입한다. 본 논문에서는 대부분의 AI 연구자들이 접근할 수 있는 상품 서버의 단일, 심지어 저사양 GPU에 대한 거대한 모델 미세 조정에 초점을 맞춘다. 이러한 시나리오에서, 최신 작업 ZeRO-Infinity는 상품 서버에서 실행될 때, 1) 비효율적인 스와핑으로 인한 낮은 GPU 활용과 2) CPU 메모리 용량으로 인한 제한된 훈련 가능한 모델 크기라는 두 가지 심각한 문제를 겪는다. 기본적인 이유는 ZeRO-Infinity가 고급 GPU 서버에서 실행되도록 최적화되어 있기 때문입니다.\n' +
      '\n' +
      '이를 위해 저사양의 GPU와 제한된 CPU 메모리 용량을 갖는 저사양의 서버에서 효율적인 100B 대용량 모델 미세조정이 가능한 저비용 트레이닝 프레임워크인 _Fuyou_를 제시한다. 핵심 아이디어는 SSD-CPU 통신을 최적화 차원으로 추가하여 GPU 활용도를 극대화하기 위해 체계적인 접근법에서 계산 및 데이터 스와핑을 신중하게 공동 최적화하는 것이다. 그렇게 하기 위해, Fuyou는 세 가지 혁신으로 구성되어 있습니다. 먼저, GPU 활용도를 극대화하기 위해 역방향 전파와 중복되는 동기식 아웃 오브 코어 CPU 최적화기를 제안한다. 둘째, GPU-CPU-SSD 완전 파이프라인 활성화 스와핑 메커니즘을 제안하여 훨씬 더 큰 모델 미세 조정을 허용한다. 셋째, 에폭 시간을 최소화하기 위해 최적의 스와핑 활성화 양을 자동으로 결정하기 위한 자동 활성화 스와핑 관리를 제시한다. 실험 결과, 1) Fuyou는 GPU 활용도가 높은 소비자 GPU RTX 4090에서 175B GPUT-3를 미세 조정할 수 있는 반면, ZeRO-Infinity는 미세 조정에 실패하고, 2) 작은 GPT-3 13B 모델을 훈련할 때 Fuyou는 RTX 4090 GPU에서 156개의 TFLOPS를 달성하는 반면 ZeRO-Infinity는 45개의 TFLOPS만 달성하는 것으로 나타났다.\n' +
      '\n' +
      '## 1. Introduction\n' +
      '\n' +
      '대형 언어 모델(LLM)은 다양한 데이터 관리 작업[12, 54]을 포함한 다양한 자연어 처리 작업[5, 8, 39, 46, 58]에서 인상적인 정확도로 세계의 주목을 받았다. 변압기 모델의 발전과 함께 빠르게 성장하는 모델 크기가 있으며, 최근에는 고밀도 변압기 모델의 모델 크기가 1.5B(GPT-2[39])에서 540B(PaLM[7])로 증가하고 있다. 그러나, 현재 80GB에서 정점을 이루는 메모리 용량이 가장 높은 GPU조차도 확률적 경사 하강 기반 최적화를 수행할 때 이러한 방대한 파라미터 및 관련 최적화 상태들을 수용하기에 충분하지 않다. 그러한 거대한 모델들을 호스팅하기 위한 하나의 접근법은 많은 GPU들로부터 디바이스 메모리를 집계하는 것이다[24, 25, 47, 59]. 예를 들어, 트레이닝을 위해 1,000억 개의 파라미터를 갖는 모델을 피팅하기 위해서는 32개의 NVIDIA A100 GPU가 필요하다. 그러나 이러한 거대한 모델을 처음부터 교육하려면 수백만 개의 GPU 시간이 필요하므로 많은 고급 GPU 서버에 대한 예산이 항상 제한된 대부분의 학계 연구자에게 엄청난 비용을 도입한다. 다행히도 미리 훈련된 모델은 미세 조정을 통해 다양한 다운스트림 AI 작업에 사용될 수 있다[34, 53]. 본 논문에서는 대부분의 AI 연구자들이 접근할 수 있는 상품 서버의 단일, 심지어 저사양 GPU에 대한 거대한 모델 미세 조정에 초점을 맞춘다.\n' +
      '\n' +
      '기존 방법[29, 37, 40, 45, 55, 60]은 이기종 스토리지를 활용하여 LLM을 학습하고, 최첨단 방법 ZeRO-Infinity[41]은 GPU, CPU, NVMe 메모리를 활용하여 고급 GPU 서버에서 거대한 모델을 미세 조정한다. 특히 ZeRO-Infinity는 GPU 메모리에서 CPU 메모리, 심지어 NVMe 스토리지로 파라미터, 그라디언트, 옵티마이저 상태를 오프로드하고, 필요한 경우 호스트 메모리로 액티베이션을 오프로드하여 제한된 GPU 메모리 하에서 거대한 모델의 미세 조정을 가능하게 한다. ZeRO-Infinity는 최적화 상태들의 대규모 데이터 전송을 줄이기 위해 CPU에 가중치 업데이트를 수행한다. 기존 작업을 통해 고급 GPU 서버에서 거대한 모델 미세 조정을 허용하더라도 제품 서버의 소비자 GPU RTX 4090에서 미세 조정 시 여전히 두 가지 심각한 문제를 겪는다.\n' +
      '\n' +
      '각주 1: 각주:\n' +
      '\n' +
      '***제한된 최대 훈련 가능한 모델 크기.** ZeRO-인피니티는 호스트 메모리 용량이 512GB보다 작을 때 65B 모델을 미세 조정하지 못한다.\n' +
      '\n' +
      '*** 낮은 GPU 활용.** 충분한 양의 호스트 메모리로도 ZeRO-Infinity는 65B 모델을 미세 조정할 때 26%의 GPU 활용률만을 달성한다.\n' +
      '\n' +
      '근본적인 이유는 기존 작업이 원래 상품 서버가 아닌 고급 GPU와 거대한 CPU 메모리를 갖춘 DGX-2와 같은 많은 고급 GPU 서버를 위해 설계되었기 때문이다. 또한, 많은 고급 서버에서 미세 조정은 활성화 및 최적화 상태를 SSD에 오프로드할 필요가 없습니다. 간단히 말해서, 우리는 먼저 저사양의 GPU와 제한된 CPU 메모리 용량으로 저사양의 서버에서 거대한 모델을 미세 조정할 때 ZeRO-Infinity와 같은 기존 오프로딩 작업이 고성능을 달성하는 것을 방지하는 두 가지 고유한 기술적 문제를 식별한다.\n' +
      '\n' +
      '**1, Serializing Synchronous Out-of-core Optimizer 및 Backward Propagation.**와 같은 기존 작업들은 CPU에 의존하여 Synchronous Out-of-core Optimizer의 상태를 SSD로 구현함으로써 ZeRO-Infinity가 더 큰 모델을 미세 조정할 수 있도록 한다. 그러나 이러한 작업은 모델 동기화를 보존하기 위해 외부 코어 옵티마이저와 역방향 전파를 겹치지 않는다. 이와 같이, ZeRO-인피니티는 최적화 상태들을 업데이트하기 위해 상당한 양의 시간이 필요하다. 예를 들어, CPU 최적화기는 전체 훈련 시간의 최대 70%를 소비한다.2\n' +
      '\n' +
      '각주 2: Angel-PTM[(29)]과 같은 비동기 방식은 역방향 전파와 중첩되어 있는 Out-of-core 최적화기를 제시하지만, 모델 훈련 수렴에 영향을 줄 수 있는 비동기 최적화기 갱신 정책을 채택한다. 그러므로, 그것들은 이 논문의 범위를 벗어난다.\n' +
      '\n' +
      '**2, Activations Only Offloaded to CPU Memory, More to SSD.** ZeRO-Infinity와 같은 기존 작업은 많은 고급 서버에서 실행되도록 설계되었으며, 따라서 이러한 고급 서버는 액티베이션을 수용할 수 있는 충분한 큰 집계 메모리 용량을 가지고 있기 때문에, 더 이상 SSD가 아닌 호스트 메모리에만 액티베이션을 Offload한다. 그러나, 이러한 오프로딩 메커니즘은 상품 서버에서 호스트 메모리 용량에 높은 압력을 발생시키는데, 이는 호스트 메모리가 또한 옵티마이저와 같은 다른 오프로딩된 객체들에 의해 공유되기 때문이다. 따라서 기존의 연구들은 SSD에 대한 오프로드 액티베이션을 고려하지 않아 보다 큰 모델의 미세 조정을 가능하게 한다.\n' +
      '\n' +
      '100B 모델을 미세 조정할 때 SSD에 최적화 상태 또는 활성화를 오프로딩하면 GPU 활용률이 상당히 낮다는 것이 일반적인 지혜가 된다[(41; 49)]. 본 논문에서는 다음과 같이 묻는다.\n' +
      '\n' +
      '높은 GPU 활용률을 유지하면서 상품 서버에서 저사양의 GPU로 100B 모델을 미세 조정할 수 있는가?__Can we fine-tune the 100B model with low-end GPU in a commodity server\n' +
      '\n' +
      '이를 위해 저사양 GPU와 제한된 CPU 메모리 용량을 가진 저사양 서버에서 효율적인 100B 대용량 모델 미세조정이 가능한 저비용 트레이닝 프레임워크 Fuyou를 제시한다. 효율적인 활성화 스와핑을 위한 최적화 차원으로 SSD를 추가하고 역방향 전파와 겹치는 동기식 아웃오브코어 최적화기를 추가하는 것이 핵심 아이디어다. 특히 푸유는 세 가지 혁신으로 구성되어 있습니다.\n' +
      '\n' +
      '* **Synchronous Out-of-core CPU Optimizer Overlapped with Backward Propagation.** 단일 GPU에서 미세 조정 시 GPU 활용도를 극대화하기 위해, CPU가 Optimizer 상태를 업데이트하고 GPU가 완전히 유휴 상태인 Optimizer 단계를 제거하기 위해 Backward Propagation과 겹치는 동기식 Out-of-core CPU Optimizer를 제안한다. 동시에 Fuyou는 동기 모델 업데이트로 인해 훈련 수렴 속도를 변경하지 않습니다.\n' +
      '***GPU-CPU-SSD Fully-Pipelined Activation Swapping.** 훈련 가능한 모델 크기를 최대화하기 위해 GPU 메모리, CPU 메모리, NVMe SSD 간의 효율적인 데이터 스와핑을 가능하게 하여 상품 서버가 CPU/GPU 메모리 크기가 아닌 SSD 용량에 의해 크기가 제한되는 거대한 모델을 미세 조정할 수 있도록 하는 GPU-CPU-SSD Full-Pipelined 액티베이션 스와핑 기술을 제안한다.\n' +
      '**자동 활성화 스와핑 관리.** 기존의 스와핑 및 재연산 작업인 Capuchin[(37)]은 GPU PCIe 트래픽과 활성화 재연산 오버헤드만을 고려하여 PCIe 통신 시간이 최적화기와 역방향 전파가 겹치지 않기 때문에 역방향 전파 시간과 대략 같도록 스와핑 활성화 양을 결정한다. 그러나 Fuyou는 동기식 out-of-core CPU 최적화기와 역방향 전파가 겹치므로 1) 역방향 전파 시간과 최적화기 시간의 최대 시간을 사용하여 활성화를 스와핑 활성화 양을 결정하는 방법에 대해 Fuyou에게 새로운 도전을 제기한다. 활성화 스와핑 및 코어 외 CPU 최적화기는 소중한 SSD 대역폭과 GPU PCIe 대역폭을 놓고 경쟁합니다. 이를 위해 상품 서버에서 단일 GPU에서 학습 시 에폭 시간이 최소화되도록 자동으로 스와핑 활성화 양을 결정하는 자동 활성화 스와핑 관리 메커니즘을 제안한다. 자동 활성화 스와핑 관리의 주요 기여는 일정량의 스와핑 액티베이션이 주어진 에폭 시간을 대략적으로 예측하기 위한 비용 모델을 구축하는 것이다. 비용 모델을 감안할 때 Fuyou는 가능한 모든 스와핑 활성화 양을 고려하고 해당 시간을 추정하며 마지막으로 가장 작은 추정 비용을 선택한다.\n' +
      '\n' +
      '우리는 인기 있는 딥러닝 프레임워크 PyTorch[(35)]에서 Fuyou를 구현한다. 우리는 상품 서버에서 NVIDIA A100-80GB[(32)] 또는 RTX 4090[(33)]에서 Fuyou를 평가한다. GPT-3 175B 모델을 미세 조정하면 Fuyou는 4090에서 87 TFLOPS(53%의 피크 FLOPs3)와 A100-80GB에서 172 TFLOPS(86%의 피크 FLOPs)를 달성하는 반면 ZeRO-Infinity와 Colossal-AI는 미세 조정에 실패한다. RTX 4090에서 GPT-3 13B 모델을 미세 조정할 때 Fuyou는 ZeRO-Infinity에 비해 최대 3.47\\(\\times\\) TFLOPS에 도달한다.\n' +
      '\n' +
      ' \n' +
      '\n' +
      '## 2. Background\n' +
      '\n' +
      '딥러닝 훈련\n' +
      '\n' +
      '**훈련 단계.** 딥러닝 모델은 수학적 함수의 여러 층으로 구성된다. 모델을 수렴하기 위해 훈련 절차는 여러 번의 훈련 반복이 필요하다. 각 반복은 세 단계로 구성된다:\n' +
      '\n' +
      '*1) Forward stage, 여기서 모델은 훈련 데이터를 입력으로 하여 오차값을 계산한다. 각 레이어는 이전 레이어의 출력 액티베이션을 얻고, 출력 액티베이션을 다음 레이어로 전달한다.\n' +
      '*2) 후방 스테이지로, 여기서 에러 값들은 그라디언트들을 계산하기 위해 마지막 레이어로부터 첫 번째 레이어로 전파된다. 각 레이어는 다음 레이어로부터 에러 값들을 획득하고, 에러 값들 및 입력 활성화들에 따라 각 파라미터들의 그래디언트를 계산하고, 출력 에러 값들을 이전 레이어에 전달한다.\n' +
      '*3) 파라미터가 기울기에 따라 업데이트되는 옵티마이저 스테이지. LLM의 경우 모델 수렴성을 높이기 위해 Adam Optimizer(Kingmaa et al., 2014)가 일반적으로 채택된다. 아담 최적화기에서, 보조 최적화기 상태들은 파라미터 업데이트 프로세스를 매끄럽게 하기 위해 도입된다.\n' +
      '\n' +
      '**Memory Footprint.** 딥러닝 훈련에서 메모리 사용은 주로 두 가지 구성요소로 구성된다 : 1) 파라미터, 그라디언트, 옵티마이저 상태를 포함한 모델 상태. 구배는 후방 단계에서 생성되고 최적화기 단계에서 소비되는 반면, 파라미터 및 최적화기 상태는 트레이닝 프로세스 전반에 걸쳐 유지된다. 모델 상태의 크기는 모델 크기에만 비례합니다. 2) 중간값, 즉 활성화. 활동은 전진 단계에서 생성되고 후진 단계에서 소비된다. 활성화 크기는 모델 크기, 배치 크기 및 서열 길이에 따라 결정된다.\n' +
      '\n' +
      '**활성화 체크포인팅.**활성화 체크포인팅은 딥러닝 훈련에서 메모리 풋프린트를 감소시키는 메커니즘이다. 활성화 체크포인팅이 적용될 때, 순방향 스테이지 동안, 활성화의 서브세트, 즉 체크포인트만이 저장되는 반면, 다른 것들은 폐기된다. 백워드 스테이지 동안, 입력 활성화들이 폐기되는 레이어의 백워드 전파를 수행할 때, 폐기된 활성화를 얻기 위해 마지막 체크포인트로부터의 여분의 순방향 전파가 수행된다. 추가적인 순방향 전파는 재계산이라고 불린다.\n' +
      '\n' +
      '**활성화 스와핑.**활성화 스와핑은 메모리 저장을 위한 또 다른 메커니즘이다. 활성화들은 포워드 스테이지에서 생산되고 백워드 스테이지에서 소비되기 때문에, 활성화 스와핑이 적용되면, 포워드 스테이지 동안, 활성화들은 생산되고 나서 GPU 메모리로부터 스왑아웃되고, 백워드 스테이지 동안, 소비되기 전에 GPU 메모리로 스왑아웃된다. 활성화 스와핑은 체크포인팅 메커니즘과 결합될 수 있으며, 여기서 활성화는 전진 단계 동안 생성된 후 교체되거나 폐기된다. 이 경우, 활성화 스와핑은 재계산 오버헤드를 위해 통신 볼륨을 트레이드한다.\n' +
      '\n' +
      '### ZeRO-Offload와 ZeRO-Infinity의 최적화\n' +
      '\n' +
      'ZeRO-Infinity(Zebro-Infinity, 2017)는 이종의 스토리지를 활용하여 대형 모델을 훈련하는 최첨단 훈련 방법이다. 대규모 모델에 특화된 최적화된 딥러닝 라이브러리인 딥스피드(Zebro and Infinity, 2017)에 통합됐다. 딥스피드는 ZeRO-Infinity 외에 모델 상태를 CPU 메모리에 오프로드하는 최적화 방법인 ZeRO-Offload(Zebro and Infinity, 2017)도 통합한다. 이 하위 섹션에서는 이 두 가지 방법의 최적화를 소개할 것이다.\n' +
      '\n' +
      '**메모리 관리 최적화.** 제한된 GPU 메모리로 더 큰 모델 크기를 가능하게 하기 위해, ZeRO-Offload는 모델 상태를 CPU 메모리로 오프로드하고, ZeRO-Infinity는 모델 상태를 NVMe SSD로 더 오프로드한다. 활성화를 위해, ZeRO-Offload와 ZeRO-Infinity는 모두 활성화의 GPU 메모리 풋프린트를 감소시키기 위해 활성화 체크포인팅과 활성화 스와핑을 채택한다. 두 방법은 변압기 블록 사이의 체크포인트 활성화만 수행하는 반면 사용자는\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{|l|c|c|c|c|c|} \\hline  & \\multicolumn{2}{c|}{**Activation Offloading**} & \\multicolumn{3}{c|}{**Optimizer Stage**} \\\\ \\cline{2-6}  & **to CPU memory** & **to SSD** & **Out-of-core** &\n' +
      '\\begin{tabular}{c} **Overpapped** \\\\ **w/ Backward Stage** \\\\ \\end{tabular} & **Synchronous** \\\\ \\hline \\hline\n' +
      '**vDNN++**(Zebro and Infinity, 2017) & ✓ & ✗ & ✗ & ✗ & ✓ \\\\ \\hline\n' +
      '**SwapAdvisor**(Han et al., 2017) & ✓ & ✗ & ✗ & ✗ & ✓ \\\\ \\hline\n' +
      '**Beaumont et al.**(Beaumont et al., 2017) & ✓ & ✗ & ✗ & ✗ & ✓ \\\\ \\hline\n' +
      '**STR**(Steiner et al., 2017) & ✓ & ✗ & ✗ & ✗ & ✓ \\\\ \\hline\n' +
      '**Capuchini**(Papulkarni et al., 2017) & ✓ & ✗ & ✗ & ✗ & ✓ \\\\ \\hline\n' +
      '**SuperNeurons**(Han et al., 2017) & ✓ & ✗ & ✗ & ✗ & ✓ \\\\ \\hline\n' +
      '**DeFiNES**(Han et al., 2017) & ✓ & ✗ & ✗ & ✗ & ✓ \\\\ \\hline\n' +
      '**L2L**(Zebro and Infinity, 2017) & ✓ & ✗ & ✗ & ✗ & ✓ \\\\ \\hline\n' +
      '**ZeRO-Offload**(Zebro and Infinity, 2017) & ✓ & ✗ & ✓ & ✗ & ✓ \\\\ \\hline\n' +
      '**STRONGHOLD**(Zebro and Infinity, 2017) & ✓ & ✗ & ✓ & ✓ & ✓ \\\\ \\hline\n' +
      '**Angel-PIM**(Zebro and Infinity, 2017) & ✓ & ✗ & ✓ & ✓ & ✗ \\\\ \\hline\n' +
      '**Fuyou** & ✓ & ✓ & ✓ & ✓ & ✓ \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1. 대규모 모델 미세 조정을 위한 푸유와 다른 솔루션의 비교.\n' +
      '\n' +
      '체크포인트 간의 변압기 블록 수를 설정할 수 있습니다. ZeRO-Offload는 GPU 메모리에 체크포인트를 유지하고, ZeRO-Infinity는 CPU 메모리에 체크포인트를 추가로 오프로드한다. 검사점은 두 가지 방법 모두에서 SSD에 오프로드되지 않습니다.\n' +
      '\n' +
      '**Optimizer Stage Optimizations.** ZeRO-Offload 및 ZeRO-Infinity에서, 순방향 및 역방향 스테이지는 GPU에서 실행되는 반면, Optimizer stage는 CPU에서 실행된다. ZeRO-Offload 및 ZeRO-Infinity는 원래 ZeRO 분산 트레이닝 전략(Wang et al., 2018)에 기초하고, 따라서 다수의 노드들에 걸쳐 샤드 옵티마이저 상태들을 샤드하며, 각 노드는 단지 모델 파라미터들의 일부를 업데이트하고, 집합적 통신을 통해 다른 노드들로부터 업데이트된 파라미터들을 획득한다. 따라서, 각 노드는 최적화기 스테이지 동안 파라미터 업데이트의 일부만을 수행하여 CPU에 대한 계산 압력을 감소시킨다. 또한, CPU 상의 계산 오버헤드를 추가로 숨기기 위해, ZeRO-인피니티는 "1단계 지연 파라미터 업데이트" 메커니즘을 제공하는데, 이는 최적화기 스테이지와 다음 반복의 순방향 및 역방향 스테이지들을 중첩시킨다. 그러나, 이러한 메커니즘으로 파라미터 업데이트는 순방향 및 역방향 단계와 비동기화되어 모델 수렴에 영향을 미치므로 대부분의 데이터 과학자들이 선호하지 않는다. 또한 DeepSpeed 라이브러리의 오픈 소스 구현은 ZeRO-Offload에 대한 지연 파라미터 갱신 기능을 제공하지 않는다.\n' +
      '\n' +
      '## 3. Motivation\n' +
      '\n' +
      'ZeRO-Infinity는 원래 단일 GPU를 가진 상품 서버가 아닌 고급 DGX-2(Zhou et al., 2017) 서버를 위해 설계되었다. 따라서, ZeRO-Infinity는 단지 하나의 GPU를 갖는 상품 서버에서 불량하게 작동한다. 아래와 같이 단일 GPU를 사용하는 상품 서버에서 ZeRO-Infinity가 거대한 모델의 효율적인 미세 조정을 허용하는 것을 방지하는 두 가지 구체적인 심각한 문제를 식별한다:\n' +
      '\n' +
      '제한된 CPU 메모리 용량 하에서 제한된 훈련 가능한 모델 크기를 지원하는###\n' +
      '\n' +
      'ZeRO-Infinity는 CPU 메모리 용량이 제한된 상품 서버에서 175B 모델을 미세 조정하지 못한다. CPU 메모리 용량이 ZeRO-Infinity에 미치는 영향을 정량적으로 검증하기 위해, 서버 상에서 서로 다른 크기의 GPT-3(Beng et al., 2018) 모델을 미세 조정하고자 하며, 그 상세한 구성은 Subsection 5.1에 나타나 있다. 그 영향을 최소화하기 위해 배치 크기는 1이다.\n' +
      '\n' +
      '그림 0(a)는 다른 CPU 메모리 크기에서 ZeRO-인피니티의 최대 훈련 가능한 모델 크기를 나타내며, 여기서 저장 공간은 전체 훈련을 수용할 수 있는 충분한 저장 공간을 훨씬 넘어선 48TB이다. 우리는 ZeRO-Infinity가 미세 조정할 수 있는 최대 훈련 가능한 모델이 CPU 메모리 용량에 크게 제약을 받는다는 것을 관찰한다. 예를 들어, ZeRO-Infinity는 512GB CPU 메모리를 가진 65B 모델만 미세 조정할 수 있다. 기본적인 이유는 ZeRO-인피니티가 NVMe SSD보다 CPU 메모리에 활성화만 오프로드할 수 있기 때문이다. 이러한 오프로딩은 CPU 메모리에 높은 압력을 유발하며, 이는 다른 중간 객체들에 의해 공유된다.\n' +
      '\n' +
      '단일 GPU에서 작은 모델을 미세 조정할 때 낮은 GPU 활용도\n' +
      '\n' +
      '단일 GPU A100-80G에서 작은 모델을 미세 조정할 때 GPU 활용도를 정량적으로 분석한다. 그림 0(b)는 배치 크기를 변경할 때 한 번의 반복 내에서 총 경과 시간에 대한 GPU 사용 시간의 비율을 보여준다. 우리는 사용된 배치 크기가 상대적으로 큰 경우(32 등)에도 GPU 활용률이 28%에 불과하다는 것을 관찰한다. 근본적인 주요 이유는 다음과 같다:\n' +
      '\n' +
      '각주 4: 우리는 4090보다 A100-80G를 선택한다. 왜냐하면 4090은 컴퓨팅 파워가 더 높은 반면 A100-80G는 메모리와 같은 IO 대역폭이 더 높기 때문에 A100은 IO에 얽매일 기회가 더 적기 때문이다.\n' +
      '\n' +
      '* [leftmargin=*,noitemsep,topsep=0pt]\n' +
      '* ** 무거운 무게 업데이트 오버헤드.** GPU 메모리 용량이 제한된 더 큰 모델을 수용하기 위해 ZeRO-인피니티는 SSD에 FP32 최적화 상태를 저장하고 CPU에서 무게 업데이트를 수행한다. 그러나 ZeRO-Infinity는 순방향 전파 단계와 역방향 전파 단계 후에 가중치 및 최적화기 상태를 한 번 업데이트하여 CPU 최적화기 단계가 GPU 연산이 발생하는 순방향 및 역방향 전파와 겹치지 않음을 나타낸다. 가중치 업데이트 단계 전체에 걸쳐, GPU는 유휴 상태이며, GPU 상에서 통신 또는 계산 작업이 실행되지 않는다. 분산 훈련에서, ZeRO-인피니티는 모든 머신들에 걸쳐 최적화 상태들을 균등하게 분배한다. 많은 노드들로부터 메모리 대역폭 및 SSD-to-CPU 대역폭을 집계함으로써, CPU Adam (Kingmae et al., 2014)\n' +
      '\n' +
      '그림 1. ZeRO-Infinity의 두 가지 이슈는 Fuyou의 디자인에 동기를 부여한다. 우리는 A100-80GB GPU에서 실험을 수행한다.\n' +
      '\n' +
      '각 반복의 사소한 시간 비율에 기여합니다. 그러나, 서버 내에서 단지 하나의 GPU로 트레이닝할 때, 최적화기 파라미터들의 완전한 세트를 업데이트하는 것은 매우 시간 소모적인 작업이 될 수 있다. 그림 (c)c는 ZeRO-Infinity에서 훈련 단계에 대한 CPU 최적화기 단계의 시간 비율을 보여준다. 최적화 단계는 GPU가 완전히 유휴 상태인 훈련 단계의 40%-70%가 소요되는 것을 관찰한다. 이는 달성 가능한 GPU 이용률에 상당한 영향을 미친다.\n' +
      'Forward and Backward Propagation.** 도 (a)a는 배치 크기가 32인 A100-80G GPU 상에서 13B 모델을 트레이닝하는 ZeRO-Infinity의 구체적인 데이터 흐름을 예시한다. NVIDIA Nsight(tm) 시스템(NVIDIA et al., 2017)으로부터, 순방향 및 역방향 전파 동안 GPU 커널은 CPU-GPU 및 CPU-SSD 통신과 너무 많이 중첩되지 않는데, 이는 ZeRO-Infinity가 SSD에 기울기 및 파라미터를 오프로드할 때 통신-계산 중첩을 최적화하지 않기 때문이다. 예를 들어, 순방향 전파 동안 \\(P^{i}\\)(SSD to CPU), \\(P^{i}\\)(CPU to GPU), \\(C^{i}_{G}\\)(GPU), \\(A^{i}\\)(GPU to CPU)가 직렬화된다.\n' +
      '\n' +
      '##4. Fuyou의 디자인\n' +
      '\n' +
      '### Design Overview\n' +
      '\n' +
      '이러한 ZeRO-Infinity 문제를 해결하기 위해 저사양 GPU를 탑재한 저사양 서버에서 효율적인 100B 대용량 모델 미세조정이 가능한 저비용 훈련 프레임워크인 Fuyou를 소개한다. 핵심 아이디어는 SSD-CPU 통신을 파이프라인 최적화 차원으로 추가하여 GPU 활용률을 극대화하기 위한 체계적인 접근법과 Fuyou가 미세 조정할 수 있는 모델 크기로부터 계산 및 데이터 스와핑을 신중하게 공동 최적화하는 것이다. Fuyou는 1) Fuyou의 자동 스와핑 관리를 위한 필수 데이터를 수집하는 프로파일링 단계(하위 섹션 4.2), 2) 훈련 수렴 속도를 저하시키지 않으면서 최적화 단계 동안 GPU가 유휴 상태가 되는 것을 회피하는 역방향 전파와 중첩된 동기식 아웃-코어 CPU 최적화기(하위 섹션 4.3), 3) 더 큰 모델 크기를 미세 조정할 수 있는 완전 파이프라인 방식의 GPU-CPU-SSD 2단계 활성화 스와핑을 가능하게 하는 완전 파이프라인 방식의 활성화 스와핑 메커니즘(하위 섹션 4.4), 4) 추가 모델 크기를 미세 조정할 수 있는 완전 파이프라인 방식의 활성화 스와핑 메커니즘(하위 섹션 4.4), 4) 추가 모델 크기를 미세 조정할 수 있는 완전 파이프라인 방식의 활성화 스와핑 양을 자동으로 결정하는 자동 활성화 스케줄링 전략(자동 활성화 스케줄링 전략)으로 구성된다.\n' +
      '\n' +
      '그림 3. Fuyou Overview.\n' +
      '\n' +
      '그림 2. Fuyou와 ZeRO-Infinity의 비교.\n' +
      '\n' +
      '에포크 시간을 최소화합니다(서브섹션 4.5). 도 3은 Fuyou의 전체 구조를 예시한다.\n' +
      '\n' +
      '### Profiling Stage\n' +
      '\n' +
      '프로파일링 단계에서 Fuyou는 추가 최적화를 위해 모델 및 하드웨어 설정 모두에서 필수 데이터를 수집합니다.\n' +
      '\n' +
      '**프로파일링 설정** 이 단계에서 Fuyou는 어떠한 최적화도 가능하게 하지 않고 모든 활성화 및 모델 상태를 NVMe SSD로 오프로드하므로 모든 계산 및 통신은 직렬로 실행된다. 따라서 각 계층의 계산/통신 비용에 대한 대략적인 정확한 예측을 얻을 수 있다.\n' +
      '\n' +
      '**프로파일링 목표** 이 단계에서 Fuyou는 다음과 같은 정보를 생산할 것이다. 먼저 초기화 중에 PyTorch 모델 정의를 취합니다. 런타임 동안 파이토치 훅을 통해 각 연산자를 파싱한 다음 각 연산자에 대한 활성화 및 매개변수의 크기를 가져옵니다. 또한, 전방 연산 시 각 연산자의 연산 시간을 기록한다. 둘째, 초기화 시 하드웨어 설정으로부터 시스템 토폴로지와 메모리 용량을 얻고, 각 PCIe 링크의 최대 PCIe 대역폭과 최대 CPU 메모리와 GPU 메모리 사용량을 모니터링한다.\n' +
      '\n' +
      '### 역전파 및 최적화기 중첩\n' +
      '\n' +
      'GPU 활용도를 극대화하기 위해 백워드 전파와 중복되는 동기식 아웃 오브 코어 CPU 최적화기를 제안한다. 당사의 최적화기는 ZeRO-인피니티의 동기식 코어 외 CPU 최적화기를 기반으로 합니다. 이 하위 섹션에서는 최적화기를 후진 단계와 겹치게 할 수 있는 기회와 구체적인 설계에 대해 설명한다.\n' +
      '\n' +
      '**Overlapping Opportunity.** 한 GPU 상의 Fuyou에서의 모델 학습 과정은 GPU 연산(R1), CPU 연산(R2), CPU-to-GPU 통신(R3), GPU-to-CPU 통신(R4), SSD I/O(R5) 등의 연산 및 통신 자원을 포함한다. SSD I/O는 단순하므로 한 방향만 동시에 활용할 수 있습니다. 역방향 전파 동안, R1, R3, R4, R5는 활용되고, R2는 예비된다. 최적화 단계 동안 R2, R5가 사용되는 반면 R1, R3, R4는 예비이다. SSD I/O를 제외하고 이 두 단계는 전혀 다른 자원을 활용한다. 이는 훈련 과정을 가속화하기 위해 두 단계를 겹칠 가능성을 남긴다.\n' +
      '\n' +
      '또한, 백워드 및 옵티마이저 스테이지들을 중첩함으로써 전체 SSD I/O를 감소시킬 수 있다. 중첩 없이, 역방향 전파 동안, GPU가 그라디언트를 계산할 때, 이들은 최적화기 스테이지에 사용될 때까지 SSD들에 일시적으로 저장될 필요가 있다. 두 단계가 중첩될 때, 역방향 전파에서 생성된 구배는 SSD에 저장될 필요 없이 옵티마이저 프로세스에 의해 직접 소비될 수 있다. 따라서, 후방 및 최적화 단계가 중복되는 것은 모든 경우에 유익하다. SSD I/O가 배치 크기와 SSD의 수가 모두 작을 때 발생하는 두 단계 전체에 걸쳐 시스템 병목 현상일 때, 두 단계를 겹치면 기울기에 대한 SSD I/O가 절약되므로 전체 학습 시간이 단축된다. SSD I/O가 병목 현상이 아닌 경우, 두 단계는 연산과 통신 자원의 충돌이 없으므로 두 단계를 겹치면 자연스럽게 전체 학습 시간을 줄일 수 있다.\n' +
      '\n' +
      '**콘크리트 설계.** 도 2c는 두 단계를 중첩한 예를 도시한 것이다. 초기화 시, 메인 트레이닝 프로세스는 최적화기 계산을 위한 CPU 서브 프로세스를 시작한다. 두 프로세스는 필요한 동기화 외에도 완전히 분리됩니다. 동기화는 PyTorch에서 제공하는 CUDA 이벤트를 통해 수행된다. GPU 상에서 계산 작업을 수행할 때, 대응하는 오퍼레이터의 최적화기 상태는 CPU에 비동기적으로 프리페칭된다. 그래디언트 연산이 GPU 상에서 완료되어 CPU 메모리에 오프로드된 후, CPU는 아담 연산을 비동기적으로 수행하는 반면, GPU는 다음 연산자에 대한 연산을 계속 실행한다. 이 예에서, 오버랩된 후방-최적화 스테이지에 대한 실행 시간은 개별 후방 스테이지에 비해 크게 증가되지 않는다.\n' +
      '\n' +
      'Fuyou는 또한 최적화 프로세스 내에서 병렬성을 향상시키는 경향이 있다. 푸유에서는 가중치 업데이트가 매개변수 그룹에서 수행됩니다. 직렬화된 환경에서 전체 워크플로우는 1) SSD에서 그룹 \\(i\\)의 최적화 상태 읽기, 2) 그룹 \\(i\\)의 최적화 상태 업데이트, 3) 업데이트된 그룹 \\(i\\)의 데이터를 다시 SSD로 쓰는 세 단계로 나뉜다. 이 경우 CPU 연산과 SSD I/O가 직렬화된다. Fuyou에서는 지연 쓰기-백 전략을 채택한다. 즉, 그룹 \\(i-1\\)의 갱신이 완료된 후 그룹 \\(i\\)의 쓰기-백이 수행된다. 이렇게 함으로써, 단계 2는 단계 1 및 단계 3과 중첩될 수 있고, 이에 따라 CPU 계산 및 SSD I/O 자원을 더 잘 활용할 수 있다.\n' +
      '\n' +
      '완전 파이프라인 작동 스왑핑\n' +
      '\n' +
      '도 2b는 Fuyou의 파이프라인 실행 전략의 예를 예시한다. 포워드 및 백워드 전파 동안 Fuyou는 GPU 계산 및 PCIe 통신(SSD-CPU 및 CPU-GPU)을 최상의 상태로 오버랩할 작정이다. 최적화 단계 동안 Fuyou는 CPU 계산과 SSD 액세스도 겹칩니다. 따라서, 이 전략은 순방향 및 역방향 전파 동안 최대 GPU 활용을 보장하여 ZeRO-인피니티의 직렬 실행 문제를 해결한다.\n' +
      '\n' +
      '깊이 파인 파이프라인 전략의 설계는 사소한 것이 아니다. 주요 과제는 데이터를 언제 프리페치할 것인지, 그리고 얼마나 많은 데이터를 프리페치할 것인지를 결정하는 것이다. 선인출이 부족하면 통신과 연산이 직렬화되는 반면, 과도한 선인출은 GPU 메모리에 불필요한 압력을 도입하여 훈련 가능한 모델 크기를 제한한다.\n' +
      '\n' +
      '학습 가능한 모델 크기를 손상시키지 않고 효율적으로 실행 전략을 구현하기 위해 GPU 메모리 인식 FIFO 프리페칭 메커니즘을 제안한다. 프로파일링 단계에서 획득한 최대 GPU 메모리 활용으로 프리페칭 파라미터 및 활성화에 대한 나머지 GPU 메모리 공간을 할당한다. 따라서 Fuyou는 파이프라인 통신에 사용될 수 있는 파라미터, 활성화 및 그라디언트를 저장하기 위한 FIFO 버퍼를 생성한다. FIFO 버퍼가 비어 있을 때마다 Fuyou는 GPU 활용도를 최대화할 수 있도록 다음 레이어의 활성화와 파라미터를 프리페치한다.\n' +
      '\n' +
      '이 디자인은 두 가지 문제를 해결합니다. 첫째, 현재 모듈에서 필요로 하는 데이터를 프리페치 큐에서 간단히 검색할 수 있기 때문에 프리페치 시기를 결정한다. 둘째, 가용 GPU 메모리의 제약 조건 내에서 선인출을 최대화함으로써 선인출 데이터 볼륨 문제를 해결한다. 초기에는 GPU 내에서 데이터 프리페칭 큐의 크기를 결정한다. 이후 SSD-CPU 대역폭에 대한 GPU-CPU 대역폭의 비율을 기반으로 CPU에서 데이터 프리페칭 큐의 크기를 확인한다.\n' +
      '\n' +
      '또한, CPU 저장 자원을 효율적으로 사용하고 시스템을 보다 유연하게 만들기 위해 Fuyou는 활성화의 오프로딩 위치를 동적으로 결정한다. CPU 메모리 리소스가 액티베이션을 저장하기에 충분한 경우, 액티베이션은 SSD I/O 압력을 감소시키기 위해 SSD에 오프로드되는 대신에 CPU 메모리에 저장된다.\n' +
      '\n' +
      '### 자동 활성화 스케쥴링\n' +
      '\n' +
      '활성화 체크포인팅을 사용하여 메모리 사용량을 줄이고 활성화 체크포인트를 SSD에 추가로 오프로드하여 GPU 및 CPU의 저장 공간을 확보합니다. 활성화 재연산은 GPU 연산에 오버헤드를 가져오기 때문에, 재연산의 오버헤드를 최소화하기 위해, 자동으로 스와핑 액티베이션의 양을 결정하는 자동 활성화 스와핑 관리 메커니즘을 제안한다.\n' +
      '\n' +
      '**Notations.** 이 하위 섹션의 Notations는 아래에 나열되어 있다. \\ (N_{\\text{SSD}}\\)은 사용된 SSD의 수, \\(h\\)은 모델의 숨겨진 차원, \\(l\\)은 레이어의 수, \\(b\\)은 배치 크기, \\(s\\)은 시퀀스 길이, \\(p\\)은 총 매개변수 카운트이다. 이 값은 훈련 설정에 따라 결정됩니다. 또한, \\(BW_{GPU}\\)은 GPU와 CPU 사이의 PCIe 대역폭, \\(T_{\\text{f}}\\)은 순방향 스테이지의 실행 시간, \\(T_{\\text{f}}^{\\text{comp}}\\)은 순방향 스테이지 동안 GPU 계산 시간, \\(T_{\\text{o}}^{\\text{comp}}\\)은 최적기를 위한 CPU 계산 시간, \\(BW_{\\text{SSC}}\\)은 단일 SSD에서 CPU로의 대역폭, \\(BW_{\\text{C2S}}\\)은 순방향 스테이지 동안 FLOPS에서 GPU 처리량이다. 이 값은 프로파일링 단계에서 획득됩니다. \\ (D_{\\text{f}}\\)는 순방향 전파 단계에서 GPU에서 SSD로의 활성화 체크포인트의 통신 볼륨을 나타내고, \\(D_{\\text{b+o}}\\)는 중첩된 역방향 최적화 단계에서 SSD에서 GPU로의 체크포인트 통신 볼륨을 나타낸다. \\(D_{\\text{f}}\\)와 \\(D_{\\text{b+o}}\\)는 동일하기 때문에 다음 텍스트에서는 \\(D_{\\text{f}}\\)에 대해서만 논의한다.\n' +
      '\n' +
      '**몇 개의 활성화들을 교환해야 하는가?** 우리의 최적화 목표는 전체 훈련 단계 \\(T_{\\text{iter}}\\)의 총 시간을 최소화하기 위해 적절한 \\(D_{\\text{f}}\\)을 선택하는 것이며, 이는 수학식 1과 같이 나타낼 수 있다.\n' +
      '\n' +
      '\\[T_{\\text{iter}}=T_{\\text{f}}+T_{\\text{b+o}} \\tag{1}\\]\n' +
      '\n' +
      '순방향 단계에서는 GPU(T_{\\text{f}}^{\\text{com}}), GPU와 CPU 사이의 데이터 통신 시간(T_{\\text{f}}^{\\text{CPU}}), SSD와 CPU 사이의 데이터 통신 시간(T_{\\text{f}}^{\\text{SSD}}}) 중 실행 시간이 최대이다. 이는 수학식 2로 표현될 수 있다.\n' +
      '\n' +
      '\\[T_{\\text{f}}=\\max\\left(T_{\\text{f}}^{\\text{comp}},T_{\\text{f}}^{\\text{GPU}},T_{\\text{f}}^{\\text{SSD}\\right}\\tag{2}\\]\n' +
      '\n' +
      '여기서, \\(T_{\\text{f}}\\) 및 \\(T_{\\text{f}}^{\\text{comp}}\\)는 프로파일 단계에서 측정된다. 통신 시간\\(T_{\\text{f}}^{\\text{GPU}}\\)과\\(T_{\\text{f}}^{\\text{SSD}}\\)은 통신 볼륨을 대역폭으로 나눈 값으로 추정할 수 있다. 여기서 SSD-CPU-GPU 경로에서 fp16 파라미터의 데이터 크기는 \\(2p\\)이다. GPU에서의 통신은 이중이므로 GPU와 CPU(T_{\\text{f}}^{\\text{GPU}}\\) 사이의 통신 시간은 두 방향에서 최대이며, 이는 수학식 3에 의해 추정될 수 있다. SSD에서의 통신은 단순하므로 SSD와 CPU(T_{\\text{f}}^{\\text{SSD}}\\) 사이의 통신 시간은 두 방향의 합이며, 이는 수학식 4에 의해 추정될 수 있다.\n' +
      '\n' +
      '\\[T_{\\text{f}}^{\\text{GPU}}=\\max\\left(\\frac{2p}{BW_{\\text{GPU}}},\\frac{D_{\\text{f}}}{BW_{\\text{GPU}}}\\right}\\tag{3}\\t}\n' +
      '\n' +
      '\\[T_{\\text{f}}^{\\text{SSD}=\\frac{2p}{BW_{\\text{SC}}N_{\\text{SSD}}+\\frac{D_{\\text{f}}{BW_{\\text{C2S}}N_{\\text{SSD}}\\tag{4}\\tag{4}}\n' +
      '\n' +
      '중첩된 역방향 옵티마이저 단계의 경우, GPU(T_{\\text{b}}^{\\text{comp}\\), CPU(T_{\\text{o}}^{\\text{comp}\\), GPU와 CPU 사이의 데이터 통신 시간(T_{\\text{b+o}}^{\\text{GPU}\\), SSD와 CPU(T_{\\text{b+o}}^{\\text{SSD}\\)의 데이터 통신 시간 중에서 실행 시간이 최대이며, 이는 수학식 5로 표현될 수 있다.\n' +
      '\n' +
      '\\[T_{\\text{b+o}}=\\max\\left(T_{\\text{b}}^{\\text{comp}},T_{\\text{o}}^{\\text{comp}},T_{\\text{b+o}}^{\\text{GPU}},T_{\\text{b+o}}^{\\text{SSD}}\\right) \\tag{5}\\\\text{b}}\n' +
      '\n' +
      '여기서, \\(T_{\\text{o}}^{\\text{comp}}\\)는 프로파일 단계에서 측정될 수 있다. 전진단과 유사하게 통신 시간\\(T_{\\text{b+o}}^{\\text{GPU}\\)과 \\(T_{\\text{b+o}}^{\\text{SSD}\\)은 통신 볼륨을 대역폭으로 나눈 값으로 추정할 수 있다. 중첩된 후방 및 최적화 스테이지 동안, fp16 파라미터들은 SSD-CPU-GPU 경로에서 전달되고, fp16 구배들은 GPU에서 CPU로 전달되고, fp32 모델 상태들은 SSD에서 CPU로 판독되고, 업데이트된 fp32 모델 상태들 및 fp16 파라미터들은 CPU에서 SSD로 기록된다. 따라서, 통신 시간은 수학식 6 및 수학식 7에 의해 추정될 수 있다.\n' +
      '\n' +
      '\\[T_{\\text{b+o}}^{\\text{GPU}}=\\max\\left(\\frac{2p}{BW_{\\text{GPU}}),\\frac{2p+D_{\\text{f}}}{BW_{\\text{GPU}}}\\right}\\tag{6}\\right}\n' +
      '\n' +
      '\\[T_{\\text{b+o}}^{\\text{SSD}}}\\frac{12p+2p+D_{\\text{f}}{BW_{\\text{SC}}N_{\\text{SSD}}+\\frac{12p+2p}{BW_{\\text{C2S}}N_{\\text{SSD}}\\tag{7}\\tag{SC}}\n' +
      '\n' +
      '백워드 스테이지(T_{\\text{b}^{\\text{comp}\\)에 대한 GPU 계산 시간은 백워드 전파 시간과 재계산 시간과 동일하다. 백워드 전파 시간은 순방향 시간\\(2\\times T_{\\text{fw}}^{\\text{com}}\\)의 2배로 추정할 수 있다. (RC(D_{\\text{f}})\\)를 재계산할 시간으로 한다. 더 많은 활성들이 교환되기 때문에, 재계산하는데 더 적은 시간이 필요하다. \\(RC(D_{\\text{f}})\\)는 \\(D_{\\text{f}}\\)의 감소 함수이다. 따라서, \\(T_{\\text{b}}^{\\text{comp}}\\)는 수학식 8과 같이 추정될 수 있다.\n' +
      '\n' +
      '\\[T_{\\text{b}}^{\\text{comp}}=2\\times T_{\\text{f}}^{\\text{comp}}+RC(D_{\\text{f}}) \\tag{8}\\]\n' +
      '\n' +
      '이상의 결과로부터, \\(T_{\\text{f}}^{\\text{comp}\\)와 \\(T_{\\text{o}}^{\\text{comp}\\)은 \\(D_{\\text{f}}\\)과 무관하다. \\(T_{\\text{f}}^{\\text{comp}\\)과 \\(T_{\\text{o}}^{\\text{comp}\\)은 서로 독립적이다. (T_{\\text{f}}^{\\text{comp}\\)는 모델 크기와 배치 크기와 관련이 있는 반면, (T_{\\text{o}}^{\\text{comp}\\)는 모델 크기와만 관련이 있다. \\(T_{\\text{f}}^{\\text{GPU}\\),\\(T_{\\text{f}}^{\\text{SSD}\\),\\(T_{\\text{b*o}}^{\\text{GPU}\\),\\(T_{\\text{b*o}}^{\\text{SSD}\\)의 경우,\\(D_{\\text{f}\\)이 증가하면 실행 시간이 증가한다. 또한, \\(D_{\\text{f}\\)가 증가하면 \\(T_{\\text{b}^{\\text{comp}\\)의 실행 시간이 감소할 것이다.\n' +
      '\n' +
      '한편, 활성화 체크포인트 데이터의 양은 GPU 메모리 용량에 의해 제한된다. 체크포인트가 너무 적으면 역방향 전파 중에 생성되는 임시 중간 변수의 수가 너무 많아 메모리 오버플로가 발생할 수 있습니다. 메모리 오버플로우를 방지하면서 적응적인 스왑 스케줄링 전략을 구현하기 위해 프로파일 단계에서 초기 값 \\(D_{\\text{f}}\\)을 사용자가 결정한 \\(D_{\\text{start}}\\)으로 설정한다. 기본적으로 \\(D_{\\text{start}}\\)는 각 변압기 블록에 대해 하나의 활성화 체크포인트를 적용하도록 설정되며, 이는 ZeRO-Infinity가 채택한 전략이다. 이 초기 전략은 트랜스포머 블록에 대한 총 파라미터 크기는 \\(12\\times h\\times h\\) 바이트이며, 각 트랜스포머 블록에 대한 활성화를 저장하려면 \\(b\\times s\\times h\\) 바이트 GPU 공간만 필요하기 때문에 큰 통신 오버헤드로 이어지지 않는다. 큰 LLM의 경우 \\(h\\)이 큰 경우가 많기 때문에 활성화 크기가 매개변수 크기에 비해 작다.\n' +
      '\n' +
      '초기화 후, 자동 스케줄링 엔진은 각 학습 반복에 대해 적응적으로 반복한다. 본 논문에서는 초기값에서 D\\(D\\text{f}\\)가 감소하면 메모리 오버플로우의 위험이 발생하므로 전체 학습시간을 단축하고자 한다. 그러나 GPU 백워드 전파가 중첩된 백워드 및 옵티마이저 단계에 대한 병목 현상, 즉 \\(T_{\\text{b*o}=T_{\\text{b}^{\\text{comp}})일 때 더 많은 활성화들을 스와핑함으로써 전체 트레이닝 시간을 줄일 수 있다. 일반적으로 배치 크기가 더 큰 시나리오에서 발생합니다. 다른 경우에, 활성화의 스왑을 증가시키는 것은 전체 트레이닝 시간의 증가로 이어진다. 게다가, 우리의 전체 트레이닝 시간 이득 \\(T_{MAX}\\)의 상한은 수학식 9에 의해 계산될 수 있다.\n' +
      '\n' +
      '\\[T_{\\text{max}=T_{\\text{b}}^{\\text{comp}-\\max(T_{\\text{b*o}}^{\\text{GPU},T_{\\text{b*o}}^{\\text{SSD}}) \\tag{9}\\\n' +
      '\n' +
      '따라서, \\(D_{\\text{f}}\\)에 대한 상한은 수학식 10과 같이 정의될 수 있다.\n' +
      '\n' +
      '\\[D_{\\text{max}=T_{\\text{max}}\\times\\min(BW_{GPU},BW_{\\text{C2S}}N_{\\text{SSD},BW_{\\text{S2C}}N_{\\text{SSD}}) \\tag{10}\\\n' +
      '\n' +
      'D\\(D\\text{f}\\)가 증가하면 \\(T\\text{b*o}^{\\text{GC}\\)과 \\(T\\text{b*o}^{\\text{SC}\\)이 모두 증가하며, 잠재적으로 순방향 단계의 전체 시간을 증가시킬 수 있다. 따라서 식 11과 같이 \\(D_{\\text{f}}\\)의 제약조건을 얻을 수 있다.\n' +
      '\n' +
      '\\[D_{\\text{start}}\\leq D_{\\text{f}}\\leq D_{\\text{MAX}}\\tag{11}\\]\n' +
      '\n' +
      '스왑할 활성화는 무엇인가? 우리는 스왑할 활성화를 분석하여 최적의 \\(D_{\\text{f}}\\을 계산한다. 변압기 블록에는 Linear_qkv, Linear_htoh, Linear_htoh, Linear_hto4h 및 Linear_4htoh의 4개의 레이어가 포함되어 있으며, 출력 활성화 형태와 FLOP가 표 2에 나열되어 있다. 스왑 오버헤드를 최소화하기 위해 재계산 시간 뒤에 스왑 시간을 최대한 숨기는 것이 최적화 목표이다.\n' +
      '\n' +
      '스왑 시간(\\(ST\\))은 활성화 크기에 비례하므로 Linear_htoh의 스왑 시간을 단위 스왑 시간\\(t_{\\text{s}}\\)으로 정의하여 표 2에서 각 레이어의 스왑 시간을 ST로 계산할 수 있다. 최적화 목표에 따라 각 레이어의 스왑 편익 계수(\\(SBF\\))를 수학식 12와 같이 정의할 수 있다.\n' +
      '\n' +
      '\\[SBF=\\frac{FLOP}{ST} \\tag{12}\\]\n' +
      '\n' +
      '각 층의 \\(SBF\\)의 비율은 표 2에 나열되어 있다. \\(SBF\\)에 따라, 우리는 스와핑을 위한 활성화를 선택하기 위해 우선화된 활성화 스와핑 전략을 채택한다. 프로파일링 스테이지 동안, 모든 레이어들은 두 개의 큐들로 푸시되며, 여기서 높은 우선순위의 큐는 Linear_4htoh 레이어들을 포함하고 낮은 우선순위의 큐는 다른 레이어들을 포함한다. 지금까지 우리는 활성화를 교환하기 위한 구체적인 계층의 순서를 가지고 있다.\n' +
      '\n' +
      '최적의 \\(D_{\\text{f}}\\)와 스왑할 대응하는 레이어를 찾기 위해, 우리는 스왑할 레이어를 반복한다. 바이트 단위의 레이어의 활성화 크기를 \\(S_{\\text{layer}}\\)으로 한다. 각 레이어에 대해, 레이어 스와핑은 \\(T_{\\text{b}}^{\\text{comp}\\)을 \\(Tpuft\\times FLOP_{\\text{layer}\\)만큼 빼고, \\(T_{\\text{b*o}}^{\\text{GPU}\\)을 \\(S_{\\text{layer}/BW_{\\text{GPU}\\)만큼 더하고, \\(T_{\\text{b*o}}^{\\text{SSD}\\)을 \\(S_{\\text{layer}/BW_{\\text{S2C}}N_{\\text{SSD}\\)만큼 더한다. 따라서, 우리는 새로운 반복시간\\(T_{\\text{iter}}\\)을 수학식 1에 의해 계산할 수 있다. 우선 순위가 가장 높은 \\(i\\) 레이어를 스와핑할 때 \\(T_{\\text{iter}}\\)을 반복적으로 계산함으로써, 최소의 \\(T_{\\text{iter}}\\)을 가지면서 수학식 11을 만족하는 최적의 \\(i\\)을 선택할 수 있다. 따라서 우선 순위가 가장 높은 첫 번째 \\(i\\) 레이어는 스와핑을 위한 레이어이다.\n' +
      '\n' +
      '## 5. Evaluation\n' +
      '\n' +
      '### Experimental Setup\n' +
      '\n' +
      '**평가 기계.** 구성을 표 3에 요약한 서버에 대해 모든 실험을 수행합니다.\n' +
      '\n' +
      '**워크로드.** 우리는 일반적인 100B 수준의 LLM인 평가 실험을 위해 GPT-3 모델을 선택한다. 우리는 GPT-3 논문(Cheng et al., 2018)에서 GPT-3 13B와 GPT-3 175B의 동일한 하이퍼파라미터를 채택한다. 표 4와 같이 보다 다양한 모델 사이즈에 Fuyou를 평가하기 위한 일련의 커스텀 구성을 설정했다. 우리는 ILaMA(Wang et al., 2019)를 따라 GPT-3 33B 및 GPT-3 65B의 하이퍼파라미터를 선택하고, GPT-3 175B를 따라 GPT-3 135B의 하이퍼파라미터를 비례적으로 확장한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{|c||c|c|c|c|} \\hline\n' +
      '**Layer** & **Act Shape** & **FLOP** & **ST** & **SBF Ratio** \\\\ \\hline \\hline\n' +
      '**Linear\\_qkv** & \\((b,s,\\hat{h})\\) & \\(6bs\\hat{h}^{3}\\) & \\(3t_{\\text{s}}\\) & \\(1\\) \\\\ \\hline\n' +
      '**Linear\\_htoh** & \\((b,s,\\hat{h})\\) & \\(2bs\\hat{h}^{3}\\) & \\(t_{\\text{s}}\\) & \\(1\\) \\\\ \\hline\n' +
      '**Linear\\_htoh** & \\((b,s,\\hat{h})\\) & \\(8bs\\hat{h}^{3}\\) & \\(4t_{\\text{s}}\\) & \\(1\\) \\\\ \\hline\n' +
      '**Linear\\_4htoh** & \\((b,s,\\hat{h})\\) & \\(8bs\\hat{h}^{3}\\) & \\(t_{\\text{s}}\\) & \\(4\\) \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2. 활성화 블록 스왑의 이점.\n' +
      '\n' +
      'GPT-3 276B, GPT-3 412B 및 GPT-3 805B. 모든 평가 실험에서, 시퀀스 길이는 1024로 설정된다.\n' +
      '\n' +
      '**기준 구성**푸유의 유효성을 평가하기 위해 3개의 오픈 소스 기준선을 선택합니다. 첫 번째 베이스라인은 현재 널리 채택되고 있는 오픈 소스 이종 훈련 시스템인 ZeRO-Infinity(Wang et al., 2019)이다. 두 번째 베이스라인은 ZeRO-Offload(Wang et al., 2019)이며, 이는 SSD 대신 모델 상태를 CPU 메모리에 오프로드하므로 ZeRO-Offload는 훨씬 더 작은 모델만을 미세 조정할 수 있다. ZeRO-Infinity 및 ZeRO-Offload에 대해, 딥스피드의 공식 예(Zhou et al., 2019)로 실험을 실행한다. 우리가 사용하는 릴리즈 버전은 0.9.3으로 각 트랜스포머 블록에 활성화 체크포인트 입도를 설정하고 CPU 메모리에 오프로드 체크포인트를 설정한다. 두 기준선 모두 CPU에서 최적화기 단계를 수행합니다. ZeRO-Infinity는 SSD에 파라미터 및 최적화 상태를 오프로드하는 반면, ZeRO-오프로드는 CPU 메모리에 파라미터를 오프로드한다.\n' +
      '\n' +
      '세 번째 기준선은 인기 있는 10억 규모의 모델 훈련 솔루션인 Colossal-AI이다. 우리는 공식 GPT-2 예(Zhou et al., 2019)를 기반으로 버전 0.3.0의 공식 도커 릴리스로 Colossal-AI를 평가한다. Colossal-AI의 경우, 각 트랜스포머 블록에 대해 체크포인트를 설정하고, CPU에 파라미터 및 그라디언트를 오프로드하고, SSD에 옵티마이저 상태를 오프로드하고, CPU에 옵티마이저 스테이지를 완료한다. 지원되지 않기 때문에 Colossal-AI에서 활성화 체크포인트를 오프로드하지 않습니다.\n' +
      '\n' +
      '### 최대 훈련 가능한 모델 크기\n' +
      '\n' +
      '먼저 ZeRO-Infinity.5에서 Fuyou의 최대 훈련 가능한 모델 크기를 검증한다. 우리는 CPU 메모리 용량이 다른 A100-80GB 및 RTX 4090 모두에서 GPT-3 모델을 훈련한다. 영향을 최소화하기 위해 배치 크기를 1로 설정했습니다. CPU 용량을 제한하기 위해 Fuyou와 ZeRO-Infinity가 모두 고정된 메모리를 사용할 수 없도록 일정량의 메모리를 고정합니다. 평가에서 리눅스 스왑 파티션을 사용할 수 없습니다. 그림 4는 결과를 보여준다. 여기서 우리는 세 가지 관측치를 가지고 있다.\n' +
      '\n' +
      '각주 5: ZeRO-Infinity보다 더 작은 훈련 가능한 모델 크기를 지원하기 때문에 Colossal-AI 및 ZeRO-Offload와 비교하지 않는다.\n' +
      '\n' +
      '첫째, Fuyou는 CPU 및 GPU 메모리 용량에서 ZeRO-Infinity보다 훨씬 더 큰 모델을 미세 조정할 수 있는데, 이는 Fuyou가 CPU 및 GPU의 메모리 용량을 완전히 활용할 수 있지만 ZeRO-Infinity는 사용할 수 없기 때문이다. 768 GB CPU 메모리에서 Fuyou는 A100-80GB와 RTX 4090에서 각각 805B와 276B 모델의 미세조정이 가능하며, ZeRO-Infinity보다 5.96\\(\\times\\)과 2.04\\(\\times\\) 더 크다.\n' +
      '\n' +
      '둘째, CPU 메모리 용량은 ZeRO-Infinity의 가장 큰 모델 크기를 제한하는데, 이는 동일한 CPU 메모리 제한 하에서 ZeRO-Infinity를 갖는 최대 트레이닝 가능한 모델 크기가 동일하기 때문이다. 여기서 A100-80GB는 80GB GPU 메모리를 갖는 반면 RTX 4090은 24GB만을 갖는다. 또한, ZeRO-Infinity는 A100-80GB와 RTX 4090에서 128GB CPU 메모리로 13B 모델을 훈련하는데 실패하고, Fuyou는 128GB CPU 메모리와 RTX 4090만으로 65B 모델을 훈련하는데 성공하여 대부분의 연구자들이 접근할 수 있다.\n' +
      '\n' +
      '셋째, CPU 메모리 용량이 384 GB 이상인 경우, Fuyou는 A100-80 GB에서 RTX 4090보다 더 큰 모델을 미세 조정할 수 있으며, 이는 RTX 4090의 24GB GPU 메모리가 이 경우 새로운 병목 현상이 됨을 나타낸다. 이는 더 큰 모델이 레이어 내에서 더 큰 중간 값 크기를 가져오기 때문에 CPU 및 SSD에 오프로드가 되지 않아 GPU 메모리 요구 사항이 높기 때문이다.\n' +
      '\n' +
      '### End-to-End Throughput 비교\n' +
      '\n' +
      'Fuyou의 효율성을 입증하기 위해 Fuyou와 세 가지 기준선의 종단간 훈련 처리량을 비교한다. 우리는 다른 배치 크기로 A100-80GB 및 RTX 4090 모두에서 GPT-3 13B 및 175B를 미세 조정하기 위해 Fuyou 및 기준선을 사용한다.\n' +
      '\n' +
      '도 5b는 A100-80GB에서 13B 모델을 미세 조정할 때 Fuyou 및 베이스라인의 처리량을 도시한다. Fuyou는 최대 202 TFLOPS에서 2.46\\(\\times\\), 3.42\\(\\times\\), 6.73\\(\\times\\)의 성능을 보이며, ZeRO-Offload, ZeRO-Infinity, Colossal-AI에 비해 각각 가장 높은 처리량을 보였다. 배치 크기가 8인 ZeRO-Offload가 더 높은 처리량을 달성\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{|c||c|c|c|} \\hline\n' +
      '**Model** & **\\#Layers** & **\\#Heads** & **Hidden Dimension** \\\\ \\hline \\hline\n' +
      '**GPT-3 13B** & 40 & 40 & 5120 \\\\ \\hline\n' +
      '**GPT-3 33B** & 60 & 52 & 6656 \\\\ \\hline\n' +
      '**GPT-3 65B** & 80 & 64 & 8192 \\\\ \\hline\n' +
      '**GPT-3 135B** & 88 & 88 & 11264 \\\\ \\hline\n' +
      '**GPT-3 175B** & 96 & 96 & 12288 \\\\ \\hline\n' +
      '**GPT-3 276B** & 112 & 112 & 14336 \\\\ \\hline\n' +
      '**GPT-3 412B** & 128 & 128 & 16384 \\\\ \\hline\n' +
      '**GPT-3 805B** & 160 & 160 & 20480 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4. 평가용 모델.\n' +
      '\n' +
      '그림 4. 다른 CPU 메모리 제한에서 Fuyou 및 기준선의 최대 훈련 가능한 모델 크기입니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{|c|c|} \\hline\n' +
      '**CPU** & Intel Xeon Gold 5320 CPU @ 2.20GHz \\\\ \\hline\n' +
      '**CPU Memory** & 768 GB 3200MHz DDR4 \\\\ \\hline\n' +
      '**PCIe** & PCIe Gen 4 \\\\ \\hline\n' +
      '**GPU** & NVIDIA A100 80GB \\\\  & NVIDIA Geforce RTX 4090 \\\\ \\hline\n' +
      '**SSD** & 12\\(\\times\\) 3.84TB Intel P5510 SSDs \\\\ \\hline\n' +
      '**CUDA Toolkit** & 11.8 \\\\ \\hline\n' +
      '**PyTorch** & 2.0.0+cu118 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3. 서버의 구성.\n' +
      '\n' +
      'ZeRO-Infinity보다. 이는 ZeRO-Offload가 최적화기 및 액티베이션을 SSD에 오프로드하지 않는 반면, Fuyou에서는 최적화기 단계의 작은 배치 크기의 CPU-SSD 통신이 반복의 큰 비중을 차지하기 때문에 합리적이다.\n' +
      '\n' +
      '그림 4(c)는 RTX 4090에서 13B 모델을 미세 조정할 때 처리량을 보여준다. Colossal-AI는 RTX 4090에서 모델을 훈련하지 못하므로 Colossal-AI를 포함하지 않는다. Fuyou는 156 TFLOPS를 달성하며, 이는 ZeRO-Offload와 ZeRO-Infinity에 비해 2.36\\(\\times\\) 및 3.47\\(\\times\\) 개선이다. Colossal-AI는 활성화 체크포인트를 오프로드하지 않기 때문에 RTX 4090의 24GB 메모리 용량보다 더 큰 GPU 메모리 공간이 필요하기 때문에 실행이 실패한다.\n' +
      '\n' +
      '그림 4(a)는 A100-80GB 및 RTX 4090에서 175B 모델을 미세 조정할 때 Fuyou의 처리량을 보여준다. 세 가지 기준선 모두 하드웨어 설정에서 175B 모델을 미세 조정하지 못한다. A100-80GB에서 Fuyou는 173 TFLOPS의 처리량을 달성하는 반면, 더 작은 13B 모델에서는 이 높은 처리량의 86%를 유지한다. RTX 4090에서 Fuyou는 86 TFLOPS의 처리량을 달성하는 반면, 13B 모델에서는 이 처리량의 55%를 유지한다. GPU 메모리 제한으로 인해, 지원되는 배치 크기는 13B 모델을 미세 조정하는 것에 비해 상대적으로 작고, 이는 GPU 처리량을 제한한다. 이는 추가적인 최적화의 가능성을 남긴다. 그러나, ZeRO-인피니티의 처리량 트레이닝이 45 TFLOPS에 불과한 RTX 4090에서 13B 모델을 트레이닝하는 것과 비교하여, 이것은 여전히 상당한 처리량이다.\n' +
      '\n' +
      '그림 6은 A100-80GB에서 더 큰 GPT-3 모델을 미세 조정할 때 Fuyou의 처리량을 보여준다. 배치 크기가 64인 Fuyou는 각각 168, 163 TFLOPS 미세 조정 276B 및 412B 모델을 달성한다. 이는 175B 모델을 미세 조정하는 것과 비교하면 큰 폭의 하락은 아니다.\n' +
      '\n' +
      '요약하면, Fuyou는 RTX 4090에서 GPT-3 175B를 미세조정할 수 있지만 기준선은 그렇지 않다. 동일한 GPU에서 동일한 모델을 미세조정할 때 Fuyou는 기준선보다 훨씬 높은 처리량을 달성하여 Fuyou가 대규모 모델에서 효율적인 미세조정을 가능하게 함을 알 수 있다.\n' +
      '\n' +
      'Backward and Optimizer Overlapping의### 효과\n' +
      '\n' +
      '역방향 및 최적화기 중첩 단계(하위 섹션 4.3)의 효율성을 검증하기 위해 후후방향 및 최적화기 중첩 최적화를 비활성화하는 구현인 Fuyou w/o 중첩과 Fuyou를 비교한다. 우리는 RTX 4090 GPU에서 Fuyou w/o 중첩 미세 조정 GPT-3 13B 및 175B를 사용하여 Fuyou를 테스트한다. 그림 7은 비교 결과를 보여준다.\n' +
      '\n' +
      'Fuyou는 역방향 및 최적화기 중첩 메커니즘으로 인해 모든 배치 크기에서 중첩되지 않은 것보다 더 높은 처리량을 달성한다. RTX 4090에서 GPT-13B를 미세 조정할 때 Fuyou w/o 중첩에 비해 Fuyou는 배치 크기가 8, 16, 32 및 64일 때 각각 1.09\\(\\times\\), 1.25\\(\\times\\), 1.38\\(\\times\\) 및 1.22\\(\\times\\) 더 높은 처리량을 달성했다. GPT-175B를 미세 조정할 때 Fuyou는 배치 크기가 8 및 16일 때 각각 1.16\\(\\times\\) 및 1.18\\(\\times\\) 더 높은 처리량을 달성한다. 처리량 이득은 배치 크기가 너무 작거나 너무 클 때 떨어지며, 이는 이러한 경우에 역방향 전파 및 최적화기 단계가 상당히 상이한 실행 시간을 가지며, 따라서 더 적은 중첩 기회를 초래하기 때문이다.\n' +
      '\n' +
      '그림 5. 배치 크기가 다른 Fuyou와 기준선 간의 종단간 GPU 처리량 비교.\n' +
      '\n' +
      '그림 6. A100-80GB에서 푸유 미세 조정 극단 대형 GPT-3 모델의 종단간 GPU 처리량.\n' +
      '\n' +
      '그림 7. 역방향 및 최적화기 중첩의 효과.\n' +
      '\n' +
      'Pipelined Activation Swapping의 효과\n' +
      '\n' +
      '파이프라인 활성화 스와핑(하위 섹션 4.4)의 유효성을 검증합니다. 우리는 배치 크기가 다른 A100-80GB 및 RTX 4090 GPU에서 Fuyou w/o 중첩 및 ZeRO-Infinity GPT-3 13B를 미세 조정한다. 그림 8은 비교 결과를 보여준다.\n' +
      '\n' +
      'Fuyou w/o 중첩은 A100-80GB와 RTX 4090에서 ZeRO-Infinity를 능가한다. A100-80GB에서 Fuyou w/o 중첩은 배치 크기 8, 16 및 32에서 각각 1.66\\(\\times\\), 1.88\\(\\times\\) 및 1.97\\(\\times\\)의 처리량을 달성하고 RTX 4090에서 Fuyou w/o 중첩은 배치 크기 8, 16 및 32에서 각각 1.85\\(\\times\\), 1.92\\(\\times\\) 및 2.28\\(\\times\\)의 처리량을 달성한다. 처리량 이득은 두 가지 이유 때문이다. 먼저, GPU 연산과 PCIe 통신을 중첩시키는 심층 파이프라인 실행 전략을 채택한다. 둘째, ZeRO-Infinity는 페이지 가능한 메모리를 사용하여 고정 메모리 대신 액티베이션을 저장하므로 GPU와 CPU 사이의 액티베이션 전송 속도가 느려지기 때문에 성능 문제가 있다.\n' +
      '\n' +
      '### 활성화 스왑핑 관리의 효과\n' +
      '\n' +
      '활성화 스와핑 관리(하위 섹션 4.5)의 유효성을 검증하기 위해 12개의 SSD가 있는 A100-80GB에서 GPT-3 13B를 미세 조정하는 다양한 활성화 스와핑 전략으로 Fuyou를 테스트한다. 배치 크기는 32, 64, 80으로 설정하였으며, 활성화 스와핑 전략을 위해 스왑 계수를 모든 인트라 트랜스포머 블록 활성화에서 스와핑될 활성화의 데이터 볼륨비로 정의한다. 우리는 서로 다른 스왑 계수를 테스트하고 한 번의 반복의 훈련 시간을 측정한다. 그림 9는 결과를 나타내며, 여기서 별은 자동 활성화 스와핑 관리 메커니즘에 의해 예측된 최적 스왑 계수를 나타낸다.\n' +
      '\n' +
      '배치 크기 32의 경우, 예측된 스왑 계수는 0인데, 이 경우 중첩 역방향 및 최적화 단계에 대한 실행 시간이 통신에 의해 제한되므로, 스왑 활성화의 증가는 훈련 시간을 줄이는 데 도움이 되지 않기 때문이다. 64 및 80의 배치 크기에 대해 Fuyou는 양의 예측 스왑 계수를 제공합니다. 세 가지 배치 크기에 대해 Fuyou의 자동 스와핑 메커니즘은 실험 결과에 따라 거의 최적의 예측을 생성한다.\n' +
      '\n' +
      '### Cost-Effectiveness Comparison\n' +
      '\n' +
      '트레이닝 처리량 향상에 있어 저렴한 SSD를 사용하는 비용 효율성을 보이기 위해 텐서 병렬성을 사용하여 NVLink-enhanced DGX-2[(31)] 노드에서 Fuyou와 Megatron-LM[(27)]의 비용 효율성을 비교한다. 메가트론-LM은 데이터 오프로딩에 의존하지 않는다. 우리는 달러로 된 가격보다 토큰/s의 처리량으로 비교 메트릭을 선택한다. 기계 및 부품 가격은 표 5와 같이 추정됩니다. 우리는 다른 SSD 번호로 A100-80GB와 RTX 4090에서 Fuyou를 평가한다. 우리가 사용하는 평가된 모델은 스와핑 오버헤드를 최대화하기 위해 GPT-3 175B이다.\n' +
      '\n' +
      '먼저 서버에서 GPU6와 SSD의 총 가격에 대한 처리량을 비교한다. 그림 (a)a는 RTX 4090 상의 Fuyou가 메가트론-LM에 비해 최대 1.70\\(\\times\\)의 비용 효율성을 달성함을 보여준다. 이는 대규모 훈련의 경우,\n' +
      '\n' +
      '그림 8. 파이프라인 활성화 스와핑의 효과.\n' +
      '\n' +
      '그림 10. GPT-3 175B를 미세 조정할 때 DGX-2에서 Fuyou와 Megatron-LM 간의 1000달러당 처리량 비교.\n' +
      '\n' +
      '그림 9. Fuyou fine-tuning GPT-3 13B의 반복 시간 A100-80GB에서 다른 재계산 전략을 사용하여. 별은 최적의 스왑 계수를 예측합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{|c|c|} \\hline\n' +
      '**Machines and Components** & **Price (S)** \\\\ \\hline \\hline\n' +
      '**DGX-2 서버** &\\멀티로우{2}{*}{200,000[(11)]}\\\\\n' +
      '**with 8 A100-80G NVLink GPUs** & \\\\ \\hline\n' +
      '**상품 4U 서버** &\\멀티로우{2}{*}{14,098[(50)]}\\\\\n' +
      '**without GPUs and SSDs** & \\\\ \\hline\n' +
      '**NVIDIA A100-80GB** & 14,177 [(50)] \\\\ \\hline\n' +
      '**NVIDIA RTX 4090** & 1,600 [(33)] \\\\ \\hline\n' +
      '**Intel P5510 SSD** & 308 [(50)] \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5. 서버 및 구성 요소의 예상 가격.\n' +
      '\n' +
      '그림 8. 파이프라인 활성화 스와핑의 효과.\n' +
      '\n' +
      'SSD에 데이터를 오프로딩하는 상품 GPU는 거대한 모델을 훈련하기 위해 오프로딩에 의존하지 않는 고급 데이터 센터 클러스터와 비교할 수 있는 비용 효율성을 여전히 달성할 수 있다. 또한 SSD의 개수가 6개 이하인 경우, SSD의 개수가 증가할수록 FuYu의 가성비가 증가한다. 이는 시스템 토폴로지 재설계의 효율성을 나타낸다. 특히, 값싼 SSD의 수를 늘리는 것만이 Fuyou하에서 GPU 활용도를 크게 높일 수 있는 경제적인 해결책이다. SSD 수가 6개에서 12개로 증가하면 가성비가 떨어진다. 이는 이 경우에 12개의 SSD가 최적의 SSD 수보다 크고, SSD의 수를 증가시킴에 따른 성능 이득이 감소하고 있기 때문이다.\n' +
      '\n' +
      '우리는 또한 그림 (b)b와 같이 전체 서버의 가격에 대한 처리량을 비교한다. Fuyou는 Megatron-LM.7에 비해 75%의 비용 효율성을 달성한다. 근본적인 이유는 서버 자체가 Fuyou에 따라 전체 비용의 대부분을 차지하기 때문이다. 일반적인 상품 4U 서버는 최대 8개의 GPU를 포함할 수 있기 때문에, 상품 GPU의 수를 증가시키면 적절한 최적화로 더 높은 비용 효율성을 달성할 수 있다. 우리는 이것을 우리의 미래 일에 맡긴다.\n' +
      '\n' +
      '각주 7: 우리의 평가는 DGX-2 클러스터에 대한 네트워크 장치의 가격을 계산하지 않는데, 왜냐하면 우리는 정확한 가격을 알지 못하기 때문이다. 푸유는 단일 GPU-트레이닝 시나리오에 대해 평가되기 때문에, 푸유는 네트워크 장치가 필요하지 않다.\n' +
      '\n' +
      '##6. 관련 저작물\n' +
      '\n' +
      '우리가 아는 한 Fuyou는 데스크톱 GPU 카드 하나만 사용하여 극도로 큰 규모의 모델을 효율적으로 미세 조정할 수 있는 첫 번째 프레임워크이다. <표 1>은 Fuyou와 이전 작품들 중 일부의 차이를 요약한 것이다. 이 절에서는 대규모 DNN 훈련의 발전을 제안하는 이전 연구에 대해 더 논의한다.\n' +
      '\n' +
      '**모델 상태 및 액티베이션을 CPU 메모리에 오프로딩.** 오프로딩은 DNN 모델 트레이닝 프로세스의 메모리 풋프린트를 감소시키기 위해 널리 연구된 접근법이었다. 이 중 vDNN(Wang et al., 2017), TFLMS(Wang et al., 2017), LayRub(Liu et al., 2017), Zhang et al., 2017), vDNN++(Wang et al., 2017), Beaumont et al.(Beaumont et al., 2018), Capuchin(Yang et al., 2018), Tsplit(Wang et al., 2017), POET(Wang et al., 2017), STR(Wang et al., 2017) 및 Sentinel(Sentinel, 2017)은 CPU 메모리에 대한 오프로딩 액티베이션을 지원한다. SuperNeurons(Wang et al., 2017), L2L(Wang et al., 2017), ZeRO-Offload(Wang et al., 2017), PatrickStar(Bai et al., 2017), 및 Elixir(Elixir, 2017)는 CPU 메모리에 오프로딩 모델 상태들을 지원한다. SwapAdvisor(Wang et al., 2017) 및 DeFiNES(Wang et al., 2017)는 활성화 및 모델 상태 모두를 CPU 메모리에 오프로딩하는 것을 지원한다. 이 모든 작업은 in-SSD 활성화 오프로딩이나 out-of-core 최적화기를 지원하지 않습니다. 이와는 대조적으로 Fuyou는 in-SSD 활성화 오프로딩과 효율적인 out-of-core 동기 최적화기를 제안하여 이전 작업보다 단일 GPU에서 훨씬 더 큰 모델 스케일을 가능하게 한다.\n' +
      '\n' +
      '**SSD-Offloading Framework.** 일부 기존 작업은 NVMe SSD에 모델 상태를 오프로드하여 단일 GPU에서 대규모 모델 학습을 가능하게 한다. 이 중 Flash-Neuron(Elixir, 2017)은 GPUDirect와 DPDK를 사용하여 SSD에 활성화를 오프로드하지만 모델 상태 오프로드와 아웃코어 옵티마이저를 지원하지 않는다. G10(Wang et al., 2017)은 GPUDirect Storage를 사용하여 모델 상태를 오프로드하고 SSD에 활성화를 수행하지만, GPU에서 최적화 기능을 수행하여 GPU와 SSD 사이의 네트워크 압력을 증가시킨다. ZeRO-Infinity (Wang et al., 2017)는 동기식 가중치 갱신과 함께 Out-of-core 최적화기를 지원하지만, 역방향 전파와 최적화기 단계와 겹치지 않아 모델 학습 효율을 제한한다. STRONGHOLD(Wang et al., 2017)는 이론적으로 SSD에 대한 모델 상태 오프로딩을 지원하지만 CPU 메모리가 충분하지 않을 때 폴백 메커니즘으로 위치하기 때문에 성능이 낮다. Angel-PTM(Wang et al., 2017)은 역방향 전파와 중복되는 Out-of-core Optimizer를 지원하지만 모델 학습 수렴에 영향을 미치는 비동기 가중치 갱신을 채택한다. 요약하면, 이 모든 작업은 단일 GPU에서 미세 조정에 유익한 역방향 전파와 겹치는 코어 외 동기 최적화 단계를 지원하지 않는다. 이와는 대조적으로 Fuyou는 GPU 활용률을 유지하면서 최대 학습 가능한 모델 크기를 보장하는 백워드 스테이지와 중복되는 최적화기를 가능하게 하면서 out-of-core 동기 최적화기를 제안한다.\n' +
      '\n' +
      '**Activation Checkpointing Strategies.** Chen et al.(Chen et al., 2018), Re-forwarding (Grusly et al., 2018), Gruslys et al.(Herrmann et al., 2018), Herrmann et al.(Beaumont et al., 2018), Beaumont et al.(Kusumoto et al., 2018), Kusumoto et al.(Hey et al., 2018), Checkmate (Elixir, 2017) 및 DTR (Wang et al., 2017)은 트레이닝 동안 메모리 풋프린트를 감소시키기 위한 최적의 활성화 체크포인팅 전략을 찾는 것에 초점을 맞춘다. 또한, Beaumont et al.(Beaumont et al., 2018), Capuchin (Yang et al., 2018), TSplit (Wang et al., 2017), 및 POET (Wang et al., 2017)는 활성화 오프로딩 시나리오 하에서 최적의 체크포인팅 전략을 고려하는 반면, SuperNeurons (Wang et al., 2017)는 모델 상태들 및 액티베이션들 모두가 CNN 모델들을 위한 CPU 메모리에만 오프로딩될 때 LRU 기반 활성화 체크포인팅 및 오프로딩 전략을 채택한다. 그러나 이 모든 작업은 오프로딩 없이 또는 활성화가 CPU 메모리에 오프로딩될 때 시나리오만을 목표로 한다. 이와는 대조적으로 Fuyou는 체계적인 관점에서 PCIe 트래픽이 더 복잡한 CPU-SSD 2단계 오프로딩으로 활성화 스와핑 및 재계산 일정을 잡은 첫 번째이다.\n' +
      '\n' +
      '## 7. Conclusion\n' +
      '\n' +
      '본 논문에서는 저사양 GPU와 제한된 CPU 메모리 용량을 갖는 저사양 서버에서 효율적인 100B 대용량 모델 미세 조정이 가능한 저비용 훈련 프레임워크인 Fuyou를 제안한다. 핵심 아이디어는 SSD-CPU 통신을 최적화 차원으로 추가하고 GPU 활용을 극대화하기 위해 체계적인 접근법에서 신중하게 공동 최적화기 계산 및 데이터 스와핑을 추가하는 것이다. 이를 위해 먼저 GPU 활용도를 극대화하기 위해 역방향 전파와 중복되는 동기식 아웃 오브 코어 CPU 최적화기를 제안한다. 둘째, GPU-CPU-SSD 완전 파이프라인 활성화 스와핑 메커니즘을 제안하여 훨씬 더 큰 모델 미세 조정을 허용한다. 셋째, 에폭 시간을 최소화하기 위해 최적의 스와핑 활성화 양을 자동으로 결정하기 위한 자동 활성화 스와핑 관리를 제시한다. PyTorch를 기반으로 Fuyou를 구현하고, ZeRO-Infinity와 Colossal-AI가 훈련에 실패하는 동안 4090과 A100-80GB에서 GPT-3 175B를 미세 조정하면 Fuyou가 각각 87과 172 TFLOPS를 달성함을 보인다. 또한, Fuyou는 A100-80GB에서 GPT-3 13B를 미세 조정할 때 ZeRO-Infinity와 Colossal-AI에 비해 최대 3.42\\(\\times\\)와 6.73\\(\\times\\) TFLOPS에 도달한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '*[1]J. 배준영 진승 손승 Kim, H. Jang, T. J. Ham, and J. W. Lee(2021) Flashneuron: ssd-enabled large-batch training of very deep neural networks. 19th USENIX Conference on File and Storage Technologies (FAST 21), pp. 387-401. Cited by: SS1.\n' +
      '*[2]O. 보몽, L. Eyraud-Dubois, and A. Shilova(2020) Optimal gpu-cpu Offloading strategies for deep neural network training. European Conference on Parallel Processing, pp. 151-166. Cited by: SS1.\n' +
      '*[3]O. Beaumont, J. Herrmann, G. Pallez, and A. Shilova (2020) Optimal memory-aware backpropagation of deep join networks. "Philosophical Transactions of the Royal Society A378(2166), pp. 20190049. Cited by: SS1.\n' +
      '*[4]O. 보몽, L. Eyraud-Dubois, 그리고 A. Shilova(2021)는 dnns 훈련을 위한 재층화 및 오프로딩의 효율적인 조합이다. The Advances in Neural Information Processing Systems34, pp. 23844-23857. Cited by: SS1.\n' +
      '*[5]T. 브라운, B. 만, N. 라이더 Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. (2020) 언어 모델은 소수의 학습자이다. neural information processing systems33, pp. 1877-1901. Cited by: SS1.\n' +
      '*[6]T. Chen, B. Xu, C. Zhang, and C. Guestrin (2016) Training deep net with sublinear memory cost. ArXiv:1604.06174. 인용: SS1.\n' +
      '*[7]A. 차우더리 나랑, J 데블린, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al. (2022) Palm: scaling language modeling with pathways. ArXiv:2204.02311. 인용: SS1.\n' +
      '*[8]J. 데블린 장경 이경호 Toutanova (2018) Bert: 언어 이해를 위한 심층 양방향 변압기의 사전 훈련. ArXiv:1810.04805. 인용: SS1.\n' +
      '*[9]J. 팽진 주성호 이현수 유진주, Y You(2022) 청크 기반 동적 메모리 관리를 통해 미리 학습된 모델의 병렬 학습. IEEE Transactions on Parallel and Distributed Systems34 (1), pp. 304-315. Cited by: SS1.\n' +
      '*[10]J. Feng and D. Huang (2021) Optimal gradient checkpoint search for arbitrary computation graph. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11433-11442. Cited by: SS1.\n' +
      '*[11]Y. 펑민 지지 천승 왕영 Lu 및 J. Shu(2023) 모비우스: 상품 gpu 서버에서 대규모 모델을 미세 조정한다. In Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, pp. 489-501. Cited by: SS1.\n' +
      '*[12]R. C. Fernandez, A. J. Elmore, M. J. Franklin, S. Krishnan, and C. Tan(2023) 얼마나 큰 언어 모델들이 데이터 관리를 방해할 것인가. Proceedings of the VLDB Endowment16 (11), pp. 3302-3309. Cited by: SS1.\n' +
      '*[13]A. 그러스리즈 무노스 I. 다니헬카, M. Lanctot, and A. Graves (2016) Memory-efficient backpropagation through time. 신경 정보 처리 시스템 29. 인용: SS1.\n' +
      '*[14]J. 헤르만 보몽, L. Eyraud-Dubois, J. Hermann, A. Joly, and A. Shilova (2019) Optimal checkpointing for heterogeneous chain: how to training deep neural networks with limited memory. ArXiv:1911.13214. 인용: SS1.\n' +
      '*[15]C. 황, G. Jin, J. Li(2020) 스와파어드바이저: 스마트 스와핑을 통해 딥 러닝을 gpu 메모리 한계를 넘어 추진한다. In Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 1341-1355. Cited by: SS1.\n' +
      '*[16]H. 황재방 리, Y 당신(2022) 엘릭시르: 작은 gpu 클러스터에서 큰 언어 모델을 훈련합니다. ArXiv:2212.05339. 인용: SS1.\n' +
      '*[17]P. Jain, A. Jain, A. Nrusimha, A. Gholami, P. Abbeel, J. Gonzalez, K. Keutzer, and I. Stoica(2020) Checkmate: the memory wall breaking the optimal tensor rematerialization. Proceedings of Machine Learning and Systems2, pp. 497-511. Cited by: SS1.\n' +
      '*[18]H. 진병우 장영 마진 시범희, S 자오(2018) 다코어 아키텍처에 대한 익스트림 스케일 딥 러닝을 위한 레이어 중심 메모리 재사용 및 데이터 마이그레이션. ACM Transactions on Architecture and Code Optimization (TACO)15 (3), pp. 1-26. Cited by: SS1.\n' +
      '*[19]D. P. Kingma and J. Ba(2014) Adam: a method for stochastic optimization. ArXiv:1412.6980. 인용: SS1.\n' +
      '*[20]M. 크루수모토 Inoue, G. Watanabe, T. Akiba, M. Koyama (2019) A Graph theoretic framework of recomputation algorithms for memory-efficient backpropagation. 신경 정보 처리 시스템32. 인용: SS1.\n' +
      '*[21]T. D. Le, H. Imai, N. 네기시, K. Kawachiya (2018) TLIMs: 그래프 재기입에 의한 텐서플로우에서의 대규모 모델 지원. ArXiv:1807.02037. 인용: SS1.\n' +
      '*[22]L. 메이경 Goetschalck, A. Symons, M. Verhelst(2023) 정의: 분석 모델링을 통해 dnn 가속기에 대한 깊이 우선 스케줄링 공간의 빠른 탐색을 가능하게 한다. 2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA), pp. 570-583. Cited by: SS1.\n' +
      '*[23]X. 마오영 왕영 장창시 Nie, H. Zhang 및 B. Cui(2022) Galvatron: 자동 병렬화를 사용하여 다중 gpus에서 효율적인 변압기 훈련. 상기 VLDB Endowment16(3)의 진행. 인용: SS1.\n' +
      '*[24]X. 마오홍장 시선 니지 양영 Tao, 및 B. Cui(2022) Het: 캐시 지원 분산 프레임워크를 통해 거대한 임베딩 모델 트레이닝을 스케일링 아웃한다. Proceedings of the VLDB Endowment15 (2), pp. 312-320. Cited by: SS1.\n' +
      '*[25]M. 메가트론 딥스피드 지텁 저장소입니다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[26]M. 메가트론 딥스피드 지텁 저장소입니다. 외부 링크: 인용된 링크: SS1입니다.\n' +
      '*[27]D. 나라야난 Shooybi, J. Casper, P. LeGresley, M. 패트워리, V Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee, M. 자하리아(2021) 메가토톰-lm을 사용하여 gpu 클러스터에 대한 효율적인 대규모 언어 모델 훈련. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC\'21, New York, NY, USA, pp. 304-315. External Links: ISBN 9781450384421, Document, Link Cited by: SS1.\n' +
      '*[28]X. 니, 엑스 마오진 양, 및 B. Cui(2022) ISPIL: 텐서 분할을 통한 효율적인 dnn 트레이닝을 위한 세립 gpu 메모리 관리. 2022년 IEEE 38th International Conference on Data Engineering (ICDE), pp. 2615-2628. Cited by: SS1.\n' +
      '*[29]X. 니영 류, F. Fu, J. Xue, D. Jiao, X. 마오영 Tao, and B. Cui(2023) AngelPtm: scalable and economical large-scale pre-training system in tencr. ArXiv:2303.02868. 인용: SS1.\n' +
      '*[30]NVIDIA(2018) Nvidia night system. 참고: URL[https://developer.nvidia.com/nsight-systems](https://developer.nvidia.com/nsight-systems) Cited by: SS1.\n' +
      '*[31]NVIDIA(2020) Nvidia a100. 참고: URL[https://www.nvidia.com/en-us/data-center/a100/](https://www.nvidia.com/en-us/data-center/a100/) Cited by: SS1.\n' +
      '*[32]NVIDIA(2022) Geforce rtx 4090. External Links: Link Cited by: SS1.\n' +
      '*[33]NVIDIA(2022) Nvidia night system. 참고: URL[https://developer.nvidia.com/nsight-systems](https://developer.nvidia.com/nsight-systems) Cited by: SS1.\n' +
      '*[34]NVIDIA(2020) Nvidia a100. 참고: URL[https://www.nvidia.com/en-us/data-center/a100/](https://www.nvidia.com/en-us/data-center/a100/) Cited by: SS1.\n' +
      '*[35]NVIDIA(2022) Nvidia a100. 참고: URL[https://www.nvidia.com/en-us/data-center/a100/](https://www.nvidia.com/en-us/data-center/a100/) Cited by: SS1.\n' +
      '*[36]NVIDIA(2022) Geforce rtx 4090. External Links: Link Cited by: SS1.\n' +
      '*[37]L. 기재우 지앙, D. 알메이다, C. 웨인라이트, P. 미쉬킨, C. 장 가왈 Slama, A. Ray, et al.(2022) Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems35, pp. 27730-27744. Cited by: SS1.\n' +
      '*[38]A. 파스케 역겨워, S 친탈라, G.찬안, E.양, Z. 데비토, 지 린 A. 데스미슨 L. Antiga, and A. Lerer(2020) Automatic differentiation in pytorch. _NIPS 2017 오토디프 워크샵: Gradient 기반 기계 학습 소프트웨어 및 기술의 미래_, 2017.\n' +
      '* [36] S. G. Patil, P. Jain, P. Dutta, I. Stoica, and J. Gonzalez. POET: Training neural networks on tiny devices with integrated rematerialization and paging. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, editors, _Proceedings of the 39th International Conference on Machine Learning_, volume 162 of _Proceedings of Machine Learning Research_, pages 17573-17583. PMLR, 17-23 Jul 2022. URL [https://proceedings.mlr.press/v162/patil22b.html](https://proceedings.mlr.press/v162/patil22b.html).\n' +
      '* [37] X. Peng, X. Shi, H. Dai, H. Jin, W. Ma, Q. Xiong, F. Yang, and X. Qian. Capuchin: Tensor-based gpu memory management for deep learning. In _Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems_, pages 891-905, 2020.\n' +
      '* [38] B. Pudipeddi, M. Mesmakosroshahi, J. Xi, and S. Bharadwaj. Training large neural networks with constant memory using a new execution algorithm. _arXiv preprint arXiv:2002.05645_, 2020.\n' +
      '* [39] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised multitask learners. _OpenAI blog_, 1 (8), 2019.\n' +
      '* [40] S. Rajbhandari, J. Rasley, O. Ruwase, and Y. He. Zero: Memory optimizations toward training trillion parameter models. In _SC20: International Conference for High Performance Computing, Networking, Storage and Analysis_, pages 1-16. IEEE, 2020.\n' +
      '* [41] S. Rajbhandari, O. Ruwase, J. Rasley, S. Smith, and Y. He. Zero-infinity: Breaking the gpu memory wall for extreme scale deep learning. In _Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis_, pages 1-14, 2021.\n' +
      '* [42] J. Rasley, S. Rajbhandari, O. Ruwase, and Y. He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In _Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, pages 3505-3506, 2020.\n' +
      '* [43] J. Ren, J. Luo, K. Wu, M. Zhang, H. Jeon, and D. Li. Sentinel: Efficient tensor migration and allocation on heterogeneous memory systems for deep learning. In _2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)_, pages 598-611. IEEE, 2021.\n' +
      '* [44] J. Ren, S. Rajbhandari, R. Y. Aminabadi, O. Ruwase, S. Yang, M. Zhang, D. Li, and Y. He. {ZeKO-Offload}: Democratizing {Billion-Scale} model training. In _2021 USENIX Annual Technical Conference (USENIX ATC 21)_, pages 551-564, 2021.\n' +
      '* [45] M. Rhu, N. Gimelshein, J. Clemons, A. Zulfiqar, and S. W. Keckler. vdm: Virtualized deep neural networks for scalable, memory-efficient neural network design. In _2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)_, pages 1-13. IEEE, 2016.\n' +
      '* [46] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ilic, D. Hesslow, R. Castagne, A. S. Luccioni, F. Yvon, M. Galle, et al. Bloom: A 176b-parameter open-access multilingual language model. _arXiv preprint arXiv:2211.05100_, 2022.\n' +
      '* [47] M. Shoeybi, M. Patwary, R. Puri, P. LeGresley, J. Casper, and B. Catanzaro. Megatron-lm: Training multi-billion parameter language models using model parallelism, 2020.\n' +
      '* [48] S. Shriram, A. Garg, and P. Kulkarni. Dynamic memory management for gpu-based training of deep neural networks. In _2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)_, pages 200-209. IEEE, 2019.\n' +
      '* [49] X. Sun, W. Wang, S. Qiu, R. Yang, S. Huang, J. Xu, and Z. Wang. Strong-hold: fast and affordable billion-scale deep learning model training. In _SC22: International Conference for High Performance Computing, Networking, Storage and Analysis_, pages 1-17. IEEE, 2022.\n' +
      '* [50] Supermicro. Supermicro. Supermicro sys-420gp-trr dual xeon scalable 4u gpu superserver, 2023. URL [https://store.supermicro.com/us_en/4u-gpu-superserver-sys-420gp-trn.html](https://store.supermicro.com/us_en/4u-gpu-superserver-sys-420gp-trn.html).\n' +
      '* [51] H.-A. Tech. Colossal examples, 2021. URL: [https://github.com/bpcaicnet/ColossalAI/tree/main/examples/language/gpt/gemini](https://github.com/bpcaicnet/ColossalAI/tree/main/examples/language/gpt/gemini).\n' +
      '* [52] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Roziere, N. Goyal, E. Hambro, F. Azhar, et al. Llama: Open and efficient foundation language models. _arXiv preprint arXiv:2302.13971_, 2023.\n' +
      '* [53] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09288_, 2023.\n' +
      '* [54] I. Trummer. The case for nlp-enhanced database tuning: towards tuning tools that\' read the manual". _Proceedings of the VLDB Endowment_, 14(7):1159-1165, 2021.\n' +
      '* [55] L. Wang, J. Ye, Y. Zhao, W. Wu, A. Li, S. L. Song, Z. Xu, and T. Kraska. Superneurons: Dynamic gpu memory management for training deep neural networks. In _Proceedings of the 23rd ACM SIGPLAN symposium on principles and practice of parallel programming_, pages 41-53, 2018.\n' +
      '* [56] H. Zhang, Y. Zhou, Y. Xue, Y. Liu, and J. Huang. G10: Enabling an efficient unified gpu memory and storage architecture with smart tensor migrations. In _Proceedings of the 86th Annual IEEE/ACM International Symposium on Microarchitecture_, pages 395-410, 2023.\n' +
      '* [57] J. Zhang, S. H. Yeung, Y. Shu, B. He, and W. Wang. Efficient memory management for gpu-based deep learning systems. _arXiv preprint arXiv:1903.06631_, 2019.\n' +
      '* [58] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al. Opt: Open pre-trained transformer language models. _arXiv preprint arXiv:2205.01068_, 2022.\n' +
      '* [59] L. Zheng, Z. Li, H. Zhang, Y. Zhuang, Z. Chen, Y. Huang, Y. Wang, Y. Xu, D. Zhuo, E. P. Xing, J. E. Gonzalez, and I. Stoica. Alpa: Automating inter- and Intra-Operator parallelism for distributed deep learning. In _16th USENIX Symposium on Operating Systems Design and Implementation (OSDI\'12)_, pages 559-578, Carlsbad, CA, July 2022. USENIX Association. ISBN 978-1-939133-28-1. URL [https://www.usenix.org/conference/osdi22/presentation/zheng-lianmin](https://www.usenix.org/conference/osdi22/presentation/zheng-lianmin).\n' +
      '* [60] Q. Zhou, H. Wang, X. Yu, C. Li, Y. Bai, F. Yan, and Y. Xu. Mpress: Democratizing billion-scale model training on multi-gpu servers via memory-saving inter-operator parallelism. In _2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)_, pages 556-569. IEEE, 2023.\n' +
      '* [61] Z. Zong, L. Lin, L. Lin, L. Wen, and Y. Sun. Str: Hybrid tensor regeneration to break memory wall for dnn training. _IEEE Transactions on Parallel and Distributed Systems_, 2023.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>