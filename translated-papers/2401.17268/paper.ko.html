<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 위버: 창작 글쓰기를 위한 기초 모델\n' +
      '\n' +
      '천안 왕 지아민 천 칭루이 지아 슈아이 왕 루유 방 후일린 왕\n' +
      '\n' +
      '조위 가오 춘자오 주중대\n' +
      '\n' +
      '장리지웨이황신영\n' +
      '\n' +
      '단준샹윤샤 왕유안주 이샤오 왕이루 시란 딩\n' +
      '\n' +
      '지아양황지아이쑤일리무 타이에 진유후청팽정\n' +
      '\n' +
      '유수예이항리완\n' +
      '\n' +
      '샤오화슈 닝위 장화준\n' +
      '\n' +
      '유천 엘리너 장\\({}^{*}\\) 왕춘슈 주\\({}^{*}\\)\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '이 작품은 콘텐츠 제작에 전념하는 대규모 언어 모델(LLM)의 첫 번째 가족인 위버를 소개합니다. 위버는 대형 언어 모델의 쓰기 능력 향상에 초점을 맞춘 엄선된 말뭉치에서 사전 훈련된다. 그런 다음 창의적이고 전문적인 글쓰기를 위해 위버를 미세 조정하고 명령어 데이터 합성 및 LLM 정렬을 위한 새로운 방법의 슈트를 사용하여 전문 작가의 선호도에 맞게 정렬하여 보다 인간다운 텍스트를 생성하고 콘텐츠 생성을 위한 보다 다양한 지침을 따를 수 있다. 위버 패밀리는 미니(1.8B), 베이스(6B), 프로(14B) 및 울트라(34B) 크기의 모델로 구성되며, 서로 다른 애플리케이션에 적합하며 질의 복잡도에 따라 라우팅 에이전트에 의해 동적으로 디스패치되어 응답 품질과 계산 비용의 균형을 맞출 수 있다. LLM의 쓰기 능력을 평가하기 위해 신중하게 선별된 벤치마크에 대한 평가는 모든 크기의 위버 모델이 일반론자 LLM보다 몇 배 더 큰 성능을 발휘함을 보여준다. 특히, 우리의 가장 가능성 있는 위버 울트라 모델은 다양한 쓰기 시나리오에서 최첨단 일반주의자 LLM인 GPT-4를 능가하여 쓰기 목적으로 특화된 LLM을 훈련하는 이점을 보여준다. 더욱이, 위버는 기본적으로 검색-증강 생성(RAG) 및 기능 호출(도구 사용)을 지원한다. 우리는 외부 지식 기반, 도구 또는 API의 통합을 포함하여 AI 지원 쓰기 시스템을 개선하고 개인화된 쓰기 지원을 제공하는 데 이러한 능력의 다양한 사용 사례를 제시한다. 또한 사전 훈련 및 도메인별 LLM을 미세 조정하기 위한 지침 및 모범 사례를 논의하고 요약한다.\n' +
      '\n' +
      '위버는 현재 우리의 혁신적인 인간-AI 협업 작성 플랫폼인 www.wawwriter.com에서 액세스할 수 있다(WawaWriter의 영어 버전은 www.wawwriter.com/en 참조). 우리는 인간-컴퓨터 상호작용의 관점에서 플랫폼의 몇 가지 혁신에 대해 논의하여 전통적인 AI 보조 쓰기 시스템에 혁명을 일으킬 방법을 설명한다.\n' +
      '\n' +
      '###### Contents\n' +
      '\n' +
      '*1 소개\n' +
      '* 2 사전 훈련\n' +
      '	* 2.1 모델 패밀리\n' +
      '	* 2.2 사전 훈련 데이터\n' +
      '	* 2.3 훈련 세부사항\n' +
      '* 3 데이터 합성\n' +
      '	* 3.1 능력\n' +
      '		* 3.1.1 지시 따르기\n' +
      '		* 3.1.2 명령어 주석\n' +
      '		* 3.1.3 평가(문학 비평)\n' +
      '		* 3.1.4 검색-증강 생성\n' +
      '		* 3.1.5 기능 호출\n' +
      '	* 3.2 명령어 역번역\n' +
      '	* 3.3 Constitution DPO: Principled negative examples로부터 학습\n' +
      '*4 정렬\n' +
      '	* 4.1 감독 미세 조정\n' +
      '		* 4.1.1 데이터\n' +
      '		* 4.1.2 훈련\n' +
      '	* 4.2 선호도 최적화\n' +
      '		* 4.2.1 데이터\n' +
      '		* 4.2.2 훈련\n' +
      '* 5 평가\n' +
      '	* 5.1 WriteBench\n' +
      '	* 5.2 비교 모델\n' +
      '	* 5.3 LLM 기반 평가\n' +
      '	* 5.4 인체 평가\n' +
      '	* 5.5 사용자 연구\n' +
      '*6 소개 WawaWriter\n' +
      '	*6.1 휴먼-AI 협업 글쓰기\n' +
      '	* 6.2 외부 지식과 도구의 통합\n' +
      '	*6.3 개인 맞춤형 쓰기 지원\n' +
      '\n' +
      '### 무한한 장문 생성\n' +
      '*7 토론\n' +
      '* 부록\n' +
      '* A.1 저자 기여도\n' +
      '* A.2 Acknowledge\n' +
      '* A.3 사례연구\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '대형 언어 모델(LLM)(Anthropic, 2023; Brown et al., 2020; Google, 2023; Jiang et al., 2023; OpenAI, 2022, 2023; Radford et al., 2018, 2019; Gemini Team, 2023; Touvron et al., 2023a,b; Yin et al., 2023; Zhao et al., 2023) based on Transformers(Vaswani et al., 2017)는 인공지능(Artificial General Intelligence, AGI)으로의 두드러진 경로가 되었다. LLM은 대규모 웹 코퍼스에서 다음 단어를 예측하는 방법을 배우면서 방대한 세계 지식을 습득한다. LLM의 기능은 모델 크기, 데이터 세트 크기 및 계산을 스케일링함으로써 지속적으로 증가하고 있다. 사전 훈련 후, LLMs는 지도된 미세 조정(Chung et al., 2022; Sanh et al., 2022) 및 인간 피드백(RLHF)으로부터의 강화 학습을 포함하는 선호도 최적화 기술(Ouyang et al., 2022; Wang et al., 2024; Zheng et al., 2023b) 및 직접 선호도 최적화(DPO)에 의해 실제 사용 사례를 지원하도록 정렬될 수 있다(Rafailov et al., 2023). LLM의 기능은 ChatGPT, Claude, Bard, Microsoft Copilot, Character.AI, Notion AI 등을 포함한 다양한 응용 프로그램에 힘을 실어주었다. 최근에, 많은 전문화된 LLM들이 상이한 타겟된 사용 시나리오에 대해 트레이닝되었다. 일반적으로 LLM은 타겟된 도메인(예를 들어, 금융(Wu et al., 2023), 헬스케어(Yang et al., 2022b), 법률(Cui et al., 2023) 등) 및 작업(예를 들어, 역할-플레이잉(Wang et al., 2023d), 코딩(Roziere et al., 2023) 등)에 따라 전문화된다. 그러나, ChatGPT와 같은 LLM 애플리케이션의 중요한 사용 사례인 인간 유사 텍스트를 작성하고 창의적인 콘텐츠를 생산하는 LLM의 능력은 커뮤니티에 의해 대부분 간과된다.\n' +
      '\n' +
      '이 보고서에서는 _literature_ 도메인과 _writing_ 또는 _content creation_의 작업에 초점을 맞추고, 이를 위해 전용으로 사전 훈련되고 정렬된 LLM의 패밀리인 Weaver를 소개한다. "위버"라는 명칭은 장인이 실을 짜서 직물을 형성하는 방식과 유사하게 언어적 요소를 능숙하게 융합하는 모델의 숙련도를 상징한다. 우리는 이 기술 보고서에서 네 가지 주요 질문에 답한다: 왜 Weaver_가 필요한지, Weaver_를 어떻게 훈련하는지, Weaver_를 어떻게 수행하는지, 그리고 Weaver_로 무엇을 구축하는지.\n' +
      '\n' +
      '**왜 Weaver가 필요한가?** GPT와 같은 일반주의 LLM은 이미 일반적인 글쓰기 기술을 보유하고 있으며 다양한 글쓰기 시나리오에서 수십억 명의 사용자를 돕고 있음에도 불구하고, 글쓰기 이야기, 소설, 소셜 미디어 복사본, 블로그, 논문/논문 등과 같은 특정 글쓰기 시나리오에서 인간과 유사한 텍스트를 생산하는데 어려움을 겪는 경우가 많다. 우리는 LLaMA와 같은 사전 훈련된 베이스 LLM 및 ChatGPT 및 LLaMA-채팅과 같은 정렬된 LLM의 거동을 분석하고 이러한 제한이 사전 훈련 단계와 정렬 단계 모두에서 기인한다고 믿는다. 한편으로 일반주의 LLM은 대규모 저품질 웹 텍스트 또는 기계/AI 생성 텍스트에 대해 사전 교육을 받는다. 결과적으로 기존의 LLM 백본은 창의적이지 않고 인간과 유사한 스타일이 없는 겉보기에 유창한 텍스트를 생성하는 경향이 있다. 한편, 정렬 스테이지 동안, GPT-4와 같은 최첨단 LLM들은 크라우드소스 주석자들에 의해 주석된 명령-응답 쌍들을 사용하여 명령-튜닝된다(지 외, 2023; 쉔 외, 2023; Wang 외, 2023c). 그러나, 대부분의 주석자는 전문 작가나 콘텐츠 제작자가 아니며 주석 지침은 유용하고 무해한 응답을 만들어내기만 하면 된다(Ouyang et al., 2022b). 결과적으로, 감독 미세 조정을 위한 크라우드소싱 데이터는 덜 스타일리시하고 창의성이 부족하다. 또한, 가장 인기 있는 선호도\n' +
      '\n' +
      '그림 1: WriteBench 상의 Weaver와 일반 LLMs의 비교.\n' +
      '\n' +
      'RLHF 및 DPO와 같은 최적화 방법은 모델 생성 데이터 쌍에서 모델을 최적화하므로 LLM의 창의성을 향상시키는데 덜 적합하다.\n' +
      '\n' +
      '이러한 요인들은 현재의 일반주의 LLMs가 창의성이 부족하고 코드 작성 및 일반 질문에 답하는 것과 같은 다른 응용 프로그램에서 매우 강력함에도 불구하고 인간 스타일 텍스트를 생성할 수 없게 만든다. 우리는 인터넷에서 LLM 생성 텍스트의 양이 기하급수적으로 증가하고 대부분의 LLM이 다른 LLM에서 생성된 텍스트를 사용하여 정렬된다는 점을 감안할 때 이러한 현상이 계속 증폭될 것이라고 믿는다. 따라서 AI 생성 콘텐츠(AIGC)의 잠재력을 충분히 활용하기 위해서는 창의적이고 인간다운 텍스트를 생성하는 쓰기 목적 전용 도메인 특화 LLM을 훈련할 필요가 있다고 본다.\n' +
      '\n' +
      '**위버를 어떻게 훈련합니까?** 일반주의 LLM의 창의적인 쓰기 능력을 제한하는 앞서 언급한 문제를 해결하기 위해 사전 훈련 및 정렬을 위한 자동화된 데이터 수집, 데이터 주석 및 데이터 필터링을 위한 일련의 전략을 신중하게 설계한다. 이를 통해 우리는 다양하고 인간다운 스타일리시한 텍스트에 위버를 사전 훈련하고 정렬할 수 있습니다. 구체적으로, 사전 훈련 데이터 필터링을 광범위하게 수행하고 사전 훈련 코퍼스에서 책, 소설, 이야기, 기사 등의 고품질 콘텐츠만 유지하여 사전 훈련된 백본이 인간과 유사한 텍스트를 생성할 가능성이 더 높다.\n' +
      '\n' +
      '정렬 단계는 전문 작가가 작성하고 인간 소비자가 선호하는 고품질 출력에 해당하는 다양하고 자연스러운 명령어를 합성하는 LongForm(Koksal et al., 2023)과 Humpback(Li et al., 2023)에서 영감을 받은 새로운 명령어 역번역 프레임워크를 제안한다. 우리의 명령어 역번역 프레임워크는 크라우드소스 주석자의 작업을 지침과 출력을 모두 쓰는 것에서 이야기, 소설, 기사, 소셜 미디어 복사본 및 블로그 게시물과 같은 고품질 콘텐츠를 수집하는 것까지 번역했다. 이는 명령어 데이터 주석 비용과 크라우드 소스 주석자에 대한 요구 사항을 크게 감소시키면서 주석된 데이터의 품질을 크게 향상시킨다.\n' +
      '\n' +
      '또한 위버를 전문 작가와 콘텐츠 제작자의 선호도에 더 잘 맞추기 위해 선호도 최적화를 위한 새로운 헌법 DPO 알고리즘을 제안한다. 헌법 DPO는 DPO(Rafailov et al., 2023), 헌법 AI(Bai et al., 2022), Self-Align(Sun et al., 2023) 및 RLCD(Yang et al., 2023a)를 포함한 몇 가지 이전 작업의 장점에 영감을 받고 결합한다. 구체적으로, 헌법 DPO는 전문가(예: 우리 사례의 전문 편집자)를 활용하여 최적의 정책(예: 우리 사례의 전문 작가 또는 콘텐츠 작성자에 의해 생산된 텍스트)에서 샘플링된 긍정적인 사례를 기반으로 특정 원칙을 위반하는 부정적인 사례를 합성하기 위해 주석이 달린 원칙을 활용한다. LLM을 사용하여 Zephyr(Tunstall et al., 2023)과 같은 두 모델 생성 응답에 선호도 주석을 생성하는 DPO를 사용하는 일반적인 관행과 달리, 우리의 접근법에 의해 합성된 쌍별 선호도 데이터는 부정적인 예가 긍정적인 예에 비해 품질이 낮도록 의도적으로 합성되기 때문에 노이즈가 적다. 헌법 DPO에 의해 생성된 쌍별 선호도 데이터는 또한 표적 도메인 및 응용에 따라 인간 전문가가 조정할 수 있는 더 원칙적이고 표적화된 학습 신호를 포함한다.\n' +
      '\n' +
      '또한, 명령어 역번역 및 헌법 DPO 단계에서 사용되는 주석 명령어 및 응답을 주석 명령어 및 평가 명령어로 변환할 것을 제안한다. 이러한 방식으로, 위버는 쓰기 지시를 따르는 능력을 보유할 뿐만 아니라, 쓰기 지시에 주석을 달 수 있고 쓰기 출력을 평가할 수 있다. 또한 위버가 외부 지식과 도구를 활용할 수 있도록 검색 증강 생성(RAG) 및 기능 호출을 위한 명령어 데이터를 큐레이션한다. 다양한 데이터 소스의 조합은 위버를 창의적인 글쓰기를 전문으로 하면서 다재다능한 기초 모델로 만듭니다.\n' +
      '\n' +
      '**위버가 어떻게 수행하는가?** LLMs의 콘텐츠 생성/쓰기 능력을 평가하는 것은 MMLU(Hendrycks et al., 2020) 또는 MTBench(Zheng et al., 2023a)와 같은 LLMs에 대한 기존의 벤치마크들이 대부분 창의적 쓰기 대신에 추론, 수학, 코딩, 또는 일반적인 질문들에 초점을 맞추고 있기 때문에 여전히 미해결 문제로 남아 있다. 더욱이, LLMs는 일반 지침에서 평가하기가 이미 어렵기로 악명 높으며, LLMs는 말할 것도 없고 문학 비평가가 인간 전문가에게도 자명하지 않기 때문에 창의적인 글쓰기 작업은 훨씬 더 어려워진다. 위버를 더 잘 평가하고 LLM 커뮤니티가 AIGC의 진행 상황을 더 잘 측정할 수 있도록 LLM의 창의적인 쓰기 능력을 평가하기 위한 벤치마크인 WriteBench를 신중하게 선별하고 오픈 소스 및 독점 모델을 모두 포함하는 10개 이상의 인기 LLM의 출력을 수집한다.\n' +
      '\n' +
      '그런 다음 벤치마크에서 위버 및 일반 LLM에 대한 LLM 기반 및 인간 평가를 모두 수행한다. 평가 결과는 일반 LLM에 비해 위버의 우수성을 확인한다. 우리는 위버 가족에서 가장 능력 있는 모델인 위버 울트라가 이전의 가장 성능이 좋은 LLM인 GPT-41에 비해 10+ 작음에도 불구하고 창의적인 글쓰기에서 최첨단 기술을 발전시킨다는 것을 발견했다. 위버 가문의 다른 모델들도 그들보다 몇 배 더 큰 경쟁 일반주의자 LLM을 능가한다. 우리의 분석과 사례 연구는 위버가 창의적이고 인간과 유사한 텍스트를 생성할 수 있는 반면 일반주의 LLM은 너무 "예측 가능한" 텍스트를 생성하는 경향이 있기 때문에 개선의 주요 원천이 있음을 보여준다. 실제 응용에서 위버가 실제로 유용하다는 것을 확인하기 위해, 위버와 GPT-4를 사용하여 인간 작가에게 이야기(픽션 쓰기)와 블로그 게시물(논픽션 쓰기)을 작성하도록 하는 사용자 연구를 수행했으며, 사용자 연구는 위버가 GPT-4에 비해 작가 생산성을 47% 향상시키고 작가가 더 나은 이야기 및 기사를 동시에 생성하는 데 도움이 된다는 것을 보여준다.\n' +
      '\n' +
      '각주 1: GPT-4의 크기에 관한 비공식 소문에 의하면\n' +
      '\n' +
      '**위버로 구축하는 것?** 글쓰기를 위한 특수 LLM을 훈련시키는 것은 AI 지원 글쓰기 경험을 향상시키는 한 측면입니다. 우리는 AI 지원 글쓰기에서 위버의 잠재력을 완전히 활용하기 위해 더 나은 인간-AI 인터페이스를 구축하는 것도 매우 중요하다고 믿는다. 이를 위해 혁신적인 휴먼-AI 협업 글쓰기 플랫폼인 와와와라이터를 소개합니다. 와와와라이터는 노션 AI와 같은 최근의 AI 필기 제품과 유사하게, 기존의 애플리케이션에서와 같이 현재의 맥락에 기초하여 다음 하나 또는 몇 개의 문장을 제안하거나 콘텐츠를 연마하는 것 대신에, 사용자가 다양한 필기 지시를 제공할 수 있는 채팅 인터페이스를 제공한다. WawaWriter는 또한 몇 가지 단계를 더 수행한다: (1) 사용자가 사용자와 동시에 편집기 내부에서 동작함으로써 인간 공동작업자처럼 행동하는 언어 에이전트(Zhou et al., 2023b)를 사용자 맞춤화함으로써 _human-AI co-editing_를 가능하게 한다; (2) 사용자가 웹 사이트를 저장하거나 문서를 업로드하여 _personal 지식베이스_를 구축하고 위버에 지식베이스를 통합하는 RAG 파이프라인을 구축하도록 한다; (3) 플랫폼 상의 그들의 작성 이력을 기반으로 LLM을 사용하여 사용자들의 개인 작성 스타일을 분석하고 그 결과를 사용하여 위버의 텍스트 생성 프로세스를 안내함으로써 _personalized writing assistance_를 제공할 것을 제안한다. 이와 같은 혁신을 접목하여 WawaWriter는 보다 도움이 되고 즐거운 차세대 AI 지원 글쓰기 경험을 제공하는 것을 목표로 한다.\n' +
      '\n' +
      '다음 섹션에서는 먼저 위버 패밀리의 아키텍처와 크기 및 사전 훈련 단계에 대해 설명한다. 그런 다음 위버의 능력에 대한 세부 사항, 위버가 이러한 능력을 습득하고 인간과 같은 스타일리시한 텍스트를 생성하는 데 도움이 되는 훈련 데이터를 합성하는 방법 및 정렬 단계에 대한 세부 사항을 제시한다. 또한 LLM의 쓰기 능력을 평가하기 위한 벤치마크와 평가 결과를 제시한다. 마지막으로 WawaWriter의 세부 사항을 소개하고 Weaver가 차세대 AI 지원 글쓰기 경험을 위한 길을 여는 방법을 제시한다.\n' +
      '\n' +
      '## 2 Pre-training\n' +
      '\n' +
      '### Model Family\n' +
      '\n' +
      '위버 모델은 트랜스포머 디코더 위에 구축된 언어 모델입니다. 우리는 최근 가장 인기 있는 오픈 소스 LLM인 LLaMA(Touvron et al., 2023a,b)의 설계로부터 개선 사항을 채택했는데, 그 예로는 RMSNorm(Zhang and Sennrich, 2019) 기능을 갖는 Pre-Norm 구조, Feed-Forward Network에 대한 활성화 함수로서 SwiGLU(Shazeer, 2020), 위치 인코딩을 위한 Rotary Embedding(Su et al., 2024), 및 GQA(Grouped-Query Attention)(Ainslie et al., 2023) 등이 있다.\n' +
      '\n' +
      '위버 패밀리는 1.8B에서 34B 매개변수 범위의 미니, 베이스, 프로 및 울트라의 4가지 다른 크기의 모델로 구성된다. 우리는 쓰기 작업의 복잡성이 도메인 및 사용 사례에 따라 많이 다르기 때문에 다양한 응용 프로그램을 지원하기 위해 다양한 모델 크기를 훈련한다. 모든 위버 모델은 강력한 오픈 소스 LLM에서 초기화됩니다. 표 1에서 위버 모델의 상세한 구성과 설명을 제공한다.\n' +
      '\n' +
      '### Pre-training Data\n' +
      '\n' +
      '그런 다음 사전 훈련 데이터 선택 전략과 그에 따른 사전 훈련 데이터 혼합물에 대한 개요를 제시한다. 위버 모델은 강력한 오픈 소스 LLM에서 초기화되어 이미 적절한 세계 지식을 보유하고 있기 때문에 지속적인 사전 훈련 데이터의 양이 초대형일 필요가 없다. 우리는 계속적인 사전 훈련 단계를 위버가 능력을 재할당하거나 재균형하도록 학습하는 과정으로 간주한다: 모델은 수학과 코딩과 같은 다른 영역의 능력을 줄이면서 쓰기 및 콘텐츠 생성에 더 많은 능력을 할당한다.\n' +
      '\n' +
      '따라서 사전 학습 데이터에는 책, 소설, 이야기, 뉴스 기사, 논문, 보고서, 소셜 미디어 사본 등 다양한 콘텐츠를 포함하는 수동으로 검증된 데이터 소스만 포함한다. 저품질 텍스트를 필터링하기 위해 규칙 기반 방법과 기계 학습 기반 방법을 결합합니다. 데이터 소스 및 필터링 외에도 서로 다른 도메인 간의 데이터 혼합을 주의 깊게 제어합니다. 구체적으로 픽션 데이터(즉, 픽션 및 스토리)와 논픽션 데이터(즉, 기사, 논문, 보고서 등)를 \\(1:1\\)의 비율로 혼합한다. 또한 위버가 중국어와 영어를 모두 지원할 수 있도록 중국어와 영어 데이터를 \\(4:1\\)의 일부로 혼합한다.\n' +
      '\n' +
      '### Training Details\n' +
      '\n' +
      '우리는 모델이 이전 토큰의 컨텍스트를 기반으로 다음 토큰을 예측하도록 학습하는 표준 자기회귀 언어 모델링 작업을 사용하여 위버를 훈련한다. 컨텍스트 길이가 4096인 위버 모델을 학습하고, 문서를 섞고 병합한 후 지정된 컨텍스트 길이로 잘라 학습 배치를 생성한다. Megatron-Deepspeed (Shoeybi et al., 2019)와 Flash Attention2 (Dao, 2023; Dao et al., 2022)를 통합하여 계산 효율을 높이고 메모리 사용량을 줄인다. 표준 최적화기 AdamW(Loshchilov and Hutter, 2017)를 채택하여 하이퍼파라미터 \\(\\beta_{1}=0.9\\), \\(\\beta_{2}=0.95\\), \\(\\varepsilon=10^{-8}\\)을 설정하였다. 우리는 각 모델에 대해 지정된 최고 학습률을 갖는 코사인 학습률 스케줄을 사용한다. 학습률은 최고 학습률의 10%의 최소 학습률로 붕괴된다. 모든 모델은 훈련 안정성을 위해 BFloat16 혼합 정밀도로 훈련된다. 표 1에서 각 모델에 대한 상세한 사전 훈련 구성을 제시한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c c c} \\hline \\hline Name & Params & \\(n_{\\text{layers}}\\) & \\(d_{\\text{model}}\\) & \\(n_{\\text{heads}}\\) & Context Length & Sequence & Learning Rate & Tokens \\\\ \\hline Weaver Mini & 1.8B & 24 & 2048 & 16 & 4096 & 512 & 1e-4 & 50B \\\\ Weaver Base & 6B & 32 & 4096 & 32 & 4096 & 512 & 1e-4 & 50B \\\\ Weaver Pro & 14B & 40 & 5120 & 40 & 4096 & 512 & 1e-4 & 40B \\\\ Weaver Ultra & 34B & 60 & 7168 & 56 & 4096 & 520 & 5e-5 & 18B \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 위버 패밀리에 대한 설명.\n' +
      '\n' +
      '## 3 데이터 합성\n' +
      '\n' +
      '사전 훈련 후 위버 모델은 많은 양의 세계 지식과 쓰기 기술을 포함하고 고품질 컨텍스트에서 인간과 유사한 텍스트를 생성할 수 있다. 실제 응용 프로그램에 대한 이러한 기능을 잠금 해제하려면 정렬을 위한 고품질 데이터 세트를 큐레이션해야 합니다. 데이터 세트의 형식과 품질은 능력의 적용 범위와 정렬된 모델의 품질에 상당한 영향을 미친다. 서론에서 논의한 바와 같이 기존 일반주의 LLM의 정렬 데이터 수집을 위한 일반적인 관행은 쓰기 능력을 심각하게 제한한다. 이 섹션에서는 데이터 합성 프레임워크를 자세히 설명한다. 먼저 정렬 단계에서 잠금 해제하고자 하는 능력을 설명하고, 지도 미세 조정과 선호도 최적화 단계를 위한 제안된 데이터 합성 방법을 제시한다.\n' +
      '\n' +
      '### Abilities\n' +
      '\n' +
      '먼저 정렬 단계에서 위버를 위해 잠금 해제하려는 능력의 범주를 설명한다.\n' +
      '\n' +
      '###### 3.1.1 안내 후\n' +
      '\n' +
      '우리가 풀어야 할 첫 번째 명백한 능력은 쓰기 지침을 따르고 인간과 같은 스타일리시한 텍스트를 생산하는 능력이다. 우리는 데이터 수집 및 정렬 교육 동안 아래에 나열된 다양한 도메인과 작업을 다룬다.\n' +
      '\n' +
      '##### 3.1.1.1 Domains\n' +
      '\n' +
      '**픽션 쓰기:**픽션 쓰기는 모델들이 이야기와 픽션을 쓰는 능력을 말합니다. 우리는 소설 쓰기를 소설의 길이와 장르에 따라 여러 하위 영역으로 나눈다. 우리는 공상과학, 로맨스, 판타지, 공포, 미스터리, 스릴러를 포함한 소설과 몇 백에서 몇 백만 명의 등장인물, 소설 유형을 다룬다.\n' +
      '\n' +
      '**창의 논픽션 글쓰기:** 창의 논픽션 글쓰기는 문학적 스타일과 기법을 활용하여 사실적으로 정확한 서사를 만들어내는 글쓰기 장르이다. 우리는 회고록, 전기, 여행기, 저널리즘, 소셜 미디어 복사, 블로그 게시물, 뉴스 기사, 해설 등을 포함한 전형적인 창의적 논픽션 작성 사례를 다룬다.\n' +
      '\n' +
      '**마케팅 글쓰기:** 우리는 또한 마케팅 글쓰기를 고려하는데, 마케팅 글쓰기는 사업 계획서, 광고 복사본, 제품 홍보, 마케팅 계획서 등을 작성한다. 마케팅 글쓰기는 응용 중심성이 높고 생성된 글의 스타일이 가장 중요하지 않기 때문에 이전 범주와 다르다. 그러나 마케팅 글쓰기는 잠재적인 사용자를 끌어들이기 위해 여전히 인간과 같은 창의성을 요구한다.\n' +
      '\n' +
      '**기술 쓰기:**기술 쓰기는 종이 쓰기, 특허 쓰기, 보고서 쓰기 등의 작업을 포함한다. 기술적 글쓰기는 창의성에 비해 정확성이 더 요구된다. 그러나 글쓰기 특정 교육은 모델이 특정 시나리오에 필요한 스타일을 정확하게 준수하는 텍스트를 생성하는 데 도움이 될 수 있기 때문에 여전히 도움이 될 수 있다.\n' +
      '\n' +
      '##### 3.1.1.2 Tasks\n' +
      '\n' +
      '**콘텐츠 작성:**콘텐츠 작성은 모델이 특정 지시에 기초하여 콘텐츠(즉, 픽션, 기사 등)를 생성하도록 요구하는 기본 작업이다. 작성 지침은 이전 컨텍스트가 제공되는지 여부 및 주어진 지침이 얼마나 세밀하게 분류되는지의 측면에서 다양하다. 이 작업은 LLM이 지침에서 표현된 특정 요구 사항을 이해하고 준수할 수 있어야 하며 이전 맥락과 일관되고 일관된 텍스트를 생산해야 한다. 예를 들어, 전형적인 콘텐츠 작성 지침은 "사람들이 마침내 AGI를 달성한 후에 무슨 일이 일어날지에 대한 공상 과학을 작성하는 것을 도와주세요."입니다.\n' +
      '\n' +
      '**아웃라이닝:**아웃라이닝은 개요를 작성하는 작업으로, 픽션과 논픽션 작문 모두에서 작가에게 일반적인 관행이다. 긴 텍스트 생성의 문헌에서 논의된 바와 같이(Sun et al., 2022; Yang et al., 2022; Zhou et al., 2019, 2023; Zhu et al., 2019, 2023), 긴 텍스트를 생성하기 전에 모델이 먼저 윤곽을 생성하도록 하는 것은 종종 도움이 된다. 윤곽선은 다른 도메인과 윤곽선의 입도/길이에 따라 다릅니다. 개요 작업의 한 예는 "제 연간 작업 보고서의 개요를 작성하는 것을 도와주세요."입니다.\n' +
      '\n' +
      '**Polishing & Editing:** Polishing and editing은 모델이 한 단락의 품질을 개선하거나 지침서에 표현된 요구 사항에 따라 다시 작성하도록 요구한다. 상기 과제는 문법적 오류 수정(Byant et al., 2019; Ng et al., 2014)의 과제와 밀접한 관련이 있으며, 수정들이 반드시 문법적 오류는 아니라는 핵심적인 차이점이 있다. Diao et al. (2023)에 기술된 학술적 글쓰기 연마의 과제와 비교하여, 우리는 AI-보조 글쓰기 시스템에서 인간-AI 상호작용에 중요한 연마 또는 편집 요구사항에 대한 맞춤화된 세립식 제어를 지원한다. 전형적인 연마 지침은 다음과 같이 보일 수 있다. "다음 텍스트를 수정할 수 있도록 도와주세요, 수정된 텍스트가 학술 논문에 적합해야 함을 명심하세요."\n' +
      '\n' +
      '**스타일 전이:** 텍스트 스타일 전이의 작업은 모델이 한 스타일의 텍스트를 다른 스타일로 변환하도록 요구한다. 예를 들어, 이야기를 스크립트로 변환하거나 보고서를 스피치 라이팅으로 변환하기를 원할 수 있다. 우리는 템플릿을 사용하여 타겟 스타일 정보를 제공하는 템플릿 기반 스타일 전송(Guu et al., 2018; Lewis et al., 2020)과 타겟 스타일에 대한 키워드(Hu et al., 2017) 또는 짧은 설명(Zhou et al., 2023) 중 하나를 사용하는 기술 기반 스타일 전송을 모두 포함한다. 예를 들어, 모델에 "다음 책 장을 스크립트로 변환"하도록 요청할 수 있습니다.\n' +
      '\n' +
      '**확장/단순화:**텍스트 확장 및 단순화는 모델이 특정 지시에 따라 입력 단락을 더 길게 또는 더 짧게 만들도록 수정하도록 요구한다. 텍스트 요약과 요약 대 아티클 생성은 이 과제의 두 가지 극단적인 경우로 간주될 수 있다. 한 가지 모범적인 지침은 "이 단락을 한 문장으로 요약하는 것을 도와주세요."입니다.\n' +
      '\n' +
      '**브레인스토밍:**브레인스토밍은 사용자가 현재 컨텍스트 및 사용자 지시에 기초하여 창의적인 아이디어를 도출하는 것을 돕기 위해 모델이 필요하다. 전형적인 브레인스토밍 지침은 다음과 같다. "악당이 다음 장에 등장할 수 있도록 그의 이름, 외모, 직업, 배경 등 가능한 5가지 캐릭터 묘사를 알려주세요."\n' +
      '\n' +
      '**검토:**검토는 주어진 텍스트 조각을 비판적으로 읽고 분석한 후 댓글을 작성하거나 제안을 수정하는 작업을 말한다. 예를 들어, 모델에게 "제 에세이를 살펴보고 이를 개선하기 위한 5가지 제안을 나열해 주세요."라고 요청할 수 있습니다.\n' +
      '\n' +
      '###### 3.1.2 명령어 주석\n' +
      '\n' +
      '우리는 또한 지시 주석 작업을 지원하기 위해 위버를 훈련시킨다. Humpback(Li et al., 2023) 및 LongForm(Koksal et al., 2023)에서 설명된 바와 같이, 텍스트 조각이 주어지면, 태스크는 모델이 입력 텍스트들이 답일 수 있는 명령어를 생성하도록 요구한다. 그러나 바닐라 명령어 역 번역은 쓰기 작업만 지원합니다. 따라서 명령어 주석을 위해 모델은 텍스트 스팬을 기반으로 명령어-응답 쌍을 합성해야 한다. 응답은 텍스트 범위, 텍스트 범위의 일부 또는 텍스트 범위에서 추론될 수 있습니다. 이는 대부분의 자동 채굴 텍스트 스팬이 그 자체의 특정 명령에 적합하지 않을 수 있는 반면 텍스트 스팬의 일부는 유효한 응답일 수 있거나 이를 기반으로 고품질 명령어-응답 쌍을 구성할 수 있기 때문에 바닐라 명령어 역변환의 범위를 실질적으로 넓힌다. 지시 주석 능력은 위버가 대규모 말뭉치에서 자신을 위한 훈련 데이터를 채굴할 수 있게 하여 웹 데이터_에서 _scalable self-training의 가능성을 열어준다.\n' +
      '\n' +
      '####3.1.3 평가(문학 비평)\n' +
      '\n' +
      '최근의 많은 연구는 태스크들(Chan et al., 2023; Jiang et al., 2023; Wang et al., 2023)에 따른 일반적인 지시를 평가하기 위해 LLM들을 사용하거나 트레이닝하는 것을 탐구했다. 그러나 일반주의 LLM은 창의적인 글쓰기와 관련된 작업을 평가하기에 적합하도록 광범위한 프롬프트 기술이 필요하다는 것을 발견했다. 더욱이, 창작 글쓰기를 전공하는 거의 모든 학생들도 문학 평론가 과정을 수강해야 하기 때문에, 우리는 문학 평론가를 수행하는 학습이 모델이 더 나은 텍스트를 생산하는 데 도움이 될 수 있다고 생각한다. 따라서 우리는 또한 위버를 훈련하여 작성 지침에 대한 응답의 품질을 판단하고 두 응답의 쌍대 비교를 수행한다.\n' +
      '\n' +
      '인공지능 기반 필기 플랫폼인 WawaWriter에서 모델 출력 간의 인간 선호도를 수집하고, 수집된 선호도 데이터를 신중하게 선별된 템플릿을 사용하여 LLM 기반 평가를 위한 훈련 데이터로 변환한다.\n' +
      '\n' +
      '######3.1.4 검색-증강 생성\n' +
      '\n' +
      '검색-증강 생성(RAG)의 능력(Gao et al., 2023; Lewis et al., 2020), 즉 외부 지식 또는 참조를 컨텍스트로서 참조하여 응답들을 생성하는 것. RAG는 LLM이 보다 정확하고 정보에 입각한 응답을 생성하는 데 도움이 되는 중요한 기술이다. 인간 작가가 소설이나 기사를 쓸 때 다른 텍스트 샘플을 참조하는 것이 일반적이기 때문에 글쓰기에 특히 도움이 될 수 있다. 그러나 대부분의 기존 LLM은 순전히 RAG를 수행하기 위해 신속한 엔지니어링에 의존하고 정렬 중에 RAG 훈련을 수행하지 않는다. 우리는 이것이 검색된 컨텍스트를 사용하는 LLM의 능력을 제한한다고 믿는다. 따라서 본 논문에서는 위버의 검색 증강 생성 능력을 향상시키기 위해 정렬 시 RAG 인식 학습 데이터를 포함할 것을 제안한다. 특히, 목표 응답과 가장 유사한 단락을 검색하여 얻은 관련 컨텍스트를 추가함으로써 훈련 데이터의 10%%를 증가시킨다. 이러한 방식으로, 위버는 외부 컨텍스트를 참조하여 쓰는 것을 학습하고, 따라서 대부분의 기존 LLM에 비해 RAG 기술과 더 호환된다.\n' +
      '\n' +
      '###### 3.1.5 기능 호출\n' +
      '\n' +
      '도구를 사용하는 능력은 또한 LLM(Schick et al., 2023)에 매우 중요하다. "기능 호출"이라고도 하는 이 기능은 모델이 인간-AI 협력 작문을 수행할 때 참조 또는 편집기 API를 위해 인터넷을 검색해야 할 수 있기 때문에 작문에 도움이 된다. 기능 호출 능력의 잠금을 해제하기 위해, 우리는 감독된 미세 조정 데이터에 데이터세트2를 호출하는 오픈 소스 기능을 포함한다. 또한 GPT-4를 사용하여 여러 도구와 API로 다양한 환경을 합성하고 문서화를 통해 보다 다양한 기능 호출 데이터를 합성할 수 있는 새로운 파이프라인을 제안한다. 그런 다음 우리는 한 번에 하나의 API를 무작위로 선택하고 GPT-4에 API가 도움이 될 수 있는 상황과 API에 대한 그럴듯한 주장을 상상하도록 요청한다. 그런 다음 API가 인수와 함께 사용되도록 해당 상황에서 LLM에 지시할 수 있는 것을 추론한다. 마지막으로 GPT가 호출을 지원하는 방법과 유사하게 올바른 API를 선택하고 명령어와 컨텍스트가 주어진 인수를 생성하여 위버가 도구를 사용하도록 훈련한다.\n' +
      '\n' +
      '각주 2: [https://huggingface.co/glaiveai](https://huggingface.co/glaiveai)\n' +
      '\n' +
      '### Instruction Backtranslation\n' +
      '\n' +
      '그런 다음 제안된 개선된 명령어 역변환 파이프라인을 설명한다. 자기 지시(Wang et al., 2023a)와 같은 지시 증강 방법 대신에 지시 역 번역을 하기 위한 동기는 매우 간단하다: 우리는 위버를 고품질, 스타일리시하고 사람이 쓴 텍스트에 정렬하고자 한다. 이 목표를 달성하기 위해 먼저 고품질 이야기, 픽션 챕터 및 다양한 도메인의 사본을 수집합니다. 수집된 텍스트의 범주를 표 2에 나열한다.\n' +
      '\n' +
      '그런 다음 세심하게 설계된 소수의 프롬프트 템플릿을 사용하여 앞서 언급한 모든 쓰기 작업에 대한 명령어-응답 쌍을 합성한다. 구체적으로, 각 하위 도메인-작업 쌍에 대해, 주석이 달린 결과와 주석 프로세스의 근거 모두를 포함하여 명령-응답 쌍을 작성할 수 있는 방법에 대한 5가지 사례에 주석을 달는다: 먼저 사례로부터 텍스트 스팬을 출력으로 선택한다(추가 프롬프트와 함께 선택된 텍스트 스팬으로부터 출력이 변환되는 작업의 개요, 브레인스토밍 및 검토). 그런 다음 우리는 출력에 대한 컨텍스트를 식별하거나 생성한다. 예를 들어, 폴리싱 작업의 경우 컨텍스트가 타겟 출력의 더 나쁜 버전이어야 하므로, 타겟 출력의 문구와 구조를 수정하여 더 나빠 보이게 할 수 있다. 그런 다음 컨텍스트를 출력으로 변환하는 데 사용할 수 있는 명령어를 추론한다. 연마 작업을 다시 예로 들자면, 우리는 어떤 수정이 이루어졌는지 추론하고 그에 따라 연마 지침을 합성해야 한다. 각 레이블이 없는 경우에 대해 주석이 달린 경우를 소수의 예시로 사용하고 GPT-4에게 먼저 Chain-of-Thought 스타일로 주석 프로세스를 생성한 다음(Wei et al., 2022) 합성된 명령어-응답 쌍을 생성하도록 요청한다. 명령어 역번역 파이프라인은 그림 1에 나와 있다. 이 파이프라인으로 모든 도메인 및 작업에 걸쳐 500,000개의 고품질 명령-응답 쌍을 합성한다. 마지막으로, 우리는 (Liu et al., 2023)에 설명된 관행에 따라 명령어 데이터 선택 절차를 수행한다: 먼저 모든 명령어-응답 쌍을 GPT-3.5-터보로 점수화한 다음 지도된 미세 조정을 위해 각 하위 도메인-작업 쌍에서 최상위 데이터를 선택한다. 구체적으로, 수업의 질과 다양성, 수업과 반응 사이의 관련성을 기반으로 각 수업-반응 쌍을 점수화한다.\n' +
      '\n' +
      '### Constitution DPO: Principlipled negative examples로부터 학습\n' +
      '\n' +
      '마지막으로, 우리는 LLM이 최적의 정책 및 AI 피드백으로 합성된 "원칙적" 부정적인 예제의 샘플로 구성된 선호도 데이터에서 학습하도록 유도하는 새로운 정렬 방법인 헌법 DPO를 제안한다. 우리의 접근법은 인간 전문가가 작성한 원칙에 기초하여 보상 모델을 훈련하는 헌법 AI(Bai et al., 2022; Sun et al., 2023), LLM이 AI 생성 선호도 데이터로 긍정/부정 예제 및 보상 모델을 훈련하도록 유도하는 RLCD(Yang et al., 2023), 및 DPO(Rafailov et al., 2023)의 장점을 결합하여, 모델 훈련을 생략하고 직접 선호도 최적화를 수행한다.\n' +
      '\n' +
      '구체적으로, 먼저 전문 작가, 편집자, 콘텐츠 제작자를 포함한 인간 전문가를 초대하여 다양한 작문 작업에 대한 원칙에 주석을 달 수 있습니다. 원칙에 대한 간단한 설명만 쓰는 이전의 "원칙 기반" 접근법과 달리 각 원칙에 대해 원칙을 준수하는 사례 1건과 원칙을 위반하는 사례 1건을 수집하고 사례가 원칙을 준수하거나 위반하는 이유를 설명하는 자연어 근거도 수집한다. 그런 다음 앞서 언급한 데이터 필터링 과정에서 가장 높은 점수를 받은 명령어 데이터의 부분 집합을 샘플링하고 출력 텍스트가 신중하게 선택되고 명령어-출력 쌍이 상위 순위이기 때문에 최적의 정책에서 샘플로 간주한다. 각 표본에 대해 먼저 과제에 대한 원리를 제시하고 GPT에게 반응이 좋은 이유를 가장 잘 설명할 수 있는 원리를 분석할 것을 요청한다. 그런 다음 GPT에 최소한의 수정을 추가하면서 원리를 위반하는 반응의 상대방을 합성하고 원래 반응의 다른 좋은 측면에 영향을 미치지 않도록 요청한다.\n' +
      '\n' +
      '수집된 데이터를 사용하여 원래 교란된 반응 쌍을 \\((y_{w},y_{l})\\) 쌍으로 간주하고 표준 DPO 훈련을 수행한다. 이러한 방식으로, 각각의 데이터 쌍은 대응하는 원리들에 대한 중요한 트레이닝 신호들을 포함하고, 원리들을 따르도록 모델을 미세조정하는 것을 돕는다. 이 방법을 통해 합성된 선호도 데이터는 표준 RLAIF 파이프라인에 비해 훨씬 적은 노이즈를 포함하고 있으며, 특히 LLM이 문학 평론가를 위해 고군분투하기 때문에 쓰기 도메인에서 더욱 그렇다. 선호도 데이터 생성을 위한 가장 관련된 방법인 RLCD와 비교하여 LLM 생성 대신 고품질 SFT 데이터를 긍정적인 예로 간주하고 부정적인 예제 생성을 위해 전문가 작성 원칙을 사용한다. 이것은 훈련 신호를 덜 잡음으로 만들고 더 원칙적으로 만든다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{p{85.4pt} p{113.8pt} p{113.8pt}} \\hline \\hline Domain & Task & Principles \\\\ \\hline Creative Non-fiction Writing & Content Writing & The content should be created to encourage readers to engage in interactions, comments, etc. \\\\  & Polishing \\& Editing Brainstorming & The revised content should align with the original text. The content should refrain from pre-judging ideas. \\\\ \\hline Technical Writing & Content Writing & The generated content should avoid bias toward certain genders, professions, regions, etc. \\\\  & Style Transferring & The style of the content should be consistent with the language style specified in the instructions. \\\\ \\hline Fiction & Content Writing & The perspective should remain consistent with the outline or previous content. \\\\  & Outlining & The global outline should not be too brief or general, omitting key plot points. \\\\ \\hline Marketing Writng & Content Writing & The content of the market writing should be accurate. \\\\  & Summarizing & The summarized content should be all-encompassing, leaving out no crucial points. \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 4개의 영역 및 샘플링된 작업에서 전문가 주석이 달린 원칙의 예.\n' +
      '\n' +
      '## 4 Alignment\n' +
      '\n' +
      '### Supervised Fine-tuning\n' +
      '\n' +
      '#### 4.1.1 Data\n' +
      '\n' +
      '감독 미세 조정을 위한 데이터 세트를 수집하기 위해 먼저 인간 작가와 콘텐츠 제작자가 작성한 고품질 콘텐츠를 등급, 읽기 수, 상향표 및 댓글을 포함한 메타데이터에 따라 수집한다. 우리는 앞서 언급한 데이터 합성 프레임워크를 채택하여 10개 이상의 작업, 명령어 주석 데이터, 텍스트 생성 평가 데이터, 검색 증강 생성 데이터 및 기능 호출 데이터를 포함하는 데이터에 이어 명령어를 합성한다. 결합된 명령어 튜닝 데이터 세트는 약 1,000,000개의 샘플로 구성된다. 그런 다음 데이터 필터링 프로세스를 실행하고 감독 미세 조정을 위한 최종 데이터 세트로 40만 개의 데이터 포인트를 선택한다.\n' +
      '\n' +
      '#### 4.1.2 Training\n' +
      '\n' +
      '우리는 3~5시대에 대해 지속적으로 사전 훈련된 모델을 미세 조정한다. 우리는 5% 워밍업 단계로 더 큰 모델(즉, 위버 울트라 및 위버 프로)의 경우 1e-5 및 2e-5의 최대 학습 속도를 갖는 코사인 학습 속도 스케줄러를 사용하고 더 작은 모델(즉, 위버 베이스 및 위버 미니)의 경우 4e-5를 사용한다. 우리는 전체 배치 크기가 256인 모든 모델을 훈련하고, 감독 미세 조정 후 선호도 최적화를 위한 내부 검증 세트에서 가장 성능이 좋은 체크포인트를 선택한다.\n' +
      '\n' +
      '### Preference Optimization\n' +
      '\n' +
      '#### 4.2.1 Data\n' +
      '\n' +
      '선호도 최적화를 위해 각 하위 도메인에 대한 데이터 필터링 단계에서 최고 등급 샘플 500개를 체질 DPO 파이프라인에 대한 긍정적인 예로 선택한다. 우리는 200개 이상의 원칙과 그에 상응하는 소수의 사례를 수집한다. 우리는 긍정적인 예제당 하나의 부정적인 예를 생성하여 25,000개의 선호 데이터 쌍을 생성한다.\n' +
      '\n' +
      '#### 4.2.2 Training\n' +
      '\n' +
      '우리는 기존의 DPO 알고리즘을 사용하여 감독된 미세 조정 모델을 미세 조정한다. 우리는 3~5년 동안 모델을 훈련시킵니다. 피크 학습률이 5e-7이고 워밍업 단계가 5%인 선형 학습률 스케줄러를 사용한다. 우리는 전체 배치 크기 40을 사용하여 위버 울트라를 훈련하고, 다른 것들은 32를 사용하여 \\(\\beta=0.1\\)을 설정한다. 내부 검증 세트에서 가장 성능이 좋은 체크포인트를 최종 위버 모델로 선택한다.\n' +
      '\n' +
      '## 5 Evaluation\n' +
      '\n' +
      '### WriteBench\n' +
      '\n' +
      'LIMs(Zheng et al., 2023) 및 자연어 생성에 대한 대부분의 기존 벤치마크들(Jiang et al., 2023; Lin et al., 2020)은 LIMs가 창의적이고 스타일리시하며 인간다운 텍스트 콘텐츠를 생성하는 능력 대신에 추론 능력 또는 범용 명령어 추종 능력에 초점을 맞춘다. 이를 위해 LLMs3의 쓰기 능력을 평가하기 위한 새로운 벤치마크인 WriteBench를 구성한다.\n' +
      '\n' +
      '각주 3: WriteBench는 [https://github.com/aiwaves-cn/WriteBench](https://github.com/aiwaves-cn/WriteBench)에서 공개적으로 이용가능할 것이다.\n' +
      '\n' +
      '위버에 대한 훈련 데이터를 수집하는 방법과 유사하게 WriteBench는 여러 도메인과 작업을 포함하도록 설계되었다. 위버와 비교 일반 LLM 간의 공정한 비교를 보장하기 위해 WriteBench의 지침에 대한 데이터 수집 및 데이터 선택 프로세스는 독립적인 평가 팀에 의해 수행된다. 결과 WriteBench는 소설 쓰기, 창의적 논픽션 쓰기, 기술 쓰기, 마케팅 쓰기를 포함한 네 가지 영역을 포괄하는 1000개 이상의 테스트 지침으로 구성되어 있다. WriteBench 벤치마크의 첫 번째 공개는 비교된 모델의 중국어 쓰기 능력을 측정하고자 하기 때문에 중국어로 되어 있다.\n' +
      '\n' +
      '### Compared Models\n' +
      '\n' +
      '우리는 위버를 GPT-4, GPT-3.5, GLM-4, Claude2, Gemini Pro, ERNIE- Bot-4.0, ERNIE- Bot-3.5, Qwen-72B-Chat, Qwen-14B-Chat, Qwen-7B-Chat, Qwen-1.8B-Chat, YI-34B-Chat, YI-6B-Chat 및 ChatGLM3-6B를 포함한 다양한 크기의 오픈 소스 모델과 독점 모델을 포함한 경쟁력 있는 중국 LLM과 비교한다. 우리는 WriteBench에서 테스트된 모든 LLM에 대한 입력 프롬프트로 동일한 지침을 직접 사용하고 모델 출력을 응답으로 수집한다.\n' +
      '\n' +
      '### LIM-based Evaluation\n' +
      '\n' +
      '먼저 LLM 기반 평가를 수행하여 비교된 모델에 대한 거친 등급 평가를 수행한다. MT-벤치의 연습 및 프롬프트 템플릿에 따라 각 지시-응답 쌍을 점수화하기 위해 GPT-4를 판사로 사용한다. 그 결과는 표 4와 같다. 글쓰기 스타일 및 창의성 측면에서 위버 울트라가 GPT-4 및 GLM-4와 같은 강력한 경쟁자를 포함한 모든 독점 모델보다 훨씬 우수하다는 것을 발견했다. GPT-4 및 GLM-4는 위버 울트라보다 최소 몇 배 이상 크고 따라서 더 나은 지시-추종 능력을 가지고 있기 때문에 관련성 메트릭에서 더 우수하다. 다른 크기의 위버는 14B 매개 변수만 있으면 위버 프로가 70B 및 34B 매개 변수를 포함한 모든 오픈 소스 모델뿐만 아니라 대부분의 독점 모델을 능가한다는 것을 알 수 있다. 유사하게, 위버 베이스 및 위버 미니는 또한 2배 이상의 크기를 갖는 일반주의자 LLM과 비교된다. 전반적으로, 결과는 창의적 글쓰기에 특화된 LLM에 대한 데이터 합성 및 훈련 프레임워크의 효과를 확인한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c} \\hline \\hline\n' +
      '**Models** & **Style** & **Relevance** & **Creativity** & **Overall** \\\\ \\hline\n' +
      '**Weaver Ultra** & 8.94 & 8.96 & 7.71 & 8.54\\\\\n' +
      '**GLM-4** & 8.83 & 9.55 & 6.58 & 8.32\\\\\n' +
      '**GPT-4** & 8.80 & 9.45 & 6.32 & 8.19\\\\\n' +
      '**Weaver Pro** & 8.52 & 8.45 & 7.3 & 8.09\\\\\n' +
      'YI-34B-Chat** & 8.70 & 9.17 & 6.26 & 8.04\\\\\n' +
      'claude2** & 8.42 & 8.89 & 6.41 & 7.91\\\\\n' +
      'Qwen-72B-Chat** & 8.47 & 8.98 & 5.95 & 7.80\\\\\n' +
      '**위버베이스** & 8.61 & 8.81 & 5.89 & 7.77\\\\\n' +
      'Qwen-14B-Chat** & 8.51 & 8.85 & 5.89 & 7.75\\\\\n' +
      '**위버 미니** & 8.41 & 8.38 & 6.35 & 7.71\\\\\n' +
      '***emini Pro** & 8.39 & 8.79 & 5.88 & 7.69\\\\\n' +
      'Qwen-7B-Chat** & 8.40 & 8.80 & 5.81 & 7.67\\\\\n' +
      'Yi.6B-Chat** & 8.24 & 8.67 & 6.00 & 7.64\\\\\n' +
      'ChatGLM3-6B** & 8.16 & 8.70 & 5.86 & 7.57\\\\\n' +
      '**GPT-3.5** & 8.37 & 8.65 & 5.60 & 7.54\\\\\n' +
      '**ERNIE- Bot-3.5** & 8.24 & 8.22 & 5.71 & 7.39\\\\\n' +
      '**ERNIE- Bot-4.0** & 8.15 & 8.05 & 5.61 & 7.27\\\\\n' +
      '**Qwen-1.8B-Chat** & 7.97 & 7.86 & 5.66 & 7.16 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: LLM 기반 평가 결과\n' +
      '\n' +
      '### Human Evaluation\n' +
      '\n' +
      '그런 다음 위버를 GPT-4, GLM-4, ERNIE-Bot-4.0 및 제미니-프로를 포함한 몇 가지 대표적인 LLM과 비교하기 위해 인간 평가를 수행한다. 우리는 인간 평가에서 44명의 전문 중국 작가 또는 편집자를 인간 주석자로 모집합니다. 챗봇 아레나4 벤치마크에서 실습을 채택하고 인간 주석자가 창의성, 스타일리시, 관련성 및 유창성에 따라 두 모델 출력 간의 3원 쌍별 비교를 수행할 수 있도록 한다. 우리는 3540개의 비교 결과를 수집하고 비교된 모델의 ELO 등급을 계산한다. 소설 작성과 전체 비교에 대한 결과는 각각 표 5와 표 6과 같다. 우리는 전문 작가와 편집자가 모든 메트릭에서 비교된 모델보다 위버 울트라를 훨씬 더 잘 평가한다는 것을 알 수 있다. 비교된 다른 모델의 경우 GPT-4 및 제미니 프로가 GLM-4 및 ERNIE-Bot에 비해 더 창의적이고 인간과 유사한 텍스트를 생성하는 것으로 간주된다는 것을 발견했으며, 이는 GLM 및 ERNIE가 GPT 증류 데이터를 사용하여 정렬되어 창의성에 해를 끼칠 수 있기 때문이라고 의심한다.\n' +
      '\n' +
      '각주 4: [https://chat.lmsys.org/](https://chat.lmsys.org/)\n' +
      '\n' +
      '### User Study\n' +
      '\n' +
      'AI 지원 글쓰기를 위한 좋은 LLM은 벤치마크에서 가장 성능이 좋을 뿐만 아니라 실제 글쓰기 시나리오에서 **진실로 도움이 되어야 한다. 위버가 얼마나 진정으로 도움이 되는지 평가하기 위해 5명의 전문 작가를 대상으로 모집하는 사용자 연구를 수행한다. 각 주제에는 위버 울트라와 GPT-4의 두 가지 채팅 인터페이스가 제공되고, 각 주제에는 GPT-4와 위버 울트라로 구동되는 두 개의 동일한 채팅 인터페이스로 약 6,000개 단어의 짧은 이야기(두 개의 신중하게 선택된 주제)를 작성하도록 하며, 두 이야기를 완성하기 위해 동일한 작가가 사용하는 시간을 측정하고 전문 편집자에게 품질을 판단하도록 요청한다. 우리는 GPT-4에 비해 위버 울트라가 작가의 효율성을 약 3배 향상시킨다는 것을 발견했다. 또한 5개의 주제 중 휴먼 에디터는 위버가 4회 생성한 스토리를 선호하고 나머지 주제에 대한 승자를 결정할 수 없다. 우리의 사용자 인터뷰는 효율성 향상이 주로 위버가 더 빠르고 덜 필요로 하는 더 많은 인간 유사 텍스트를 생성한다는 사실에서 비롯된다는 것을 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline\n' +
      '**Models** & **Creativity** & **Style** & **Relevance** & **Fluency** & **Overall** \\\\ \\hline\n' +
      '**Weaver Ultra** & **1589** & **1590** & **1593** & **1588** & **1576**\n' +
      '**GLM-4** & 1482 & 1527 & 1491 & 1513 & 1521\\\\\n' +
      '**GPT-4** & 1468 & 1505 & 1427 & 1501 & 1501\\\\\n' +
      '***emini Pro** & 1548 & 1490 & 1434 & 1380 & 1454\\\\\n' +
      '**ERNIE-Bot-4.0** & 1410 & 1385 & 1552 & 1515 & 1445 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 엘로 랭킹 시스템에 대한 전반적인 인간 선호도\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline\n' +
      '**Models** & **Creativity** & **Style** & **Relevance** & **Fluency** & **Overall** \\\\ \\hline\n' +
      '**Weaver Ultra** & **1682** & **1661** & **1689** & **1641** & **1657**\\\\\n' +
      '**GPT-4** & 1507 & 1513 & 1421 & 1534 & 1508\\\\\n' +
      '**ERNIE-Bot-4.0** & 1404 & 1409 & 1564 & 1544 & 1477\\\\\n' +
      '***emini Pro** & 1513 & 1469 & 1409 & 1360 & 1430\\\\\n' +
      '**GLM-4** & 1391 & 1445 & 1415 & 1417 & 1425 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: Elo Ranking System Post-Editing을 이용한 픽션 글쓰기에 대한 인간 선호도.\n' +
      '\n' +
      '##6 소개 WawaWriter\n' +
      '\n' +
      '이 절에서는 위버의 기능을 완전히 발휘하기 위해 구축한 차세대 AI 보조 글쓰기 플랫폼인 와와와라이터에 대해 설명한다. WawaWriter는 차세대 AI 쓰기 경험을 위한 몇 가지 새로운 혁신을 구현하는 동시에 AI 지원 세대, 연마 및 요약 등 최근 AI 지원 쓰기 플랫폼(예: Notion AI)의 주요 기능을 통합한다. 다음 섹션에서 이러한 혁신을 설명합니다.\n' +
      '\n' +
      '### Human-AI 협업 글쓰기\n' +
      '\n' +
      'WawaWriter의 한 가지 주요 혁신은 인간-AI 협력 글쓰기를 위한 새로운 인터페이스이며, 이는 전통적인 AI 지원 글쓰기 플랫폼과 비교하여 획기적으로 다른 사용자 경험을 제공한다. 에이전트(Zhou et al., 2023b) 프레임워크 덕분에 구글 문서 또는 노션과 같은 표준 협업 편집기에서 독립적인 인간 협력자/공저자처럼 행동하는 제어 가능한 작문 에이전트를 구축할 수 있다. 작성 에이전트는 문서의 제목이나 짧은 설명과 같은 맞춤 설정을 읽음으로써 현재 문서의 목표를 이해한다. 그런 다음 문서 내의 현재 내용 및 그들의 초점을 드러내는 인간 사용자(또는 다른 글쓰기 에이전트)의 최근 행동에 따른 행동을 취한다. 인간 사용자는 또한 채팅 인터페이스에서 작성 에이전트와 채팅하여 무엇을 해야 하는지 지시할 수 있다. 웹 검색과 같은 외부 API와 볼딩 또는 라인 스페이스 조정과 같은 빌드인 에디터 API를 모두 사용하는 쓰기 에이전트의 능력은 기존의 AI 어시스턴트가 할 수 있는 것보다 훨씬 더 복잡한 작업을 수행할 수 있게 한다. 에이전트 프레임워크에서 인간-에이전트 상호 작용 기능을 통해 WriteBench는 또한 다수의 인간 작가와 언어 에이전트 간의 협업 편집을 지원한다. 사용자는 스토리 또는 기사를 작성할 때 다수의 작문 에이전트를 사용자 정의하고 그 중 하나 또는 몇 개와 협업할 수 있다. 사용자는 각각의 필기 에이전트에 대해 태스크를 지정할 수 있는 반면, 다수의 필기 에이전트는 또한 자율적으로 노동을 분배하기 위해 서로 통신할 수 있다.\n' +
      '\n' +
      '### 외부 지식과 도구의 통합\n' +
      '\n' +
      'WawaWriter의 또 다른 새로운 특징은 사용자가 문서 업로드 또는 웹 페이지 저장을 통해 자신의 개인 지식 베이스를 구축할 수 있다는 것이다. 와와작가는 지식베이스를 자동으로 정리, 정리한 후 이야기, 기사 작성 시 참고자료로 활용한다. 구체적으로, LLM이 문서들을 의미론에 기초하여 청크로 분할하고, 임베딩 모델에 임베딩하고, 벡터DB에 저장하도록 촉구한다. 글을 쓰는 동안, 사용자의 편집기에서 현재 컨텍스트를 쿼리로 사용하여 의미 검색을 사용하여 사용자의 개인 지식 베이스의 항목을 동적으로 검색한다. 소크라테스 모델(Zeng et al., 2023)에 이어, 우리의 지식 베이스는 또한 GPT-4V를 사용하여 각 이미지에 대한 상세한 캡션을 수행한 다음 캡션을 해당 이미지를 나타내는 엔트리로 사용하여 문서 내의 이미지를 지원한다. 사용자는 또한 WawaWriter의 모든 AI-쓰기 기능을 사용하여 개인 지식 베이스의 문서를 편집할 수 있다. 또한, 이전 섹션에서 설명된 작문 에이전트는 기능 호출을 통해 사용자의 개인 지식 베이스에 액세스할 수도 있다.\n' +
      '\n' +
      '### 개인 맞춤형 글쓰기 지원\n' +
      '\n' +
      'WawaWriter는 현재의 AI 지원 필기 시스템과 달리, 자신의 필기 스타일 및 콘텐츠 선호도에 맞는 다양한 사용자를 위한 개인화된 필기 보조를 제공한다. 이를 위해 사용자의 기본적인 글쓰기 습관 및 스타일(단어 선택, 문장 길이 선호도 등)을 기술하는 텍스트 기반 사용자 프로파일을 사용자별로 유지한다. 사용자 프로파일은 주의 깊게 설계된 프롬프트와 함께 사용자에 의해 작성된 최근 텍스트들에 따라 LLM을 사용하여 주기적으로 업데이트된다. 그런 다음 사용자 프로파일은 위버에 대한 프롬프트에서 접두사로 사용된다. 텍스트 기반 사용자 프로파일 외에도 편집기에서 현재 컨텍스트와 가장 유사한 단락을 검색하여 RAG에 대한 참조로 사용한다.\n' +
      '\n' +
      '### 무한한 장문 생성\n' +
      '\n' +
      'WawaWriter는 또한 Weaver가 제안한 리커런트 프롬프트 기술을 원천적으로 지원하기 때문에 무한히 긴 텍스트 생성을 지원한다(Zhou et al., 2023a). 구체적으로, 매우 긴 텍스트를 생성하기 위해, 우리는 위버가 현재 컨텍스트에 기초하여 윤곽을 생성하도록 반복적으로 프롬프트한 다음, 생성된 윤곽에 기초하여 텍스트의 단락을 생성한다. WawaWriter는 RecurrentGPT에서 "단계별" 모드와 "연속" 모드를 통합하며, 여기서 다음 개요는 사용자에 의해 수동으로 선택되거나 LLM에 의해 자동으로 선택된다. Zhou et al. (2023a)에서 논의된 바와 같이, 이러한 반복적인 프롬프트 메커니즘은 생성된 긴 텍스트의 창의성, 일관성 및 관련성을 획기적으로 개선시키며, 이는 특히 WawaWriter와의 스토리/픽션 작문에 도움이 된다.\n' +
      '\n' +
      '## 7 Discussion\n' +
      '\n' +
      '이 기술 보고서에서 우리는 작문 노력에 특화된 LLMs의 가족인 Weaver를 소개한다. 위버는 신중하게 선별된 데이터 세트에 대해 지속적으로 사전 훈련된 다음 새로운 데이터 합성 프레임워크를 사용하여 전문 작가 및 편집자의 선호도에 정렬된다. 또한 LLM의 쓰기 능력을 평가하기 위한 첫 번째 벤치마크인 WriteBench를 출시합니다. WriteBench는 글쓰기와 관련된 여러 도메인 및 작업을 다룬다. 우리는 위버를 10개 이상의 인기 일반주의자 LLM과 비교하고 위버 울트라가 벤치마크에서 현재 최첨단이라는 것을 발견했다. 우리의 사용자 연구는 또한 실제 AI 지원 쓰기 시나리오에서 위버의 우월성을 확인한다. 이 결과는 또한 도메인별 LLM을 훈련하기 위한 데이터 합성 파이프라인의 효율성을 확인한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Ainslie et al. [2023] J. Ainslie, J. Lee-Thorp, M. de Jong, Y. Zemlyanskiy, F. Lebron, and S. Sanghai. Gqa: Training generalized multi-query transformer models from multi-head checkpoints. _arXiv preprint arXiv:2305.13245_, 2023.\n' +
      '* 인류학[2023] 인류학. Claude, 2023. URL[https://www.anthropic.com/index/introductiong-claude](https://www.anthropic.com/index/introductiong-claude)\n' +
      '* Bai et al. [2022] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirhoseini, C. McKinnon, C. Chen, C. Olsson, C. Olah, D. Hernandez, D. Drain, D. Ganguli, D. Li, E. Tran-Johnson, E. Perez, J. Kerr, J. Mueller, J. Ladish, J. Landau, K. Ndousse, K. Lukosuite, L. Lovitt, M. Sellitto, N. Elhage, N. Schiefer, N. Mercado, N. DasSarma, R. Lasenby, R. Larson, S. Ringer, S. Johnston, S. Kravec, S. E. Showk, S. Fort, T. Lanham, T. Telleen-Lawton, T. Conerly, T. Henighan, T. Hume, S. R. Bowman, Z. Hatfield-Dodds, B. Mann, D. Amodei, N. Joseph, S. McCandlish, T. Brown, and J. Kaplan. Constitutional ai: Harmlessness from ai feedback, 2022.\n' +
      '* Brown et al. [2020] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language models are few-shot learners, 2020.\n' +
      '\n' +
      'C. 브라이언트 펠리스, O. E. 앤더슨, T. 브리스코 BEA-2019는 문법 오류 정정에 관한 과제를 공유하였다. H. Yannakoudakis, E. Kochmar, C. Leacock, N. Madnani, I. Pilan, T. 제쉬, 편집자, _Proceedings of the 14th Workshop on Innovative Use of NLP for Building Educational Applications_, pages 52-75, Florence, Italy, August. 2019. Computational Linguistics Association. doi: 10.18653/v1/W19-4406. URL[https://aclanthology.org/W19-4406](https://aclanthology.org/W19-4406).\n' +
      '* Chan et al.(2023) C.-M. 찬우 천영 수진우 수승 장재훈 류 Chateval: 2023년 다중 에이전트 토론을 통해 더 나은 llvm 기반 평가자를 향한다.\n' +
      '* Chung et al. (2022) H. W. Chung, L. 허승 롱프레, B. 조프, Y 테이원 페더스 리진 왕민 데하니, S. 브라마, A. 웹슨, S. S. 구, Z. 다이문 엑스 스즈건 A. Chowdhery, A. Castro-Ros, M. 펠랏 로빈슨, D. 발터, S. 나랑, G. 미쉬라, A. 유, V. 조영 황아대 Petrov, E. H. Chi, J. Dean, J. Devlin, A. Roberts, D. Zhou, Q. V. Le, and J. Wei. 2022년, 확장 명령어 중심 언어 모델\n' +
      '* Cui et al.(2023) J. Cui, Z. 이영 양, B. 첸, L. 위안 Chatahw: Open-source legal large language model with integrated external knowledge base, 2023.\n' +
      '*Dao(2023)T. 다오 플래시 어텐션-2: 더 나은 병렬성과 작업 분할로 더 빠른 어텐션. 2023년\n' +
      '*Dao et al.(2022) T. 다도용 Ermon, A. Rudra, C. Re. 플래시 어텐션: IO 인식으로 빠르고 메모리 효율적인 정확한 어텐션. In _Advances in Neural Information Processing Systems_, 2022.\n' +
      '* Diao et al.(2023) S. 변용 레이용 판태 팽원 주성근 -Y. 간, T. 장 두리틀: 학술적 글쓰기 공식화를 위한 벤치마크와 말뭉치. 2023년\n' +
      '* Gao et al.(2023) Y. 가오영 Xiong 가오경 지아판 비영 Dai, J. Sun, H. Wang. 대용량 언어 모델에 대한 검색-증강 생성: 설문조사. _ arXiv preprint arXiv:2312.10997_, 2023.\n' +
      '* 구글(2023) 구글. 우리의 AI 여정의 중요한 다음 단계인 2023. URL[https://blog.google/technolo](https://blog.google/technolo) gy/ai/bard-google-ai-search-updates/).\n' +
      '* Guu et al.(2018) K. 구태범 하시모토 오렌, P. 량 시제품을 편집하여 문장을 생성하는 단계; _ Transactions of the Association for Computational Linguistics_, 6:437-450, 2018. doi: 10.1162/tacl_a_00030. URL[https://aclanthology.org/Q18-1031](https://aclanthology.org/Q18-1031).\n' +
      '* Hendrycks et al. (2020) D. Hendrycks, C. Burns, S. 바사르트, A. 주 Mazeika, D. Song, J. Steinhardt. 대규모 멀티태스크 언어 이해도 측정 arXiv preprint arXiv:2009.03300_, 2020.\n' +
      '* Hu et al.(2017) Z. 허진 양진욱 량락 살라쿠트디노프와 E. P. 싱 텍스트 생성을 제어합니다. _International conference on machine learning_, pages 1587-1596. PMLR, 2017.\n' +
      '* Ji et al. (2023) J. Ji, T. 주봉진 왕영 두안지 그, 주, 주 Zhang, et al. Ai alignment: A comprehensive survey _ arXiv preprint arXiv:2310.19852_, 2023.\n' +
      '* Jiang et al. (2023a) A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, et al. Mistral 7b. _ arXiv preprint arXiv:2310.06825_, 2023a.\n' +
      '* Jiang et al.(2023b) D. Jiang, Y. 이기장 황병영 첸 타이거스코어: 모든 텍스트 생성 작업에 대한 설명 가능한 메트릭을 구축하기 위해, 2023b.\n' +
      '* Jiang et al.(2023) Y. E. Jiang, T. 류승 마동장 코터렐, M. 사찬 조밀하게 주석이 달린 병렬 말뭉치를 사용한 기계 번역의 담론 중심 평가. _Proceedings of the 2023 Conference of the Computational Linguistics: Human Language Technologies_, pages 1550-1565, Canada, Toronto, July 2023c. 컴퓨터 언어학과의 연관성 doi: 10.18653/v1/2023.main.111. URL[https://aclanthology.org/2023.acl-main.111](https://aclanthology.org/2023.acl-main.111).\n' +
      '\n' +
      'A. 톡살 Schick, A. Korhonen, H. Schutze. Longform: 코퍼스 추출로 긴 텍스트 생성을 위한 명령어 튜닝 최적화, 2023.\n' +
      '* Lewis et al. [2020] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Kuttler, M. Lewis, W.-t. Yih, T. Rocktaschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. _Advances in Neural Information Processing Systems_, 33:9459-9474, 2020.\n' +
      '* Li et al. [2023] X. Li, P. Yu, C. Zhou, T. Schick, L. Zettlemoyer, O. Levy, J. Weston, and M. Lewis. Self-alignment with instruction backtranslation, 2023.\n' +
      '* Lin et al. [2020] B. Y. Lin, W. Zhou, M. Shen, P. Zhou, C. Bhagavatula, Y. Choi, and X. Ren. CommonGen: A constrained text generation challenge for generative commonsense reasoning. In _Findings of the Association for Computational Linguistics: EMNLP 2020_, pages 1823-1840, Online, Nov. 2020. Association for Computational Linguistics. URL [https://www.aclweb.org/anthology/2020.findings-e-mnlp.165](https://www.aclweb.org/anthology/2020.findings-e-mnlp.165).\n' +
      '* Liu et al. [2023] W. Liu, W. Zeng, K. He, Y. Jiang, and J. He. What makes good data for alignment? a comprehensive study of automatic data selection in instruction tuning, 2023.\n' +
      '* Loshchilov and Hutter[2017] I. Loshchilov and F. Hutter. Decoupled weight decay regularization. _ arXiv preprint arXiv:1711.05101_, 2017.\n' +
      '* Ng et al. [2014] H. T. Ng, S. M. Wu, T. Briscoe, C. Hadiwinoto, R. H. Susanto, and C. Bryant. The CoNLL-2014 shared task on grammatical error correction. In H. T. Ng, S. M. Wu, T. Briscoe, C. Hadiwinoto, R. H. Susanto, and C. Bryant, editors, _Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task_, pages 1-14, Baltimore, Maryland, June 2014. Association for Computational Linguistics. doi: 10.3115/v1/W14-1701. URL [https://aclanthology.org/W14-1701](https://aclanthology.org/W14-1701).\n' +
      '* OpenAI[2022] OpenAI. ChatGPT, 2022. URL[https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)을 소개한다.\n' +
      '* OpenAI[2023] OpenAI. GPT4 기술 보고서입니다 arXiv preprint arXiv:2303.08774_, 2023.\n' +
      '* Ouyang et al. [2022a] L. 오양, 제이우, 엑스. 지앙, D. 알메이다, C. 웨인라이트, P. 미쉬킨, C. 장 가왈 Slama, A. Ray, et al. Training language models to follow instructions with human feedback. _ 신경 정보 처리 시스템_, 35:27730-27744, 2022a에서의 발전.\n' +
      '* Ouyang et al. [2022b] L. 오양, 제이우, 엑스. 지앙, D. 알메이다, C. L. 웨인라이트, P. 미쉬킨, C. 장. 가왈 Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. 밀러 Simens, A. Askell, P. Welinder, P. Christiano, J. Leike, and R. 로우 언어 모델을 인간 피드백으로 지침을 따르도록 훈련, 2022b.\n' +
      '* Radford et al. [2018] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Improving language understanding by generative pre-training. 2018.\n' +
      '* Radford et al. [2019] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised multitask learners. _OpenAI blog_, 1(8):9, 2019.\n' +
      '* Rafailov et al. [2023] R. Rafailov, A. Sharma, E. Mitchell, S. Ermon, C. D. Manning, and C. Finn. Direct preference optimization: Your language model is secretly a reward model. 2023.\n' +
      '* Roziere et al. [2023] B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin, A. Kozhevnikov, I. Evtimov, J. Bitton, M. Bhatt, C. C. Ferrer, A. Grattafiori, W. Xiong, A. Defossez, J. Copet, F. Azhar, H. Touvron, L. Martin, N. Usunier, T. Scialom, and G. Synnaeve. Code llama: Open foundation models for code, 2023.\n' +
      '* Raza et al. [2019]V. 산A. 웹슨, C. 라펠, S. 박락 수타위카 Alyafai, A. Chaffin, A. Stiegler, A. Raja, M. Dy, M. S. Bari, C. Xu, U. Thakker, S. S. Sharma, E. Szchchla, T. 김기희 나약 D. Datta J. Chang M. T.-J 장홍왕 마니카, S. 심진용 보든, T 왕태 Neeraj, J. Rozen, A. Sharma, A. Santilli, T. Fevry, J. A. Fries, R 티한 T. L. Scao, S. 바이더만, L. 가오태 울프, 그리고 A.M. 러쉬 멀티태스크 프롬프트 트레이닝은 제로 샷 태스크 일반화를 가능하게 한다. _International Conference on Learning Representations_, 2022. URL[https://openreview.net/forum?id=9Vrb9D0WI4](https://openreview.net/forum?id=9Vrb9D0WI4).\n' +
      '* Schick et al.(2023) T. 칙주두비유 데시, R 레일리아누 로멜리, E 함브로, L. 제틀모이어 Cancedda, T. 사이알롬 도구 형성자: 언어 모델은 스스로 도구를 사용하는 법을 배울 수 있습니다. _30-7th Conference on Neural Information Processing Systems_, 2023. URL[https://openreview.net/forum?id=Yacmpz84TH](https://openreview.net/forum?id=Yacmpz84TH)에서,\n' +
      '* Shazeer(2020)N. 셰이저 Glu 변형은 변압기를 개선한다. _ arXiv preprint arXiv:2002.05202_, 2020.\n' +
      '* Shen et al.(2023) T. 심록 진영 황철우 동종 곽선 우영 류, 그리고 D. 시옹 대언어 모델 정렬: 설문조사 _ arXiv preprint arXiv:2309.15025_, 2023.\n' +
      '* Shoeybi et al.(2019) M. 회비 패트워리 Puri, P. LeGresley, J. Casper, B. Catanzaro 메가트론-1m: 모델 병렬성을 사용하여 수십억 매개 변수 언어 모델을 훈련합니다. _ ArXiv preprint arXiv:1909.08053_, 2019.\n' +
      '* Su et al. (2024) J. Su, M. 아메드 류승 판원 보, Y. 류 로포머: 회전 위치 매립을 갖는 향상된 트랜스포머. _ Neurocomputing_, 568:127063, 2024.\n' +
      '* Sun et al.(2023) X. 선종욱 선영 멍준리, 그리고 C. 팬. 요약, 개요 및 정교화: 추출 요약에서 계층적 감독을 통한 긴 텍스트 생성. N. 칼졸라리, C-R 황, 김, J. 푸스테조프스키, L. 와너규 - S. 최필민 류현현 천락 도나텔리 쿠로하시, P. 파지오, N. 수승 김용 함지 He, T. K. Lee, E. Santus, F. Bond, S. -H. 나 편집자, _Proceedings of the 29th International Conference on Computational Linguistics_, pages 6392-6402, 대한민국 경주, 10월. 2022년, 국제 컴퓨팅 언어 위원회 URL[https://aclanthology.org/2022.coling-1.556](https://aclanthology.org/2022.coling-1.556).\n' +
      '* Sun et al.(2023) Z. 선영 신홍장 주주 천덕옥스 양찬간 연어: 원칙 따르는 보상 모델과의 자기 정렬, 2023.\n' +
      '* 쌍둥이자리팀(2023) 쌍둥이자리팀. 쌍둥이자리: 매우 유능한 멀티모달 모델의 가족, 2023년.\n' +
      '* Touvron et al.(2023a) H. Touvron, T. 라브릴, G. 이자카드, X. 마티넷 - A. 라초, T. 라크루아, B. 로지에르, N. Goyal, E. Hambro, F. Azhar, et al. LLaMA: Open and efficient foundation language models. _ arXiv preprint arXiv:2302.13971_, 2023a.\n' +
      '* Touvron et al.(2023b) H. Touvron, L. 마틴기 스톤, P. 알버트, A. 알마하일리, Y. 바배이 바슐리코프 바트라, P. 바가바, S. 보살, D. 비켈, L. Blecher, C. Canton-Ferrer, M 첸, G. 쿠쿠럴, D. 에시오부, J. 페르난데스, J. 푸, W. Fu, B. Fuller, C. Gao, V. 고스와미 고열 A. 하트쇼른, S. 호세이니 허현인 카다스, V 커케즈 Khabsa, I. Kloumann, A. Korenev, P. S. Koura, M. 라초, T. 라브릴, J. 리, D. 리스코비치, Y. 류영 마오진 마티넷 미하일로프, P. 미쉬라, I. 몰리보그, Y. 니, A. 폴튼, J. 레이젠슈타인, R. 룽타 살라디, A. Schelten, R. 실바, E. M. 스미스, R. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. 얀인자로프 장아환 캄바두르 나랑 A. 로드리게스, R. 스톱닉 에두노프와 T 사이알롬 라마 2: 오픈 파운데이션 및 미세 조정 채팅 모델들_ CoRR_, abs/2307.09288, 2023b. doi: 10.48550/arXiv.2307.09288. URL[https://doi.org/10.48550/arXiv.2307.09288](https://doi.org/10.48550/arXiv.2307.09288)\n' +
      '\n' +
      'L. 툰스톨, E. 비칭, N. N. 램버트 라자니 라술영 벨카다, S 황룡 본 베르라, C. 포에레, N. N. 하빕 사라진 Saneviero, A. M. Rush and T. 늑대 제퍼: lm 정렬의 직접 증류, 2023.\n' +
      '* Vaswani et al. (2017) A. Vaswani, N. N. 쉐이저 파마르, J. 우즈코리트, L. 존스, A. N. 고메즈, L. 카이저, 나 폴로수킨 주목해 주세요 신경 정보 처리 시스템_, 30, 2017의 발전.\n' +
      '* Wang et al. (2024) B. Wang, R. 정룡 천영 류승 도창황 심승 Jin, E. Zhou, C. Shi, et al. Secrets of rlhf in large language models part ii:Reward modeling. _ arXiv preprint arXiv:2401.06080_, 2024.\n' +
      '* Wang et al.(2023) Y. 왕영 고르디 Mishra, A. Liu, N. A. Smith, D. Khashabi, 및 H. Hajishirzi. 자가 지시: 언어 모델을 자가 생성 지시와 정렬합니다. A. 로저스, J. 보이드-그라버, N. 오카자키, 편집자, _Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 13484-13508, Canada, Toronto, July 2023a. 컴퓨터 언어학과의 연관성 doi: 10.18653/v1/2023.acl-long.754. URL[https://aclanthology.org/2023.acl-long.754](https://aclanthology.org/2023.acl-long.754).\n' +
      '* Wang et al.(2023b) Y. 왕주영 유진 정룡 양창창 시제왕 시원 예승 장영 장 Pandalm: llm 명령어 튜닝 최적화를 위한 자동 평가 벤치마크, 2023b.\n' +
      '* Wang et al.(2023c) Y. 왕욱 중림 이필미 정우 황룡 상욱 장, 큐. 류 대언어 모델을 인간과 정렬: 설문조사. _ arXiv preprint arXiv:2307.12966_, 2023c.\n' +
      '* Wang et al. (2022) Z. M. Wang, Z. 팽현규 주영 우현국 간진 Ni, M. 장장 장원 오양기 서원 첸, J. 푸, J. 펭 롤렘: 2023d의 대형 언어 모델의 벤치마킹, 이끌어내기, 역할극 능력 향상.\n' +
      '* Wei et al.(2022) J. Wei, X. 왕동우르만 Bosma, Brian ichter, F. Xia, E. H. Chi, Q. V. Le, and D. Zhou. 사고의 사슬은 큰 언어 모델에서 추론을 이끌어낸다. A. H. 오, A. 아가왈, D. 벨그레이브, K. Cho, editors, _Advances in Neural Information Processing Systems_, 2022. URL[https://openreview.net/forum?id=_VjQlMeSB_J](https://openreview.net/forum?id=_VjQlMeSB_J).\n' +
      '* Wu et al.(2023) S. 우오 어소이 루브이 다브라볼스키 준설수 게르만, P. 캄바두르, D. 로젠버그, G. 맨 Bloomberggpt: 금융을 위한 큰 언어 모델, 2023.\n' +
      '* Yang et al.(2022a) K. 양영 천남 펭과 D 클라인 Re3: 재귀적인 보고와 수정으로 더 긴 이야기를 생성하는 것. 인영 골드버그, 지 코자레바, Y 장, 편집자, _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 4393-4479, Abu Dhabi, United Arab Emirates, Dec. 2022a. 컴퓨터 언어학과의 연관성 doi: 10.18653/v1/2022.emnlp -main.296. URL[https://aclanthology.org/2022.emnlp-main.296](https://aclanthology.org/2022.emnlp-main.296)\n' +
      '* Yang et al.(2023a) K. 양동진 펭과 Y 천 Rlcd: 언어 모델 정렬을 위한 콘트라스트 증류로부터의 강화 학습, 2023a.\n' +
      '* Yang et al.(2023b) K. 양동린 펭과 Y 천 DOC: 상세한 개요 제어로 긴 이야기 일관성을 향상시킵니다. A. 로저스, J. 보이드-그라버, N. 오카자키, 편집자, _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 3378-3465, Canada, Toronto, July 2023b. 컴퓨터 언어학과의 연관성 doi: 10.18653/v1/2023.acl-long.190. URL[https://aclanthology.org/2023.acl-long.190](https://aclanthology.org/2023.acl-long.190).\n' +
      '* Yang et al.(2022b) X. 양아천 PourNejatian, H. C. Shin, K. E. Smith, C. Parisien, C. Compas, C. Martin, A. B. Costa, M. G. Flores, et al. A large language model for electronic health records. _ NPJ Digital Medicine_, 5(1):194, 2022b.\n' +
      '\n' +
      'S. 음창복 조경 리진 선태호 Xu, E. Chen 멀티모달 대형 언어 모델에 대한 조사. _ arXiv preprint arXiv:2306.13549_, 2023.\n' +
      '* Zeng et al.(2023) A. Zeng, M. Attarian, Brian ichter, K. M. Choromanski, A. Wong, S. 웰커, F. 톰바리, A. 푸로히트, M. S. 류, V. Sindhwani, J. Lee, V. 바누크, 피렌체 소크라테스 모델: 제로 샷 멀티모달 추론을 언어로 구성합니다. _The Eleventh International Conference on Learning Representations_, 2023. URL[https://openreview.net/forum?id=G2Q2Mh3avow](https://openreview.net/forum?id=G2Q2Mh3avow).\n' +
      '* Zhang and Sennrich (2019) B. Zhang and R. 센리히 Root mean square layer normalization. _ Neural Information Processing Systems_, 32, 2019에서의 발전\n' +
      '* Zhao et al. (2023) W. X. Zhao, K. 주종리 탕익 왕영 허영 민병장 Dong, et al. A survey of large language models. _ arXiv preprint arXiv:2303.18223_, 2023.\n' +
      '* Zheng et al.(2023a) L. 정원 - L. 장영 성성 장종 우영 장종 린지 Li, D. Li, E. P. Xing, H. Zhang, J. E. Gonzalez, and I. Stoica. Mt-bench와 챗봇 무대로 판단할 수 있습니다. 2023a.\n' +
      '* Zheng et al.(2023b) R. 정승 두성 가오영 화원 신봉왕 류승 진규 유영 Zhou, et al. The Secrets of rhlf in large language models part i: Ppo. _ arXiv preprint arXiv:2307.04964_, 2023b.\n' +
      '* Zhou et al. (2019) W. 저우태 기경 Xu, F. Wei, M. 주 Hierarchical summary-to-article generation, 2019. URL[https://openreview.net/forum?id=Hk18Ia4YPH](https://openreview.net/forum?id=Hk18Ia4YPH).\n' +
      '* Zhou et al.(2023a) W. 주영웅 왕주영 샤오영 허록 코터렐, M. 사찬 Recurrentgpt: (임의로) 긴 텍스트의 대화형 생성, 2023a.\n' +
      '* Zhou et al.(2023b) W. 주영강 이종우 왕승 J. 장, J. 천, R. 우승 왕승 주준천 장남 장현천, P. Cui, M. 사찬 에이전트: 자율 언어 에이전트를 위한 오픈 소스 프레임워크, 2023b.\n' +
      '* Zhou et al.(2023c) W. Zhou, Y. E. Jiang, E. Wilcox, R 코터렐, M. 사찬 자연어 명령어를 사용하여 텍스트 생성을 제어합니다. A. 크라우스, E. 브런스킬, K. 조병하르트 Sabato, and J. Scarlett, editors, _Proceedings of the 40th International Conference on Machine Learning_, volume 202 of _Proceedings of Machine Learning Research_, pages 42602-42613. PMLR, 23-29 Jul 2023c. URL[https://proceedings.mlr.press/v202/zhou23g.html](https://proceedings.mlr.press/v202/zhou23g.html)\n' +
      '\n' +
      '## 부록, 부록\n' +
      '\n' +
      '### Author Contributions\n' +
      '\n' +
      '천안 왕**는 위버의 핵심 공신입니다. Tiannan은 지속적인 사전 훈련, 감독 미세 조정 및 선호도 최적화를 담당합니다. Tiannan은 또한 데이터 합성과 벤치마크/평가 프로세스의 주요 기여자이다.\n' +
      '\n' +
      '지아민 첸**은 위버의 주요 공신입니다. 지민은 WriteBench를 담당하고 있으며 데이터 합성 및 모델 평가 프로세스의 주요 기여자이기도 하다.\n' +
      '\n' +
      '**칭루이 지아**는 소설 작문을 위한 데이터 합성 및 감독 미세 조정 단계의 주요 기여자이다. 칭루이는 논픽션 글쓰기를 위한 데이터 합성 과정에도 기여한다.\n' +
      '\n' +
      '**슈아이 왕**는 위버의 응용 및 배치와 아워 작가에게 신속한 엔지니어링을 담당합니다.\n' +
      '\n' +
      '**루유팡**은 지속적인 사전 훈련 및 감독 미세 조정을 위한 데이터 합성 프로세스의 주요 기여자이다.\n' +
      '\n' +
      '후일린 왕**, **춘자오 시**, **성웨이 딩**은 와와 작가 내부의 프롬프트의 주요 기여자이다.\n' +
      '\n' +
      '**Zhaowei Gao**, **Chunzhao Xie**, **Jihong Dai**, ** Jiialong Wu**, **Long Li**, **Zhiwei Huang**는 논픽션 글쓰기를 위한 데이터 합성 과정에 기여하였다.\n' +
      '\n' +
      '추우 슈**, **이빈 류**, **신일 덩**은 평가 및 벤치마킹 과정에 기여했다.\n' +
      '\n' +
      '**탱유**, **지아양황**, **강안마**, **한샤오**, **지신첸강안마**, *이루왕**, **시란딩**은 와와작가 마케팅 및 운영을 담당하며 제품에 기여하였다.\n' +
      '\n' +
      '지아이 슈**, **일리하무 타이에르**, **젠유 후**, **원가오**, **청펑 정**, **유슈 예**는 와와작가 구현을 담당한다.\n' +
      '\n' +
      '**레이완**, **시유청**, **신우에장**, **시유청**, **줄레송**이 위버의 제품 디자인을 책임지고 있습니다.\n' +
      '\n' +
      '**샹루 탕**, **샤오화 쑤**, **닌규 장**, **화준 첸**은 기술보고서의 논의 과정과 수정에 기여한 학문적 협력자이다.\n' +
      '\n' +
      '**유첸 엘레노어 장**와 **왕춘슈 주**는 프로젝트 리드로서 위버 교육, 라이트벤치 구축, 와와작가 제품화의 모든 부분에 대한 개념화, 분업화, 프로젝트 관리를 담당한다. 그들은 함께 기술 보고서를 작성한다.\n' +
      '\n' +
      '### Acknowledgments\n' +
      '\n' +
      '통찰력 있는 토론, 초안 수정에 대한 도움, 특히 논문 이름 지정에 대한 제안에 대해 캔웬 쉬에게 감사드리고 싶습니다. 우리는 또한 APUS가 전산 자원에 대한 지원을, ABAKA.AI가 데이터 수집에 대한 지원을, 저장 대학이 일반 지원에 대해 감사를 표한다.\n' +
      '\n' +
      '### Case Study\n' +
      '\n' +
      'Weaver Ultra 및 GPT-4에 의해 생성된 콘텐츠에 대한 몇 가지 사례 연구를 제시한다:\n' +
      '\n' +
      '## Appendix A\n' +
      '\n' +
      '## Appendix A\n' +
      '\n' +
      '## Appendix A\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>