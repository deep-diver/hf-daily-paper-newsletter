<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# Quiet-STaR: 언어 모델은 말하기 전에 스스로 생각하도록 가르칠 수 있다\n' +
      '\n' +
      ' 에릭 젤릭먼\n' +
      '\n' +
      'Stanford University\n' +
      '\n' +
      'Georges Harik\n' +
      '\n' +
      '노배드 인공지능(주)\n' +
      '\n' +
      'Yijia Shao\n' +
      '\n' +
      'Stanford University\n' +
      '\n' +
      'Varuna Jayasiri\n' +
      '\n' +
      '노배드 인공지능(주)\n' +
      '\n' +
      'Nick Haber\n' +
      '\n' +
      'Stanford University\n' +
      '\n' +
      '노아대 굿맨\n' +
      '\n' +
      'Stanford University\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '글을 쓰고 말할 때, 사람들은 때때로 생각하기를 멈춘다. 추론 중심 작품은 질문에 답하거나 에이전트적 과제를 완수하는 방법으로 추론을 프레임화하는 경우가 많았지만, 추론은 거의 모든 서면 텍스트에서 암묵적이다. 예를 들어, 이것은 증명의 선들 사이에 명시되지 않은 단계들 또는 대화의 기초가 되는 마음 이론에도 적용된다. Self-Taught Reasoner (STaR, Zelikman et al., 2022)에서는 질의응답에서 소수의 예제로부터 논리를 추론하고 정답으로 이어지는 예제로부터 학습함으로써 유용한 사고를 학습한다. 이것은 매우 제약적인 설정이다 - 이상적으로는 언어 모델이 대신 임의의 텍스트에서 언급되지 않은 논리를 추론하는 것을 학습할 수 있다. **Quiet-STaR**을 제시한다. **Quiet-STaR**는 LMs가 미래의 텍스트를 설명하기 위해 각 토큰에서 논리를 생성하는 것을 학습하는 STaR의 일반화, 그들의 예측을 개선한다. 1) 연속체를 생성하는 계산 비용, 2) LM이 내부 생각을 생성하거나 사용하는 방법을 처음에 알지 못한다는 사실, 및 3) 개별 다음 토큰을 넘어 예측해야 할 필요성. 이를 해결하기 위해 아이디어의 시작과 끝을 나타내는 학습 가능한 토큰을 사용하는 토큰 병렬 샘플링 알고리즘과 확장된 교사 강제 기법을 제안한다. 자극적으로 생성된 근거는 예측하기 어려운 토큰을 모델링하고 어려운 질문에 직접 답하는 LM의 능력을 향상시키는 데 불균형적으로 도움이 된다. 특히, Quiet-STaR로 인터넷 텍스트 코퍼스에서 LM을 계속 사전 훈련한 후 GSM8K(5.9%\\(\\rightarrow\\)10.9%)와 CommonsenseQA(36.3%\\(\\rightarrow\\)47.2%)에서 제로샷 개선을 발견하였고, 자연어 텍스트에서 어려운 토큰의 복잡성 개선을 관찰하였다. 결정적으로, 이러한 개선은 이러한 작업에 대한 미세 조정을 필요로 하지 않는다. 조용한 STaR은 보다 일반적이고 확장 가능한 방식으로 추론하는 법을 배울 수 있는 LM을 향한 단계를 표시한다.\n' +
      '\n' +
      '\'삶은 뒤로만 이해될 수 있지만 앞으로 살아야 한다\'\n' +
      '\n' +
      '스렌 키에르케고르\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '텍스트의 많은 의미는 문장 사이에 숨겨져 있는데, 문장이 문서에 나타나는 이유를 이해하지 못하면 독자는 얕은 이해만 할 뿐이다. 더욱이, 이것은 상식 추론에서 프로그래밍 증명에 이르는 정리에 이르기까지 태스크의 맥락에서 LMs에 대해서도 사실인 것으로 반복적으로 나타났다(Wei et al., 2022; Nye et al., 2021; Zelikman et al., 2022; Kojima et al., 2022; Nye et al., 2022; Koyama et al., 2022). 후기 텍스트를 예측하기 위한 텍스트의 의미에 대한 추론은 다양한 태스크에서 LM 성능을 향상시키는 것으로 일관되게 나타났지만, LMs가 그들의 추론으로부터 학습할 수 있도록 하는 방법(예를 들어, Zelikman et al., 2022)은 개별 태스크 또는 미리 정의된 태스크 세트(예를 들어, Wei et al., 2021)를 해결하는 데 중점을 두었다. 이러한 작업은 특정 추론 작업 또는 경우에 따라 추론 자체를 제공하기 위해 신중하게 선별된 데이터 세트에 의존한다. 대신 모든 텍스트에 추론이 내포되어 있다면, 왜 우리는 언어 모델링의 작업을 활용하여 추론을 가르쳐서는 안 되는가?특히, Self-Taught Reasoner(STaR, Zelikman et al., 2022)는 LMs가 질문에 대한 답을 시도하기 위해 논리를 샘플링하고, 정확한 최종 답으로 이어질 경우 논리에 대한 훈련을 수행한 다음 이를 반복하여 더 어려운 문제를 반복적으로 해결함으로써 질문 응답(QA) 데이터 세트에서 추론 능력을 부트스트랩할 수 있음을 보여주었다. 그러나 선별된 QA 데이터 세트로부터의 훈련은 근거의 규모와 일반화 가능성을 제한한다. QA 데이터 세트, 특히 고품질 데이터 세트는 사려 깊은 큐레이션을 필요로 하며 본질적으로 추론 작업의 하위 집합만 다룰 것이다. 따라서, 우리는 수학적 QA와 같은 특정 작업에 대한 추론으로 LM 학습을 확장하는 대신, 대규모 인터넷 텍스트 코퍼스에서 미래의 텍스트를 추론하는 데 도움이 되는 추론을 생성하기 위해 LM을 훈련한다. 결과적으로, 우리는 LM이 언어로 존재하는 다양한 작업으로부터 학습할 수 있게 한다(Weber et al., 2021). 이는 현재의 언어 모델링 패러다임에 필수적인 직관, 즉 "언어 모델은 감독되지 않은 멀티태스크 학습자"를 기반으로 한다(Radford et al., 2019). 따라서 STaR에서와 같이 LM의 기존 추론 능력을 활용하여 이론적 근거를 생성하고 REINFORCE 기반 보상으로 LM을 훈련한다(Williams, 1992). 우리는 이 기법을 Quiet-STaR이라고 부르는데, 이는 STaR을 "조용히" 적용하는 것으로 이해될 수 있기 때문에 모델이 말하기 전에 생각하도록 훈련한다.\n' +
      '\n' +
      '넓게는 Quiet-STaR은 미래 텍스트(_think_)를 설명하기 위해 모든 토큰 후에 논리를 생성하고, 논리가 있거나 없는 미래-텍스트 예측을 혼합한 후 REINFORCE(_learn_)를 사용하여 더 나은 논리를 생성하는 학습을 통해 진행된다. 우리는 웹 텍스트 데이터세트 OpenWebMath(Paster et al., 2023) 및 Colossal Clean Crawled Corpus(C4, Raffel et al., 2020)를 사용하여 Mistral 7B(Jiang et al., 2023)에 Quiet-STaR을 적용한다. 데이터세트별 미세조정이 없어도 Quiet-STaR은 CommonsenseQA(36.3%\\(\\rightarrow\\)47.2%)와 GSM8K(5.9%\\(\\rightarrow\\)10.9%)에서 제로샷 직접추론 능력이 향상되었으며, 이러한 개선은 LM 내부 생각에 사용되는 토큰의 수에 따라 지속적으로 증가하는 것으로 나타났다. 마지막으로 생성된 이론적 근거의 패턴을 정성적으로 조사한다.\n' +
      '\n' +
      '이 과제를 해결함에 있어서 다음과 같은 공헌을 한다.\n' +
      '\n' +
      '1. STaR을 일반화하여 비정형 텍스트 데이터로부터 추론을 학습한다. 우리가 아는 한, 이것은 선별된 추론 작업이나 추론 작업의 집합이 아니라 일반적으로 텍스트에서 LMs를 **이성적으로 명시적으로 훈련시키는 첫 번째 작업이다.\n' +
      '2. 주어진 문자열의 모든 토큰 위치로부터 논리를 생성하여 훈련 절차를 확장 가능하게 하는 **병렬 샘플링 알고리즘**을 제안하고 구현한다.\n' +
      '3. 우리는 LM이 근거를 생성하고 언제 그 근거를 기반으로 예측을 해야 하는지 알 수 있도록 각 생각의 시작과 끝에서 맞춤형 **메타-토켄**을 소개한다.\n' +
      '4. **믹싱 헤드**를 적용하여 주어진 사고로부터 다음-토큰 예측을 현재의 다음-토큰 예측에 얼마나 포함할지를 소급적으로 결정한다.\n' +
      '5. 언어 모델링을 위해 앞서 있는 다중 토큰을 포함하는 ** 비근시안 손실**이 사고의 효과를 향상시킨다는 것을 보여준다.\n' +
      '6. 다중 작업에서, 우리는 사고가 LM이 동일한 웹 텍스트에서 훈련된 것보다 어려운 토큰을 더 잘 예측할 수 있게 하여 더 긴 생각으로 개선된다는 것을 입증한다.\n' +
      '\n' +
      '도 1: **Quiet-STaR. 우리는 한 가지 생각에 훈련하는 동안 적용된 알고리즘을 시각화한다. 우리는 텍스트의 모든 토큰(생각)을 따라 생각을 병렬로 생성한다. 그 모델은 생각(말)이 있거나 없는 다음 토큰 예측의 혼합물을 생성한다. 우리는 STaR에서와 같이 REINFORCE를 적용하여 모델이 미래 텍스트를 예측하는 데 도움이 되는 생각의 가능성을 높이는 동시에 미래 텍스트를 덜 가능성 있게 만드는 생각을 버린다(학습).\n' +
      '\n' +
      '##2 관련 업무\n' +
      '\n' +
      '### 언어 모델에서의 추론\n' +
      '\n' +
      '어려운 과제를 먼저 이를 통해 추론할 수 있도록 훈련하여 해결하기 위해 언어 모델을 훈련하고 활용하는 작업이 많이 있었다. 예를 들어, Rajani 등(2019)은 선다형 상식 추론 질문에 답하기 전에 인간 추론 트레이스에 출력하도록 미세 조정된 사전 훈련된 언어 모델이 답에 대해 직접 훈련된 언어 모델보다 우수하다는 것을 입증했다. Shwartz et al. (2020)은 언어 모델들이, 일부 스캐폴딩과 함께 제공될 때, 추가적인 감독 없이 이러한 유용한 생각 사슬 솔루션을 생성할 수 있다는 것을 입증했다. 나중에 Nye et al. (2021)은 언어 모델이 더 유능할 때 "스크래치패드"가 더 적은 스캐폴딩을 필요로 한다는 것을 입증했으며, 이후 Wei et al. (2022)에 의해 강화되고 비공식 작업을 강조하며 Kojima et al. (2022)에 의해 더 강화되어 이러한 행동이 제로 샷을 달성할 수 있음을 입증했다. 가장 최근에 Wang과 Zhou(2024)는 상식적 질문에 대한 답변을 위해 언어 모델이 자신감이 없는 한 유효한 답변 토큰을 방출하는 것을 방지하여 생각 사슬 추론을 활용하도록 강요할 수 있음을 추가로 보여주었다. 그러나, 다시 한번, 이러한 접근법들은 질문-답변 데이터세트에서만 작동하고, Wang 및 Zhou(2024)는 모델이 언제 출력 답변 토큰들을 갖는지를 식별하기 위해 휴리스틱에 의존한다. 다소 TRICE(Phan et al., 2023)와 같이, 우리는 품질의 추정치로서 근거에 걸친 대상 텍스트의 로그 우도의 상대적 개선을 사용하지만, 우리는 단순히 평균 보상을 차감하고 더 복잡한 제어 변량을 통합하지 않는다.\n' +
      '\n' +
      '합리적인 학습 언어 모델\n' +
      '\n' +
      '연구자들이 자신의 추론을 추론하거나 개선하기 위해 언어 모델을 훈련시키는데 사용한 한 가지 방향은 채굴된 추론 트레이스 또는 추론 유사 데이터에 대해 언어 모델을 훈련시키는 것이다(Rajani et al., 2019; Wei et al., 2021; Lewkowycz et al., 2022; Chung et al., 2022; Gunasekar et al., 2023). 이 접근법이 효과적인 것으로 입증되었지만 단점이 있다. 그것은 주석자의 능력에 민감하고 언어 모델에 대한 정책이 아닌 수동 주석을 필요로 한다(즉, 추론 분포는 언어 모델이 생성했을 가능성이 있는 텍스트가 아니다). 이 접근법은 또한 비용이 많이 들고, 확장하기가 어려우며, 주석자가 해결할 수 있는 것보다 더 어려운 문제를 해결하기 위한 명확한 경로를 제공하지 않는다.\n' +
      '\n' +
      '추론을 가르치는 또 다른 방향은 언어 모델의 자체 생성 추론에 의존하는데, 이는 자기놀이에 관한 방대한 문헌을 구축하는 것으로 볼 수 있다(Silver et al., 2017; Anthony et al., 2017; Polu and Sutskever, 2020). 여기에는 다음과 같은 방법이 포함된다.\n' +
      '\n' +
      '그림 2: **일반화 결과. Quiet-STaR로 훈련된 모델이 추론이 필요한 문제에 직접 답하는 것으로 일반화되는 정도를 평가한다. 왼쪽 도표(a)는 GSM8K에서 제로 샷 정확도를 나타내는 반면, 오른쪽 도표(b)는 미세 조정 없이 커먼센스QA에서 제로 샷 정확도를 나타낸다. 두 플롯에서 x축은 훈련 단계를 나타내며, 각 라인은 Quiet-STaR 훈련 동안 사용되는 다른 수의 사고 토큰에 해당한다. y축은 각 데이터 세트에서 제로 샷 직접 정확도를 측정합니다. 우리는 또한 이 플롯의 추론 정규화 버전을 그림 7.**Self-Taught Reasoner(Zelikman et al., 2022)에 포함하며, 이는 정답으로 이어지는 자신의 추론에 대해 반복적으로 훈련된 언어 모델이 점점 더 어려운 문제를 해결할 수 있음을 입증했다. 이후 작업은 Huang et al.(2022)과 같은 추가 정보 또는 가정을 활용하는 것을 목표로 했으며, 이는 StaR에서 제안된 알고리즘이 다수결 답변이 정확하다고 가정하더라도 여전히 작동할 수 있음을 보여주었다. 추가 작업은 잘못된 추론 흔적이 필터링된 "프로세스 기반" 감독에 추가적인 유용성을 입증한 Uesato et al.(2022)과 같은 Zelikman et al.(2022)의 결과를 일반화했으며, 최근에 V-StaR(Hosseini et al., 2024)은 생성을 안내하는 검증자를 훈련하는 것이 또한 성능을 향상시킨다는 것을 입증하고, 문제당 여러 추론 흔적이 주어진 정답의 한계 가능성을 최대화하는 TRICE(Hoffman et al., 2024)를 포함한다. 마지막으로, 관련 연구는 또한 수학적 진술을 만드는 제한된 설정에서 학습 중간 추론을 탐구했으며, 여기서 모델의 중간 추론에서 진술은 유효한 수학적 진술로만 제한될 수 있다(Poesia et al., 2023). 우리는 부록 F에서 관련 추론 작업에 대한 추가 논의를 포함한다.\n' +
      '\n' +
      '### Meta-tokens\n' +
      '\n' +
      '최근, 성장하는 작업체는 신경망의 맥락에서 특정 기능을 수행하도록 최적화된 커스텀 토큰의 유용성을 입증했다 - 이러한 이유로, 이들은 또한 "기능 벡터"로 지칭되었다. (Todd et al., 2023). 이것의 원래 인스턴스화들 중 하나는 프롬프트-튜닝(Lester et al., 2021)(및 관련 프리픽스-튜닝(Li and Liang, 2021))이었고, 프롬프트의 토큰들에 대응하는 임베딩들은 태스크를 더 잘 달성하기 위해 최적화될 수 있었다. 다른 사람들은 효율성을 위해 긴 프롬프트(Li et al., 2023; Jung and Kim, 2023)를 압축하기 위해 메타 토큰을 적용했다. 이 작업과 가장 관련이 있는 Mu et al.(2024)은 토큰을 최적화함으로써, 그 이후의 토큰들이 그 이전의 토큰들(즉, 컨텍스트 압축 토큰)에 참석할 수 없을 때, 그것은 미래의 토큰들에 충분한 정보를 제공할 것이다. 우리는 압축에 초점을 맞추지는 않지만, 주의 집중에 영향을 주는 토큰을 학습하는 문제를 공유하고 복잡한 다운스트림 행동을 통제한다. 하나의 관련 작업에서, Goyal 등(2023)은 하나의 "일시정지" 토큰(본질적으로 각각의 토큰을 두 개의 토큰으로 나타냄)을 학습하는 것이 LM 성능을 향상시킨다는 것을 보여준다. 그러나, 우리의 작업에서 생각 토큰과 달리, 이 일시 정지 토큰은 생각을 초기화하지 않는다 - 대신에, 그것은 생각의 전체로서 작용하는 것으로 볼 수 있다. 우리는 언어에서의 추론이 훨씬 더 도움이 된다는 것을 발견한다.\n' +
      '\n' +
      '## 3 문제 진술\n' +
      '\n' +
      '이 작업에서 우리는 시퀀스의 관찰된 토큰의 각 쌍 사이에 보조 \'합리\' 변수를 도입한다. 그런 다음 매개 변수\\(\\theta\\)를 사용하여 중간 생각(또는 근거)을 생성할 수 있는 능력을 가진 언어 모델을 최적화하는 것을 목표로 한다.\n' +
      '\n' +
      '\\[\\theta^{*}=\\arg\\max_{\\theta}E_{x}\\left[logp_{\\theta}\\left(x_{i:n}|x_{0:i}, \\text{rationale}_{\\theta}\\left(x_{0:i}\\right)\\right)\\right]\\]\n' +
      '\n' +
      '원칙적으로, 이것은 문자열에 대한 언어의 분포를 이미 올바르게 모델링하는 최적의 언어 모델에 비해 이점을 제공하지 않는다는 점에 유의한다. 그러나, 실제로, 광범위한 선행 작업은 언어 모델들이 추론 태스크들에 대한 중간 이성들로부터 이익을 얻는다는 것을 보여주었다 (Nye et al., 2021; Zelikman et al., 2022; Wei et al., 2022). 일부 작업은 사고 연쇄 추론의 효과, 즉 그것을 "경험의 지역성"(Prystawski et al., 2024)에 귀속시키는 것을 설명하는 것을 목표로 했다. 보다 광범위하게 추론하면 모델은 어려운 계산을 더 작은 단계로 분해할 수 있다. 효과적으로, 우리는 어떤 분해 및 계획 단계가 미래의 텍스트를 예측하는 데 효과적인지를 학습하도록 모델을 훈련시킨다. 또한 목표는 다음 토큰만이 아니라 나머지 시퀀스를 정확하게 예측하는 것으로 공식화한다는 점에 유의한다. 다시 한 번, 최적의 LM에 대해 이들은 동등할 것이다. 그러나 우리는 비근시안 공식이 이론적 근거를 학습하는 데 더 효과적인 손실로 이어진다는 것을 발견했다.\n' +
      '\n' +
      '## 4 Quiet-STaR\n' +
      '\n' +
      '### Overview\n' +
      '\n' +
      'Quiet-STaR은 세 가지 주요 단계로 작동한다(도 1):\n' +
      '\n' +
      '1. **Parallel rationale 생성(think, Subsection 4.2)**: 입력 시퀀스 \\(x_{0:n}\\)에서 \\(n\\)token \\(x_{i}\\)에 걸쳐 병렬로 \\(r\\) 길이의 \\(t\\): \\(c_{i}=(c_{i1},\\dots,c_{it})\\)을 생성하여 \\(n\\times r\\)의 rationale 후보를 생성한다. 각 이론의 시작과 끝을 표시하기 위해 학습한 \\(<\\)\\(\\mid\\)start\\(\\mid\\)\\(>\\)과 \\(<\\\\)\\(\\mid\\)end\\(\\mid\\)\\(>\\)의 토큰들을 삽입하였다.\n' +
      '2. **Mixing post-rationale and base predictions (talk, Subsection 4.3)**: 각 근거 이후의 숨겨진 상태 출력으로부터, 우리는 "mixing head" - 얕은 MLP를 트레이닝하여, 기초 언어 모델 예측 로짓들에 비해 post-rationale next-token 예측 로짓들이 얼마나 통합되어야 하는지를 결정하는 가중치를 생성한다. 이 접근법은 이론적 도입으로 인해 미세 조정 초기에 분포 이동을 완화한다.\n' +
      '3. ** 합리화 합리화(학습, 서브섹션 4.4)**: 미래 텍스트를 더 가능성 있게 만드는 합리화의 가능성을 높이기 위해 합리화 생성 파라미터(시작/종료 토큰 및 LM 가중치)를 최적화한다. 우리는 REINFORCE를 사용하여 미래-토큰 예측에 미치는 영향에 기초하여 추론에 학습 신호를 제공한다. 분산을 줄이기 위해 사고 후 토큰뿐만 아니라 이후 토큰도 예측할 수 있는 가능성을 손실에 포함하도록 교사 강제 트릭을 적용한다.\n' +
      '\n' +
      '### Parallel Generation\n' +
      '\n' +
      'Quiet-STaR의 핵심 과제는 입력 시퀀스의 각 토큰 위치에서 논리를 효율적으로 생성하는 것이다. 순진하게, 이것은 각 토큰에 대해 별도의 순방향 패스를 필요로 할 것이며, 이는 긴 시퀀스에 대해 계산적으로 난해해진다.\n' +
      '\n' +
      '먼저 언어 모델의 추론 패스가 모든 입력 토큰에 대해 다음 토큰에 대한 확률 분포를 생성한다는 것을 관찰함으로써 고도로 병렬적인 생성을 허용한다. 자연스럽게, 이것은 우리가 입력의 각 토큰으로부터 하나의 다음 토큰을 샘플링할 수 있게 한다. 각각의 토큰으로부터 후계자를 생성했다면, 단순히 원래의 시퀀스를 계속하는 것은 불가능하다. 예를 들어, "\\(<bos>\\) cat sat"의 각 토큰이 "yes orange saw down"을 생성할 수 있는 다음 토큰을 예측하는 것을 상상해 보십시오 - 각 후계자는 그 자체로 시퀀스의 접두사에 대한 합리적인 다음 토큰이지만, 토큰 목록은 이러한 접두사의 "반사실적" 연속체의 집합입니다. 그러나 우리는 이러한 연속체를 활용하여 관찰된 각 토큰에 대한 숨겨진 생각을 생성할 수 있다.\n' +
      '\n' +
      '이를 효율적으로 수행하기 위해, 각 포워드 패스를 캐시하고 대각선 어텐션 마스크를 이전 어텐션 마스크에 연결한다: 각 생성된 토큰은 현재 그것을 생성하는 데 사용된 모든 토큰뿐만 아니라 다른 "반사실적" 경로 상의 토큰에도 참석한다. 더욱이, 이러한 병렬화된 다음 샘플링 토큰 절차는 임의적으로 여러 번(또는 적어도 하나의 메모리가 고갈될 때까지) 반복될 수 있다. 우리는 그림 3에서 이 절차를 시각화하고 부록 B에서 이 알고리즘을 더 빠르게 만드는 추가 방법을 강조한다.\n' +
      '\n' +
      '### "혼합"(잔여) 헤드\n' +
      '\n' +
      '사전 훈련된 모델로 시작할 때, 생각은 초기에 분포에서 벗어나 언어 모델링 성능에 해를 끼친다. 사고로의 전환을 원활하게 하기 위해 우리는 생각이 있는 LM 예측과 없는 LM 예측 사이에 학습된 보간법을 소개한다. 생각 종료 토큰의 숨겨진 상태 및 원본 텍스트 토큰의 숨겨진 상태가 주어지면, 믹싱 헤드는 사후 생각 예측 로짓이 사용될 정도를 결정하는 가중치를 출력한다. 이 헤드에는 얕은 다층 퍼셉트론을 사용하여 각 토큰에 대한 스칼라(scalar)를 출력한다. 우리는 부록 A에 구현 세부사항을 포함한다.\n' +
      '\n' +
      '합리적인 생성의 최적화\n' +
      '\n' +
      '#######4.4.1 생각의 시작 및 생각의 끝 토큰 최적화\n' +
      '\n' +
      '[\\(<\\)\\(|\\)startofthought\\(|>\\) 및 [\\(<\\)\\(|\\)endofthought\\(|>\\) 토큰은 모델의 이론적 생성을 제어하는 학습된 메타 토큰 역할을 한다. 이러한 토큰의 표현, 특히 \\(<\\)\\(|>\\)startofthought\\(|>\\) 토큰의 표현을 최적화하는 것은 중요하지만 이론적 토큰의 이산적 특성으로 인해 어렵다. 우리는 시작 및 종료 토큰 임베딩을 em 대시 "---"에 해당하는 임베딩으로 초기화하고, 이는 종종 텍스트 데이터에 나타나 일시 정지 또는 생각을 나타낸다. 이것은 언어 모델의 기존 지식을 활용합니다. 또한, 이러한 임베딩이 보다 신속하게 최적화될 수 있도록, 업데이트 단계 동안 이러한 임베딩의 기울기에 (하이퍼 파라미터) 가중치를 적용한다. 직관적으로 시작 사고 토큰은 모델을 "사고 모드"에 넣는 것으로 이해될 수 있고, 끝 사고 토큰은 모델이 사고가 끝났을 때 말하는 것으로 이해될 수 있다.\n' +
      '\n' +
      '근시안 점수 4.4.2 비근시안 점수 및 교사 강요\n' +
      '\n' +
      '우리는 생각이 모든 토큰을 예측하는 데 유용하기를 기대하지 않기 때문에, 모델의 보상은 생각을 따르는 텍스트의 정확한 다음 단어에 덜 의존하고 다음 의미 내용에 더 의존하는 것을 선호할 것이다. 여기에는 두 가지 주요 과제가 있다. 첫째, 트랜스포머를 이용한 일반적인 언어 모델링과 달리,\n' +
      '\n' +
      '도 3: **병렬 생성**. 모든 사고 토큰이 자신에게 주의를 기울일 수 있도록 하는 주의 마스크를 구성하고, 동일한 사고 내의 모든 선행 사고 토큰과 선행 텍스트를 구성함으로써 모든 사고의 연속성을 병렬적으로 생성할 수 있다. 각 추론 호출은 모든 텍스트 토큰에 대해 하나의 추가 생각 토큰을 생성하는 데 사용된다.\n' +
      '\n' +
      '주어진 다음 토큰 예측은 병렬 샘플링 전략의 결과인 그 예측으로부터 기울기를 받는다. 우리는 이전에 토큰을 샘플링하여 미래의 토큰에 대한 손실 항을 추가하여 이를 해결할 수 있다. 그러나 이는 LM이 선행 토큰을 부분적으로 무시하도록 훈련하기 때문에 일반적으로 언어 모델링에 대해 훨씬 더 높은 엔트로피와 더 낮은 품질의 생성된 텍스트를 초래할 것이다. 대신 병렬 어텐션 마스크를 사용하여 진정한 다음 토큰의 로그 확률을 계산하고, 모델이 올바른 다음 지상-진실 토큰(트랜스포머를 사용한 일반 언어 모델링에서 암시적으로)을 선택했다고 가정하여 교사 강제성을 적용한다. 각각의 미래 토큰에 대한 손실은 또한 최종 생각 토큰 및 이전의 관찰된 토큰으로부터 계산된 혼합 가중치에 의존한다는 점에 유의한다. 손실에 포함된 미래 토큰의 개수는 하이퍼-파라미터이다. 시작 토큰과 끝 토큰을 삽입하기 위해 동일한 교사 강제 기법을 적용한다. 우리는 그림 4에서 이 절차를 시각화한다.\n' +
      '\n' +
      '#### 4.4.3 Objective\n' +
      '\n' +
      '우리는 REINFORCE를 이용하여 기존의 관측된 토큰과 특정 근거(\\(p^{\\text{talk}}_{j+n_{true}}\\)를 사고 후 혼합 예측 확률의 속기로 사용하는 언어 모델 하에서 \\(n_{true}\\)의 참 다음 토큰의 로그 우도(X_{j+1:j+n_{true}+1}\\)에 기초하여 근거의 우도를 최적화한다. 분산 감소를 위해, 입력 시퀀스에서 각 토큰에 대한 다수의 근거 연속체를 생성한다( 느슨하게 TRICE, Phan et al. (2023)). 따라서 우리는 각 근거에 대한 보상 \\(r_{j}\\)을 그 토큰에 대한 \\(p^{\\text{talk}}_{j+n_{true}}\\)과 근거에 걸친 평균의 차이로 정의한다.\n' +
      '\n' +
      '\\[r_{j}=\\log p^{\\text{talk}}_{j:j+n_{true}}(X_{j+1:j+n_{true}+1})-\\log\\overline{p}^{\\text{talk}}_{j:j+n_{true}}(X_{j+1:j+n_{true}+1})\\]\n' +
      '\n' +
      '그런 다음 이 보상을 REINFORCE 손실 항에서 사용하여 언어 모델 매개변수 \\(\\theta\\)를 업데이트하여 평균보다 더 나은 성능을 보이는 근거의 가능성을 높인다:\n' +
      '\n' +
      '\\[\\nabla_{\\theta}\\mathcal{L}^{\\text{REINFORCE}_{j}=-r_{j}\\cdot\\nabla_{\\theta}\\log p_{\\theta}(T_{j}|[X_{:j};<\\mid\\texttt{startofthought}\\mid])\\\n' +
      '\n' +
      '우리는 부정적인 보상을 REINFORCE 손실 항에서 제외하는 것이 유용하다는 것을 발견했는데, 이는 그것이 약간의 편견을 도입할 수 있다고 생각하여 더 안정적인 훈련으로 이어졌기 때문이다.\n' +
      '\n' +
      '이 손실 항은 모델이 그 토큰에 대해 생성된 모든 논리에 걸친 평균 예측과 비교하여 미래 토큰의 예측을 개선하는 논리를 생성하도록 유도한다. 이 손실로 인한 기울기는 LM 매개변수와 생각 시작 및 생각 종료 토큰 임베딩을 모두 업데이트하는 데 사용되며, 최적화를 가속화하기 위해 생각 시작 및 생각 종료 토큰 임베딩의 기울기에 (하이퍼파라미터) 가중치가 적용된다. 이러한 매개변수를 반복적으로 최적화함으로써 Quiet-STaR은 모델을 훈련하여 훈련 전반에 걸쳐 보다 유용한 근거를 생성한다. 마지막으로, 로그 우도 손실(log-likelihood loss, \\(\\mathcal{L}^{\\text{NLL}}_{j}\\)을 포함하여, LM이 대화 헤드를 최적화하도록 학습하고, 또한 기본 LM 헤드1에 대한 다음-토큰 예측 신호를 수신하도록 한다.\n' +
      '\n' +
      '각주 1: 선형 혼합으로 인해 혼합 가중치를 기본 예측 쪽으로 이동시키는 것과 동일하다.\n' +
      '\n' +
      '그림 4: **Forward Pass and Teacher Forcing**. 우리는 알고리즘의 단일 전진 패스를 시각화한다. 실선은 언어 모델 계산을 나타내는 반면, 점선은 교사 강제력을 통해 토큰이 삽입되고 믹서는 혼합 헤드를 나타낸다. 특히, 우리는 세 개의 토큰을 예측하는 것을 시각화합니다. 사상 세대는 그림 1과 그림 3에 더 자세히 나타나 있다.\n' +
      '\n' +
      '##5 실험 및 결과\n' +
      '\n' +
      '직관적으로 모든 토큰이 동일한 양의 사고를 요구하는 것은 아니다. 예를 들어, "사람이 실행됨-"이라는 문장을 고려한다: 토큰이 "ing"2가 아닌 다른 것일 가능성이 불가피하지만, 문맥이 없는 독립형 문장으로서, 추가적인 사고는 잘 훈련된 모델의 예측을 개선하지 않을 것이다. 실제로, 우리는 대부분의 온라인 텍스트 덩어리에 대해 추가 생각이 거의 또는 전혀 영향을 미치지 않는다고 추측한다. 실제로, 탐색 초기에 Quiet-STaR이 모든 토큰에 동등하게 혜택을 주지 않는다는 것을 관찰했다. 따라서 우리는 우리의 접근법이 _do_가 생각을 필요로 하는 토큰을 예측하는 데 유용한지 여부를 조사하기 위해 실험을 설계한다. 우리는 1) Quiet-STaR이 추론이 필요한 데이터셋에서 정답을 직접 예측하는 언어 모델의 능력을 향상시키는지, 2) 사고 토큰으로 인한 영향의 분포를 평가한다. 우리는 Mistral 7B의 기본 버전(Jiang et al., 2023)을 시작으로 모든 실험을 수행한다.\n' +
      '\n' +
      '각주 2: 예를 들어, 바로 이 텍스트에서, "실행" 다음의 토큰은 "-"이다.\n' +
      '\n' +
      '우리는 더 많은 기술 웹 페이지를 강조하는 크롤인 OpenWebMath(Paster et al., 2023)에 대한 훈련을 통해 대부분의 실험을 수행한다. 우리는 OpenWebMath가 우리의 실험이 지원하는 추론에서 이익을 얻는 토큰의 밀도가 더 높을 것으로 예상했기 때문에 선택했다. 또한 보다 다양한 텍스트가 있는 널리 사용되는 LM 사전 훈련 말뭉치인 C4(Raffel et al., 2020)에 대한 Quiet-STaR을 평가하고 더 작은 이점에도 불구하고 다시 상당한 이점을 보여준다.\n' +
      '\n' +
      '### Downstream Performance\n' +
      '\n' +
      '이 하위 섹션에서는 Quiet-STaR이 CommonsenseQA(Talmor et al., 2018) 및 GSM8K(Cobbe et al., 2021)에서 언어 모델의 제로 샷 추론 능력을 향상시키는 정도를 평가한다. CommonsenseQA에서는 Quiet-STaR이 기본 언어 모델에 비해 10.9%의 성능 향상을 보였다. 그림 2와 같이 이러한 개선은 모델의 이론적 근거에 사용된 토큰의 수에 따라 일관되게 증가하며, 이는 사고 토큰을 통한 보다 철저한 추론이 더 나은 직접적인 질문 응답 성능으로 번역되고 있음을 나타낸다. 마찬가지로 GSM8K에서 Quiet-STaR은 기본 모델에 비해 5.0%의 부스트를 가져오며, Quiet-STaR 훈련 동안 생성된 근거의 길이로 성능이 확장된다. 참고로 그림 2에서는 사고 토큰 없이 동일한 데이터셋에서 동일한 모델을 훈련하는 것에 해당하는 기준선을 포함한다. 우리는 여러 곡선에서 성능이 결국 악화되는 것으로 보인다는 것을 관찰한다.\n' +
      '\n' +
      '그림 5: **로그 확률**의 변화 분포. 우리는 평가 데이터 세트에 걸쳐 생성된 생각으로 인한 로그 확률의 변화 분포를 시각화한다. 우리는 로그 밀도를 기반으로 채색된 생각 없이 LM에 대한 로그 확률의 변화 밀도를 시각화한다. 대부분의 토큰은 영향을 받지 않고 분포가 왜곡되는 반면 하드 토큰의 작은 부분은 생각에서 상당한 개선을 본다. 이것은 일반적인 웹 텍스트의 대부분의 토큰이 예측하기 위해 상당한 추론을 필요로 하지 않지만 생각이 도전적인 토큰에 불균형적으로 유익하다는 우리의 직관과 일치한다.\n' +
      '\n' +
      '- 우리는 이것이 우리가 이러한 다운스트림 작업에 대해 훈련하고 있지 않기 때문에 생각 토큰의 역할이 시간이 지남에 따라 변할 수 있기 때문이라고 예상한다. 우리는 또한 부록 D에서 논의하는 우리의 비근시안적 목표의 이점을 찾는다.\n' +
      '\n' +
      'GSM8K(5.9%\\(\\rightarrow\\) 8.1%)와 CommonsenseQA(36.3%\\(\\rightarrow\\) 42.6%)에서 C4에 Quiet-STaR(Raffel et al., 2020)을 이용한 훈련은 성능을 향상시키지만, 적은 마진으로 개선됨을 알 수 있었다. 특히 C4 평가를 위해 16개의 사고 토큰과 4개의 실제 토큰을 앞에 두고 그렇지 않으면 동일한 설정으로 미스트랄 7B를 훈련한다.\n' +
      '\n' +
      '우리는 이러한 개선들을 일시정지 토큰들에 의해 제공되는 것들과 비교할 수 있는데, 이는 각각의 토큰이 두 개의 토큰으로 표현되고 두 번째 "일시정지" 토큰이 사고의 전체로서 작용하는 Quiet-STaR의 제약된 버전으로 볼 수 있다. 특히, 사전 훈련된 모델을 미세 조정하기 때문에 우리의 설정은 일시 중지 토큰 미세 조정과 가장 유사합니다. 그들의 결과는 일시정지 토큰 미세조정이 또한 CommonsenseQA에서 기본 모델에 비해 약간의 이득을 제공함을 나타내며, 26.9%에서 28.8%로 개선됨을 관찰했으며, GSM8K에서 Goyal 등(2023)은 일시정지 토큰 미세조정이 성능에 해를 끼친다는 것을 발견했다. 또한 두 작업(및 평가된 작업의 대부분) 모두에서 추가 사고 토큰이 성능에 해를 끼친다는 것을 관찰했다. 더욱이, 그들은 "일시정지-피네튜닝 a standard-pretrained model"에 대해 논의한다(Goyal et al., 2023). 이는 모델이 다중토큰 논리를 생성하는 것을 허용하는 것이 단일토큰 "일시정지"에 비해 더 효과적인 추론으로 이어진다는 것을 시사한다. 다만, Goyal et al.(2023)과 달리 다운스트림 태스크에 대해서는 fine-tune_를 하지 않는다.\n' +
      '\n' +
      '전반적으로, 이러한 다운스트림 결과는 일반 텍스트 데이터의 라인 사이의 서브텍스트를 예측하기 위해 언어 모델을 훈련하는 것이 명시적으로 훈련되지 않은 데이터 세트에서도 추론 능력을 실질적으로 향상시킬 수 있음을 검증한다. 더 긴 근거는 일관되게 더 나은 결과를 가져오고 Quiet-STaR이 제한된 일시 중지 토큰 접근법을 능가한다는 사실은 Quiet-STaR이 입력에 대해 더 철저하게 추론하기 위해 자체 생성된 생각을 활용하도록 모델을 성공적으로 가르치고 있다는 개념을 뒷받침한다.\n' +
      '\n' +
      '### Improvement Distribution\n' +
      '\n' +
      '그림 5에서 시각화된 바와 같이, 우리는 평균적으로 LM이 임의의 토큰을 예측하는 능력이 거의 향상되지 않는다는 것을 발견한다. 그러나 상대적 개선의 분포를 시각화할 때 더 어려운 토큰에 대한 불균형적인 개선이 있다. 이는 일부 텍스트 토큰이 실질적으로 더 어렵고 신중한 사고로부터 더 많은 이익을 얻는다는 생각을 반영한다.\n' +
      '\n' +
      '그림 6에서 우리는 개선이 일어나는 토큰의 종류에 대한 통찰력을 제공하는 것을 목표로 한다. 즉, 사고력이 예시에서 많은 토큰에 도움이 되는 것처럼 보이지만, 검사는 적용 가능한 정리의 이름이나 증명의 다음 단계의 시작과 같이 관련 정보를 회상하는 것이 유용한 경우 토큰을 예측하는 데 불균형적으로 도움이 된다고 제안한다. 특히, 이는 Prystawski 등에 의해 제안된 프레이밍과 잘 정렬될 것이다(2024).\n' +
      '\n' +
      '그림 6: ** 기여도 시각화**. 우리는 텍스트 전체에서 생각을 도입하는 것이 토큰에 도움이 된 정도를 시각화하는 예제 텍스트를 제공한다. 녹색은 토큰 이전의 생각이 토큰을 예측하기 더 쉽게 만든다는 것을 나타내고 노란색은 예측을 더 어렵게 만든다는 것을 나타낸다. 영향력이 있는 생각이 많을수록 불투명도가 높아집니다.\n' +
      '\n' +
      '논의와 분석\n' +
      '\n' +
      '### Handling Instability\n' +
      '\n' +
      '이 과제의 여러 측면은 불안정성을 도입할 가능성이 있다. 첫째, 그리고 아마도 가장 중요한 것은 생성된 생각(또는 생각 토큰)의 유용성은 생각에서 언어 예측에 대한 기여로의 매핑의 함수이지만, 생각에서 이 기여로의 매핑은 생각 자체에 기초하여 학습된다. 이것은 다음 토큰을 완벽하게 예측할 수 있는 생각을 생성하더라도 그 생성에 대한 혼합 헤드의 무게가 0이면 손실에서 신호를 받을 수 없다는 것을 의미한다. 우리가 탐구한 한 가지 해결책은 직관 추정기 장 등(2016)과 함께 Gumbel-Softmax 트릭을 사용하는 것이지만 많은 연속 소프트맥스 연산으로 소실 구배를 관찰했다. 이것은 강화 학습의 근본적인 도전인 탐구-탐험 절충안을 소개한다. DQN(Mnih et al., 2013), PPO(Schulman et al., 2017) 및 A3C(Mnih et al., 2016)와 같은 접근법은 종종 각 주로부터 예상되는 미래 보상을 추정하는 상태 값 함수를 학습함으로써 이러한 절충을 해결한다. 그러나 이 환경과 관련된 보상 기능은 불안정하다(앞서 언급한 바와 같이 혼합 헤드도 변경됨) 결과적으로 이러한 기술에 대한 예비 탐색은 유망하지 않았다. 우리는 합리성을 최적화하는 것이 강화-학습 과제(Zelikman et al., 2022; Zhang and Parkes, 2023; Phan et al., 2023)라는 것을 처음으로 주목하는 것과는 거리가 멀지만, 기본 모델 성능에 해를 끼치지 않기 위한 합리성의 필요성은 추가적인 복잡성을 도입한다. 본질적으로 LM 출력에서 다음 토큰 예측으로의 매핑이 복잡할수록 불안정성을 관찰했다. 반면에, 보간 없이, 즉 혼합 헤드를 제거하고 생각 후에 언어 모델 예측만을 사용하여 훈련했을 때, 모델은 생각들을 단순히 무시하는 것을 빠르게 학습했다(그리고 어떤 다운스트림 작업들에 대한 일반화를 보지 못했다).\n' +
      '\n' +
      '우리는 사고와 대화를 위해 별도의 머리를 사용하는 것을 탐구했다(여기서는 혼합 중량이 아니라 숨겨진 상태나 로짓들을 직접 출력하는 것을 언급하기 위해 대화를 사용한다). 특히, 언어 모델이 그렇지 않으면 생성했을 것과 유사한 생각 및 다음 토큰 예측을 생성하기 위해 기본 언어 모델 출력에 0을 기여하도록 초기화된 숨겨진 상태와 MLP에서 선형 레이어를 모두 조사했다. 그러나 우리는 모든 경우에 앞서 언급한 불안정성이 학습을 방지한다는 것을 관찰했다. 결과적으로, 우리는 언어 모델의 출력을 변환할 수 있는 모든 구성요소를 제거하거나 최소화하는 것을 목표로 했다. 우리는 또한 언어 모델을 사용하여 (우리의 혼합 헤드에 의해 수행된 것처럼) 여러 상태를 결합하는 가중치를 출력하는 우리의 선택은 본질적으로 모델이 그 사고에 주의를 기울일 수 있게 하는 주의 메커니즘이라는 점에 주목한다. 이것은 백팩 언어 모델(Hewitt et al., 2023)에서 취해진 접근법과 유사하며, 이는 또한 언어 모델이 임의의 임베딩을 출력하도록 하는 것이 아니라, 미래의 텍스트를 모델링하기 위해 합산된 입력 임베딩에 적용하기 위해 가중치를 예측하는 것을 학습한다. 이러한 제약에도 불구하고, 백팩 언어 모델들은 전통적인 언어 모델들과 유사한 성능을 갖는 것으로 보인다(Hewitt et al., 2023).\n' +
      '\n' +
      '### Examples\n' +
      '\n' +
      'Quiet-STaR에는 생각이 인간이 해석할 수 있도록 명시적인 압력이 없지만 모델 언어로 훈련된 동일한 변압기에서 생성되므로 적어도 부분적으로 이해할 수 있다. 참고로 우리는 OpenWebMath에서 미래 토큰을 예측하는 데 모델에 도움이 된 몇 가지 생각의 예를 포함한다. 첫째, 한 경우에 마그네슘 질화물을 생성하기 위해 마그네슘으로 시작해야 한다는 것을 상기하면 절차의 첫 번째 단계가 마그네슘 가열을 포함한다는 것을 더 잘 예측할 수 있다.\n' +
      '\n' +
      '\'번 # 마그네슘은 질소와 반응하여 마그네슘 질화물을 형성한다. 이 반응에 대한 화학식은 Mg+N_2>MgN_2이다. 이 반응의 생성물, 또는 생성물은 무엇인가?n\\nJan 12, 2016\\nUn이 이 반응의 생성물은 SM(g)_{3}{N_{2}}$.n\\n### 설명:n\\n### 많은 활성 금속을 수행하는 바와 같이, 질화마그네슘은 <|startofthought|>1 --일 수 있고, 따라서 질화마그네슘을 형성하는 반응의 방정식은 금속이 가열됨으로써 형성되는\\n\\nMg + N_2\\n <|endofthought|>(Fier\'경우에 따라 가장 유용한 생각은 타겟 텍스트에 보다 밀접하게 대응하는 거의 연속인 것으로 보인다.\n' +
      '\n' +
      '어떤 정수 $k$에 대해 sn = 2k+1$이면 정수 sns는 홀수이다.\\ $A = B$임을 증명하려면 $A\\subseteq B$와 $B\\subseteq A$를 보여야 한다. 이 중 첫 번째는 어떤 의미에서 <|startthought|> - 학생들에게 더 어려운 <|endthought|>가 되는 경향이 있다.\n' +
      '\n' +
      '마지막으로, 우리는 CommonsenseQA에 답하는 예시를 포함한다. 특히 이 생각은 질문을 읽는 동안 발생하기 때문에 최종 답을 예측하는 데 사용되지 않았다.\n' +
      '\n' +
      '\'Q: 같은 사람과 같은 것에 대해 계속해서 이야기하는 것은 <|startofthought|>\\n\\n(a) a one-to-one correlation\\n\\n(b) a one-to<|endofthought|> 어떤 사람이 무엇을 할 수 있는가?\n' +
      '\n' +
      '정숙-STaR과 사고의 사슬\n' +
      '\n' +
      '우리는 사고 연쇄 촉진과 우리의 접근법 사이에 자연스러운 평행이 있지만 본질적으로 직교한다는 점에 주목한다. 생각 사슬에서 사용자는 모델이 \'크게\' 생각하도록 적극적으로 프롬프트하고, 그렇지 않으면 일반적인 생산 분배를 사용한다; 조용한-STaR은 대신 유용하도록 훈련된 분배와 함께 모든 토큰에서 조용히 생각한다. 두 가지 방법은 상호 보완적일 가능성이 높다. 예를 들어, 언어 모델이 생각 사슬을 사용하도록 촉구할 수 있는 맥락에서, 어떤 것도 우리가 근거의 각 토큰을 출력하기 전에 모델이 생각하도록 하는 것을 방해하지 않는다. 이에 대한 예비 실험을 수행하여 내부 이론적 근거가 모델이 부록 E에 설명된 보다 구조화되고 일관된 사고 사슬을 생성할 수 있음을 시사한다.\n' +
      '\n' +
      '## 7 Limitations\n' +
      '\n' +
      '이 연구는 이성에 대한 학습을 위한 새로운 프레임워크를 제안하고, 이를 통해 다양한 메타 학습 과제에 대한 솔루션을 탐구한다. 그러나 이러한 문제를 해결하기 위해서는 일정한 단순화가 필요했다. 예를 들어, 모델이 처음부터 훈련될 때 이러한 기술이 작동하는지 여부를 이해하는 것이 가치가 있을 것이다. 우리는 또한 강력한 모델이지만 70억 매개변수 모델에 Quiet-STaR만 적용했다. 더 나은 모델에 적용된 동일한 기술은 추론으로부터의 이득에 대해 종종 관찰된 바와 같이 불균형적으로 더 나은 결과를 산출할 가능성이 있다(Wei et al., 2022).\n' +
      '\n' +
      'Quiet-STaR은 상당한 오버헤드를 초래하여, 모든 추가 토큰을 생성하기 전에 많은 토큰을 생성한다. (수정된 성능 결과를 계산하기 위해 부록 C 참조) 그러나, 이것은 또한 장점으로 볼 수 있다: 전형적으로, 언어 모델은 현재 컨텍스트에 기초하여 다음 토큰을 생성할 수 있고, 샘플링 품질을 향상시키는 기법들이 있지만, 다음-토큰 예측을 향상시키기 위해 추가 컴퓨팅을 활용하는 일반적인 방법은 없다. 현재 구현에서 우리는 언제 근거를 생성하거나 종료할지를 동적으로 예측하는 것을 지원하지 않는다. 그러나 이것은 자연스러운 확장일 것입니다. 예를 들어, 혼합 헤드가 기본 언어 모델의 예측이었다면, 사고 후가 아니라 어떤 사고 전에, 통합되지 않을 생각을 생성하는 것을 방지하기 위해 임계값을 적용할 수 있다. 우리는 이미 생각을 생성했을 때 생각의 유용성을 예측하는 것이 더 간단하기 때문에 이것이 더 어려운 과제라고 기대한다.\n' +
      '\n' +
      '## 8 Conclusion\n' +
      '\n' +
      'Quiet-STaR은 일반적이고 확장 가능한 방식으로 추론하는 법을 배울 수 있는 언어 모델을 향한 단계를 나타낸다. Quiet-STaR은 특정 데이터 세트를 좁게 전문화하기보다는 다양한 웹 텍스트에 내포된 풍부한 추론 태스크 스펙트럼에 대해 훈련함으로써 더 강력하고 적응 가능한 언어 모델로 가는 방법을 지적한다. 본 연구의 결과는 Quiet-STaR이 질적으로 의미 있는 근거를 생성하면서 다운스트림 추론 성능을 향상시키면서 이 접근법의 가능성을 보여준다. 우리는 이것이 또한 많은 잠재적인 미래 방향을 열어준다고 믿는다 - 예를 들어, 미래 토큰에 대한 예측을 더 개선하기 위해 생각을 앙상블하는 것을 목표로 할 수 있다. 더욱이, 언어 모델이 예를 들어 예측 전에 혼합 헤드를 둠으로써 언제 생각이 유용할지를 예측할 수 있다면, 예측된 혼합 가중치는 생성 동안 동적으로 컴퓨팅을 할당하는 데 사용될 수 있다. 향후 작업은 이러한 통찰력을 기반으로 언어 모델과 인간과 유사한 추론 능력 사이의 격차를 더욱 좁힐 수 있다.\n' +
      '\n' +
      '## Ethics Statement\n' +
      '\n' +
      '이 작업은 STaR에도 적용되는 몇 가지 중요한 윤리적 질문을 제기한다. 예를 들어, 모델이 언어로 표현한 추론이 모델의 내부 처리(즉, 충실성)를 정확하게 나타낸다는 것은 알 수 없다. 또한 충실성과 상관없이 모델이 유용하다고 생각한다면 유해하거나 편향된 추론 패턴에 대한 안전장치가 없다. 이와 관련하여 CommonsenseQA는 편향된 질문과 저품질 답변이 많은 것으로 알려져 있지만(Geva et al., 2019), 선행 작업(Zelikman et al., 2022; Goyal et al., 2023)에 따라 사용한다. 따라서 언어 모델링을 개선하는 것 외에도 근거 자체가 어떤 용량을 사용해야 하는지 불분명하다.\n' +
      '\n' +
      '## Acknowledgements\n' +
      '\n' +
      '특히 신디 우, 마이클 리, 치안 황은 도움이 되고 상세한 논평에 감사하고, 쉬에첸 리, 얀 필립 프렁켄, 유화이 우, 위니 쉬, 오마르 샤이크, 윌리엄 음은 유용한 토론에 감사한다. 또한, 이 작업이 NSF Grant #2302701에 의해 지원되었음을 인정하고자 한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Anthony et al. (2017) Thomas Anthony, Zheng Tian, and David Barber. 딥러닝과 트리 탐색으로 빠르고 느리게 사고하기 신경 정보 처리 시스템_, 30, 2017의 발전.\n' +
      '* Chen et al. (2023) Baian Chen, Chang Shu, Ehsan Shareghi, Nigel Collier, Karthik Narasimhan, and Shunyu Yao. Fireact: 언어 에이전트를 미세 조정합니다. _ arXiv preprint arXiv:2310.05915_, 2023.\n' +
      '* Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. _ ArXiv:2210.11416_, 2022.\n' +
      '* Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 수학 단어 문제 해결을 위한 검증자 훈련 arXiv_, 2021. _eprint_: 2110.14168.\n' +
      '* Gandhi et al. (2023) Kanishk Gandhi, Dorsa Sadigh, and Noah D Goodman. 언어 모델을 이용한 전략적인 추론 arXiv preprint arXiv:2305.19165_, 2023.\n' +
      '* Geva et al. (2019) Mor Geva, Yoav Goldberg, and Jonathan Berant. 우리가 작업을 모델링하는 건가요, 아니면 주석자를 모델링하는 건가요? 자연어 이해 데이터 세트에서 주석자 편향에 대한 조사. _ ArXiv preprint arXiv:1908.07898_, 2019.\n' +
      '* Goyal et al. (2023) Sachin Goyal, Ziwei Ji, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar, and Vaishnavh Nagarajan. 말하기 전에 생각하십시오: 일시 중지 토큰으로 언어 모델을 교육합니다. _ arXiv preprint arXiv:2310.02226_, 2023.\n' +
      '* Gulcehre et al. (2023) Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, et al. Reinforced self-training(rest) for language modeling. _ arXiv preprint arXiv:2308.08998_, 2023.\n' +
      '* Gunasekar et al. (2023) Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio Cesar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi et al. arXiv preprint arXiv:2306.11644_, 2023.\n' +
      '* Gunasekar et al. (2023) Patrick Haluptzok, Matthew Bowers, and Adam Tauman Kalai. 언어 모델은 스스로 프로그래밍을 더 잘 가르칠 수 있습니다. _The Eleventh International Conference on Learning Representations_, 2023. URL[https://openreview.net/forum?id=SaRjZka1XZ3](https://openreview.net/forum?id=SaRjZka1XZ3)에서,\n' +
      '* Hewitt et al. (2023) John Hewitt, John Thickstun, Christopher D Manning, and Percy Liang. 백팩 언어 모델 arXiv preprint arXiv:2305.16765_, 2023.\n' +
      '* Ho et al. (2022) Namyu Ho, Laura Schmid, and Se-Young Yun. 큰 언어 모델은 추론 교사이다. _ ArXiv:2212.10071_, 2022.\n' +
      '* Hoffman et al. (2024) Matthew Douglas Hoffman, Du Phan, David Dohan, Sholto Douglas, Tuan Anh Le, Aaron Parisi, Pavel Sountsov, Charles Sutton, Sharad Vikram, and Rif A Saurous. 잠재변수추론을 통한 사고연쇄 훈련 신경 정보 처리 시스템_, 36, 2024의 발전.\n' +
      '* Hosseini et al. (2024) Arian Hosseini, Xingdi Yuan, Nikolay Malkin, Aaron Courville, Alessandro Sordoni, and Rishabh Agarwal. V-star: 스스로 배운 추론자를 위한 훈련 검증자. _ arXiv preprint arXiv:2402.06457_, 2024.\n' +
      '* Hsieh et al. (2023) Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 차근차근 증류합니다! 더 적은 트레이닝 데이터 및 더 작은 모델 사이즈로 더 큰 언어 모델들을 수행하는 것을 능가한다. _ arXiv preprint arXiv:2305.02301_, 2023.\n' +
      '* Huang et al. (2022) Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, 및 Jiawei Han. 대형 언어 모델은 스스로 개선할 수 있습니다. _ ArXiv:2210.11610_, 2022.\n' +
      '* Jang et al.(2016) Eric Jang, Shixiang Gu, and Ben Poole. Gumbel-softmax를 사용한 범주형 재매개변수화 _ ArXiv:1611.01144_, 2016.\n' +
      '* Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. _ arXiv preprint arXiv:2310.06825_, 2023.\n' +
      '* 정과 김(2023) 호윤정과 김경중. 강화 학습으로 신속한 압축을 분리합니다. _ arXiv preprint arXiv:2308.08758_, 2023.\n' +
      '* Khattab et al. (2022) Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, and Matei Zaharia. 실증-검색-예측: 지식 집약적 nlp를 위한 검색 및 언어 모델 구성 ARXiv 프리프린트 arXiv:2212.14024_, 2022.\n' +
      '* Khattab et al. (2023) Omar Khattab, Arnav Singhvi, Paridih Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Srii Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T Joshi, Hanna Moazam et al. Dspy: Compiling declarative language model calls into self improved pipelines. _ arXiv preprint arXiv:2310.03714_, 2023.\n' +
      '* Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Michel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 대언어 모델은 Zero-Shot Reasoners, 2022. URL[https://arxiv.org/abs/2205.11916](https://arxiv.org/abs/2205.11916)이다.\n' +
      '* Lampinen et al. (2022) Andrew K Lampinen, Ishita Dasgupta, Stephanie CY Chan, Kory Matthewson, Michael Henry Tessler, Antonia Creswell, James L McClelland, Jane X Wang, and Felix Hill. 언어 모델은 문맥에서 설명으로부터 배울 수 있나요? _ arXiv preprint arXiv:2204.02329_, 2022.\n' +
      '* Lanchantin et al. (2024) Jack Lanchantin, Shubham Toshniwal, Jason Weston, Sainbayar Sukhbaatar, et al. Learning to reasoning and memor with self-notes. _ 신경 정보 처리 시스템_, 36, 2024의 발전.\n' +
      '* Lester et al. (2021) Brian Lester, Rami Al-Rfou, and Noah Constant. 매개변수 효율적인 프롬프트 조정을 위한 축척의 검정력 arXiv preprint arXiv:2104.08691_, 2021.\n' +
      '* Lester et al. (2021)Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. 신경 정보 처리 시스템_, 35:3843-3857, 2022에서의 발전.\n' +
      '* Li et al. (2024) Michael Y Li, Emily B Fox, and Noah D Goodman. 언어 모델을 사용한 통계 모델 검색 자동화. _ arXiv preprint arXiv:2402.17879_, 2024.\n' +
      '* Li et al. (2022) Shiyang Li, Jianshu Chen, Yelong Shen, Zhiyu Chen, Xinlu Zhang, Zekun Li, Hong Wang, Jing Qian, Baolin Peng, Yi Mao, et al. arXiv preprint arXiv:2210.06726_, 2022.\n' +
      '* Li and Liang(2021) Xiang Lisa Li and Percy Liang. Prefix-tuning: 생성을 위한 연속 프롬프트 최적화. _ arXiv preprint arXiv:2101.00190_, 2021.\n' +
      '* Li et al. (2023) Yucheng Li, Bo Dong, Chenghua Lin, and Frank Guerin. 큰 언어 모델들의 추론 효율을 향상시키기 위해 컨텍스트를 압축하는 단계; _ arXiv preprint arXiv:2310.06201_, 2023.\n' +
      '* Liu et al. (2023) Jiacheng Liu, Ramakanth Pasunuru, Hannaneh Hajishirzi, Yejin Choi, and Asli Celikyilmaz. 크리스탈: 자기 피드백이 강화된 성찰적 추론기. _ arXiv preprint arXiv:2310.04921_, 2023.\n' +
      '* Luo et al. (2023) Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. Wizardmath: 강화된 evol-instruct를 통해 큰 언어 모델에 대한 수학적 추론력을 강화한다. _ arXiv preprint arXiv:2308.09583_, 2023.\n' +
      '* Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-refine. _ 피드백_, 2023.\n' +
      '* Mnih et al. (2013) Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 심층 강화 학습으로 아타리 연주 arXiv preprint arXiv:1312.5602_, 2013.\n' +
      '* Mnih et al.(2016) Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. 심층 강화 학습을 위한 비동기식 방법. In _International conference on machine learning_, pp. 1928-1937. PMLR, 2016.\n' +
      '* Mu et al. (2024) Jesse Mu, Xiang Li, and Noah Goodman. 요지 토큰으로 프롬프트를 압축하는 방법을 배우는 중입니다. _ 신경 정보 처리 시스템_, 36, 2024의 발전.\n' +
      '* Nye et al. (2021) Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. show your work: Scratchpads for intermediate computation with language models. _ arXiv preprint arXiv:2112.00114_, 2021.\n' +
      '* Pan et al. (2024) Alexander Pan, Erik Jones, Meena Jagadeesan, and Jacob Steinhardt. 언어 모델을 사용한 피드백 루프는 문맥 내 보상 해킹을 유도한다. _ arXiv preprint arXiv:2402.06627_, 2024.\n' +
      '* Paster et al. (2023) Keiran Paster, Marco Dos Santos, Zhangir Azerbayev, and Jimmy Ba. Openwebmath: 양질의 수학 웹 텍스트의 오픈 데이터셋. _ arXiv preprint arXiv:2310.06786_, 2023.\n' +
      '* Phan et al. (2023) Du Phan, Matthew Douglas Hoffman, Sholto Douglas, Tuan Anh Le, Aaron T Parisi, Pavel Sountsov, Charles Sutton, Sharad Vikram, Rif A Saurous, et al. Training chain-of-thought via latent-variable inference. 30-7차 신경 정보 처리 시스템 회의에서_, 2023.\n' +
      '* Poesia et al. (2023) Gabriel Poesia, Kanishk Gandhi, Eric Zelikman, and Noah D Goodman. 인증된 추론 언어 모델. _ arXiv preprint arXiv:2306.04031_, 2023.\n' +
      '* Poesia et al. (2024)* Polu and Sutskever (2020) Stanislas Polu and Ilya Sutskever. 자동정리증명을 위한 생성언어 모델링 CoRR_, abs/2009.03393, 2020. URL[https://arxiv.org/abs/2009.03393](https://arxiv.org/abs/2009.03393) _ 에프린트: 2009.03393.\n' +
      '* Prystawski et al. (2024) Ben Prystawski, Michael Li, and Noah Goodman. 왜 차근차근 생각하죠? 추론은 경험의 지역성에서 나온다. _ 신경 정보 처리 시스템_, 36, 2024의 발전.\n' +
      '* Qiao et al. (2024) Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, and Huajun Chen. Autoact: Automatic Agent learning from scratch via selfplanning. _ arXiv preprint arXiv:2401.05268_, 2024.\n' +
      '* Qiu et al. (2023) Linlu Qiu, Liwei Jiang, Ximing Lu, Melanie Sclar, Valentina Pyatkin, Chandra Bhagavatula, Bailin Wang, Yoon Kim, Yejin Choi, Nouha Dziri, et al. Phenomenal yet puzzling: Test inductive reasoning capabilities of language models with hypothesis refined. _ arXiv preprint arXiv:2310.08559_, 2023.\n' +
      '* Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever 등 언어 모델들은 비감독 멀티태스크 학습자들이다. _ OpenAI blog_, 1(8):9, 2019.\n' +
      '* Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 단일 텍스트-텍스트 변환기를 이용한 전이학습의 한계점 탐색 Journal of Machine Learning Research_, 21(140):1-67, 2020.\n' +
      '* Rajani et al.(2019) Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 설명해 봐! 상식적인 추론을 위해 언어 모델을 활용하는 것. In _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_, pp. 4932-4942, 2019.\n' +
      '* Schick et al. (2024) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 도구 형성기: 언어 모델은 스스로 도구를 사용하는 법을 배울 수 있습니다. _ 신경 정보 처리 시스템_, 36, 2024의 발전.\n' +
      '* Schulman et al. (2017) John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 근위 정책 최적화 알고리즘. _ ArXiv:1707.06347_, 2017.\n' +
      '* Schuster et al.(2021) Tal Schuster, Ashwin Kalyan, Alex Polozov, and Adam Tauman Kalai. 프로그래밍 퍼즐 _30-fifth Conference on Neural Information Processing Systems_, 2021. URL[https://openreview.net/forum?id=fe_hCc4RBrg](https://openreview.net/forum?id=fe_hCc4RBrg).\n' +
      '* Shinn et al. (2023) Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 반사: 언어 강화 학습이 있는 언어 에이전트 _ arXiv preprint arXiv:2303.11366_, 2023.\n' +
      '* Shwartz et al. (2020) Vered Shwartz, Peter West, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 자화자찬으로 대답하는 감독되지 않은 상식적인 질문 In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_, pp. 4615-4629, 2020.\n' +
      '* Silver et al. (2017) David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, et al. Mastering ches and shogi by self-play with general reinforcement learning algorithm. _ ArXiv preprint arXiv:1712.01815_, 2017.\n' +
      '* Talmor et al. (2018) Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. Commonsenseqa: commonsense 지식을 대상으로 하는 질문 응답 도전. _ arXiv preprint arXiv:1811.00937_, 2018.\n' +
      '* Todd et al. (2023) Eric Todd, Millicent L Li, Arnab Sen Sharma, Aaron Mueller, Byron C Wallace, and David Bau. 큰 언어 모델에서의 함수 벡터 _ arXiv preprint arXiv:2310.15213_, 2023.\n' +
      '* Uesato et al. (2022) Jonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, Lisa Wang, Antonia Creswell, Geoffrey Irving, and Irina Higgins. 과정 및 결과 기반 피드백으로 수학 단어 문제를 해결합니다. _ Neural Information Processing Systems (NeurIPS 2022) Workshop on MATH-AI_, 2022.\n' +
      '* Uesato et al. (2019)Ruocheng Wang, Eric Zelikman, Gabriel Poesia, Yewen Pu, Nick Haber, and Noah D Goodman. 가설 검색: 언어 모델을 이용한 귀납적 추론. _ arXiv preprint arXiv:2309.05660_, 2023.\n' +
      '* Wang and Zhou (2024) Xuezhi Wang and Denny Zhou. 프롬프트 없이 생각 추론을 계속합니다. _ arXiv preprint arXiv:2402.10200_, 2024.\n' +
      '* Weber et al. (2021) Lucas Weber, Jaap Jumelet, Elia Bruni, and Dieuwke Hupkes. 다중 작업 문제로서의 언어 모델링. _ arXiv preprint arXiv:2101.11287_, 2021.\n' +
      '* Wei et al. (2021a) Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 재정 조정된 언어 모델은 제로 샷 학습자입니다. _International Conference on Learning Representations_, 2021a.\n' +
      '* Wei et al. (2021b) Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 최적화된 언어 모델은 제로샷 학습자입니다. _ arXiv preprint arXiv:2109.01652_, 2021b.\n' +
      '* Wei et al. (2022a) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022년 10월, 대규모 언어 모델의 새로운 능력 URL[http://arxiv.org/abs/2206.07682](http://arxiv.org/abs/2206.07682). arXiv:2206.07682[cs].\n' +
      '* Wei et al. (2022b) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022b년 대형 언어 모델에서의 사고 프롬프트 추론 체인 URL[https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)\n' +
      '* Williams (1992) Ronald J Williams. 연결주의 강화 학습을 위한 간단한 통계적 기울기 추종 알고리즘. _ Machine learning_, 8:229-256, 1992.\n' +
      '* Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 반응: 추론과 언어 모델에서의 연기의 동기화. _ International Conference on Learning Representations (ICLR 2023)_, 2022.\n' +
      '* Zelikman et al. (2022) Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. 별: 추론과 함께 부트스트래핑 추론_ 신경 정보 처리 시스템_, 35:15476-15488, 2022에서의 발전.\n' +
      '* Zelikman et al. (2023a) Eric Zelikman, Qian Huang, Gabriel Poesia, Noah D. Goodman, and Nick Haber. Parsel: 분해를 구성하여 언어 모델을 사용한 알고리즘 추론, 2023a.\n' +
      '* Zelikman et al. (2023b) Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. 셀프 트레이닝된 최적화기(정지): 재귀적으로 자체 개선 코드 생성. _ arXiv preprint arXiv:2310.02304_, 2023b.\n' +
      '* Zhang and Parkes (2023) 휴 Zhang and David C Parkes. 생각 사슬 추론은 정책 개선 연산자이다. _ arXiv preprint arXiv:2309.08589_, 2023.\n' +
      '* Zhang et al. (2024) Tianjun Zhang, Aman Madaan, Luyu Gao, Steven Zheng, Swaroop Mishra, Yiming Yang, Niket Tandon, and Uri Alon. 실수로부터 맥락 내 원리 학습. _ arXiv preprint arXiv:2402.05403_, 2024.\n' +
      '* Zhang et al. (2022) Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 대용량 언어 모델에 대한 자동 사고 연쇄 ArXiv:2210.03493_, 2022.\n' +
      '* Zhao et al. (2023) Wenting Zhao, Justin T Chiu, Claire Cardie, and Alexander M Rush. 홉, 조합, 생성: 합리적 감독 없이 설명 가능한 다중 홉 추론 _ arXiv preprint arXiv:2305.14237_, 2023.\n' +
      '* Zhou et al. (2022) Hattie Zhou, Azade Nova, Hugo Larochelle, Aaron Courville, Behnam Neyshabur, and Hanie Sedghi. 상황 내 학습을 통한 알고리즘 추론 교수 ArXiv:2211.09066_, 2022.\n' +
      '* Zhu et al. (2023) Zhaocheng Zhu, Yuan Xue, Xinyun Chen, Denny Zhou, Jian Tang, Dale Schuurmans, and Hanjun Dai. 큰 언어 모델은 규칙을 학습할 수 있다. _ arXiv preprint arXiv:2310.07064_, 2023.\n' +
      '\n' +
      '## 부록 하이퍼파라미터 선택\n' +
      '\n' +
      '최적화 및 최적화를 위한 평가를 위해 20단계의 예열, \\(1e-6\\)의 학습 속도, 0.001의 중량 감소 및 8의 배치 크기를 갖는 AdamW 최적화기를 사용한다(실행 전반에 걸쳐 고정된 상태를 유지하기 위해 필요한 구배 축적과 함께). 또한, <!startofthought|>와 <!endofthought|> 임베딩 기울기 가중치는 \\(1e2\\)이고, 정책 가중치는 \\(1e6\\)이다. 훈련 시 온도\\(T=1\\)로 샘플링하고 평가 시 생각에는 탐욕 디코딩을 사용한다. 우리는 온도\\(T=3\\)에서 REINFORCE 손실을 계산하여 샘플을 중요 샘플로 취급한다. 우리는 어떤 예제로도 모델을 프롬프트하지 않기 때문에 정답 확률을 직접 계산하는데, 예를 들어 \\(A\\cdots E\\) 사이의 객관식 질문에 대해, \\(A\\cdots E\\)에 해당하는 토큰에 대해 로짓에 대한 정확도를 계산한다. 마지막으로, 교육을 위해 각 샘플(또는 256개 미만의 토큰이 있는 경우 패드)에서 256개 토큰의 랜덤 스팬을 선택합니다.\n' +
      '\n' +
      '믹싱 헤드(Mixing Head for our mixing head)는 ReLU 활성화와 함께 3-계층 MLP를 사용하여 언어 모델의 숨겨진 상태 크기의 2배 크기의 벡터를 취하고(그들의 가중치를 결정하기 위해 두 예측을 연결함에 따라), 스칼라(scalar)를 출력한다. 이 스칼라(scalar)는 주어진 토큰으로부터 예측을 하기 위해 생각하거나 생각하지 않고 LM 헤드의 로짓에 가중치를 부여하는 데 사용된다.\n' +
      '\n' +
      '우리는 80GB H100 8개의 단일 노드에서 모든 모델을 훈련한다.\n' +
      '\n' +
      '## 부록 B 더 빠른 병렬 샘플링\n' +
      '\n' +
      '이 절에서는 병렬 생성 알고리즘을 더욱 가속화하기 위한 몇 가지 간단한 방법을 강조한다. 예를 들어, 대각 주의를 단순히 요소별(쌍별이 아닌) 도트 곱으로 계산함으로써 주의의 메모리 비용을 줄일 수 있다는 점에 유의하십시오. 즉, \\(b,t,l,d)\\)와 \\(b,1,l,d)\\)의 두 입력 임베딩 시퀀스가 주어졌을 때, \\(t\\)은 타임스테프의 앞수, \\(b\\)은 배치 크기, \\(l\\)은 시퀀스 길이, \\(d\\)은 임베딩 차원이다. \\(b,t,l,l)\\)의 쌍별 주의력을 계산할 필요가 없으며, \\(b,t,l)\\)의 대각선을 따라 쌍을 이루는 요소에 대한 주의력을 계산할 필요가 있다. 추가적으로, 모든 토큰들에 대한 연속체들을 생성하는 것을 피하기 위해(예를 들어, 생각들이 가장 유용할 곳을 결정하기 위해 값 함수를 적용하기를 원한다면), 이 생성된 주의 마스크에 인덱싱할 수 있다. 그러나, 특히, 이것은 또한 위치 임베딩과 같은 순방향 패스 동안 다른 입력들의 조작을 필요로 한다.\n' +
      '\n' +
      '## 부록 C 계산 조정 플롯\n' +
      '\n' +
      '우리는 또한 훈련에 사용되는 사고 및 토크 토큰의 수로 정규화하는 그림 2를 시각화한다.\n' +
      '\n' +
      '## 부록 D: 시퀀스별 다중 사고와 다중 토큰 사전의 영향 측정\n' +
      '\n' +
      '우리는 12-생각-토큰-4-사전 기준선에 대해 간단한 절제, 즉 서열당 여러 생각을 샘플링하는 것이 필요한지 여부를 질문한다. 우리는 단순히 보상이 생각이 있는 손실과 없는 손실의 차이로 계산되는 것이 강력한 기준선임을 입증하지만, 여러 생각을 사용하는 것이 일관되게 그것을 능가한다는 것을 발견했다(GSM8K 일반화에서 약 0.5%, 커먼센스QA 일반화에서 약 3%). 그러나, 정확한 생각의 수는 거의 영향을 미치지 않았다: 시퀀스당 2, 3, 4개의 생각 사이에서 변하는 것은 부가적인 생각과 함께 일관된 개선을 초래하는 것으로 나타났지만, GSM8K와 커먼센스QA 모두에서 2개의 성능을 능가하는 추가 생각은 단지 0.1-0.3% 개선되었다. 유사하게, 우리는 하나 이상의 토큰 전방을 예측하는 것이 GSM8K에서는 0.3%, 커먼센스QA에서는 3.1% 도움이 된다는 것을 발견했지만, 12개의 아이디어 토큰에서는 2개 이상의 추가 토큰 전방이 성능을 향상시킨다는 것을 발견하지 못했다. 그러나 질적으로, 우리는 이론적 근거가 감독 이전에 추가 토큰과 더 일관성이 있는 것으로 나타났음을 발견했다. 이는 향후 작업에서 세대 품질에 대한 보다 구체적인 평가가 필요함을 시사한다.\n' +
      '\n' +
      '## 부록 E 합리성 강화 합리성\n' +
      '\n' +
      '언어 모델은 사고를 어디에나 삽입할 수 있기 때문에, 문제를 해결하기 위해 외부 추론(즉, 사고 사슬)을 생성하는 동안 내부 추론에 접근할 수 있을 때 언어 모델이 생성한 추론을 조사하는 예비 연구를 수행한다. 이러한 생각의 사슬은 그 자체가 생각의 사슬에 의해 생성되기 때문에, 이를 생각의 순(또는 NoT)이라고 지칭할 수 있다. GSM8K의 고정 무작위 질문과 모델로부터 5개의 해를 비교하여 기본 미스트랄 7B의 출력, 오픈웹마스의 동일한 단계(Paster et al., 2023)에 대한 미스트랄 미세 조정 출력 및 최상의 Quiet-STAR 모델의 근거를 살펴본다. 온도\\(t=1\\)에서 직접 시료를 채취한다.\n' +
      '\n' +
      '### 베이스 미스트랄 7B\n' +
      '\n' +
      'First Response:\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다. 3명이 아침으로 먹고 4명이 친구들을 위해 머핀 믹스에 들어간 후 얼마나 많은 신선한 달걀이 남아 있는지. 우리는 16-3-4로 계산할 수 있다. 그 양은 9개의 신선한 달걀과 같다. 그래서 매일 버는 달러는 2달러를 곱한 것과 같습니다. 12 x 2. 답은 24달러입니다.\n' +
      '\n' +
      'Second Response:\n' +
      '\n' +
      'Q: 자넷의 오리는 하루에 16개의 알을 낳습니다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가?\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다. 그녀는 아침 식사로 매일 3개씩 먹는다. 그녀는 친구들을 위해 매일 4개씩 머핀에 굽는다. 그것은 9를 남깁니다. 그녀는 9를 \\(\\(2\\)), 그래서 \\(9\\) 곱하기 2=\\(\\$18\\)\\()에 팔았습니다. 그래서 자넷은 매일 오리알을 팔아서 18달러를 번다.\n' +
      '\n' +
      '도 7: **Compute-Normalized Generalization Results**. 우리는 사용된 추론 호출의 수로 정규화된 성능 곡선을 시각화한다.\n' +
      '\n' +
      '66. 자넷이 농산물 시장에서 매일 평균 12개의 신선한 오리 알을 판매한다. 자넷이 농산물 시장에서 매일 가장 많이 판매한다고 가정할 때 일주일에 얼마나 버는지 계란당 2달러에 판매한다면: 자넷이 농산물 시장에서 매일 평균 12개의 신선한 오리 알을 판매한다면. 이것은 \\(\\{12\\)times 7\\}과 같으므로, 12\\(\\{\\{\\)\\(\\(\\}\\)\\(\\(\\}\\)\\(7\\)\\(7\\)\\(8\\(\\}\\)\\(\\백슬래시\\)이다. 그녀가 벌어들일 총 금액은 주당 168원(84배 2원)이다. 그래서 자넷은 일주일에 오리알을 팔아서 168달러를 번다.\n' +
      '\n' +
      'Third Response:\n' +
      '\n' +
      'Q: 자넷의 오리는 하루에 16개의 알을 낳습니다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가?\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다.\n' +
      '\n' +
      '그녀는 매일 달걀을 몇 개나 남기지?\n' +
      '\n' +
      '이것은 그녀가 하루에 얼마나 많은 달걀을 파는지를 찾는 데 도움이 될 것이기 때문에 중요합니다.\n' +
      '\n' +
      '우리가 그 질문에 답하기 위해 무엇을 할 수 있을까?\n' +
      '\n' +
      '자넷이 얼마나 많은 오리알을 남겼는지, 얼마나 많이 먹는지, 머핀을 위해 얼마나 많이 굽는지 관계를 적으면, 자넷이 얼마나 많은 달걀을 농산물 시장에서 팔 수 있는지 알 수 있습니다.\n' +
      '\n' +
      '우리의 딜레마를 풀 수 있는 방정식을 써보자.\n' +
      '\n' +
      '먹힌 계란에 대한 방정식과 구운 계란에 대한 방정식을 빼서 남은 달걀을 찾아라. 뭘 찾을 수 있는지 보자고\n' +
      '\n' +
      '우리는 자넷이 매일 6개의 달걀을 남기는 것을 볼 수 있다. 6\\(\\sim\\)$2 = \\(\\backslash\\)$12.\n' +
      '\n' +
      '따라서 자넷은 농산물 시장에서 하루에 12달러를 추가로 받는다.\n' +
      '\n' +
      '기억하세요, 이것은 단지 하루 동안입니다. 그래서 이제 그녀는 매일 농부 시장에서 알을 판매하기 때문에 추가 수입으로 하루에 12달러를 벌고 있습니다.\n' +
      '\n' +
      '### Answer\n' +
      '\n' +
      '$12\n' +
      '\n' +
      'Fourth Response:\n' +
      '\n' +
      'Q: 자넷의 오리는 하루에 16개의 알을 낳습니다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가?\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다. 먼저, 당신은 자넷이 매일 수집하는 총 계란의 수를 알고 싶어한다. 3에 이 많은 달러를 가져다가 계란 한 개당 받는 돈에서 빼면 2달러입니다. 그 질문에 대한 답은 5달러입니다.\n' +
      '\n' +
      '다섯 번째 응답 Q: 자넷의 오리는 하루에 16개의 알을 낳습니다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가?\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다.\n' +
      '\n' +
      '첫 번째 단계로, 알의 수를 추적하기 위해 몇 가지 변수를 사용하여 하루 전체를 생각해 봅시다. $n$ = 자넷의 오리가 하루에 낳는 알의 수입니다. 그러면 그녀가 하루에 먹는 계란의 수는 $(3)$ =일 것이다.\n' +
      '\n' +
      '다음으로, 그녀는 $n$ = 머핀을 만든다. 각각의 머핀에 대해, 그녀는 4$ = 달걀을 사용하므로, 우리는 재닛의 오리가 낳은 달걀을 가지고 그녀가 사용하는 숫자를 나타낼 수 있습니다: $4(n)$. 달걀의 시작 숫자로 돌아가려면 이 달걀을 다시 넣어야 해요 자넷이 매일 파는 계란은 그녀에게 $2$$(n)$ = $를 가져다 준다. 이것은 우리를 다음 단계로 이끈다.\n' +
      '\n' +
      '이제 우리는 우리의 시작 숫자인 n$=의 모든 알들을 우리가 이전에 설정했던 조각들로 분해할 것이다. 시작 숫자에 대해, 우리는 다음과 같다: 이것은 우리를 다시 시작 숫자로 가져오고, 우리는 이 식을 단순화할 수 있다.\n' +
      '\n' +
      '맨 위 선에서 두 번째 선으로 이동하면 각 선 내의 수를 곱한다.\n' +
      '\n' +
      '미장군. 두 번째 줄에서 세 번째 줄로 이동하면\n' +
      '\n' +
      '총계를 찾기 위해 제품을 함께 찾습니다. 마지막으로 배포하고 결정할 수 있습니다.\n' +
      '\n' +
      '최종 제품: $=360.$\n' +
      '\n' +
      '그래서 자넷의 오리가 하루에 낳는 알의 총 수는 자넷이 판매하기 때문에 360.$이다.\n' +
      '\n' +
      '농산물 시장에서 2,000달러의 총 수입을 위해 그녀가 가지고 있는 계란은 각각 $boxed($\n' +
      '\n' +
      '720).$\n' +
      '\n' +
      '### OpenWebMath-Trained Mistral 7B\n' +
      '\n' +
      'First Response:\n' +
      '\n' +
      '자넷의 오리는 하루에 16개의 알을 낳는다. 그녀는 매일 아침 세끼를 먹는다.\n' +
      '\n' +
      '매일 4개로 그녀의 친구들을 위해 머핀을 굽는다. 그녀는 나머지를 판다.\n' +
      '\n' +
      '농부들의 시장은 매일 신선한 오리알당 2달러에 판매된다. 얼마나요?\n' +
      '\n' +
      '그녀는 농산물 시장에서 매일 돈을 버나요?\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다. 그녀는 매일 얼마나 버나요? 질문에 따르면\n' +
      '\n' +
      '그것은 오리알 하나에 2달러이다. 이제, 그녀는 하루에 몇 개의 오리 알을 판매하나요? 음...\n' +
      '\n' +
      '그것은 16에서 그녀가 먹는 달걀에서 그녀가 만드는 달걀을 뺀 것이다.\n' +
      '\n' +
      'ke muffins.\n' +
      '\n' +
      '그녀는 매일 아침 3개의 달걀을 먹으므로 16달러-3달러 = 13달러이다.\n' +
      '\n' +
      '4개의 머핀을 만들어요 달걀 4개를 사용해서요 16-3-4 = $5.\n' +
      '\n' +
      '따라서 그녀가 판매하고 있는 오리알의 수는 55달러입니다.\n' +
      '\n' +
      '분명히, 오리알 1개는 2달러입니다. 따라서, 그녀가 그 알을 팔기 위해 만드는 총 금액은\n' +
      '\n' +
      '10달러 25센트입니다. 자, 이것은 "10달러 2달러"로 분수로 쓰여질 수 있습니다. 따라서 102달러 -\n' +
      '\n' +
      'bucks.$\n' +
      '\n' +
      '분수, 즉 "10분의 10"으로 변환하면, $102 - $=$1$$10 - $$\n' +
      '\n' +
      '[공개-답변 q="fs-id1165135856725"]Show Solution[/공개-답변]\n' +
      '\n' +
      '[hidden-answer a="fs-id1165135856725"]\n' +
      '\n' +
      'Second Response:\n' +
      '\n' +
      '자넷의 오리는 하루에 16개의 알을 낳는다. 그녀는 매일 아침 세 끼를 먹는다.\n' +
      '\n' +
      '매일 네 마리로 친구들을 위해 머핀을 구워요 그녀는 나머지를 …에 판다.\n' +
      '\n' +
      '농산물 시장은 매일 신선한 오리알당 2달러에 판매된다. 그녀는 얼마나 많은 돈을 가지고 있는가?\n' +
      '\n' +
      '농산물 시장에서 매일 만들어?\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다. 우리가 어떤 근거로 그 질문에 답할 수 있을까?\n' +
      '\n' +
      '질문이요? 주어진 것과 주어진 것을 어떻게 사용할 수 있는가?\n' +
      '\n' +
      '대답으로. 3이 주어지고, 4가 주어지고, 16이 주어지고, 생각나는 사람 있나요?\n' +
      '\n' +
      'A: 우물 16에서 3에서 4를 빼면 9가 되고, 9에서 1을 빼면 4가 된다.\n' +
      '\n' +
      '달걀 다섯 개 더\n' +
      '\n' +
      'M: 그리고 우리는 2 곱하기 5가 얼마라는 것을 알고 있어?\n' +
      '\n' +
      'A: Ten\n' +
      '\n' +
      'M: Yes.\n' +
      '\n' +
      'A: 만약 그녀가 아침으로 3개의 오리알을 먹는다면, 아침에는 \\((3\\) 곱하기 2 = 6\\)과 같다. 만약\n' +
      '\n' +
      '그녀는 친구들을 위해 머핀을 굽는 오리알 4개를 먹는다.\n' +
      '\n' +
      '총 돈과 그녀가 받은 돈의 합계는 6달러 더하기 8달러는 14이다. 체중 증가는 5이다.\n' +
      '\n' +
      '왜냐하면 5는 당신이 거기에 올려놓은 것을 5 곱하기 2개의 오리로 빼는 것이기 때문입니다.\n' +
      '\n' +
      '16살 때 7살 때 우리가 뭘 적었더라? 당신은...\n' +
      '\n' +
      '지금 그 질문이 무엇인지, 그리고 그 질문이 진짜 무엇인지. 14점\n' +
      '\n' +
      '체중 감량, 당신은 16에서 2, 14달러에서 2를 뺀 것입니다.\n' +
      '\n' +
      '남은 사람이 뭐?\n' +
      '\n' +
      'A: 12.\n' +
      '\n' +
      'M: 문제는 재닛 오리가 16개의 알을 낳고, 그녀는 12개를 팔기 위해 먹는 것이 무엇인지야. 너\n' +
      '\n' +
      '3 더하기 4 빼기 5, 그래서 머핀을 먹을 때 5는 5, 곱하기 2, 12,\n' +
      '\n' +
      '5 곱하기 2, $-125. So \\((2\\) 곱하기 9 = 18\\)에서 $10을 빼면 4가 더 된다.\n' +
      '\n' +
      '계란... 여전히 2달러 곱하기, 총액은 20달러가 된다.\n' +
      '\n' +
      'A: 나는 3 더하기 4를 먹는 하루가 있다는 것을 알고 있다.\n' +
      '\n' +
      'M: 하지만 정확하게 대답하기 위해서는 조금 가까이서 봐야 할 것 같아. 전형적으로\n' +
      '\n' +
      '그들이 당신에게 먼저 주는 절차에서, 나는 우리가 어떻게 여기 있는지 말할 수 있습니다.\n' +
      '\n' +
      'M: 이제 16을 더하면 16 빼기 3 빼기 4를 결정해야 하고 나머지를 더하면 9가 된다. 그러면 1을 빼고 나머지를 더하면 5가 된다. 그러면 다음 대답은 10이 되는 5 곱하기 2가 된다. M: 10이 되고 나머지가 되는 14가 된다. M: 6과 8이 되고 나머지가 되는 14가 된다. 그리고 이제 2를 빼면 16 빼기 5가 된다. M: 다음 일은 16 빼기 3 더하기 4가 되는 11이 된다. M: 다음 일은 16 빼기 3 더하기 4가 되는 두 번째 상황에 대한 수익률이다. 5 곱하기 2는 10이 되고, 16달러는 4.5를 더하면, 이제 총합은 16 더하기 2가 됩니다. 그러나 이제 10달러 더하기 2는 12달러입니다. 그래서 16에서 얼마를 팔고 그 다음에 마이너스 12는 4가 됩니다. M: 그래서 나머지 16 빼기 3 더하기 4 빼기 57은 3이 빠진 것입니다. 네 개야 계란 다섯 개 그래서 5 곱하기 2, 그래서 10달러는 10달러로 유지됩니다. 그래서 이제 10달러는 10달러로 감소합니다. 다음 문제는 16미너스 3 더하기 4이고, 아마도 당신은 이것을 전에 했을 것입니다. 그렇지 않다면 16 빼기 3 더하기 4를 더하면 9가 되고, 57 뒤에 남은 것은 무엇입니까? 그래서 5 곱하기 2? 그래서 10. 2, 3, 더하기 2 = 5이고, 그래서 지금까지 당신의 대답은 16 빼기 3 더하기 4이고, 우리에게 바구니 -2를 주고, 이제 두 번째 부분의 총합이 얼마인지 결정해야 합니다. 당신은\n' +
      '\n' +
      'Third Response:\n' +
      '\n' +
      'Q: 자넷의 오리는 하루에 16개의 알을 낳는다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가? A: 단계별로 생각해 보자. "달러로 얼마"라는 부분은 하나의 계란이 1달러의 가치가 있다는 것을 의미합니다. 그래서 12마리의 오리가 16개의 알을 낳았다는 것은 자넷이 20달러를 팔아치운다는 것을 의미한다. 16개의 머핀은 우리에게 4개의 달걀을 줄 것이고, 그것은 우리에게 8달러를 준다. 그래서 우리는 16개의 머핀을 만들기 위해 재료비로 108달러를 지불했다. 그래서 96달러를 잃었습니다. 안녕, 여주인공, 우리는 그것보다 더 잘해야 해! 평균을 살펴보세요. 계란 하나에 5달러를 지불한다고 합시다. 이제 12달러는 저희 상품이고 5달러는 저희 투자입니다. 우리의 순 재산은 $12-$*12 = 24달러입니다. 맞습니까?\n' +
      '\n' +
      'Fourth Response:\n' +
      '\n' +
      'Q: 자넷의 오리는 하루에 16개의 알을 낳는다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가? A: 차근차근 생각해 봅시다. 첫째, 제인의 오리는 하루에 16개의 알을 낳습니다. 그래서 월요일에는 계란 16개, 트웨데이 16개, 트웨데이 16개, 목요일 16개, 금요일 16개 등이 있습니다. 둘째, 자넷은 아침 식사로 오리털 에이프 데이의 16개 계란 중 3개를 먹는다. 그녀는 구운 음식(머핀)이나 다른 음식이 아니라 오리알만 먹는다. 따라서 그녀는 월요일 3시, 트웨데이 3시, 수요일 3시, 목요일 3시 등을 먹는다. 셋째, 그녀는 처음 4개의 먹지 않은 계란만 머핀에 굽습니다. 따라서 그녀는 월요일, 트웨세이 12개, 수요일, 목요일 12개 등 나머지 12개의 비식용 달걀을 판매한다. 넷째, 자넷은 월요일, 화요일, 수요일, 목요일, 금요일에 오리알을 각각 2개씩 판매합니다. 셋째, 파머스 마켓에서 3월, 3월, 3월, 3월, 3월, 3월, 3월, 3월, 목요일, 금요일에 식사를 하고, 마지막으로 파머스 마켓에서 매일 12월, 12월, 12월, 12월, 12월, 12월, 12월, 12월, 12월, 12월 등을 달러로 만듭니다. 아래 워크시트는 이러한 단계를 요약합니다. 해당 행 항과 열 항이 교차하여 형성되는 숫자가 정답이 될 것이다. (3, J)항과 (J, 8)항의 곱은 1,150입니다. 그래서 자넷은 하루에 1,150달러를 벌어요! (주: 단계 3 및 단계 8은 반복되지만, 단계 8에서의 (3,7) 항은 단계 3에서의 (3,7) 항과 동일하지 않다.)\n' +
      '\n' +
      'Fifth Response\n' +
      '\n' +
      'Q: 자넷의 오리는 하루에 16개의 알을 낳는다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가? A: 차근차근 생각해 봅시다. 우리가 아는 건?\n' +
      '\n' +
      '재닛의 오리는 하루에 16개의 알을 낳아요\n' +
      '매일 아침 세 끼를 먹고 4끼로 매일 친구들을 위해 머핀을 구워요\n' +
      '\n' +
      '이 두 가지 사실로부터 우리는 적어도 자넷이 하루에 소비하기 위해 적어도 7개의 계란이 필요하다는 결론을 내릴 수 있다. 정확히 뭘 찾아야 하죠?\n' +
      '\n' +
      '재닛이 농산물 시장에서 매일 얼마나 버는지 알아내야 해요\n' +
      '\n' +
      '정답을 찾기 위해 방정식을 써서 풀자. 우린 알아\n' +
      '\n' +
      '- \\(\\langle\\)16-3-4=9\\(\\rangle\\) 그래서 우리의 일당 이익은 $2의 9배 또는 \\(\\langle\\)9times\\$2=\\$18\\(\\rangle\\)이므로 주어진 날에 시장에서 그녀의 이익은 \\(\\langle\\)$18\\(\\rangle\\)이다. 정답: \\(\\langle\\)$18\\(\\rangle\\)\n' +
      '\n' +
      '### Quiet-STaR-Trained Mistral 7B\n' +
      '\n' +
      'First Response:\n' +
      '\n' +
      '자넷의 오리는 하루에 16개의 알을 낳는다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가? A: 차근차근 생각해 봅시다.\n' +
      '\n' +
      '오리는 하루에 16개의 알을 낳습니다.\n' +
      '\n' +
      '이것은 계란의 총 수입니다.\n' +
      '\n' +
      '계란 3개는 아침 식사로 먹습니다.\n' +
      '\n' +
      '이것은 아침 식사로 먹는 계란의 수입니다.\n' +
      '\n' +
      '계란 4개는 머핀을 만드는 데 사용됩니다.\n' +
      '\n' +
      '이것은 머핀을 만드는 데 사용되는 계란의 수입니다.\n' +
      '\n' +
      '16 - 3 - 4 = 9\n' +
      '\n' +
      '9는 농산물 시장에서 판매되는 계란의 수이다.\n' +
      '\n' +
      '계란 중 9개는 농산물 시장에서 판매됩니다.\n' +
      '\n' +
      '계란 한 개당 가격은 2달러입니다.\n' +
      '\n' +
      '$2\\times 9 = 18$\n' +
      '\n' +
      '18은 계란의 총 가격입니다.\n' +
      '\n' +
      '계란 총 가격은 18달러입니다.\n' +
      '\n' +
      '두 번째 응답:A: 단계적으로 생각해 봅시다.\n' +
      '\n' +
      '1. 오리는 하루에 16개의 알을 낳는다.\n' +
      '2. 그녀는 매일 아침 세끼를 먹는다.\n' +
      '3. 그녀는 매일 4와 함께 친구들을 위해 머핀을 굽는다.\n' +
      '4. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리알당 2달러에 판다.\n' +
      '5. 그녀가 농산물 시장에서 판매하는 계란의 수는 16-3-4개이다.\n' +
      '6. 그녀가 농산물 시장에서 판매하는 계란의 수는 16-3-4개이다.\n' +
      '7. 그녀가 농산물 시장에서 판매하는 계란의 수는 16-3-4개이다.\n' +
      '8. 그녀가 농산물 시장에서 판매하는 계란의 수는 16-3-4개이다.\n' +
      '9. 그녀가 농산물 시장에서 판매하는 계란의 수는 16-3-4개이다.\n' +
      '10. 그녀가 농산물 시장에서 판매하는 계란의 수는 16-3-4개이다.\n' +
      '11. 개수\n' +
      '\n' +
      'Third Response:\n' +
      '\n' +
      '자넷의 오리는 하루에 16개의 알을 낳는다. 그녀는 매일 아침 세 개를 먹고 4개로 매일 친구들을 위해 머핀을 굽는다. 그녀는 남은 것을 매일 농산물 시장에서 신선한 오리 알 한 개당 2달러에 판다. 그녀는 매일 농산물 시장에서 얼마나 버는가?\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다.\n' +
      '\n' +
      '오리는 하루에 16개의 알을 낳습니다.\n' +
      '\n' +
      '이것은 계란의 총 수입니다.\n' +
      '\n' +
      '3은 자넷이 매일 아침 아침으로 먹는 계란의 수입니다.\n' +
      '\n' +
      '4는 그녀가 매일 친구들을 위해 굽는 머핀에 사용하는 계란의 수입니다.\n' +
      '\n' +
      '16 - 3 - 4 = 9\n' +
      '\n' +
      '9는 그녀가 매일 농산물 시장에서 신선한 오리 알당 $2에 판매하는 알의 수이다.\n' +
      '\n' +
      '9$2 = 9$2\n' +
      '\n' +
      '=9$2\n' +
      '\n' +
      '= 18\n' +
      '\n' +
      '그래서 18은 그녀가 농산물 시장에서 매일 버는 달러 금액입니다.\n' +
      '\n' +
      '그녀가 농산물 시장에서 매일 버는 달러 금액은 18달러입니다.\n' +
      '\n' +
      'A: 18</s>\n' +
      '\n' +
      'Fourth Response:\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다.\n' +
      '\n' +
      '재닛의 오리가 하루에 낳는 알의 수는 16개입니다.\n' +
      '\n' +
      '이 중, 그녀는 매일 아침 세 끼를 먹는다.\n' +
      '\n' +
      '3번입니다.\n' +
      '\n' +
      '이 중, 그녀는 4명의 친구들을 위해 머핀을 굽습니다.\n' +
      '\n' +
      '이것은 4입니다.\n' +
      '\n' +
      '남은 계란의 수는 16-3-4개입니다.\n' +
      '\n' +
      '이건 16-7이야\n' +
      '\n' +
      '이건 9시예요\n' +
      '\n' +
      '그녀가 매일 농산물 시장에서 계란 한 개당 2달러에 판매하는 계란의 수는 9개이다.\n' +
      '\n' +
      '그녀가 농산물 시장에서 매일 버는 총액은 9달러 2센트이다.\n' +
      '\n' +
      '9시 2분입니다\n' +
      '\n' +
      '이건 18살이야\n' +
      '\n' +
      '그녀가 농산물 시장에서 매일 버는 총액은 18달러입니다.\n' +
      '\n' +
      'A: 18\n' +
      '\n' +
      'Fifth Response\n' +
      '\n' +
      'A: 차근차근 생각해 봅시다.\n' +
      '\n' +
      '오리는 하루에 16개의 알을 낳습니다.\n' +
      '\n' +
      '이것은 계란의 총 수입니다.\n' +
      '\n' +
      '3 + 4 + 16 = 23\n' +
      '\n' +
      '계란 3개는 매일 아침 아침으로 먹습니다.\n' +
      '\n' +
      '달걀 4개는 매일 친구들을 위해 머핀을 만드는 데 사용됩니다.\n' +
      '\n' +
      '16개의 계란이 농산물 시장에서 매일 2달러에 판매됩니다.\n' +
      '\n' +
      '농산물 시장에서 판매되는 16개의 계란은 남은 계란이다.\n' +
      '\n' +
      '16 - 3 - 4 = 9\n' +
      '\n' +
      '9개의 계란은 농산물 시장에서 매일 2달러에 판매됩니다.\n' +
      '\n' +
      '9(2) = 18\n' +
      '\n' +
      '18은 그녀가 농산물 시장에서 매일 벌어들인 총 달러이다.\n' +
      '\n' +
      '18이 정답입니다.\n' +
      '\n' +
      'A: 18\n' +
      '\n' +
      '## 부록 F 추론 학습에 대한 추가 작업\n' +
      '\n' +
      '완전성을 위해, 우리는 많은 다른 작품들이 언어 모델을 추론(종종 STAR과 유사하거나 영감을 받은 알고리즘으로)하기 위해 자신의 이론적 이유, 환경과의 상호 작용 또는 손으로 구성된 데이터 세트에서 탐구했음을 강조한다. 예를 들어, 작업들은 멀티홉 질문 응답(Zhao et al., 2023), 수학(Luo et al., 2023; Uesato et al., 2022), 기계 번역(Gulcehre et al., 2023)의 맥락에서 이를 탐구한다. 여러 연구는 계획에서 추론에 대한 언어 모델 에이전트를 조사(Chen et al., 2023; Gandhi et al., 2023; Qiao et al., 2024)하거나 특정 도구 또는 메모리를 사용(Yao et al., 2022; Lanchantin et al., 2024; Schick et al., 2024)하는 반면, 다른 연구는 큰 언어 모델에서 더 작은 언어 모델 Ho et al. (2022); Li et al. (2022); Hsieh et al. (2023). 그러나 특히 이러한 피드백 루프에 대한 Pan 등(2024)은 리워드 해킹을 초래할 수 있다. Zelikman et al.(2023b)는 모델이 동일한 코드 개선자를 사용하여 코드 개선자를 반복적으로 개선하는 경우에 부트스트래핑 루프가 어떻게 구현될 수 있는지를 보여주고 Haluptzok et al.(2023)은 언어 모델들이 프로그래밍 퍼즐 Schuster et al.(2021)로 그들의 프로그래밍 능력을 부트스트랩할 수 있는지를 보여준다. 다른 작업들은 귀납적 추론 태스크들을 해결하기 위해 또는 실제-세계 시스템들을 모델링하기 위해 언어 모델들을 사용하기 위한 유사한 전략을 채용하였다(Wang et al., 2023; Qiu et al., 2023; Zhu et al., 2023; Li et al., 2024).\n' +
      '\n' +
      '일부 작업은 모델들이 그들의 추론 실수들로부터 어떻게 부정확하게 학습할 수 있는지를 조사했다(Shinn et al., 2023; Madan et al., 2023; Zhang et al., 2024; Liu et al., 2023). 많은 연구들은 또한 문맥 내 추론 예제(Lampinen et al., 2022; Zhou et al., 2022)로부터 LMs가 학습하는 능력에 초점을 맞추었다 - 이에 대응하여, Khattab et al. (2022) 및 Khattab et al. (2023)은 모델을 추론하도록 프롬프트하기 위해 사용된 예제 세트가 어떻게 다중 단계 추론 파이프라인의 맥락에서 최적화될 수 있는지를 보여준다. 또한 Zhang et al.(2022)은 추론에 다양한 제로샷 프롬프트를 사용하여 언어 모델에서 제로샷 질문 응답을 개선할 수 있음을 보여주었다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>