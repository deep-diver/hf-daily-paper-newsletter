<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 추상화 추론을 이용한 효율적인 도구 사용\n' +
      '\n' +
      ' Silin Gao\\({}^{1,2}\\), Jane Dwivedi-Yu\\({}^{2}\\), Ping Yu\\({}^{2}\\), Xiaoqing Ellen Tan\\({}^{2}\\)\n' +
      '\n' +
      'Ramakanth Pasunuru\\({}^{2}\\)**, **Olga Golovneva\\({}^{2}\\)**, **Koustuv Sinha\\({}^{2}\\)**\n' +
      '\n' +
      'Asli Celikyilmaz\\({}^{2}\\)**, **Antoine Bosselut\\({}^{1}\\)**, **Tianlu Wang\\({}^{2}\\)**\n' +
      '\n' +
      'EPFL, \\({}^{2}\\)FAIR@Meta\n' +
      '\n' +
      '\\({}^{1}\\){silin.gao,antoine.bosselut}@epfl.ch\n' +
      '\n' +
      '\\({}^{2}\\){silingao,janyu,pingyu,ellenxtan}@meta.com\n' +
      '\n' +
      '\\({}^{2}\\){rpasunuru,olggol,koustuvs,aslic,tianluwang}@meta.com\n' +
      '\n' +
      'FAIR에서 실린 가오가 인턴쉽을 하는 동안 일을 했다.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '인간의 기대와 일치하는 충실한 추론을 달성하기 위해, 대형 언어 모델(LLM)은 그들의 추론을 실제 지식(예: 웹 사실, 수학 및 물리적 규칙)에 기초할 필요가 있다. 도구는 LLM이 이러한 외부 지식에 접근하는 것을 돕지만, 상호 연결된 도구 호출이 전체적이고 효율적인 도구 사용 계획을 필요로 하는 다단계 추론 문제에서 LLM 에이전트(예: Toolformer)가 도구를 호출하기 위해 미세 조정해야 하는 과제가 남아 있다.\n' +
      '\n' +
      '본 연구에서는 다단계 추론에서 LLM이 도구를 더 잘 활용할 수 있는 새로운 방법을 제안한다. 추상화 체인(Chain-of-Abstraction, CoA)은 LLM을 학습하여 먼저 추상적 자리 표시자가 있는 추론 체인을 해독하고, 도메인 도구를 호출하여 특정 지식을 채워 각 추론 체인을 검증한다. 추상 체인을 사용한 이러한 계획은 LLM이 더 일반적인 추론 전략을 학습할 수 있게 하며, 이는 다양한 추론 질문과 관련된 도메인 지식(예: 수학 결과)의 이동에 강력하다. 또한, LLM이 외부 툴의 디코딩 및 호출을 병렬로 수행할 수 있게 하여 툴 응답들을 대기하는 것에 의해 야기되는 추론 지연을 방지한다. 수학적 추론과 위키 QA 영역에서, 본 논문에서 제안한 방법은 평균 \\(\\sim 6\\%\\)의 절대 QA 정확도 향상으로 분포 내 테스트 세트와 분포 외 테스트 세트 모두에서 기존의 생각 및 도구 확장 기준보다 일관되게 우수함을 보인다. 또한 본 논문에서 제안한 방법으로 훈련된 LLM 에이전트는 기준선 도구 증강 LLM에 비해 추론 속도가 평균 \\(\\sim\\)\\(1.4\\times\\) 빨라 더 효율적인 도구 사용을 보인다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '최근의 대형 언어 모델들(LLMs; Touvron et al., 2023; Anil et al., 2023; OpenAI, 2023)은 명령어들을 해석하고 실행하는 데 진전을 이루었지만(Wei et al., 2021; Chung et al., 2022), 그들의 응답들에 대한 세계 지식을 회상하고 구성할 때 여전히 오류를 범하고, 예를 들어, 비사실적 진술들(Maynez et al., 2020; Ji et al., 2023), 부정확한 계산들(Patel et al., 2021) 등을 포함한다. 추론 시간에 보조 도구(_예를 들어, 신뢰할 수 있는 사실을 제공하기 위한 검색 엔진, 정확한 수학 연산을 위한 계산기 등)를 사용하면 이러한 오류 중 일부를 완화할 수 있으며, 외부 API 호출을 자신의 출력 세대에 통합하는 도구 증강 언어 모델을 동기화할 수 있다(Parisi et al., 2022; Schick et al., 2023; Hao et al., 2023).\n' +
      '\n' +
      '그러나, 현재 툴-증강 LLMs, _e.g._, Toolformer(Schick et al., 2023)가 다단계 추론에서 툴을 신뢰성 있고 효율적으로 활용하기 위해 고군분투하고 있음을 보인다. 특히, 다단계 추론 작업에서의 툴 호출은 종종 인터리빙된다(_i.e._, API 호출의 응답은 종종 후속 호출의 질의의 일부; 도 1에 도시된 바와 같이). 이러한 상호 연결을 명시적으로 모델링하지 않고\n' +
      '\n' +
      '그림 1: 도구를 사용한 추상화 추론의 개요. 도메인 질문(녹색 스크롤)이 주어지면 LLM은 먼저 추상적인 다단계 추론 체인(파란색 버블)을 생성하고 외부 도구를 호출하여 도메인별 지식(주황색 레이블)으로 체인을 검증한다. 최종 답(노란 거품)은 재화된 추론의 사슬을 바탕으로 얻어진다.\n' +
      '\n' +
      '추론 체인에서 LLM은 도구 사용에 대한 효과적인 계획을 학습하지 못하며, 이는 도구 사용에 대한 덜 정확한 추론으로 이어진다.1 한편, API 호출을 사용한 인터리빙 텍스트 생성은 또한 비효율적인 추론 "대기 시간"을 도입하며, 여기서 모델은 디코딩 프로세스를 재개하기 전에 API 호출로부터 응답을 기다려야 한다. 이러한 비효율성은 일반적으로 각 추론 프로세스에 대해 여러 라운드의 API 호출이 필요할 때 다단계 추론 시나리오에서 더욱 중요해진다.\n' +
      '\n' +
      '각주 1: §5에서 분석을 통해 확인된 바와 같다.\n' +
      '\n' +
      '본 논문에서는 LLM이 도구를 이용하여 다단계 추론을 수행할 수 있는 강인하고 효율적인 방법인 **C**hain-**of-**A**bstraction **(CoA)** 추론을 제안한다. 그림 1에서 볼 수 있듯이 LLM은 추상적 자리 표시자와 추론 체인을 만드는 것을 목표로 미세 조정된다. 자리 표시자는 LLM의 추론 흐름에 영향을 미치지 않으며 후속적으로 최종 답변 세대를 분쇄하기 위해 특수 도구에서 검색된 특정 지식으로 채워진다. 추상적 추론 체인을 계획하는 것은 LLM이 여러 도구 호출을 상호 연결하고 보다 실현 가능한 추론 전략을 채택하도록 권장하며, 이는 각 추론 프로세스, 즉 특정 계산 결과에 관련된 도메인 지식의 변화에 강력한다. LLM 디코딩 및 API 호출이 인터리브 방식으로 실행되는 이전 방법과 달리, 본 방법은 추론 전체 체인이 생성된 후 지식 **온스**를 채우기 위해 도구를 활용한다. 이것은 다수의 예(_e.g._, 스트림에서와 같이)에 걸쳐 보다 효율적인 디코딩을 가능하게 하는데, 그 이유는 후속 예들에 대한 CoA 트레이스들이 선행하는 것에 대해 툴 호출들이 이루어지는 동안 디코딩될 수 있기 때문에, 전체 추론 시간을 상각한다. 우리는 CoA를 학습하기 위해 모델에 대한 미세 조정 데이터를 구축하기 위한 간단한 파이프라인을 개발하며, 여기서 먼저 LLM이 지침에 대한 기존 응답을 추상 체인으로 다시 작성하도록 프롬프트한 다음 도메인 도구를 사용하여 그림 2와 같이 재작성의 유효성을 확인한다.\n' +
      '\n' +
      'Cobbe 등(2021); Miao 등(2020); Patel 등(2021); Koncel-Kedziorski 등(2016) 및 Wikipedia 등(Wiki) QA Yang 등(2018); Berant 등(2013); Kwiatkowski 등(2019); Joshi 등(2017)은 사실적 기술지식에 대한 추론을 포함한다. 본 논문에서 제안한 방법은 수학 QA와 위키 QA에서 각각 평균 \\(\\sim\\)\\(7.5\\%\\)과 \\(4.5\\%\\)의 절대 정확도 향상으로 LLMs의 성능을 향상시킴을 보인다. 이러한 개선은 분포 내 및 (제로 샷) 분포 외 테스트 세트 모두에서 일관적이며 복잡한 사고 연쇄 추론이 필요한 질문에서 특히 두드러진다.2 한편, 본 방법은 수학 및 위키 QA 작업에서 각각 평균 \\(\\sim\\)\\(1.47\\times\\) 및 \\(1.33\\times\\) 더 빠른 추론 속도로 기존의 증강 방법보다 도구를 더 효율적으로 사용한다. 마지막으로, 본 논문에서 제안한 방법이 LLMs에게 보다 정확한 추론을 학습하도록 유도함으로써 추론 오류를 줄인다는 것을 증명한다.\n' +
      '\n' +
      '각주 2: _e.g._, 수학 유도의 3단계 이상\n' +
      '\n' +
      '##2 관련 업무\n' +
      '\n' +
      '도구 증강 LLMs 외부 도구를 사용하여 LLM을 증강하는 데 관심이 증가하고 있다. 상당한 연구가 문맥 내 학습을 통해 LLMs를 도구 사용 추론자로 적용하려고 시도했으며, 다양한 응용 분야에서 유망한 성능 향상을 보여주었다. 예를 들어, 수학 문제 해결 가오 등(2023); Chen 등(2022), 생물의학 문제 해결 Jin 등(2023) 및 자기 비판 Gou 등(2023). 그럼에도 불구하고, 상황 내 시연을 사용하여 LLM이 도구를 효과적으로 사용하도록 안내하는 것은 어려운 일이며, 이는 정교한 작업 특정 프롬프트 엔지니어링이 필요하며 모델의 지시 추종 능력 Jacovi 등(2023)에 의해 제한된다. 맥락 내 학습의 한계에 주목하여, 몇몇 작품들은 파리시 등(2022); Schick 등(2023); Hao 등(2023)을 미세 조정함으로써 도구들의 사용을 학습하도록 LLMs들을 가르치며, 이는 LLMs들의 성능을 더욱 강건하게 향상시킨다. 그러나 위의 모든 접근법은 추론 전반에 걸쳐 도구와의 순차적 상호 작용을 채택하여 도구(또는 API)의 지연 시간 및 수행되는 API 호출 수의 함수로서 추론 속도를 늦춘다.\n' +
      '\n' +
      '일부 다른 선행 연구는 다른 모듈과의 다단계 추론을 위해 LLM을 사용하는 데 중점을 둔다. 특히 ReAct Yao et al. (2023) 및 FireAct Chen et al. (2023)은 LLMs를 도구와 함께 사고, 행동 및 관찰 단계의 닫힌 루프에 통합한다. 이 장황한 추론 루프는 LLM 디코딩을 늦추고, 여전히 순차적 상호 작용을 통해 도구를 통합하여 비효율적인 추론을 초래한다. 또 다른 작업 라인인 PAL Gao et al. (2023) 및 Program of Thoughts Chen et al. (2022)는 LLMs에게 프로그램 기반 추론을 생성하고 코드 실행기들과 상호작용하도록 프롬프트하지만, 이는 폐쇄 소스 코딩 모델들 _i.e._, Codex Chen et al. (2021)에 크게 의존하며 프로 cedural 산술 추론에 제한된다. 본 연구에서는 특히 다단계 추론 시나리오에서 도구를 활용하기 위해 LLM을 위한 보다 일반적이고 효율적인 전략을 설계하는 것을 목표로 한다.\n' +
      '\n' +
      '도구 사용 계획 여러 이전 작업은 LLM의 도구 사용 계획을 연구한다. 구체적으로, HuggingGPT(Shen et al., 2023), Chameleon(Lu et al., 2023), OpenAGI(Ge et al., 2023) 및 MetaTool(Huang et al., 2023)은 멀티-도메인 혼합 태스크들을 다루기 위해 다중 툴들을 사용하는 하이-레벨 시퀀스를 계획하는 것에 초점을 맞춘다. 유사하게, LATM(Cai et al., 2023), ML-BENCH(Liu et al., 2023) 및 고릴라(Patil et al., 2023)는 절차적 태스크들의 스크립트들을 설계하기 위한 다수의 API들의 프로그램-레벨 통합을 계획하는 것을 목표로 하며, _e.g._, GitHub 리포지토리에 의해 기술된 모델을 트레이닝하기 위한 스크립트이다. ToolChain*(Zhuang et al., 2023)은 도구 사용의 계획과 트리 검색 기반 추론(Yao et al., 2023; Hao et al., 2023)을 결합하며, 이는 절차적 작업에 특히 유용하다(Xu et al., 2023; Cobbe et al., 2021). 위의 작업과는 달리, 우리는 도메인 특화 도구에 대한 인식을 가지고 일반적인 생각 사슬 추론(Wei et al., 2022)을 계획하는 데 중점을 둔다.\n' +
      '\n' +
      '## 3 Method\n' +
      '\n' +
      '추상 사슬 추론(CoA) 우리의 방법은 외부 도구에서 얻은 도메인 특정 지식에서 LLM의 일반적인 추론을 분리한다. 그림 1은 우리의 방법의 개요를 보여준다. 특히, 그림 1과 같이 추상적 장소 표시자(_e.g._, \\(y1\\), \\(y2\\), \\(y3\\), \\(y3\\), 3으로 추론 체인을 생성하기 위해 먼저 LLM을 미세 조정한다. 두 번째 단계에서는 장소 표시자를 외부 도구에서 얻은 도메인별 지식, _e.g._, 계산기에서 계산한 결과, 웹 검색 엔진에서 검색된 관련 기사 등으로 대체하여 각 추론 체인을 재조정한다. 마지막으로, 재화된 추론 체인을 기반으로 질문에 답한다.\n' +
      '\n' +
      '각주 3: 우리는 또한 단일 문자 형식인 _e.g._, \\(x\\), \\(y\\) 및 \\(z\\)으로 자리 표시자를 테스트하며, 이는 차선책 결과로 이어진다.\n' +
      '\n' +
      'LLM은 명시적 값을 갖는 정규 사상 연쇄(CoT) 추론 대신 추상적 추론 체인을 생성하도록 훈련되기 때문에 LLM은 모델의 매개변수에 대한 인스턴스 특정 지식을 생성할 필요 없이 일반적이고 총체적인 추론 전략을 학습하는 데 집중할 수 있다. 더욱이, 일반 추론 및 도메인-특정 지식을 디커플링하는 것은 LLM 디코딩이 (파이프라인을 통해) API 호출과 병행하여 상이한 샘플들 사이에서 진행 및 스위칭할 수 있게 하는데, _i.e._, LLM은 툴이 현재 체인을 채우는 동안 다음 추상 체인을 생성하기 시작할 수 있고, 이는 전체 추론 프로세스를 가속화한다.\n' +
      '\n' +
      'Cobbe et al., 2021; Miao et al., 2020; Yang et al., 2018) 및 LLMa-70B(Touvron et al., 2023)는 도 2에 도시된 바와 같이, 샘플링된 각 질문의 답변을 다시 작성하도록 프롬프트한다. 구체적으로, LLMa-70B에게 지식 연산에 해당하는 골드 답변에 스팬을 레이블링하도록 프롬프트한다(_e.g._, 수학 유도, Wikipedia 참조에 기반한 진술) 그리고 레이블링된 스팬을 채우기 가능한 CoA 트레이스로 문장들을 다시 작성하도록 프롬프트한다. 예를 들어, 도 2의 예에서 두 개의 파생어는 각각 "[\\(20+35=y1\\)]" 및 "[\\(90-y1=y2\\)]"으로 재작성된다.\n' +
      '\n' +
      '각주 4: 부록 C에서 CoA 데이터 재작성에 대한 몇 안 되는 프롬프트 예를 제공합니다.\n' +
      '\n' +
      '중간 결과는 재작성된 답변, _e.g._, 수학 계산 결과 \\(55\\)에서 여러 번 나타날 수 있음을 유의한다. LLMa를 프롬프트한다\n' +
      '\n' +
      '그림 2: 미세 조정 데이터 구축을 위한 골드 데이터 재작성 일러스트레이션. 도메인 질문(녹색 스크롤)과 골드 답변(노란색 스크롤) 쌍이 주어지면 LLM은 골드 답변을 추상 변수(보라색 버블)가 있는 추론 체인으로 다시 작성하라는 프롬프트가 표시됩니다. 그런 다음 도메인 전문 도구는 최종 답변(주황색 레이블)을 얻기 위해 추상 체인을 재수정할 수 있는지 여부를 확인하여 재작성의 정확성을 검증한다.\n' +
      '\n' +
      '70B는 동일한 중간 결과의 모든 발생을 동일한 자리 표시자로 대체함으로써, 다수의 추론 단계를 명시적으로 연결한다. 재작성된 데이터가 정확한지 확인하기 위해 도메인 전문 도구를 사용하여 각 CoA 추론 추적의 정확성을 검증한다.5 구체적으로, 도구를 사용하여 각 CoA에서 레이블이 지정된 작업을 실행하고 CoA에 유효한 결과를 채울 수 있는 질문만 도구에서 유지한다.\n' +
      '\n' +
      '각주 5: 추론 연쇄 검증의 상세한 구현은 Sec. 4.1 및 4.2에 설명되어 있다.\n' +
      '\n' +
      '##4 실험 설정\n' +
      '\n' +
      '우리는 수학적 추론과 사실적 기술지식에 대한 상식과 논리적 추론을 포함하는 위키피디아(Wiki) QA의 두 가지 대표적인 영역에 대한 실험을 수행한다.\n' +
      '\n' +
      '### Mathematical Reasoning\n' +
      '\n' +
      '수학 문제가 주어지면, QA 시스템은 (도 1의 왼쪽 열에서 증명된 바와 같이) 단계적 산술 도출로 문제에 대한 자연 언어 솔루션을 생성할 필요가 있다. 우리는 솔루션과 관련된 파생물이 이 도메인에서 필요한 전문 지식 연산이라고 가정하며, 파생 결과는 "\\([20+35=y1]\\)"과 같은 추상적 자리 표시자로 대체되는 대괄호로 표시된다.\n' +
      '\n' +
      'DatasetsWe constructed our fine-tuning CoA data most by re-writing the GSM8K Cobbe et al.(2021) training set, which contains 7473 languageistically diverse 초등학교 수학 문제를 포함하고 있다. GSM8K 데이터셋은 다단계 추론에 중점을 두고 있기 때문에 단일 단계 산술 문제에 대한 커버리지가 부족하므로 ASDiv Miao et al.(2020) 데이터셋으로부터 691개의 단일 단계 수학 문제의 추가 집합을 다시 작성한다. 이러한 재작성된 데이터 셋을 통해 LLaMa-70B에 의해 생성된 CoA 추론 트레이스의 \\(\\sim 76.6\\%\\)이 수식 풀이기(아래 설명)에 의해 검증됨을 알 수 있다. 표 1은 구축된 미세 조정 데이터의 추론 단계 분포(_i.e._, 파생 횟수)를 보여준다.\n' +
      '\n' +
      '배포 내 평가를 위해 1319 및 2305 테스트 문제를 포함하는 GSM8K 및 ASDiv에 대한 모델을 테스트한다. 모델의 일반화 능력을 추가로 테스트하기 위해 각각 1000개 및 2065개의 테스트 샘플을 포함하는 SVAMP Patel et al.(2021) 및 MAWPS Koncel-Kedziorski et al.(2016)을 포함한 다른 대표적인 수학 데이터 세트에 대해 제로 샷 평가를 수행한다.\n' +
      '\n' +
      '각주 6: MAWPS 벤치마크에 대해 AddSub, SingleEq, SingleOp 및 MultiArith 부분으로부터 각각 395, 508, 562 및 600개의 수학 문제에 대해 테스트한다.\n' +
      '\n' +
      '도메인 도구 우리는 수학 영역에서 필요한 산술적 미분을 수행하기 위해 방정식 풀이기를 사용한다. 우리의 방정식 해결자는 먼저 CoA 추론에 표시된 "\\([20+35=y1]\\)"과 "\\([90-y1=y2]\\)"의 유도체를 추출하고 모든 유도체를 방정식 체계로 결합한다. 그런 다음 연립방정식은 SymPy toolkit,7에 의해 풀어져 각 변수의 참값(_i.e._, 추상적 자리 표시자의 값)을 얻는다. 마지막으로, 우리의 방정식 해결자는 모든 변수를 풀어진 참값(답안 포함)으로 대체함으로써 재화된 추론 사슬을 반환한다.\n' +
      '\n' +
      '각주 7: [https://www.sympy.org/en/index.html](https://www.sympy.org/en/index.html)\n' +
      '\n' +
      '### Wikipedia QA\n' +
      '\n' +
      '위키피디아 지식에 기초한 질문이 주어지면, 모델은 먼저 질문과 관련된 참조로서 위키피디아 기사를 식별한 다음, (도 1의 오른쪽 열에 도시된 바와 같이) 질문에 답하기 위해 참조 기사의 핵심 지식에 대한 이유를 식별할 필요가 있다. 이 도메인에서 전문화된 지식 연산은 위키피디아 검색(WikiSearch)과 이름인식(NER)8 질의로 재작성되는 관련 위키피디아 기사와 중요 이름인문의 검색이라고 가정한다. 표 2는,\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c} \\hline \\hline \\multirow{2}{*}{**Source**} & \\multicolumn{5}{c}{**Reasoning Step**} \\\\ \\cline{2-7}  & 1 & 2 & 3 & 4 & 5 & \\(>\\)5 & All \\\\ \\hline GSM8K & 8 & 1540 & 1648 & 1164 & 666 & 553 & 5579 \\\\ ASDiv & 677 & 0 & 0 & 0 & 0 & 0 & 677 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 수학 영역에서 올바르게 재작성된 추론 체인의 추론 단계 분포.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l} \\hline \\hline\n' +
      '**Question** & The director of the romantic comedy “Big Stone Gap” is based in \\\\  & what New York city? \\\\ \\hline\n' +
      '**Answer** & Greenville Village \\\\ \\hline\n' +
      '**위키피디아** & 빅스톤 갭 (필름)\\textgreater{} Big Stone Gap is 2014 American romantic \\\\\\\n' +
      '**위키피디아** & 코미디 영화 Aditran Trigiani 감독 \\\\\n' +
      '**References** & Aditran Trigiani \\textgreater{} Aditran Trigiani is an Indian American film \\\\  & director based in Greenville Village. \\\\ \\hline\n' +
      '**Coa Trace** & Find the [direct of romantic comedy “Big Stone Gap” \\textgreater{} \\textgreater{} \\textgreater{} \\textgreater{}1]. The name of the films’ director is [\\(y1\\) -NER(person)\\textgreater{} \\textgreater{}2]. Then determine [\\(y2\\) in what New York city?-Wiki\\textgreater{} \\textgreater{}3]. \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 위키 QA 도메인에서 CoA 미세 조정 데이터 구축의 예.\n' +
      '\n' +
      '위키 QA.9에 대한 다시 작성된 CoA 추적\n' +
      '\n' +
      '각주 9: 우리는 부록 C에 위키 QA 답변 재작성의 더 프롬프트한 예들을 포함한다.\n' +
      '\n' +
      'DatasetsWe using the HotpotQA Yang et al.(2018) dataset to construct our fine-tuning CoA data in the Wiki QA domain. 핫팟 QA는 113K 멀티홉 QA 예제를 포함하며, 각각은 지원 지식을 제공하는 두 개의 위키피디아 기사들로 라벨링된다. 90447개의 훈련 QA 쌍 중 72991개를 **Bridge** QA 쌍으로 식별하여 질문에 대한 답변을 연결하려면 표 2와 같이 중간 개체를 식별해야 한다. 나머지 17456개는 **비교** QA 쌍으로 두 개체의 속성이 비교되는 _예: "Randal Kleiser and Kyle Schickner of the same nationality?"이다. 우리는 LLaMa-70B에게 이러한 훈련 QA를 위키서치 및 NER 쿼리가 있는 CoA에 다시 작성하도록 요청하고, 위키서치 쿼리에 의해 반환되는 모든 기사가 골드 문서의 제목 중 하나와 일치하는지 여부를 확인하여 도메인 도구(아래 설명)로 각 CoA를 확인한다. 마지막으로, 8956개의 Bridge QAs와 5405개의 Comparison QAs를 미세조정 데이터로 선정한다.10 위키 QA의 경우, 위키서치를 사용하여 CoA 데이터를 생성하기 위해 LLM을 훈련하는 것 외에도, 정확하게 재검증된 CoA 추론 추적에 기초하여 최종 금 답안을 생성하기 위해 두 번째 LLM을 미세조정한다.\n' +
      '\n' +
      '각주 10: 수학적 추론에 비해 위키 QA에 대한 CoA 데이터를 생성하려면 위키서치와 NER 모델을 결합한 더 복잡한 도구 사용이 필요하므로 재작성 성공률이 낮다(\\(\\sim 15.9\\%\\)).\n' +
      '\n' +
      '우리는 5918개의 브리지 QA 쌍과 1487개의 비교 QA 쌍을 포함하는 HotpotQA 개발 세트에 대한 모델을 평가한다. 수학적 추론 영역과 유사하게, 우리는 또한 2032, 3610 및 17944개의 테스트 질문을 포함하는 다른 오픈 도메인 QA 데이터 세트: WebQuestions (WQ; Berant et al., 2013), NaturalQuestions (NQ; Kwiatkowski et al., 2019) 및 TriviaQA Joshi et al. (2017)에 대해 제로 샷 평가를 수행한다.\n' +
      '\n' +
      '도메인 도구 위키 QA에 필요한 전문 도구는 참조 기사를 검색하는 위키피디아 검색 엔진과 다단계 검색 쿼리를 연결하는 개체를 추출하는 NER 툴킷을 포함한다. 우리는 Toolformer Schick 등(2023)을 따르고 BM25 Retriever Robertson 등(1995); Baeza-Yates 등(1999)은 KILT 벤치마크 Petroni 등(2021)으로부터 Wikipedia 덤프를 인덱싱하는 Wikipedia 검색 엔진을 구현한다. BM25 리트리버를 사용하여 입력된 질의와 관련된 상위 10개의 기사를 검색한 후 질문과 코사인 유사도를 임베딩한 Sentence-BERT Reimers와 Gurevych(2019)를 기반으로 기사 순위를 재조정한다. 재순위화 후 상위\\(1\\) 기사를 최종 검색 결과로 선정한다.\n' +
      '\n' +
      '우리는 명명된 개체를 추출하기 위해 NER 툴킷으로 SpaCy11(en_core_web_sm)을 사용한다. NER을 단순화하기 위해 표 3과 같이 수많은 SpaCy NER 유형을 6개의 일반 클래스로 집계한다. 다수의 명명된 엔티티가 인식되면, 인식된 각각의 엔티티를 후속 위키서치 질의에 입력하고, 후속 검색 결과가 질문과 가장 높은 Sentence-BERT 임베딩 코사인 유사성을 갖는 엔티티를 선택한다.\n' +
      '\n' +
      '각주 11: [https://spacy.io/models/en](https://spacy.io/models/en)\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      '우리는 7B 및 70B LLaMa 모델 모두에 **CoA** 추론 방법을 적용하고, LLaMa Touvron et al.(2023)의 첫 번째 버전과 보다 진보된 LLaMa-2 및 LLaMa-2-Chat Touvron et al.(2023)을 포함한 다양한 모델 버전을 테스트한다. 본 논문에서 제안하는 방법을 여러 개의 베이스라인들과 비교한다: a) 재작성되지 않은 원본(_i.e._, 재작성되지 않은) 사상체인의 데이터(**CoT-FSP**)로부터 무작위로 샘플링된 8개의 QA 예제를 사용한 수 샷 프롬핑, b) 사상체인의 데이터(**CoT-FT**)12로 미세 조정, c) CCNet Wenzek et al. (2020) 텍스트에서 API 호출로 증강된 LLMs를 미세 조정하는 **Toolformer**Schick et al. (2023). 위키 QA에 대한 평가를 위해, 우리는 또한 GPT-4 OpenAI, 2023에서 증류된 HotpotQA ReAct Yao 등(2022) 상의 LLMs를 미세 조정하는 **FireAct**Chen 등(2023)과 우리의 방법을 비교했다.\n' +
      '\n' +
      '각주 11: [https://spacy.io/models/en](https://spacy.io/models/en)\n' +
      '\n' +
      '##5 결과 및 분석\n' +
      '\n' +
      '### Mathematical Reasoning\n' +
      '\n' +
      '표 4는 GSM8K에 대한 LLaMa-2 및 LLaMa-2-Chat 모델에 대한 평가 결과를 나타낸다.13\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l} \\hline \\hline\n' +
      '**General Class** & **SpaCy NER Types included in each General Class** \\\\ \\hline \\begin{tabular}{l} person \\\\ group \\\\ location \\\\ culture \\\\ \\end{tabular} & \\begin{tabular}{l} PersON \\\\ NORP, ORG, LANGUAGE \\\\ GPE, FAC, LOC \\\\ EVENT, WORK\\_OF\\_ART, Law, PRODUCT \\\\ DATE, TIME \\\\ \\end{tabular} \\\\ \\begin{tabular}{l} numeral \\\\ \\end{tabular} &\n' +
      '\\begin{tabular}{l} CARDINAL, PERCENT, MONEY, QUANTITY, ORDINAL \\\\ \\end{tabular} \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: SpaCy NER 타입의 응집.\n' +
      '\n' +
      '그리고 ASDiv 데이터 세트, 우리의 추상화 체인(CoA) 방법은 소수의 기준선 방법 CoT-FSP 및 규칙적인 미세 조정 기준선 CoT-FT보다 우수하며, 도구 증강을 사용한 CoA 미세 조정이 LLM을 다단계 추론 작업에 적용하는 데 더 효과적임을 보여준다. 유사하게, SVAMP 및 MAWPS에서 평가할 때 CoA도 일관되게 CoT-FSP보다 우수하다. 흥미롭게도 이러한 유통 외 데이터 세트의 경우 CoT-FT는 특히 7B 모델의 경우 CoA에 더 뒤처져 CoA 추론이 더 분산적으로 강력한 추론 성능을 산출함을 보여준다.\n' +
      '\n' +
      '우리의 CoA 방법은 또한 도구 증강 기준 툴포머를 능가하며, 이는 CoA의 추상 변수를 계획하는 것이 도구를 사용한 추론의 정확도를 향상시킬 수 있음을 의미한다. 그러나, 툴포머가 원래 도메인 내 미세 조정 데이터로 훈련되지 않았기 때문에, 도 14는 또한 표 4의 **툴포머 - 수학**로 표시된 GSM8K 및 ASDiv의 사상 연쇄 데이터를 사용하여 새로운 버전의 툴포머를 미세 조정한다. 또한 CoA가 툴포머 - 수학보다 더 나은 성능을 보여 추상 변수의 도입이 사상 연쇄 추론 내에서 API 호출의 직접 통합에 비해 더 강력한 도구 사용을 가능하게 한다는 것을 확인한다.\n' +
      '\n' +
      '각주 14: 툴포머는 풍부한 수학적 추론 샘플을 포함하지 않을 수 있는 CCNet 데이터에 대해 미세 조정된다.\n' +
      '\n' +
      '절제 연구 표 4에서 **CoA(도구 없음)**로 표시된 방정식 해결자를 호출하는 대신 방정식 해결을 수행하기 위해 다른 LLM(동일한 모델 백본에서)을 미세 조정함으로써 CoA 추론의 견고성이 추가 도구를 사용하는 데만 도움이 되지 않는다는 것을 검증한다. CoA(도구 없음)는 모든 데이터 세트에서 CoA보다 일관되게 더 나쁜 성능을 나타냄을 발견하여 특수 도구를 사용하면 LLM 에이전트가 동일한 작업을 직접 해결하는 것이 아니라 더 정확한 작업을 수행할 수 있음을 확인한다. 그러나 CoA(no Tool)가 여전히 SVAMP 및 MAWPS 데이터 세트에 대한 제로 샷 일반화에 대한 모든 기본 방법을 능가한다는 것을 발견했으며, 이는 추상화 연쇄 추론이 아마도 추상 변수에 의해 인덱싱된 여러 추론 단계의 더 나은 계획으로 인해 CoA의 더 나은 견고성에 기여함을 의미한다.\n' +
      '\n' +
      '추론 단계 우리의 연구 결과는 문제가 긴 추론 체인을 해결해야 할 때 추상화 추론의 이점이 가장 두드러진다는 것을 시사한다. 그림 3은 예측 및 금 추론 체인의 추론 단계 수에 대한 GSM8K QA에서 세 가지 모델의 계층화된 성능을 보여준다. 소샷 CoT-FSP와 비교하여 CoA는 열-맵 통계(왼쪽 열)가 대각선(CoT-FT와 비교 가능) 주위에 더 많이 집계됨에 의해 반영되는 바와 같이 금 추론 체인의 길이와 더 자주 일치하는 추론 체인을 생성한다. 동시에, 생성된 답변에서 추론 단계의 수가 금 참조(_i.e._, 오른쪽 열의 열 지도의 대각선)와 정렬될 때 모델이 더 나은 QA 정확도를 달성한다는 것을 관찰한다. 위의 모든 결과는 미세 조정 모델이 추론 체인을 생성하는 데 더 잘 학습한다는 것을 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Model**} & \\multirow{2}{*}{**Method**} & \\multirow{2}{*}{**GSM8K**} & \\multirow{2}{*}{**ASDiv**} & \\multirow{2}{*}{**SVAMP**} & \\multicolumn{5}{c}{**MAWPS**} \\\\ \\cline{5-10}  & & & & & **AddSub** & & **SingleEQ** & **SingleOp** & **MultiArith** & **All** \\\\ \\hline \\multirow{3}{*}{**LLaMa-2**} & CoT-FSP & 16.38 & 47.85 & 38.40 & 52.41 & 63.39 & 82.03 & 43.33 & 60.53 \\\\  & CoT-FT & 35.33 & 57.18 & 48.20 & 66.08 & 74.41 & 85.23 & 65.00 & 73.03 \\\\ \\multirow{3}{*}{**-7B**} & Toolformer & 17.59 & 48.55 & 37.10 & 47.34 & 58.46 & 79.54 & 50.67 & 59.81 \\\\  & CoA & **37.83** & **57.61** & **51.70** & **72.15** & **82.48** & **86.48** & **73.17** & **78.89** \\\\ \\hline \\multirow{3}{*}{**LLaMa-2**} & CoT-FSP & 24.03 & 54.14 & 51.30 & 71.90 & 72.44 & 85.41 & 74.00 & 76.32 \\\\  & CoT-FT & 35.41 & 59.00 & 46.90 & 58.23 & 72.24 & 85.41 & 73.00 & 73.37 \\\\ \\multirow{3}{*}{**LLaMa-2**} & Toolformer & 23.65 & 50.85 & 48.80 & 61.01 & 69.09 & 81.85 & 68.50 & 70.85 \\\\  & Toolformer - Math & 36.01 & 59.18 & 47.60 & 58.99 & 72.44 & 85.94 & 75.50 & 74.43 \\\\ \\multirow{3}{*}{**-Chat-7B**} & CoA & 38.29 & **59.57** & **54.20** & **72.41** & **81.89** & **88.26** & 83.00 & **82.13** \\\\  & CoA (no Tool) & 35.03 & 58.79 & 51.50 & 68.10 & 74.21 & 86.48 & 77.67 & 77.38 \\\\ \\hline \\multirow{3}{*}{**LLaMa-2**} & CoT-FSP & 56.18 & 65.94 & 70.60 & 86.08 & 89.17 & 92.88 & 84.50 & 88.23 \\\\  & CoT-FT & 60.50 & 70.24 & 70.40 & 81.52 & 87.60 & 92.35 & 89.17 & 88.18 \\\\ \\multirow{3}{*}{**-Chat-70B**} & Toolformer & 52.54 & 69.07 & **73.60** & **86.84** & 89.76 & 91.46 & 81.50 & 87.26 \\\\ \\cline{1-1}  & Toolformer - Math & 61.03 & 70.59 & 73.20 & 85.57 & 91.34 & 91.99 & 92.00 & 90.60 \\\\ \\multirow{3}{*}{CoA} & CoA & **62.32** & **71.89** & 73.40 & 86.33 & **94.49** & **93.06** & **92.33** & **91.91** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 수학적 추론을 위한 LLaMa-2 및 LLaMa-2-Chat에 대한 평가 결과. "모두"는 4개의 MAWPS 부분에 대한 평균 결과를 나타낸다. 최종 금 답변에 대한 정확한 일치율(_i.e._, 정확도)이 보고된다. 각 기본 모델에 대한 최상의 성능 증대 접근법은 **볼드**입니다.\n' +
      '\n' +
      '그 문제에 대한 진정한 추론 체인을 일치시키다.\n' +
      '\n' +
      '흥미롭게도, 우리는 CoT-FT에 비해 CoA가 특히 더 많은 추론 단계가 필요한 질문에서 더 높은 성능을 달성한다는 것을 발견했다. 그림 3의 오른쪽 열에서 CoT의 CoT-FT에 대한 개선은 금추론 사슬에서 \\(3\\) 단계 이상의 질문(빨간 사각형 강조)에서 더 두드러진다. 또한 표 5에서 다양한 수의 금 추론 단계에 따라 GSM8K 하위 집합에 대한 전반적인 정확도 점수를 제시하며, 여기서 이 결과를 확인함으로써 CoA로 훈련된 모델이 추상화를 사용하여 학습에서 계획까지 가능한 더 강력한 긴 생각 연쇄 추론 능력을 가지고 있음을 나타낸다.\n' +
      '\n' +
      '인간 평가 CoA가 지식 연산(도구 사용에 의한 연산)과 추론 정확도를 모두 향상시킨다는 것을 보다 종합적으로 검증하기 위해 무작위로 샘플링된 200개의 GSM8K 테스트 질문에 대해 서로 다른 모델 답변에 대해 인간 평가를 수행한다. 구체적으로, GSM8K 질문과 그 질문에 대한 모델의 답이 주어지면, 우리는 인간 작업자들에게 그 대답에 산술 오류(_e.g._, 잘못된 계산, 무효 방정식)가 포함되어 있는지 또는 수학 파생과 무관한 추론 오류(_e.g._, 질문의 오해, 질문 해결을 위한 부적절한 전략)가 포함되어 있는지 여부를 판단하고, 모델이 얼마나 자주 이 두 가지 종류의 오류를 만드는지 보고한다. 표 6에서 우리는 CoA가 정확한 계산을 수행하기 위해 방정식 풀이기를 사용하기 때문에 산술 오류를 효과적으로 0으로 줄인다는 것을 발견했다. 더 중요한 것은, 우리의 방법은 또한 기준선에 비해 추론 오류를 적게 만들어 CoA 미세 조정이 추상적 추론 사슬의 전체론적 계획을 통해 모델이 더 정확한 추론을 학습하도록 유도한다는 것을 검증한다. 대조적으로, 일반적인 미세 조정(_i.e._, CoT-FT)은 소수의 샷 CoT-FSP에 비해 더 제한된 추론 개선을 생성하는 동시에 산술 오류를 억제하지 못한다.\n' +
      '\n' +
      '추론 효율성 중요한 것은 CoA 추론의 성능 이점이 계산 비용 증가와 함께 제공되지 않는다는 것이다. 그림 4에서 CoA와 기준 에이전트(LLaMa-2-Chat-7B로 시드됨)가 다양한 수의 금 추론 단계에 대한 질문에 답해야 하는 평균 시간(초)을 보여준다. CoT 기준선과 비교하여 CoA는 추가 예에 따라 생성을 조정해야 하는 소수의 기준선 CoT-FSP보다 시간이 덜 필요하다. 그러나, CoA는 CoT-FT에 비해 약간 덜 추론-효율적이며, 이는 추상적 진술들에 대한 추가적인 토큰들(_e.g._, "[" 및 "]")의 디코딩으로 인해 발생할 가능성이 있다.\n' +
      '\n' +
      'CoA는 툴포머에 비해 낮고\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline \\hline \\multirow{2}{*}{**Method**} & \\multicolumn{2}{c}{**Error Rate**} \\\\ \\cline{2-3}  & Arithmetic & Reasoning \\\\ \\hline CoT-FSP & 17.3 & 70.3 \\\\ CoT-FT & 25.2 & 67.8 \\\\ \\hline CoA & **0.0** & **60.4** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 200개의 GSM8K 테스트 샘플에 대한 산술 및 추론 오류율의 인간 평가 결과. LLaMa-2-Chat-7B를 기반으로 개발된 모델을 제시한다.\n' +
      '\n' +
      '그림 3: 예측 및 금 추론 체인의 추론 단계 수 LLaMa-2-Chat-7B _w.r.t._에 대한 세립 GSM8K 평가 결과. (왼쪽) 각 지층에 속하는 시험예들의 총 개수. (Right) 해당 예들에 대한 해당 모델 정확도(%). 15개 미만의 예시들을 갖는 비-대각선 셀들은 무시된다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline \\multirow{2}{*}{**Method**} & \\multicolumn{4}{c}{**Gold Reasoning Step**} \\\\ \\cline{2-6}  & \\(\\leq 2\\) & \\(3\\) & \\(4\\) & \\(5\\) & \\(>5\\) \\\\ \\hline CoT-FSP & 42.9 & 26.3 & 18.0 & 10.9 & 3.6 \\\\ CoT-FT & 55.5 & 42.6 & 25.8 & 19.0 & 10.8 \\\\ \\hline \\multirow{2}{*}{CoA} & **55.8** & **44.4** & **32.5** & **25.3** & **15.1** \\\\  & +0.3 & +1.8 & +6.7 & +6.3 & +4.3 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 금 추론 단계가 상이한 GSM8K에 대한 계층화된 LLaMa-2-Chat-7B 평가 결과. 마지막 행은 미세 조정 기준 CoT-FT와 비교하여 CoA 방법의 절대 정확도 향상을 보고한다.\n' +
      '\n' +
      '평평한 추론 시간 곡선은 추론 단계의 수가 증가함에 따라 더 나은 스케일링을 나타낸다. 이러한 차이는 CoA가 지식의 검색(_i.e._, 툴 사용)으로부터 (추상적인) 추론 체인의 생성을 분리함으로써, 임의의 툴이 호출되기 전에 완전한 추론 체인이 디코딩될 수 있게 하기 때문에 발생한다. 이 절차는 추론 비용을 두 가지 방법으로 상각합니다. 먼저, CoA 트레이스가 디코딩된 후에 툴 호출이 이루어지며, 동일한 트레이스에 대한 병렬 툴 호출(_e.g._, 계산기에 대한 다수의 호출이 아닌 방정식 솔버를 한 번 사용하여)을 가능하게 하고, 외부 API 응답을 대기함으로써 야기되는 시간 지연을 회피한다. 결과적으로, CoA로 미세 조정된 모델은 특히 추론 단계(_i.e._, 툴 호출)의 수가 증가할 때 다단계 추론에서 더 효율적이다. 둘째, 다수의 예시들에 걸쳐, 모델은 다음 예시의 CoA 트레이스를 생성할 수 있는 한편, 선행하는 것에 대해 툴 호출들이 이루어지고, 예시들에 걸쳐 CoA 디코딩 및 툴 호출들을 병렬화한다.\n' +
      '\n' +
      '### Wiki QA\n' +
      '\n' +
      '표 7은 LLaMa-2-Chat 모델을 사용한 위키 QA 평가 결과를 보여준다.15 수학적 추론과 유사하게 **툴포머 - 위키**로 표시된 핫팟QA의 도메인 내 생각 사슬 데이터로 새로운 버전의 툴포머를 미세 조정한다. 핫팟QA에서 CoA는 소수의 샷 또는 미세 조정 기준선에 비해 골드 참조와 더 높은 정확한 일치율을 달성한다. 특히, CoA는 보다 도전적인 브리지형 QA에서 CoT-FSP, CoT-FT, Toolformer 및 Toolformer-Wiki를 능가하는데, 여기서 Wikipedia 지식에 대한 추론의 두 단계가 비교형 QA와 같이 _consecutively_ 얽힘, _i.e._로 독립적으로 병렬적으로 수행될 수 없다. CoA는 FireAct 미세 조정에 비해 폐쇄 소스 GPT-4에서 증류된 데이터를 요구하지 않고 브리지 및 비교 QA 모두에서 더 나은 성능을 달성한다.\n' +
      '\n' +
      '각주 15: 부록 B에 LLaMa-2-7B에 대한 유사한 평가 결과를 포함한다.\n' +
      '\n' +
      '수학적 추론과 마찬가지로 CoA 에이전트는 HotpotQA 질문에 답할 때 Toolformer 및 FireAct 에이전트보다 더 효율적인 추론을 수행한다. 또한 CoA는 추가 입력으로서 소수의 샷 예가 필요하지 않고 생성할 필요가 없기 때문에 CoA가 CoT-FSP 및 CoT-FT 둘 다보다 더 효율적(**시간** 열)임을 발견했다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Model**} & \\multirow{2}{*}{**Method**} & \\multicolumn{5}{c}{**HotpotQA**} & \\multirow{2}{*}{**WQ**} & \\multirow{2}{*}{**NQ**} & \\multirow{2}{*}{**TriviaQA**} \\\\ \\cline{3-3} \\cline{6-9}  & & & **Bridge** & & & **Comparison** & & **Both** & **Time** \\\\ \\hline \\multirow{4}{*}{**LLaMa-2**} & CoT-FSP & 11.69 & 45.46 & 18.47 & 2.074 & 34.65 & 30.91 & 53.48 \\\\  & CoT-FT & 14.24 & 56.69 & 22.77 & 1.937 & 33.51 & 25.40 & 51.05 \\\\  & Toolformer & 12.99 & 44.59 & 20.00 & 2.350 & 36.22 & 30.22 & 54.15 \\\\\n' +
      '**-Chat-7B** & Toolformer - Wiki & 15.68 & 56.42 & 23.86 & 2.301 & **36.61** & 32.96 & 55.08 \\\\  & FireAct & 19.18 & 54.14 & 26.20 & 2.706 & 36.02 & 35.87 & 52.96 \\\\  & CoA & **21.00** & **56.96** & **28.22** & **1.896** & 35.97 & **38.67** & **57.90** \\\\ \\hline \\multirow{4}{*}{**LLaMa-2**} & CoT-FSP & 21.39 & 56.62 & 28.47 & 6.668 & 34.89 & 37.42 & 63.61 \\\\  & CoT-FT & 23.84 & 63.95 & 31.90 & 6.401 & 34.15 & 39.75 & 62.28 \\\\\n' +
      '**-Chat-70B** & Toolformer & 22.24 & 56.09 & 29.04 & 6.888 & 37.16 & 40.42 & 64.31 \\\\  & Toolformer - Wiki & 26.38 & 63.82 & 33.90 & 6.855 & **37.70** & 41.25 & 66.64 \\\\  & CoA & **27.61** & **64.09** & **34.94** & **6.369** & 36.37 & **43.57** & **69.08** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: LLaMa-2-Chat 기반 모델에 대한 위키 QA 평가 결과. "둘 다"는 HotpotQA의 브리지 및 비교 부분 모두에 대한 전체 평가 결과를 나타낸다. "시간"은 핫팟QA에서 각 에이전트가 질문에 답해야 하는 평균 초를 나타낸다. 최종 금 답변에 대한 정확한 일치율(_i.e._, 정확도)이 보고된다.\n' +
      '\n' +
      '도 4: GSM8K(LLaMa-2-Chat-7B로 시드됨) 상의 벽-시계 추론 시간. 질문에 응답하는 평균 시간은 질문에 필요한 골드 추론 단계의 수 _w.r.t.를 측정한다.\n' +
      '\n' +
      '위키피디아 검색 엔진에서 제공하는 긴 위키 기사를 삭제합니다. 마지막으로, CoA는 다른 위키 QA 데이터 세트에 대한 제로 샷 일반화 실험에서 기준선 방법에 비해 개선되며, NaturalQuestions 및 TriviaQA에서 모든 기준선을 능가하고 웹Questions에서 최상의 기준선을 일치시킨다.\n' +
      '\n' +
      '## 6 Conclusion\n' +
      '\n' +
      '본 연구에서는 LLM 에이전트의 일반적인 추론 능력을 외부 도구를 통해 전문화된 지식을 실행하는 것으로부터 분리할 것을 제안한다. 우리의 방법인 추상화 연쇄(CoA)는 LLM이 분산 외 지식 이동에 더 강력한 추상적 다단계 추론의 계획을 배우도록 권장한다. CoA는 또한 도구 증강 다단계 추론의 속도를 크게 향상시키는 도구 사용을 위한 보다 효율적인 파이프라인을 달성한다. 두 가지 다양한 작업(_i.e. 수학적 추론 및 개방형 도메인 QA)에 대한 간단하면서도 효과적인 본 방법의 구현은 새로운 추론 시나리오에 적응할 수 있는 가능성을 보여준다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* A. M. Dai, O. 피라트 존슨, D. 레피킨, A. 파소스, S. 샤케리, E. 타로파, P. 베일리, Z. Chen, et al. (2023)Palm 2 기술 보고서. ArXiv:2305.10403. 인용: SS1.\n' +
      '*R. Baeza-Yates, B. Ribeiro-Neto, et al.(1999)Modern information retrieval. Vol. 463, pp.. 외부 링크: ISSN 1073-030, 문서, 인용 링크: SS1.\n' +
      '* J. Berant, A. Chou, R. Frostig와 P. Liang(2013)은 질문-답변 쌍으로부터 자유베이스에 대한 시맨틱 파싱이다. In Proceedings of the 2013 conference on empirical methods in natural language processing, pp. 1533-1544. Cited by: SS1.\n' +
      '*T. 카이영 왕태 마진 Chen과 D. Zhou(2023)는 도구 제작자로서 대형 언어 모델이다. ArXiv:2305.17126. 인용: SS1.\n' +
      '* B. Chen, C. Shu, E. Sharegli, N. 콜리어 나라심한, S. 야오(2023)Fireact: 언어 에이전트 미세 조정을 위한 것. ArXiv:2310.05915. 인용: SS1.\n' +
      '* M. 천진욱 Wuan, H. Ponde de Oliveira Pinto, J. Kaplan, H. Edwards, Y. 부르다 Joseph, G. Brockman, et al.(2021)Evalating large language models trained on code. ArXiv:2107.03374. 인용: SS1.\n' +
      '*W. 천진 마진 Wang and W. W. Cohen (2022)Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. ArXiv:2211.12588. 인용: SS1.\n' +
      '*H.W.정룡 허승 롱프레, B. 조프, Y 테이원 페더스 리진 왕민 데하니, S. Brahma, et al.(2022)Scaling instruction-finetuned language models. ArXiv:2210.11416. 인용: SS1.\n' +
      '*K. 코비, V 고사라주 바이에른 M. 천현정카즈 플래퍼트, J 트워렉, J 힐튼, R. Nakano, et al.(2021)Training verifiers to solve math word problems. ArXiv:2110.14168. 인용: SS1.\n' +
      '* L. 가오아마단 저우우 알론유 Yang, J. Callan, and G. Neubig(2023)Pal: program-aided language models. In International Conference on Machine Learning, pp. 10764-10799. Cited by: SS1.\n' +
      '*Y. 지욱 화종지 Xu, Y. Zhang(2023)Openagi: llm이 도메인 전문가를 만날 때. ArXiv:2304.04370. 인용: SS1.\n' +
      '*Z. 고지 샤오영 공영 심영 양남 두안, W. 첸(2023) 비판: 큰 언어 모델은 도구 상호 작용 비평으로 스스로 수정할 수 있다. ArXiv:2305.11738. 인용: SS1.\n' +
      '* S. 하용 구현마 왕동진, 왕동진, 지동진 Hu (2023) Reasoning with language model is planning with world model. ArXiv:2305.14992. 인용: SS1.\n' +
      '* S. 하태 류종 왕과 Z Hu(2023)ToolKengPT: 도구 임베딩을 통해 거대한 도구로 냉동 언어 모델을 증강한다. ArXiv:2305.11554. 인용: SS1.\n' +
      '*Y. 황정시 이창환 우규 장영 류필주 완남 Zhenqiang Gong, et al. (2023)Metatool 벤치마크: 툴 사용 여부 및 어느 것을 사용할 것인지를 결정한다. ArXiv:2310.03128. 인용: SS1.\n' +
      '* A. Jacovi, A. Caciularu, J. Herzig, R. 아하로니, B. 보넷, M. Geva(2023) 도구 지원 생성 전략에 대한 포괄적인 평가. In Findings of the Association for Computational Linguistics: EMNLP 2023, pp. 13856-13878. Cited by: SS1.\n' +
      '*Z. 지남 이락 감자튀김, T 유동수 Xu, E. Ishii, Y. J. Bang, A. Madotto, and P. Fung(2023)의 자연언어 세대 환각에 대한 조사. ACM Computing Surveys55, pp. 1-38. Cited by: SS1.\n' +
      '*차오진, 이판양, 칭유천, 지용루. 2023. Genepgt: 생물 의학 정보에 대한 접근성을 향상시키기 위해 도메인 도구들로 대형 언어 모델들을 증강시킨다.\n' +
      '* Joshi et al.(2017) Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. 2017. Triviaqa: 읽기 이해를 위한 대규모 원거리 감독 챌린지 데이터세트. _Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 1601-1611.\n' +
      '* Koncel-Kedziorski et al. (2016) Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016. Mawps: 수학 단어 문제 저장소. _Proceedings of the 2016 in the north American chapter of the association for computational linguistics: Human language technologies_, pages 1152-1157.\n' +
      '* Kwiatkowski et al. (2019) Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. 2019. Natural questions: question answer research의 벤치마크. _ The Association for Computational Linguistics_, 7:452-466의 트랜잭션.\n' +
      '* Liu et al. (2023) Yuliang Liu, Xiangru Tang, Zefan Cai, Junjie Lu, Yichi Zhang, Yanjun Shao, Zexuan Deng, Helan Hu, Zengxian Yang, Kaikai An, et al. 2023. Mlbench: Large language models leverage open-source libraries for machine learning tasks. _ arXiv preprint arXiv:2311.09835_.\n' +
      '* Loshchilov and Hutter (2018) Ilya Loshchilov and Frank Hutter. 2018. Decoupled weight decay regularization. _International Conference on Learning Representations_.\n' +
      '* Lu et al. (2023) Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, 및 Jianfeng Gao. 2023. 카멜레온: 큰 언어 모델을 가진 플러그 앤 플레이 구성 추론 _ arXiv preprint arXiv:2304.09842_.\n' +
      '* Maynez et al. (2020) Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. 추상적 요약에서 충실성과 사실성에 관한 것이다. _Proceedings of the 58th Annual Meeting of the Computational Linguistics_, pages 1906-1919.\n' +
      '* Miao et al. (2020) Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2020. 영어 수학 단어 문제 해결기를 평가하고 개발하기 위한 다양한 말뭉치. _Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics_, pages 975-984.\n' +
      '* OpenAI(2023) OpenAI. 2023. Gpt-4 기술 보고서\n' +
      '* Parisi et al. (2022) Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022. Talm : 도구 증강 언어 모델 _ arXiv preprint arXiv:2205.12255_.\n' +
      '* Patel et al. (2021) Arkil Patel, Satwik Bhattacharya, and Navin Goyal. 2021. nlp 모델이 정말 간단한 수학 단어 문제를 해결할 수 있나요? _Proceedings of the 2021 Conference of the North American chapter of Computational Linguistics Association: Human Language Technologies_, pages 2080-2094.\n' +
      '* Patil et al. (2023) Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. 2023. 고릴라: massive apis와 연결된 대용량 언어 모델 _ arXiv preprint arXiv:2305.15334_.\n' +
      '* Petroni et al. (2021) Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, et al. 2021. Kilt: 지식 집약적 언어 작업에 대한 벤치마크. _Proceedings of the 2021 Conference of the North American chapter of Computational Linguistics Association: Human Language Technologies_, pages 2523-2544.\n' +
      '* Reimers and Gurevych (2019) Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: siamese bert-networks를 이용한 Sentence embedding. _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pages 3982-3992.\n' +
      '* Robertson et al. (1995) Stephen E Robertson, Steve Walker, Susan Jones, Micheline M Hancock-Beaulieu, Mike Gatford, et al. 1995. Okapi at trec-3. _Nist Special Publication Sp_, 109:109.\n' +
      '* Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. 툴포머: 언어 모델들은 스스로 툴을 사용하는 것을 가르칠 수 있다. _ arXiv preprint arXiv:2302.04761_.\n' +
      '* Shen et al. (2023) Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023. Hugging-gpt: ai task with chatgpt and its friends in huggingface. _ arXiv preprint arXiv:2303.17580_.\n' +
      '* Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. 개방적이고 효율적인 기초 언어 모델 arXiv preprint arXiv:2302.13971_.\n' +
      '* Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajwal Bhargava, Shruti Bhosale, et al. 2023b. 라마 2: 오픈 파운데이션 및 미세 조정 채팅 모델들_ arXiv preprint arXiv:2307.09288_.\n' +
      '* Wang et al. (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. 자기일관성은 언어 모델에서 사고 추론의 사슬을 향상시킨다. _The Eleventh International Conference on Learning Representations_.\n' +
      '* Wei et al. (2021) Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language models is zero-shot learners. _ arXiv preprint arXiv:2109.01652_.\n' +
      '\n' +
      'Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou et al. 2022. Chain-of-thought prompting reasoning in large language models. _ 신경 정보 처리 시스템_, 35:24824-24837의 발전.\n' +
      '* Wenzek et al. (2020) Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzman, Armand Joulin, and Edouard Grave. 2020. Ccnet: 웹 크롤 데이터에서 고품질 단일 언어 데이터 세트를 추출한다. _Proceedings of the Twelfth Language Resources and Evaluation Conference_, pages 4003-4012.\n' +
      '* Xu et al.(2023) Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, Jian Zhang. 2023. 오픈 소스 대형 언어 모델의 툴 조작 능력. _ arXiv preprint arXiv:2305.16504_.\n' +
      '* Yang et al. (2018) Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D Manning. 2018. Hotpotqa: 다양하고 설명 가능한 멀티홉 질문 응답을 위한 데이터셋. [Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing_] 컴퓨터 언어학과의 연관성\n' +
      '* Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. 2023a. 생각의 나무: 큰 언어 모델을 사용하여 문제를 해결합니다. _ arXiv preprint arXiv:2305.10601_.\n' +
      '* Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. 반응: 추론과 언어 모델에서의 연기의 시너지 효과 _ arXiv preprint arXiv:2210.03629_.\n' +
      '* Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023b. 반응: 추론과 언어 모델에서의 행동을 동기화하는 것.\n' +
      '* Zhuang et al. (2023) Yuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor Bursztyn, Ryan A Rossi, Somdeb Sarkhel, and Chao Zhang. 2023. 툴체인*: a* 검색을 갖는 대형 언어 모델에서의 효율적인 액션 스페이스 네비게이션_ arXiv preprint arXiv:2310.13227_.\n' +
      '\n' +
      '## 부록 구현 세부사항\n' +
      '\n' +
      '수학적 추론 평가를 위한 평가 세부 사항은 각 모델의 답변에 나타난 마지막 숫자를 추출하고, 그 숫자가 gold reference와 정확히 일치하는지 확인한다. 정확도는 테스트 세트의 모든 QA에 걸쳐 이러한 정확한 일치율로 보고된다. 위키 QA 평가는 수학적 추론과 유사하게 각 모델의 최종 답을 추출하고 금 참조에 대한 정확한 일치율을 계산한다. 구체적으로, 최종 답변은 "Action: finish[\' for FireAct baseline", "The answer is the other model"의 경우 "The answer" 이후의 단어로 되어 있다. CoT-FSP 기준선에 사용된 8샷 도메인 내 예는 표 13 및 14에 나와 있으며, 이는 모델이 "답변" 후 최종 답변을 명시하는 평가에 필요한 형식인 _i.e._로 답변을 제공할 수 있도록 한다. GSM8K에 대한 인간 평가는 연구 그룹의 5명의 내부 도메인 전문가가 수행한다. 각 수학 문제에 대해, 우리는 전문가들에게 금 답안을 참조로 제공하고, 각 모델 답안을 익명으로 평가하도록 요청하는데, 즉, 전문가들은 각 답이 어떤 모델로부터 왔는지 모른다. 각 모델 답변을 평가하기 위해 두 개의 예 또는 아니오 질문이 요청되는데, a) 정답에 산술 오류가 있는지 여부, b) 정답에 추론 오류가 있는지 여부, 전문가로부터 이진 선택을 수집하여 각 모델 생성의 오류율을 계산한다. 우리는 인간 평가에 대한 자세한 지침을 그림 5에 제시한다.\n' +
      '\n' +
      '모델 트레이닝은 워밍업 단계(10\\)의 코사인 학습률 스케줄러를 사용하여 7B 및 70B 모델 크기에 대해 배치 크기(8\\)와 학습률(2e^{-5}\\) 및 학습률(1e^{-5}\\)으로 모델을 미세 조정한다. 모든 미세조정 실험은 AdamW(Loshchilov and Hutter, 2018) 최적화기를 사용하였으며, 각각 \\(\\beta_{1}\\), \\(\\beta_{2}\\) 및 \\(\\epsilon\\)을 \\(0.9\\), \\(0.95\\) 및 \\(1e^{-8}\\으로 설정하였다. 훈련 중량 감쇠는 \\(0.1\\)으로 설정된다. 수학적 추론을 위해 총 400\\(400\\)의 훈련 단계를 사용하고, 7B 및 70B 모델 크기에 대해 단계 \\(240\\) 및 단계 \\(200\\)에서 가장 좋은 모델 체크포인트(검증 점수가 가장 높음)를 얻는다. 위키 QA 도메인의 경우, 전체 학습 단계를 \\(500\\)으로 조정하고, 7B 및 70B 모델에 대해 \\(450\\) 및 \\(300\\) 단계에서 최상의 체크포인트를 얻는다. 따라서 수학 및 위키 QA 영역에서 모델을 미세 조정하기 위해서는 실제로 \\(\\sim\\)2K 및 \\(\\sim\\)3K QA만 필요하다. 7B 및 70B 모델의 훈련은 각각 8 및 64 NVIDIA A100-SXM4(80GB) GPU를 기반으로 한다.\n' +
      '\n' +
      '## 부록 B 전체 실험 결과\n' +
      '\n' +
      '표 9와 10은 수학 및 위키 QA 도메인에 대한 실험의 전체 결과를 보여준다. 우리의 CoA 방법은 다양한 LLaMa 모델 버전(LLaMa, LLaMa-2 및 LLaMa-2-Chat), 모델 크기(7B 및 70B) 및 도메인 벤치마크에 걸쳐 기준선보다 일관된 개선을 달성한다. 이것은 우리의 방법이 새로운 모델 백본 및 추론 작업으로 일반화될 수 있는 큰 잠재력을 보여준다.\n' +
      '\n' +
      '수학적 추론 영역에서 미세 조정 데이터 균형도 중요도를 검증한다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:12]\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Model**} & \\multirow{2}{*}{**Method**} & \\multicolumn{4}{c}{**HotpotQA**} & \\multicolumn{2}{c}{**NebQ.**} & \\multicolumn{2}{c}{**NaturalQ.**} & \\multicolumn{2}{c}{**TriviaQA**} \\\\ \\cline{3-8}  & & **Bridge** & **Comparison** & **All** & & & & \\\\ \\hline \\multirow{4}{*}{**LLaMa-2-7B**} & CoT-FSP & 14.43 & 45.26 & 20.62 & 33.96 & 33.35 & 56.95 \\\\  & CoT-FT & 14.85 & 57.36 & 23.39 & 31.50 & 26.93 & 52.32 \\\\  & Toolformer & 14.12 & 42.76 & 20.35 & **37.11** & 34.49 & 57.79 \\\\  & CoA & **22.00** & **57.43** & **29.12** & 34.60 & **38.28** & **58.28** \\\\ \\hline \\multirow{4}{*}{**LLaMa-2-Chat-7B**} & CoT-FSP & 11.69 & 45.46 & 18.47 & 34.65 & 30.91 & 53.48 \\\\  & CoT-FT & 14.24 & 56.69 & 22.77 & 33.51 & 25.40 & 51.05 \\\\ \\cline{1-1}  & Toolformer & 12.99 & 44.59 & 20.00 & 36.22 & 30.22 & 54.15 \\\\ \\cline{1-1}  & Toolformer - Wiki & 15.68 & 56.42 & 23.86 & **36.61** & 32.96 & 55.08 \\\\ \\cline{1-1}  & FireAct & 19.18 & 54.14 & 26.20 & 36.02 & 35.87 & 52.96 \\\\ \\cline{1-1}  & CoA & **21.00** & **56.96** & **28.22** & 35.97 & **38.67** & **57.90** \\\\ \\hline \\multirow{4}{*}{**LLaMa-2-Chat-70B**} & CoT-FSP & 21.39 & 56.62 & 28.47 & 34.89 & 37.42 & 63.61 \\\\  & CoT-FT & 23.84 & 63.95 & 31.90 & 34.15 & 39.75 & 62.28 \\\\ \\cline{1-1}  & Toolformer & 22.24 & 56.09 & 29.04 & 37.16 & 40.42 & 64.31 \\\\ \\cline{1-1}  & Toolformer - Wiki & 26.38 & 63.82 & 33.90 & **37.70** & 41.25 & 66.64 \\\\ \\cline{1-1}  & CoA & **27.61** & **64.09** & **34.94** & 36.37 & **43.57** & **69.08** \\\\ \\hline GPT-J & Toolformer & - & - & - & 26.3 & 17.7 & 48.8 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 10: 위키 QA 평가 결과.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c c c c c c c} \\hline \\hline \\multirow{2}{*}{**Model**} & \\multirow{2}{*}{**Method**} & \\multicolumn{2}{c}{**GSM8K**} & \\multirow{2}{*}{**ASDiv**} & \\multicolumn{2}{c}{**SVAMP**} & \\multicolumn{4}{c}{**MAWPS**} \\\\ \\cline{4-9}  & & & & & **AddSub** & **SingleEQ** & **SingleOp** & **MultiArith** & **All** \\\\ \\hline \\multirow{4}{*}{**LLaMa-7B**} & CoT-FSP & 11.90 & 44.69 & 31.80 & 56.20 & 59.65 & 70.28 & 43.00 & 57.05 \\\\  & CoT-FT & 30.71 & 53.19 & 42.30 & 55.70 & 69.09 & 77.05 & 54.17 & 64.36 \\\\  & CoA & **35.71** & **56.36** & **51.10** & **67.59** & **80.51** & **85.94** & **68.33** & **75.98** \\\\ \\hline \\multirow{4}{*}{**LLaMa-2-7B**} & CoT-FSP & 16.38 & 47.85 & 38.40 & 52.41 & 63.39 & 82.03 & 43.33 & 60.53 \\\\  & CoT-FT & 35.33 & 57.18 & 48.20 & 66.08 & 74.41 & 85.23 & 65.00 & 73.03 \\\\  & Toplformer & 17.59 & 48.55 & 37.10 & 47.34 & 58.46 & 79.54 & 50.67 & 59.81 \\\\  & CoA & **37.83** & **57.61** & **51.70** & **72.15** & **82.48** & **86.48** & 73.17 & **78.89** \\\\ \\hline \\multirow{4}{*}{**LLaMa-7B**} & CoT-FSP & 24.03 & 54.14 & 51.30 & 71.90 & 72.44 & 85.41 & 74.00 & 76.32 \\\\  & CoT-FT & 35.41 & 59.00 & 46.90 & 58.23 & 72.24 & 85.41 & 73.00 & 73.37 \\\\  & CoT-FT (no ASDiv) & 36.19 & 44.93 & 35.30 & 38.48 & 52.95 & 61.21 & 77.67 & 59.61 \\\\  & Toplformer & 23.65 & 50.85 & 48.80 & 61.01 & 69.09 & 81.85 & 68.50 & 70.85 \\\\  & Toplformer - Math & 36.01 & 59.18 & 47.60 & 58.99 & 72.44 & 85.94 & 75.50 & 74.43 \\\\  & CoA & 38.29 & **59.57** & **54.20** & **72.41** & **81.89** & **88.26** & 83.00 & **82.13** \\\\  & CoA (no ASDiv) & **39.73** & 54.19 & 44.40 & 54.18 & 73.62 & 73.49 & **85.33** & 73.27 \\\\  & CoA (no Tool) & 35.03 & 58.79 & 51.50 & 68.10 & 74.21 & 86.48 & 77.67 & 77.38 \\\\ \\hline \\multirow{4}{*}{**LLaMa-2-Chat-70B**} & CoT-FSP & 56.18 & 65.94 & 70.60 & 86.08 & 89.17 & 92.88 & 84.50 & 88.23 \\\\  & CoT-FT & 60.50 & 70.24 & 70.40 & 81.52 & 87.60 & 92.35 & 89.17 & 88.18 \\\\ \\cline{1-1}  & Toplformer & 52.54 & 69.07 & **73.60** & **86.84** & 89.76 & 91.46 & 81.50 & 87.26 \\\\ \\cline{1-1}  & Toplformer - Math & 61.03 & 70.59 & 73.20 & 85.57 & 91.34 & 91.99 & 92.00 & 90.60 \\\\ \\cline{1-1}  & CoA & **62.32** & **71.89** & 73.40 & 86.33 & **94.49** & **93.06** & **92.33** & **91.91** \\\\ \\hline\n' +
      '**GPT-J** & Toolformer & - & 40.4 & 29.4 & - & - & - & - & 44.0 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 9: 수학적 추론 평가 결과.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:14]\n' +
      '\n' +
      '프리츠 폰 브로도스키는 1939년부터 1945년까지 지속된 세계 전쟁 중에 사망했습니다\n' +
      '\n' +
      '대답은 제2차 세계대전입니다\n' +
      '\n' +
      'Fritz von Brodowski > Friedrich Wilhelm Konrad von Brodowski는 2차 세계대전 중 프랑스 구류 중에 논란이 되어 살해되었다.\n' +
      '\n' +
      '**C**: [프리츠 폰 브로도스키가 살해된 전쟁-위키-> y1]을 찾아라.\n' +
      '\n' +
      '헨리 레콘테와 조나단 스타크 중 어느 테니스 선수가 그랜드 슬램 타이틀을 더 획득했는가?\n' +
      '\n' +
      '대답은 조나단 스타크\n' +
      '\n' +
      '1984년 프랑스오픈 남자 복식 우승을 차지한 앙리 레콘트, 조나단 스타크(테니스)가 그랜드슬램 복식 2개 우승을 차지했다.\n' +
      '\n' +
      '**C**: 먼저 [앙리 레콘테가 우승한 그랜드 슬램 타이틀 수 - 위키 -> y1]을 식별합니다. 그런 다음 [조나단 스타크가 우승한 그랜드 슬램 타이틀 수 - 위키 -> y2]를 알아봅니다.\n' +
      '\n' +
      '로맨틱 코미디 "빅 스톤 갭"의 감독이 뉴욕의 어떤 도시에 기반을 두고 있나요?\n' +
      '\n' +
      '답은 그리니치 빌리지에요\n' +
      '\n' +
      '**W**: Big Stone Gap(영화)>Big Stone Gap은 Adriana Trigiani가 감독한 2014년 미국 로맨틱 코미디 영화이다. 아드리아나 트리기아니 > 아드리아나 트리기아니는 그리니치 빌리지에 본사를 둔 이탈리아계 미국인 영화감독이다.\n' +
      '\n' +
      '**C**: [로맨틱 코미디 "Big Stone Gap"의 감독 - 위키-> y1]을 먼저 검색합니다. 이 영화의 감독의 이름은 [y1 - NER(사람)-> y2]이다. 그런 다음 [뉴욕 시에서 y2 - 위키 -> y3]를 결정합니다.\n' +
      '\n' +
      'Randal Kleiser와 Kyle Schickner는 같은 국적의 사람인가?\n' +
      '\n' +
      '대답은 \'네\'야\n' +
      '\n' +
      '**W** : Randal Kleiser > John Randal Kleiser (1946년 7월 20일 출생)는 미국의 영화감독이자 프로듀서이다. 카일 쉬크너>카일 쉬크너는 미국 영화 제작자, 작가, 감독, 배우입니다.\n' +
      '\n' +
      '**C**: 먼저 [랜들 클라이저의 국적 - 위키-> y1]을 알아봅니다. 그런 다음 [카일 쉬크너의 국적 - 위키-> y2]를 파악합니다.\n' +
      '\n' +
      '**Q**: 엑스트라는 영국 코미디언, 배우, 작가, 프로듀서, 감독, 가수, 음악가인 리키 데네 게르베스가 만들어 쓰고 연출했다.\n' +
      '\n' +
      '대답은 1961년 6월 25일\n' +
      '\n' +
      '**W**: Ricky Gervais > Ricky Dene Gervais (1961년 6월 25일 출생)는 영국 코미디언, 배우, 작가, 프로듀서, 감독, 가수, 음악가이다.\n' +
      '\n' +
      '**C**: 검색[리키 데니 게르베스가 태어났을 때 - 위키-> y1].\n' +
      '\n' +
      '사미라 페레라는 인도 공화국의 남동쪽과 매디브의 북동쪽에 위치한 섬나라의 크리켓 선수입니다\n' +
      '\n' +
      '대답은 스리랑카야\n' +
      '\n' +
      '**W** : Sameera Perera > Sameera Perera (1988년 8월 20일 출생)는 스리랑카 크리켓이다.\n' +
      '\n' +
      '**C**: [크리켓 사메라 페레라가 -위키-> y1에서 온 나라]를 식별합니다.\n' +
      '\n' +
      '"진화"의 크레딧을 가진 어떤 시나리오 작가가 니콜라스 케이지와 티 레오니가 출연한 영화를 공동 집필했는가?\n' +
      '\n' +
      '데이비드 와이즈먼입니다\n' +
      '\n' +
      '**W**: The Family Man > The Family Man은 니콜라스 케이지와 티 레오니가 출연하는 2000 미국 로맨틱 코미디 드라마 영화이다. 데이비드 와이즈먼 > 그의 영화 크레딧에는 "가족의 남자"(2000), "진화"(2001), "로마에 있을 때"(2010)가 포함됩니다.\n' +
      '\n' +
      '**C**: [니콜라스 케이지와 티레오니의 영화 - 위키-> y1]을 먼저 알아보세요. 이 영화의 이름은 [y1 - NER(culture)-> y2]이다. 그리고 나서 [누가 "진화"에 대한 학점으로 y2를 썼는지 알아보세요 - 위키 -> y3.\n' +
      '\n' +
      '랄프 헤퍼닌은 어느 도시에 위치한 대학의 심리학 교수였다.\n' +
      '\n' +
      '대답은 뉴욕입니다\n' +
      '\n' +
      '**W**: 랄프 헤퍼닌 > 랄프 프랭클린 헤퍼닌은 컬럼비아 대학의 심리학 교수였다. 컬럼비아 대학 > 컬럼비아 대학은 뉴욕시 어퍼 맨해튼에 있는 사립 아이비리그 연구 대학이다.\n' +
      '\n' +
      'C**: 먼저 [심리학과 교수 랄프 헤퍼닌-위키-> y1]을 식별합니다. 이 교수의 대학은 [y1-NER(그룹)->y2]이다. 그런 다음 [y2가 어느 도시에 있는지 -위키->y3]를 파악합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l} \\hline\n' +
      'Fritz von Brodowski는 1939년부터 1945년까지 지속된 어떤 세계 전쟁 중에 살해되었는가?\n' +
      '대답은 제2차 세계대전입니다\n' +
      '**W**: Fritz von Brodowski > Friedrich Wilhelm Konrad von Brodowski는 2차 세계대전 중 프랑스 구치소에서 논란이 되어 살해되었다. \\\\\n' +
      '**C**: [프리츠 폰 브로도스키가 살해된 전쟁-위키-> y1]을 찾아라. \\\\\n' +
      'Q**: 어떤 테니스 선수가 그랜드 슬램 타이틀을 더 획득했는가, 앙리 레콘트인가 조나단 스타크인가? \\\\\n' +
      '대답은 조나단 스타크\n' +
      '1984년 프랑스 오픈 남자 복식 우승을 차지한 앙리 레콘트 조나단 스타크(테니스)\n' +
      '**C**: 먼저 [앙리 레콘테가 우승한 그랜드 슬램 타이틀 수 - 위키 -> y1]을 식별합니다. 그런 다음 [조나단 스타크가 우승한 그랜드 슬램 타이틀의 수 - 위키 -> y2]를 알아봅니다.\n' +
      '**Q**: 로맨틱 코미디 "Big Stone Gap"의 감독은 뉴욕의 어느 도시에 기반을 두고 있나요? \\\\\n' +
      '답은 그리니치 빌리지에요\n' +
      '**W**: Big Stone Gap(영화)>Big Stone Gap은 Adriana Trigiani가 감독한 2014년 미국 로맨틱 코미디 영화이다. 아드리아나 트리기아니 > 아드리아나 트리기아니는 그리니치 빌리지에 기반을 둔 이탈리아계 미국인 영화감독이다. \\\\\n' +
      '**C**: 먼저 [로맨틱 코미디 “빅 스톤 갭”의 감독 - 위키-> y1]을 검색하세요. 이 영화의 감독의 이름은 [y1 - NER(사람)-> y2]이다. 그런 다음 [뉴욕 시에서 y2 - 위키 -> y3]를 결정합니다. \\\\\n' +
      '**Q**: Randal Kleiser와 Kyle Schickner가 같은 국적의 사람인가? \\\\\n' +
      '대답은 \'예스\'야\n' +
      '**W** : Randal Kleiser > John Randal Kleiser (1946년 7월 20일 출생)는 미국의 영화감독이자 프로듀서이다. 카일 쉬크너 > 카일 쉬크너는 미국 영화 제작자, 작가, 감독, 배우입니다. \\\\\n' +
      '**C**: 먼저 [랜들 클라이저의 국적 - 위키-> y1]을 알아봅니다. 그런 다음 [카일 쉬크너의 국적 - 위키 -> y2]를 파악합니다. \\\\\n' +
      '**Q**: 엑스트라는 영국 코미디언, 배우, 작가, 프로듀서, 감독, 가수, 뮤지션인 리키 데네 거비스가 만들어 쓰고, 연출했다.\n' +
      '대답은 1961년 6월 25일\n' +
      '**W** : Ricky Gervais > Ricky Dene Gervais (1961년 6월 25일 출생)는 영국 코미디언, 배우, 작가, 프로듀서, 감독, 가수, 음악가이다. \\\\\n' +
      '**C**: 검색 [Ricky Dene Gervais가 태어났을 때 -Wiki-> y1]\n' +
      '사미라 페레라는 인도 공화국의 남동쪽과 매디브의 북동쪽에 위치한 어느 섬나라의 크리켓 선수입니까?\n' +
      '답은 스리랑카야\n' +
      '**W** : Sameera Perera > Sameera Perera (1988년 8월 20일생)는 스리랑카 크리켓이다. \\\\\n' +
      '**C**: [크리켓 사메라 페레라가 -위키->y1에서 온 나라]를 식별하라. \\\\\n' +
      '**Q**: "Evolution"의 크레딧을 가진 어떤 시나리오 작가가 니콜라스 케이지와 티 레오니가 출연한 영화를 공동 집필했는가? \\\\\n' +
      '답은 데이빗 와이즈먼입니다\n' +
      '**W**: The Family Man > The Family Man은 니콜라스 케이지와 티 레오니가 출연하는 2000 미국 로맨틱 코미디 드라마 영화이다. 데이비드 와이즈먼 > 그의 영화 크레딧에는 “The Family Man” (2000), “Evolution” (2001), “When in Rome” (2010). \\\\\n' +
      '**C**: [니콜라스 케이지와 티레오니의 영화 - 위키-> y1]을 먼저 알아보세요. 이 영화의 이름은 [y1 - NER(culture)-> y2]이다. 그런 다음 [진화학 학점으로 y2를 쓴 사람] - 위키-> y3을 알아봅니다. \\\\\n' +
      'Ralph Heffernine은 어느 도시에 위치한 대학의 심리학 교수였다. \\\\\n' +
      '답은 뉴욕시입니다\n' +
      '**W**: 랄프 헤퍼닌 > 랄프 프랭클린 헤퍼닌은 컬럼비아 대학의 심리학 교수였다. 컬럼비아 대학 > 컬럼비아 대학은 뉴욕 맨해튼 어퍼 맨해튼에 있는 사립 아이비리그 연구 대학이다. \\\\\n' +
      '**C**: First identify the [university of psychology professor Ralph Heffernine -Wiki-> y1]. The university of this professor is [y1 -NER(group)-> y2]. Then figure out [y2 is in what city -Wiki-> y3]. \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 12: 위키 QA 도메인에서의 미세 조정 데이터 구축을 위한 프롬프트 예. 질문(Q), 금답(A) 및 이를 지원하는 위키피디아 기사(W)가 주어지면, LLaMa-70B는 위키피디아 검색 및 NER 질의를 갖는 추상 추론 체인(C)을 생성하도록 프롬프트된다. 이를 바탕으로 먼저 LLM을 학습하여 질의의 추상체인을 생성한 후, 도메인 도구(_i.e.e._, Wikipedia 검색 엔진 및 NER 툴킷)로 질의를 실행한다. 마지막으로, 제2 LLM은 재화된 추론 체인에서 위키피디아 검색 결과(중간 NER 결과 제외)를 기반으로 최종 답변을 생성하도록 훈련된다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:16]\n' +
      '\n' +
      '이 과제에서는 중학교 수학 문제(**Question**)와 그 표준 해법으로 금 참조 답(**Gold_Answer**)을 부여받는다. 또한 우리의 Al 모델 A, B, C 및 D에 의해 생성된 4개의 후보 답변(**Answer_A/B/C/D**)이 있으며, 당신의 과제는 각각의 후보 답변에 오류가 있는지를 판단하는 것이다.\n' +
      '\n' +
      '주석에서 **2** 유형의 오류(아래 정의)에 대해 각 후보 답변에 대해 **"예" 또는 **"아니오"**의 이진 선택 선택을 수행합니다. 왜냐하면 4개의 후보 답변과 2개의 오류 유형이 있기 때문이다. 각 질문에 대해 **는 총 8개의 이진 선택**을 하게 됩니다.\n' +
      '\n' +
      '구체적으로, 우리는 **2가지 유형의 오류를 고려한다**: 1) **산술 오류; 2) 추론 오류**\n' +
      '\n' +
      '1. 정답에 **산술 오류가 있는지 여부?** 즉, 수학 미분이 잘못 계산되거나 수학 방정식이 성립하지 않는다. 예 또는 아니오를 선택합니다. 예를 들어:\n' +
      '\n' +
      '해적 선원들이 지도에 X자로 표시된 섬에 묻힌 보물을 파헤치고 있습니다 이들은 첫날 10홀, 둘째 날 13홀, 셋째 날 8홀을 팠다. 그들은 3일째 되는 날 일찌감치 파기를 멈추고 해적들이 계속 빠져들었던 두 개의 구멍을 메웠다. 이 섬에는 지금 몇 개의 구멍이 있나요?\n' +
      '\n' +
      '첫날 해적들이 10개의 구멍을 팠습니다 둘째 날, 그들은 13개의 구멍을 팠습니다. 셋째 날에는 8개의 홀을 파서 2개의 홀에 채워 10+13+8-2=27개의 홀이 있다. 답은 27\n' +
      '\n' +
      '**분석**: 예, 정답은 산술 오류가 있으며, 여기서 10 + 13 + 8 - 2는 29이어야 합니다.\n' +
      '\n' +
      '2. 정답에 **추리 오류가 있는지?** 즉, 질문에 대한 오인인지 또는 잘못된 문제 해결 전략을 가지고 있는지 여부는 산술적 정확성과 무관하다. 예 또는 아니오를 선택합니다. 예를 들어:\n' +
      '\n' +
      '마커스는 레오 나이의 절반이고 디에나보다 5살 어려 디애나는 26살이에요 리오는 몇 살이죠?\n' +
      '\n' +
      '마커스는 레오 나이의 절반이야 그래서 마커스는 26/2 = 13살이다. Leo는 13+5=18세이다. 정답은 18\n' +
      '\n' +
      '**분석**: 예, 답변에 추론 오류가 있습니다. 레오는 (26 - 5) * 2 = 42세여야 합니다.\n' +
      '\n' +
      '**Notes**:\n' +
      '\n' +
      '1. 모든 질문과 답변에서 문법이나 철자 오타를 용서해 주세요, 수학 풀이 오류로 간주되지 않습니다.\n' +
      '\n' +
      '2. 금 참조 답변(Gold_Answer)이 틀렸다고 느끼면 그냥 무시하고 자신의 질문에 대한 답변을 토대로 판단을 한다.\n' +
      '\n' +
      '그림 5: GSM8K 수학적 추론에 대한 인간 평가 지침.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>