<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '[MISSING_PAGE_FAIL:1]\n' +
      '\n' +
      '수정할 메쉬, 텍스트 프롬프트를 제공하고 업데이트된 영역을 환각합니다(도 1 참조). 우리가 입증했듯이, 우리의 하이브리드 표현은 제어에 대한 기여 외에도 다양한 이전을 두 표현에 보다 직관적으로 배치할 수 있기 때문에 계산 노력과 전반적인 기하학적 품질에도 도움이 된다.\n' +
      '\n' +
      '하이브리드 접근법의 핵심 기술적 과제는 두 표현을 효율적으로 동기화시키는 것이다. 이를 위해 다양한 각도에서 두 표현을 차별적으로 렌더링하고 RGB 렌더, 불투명도 및 정규 맵에서 일관성을 요구한다. 또한, 더 높은 해상도와 더 빠른 속도로 SDF를 렌더링하기 위해 인싱크 메쉬 표현에 의존하며, 광선당 수백 개의 샘플 대신 메쉬 표면 주위에 SDF 샘플링을 국한하고 최소 3개의 샘플을 사용한다. 비판적으로, 메시를 일관되고 안정적으로 진화하는 것은 추가적인 과제이다. 해상도의 측면에서 거친 메쉬는 새로운 세부 사항에 충분히 표현되지 않으며 미세한 메쉬는 비싸고 불안정하다. 따라서 필요한 모양과 함께 진화하는 적응형 테셀레이션이 필요하다. 우리는 얼굴 분할, 에지 붕괴 및 에지 플립을 포함하는 동적 메쉬 토폴로지 업데이트를 달성하기 위해 미분 가능한 메쉬 재구성(Barda et al., 2023)에서의 최근의 발전에 의존한다. 메쉬의 토폴로지의 변화에도 불구하고 메쉬를 텍스쳐링하기 위해, 우리는 삼각형 수퍼샘플링을 기반으로 하는 새로운 전략에 기여한다. 중요한 것은 이 레이어를 사용하여 최적화 전반에 걸쳐 메쉬 특성을 유지할 수 있다는 것이다.\n' +
      '\n' +
      '우리가 증명한 바와 같이, 우리의 하이브리드 접근법은 국부적이고 순차적인 메쉬 편집 동작을 허용하여, 한편으로는 메쉬 토폴로지와 정보를 보존하는 반면, 다른 한편으로는 급진적이고 의미론적 진화를 허용한다. 또한, 두 표상이 서로에게 부과한 전적 덕분에 전체적으로 더 높은 생성 기하 품질을 보여준다. 하이브리드 접근법과 조각 도구는 두 선도 표현의 장점이 어떻게 결합될 수 있는지를 보여준다. 본질적으로, 우리의 프레임워크는 신경 형태 생성의 최근 및 미래의 돌파구를 예술 워크플로우에 더 가깝게 제공하며, 여기서 작업은 점진적인 단계에 있으며, 예술가는 최종 결과에 대한 정확성과 통제를 제공하지만 전례 없는 표현력을 제공한다.\n' +
      '\n' +
      '##2. 관련업무\n' +
      '\n' +
      '**3D 생성 모델.** 그들의 seminal work, DreamFusion, pool et al.(Poole et al., 2022)은 Text-to-Image 확산 모델이 Score Distillation Sampling(SDS)을 통해 Neural Radiance Field(NeRF)를 최적화하기 위한 그라디언트를 제공하는데 사용될 수 있음을 보여준다. Magic3D(Lin et al., 2023)는 두 단계 접근법을 사용함으로써 더 나은 품질을 달성한다: 첫 번째 단계는 DreamFusion과 유사하며, 그들은 생성된 객체의 품질이 고해상도 이미지에 대한 체적 렌더링을 수행하는 높은 비용에 의해 제한된다는 것을 주목한다. 두 번째 단계는 미분 가능한 메쉬 표현을 사용하여 생성된 객체를 더욱 미세하게 하는데, 이는 메쉬를 고해상도로 미분 가능하게 렌더링하는 것이 시간과 메모리 모두에서 상당히 저렴하기 때문이다. Magic123(Qian et al., 2023)은 3d 및 2d 확산 프리어를 모두 사용함으로써 Magic3d에 대해 더욱 개선된다. ProlificDreamer (Wang et al., 2023)는 2d 확산 사전으로부터 3D 생성을 유도하기 위해 VSD 손실인 SDS에 대한 개선을 제안한다. Fantasia3d(Chen et al., 2023) 및 TextMesh(Tsalicoglou et al., 2023)는 NeRF를 SDF로 대체하고, 컬러 네트워크를 별도로 최적화하여 기하학으로부터 외관을 분리한다. TextDeformer(Gao et al., 2023)는 텍스트 프롬프트에 따라 메쉬들을 변형시키기 위해 메쉬 자코비안들에 기초한 새로운 그래디언트 스무딩 기술과 함께 CLIP를 이전으로서 사용한다.\n' +
      '\n' +
      'Magic3D(Lin et al., 2023)에서 두 단계를 사용하는 선택은 3D 생성 모델에 대한 올바른 3D 표현을 선택하는 것과 관련된 절충점을 강조한다. 암시적 함수는 토폴로지 업데이트를 허용하기 때문에 거친 생성에 매우 적합하지만 메쉬는 높은 해상도에서 매우 효율적으로 래스터화되어 두 번째 단계에서 미세한 세부 정보를 얻을 수 있다. 그러나 2단 파이프라인은 국부적으로 최소가 되기 쉽고 결정적으로 미리 계산된 UV가 있는 기존 메쉬를 편집하기 위해 확장할 수 없다. 이와는 대조적으로, 기존의 메쉬로부터 초기화될 수 있고 최적화 동안 모든 특성을 유지할 수 있는 하이브리드 SDF 및 메쉬 표현을 공동으로 최적화하여, _1-단계 파이프라인_: SDF 부분으로부터의 토폴로지 업데이트 및 메쉬 부분으로부터의 미세한 세부사항에서 양 세계의 최상의 이점을 얻는다.\n' +
      '\n' +
      '로컬 편집에 집중..___로컬 편집에 집중..__로컬 편집에 집중..__로컬 편집에 집중 Vox-E(Sella et al., 2023)는 SDS를 통해 복셀 그리드를 편집하고 주의 레이어를 사용하여 국부적인 편집을 장려한다. 그러나 로컬리제이션 메커니즘이 부드러운 주의를 기반으로 하기 때문에 편집이 어디에서 발생할지 보장할 수 없다.\n' +
      '\n' +
      '_Concurrent work:_ DreamCraft3D(Sun et al., 2023)는 DreamBooth(Ruiz et al., 2022)를 이용하여 생성 과정 중 확산 모델을 미세 조정함으로써 최근의 SDS 작업들을 기반으로 구축한다. 참고로, Instant3D(Li et al., 2023)는 비용이 많이 드는 최적화를 요구하지 않고, 단일 순방향 패스에서 3D 형상을 생성한다. 우리가 제시하는 조각 애플리케이션과 유사한 지역 예술적 통제를 허용하지 않지만, 우리는 향후 우리의 방법을 가속화하기 위해 이 연구 방향의 아이디어를 활용하게 되어 흥분된다.\n' +
      '\n' +
      '**Hybrid Representations.** 이미지의 경우 2D에 존재하는 것처럼 3D에는 유비쿼터스 표현이 없으므로 여러 표현들이 존재하고 다양한 3D 작업을 위해 결합되어 왔다. 많은 표현과 조합은 모든 것에 맞는 해결책이 없다는 것을 보여준다. 본 연구에서는 생성 모델링에 특화된 하이브리드 표현을 소개하고, 관련 작업을 본 논문과 가장 관련이 있는 잡종에 집중한다. Poursaeed et al.(Poursaeed et al., 2020)은 3D 손실에 의해 동기화된 상태로 유지되는 생성적 3D 모델링을 위해 암시적 및 명시적 표면 표현의 커플링을 사용한다. NerfMeshing(Rakotosona et al., 2023)은 NeRFs를 위한 개선된 메쉬링 파이프라인을 제안한다. (Poursaeed et al., 2020)과 대조적으로, 커플링은 커플링된 정규화 손실을 통해 달성되지 않고, SDF로부터 메시로의 투영 층들에 의해 명시적으로 강제된다. 마지막으로, DmTeT(Shen et al., 2021)는 고해상도 3D Shape 합성을 위한 하이브리드 표현으로서 Deep Marching Tetrahedra를 제안하며, 특히 동시 작업 Magic3D(Lin et al., 2023)에 사용된다. 우리의 방법은 SDF와 메쉬 부분을 동기화하기 위해 ROAR(Barda et al., 2023)에 기반한 동적 프로젝션 레이어뿐만 아니라 정규화 손실의 세트를 모두 사용한다.\n' +
      '\n' +
      '**스컬프팅 메쉬를 위한 전통적인 접근법.** 많은 상업적 도구들은 Zbrush(Zbrush, 2024), Mudbox(Autodesk, 2024), 또는 Substance-Modeler(SubstanceModeler, 2024)와 같은 3D 모델링을 위한 디지털 스컬프팅 메타포를 사용한다. 이러한 워크플로우에 의해 동기화된 기하학 처리 연구는 메쉬 변형(Jacobson et al., 2014), 컷 앤 페이스트를 위한 메쉬 블렌딩(Biermann et al., 2002), 표면 상세를 추가하기 위한 로컬 파라미터화(Schmidt et al., 2006), 대칭 유도 자동 완성(Peng et al., 2018), 협력 편집을 위한 버전 제어(Salvati et al., 2015)와 같은 상호 작용 기술을 개선하는 데 중점을 두었다. 이러한 발전에도 불구하고 3D 모델링은 전문가에게만 접근할 수 있어야 한다. 대안으로서, 부품들로부터 새로운 형상들을 조립하기 위해 스톡 3D 모델들의 데이터베이스로부터 기존의 기하학을 사용함으로써 3D 모델링 툴들을 민주화하기 위한 예시적인 기반 접근법들이 제안되었다(Funkhouser et al., 2004). 이후의 방법들은 부품 어셈블리들을 통해 통계 모델들을 구축하였고(Kalogerakis et al., 2012), 변형에 대한 높은 수준의 의미 제어를 허용한다(Yumer et al., 2015). 접근성에도 불구하고 이러한 도구는 종종 도메인에서 제한되며 종종 스톡 자산의 무거운 주석에 의존하므로 전문 모델러에 의해 제한된 사용을 받았다. 본 논문에서는 사전 주석이 달린 3D 스톡 데이터의 필요 없이 로컬 및 반복 모델링 워크플로우에 대한 의미 제어를 가능하게 하기 전에 사전 훈련된 2D 생성 데이터를 활용한다.\n' +
      '\n' +
      '## 3. Method\n' +
      '\n' +
      '메쉬, 사용자-하이라이트된 표면 영역, 및 원하는 타겟을 기술하는 텍스트 프롬프트가 주어지면, 매직클레이는 결과적인 메쉬가 타겟과 일치하도록 선택된 영역의 형상을 최적화한다. 형상 최적화를 추진하기 위해 현재 문헌을 따르고 텍스트 조건 2D 확산에 활용하고 형상 최적화를 안내하기 위해 미분 가능한 렌더링과 함께 SDS(Score Distillation Sampling) 기법(Poole et al., 2022)을 사용한다. 그러나 이 접근법은 메쉬에서 작동할 때 잘 작동하지 않는다. 메쉬는 희박하고 불규칙한 샘플(수직)에 의해 구동되며, 이들의 연결성은 자기 교차 및 플립오버를 피하면서 안정적이고 매끄러운 변형을 요구한다. 이러한 이유로 메쉬 형상 최적화 및 토폴로지 업데이트를 위해 신경 부호 거리 필드(Neural Signed Distance Field, SDF)를 사용한다. 따라서 본 논문에서는 Signed Distance Field(SDF)와 지표면을 모두 포착하여 두 세계의 장점을 얻을 수 있는 하이브리드 표현을 제안한다. SDF는 더 큰 규모의 복잡한 변화를 향해 형상을 안내하는 것을 허용하지만, 메쉬는 미세한 세부 사항을 캡처하고 사용자 강조 표면 영역에 대한 제어를 로컬화할 수 있게 한다.\n' +
      '\n' +
      '이 섹션에서는 하이브리드 SDF/Mesh 표현(Sec. 3.1), SDS 안내로 효율적으로 최적화될 수 있는 방법(Sec. 3.2), 표면 및 체적 사전의 효과적인 사용 방법(Sec. 3.3), 최적화 동안 메쉬 토폴로지를 업데이트하는 방법(Sec. 3.4)에 대한 세부 사항을 제공한다. 그림 2는 전체 파이프라인을 개관한다.\n' +
      '\n' +
      '### Hybrid Representation\n' +
      '\n' +
      '제안된 하이브리드 표현은 입력 3D 좌표에 대한 RGB 컬러를 인코딩하는 표면(메쉬), 볼륨(SDF) 및 공유 외관 네트워크로 구성된다. 표면 및 체적 표현 모두 차등적으로 렌더링될 수 있으며, 공유된 외관 네트워크를 활용하여 색상, 정규 및 불투명 채널을 갖는 이미지를 출력할 수 있다. 이제 하이브리드 모양 표현의 세 가지 요소를 자세히 설명합니다.\n' +
      '\n' +
      '표면 표현 우리는 형상의 표면을 2-매니폴드 삼각형 메쉬로 표현한다. 메쉬 토폴로지 또는 샘플링 해상도는 SDF에 따라 국부적으로 적응된다(자세한 내용은 Sec. 3.4 참조). 우리\n' +
      '\n' +
      '그림 2. 하이브리드 최적화의 개요. 입력 프롬프트에 따라 메쉬, SDF 및 공유 외관 MLP를 공동으로 최적화한다. 전체 지오메트리를 최적화하거나 반복적인 3D 모델링 워크플로우를 위해 메시의 사용자가 선택한 부분만 최적화할 수 있습니다. 우리는 두 표현을 차별적으로 렌더링하는 것으로 시작하여 일관성을 강화한다. 동기화된 상태를 유지하기 위해 메쉬를 사용하여 체적 광선을 효율적으로 샘플링하여 메모리 효율적인 방식으로 SDF에서 하이-res 맵을 렌더링한다. 표준 SDS 손실에 더하여, 고-res 렌더링은 SDF를 진화시키기 위해 고품질 VSD 손실(Wang et al., 2023)을 사용할 수 있게 한다. RGB 픽셀, 이미지 불투명도 및 표면 법선에 대한 다시점 일관성 제약 조건을 통해 메쉬 표면과 SDF를 동기화한다. 메쉬 로컬 토폴로지는 ROAR(Barda et al., 2023)을 사용하여 SDF에 따라 업데이트되고, 기하학이 생성되는 삼각형들을 분할하고, 필요한 경우 에지들을 붕괴시킨다. 또한 표현별 손실을 활용하여 최적화를 정규화한다. 즉, SDF에서의 Eikonal 손실과 메쉬에서의 smoothness 손실이다.\n' +
      '\n' +
      'SDF 자체에서 파생된 보조 외관 네트워크를 사용하여 메쉬에 대한 색상을 인코딩합니다(아래 참조). 우리는 이 접근법이 전통적인 메쉬 컬러링 기법보다 간단하고 더 자연스럽다는 것을 발견했다; 정점당 컬러를 사용하는 것은 삼각측량에 민감하며, SDF의 해상도와 일치하기 위해 많은 수의 정점이 필요할 것이다. 텍스처 이미지를 사용하는 것은 복잡한 UV 매개변수화를 필요로 하며, 일반적으로 고정된 모양에 선험적으로 수행된다. 또한, 우리의 표면은 지속적으로 최적화되고 위상 변화, 재-테셀레이션 및 대규모 변형을 겪으며, 이는 이 최적화 동안 전통적인 UV 매개변수화 기술을 적용하는 것을 계산적으로 불가능하게 만든다.\n' +
      '\n' +
      '대신, 우리의 하이브리드 접근법은 채색을 형상화하는 더 간단한 접근법을 제공한다. 외관 네트워크에서 메쉬에 색상을 적용하기 위해, 삼각형 영역에 따라 베이스 메쉬의 각 면을 적응적으로 세분화할 것을 제안한다. 우리는 색상을 표현하기 위해 이러한 세분화된 삼각형만을 사용하기 때문에 전통적인 세분화 기술과 달리 연결된 메쉬를 형성할 필요가 없다. 따라서 본 논문에서는 UV-less 텍스쳐링(23)을 위해 제안된 메쉬컬러스킴을 사용하였으며, 효율적인 GPU 구현이 가능하다. 삽입에서 우리는 예제 세분화를 설명합니다. 인접한 두 면의 하위 삼각형이 모서리를 따라 정점을 공유하지 않는 방법에 주목하십시오. 렌더링하는 동안 우리는 세 개의 연관된 슈퍼샘플링된 정점의 좌표를 사용하여 출현 네트워크를 샘플링함으로써 각 서브삼각형에 색상을 할당한다.\n' +
      '\n' +
      '부호 거리 함수 우리의 체적 형상 표현은 기성품에서 선택되며, 개념적으로 기존의 최첨단 텍스트2 형상 도구를 사용하여 메쉬 진화를 안내하는 정규화의 역할을 한다. 우리는 \\(\\mathbb{R}^{3}\\)의 어느 곳에서나 샘플링할 수 있는 신경 SDF 또는 암시적 연속 스칼라 필드를 사용하여 서명된 최단 거리를 표면으로 되돌린다(내부에서는 음수, 외부에서는 양수). 우리는 그리드 상에서 정의된 특징들의 다중 해상도 해시 인코딩을 사용하여 SDF를 인코딩하고, 이 해시 인코딩은 인스턴트-NGP에 이어 작은 MLP에 의해 거리 값에 매핑된다[24]. 메쉬 케이스에서와 같이, 공유된 외관 네트워크는 렌더링 동안 컬러들을 획득하기 위해 샘플링된다.\n' +
      '\n' +
      '외관망(Appearance Network) 공유외관망(Shared appearance network)은 색들을 암시적으로 \\(\\mathbb{R}^{3}\\) 위에 지도로 인코딩한다. 그것은 SDF와 동일한 해시 그리드를 공유하지만, 해시 그리드 특징을 입력으로 하고 RGB 값을 출력하는 단일 은닉 레이어를 갖는 더 작은 MLP 헤드를 갖는다.\n' +
      '\n' +
      '### 하이브리드 형상 안내\n' +
      '\n' +
      '본질적으로, 형상 최적화는 텍스트 프롬프트로부터 구배를 증류하기 위해 스코어-증류 샘플링(SDS)에 기초한다. 메쉬 외에 SDF 표현을 유지하기 위한 일차적인 동기는 SDF가 더 강건한 잡음 안내이기 때문이며, 이는 멀티뷰 SDS 접근법의 고유한 속성이다(도 5 참조). 따라서 보조 SDF 표현에만 텍스트 안내를 주입하고 일관성 손실(Sec. 3.3)과 토폴로지 업데이트(Sec. 3.4)를 통해 메시에 변경 사항을 전파한다.\n' +
      '\n' +
      '텍스트 안내와 일관성 손실을 적용하려면 두 표현을 차별화해야 한다. 우리는 Nvdiffrast[12]를 사용하여 메쉬를 렌더링하고 VolSDF[13]을 사용하여 SDF의 볼륨 렌더링을 수행한다. 메쉬 래스터화가 볼륨 렌더링보다 훨씬 저렴하기 때문에 속도와 메모리 측면에서 SDF를 렌더링할 수 있는 해상도에 의해 프로세스가 병목 현상이 발생한다. 제안된 하이브리드 표현은 512x512의 높은 해상도에서 SDF를 더 빠르고 저렴하게 렌더링하는 전략을 독특하게 가능하게 하며, 이는 최적화 전반에 걸쳐 메쉬와 SDF 표현 사이의 일관성 덕분에 달성된다. 우리는 광선과 메쉬 표현(미분 가능한 메쉬 렌더러에 의해 효율적으로 계산됨)의 교점을 사용하여 SDF를 렌더링하는 데 필요한 광선당 일반적인 512개의 샘플을 크게 줄일 수 있다. 교차점을 샘플들의 작은 확산(전형적으로 3)의 중심으로서 사용하는 것은, 그렇지 않으면 메모리 금지인 SDF(즉, 512x512 및 더 큰)의 고해상도 렌더들을 허용한다. 레이당 네트워크 질의 수를 줄이기 위해 표면을 활용하는 아이디어는 적응형 쉘[25]과 하이브리드 너프[24]와 같은 동시 작업에서 등장했으며, 이는 우리가 아닌 다른 설정에서 일반성과 성공을 보여준다.\n' +
      '\n' +
      '이 전략을 사용하여, 우리는 512x512에서 SDF를 렌더링하고 이러한 고-res 렌더링의 VSD 손실을 적용한다. 또한 정규 VolSDF에 의한 하위 128x128 렌더링에 정규 SDS를 적용하므로 결과가 약간 개선된다.\n' +
      '\n' +
      '### Representation Priors\n' +
      '\n' +
      '텍스트 안내 외에도, 우리는 두 표현을 동기화하는 표현-특정 정규화 및 일관성 손실을 적용한다.\n' +
      '\n' +
      '일관성 손실 SDF와 메시는 그들의 이미지가 임의의 카메라 각도에서 1 대 1 대응 관계에 있는 경우 일관성이 있다. 따라서 RGB 렌더링, 일반 맵 및 불투명 맵 간의 L2 차이를 감독한다. 렌더링이 다른 해상도로 이루어지면 L2 손실을 계산하기 전에 더 낮은 해상도로 축소한다.\n' +
      '\n' +
      '로컬화 및 동결 손실 강제 사용자 선택 영역에 대한 변경 사항을 로컬화하기 위해 먼저 사용자 선택 이외의 기울기를 0으로 지정하여 최적화 중에 선택되지 않은 모든 영역의 메쉬 정점을 고정합니다. SDF에 대해 로컬리제이션을 달성하기 더 어렵지만, 우리는 고정된 정점 주변의 영역이 변경되지 않은 채로 유지되는 것을 선호하는 샘플링 기반 동결 손실을 추가한다:\n' +
      '\n' +
      '\\[s(v_{\\text{sampled}})=0 \\tag{1}\\]\n' +
      '\n' +
      '여기서 \\(v_{\\text{sampled}}\\)는 사용자에 의해 선택된 최적화 영역의 일부가 아닌 면들 위에 균일하게 샘플링된 정점들이다.\n' +
      '\n' +
      'Laplacian(Smoothness) Loss implicit 함수의 표면을 평활하게 정규화하기 어렵지만, mesh의 명시적 표현은 각 정점에 대해 정의된 mesh의 Laplacian을 사용하여 평활도 항을 쉽게 정의할 수 있다:\\[\\delta(x_{i})=x_{i}-\\frac{\\Sigma_{j}x_{j}{N}, \\tag{2}\\.\n' +
      '\n' +
      '여기서 \\(x_{j}\\)는 \\(x_{i}\\)의 이웃이다. 라플라시안 벡터는 국부적 기하 변화를 인코딩하며, 매끄러운 메쉬는 낮은 라플라시안 벡터에 의해 정의되며, 우리는 전역적 평활도 손실을 사용한다:\n' +
      '\n' +
      '\\[L_{\\text{smooth}}=\\Sigma_{i}||\\delta_{i}||. \\tag{3}\\]\n' +
      '\n' +
      'SDF Eikonal Loss는 묵시적 함수가 유효한 SDF 표현을 학습하도록 장려하기 위해 우리는 Eikonal 용어를 손실로 사용한다. SDF\\(s\\)는 Eqn 4에서의 손실이 0인 경우에만 유효하다:\n' +
      '\n' +
      '\\[L_{\\text{Eik}}=\\Sigma_{x}(||\\nabla s(x)||-1)^{2} \\tag{4}\\]\n' +
      '\n' +
      'TextMesh[14]에 의해 영감을 받은 SDF 불투명도 및 정상 손실 또한 SDF 불투명도를 이진화하고 이산 0 또는 1 값을 장려하기 위해 이진 교차 엔트로피 손실을 적용한다. 암시적 표면의 잘못 지향된 법선을 벌하기 위해 음수인 경우 법선과 카메라 방향 사이의 내적에 L2 벌점을 적용한다.\n' +
      '\n' +
      '### 메쉬 토폴로지 업데이트\n' +
      '\n' +
      '메쉬와 SDF 사이의 일관성을 유지하기 위해, 필요한 경우 메쉬 해상도를 증가 또는 감소시키는 점에서 메쉬에 대한 로컬 토폴로지 편집을 수행할 필요가 있다. Continuous Remeshing[13]은 Adam optimizer 상태를 신호로 사용함으로써, 이러한 로컬 토폴로지 업데이트 접근법을 개척하였다. 이 접근법은 이미지가 선명하고 카메라 매개변수가 알려져 있는 다중 뷰 재구성 시나리오에서 잘 작동하지만 SDS와 관련된 노이즈는 기울기를 만들고 Adam 상태를 확장함으로써 매우 시끄럽고 불안정한 신호를 발생하여 이러한 동작을 트리거한다. 우리는 또 다른 작품인 ROAR[1]로 눈을 돌리고, 특히 우리의 하이브리드 표현에 잘 어울린다. 이 프레임워크 내에서 SDF를 신호로 사용하여 메쉬 삼각형 분할을 트리거한다.\n' +
      '\n' +
      '간단히 말해서, 메쉬 상의 각각의 삼각형에 대해, ROAR는 삼각형을 K개의 서브-페이스들로 슈퍼샘플링함으로써 시작하고, 프로젝션 연산자를 사용하여 SDF\\(s\\)의 0-레벨 세트 상에 각각의 서브-버텍스들을 투영한다:\n' +
      '\n' +
      '[P(x)=-s(x)\\cdot\\nabla s(x)\\tag{5}\\]\n' +
      '\n' +
      '이 투영은 초기 삼각형에 가장 가까운 암시적 표면에 근사하는 조각별 선형 표면을 생성한다. 이 삼각형을 분할하기로 한 결정은 이 투영된 표면의 곡률 점수에 기초한다. 표면이 매우 구부러지면 삼각형은 \\(\\sqrt{3}\\)-부분분할[12]을 사용하여 분할된다. 유사하게, 각각의 에지는 에지의 1-링에 있는 모든 평면들에 대한 그것의 정점들의 2차 거리에 기초하여 점수가 할당되며, 이는 에지가 기하학에 얼마나 중요한지를 직관적으로 나타낸다. 점수가 낮으면 Qslim[1]로 모서리를 접을 수 있습니다.\n' +
      '\n' +
      '우리는 관심 있는 독자를 더 자세한 내용은 ROAR 용지[1]에 참조하지만, ROAR의 각 반복이 가장 높은 얼굴 점수와 가장 낮은 에지 점수의 차이인 에너지를 엄격하게 감소시킨다는 의미에서 ROAR는 에지 붕괴 및 얼굴 분할을 수행하는 원칙적인 방법을 제공한다는 점에 주목해야 한다. 따라서 충분한 반복 후에 수렴 거동을 나타낸다. 우리는 또한 다양성이 반복 전반에 걸쳐 보존되도록 보장된다는 점에 주목한다.\n' +
      '\n' +
      '## 4. Experiments\n' +
      '\n' +
      '우리는 트레스투디오[1]에서 파이프라인을 구현하고 골격 확산 모델로 안정적인 확산 v1.5와의 비교를 위해 프레임워크에서 제공되는 다른 방법의 구현을 사용한다. 이 작업에 제시된 모든 실험은 단일 A100-40GB GPU에서 실행되었다.\n' +
      '\n' +
      '이 섹션의 나머지 부분에서는 본 표현을 텍스트 조건 3D 생성에 대한 이전 작업(Sec. 4.1)과 비교하고 메쉬 조각 응용 프로그램(Sec. 4.2)에서 그 유용성을 입증하고 텍스트 기반 메쉬 변형 기준(Sec. 4.3)과 비교한다. 그런 다음 잡음이 있는 구배(Sec 4.4)를 사용하여 SDS 지침을 사용할 때 하이브리드 표현을 동기화하기 위한 간단한 예시적인 실험을 제공하고 마지막으로 방법(Sec 4.5)을 삭제한다.\n' +
      '\n' +
      '### 생성 방법과의 비교\n' +
      '\n' +
      '매직클레이는 모델링 도구이기 때문에 기하학의 품질을 평가하는 데 주로 관심이 있으며 따라서 질감이 없는 메쉬 렌더링에 중점을 둔다. 기존의 3D 생성 기법은 기존의 메쉬의 일부를 편집하도록 설계되지 않았기 때문에 텍스트-3D 생성 태스크에 대한 하이브리드 접근법의 성능을 비교한다. 우리는 Fantasia3d[1], ProlificDreamer[23] 및 TextMesh[14]의 세 가지 최근 접근법과 비교한다. TextMesh[14]에서 사용되는 표현은 SDF이므로 메쉬의 품질을 평가하기 위해 그들의 출력에 대해 행진 큐브를 실행한다. ProlificDreamer는 두 단계 접근 방식을 사용한다: 먼저 NeRF-base 생성 후 명시적 표현을 사용하는 정제이다. Fantasia3d는 DMtet[1]을 사용하여 SDF에서 메쉬를 추출한다.\n' +
      '\n' +
      '우리는 그림 3에서 우리의 결과를 제시한다. 각각의 접근법이 사실적인 RGB 렌더들을 생성할 수 있는 표현을 생성하더라도,\n' +
      '\n' +
      '도 3. **처음부터 text-to-3D에 대한 비교.** 우리는 다양한 최신 생성 방법: Fantasia3d[1], ProlificDreamer[23] 및 TextMesh[14]로부터 추출된 삼각형 메쉬의 품질을 비교한다. 모든 방법이 사실적인 RGB 렌더링을 생성하는 반면, 하이브리드 표현만이 부드러운 형상을 생성한다.\n' +
      '\n' +
      '추출된 메쉬는 종종 상당한 표면 아티팩트를 나타내며, 이는 텍스처 없이 거의 인식할 수 없게 한다(ProlificDreamer의 "Chow Chow puppy" 또는 TextMesh의 "Croissant" 참조). 이에 비해, 하이브리드 표현이 표면의 명시적인 정규화를 가능하게 한다는 사실 덕분에 우리의 기하학은 인식 가능하고 부드럽다. 이는 매직클레이가 암시적 복사 필드의 생성 기능을 메쉬의 표면 수준 제어와 성공적으로 연결했음을 입증한다.\n' +
      '\n' +
      '### Mesh Sculpting\n' +
      '\n' +
      '또한 본 논문에서 제안한 방법을 사용하여 새로운 3D 스컬프팅 워크플로우를 구현할 수 있음을 보인다. 초기 메시로 시작하여, 아티스트는 원하는 업데이트된 형상을 기술하는 텍스트 프롬프트와 함께 관심 영역을 선택할 수 있다(그리고 선택적으로 그 영역에 대한 거친 조정을 조각할 수 있다). 매직클레이는 수정된 메시를 생성하며, 이는 새로운 요소로 반복적으로 정제될 수 있다. 혼성 표현은 본 출원에 필수적임에 유의한다. 먼저, 관심 영역을 선택하고 조정하는 것은 표준 메쉬 편집 툴(Blender, 2024)을 이용하여 용이하게 달성된다. 둘째, 생성된 결과는 추가적인 SDF 표현 지침으로 더 표현력이 있는 경향이 있다. 셋째, 메쉬를 사용하여 비선택된 표면 영역을 변형 기울기를 제로화함으로써 손상되지 않게 유지할 수 있으며, 이는 변화가 사용자 선택 영역에만 영향을 미칠 것임을 보장한다. 예를 들어 결과는 그림 1, 9 및 보충 비디오를 참조하십시오. 매직클레이는 거친 로컬 편집과 일치하고 사용자의 텍스트 프롬프트를 준수하는 고품질 편집을 생성합니다.\n' +
      '\n' +
      'TextDeformer와의 비교\n' +
      '\n' +
      '이 방법은 텍스트 기반 프롬프트를 통해 상호 작용적이고 국부적인 메쉬 조각 문제를 해결하는 첫 번째 방법이다. 순진한 대안은 단순히 기존의 텍스트-구동 메쉬 변형 기술(Gao et al., 2023)을 사용자-변형 메쉬 상에서 사용하는 것이며, 여전히 기하학에서 원하는 변화를 달성하는 것을 목표로 한다. 그림 4에서 우리는 우리의 방법을 이 기준선과 비교한다. 우리의 방법은 SDF 및 위상 업데이트의 안내로 인해 기하학적으로 복잡한 대규모 세부 정보를 추가할 수 있는 방법에 주목한다. 제안된 방법의 변화는 사용자 변형 영역에만 제한되며, 입력의 다른 부분에 대규모 변형이 발생하지 않는다.\n' +
      '\n' +
      '### 잡음에 대한 메쉬와 SDF의 강건성 분석\n' +
      '\n' +
      '이제 간단한 제어 실험을 통해 하이브리드 표현에 대한 동기를 설명하며, 여기서 우리는 지침에서 다양한 수준의 소음을 가진 고정된 3D 표적을 재구성하는 것을 목표로 한다. 명확한 근거 진리를 갖고 텍스트 기반 목표로 인해 발생하는 모호성을 제거하기 위해 재구성 문제로 공식화한다. 비록 합성 잡음을 사용하지만, 이러한 결과는 각 SDS 반복에서 수행되는 무작위 잡음 단계(Poole et al., 2022)로 인해 구배도 잡음이 있는 SDS 설정에서 적용될 것으로 기대한다.\n' +
      '\n' +
      '고정된 (진정한) 3D 모델의 다시점 렌더링이 주어지면, 우리는 각 이미지에 상관되지 않은 픽셀별 가우시안 잡음을 추가하고 L2 픽셀별 손실을 계산하여 타겟을 향한 형상 표현을 유도한다. 우리가 (표준 편차를 증가시킴으로써) 잡음 레벨을 증가시킴에 따라, 우리는 상이한 표현들이 타겟을 재구성하는 데 더 오류가 발생하기 쉽다는 것을 발견한다. 본 논문에서는 지면 진리 형상에 대한 L2 재투영 오차를 평가 메트릭으로 사용하고, 바닐라 메쉬, SDF 표현과 하이브리드 접근법(메쉬 렌더링 사용)을 비교하여 그림 5의 결과를 보여준다. 잡음의 양이 증가함에 따라 메쉬 재구성의 품질이 급격히 저하된다는 점에 유의한다. 가장 높은 잡음 레짐(표준 편차 5)에서, 메쉬 재구성은 블롭으로 퇴화하는 반면, SDF 재구성은 표면 불규칙에도 불구하고 여전히 인식 가능하다. 중요한 것은, 하이브리드 표현이 모든 노이즈 레벨에서 두 개별 표현보다 더 나은 성능을 보이고, 이점이 더 높은 노이즈 레벨에서 가장 강력하다는 것이다.\n' +
      '\n' +
      '### Ablations\n' +
      '\n' +
      '우리는 시스템의 설계를 정당화하기 위해 여러 가지 절제 작업을 수행합니다.\n' +
      '\n' +
      '메쉬 색상에 대한 얼굴 슈퍼샘플링은_No mesh color.___No face superpersampling. 도 6은 메쉬 컬러 스키마(Sec 3.1)에 기초한 출현 네트워크의 메쉬-구동 슈퍼-샘플링의 필요성을 예시한다. 우리는 최선을 다한다.\n' +
      '\n' +
      '도 4. **TextDeformer와의 비교(Gao et al., 2023). 사용자 수정 입력 메시가 주어지면 텍스트 변환기를 실행하거나 방법을 실행하여 대상 프롬프트를 향해 수정한다.**\n' +
      '\n' +
      '그림 5. **메쉬와 SDF가 잡음 구배에 강건하다. 다양한 노이즈 레벨을 그라운드 트루스 렌더링에 적용한 후 멀티뷰 재구성 손실을 갖는 메쉬, SDF를 하이브리드 표현으로 최적화한다. 우리는 지상 진실 렌더링에 대한 L2 재투영 오류를 보고한다. SDF는 높은 잡음 체제에 대해 메쉬보다 더 견고함을 나타내며, 우리의 하이브리드는 두 가지 모두를 능가한다.\n' +
      '\n' +
      '대상 이미지에 대한 표현(첫 번째 열), 정점당 색상 샘플링(두 번째 열) 또는 메쉬컬러(세 번째 열)를 사용한 적응형 샘플링을 사용합니다. 메쉬컬러 샘플링 없이 훨씬 더 높은 해상도가 필요하며, 이는 재구성 불량 및 과셀레이트 메쉬로 이어진다.\n' +
      '\n' +
      '로컬리제이션을 시행하지 않고, 동결 손실 없이 Sec. 3.3에서 논의된 바와 같이 선택되지 않은 표면 영역과 근처의 SDF 값을 고정하여 로컬리제이션을 시행하기 위한 메커니즘을 제거한다. 그림 7에서 이 기능이 없으면 모양이 의도하지 않은 전역적 변화를 겪으며 잠재적으로 원래 모양을 지울 수 있음을 보여준다.\n' +
      '\n' +
      '위상 업데이트가 없습니다. 최적화 중 위상 업데이트(Sec. 3.4)는 해상도를 점진적으로 추가할 수 있으므로 결과를 크게 개선합니다. 고정-해상도 메시를 최적화하는 것은 초기 해상도가 너무 높으면 입력과 약간만 다른 형상을 초래하거나(도 8, 왼쪽), 초기 해상도가 너무 거칠면 미세한 세부사항이 결여된다(도 8, 오른쪽).\n' +
      '\n' +
      '## 5. Conclusion\n' +
      '\n' +
      '우리는 새로운 하이브리드 SDF와 메쉬 표현이 뒷받침되는 생성 조각 도구인 매직클레이를 제시했다. 우리는 신중한 분석과 기준선을 통해 하이브리드 표현의 중요성을 입증했다. 생성 과정의 성공의 열쇠는 SDF의 볼륨 렌더링에서 샘플링된 광선을 국소화하기 위해 하이브리드 표현의 메쉬 부분을 활용하는 새로운 렌더링 전략이다. 매직클레이는 텍스트에서 이미지로의 최근 발전을 반복적인 워크플로우에서 아티스트가 사용할 수 있는 실제 모델링 도구로 전환하는 중요한 단계라고 믿습니다.\n' +
      '\n' +
      '우리의 방법은 본질적으로 SDS 기울기의 품질에 의해 제한된다. 이는 점수 증류 샘플링 동안 현재 생성 모델이 _일관성_다시점 이미지를 생성할 수 없기 때문이다. 각 뷰는 다른 방향으로 최적화를 지향하여 시끄러운 프로세스를 초래하여 미세한 세부 사항의 출현을 더욱 어렵게 만든다. 즉, 매직클레이는 적응 없이 현재의 텍스트 대 모양 방법을 사용하며, 피할 수 없는 현장 추가 개발로 쉽게 통합 및 이점을 얻을 수 있다. 둘째, 매직클레이를 실행하는 데 A100 GPU에서 프롬프트당 1시간이 소요되기 때문에 매직클레이는 상호 작용하지 않는다. 우리는 NeRF 문헌을 통해 수십 개의 다시점 영상이 3차원 형상을 매우 효율적으로 재구성하기에 충분하다는 것을 알고 있다. 따라서 확산 모델이 일관된 이미지를 생성하는 데 더 잘 될수록 매직클레이가 필요로 하는 반복 횟수가 크게 감소하여 훨씬 더 빨라질 것이라고 믿는다.\n' +
      '\n' +
      '향후 연구에서는 향후 연구를 위한 여러 장소를 볼 수 있다. 먼저, 인페인팅 및 깊이 조절 확산 모델을 활용할 수 있는 기회를 봅니다. 실제로, 이러한 생성 프로세스는 각각의 렌더링에서 전체 객체를 변환하는 반면, 생성된 이미지의 일부 부분은 3D 편집이 로컬화되는 것과 동일하게 유지되어야 한다는 것이 분명하다. 우리는 이 통찰력을 활용하면 최적화가 더 나은 기하학과 더 빠른 속도에 도달하는 데 도움이 되는 3D 최적화에서 노이즈의 양을 줄일 수 있다고 생각한다. 둘째, 저희 시스템으로 이미지 표적을 사용하여 탐색하고자 합니다. 우리는 이것이 편집을 보다 구체화하는 데 도움이 될 수 있고, 또한 사용자가 이미지의 어느 부분이 생성된 모양에 영향을 미칠지를 강조할 수 있는 더 많은 제어를 허용할 수 있다고 믿는다. 마지막으로, 높은 해상도의 기하학적 세부사항(정상 및 범프 맵과 같은)을 캡처하기 위해 표면 표현을 장식하고 적절한 일관성 손실로 SDF 표현에 연결하는 것은 결과적인 형상의 품질을 더욱 향상시킬 수 있다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* (1)\n' +
      '* 오토데스크(2024) 오토데스크. 2024. Mudbox. [https://www.autodesk.com/products/mudbox] (https://www.autodesk.com/products/mudbox).\n' +
      '*Barda et al. (2023) Amir Barda, Yotam Erel, Yotam Kasten, and Amir H. Bermono. 2023. ROAR: 평면 투영을 이용한 강건한 적응적 형상 재구성 arXiv:2307.00690 [cs.GR].\n' +
      '* Biermann et al. (2002) Henning Biermann, Ioana Martin, Fausto Bernardini, and Denis Zorin. 2002. 다해상도 표면의 절단 및 붙여넣기 편집.\n' +
      '* 블렌더(2024) 블렌더. 2024. [http://www.blender.org](http://www.blender.org)\n' +
      '* Chen et al. (2023) Rui Chen, Yongwei Chen, Ningxin Jiao, and Kui Jia. 2023. Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation. arXiv:2303.13873 [cs.CV]\n' +
      '\n' +
      '도 8. **Ablation: 토폴로지 업데이트 없음.** 토폴로지 업데이트 없이 메쉬를 최적화하는 것은 초기 해상도에 의해 최종 생성된 객체가 제한되는 결과를 초래한다. **왼쪽** 미세한 메쉬로 시작할 때 각 정점은 목표에 작은 영향을 미치기 때문에 최적화는 종종 고착된다. **Right** 거친 메시로부터 시작할 때, 어떠한 미세한 세부사항도 생성될 수 없다.\n' +
      '\n' +
      '그림 6. **절제: 색상 슈퍼샘플링 없음.** 외관 네트워크와 함께 메쉬 유도 슈퍼샘플링을 사용하면 기하학과 외관을 분리할 수 있다. 이러한 접근법(우상단)을 사용하여, 렌더링이 여전히 높은 주파수 컬러들(하단)을 제시함에도 불구하고, 메쉬에 대해 큰 면들이 사용된다. 컬러-퍼-정점 스킴(상위 중간)을 사용할 때, 유사한 외관을 달성하기 위해 상당히 큰 메시 분해능이 요구된다.\n' +
      '\n' +
      '그림 7. **절제: 국소화를 강제하지 않음.** 국소화 및 동결 손실 없이 형상 변화가 사용자 강조 영역을 넘어 전파되어 잠재적으로 원래 콘텐츠를 파괴할 수 있음을 관찰한다. 여기서 아르마딜로는 "천사의 날개"에 의해 지워졌다.\n' +
      '\n' +
      '* [Chen and Zhang2019] Zhiqin Chen and Hao Zhang. 2019. 생성적 형상 모델링을 위한 암시적 필드 학습.\n' +
      '*[Funkhouser et al.2004] Thomas Funkhouser, Michael Kazhdan, Philip Shilane, Patrick Min, William Kiefer, Ayellet Tal, Szymon Rusinkiewicz, and David Dobkin. 2004. 예시에 의한 모델링. _ ACM Transactions on Graphics_(2004).\n' +
      '*[Gao et al.2023] William Gao, Noon Augerman, Thiabult Groueix, Vladimir G. Kim, and Rana Hancoka. 2023. TextDeformer: Text Guidance를 이용한 기하학 조작. arXiv:2304.13348 [cs.CV]\n' +
      '* Garland and Heckbert (2023) Michael Garland and Paul S. 헥버트 2023. Quadric Error Metrics를 이용한 표면 간소화, 8페이지. [https://doi.org/10.1145/359671.3596727] (https://doi.org/10.1145/359671.3596727)\n' +
      '* Guo et al. (2020) Yuan-Chou Guo, Ying-Tian Lu, Ruihai Shi, Christian Laorte, Vikram Voelci, Guan Luo, Chi-Hao Chen, Zi-Xin Zou, Chen Wang, Yan-Fei Cao, and Song-Hai Zhang. 2020. 3fold: 3D 콘텐츠 생성을 위한 통일된 프레임워크. [https://github.com/thew09cti/bertresearch] (https://github.com/thew09cti/bertresearch).\n' +
      '* Jacobson et al. (2014) Alec Jacobson, Zhigang Deng, Ladislav Kavan, and J.P. Lewis. 2014. 스키밍: 실시간 형상 변형.\n' +
      '* Logorakis et al. (2012) Evangelos Kalogorakis, Siddhartha Chaudhuri, Daphne Koller, and Vladlen Koltun. 2012. Component-Based Shape Synthesis의 확률 모델_ ACM Transactions on Graphics_31, 4(2012).\n' +
      '* 코벨트(2000) 얼 코벨트. 2000. Sqr(3)-Sublitation. _ ACM SIGGRAPH_2000 (05 2000).\n' +
      '* Laine et al. (2020) Samulul Laine, James Hellsten, Teero Karras, Youngho Seel, Jaakko Lehtinen, and Timo Aila. 2020. Modular Primitives for High Performance Differentiable Rendering. _ ACM Transactions on Graphics_39, 6 (2020).\n' +
      '* Liao et al. (2023) Jiahao Li, Hao Tan, Kai Zhang, Zexiang Xu, Fujun Luan, Yinghao Xu, Yicong Hong, Kalyan Sunkavalli, Greg Shakhmrovrovich, and Sali B. 2023. Instal(tm): Fast text-to-3d with sparse-view generation and large reconstruction model.\n' +
      '* Lin et al. (2023) Chen-Hsuan Lin, Jin Gao, Luning Tang, Towaki Takikawa, Xiaohui Zeng, Xun Huang, Karsten Kresin, Saria Fidler, Ming-Yu Liu, and Tsung-Yi Lin. 2023. Magic3D: High-Resolution Text-to-3D Content Creation. arXiv:2110.1404 [cs.CV]\n' +
      '* Millenall et al. (2021) Ben Millenall, Pratul P Srinivasan, Matthew Tanci, Jonathan T Barron, Ravi Ramamoamoorthi, and Ren Ng. 2021. 다음: 장면들을 뷰 합성을 위한 신경 래디언스 필드들로서 표현하는 단계. 90-106페이지\n' +
      '* Muller et al. (2022) Thomas Muller, Alex Evans, Christoph Schied, and Alexander Keller. 2022. 다해상도 해시 인코딩을 갖는 인스턴트 뉴럴 그래픽 프리미티브들 _ ACM Trans. Graph_41, 4: Article 102(2022년 7월), 15 페이지. [https://doi.org/10.1145/3528223.35302127] (https://doi.org/10.1145/3528223.35302127)\n' +
      '* Palinger(2022) Werner Palinger. 2022. 역 렌더링에 대한 지속적인 기억; _ Computer Animation and Virtual Workshops_39 (7 2022). [https://doi.org/10.1002/cvzn2011] (https://doi.org/10.1002/cvzn2011)\n' +
      '* Park et al. (2019) Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven Lovegrove. 2019. DeepSDF: Shape Representation을 위한 연속 부호 거리 함수 학습.\n' +
      '* Jung and Wei(2018) Mengqi Peng, Jun Xing, and Li-Yi Wei. 2018. 자동완성 3D 조각.\n' +
      '* Poole et al. (2022) Ben Poole, Ajay Liu, Jonathan T. 배런과 벤 밀덴홀 2022. DreamFusion: Text-to-3D Using 2D Diffusion. arXiv:2209.14988 [cs.CV]\n' +
      '* ECCV 2020_. Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm (Eds.) Springer International Publishing, Cham, 667-683.\n' +
      '* Qian et al. (2023) Guocheng Qian, Jingxie Abdullah Hamd, Jian Ren, Aaliskandar Sarohin, Bing Li, Hsin-Ying Lee, Ivan Skorokhodov, Peter Wonka, Sergey Tulyakov, and Bernard Ghanen. 2023. Magic12: On Image to High-Quality 3D Object Generation Using 2020 and 3D Diffusion Priors. arXiv:2306.17858 [cs.CV]\n' +
      '* Rakotsotsson et al.(2023) Marie-Julie Rakotsson, Fabian Mahmatiel, Diego Martin Arroyo, Michael Niemeyer, Ahbiuut Kunde, and Federico Tonnoliar. 2023. NeRFMashing: Neural Radio-ance Fields를 Geometrically-Accurate M Usehres로 증류하는 단계. arXiv:2303.09431 [cs.CV]\n' +
      '* Ruiz et al. (2022) Natanat Ruiz, Yuanzhe Li, Varun Jagmani, Yael Pirch, Michael Rubinstein, and Kfir Abermann. 2022. DreamDooth: 피사체 주도형 생성을 위한 텍스트-이미지 확산 모델을 미세 조정한다.\n' +
      '* Salvati et al.(2015) Gabriele Salvati, Christian Santoni, Valentina Tibaldo, and Fabio Pellacini. 2015. MeshHirst: 공유 및 리타겟팅 편집 히스토리에 의한 협업 모델링_ ACM Trans. Graph_(2015).\n' +
      '* Schmidt et al. (2006) R Schmidt, C. Grimm, and B Wyvill. 2006. Interactive declong with discrete exponential map.\n' +
      '* Sella et al. (2023) Rii Sella, Gal Fleelman, Peter Hedman, and Hadar Averbuch-Elor. 2023. Vox-E: 3D 객체의 텍스트 유도 복셀 편집. arXiv:2303.12048 [cs.CV]\n' +
      '*Shen et al. (2021) Tanchang Shen, Jun Gao, Kangueo Yin, Ming-Yu Liu, and Sanja Fidler. 2021. 딥 마칭 사면체: 고해상도 3차원 형상 합성을 위한 하이브리드 표현.\n' +
      '* Mudgele(2024) SubstoneModele. 2024. Substance Modeler. [https://www.adobe.com/ie/products/substance3d-modeler.html] (https://www.adobe.com/ie/products/substance3d-modeler.html)\n' +
      '* Sun et al. (2023) Jingxing Sun, Bo Zhang, Ruhish Shao, Lizhen Wang, Wen Liu, Zhenda Xie, and Yebin Liu. 2023. DreamCraft3D: Bootstrapped Diffusion Prior를 갖는 계층적 3D 생성. arXiv:2310.1618 [cs.CV]\n' +
      '* Tsalcooglu et al. (2023) Christina Tsalcooglu, Fabian Manhardt, Alessio Tonioni, Michael Niemeyer, and Federico Tonnoliar. 2023. TextMesh: Text Prompts로부터 사실적인 3D Mesh의 생성. arXiv:2304.12493 [cs.CV]\n' +
      '* Turki et al. (2023) Haifhem Turki, Vasu Agrawal, Samuel Rota Bulo, Lorenzo Porzi, Peter Kontschieder, Deva Ramanan, Michael Zollhofer, and Christian Richard. 2023. HybridNet: Adaptive Volumetric Surfaces를 통한 효율적인 Neural Rendering. arXiv:2312.03160 [cs.CV]\n' +
      '* Wang et al. (2023) Zhengyi Wang, Cheng Lu, Yixai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu. 2023. Drift-Difference: Variational Score Distillation을 이용한 고 충실도 및 다양한 Text-to-3D Generation. arXiv:2305.16123 [cs.LG]\n' +
      '* Wang et al. (2023) Zian Wang, Tianchang Shen, Merlin Nimier-David, Nicholas Sharp, Jun Gao, Alexander Keller, Sanja Fidler, Thomas Muller, 및 Zan Ogolic. 2023. 효율적인 신경 복사 필드 렌더링을 위한 적응적 쉘. : 15 페이지. [https://doi.org/10.1145/3618390] (https://doi.org/10.1145/3618390)\n' +
      '* Yariv et al. (2021) Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. 2021. 신경 암시적 표면들의 볼륨 렌더링.\n' +
      '* Yuksel et al. (2010) Cen Yuksel, John Keyser, and Donald House. 2010. 메쉬 컬러스_ ACM Trans. Graph.__ 29(03 2010). [https://doi.org/10.1145/3713047.371053] (https://doi.org/10.1145/3713047.371053)\n' +
      '* Yuner et al. (2015) Ersin Yumer, Siddhina Chaudhuri, Jessica Hodgins, and Levent Burak Kara. 2015. 변형 핸들을 이용한 의미론적 형상 편집.\n' +
      '* Zbrush(2024) Zbrush. 2024. [https://www.maxon.net/en/zbrush](https://www.maxon.net/en/zbrush)\n' +
      '\n' +
      '도 9: **Sculpting gallery.**_Left_: 소스 메쉬로부터, 사용자는 노란색으로 강조된 2분 이내에 대략적인 편집을 수행한다. _ Right_: 매직클레이가 제공된 프롬프트와 일치하도록 정제한다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>