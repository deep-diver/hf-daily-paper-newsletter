<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 라리마르: 에피소드 메모리 컨트롤을 갖는 대용량 언어 모델\n' +
      '\n' +
      'Payel Das\n' +
      '\n' +
      '1\n' +
      '\n' +
      'Subhajit Chaudhury\n' +
      '\n' +
      '1\n' +
      '\n' +
      ' 엘리 넬슨\n' +
      '\n' +
      'Igor Melnyk\n' +
      '\n' +
      '**Sarathkrishna Swaminathan**\n' +
      '\n' +
      '**Sihui Dai**\n' +
      '\n' +
      '2\n' +
      '\n' +
      'Aurelie Lozano\n' +
      '\n' +
      'Georgios Kollias\n' +
      '\n' +
      'Vijil Chenthamarakshan\n' +
      '\n' +
      '**Jiri Navratil**\n' +
      '\n' +
      '**Soham Dan**\n' +
      '\n' +
      '**Pin-Yu Chen**\n' +
      '\n' +
      '동등 기여 IBM AI 연구 프린스턴 대학. 대응: Payel Das \\(<\\)daspa@us.ibm.com\\(>\\)\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '대규모 언어 모델(LLM)에 저장된 지식의 효율적이고 정확한 업데이트는 오늘날 가장 시급한 연구 과제 중 하나이다. 이 논문은 분산 에피소드 메모리로 LLM을 향상시키기 위한 새롭고 뇌에서 영감을 받은 아키텍처인 라리마를 제시한다. 라리마르의 메모리는 계산적으로 비싼 재교육이나 미세 조정이 필요 없이 지식의 동적, 원샷 업데이트를 허용한다. 여러 팩트 편집 벤치마크에 대한 실험 결과는 라리마가 도전적인 순차 편집 설정에서도 대부분의 경쟁 기준선에 필적하는 정확도를 달성하지만, 기본 LLM에 따라 4-10배의 속도 향상뿐만 아니라 제안된 아키텍처가 단순하고 LLM 비진단적이며 일반적이기 때문에 유연성을 제공한다는 것을 보여준다. 우리는 라리마르를 사용하여 선택적 사실 망각 및 입력 컨텍스트 길이 일반화를 위한 메커니즘을 추가로 제공하고 그 효과를 보여준다.\n' +
      '\n' +
      '머신러닝, ICML\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '사전 학습된 LLM(Large Language Models)은 다양한 NLP(Natural Language Processing) 태스크(Devlin et al., 2018; Raffel et al., 2020; Brown et al., 2020; Vaswani et al., 2017)에서 인상적인 성능을 달성하였으며, 종종 지식 리포지토리로 고려된다(Petroni et al., 2019). 이러한 모델을 배포 후 사실 관련, 안전 및 윤리적으로 유지하려면 LLM의 _ 지식이 지속적으로 업데이트되어야 한다. 따라서 모델이 프라이버시를 보호하고 편견과 환각을 제거하고 새로운 사실을 따라잡을 수 있도록 LLM을 신속하게 업데이트하기 위한 효율적인 메커니즘을 개발하는 것이 중요하다. 모델 편집은 LLM의 "메모리"에서 원하지 않거나 올바르지 않거나 쓸모없는 사실을 제거하고 선택적으로 원하는 결과로 대체해야 합니다. 유사하게, LLM을 신속하게 업데이트하는 능력은 또한 더 긴 컨텍스트 인스턴스가 드문 데이터세트로부터 학습할 때 중요한 트레이닝 분포를 넘어서는 입력 _context 길이 일반화_의 도전적인 문제를 도울 수 있다(Anil et al., 2022; Kazemnejad et al., 2023). 간단한 해결책은 수정된/새로운 데이터 세트에서 모델을 미세 조정하는 것이다. 이러한 접근법은 지식이 LLM 매개변수에 걸쳐 암묵적으로 그리고 분배적으로 인코딩되기 때문에 과적합 및 치명적인 망각의 위험을 겪는다(Kirkpatrick et al., 2017; Zhu et al., 2020). 여러 연구 라인에서 효과적이고 정밀한 LLM 편집(LLM 편집에 대한 포괄적인 조사를 위해, 참조(Li et al., 2022; Liu et al., 2023; Zhu et al., 2020))이 제안되었으며, 이는 동결된 LLM과 함께 작업하도록 외부 메모리 모델 또는 하이퍼네트워크 모델을 트레이닝하는 것을 포함한다. 또 다른 인기 있는 접근법은 LLM 기능 내에서 원래 사실을 찾은 다음 로컬 매개변수 업데이트를 수행하는 것이다. 표 1에 나타난 바와 같이, 두 가지 방법의 라인은 오버피팅 및 새로운 상태에 대한 재트레이닝 또는 로케이팅의 필요성으로 인해 확장성 문제에 직면하여 편집 속도가 느려진다. 수많은 편집물을 저장하기 위한 높은 메모리 요구는 순차 및 일괄 편집 설정에 대한 스케일링 측면에서 추가적인 장애물을 제공한다. 이러한 과제는 실제 산업 환경에서 대규모 언어 모델 업데이트의 적용을 방해한다. 또한, 팩트 편집 및 선택적 팩트 망각을 처리하는 것은 현재의 최신 편집 방법에 대해서도 동일한 방법론적 프레임워크 내에서 어려운 것으로 보이지만(Patil et al., 2023), 새로운 정보 학습 및 오래된 정보 망각은 모두 뇌에서 서로 본질적으로 관련되어 있다(Dempsey et al., 2022; Autore et al., 2023).\n' +
      '\n' +
      '대조적으로, 인간은 지식 업데이트와 일반화를 매우 빠르게 수행할 수 있으며, 둘 다 첫 번째 관련 사례를 본 후 신속한 학습에 부합한다. 뇌에서 이러한 빠른 학습은 해마와 일시적인 기억력에 의존하는 것으로 생각된다. 일관되게, 시멘틱 및 워킹 메모리 시스템들 둘 다 순차적인 의사 결정 작업들로 어려움을 겪는 동안, 에피소드 메모리 시스템들은 유익한 것으로 발견된다(Blundell et al., 2016; Lengyel and Dayan, 2007). CLS(complementary learning systems) 이론(Kumaran et al., 2016)은 뇌에서 상보적 _fast_(hippocamps) 및 _slow_(neocortex) 학습 시스템을 결합하기 위한 근거를 제공하며, 이는 나중에 입력 분포를 모델링하면서 단일 인스턴스로부터의 이전 학습이다. 뇌에서의 신피질-해마 상호작용은 암기 및 일반화를 통해 적응 행동을 촉진하는 것으로 알려져 있다(Sun et al., 2023). 또한, 해마에서 신피질로의 기억 통합은 해마에서 인코딩된 경험의 여러 정확하거나 거짓된 재생과 동기화된 활성화를 통해 촉진됨을 제안한다 - _생성 연관 네트워크_(Ramirez et al., 2013)의 형태를 취하는 해마를 제안한다.\n' +
      '\n' +
      '이러한 통찰력에 영감을 받아 외부 에피소드 메모리 컨트롤러로 증강된 LLM 클래스 **Larimar**를 제안합니다. 우리는 해마 고속 학습 시스템이 샘플을 일화 기억으로 기록하고 신피질 저속 학습 시스템(LLM)이 입력 분포의 요약 통계를 의미 기억으로 학습하는 CLS 관점을 따른다. 우리의 목표는 에피소드 메모리 모듈을 현재 사실적 업데이트 또는 편집 세트의 글로벌 저장소로 취급하고 이 메모리를 LLM 디코더에 조건으로 적용하는 것이다. 새로운 편집이 도착함에 따라 교육을 거치지 않고도 이 메모리를 효율적이고 정확하게 업데이트하는 방법을 배우는 것이 중요합니다.\n' +
      '\n' +
      '이를 해결하기 위해, 우리는 메모리 쓰기 및 읽기가 생성 모델에서 추론으로 해석되는 Kanerva Machine(Wu et al., 2018)과 정신적으로 유사한 계층적 메모리를 활용하고자 한다. 구체적으로, 메모리를 결정론적인 것으로 취급하는 (Pham et al., 2021)의 메모리 모델을 고려함으로써, Kanerva Machine에서 제안된 메모리 및 주소의 베이지안 업데이트를 선형 시스템에 대한 최소 제곱 해를 찾는 것으로 재구성할 수 있다. 일단 업데이트되면, 이 빠른-학습 메모리는 느린-학습 LLM 디코더를 컨디셔닝하는 데 사용된다.\n' +
      '\n' +
      '샘플들의 집합과 연관된 _global_ 메모리의 사용 및 메모리에 대한 _fast write_의 능력은 이 계층적 메모리 프레임워크를 새로운 지식과 관련하여 효율적인 LLM 업데이트에 매력적으로 만든다. 구현-와이즈로, 메모리는 _generic_ 데이터에 대한 종단간 경사 하강에 의해 LLM에 결합되고 편집에 대한 액세스를 가정하지 않는다. 추론 동안, 새로운 데이터는 원샷으로 메모리에 기록되고, 업데이트된 메모리는 편집된 출력을 강제하기 위해 LLM 디코딩을 조건화한다. 또한 Larimar의 One-shot 메모리 갱신 메커니즘을 기반으로 훈련 없는 _selective fact forgetting_와 _information leakage prevention_ 연산을 정형화한다.\n' +
      '\n' +
      '우리가 아는 한, 이것은 LLM의 새로운 지식에 대한 테스트-시간 적응을 위한 해결책으로 계층적 조건부 메모리 모델에 온라인 분산 쓰기를 제안하고 입증하는 첫 번째 작업이다. 기존 벤치마크에서 단일 및 순차 사실 편집 작업에 대해 라리마를 시연하고 기준 방법과 비교했다. 라리마르는 이러한 설정 전반에 걸쳐 정확하고 정확한 편집을 제공하는 반면 경쟁 모델 편집 기준선에 비해 최대 10배 더 빠르다. 라리마르는 선택적 사실 망각 및 정보 유출 방지에 더 중점을 두고 이러한 작업에서 그 효과를 보여준다. 마지막으로, Larimar의 메모리가 더 긴 입력 컨텍스트로 일반화될 수 있도록 하는 간단한 재귀 검색 기반 솔루션을 제공한다.\n' +
      '\n' +
      '우리의 기여는...\n' +
      '\n' +
      '* 뇌의 보완적 학습 메커니즘에서 영감을 받아 실시간 테스트 시간 적응을 위한 일화적이고 적응 가능한 기억 조절 LLM 아키텍처의 클래스를 제안한다. 우리의 방법은 편집을 수행하기 위해 LLM 내에서 시간 집약적인 기울기 기반 학습 또는 사실 추적이 필요하지 않으므로 LLM 업데이트를 위한 더 빠른 대안을 제공한다.\n' +
      '* 우리는 지식 편집 및 입력 컨텍스트 길이 일반화라는 두 가지 관련되고 도전적인 사용 사례에 대한 이 아키텍처의 유용성을 보여준다. 라리마는 베이스라인 편집 방법 및 언어 모델에 비해 두 시나리오 모두에서 새로운 입력에 대한 빠르고 정확한 훈련 없는 적응을 보여준다.\n' +
      '* 원샷 메모리 갱신을 이용한 선택적 사실 망각 및 정보 유출 방지를 보인다.\n' +
      '* 우리는 메모리 공간에 대한 재귀적 검색을 기반으로 라리마르에서 긴 컨텍스트 일반화를 가능하게 하는 간단한 수단을 제공한다.\n' +
      '\n' +
      '##2 모델 아키텍처\n' +
      '\n' +
      '**노트**: 입력공간과 출력공간을 각각 \\(\\mathcal{X}\\)과 \\(\\mathcal{Y}\\)으로 정의한다. 이 모델은 적응 메모리를 통해 연결된 인코더\\(e:\\mathcal{X}\\rightarrow\\mathbb{R}^{C}\\)와 디코더\\(d:\\mathbb{R}\\rightarrow\\mathcal{Y}\\)로 구성된다. 인코더는 차원\\(C\\)의 잠재공간에 출력된다. 메모리는 초기 상태(\\mathbf{M}_{0}\\in\\mathbb{R}^{K\\times C}\\)와 읽기 및 쓰기 가중치 \\(\\mathbf{W},\\mathbf{W}_{0}\\in\\mathbb{R}^{N\\times K}\\)를 갖는 인코딩된 길이의 에피소드들을 저장하기 위해 \\(K\\) 행들을 사용하며, 결과적으로 업데이트된 메모리 \\(\\mathbf{M}\\)을 생성한다.\n' +
      '\n' +
      '### Training\n' +
      '\n' +
      'Kanerva Machine은 메모리\\(\\mathbf{M}\\)을 고려할 때, \\(\\ln p(\\mathbf{X}|\\mathbf{M})\\)의 조건부 로그우도를 최대화하는 것을 목표로 하며, 여기서 \\(\\mathbf{X}\\)는 교환가능(차 불변) 에피소드: \\(\\mathbf{X}=\\{x_{1},\\ldots,x_{N}\\}\\) 샘플로 구성된 입력 데이터의 하위 집합인 \\(\\ln p(\\mathbf{X}|\\mathbf{M})의 조건부 로그우도를 최대화한다. 이 조건부 우도의 변량 하한은 변량 오토인코더(Kingma and Welling, 2013)에서와 유사하게 최적화된다. 그 결과, 이 모델은 \\(\\mathbf{X}\\)을 메모리 \\(\\mathbf{M}\\)에 압축하여 분산 연상 메모리가 되도록 학습한다. 실제로, \\(\\mathbf{M}\\)은 에피소드에 대한 \\(\\mathbf{Z}=e(\\mathbf{X})\\)인 잠재 부호화(\\(\\mathbf{Z}+\\xi\\)의 시끄러운 버전으로 학습된다. 이 연구의 나머지 부분에서 우리는 에피소드에 의존하는 사후 기억으로 \\(\\mathbf{M}\\)을 사용하는 반면, \\(\\mathbf{M}_{0}\\)은 사전 기억을 나타낸다. 읽기 가중치 행렬 \\(\\mathbf{W}\\)은 모델의 생성 능력을 강화하기 위한 무작위 변수이며, 표준 가우시안 사전 \\(p(\\mathbf{W})\\sim\\mathcal{N}(0,I_{N\\times K})\\)과 사후 \\(q(\\mathbf{W})\\sim\\mathcal{N}(\\overline{\\mathbf{W}},\\sigma_{\\mathbf{W}}^{2}}cdot I_{N\\times K})을 사용하여 각 에피소드에서 평균 \\(\\sigma_{\\mathbf{W}\\)이 추정되고 \\(\\sigma_{\\mathbf{W}\\)이 학습 가능하다. 메모리 판독값은 \\(\\mathbf{Z}_{readout}=\\mathbf{W}\\mathbf{M}\\)으로 얻어진다. 전체 메모리 증강 아키텍처는 그림 1에 나와 있다.\n' +
      '\n' +
      '인코더(\\(e\\)), 연상 기억(\\(\\mathbf{M}\\)), 디코더(\\(d\\))의 세 모듈을 훈련하는 동안 다음과 같은 손실을 사용하여 에피소드\\(\\mathbf{X}\\)에 대해 공동으로 훈련되고 최적화된다.\n' +
      '\n' +
      '\\mathbbb{E}_{q(\\mathbf{X}\\sim\\text{data}\\big{(}\\mathbf{X}|\\mathbf{M})\\] \\[+\\alpha\\ln p(d(\\mathbf{X})-\\beta D_{KL}(q(\\mathbf{W}||p(\\mathbf{x}_{i}|\\mathbf{x}_{1}))\\\\ln p(\\mathbf{x}\\sim\\text{pretrain}\\ln p(\\mathbf{X}\\sim\\text{w})}\\big{(}\\mathbbbb{E}_{x}\\mathbf{X}\\sim\\text{data}\\big{(}\\mathbf{X}|\\mathbf{M})}\\ln p(d(e(\\mathbf{X})})\\beta D_{KL}(q(\\mathbf{X}\\\n' +
      '\n' +
      '첫 번째 항은 메모리를 사용한 음의 재구성 손실과 \\(\\mathbf{W}\\), \\(N\\times K\\) 행렬이다. 두 번째는 메모리가 없는 오토인코더의 음성 복원 손실이다. 세 번째는 이전\\(p(\\mathbf{W})\\)와 후\\(q(\\mathbf{W})\\) 사이의 KL 발산이다. 트레이닝 동안 디코더 성능을 유지하기 위해, 사전 트레이닝 데이터 정규화 항이 추가된다.\n' +
      '\n' +
      '### Memory inference\n' +
      '\n' +
      '(Pham et al., 2021)에서 제안한 최소화 문제를 풀어서 (\\text{min}_{\\mathbf{M}_{0}\\)을 역전파 학습한 후, (\\text{min}_{\\mathbf{M}}||\\mathbf{M}}||\\mathbf{Z}_{\\text{c}-\\mathbf{W}_{0}\\mathbf{M}||_{F}^{2}\\). 선형 연립방정식을 푸는 것에 해당하는 이 최소화 문제는 계산 행렬 의사 역행렬을 통해 효율적으로 수행된다.\n' +
      '\n' +
      '**Implementation**:\n' +
      '\n' +
      '우리는 훈련 실험을 위해 GPT2-대(Radford et al., 2019) 또는 GPTJ-6B 디코더와 메모리 매트릭스(512x768)와 결합된 BERT 대형 인코더(Devlin et al., 2018)를 사용하여 결과 모델 Larimar-1.3B 및 Larimar-6B를 각각 명명했다. 우리의 훈련 데이터는 위키텍스트(Merity et al., 2016) 텍스트를 64개의 토큰의 작은 청크로 분할함으로써 구성된 760만 개의 예로 구성되었다. 테스트에서 라리마르-1.3B 모델은 14.6의 복잡성을 달성한 반면, 라리마르-6B 모델은 1,000개의 무작위 위키텍스트 샘플에서 15.9에 도달하여 메모리 추가가 성능에 거의 영향을 미치지 않음을 나타낸다. Larimar-6B 모델은 Adam optimizer, learning rate 5e-6, batch size 32를 사용하여 10개의 에폭에 대해 훈련하였으며, Larimar-6B의 훈련은 단일 노드에서 8개의 NVIDIA A100-80GB GPU를 사용하여 bfloat16 정밀도와 PyTorch Lightning과 DeepSpeed ZeRO Stage 2를 사용하여 효율적인 분산 훈련을 수행하였다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c} \\hline \\hline\n' +
      '**Editor** & **+Edit Train** & **+Fact Trace** & **Sequential Edit** & **Batch Edit** & **Forgetting/Deletion** & **Time (GPT-2)** & **Time (GPT-J)** \\\\ \\hline ROME & No & Yes & No & No & Yes & 4.8s & 13.9s \\\\ GRACE & Yes & No & Yes & No & No & 13.9s & 19.3s \\\\ Larimar & No & No & Yes & Yes & Yes & 1.1s & 1.7s \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 요구 사항과 능력 관점에서 서로 다른 편집 방법 간의 비교. 기존의 편집 방법으로부터의 ROME 및 GRACE가 도시된다. ROME(Meng et al., 2022) 및 GRACE(Hartvigsen et al., 2022)에 대한 CounterFact 데이터세트 상의 단일 편집(평균 10개 이상의 편집)에 대한 벽 시계 시간은 단일 A100(80G) GPU를 갖는 EasyEdit(Wang et al., 2023) 프레임워크를 사용하여 계산되었다.\n' +
      '\n' +
      '도 1: 라리마 아키텍처: \\(X\\) 및 \\(X_{query}\\)은 각각 데이터 입력 및 쿼리를 나타내며, \\(Z\\), \\(Z_{query}\\) 및 \\(Z_{r}\\)은 잠재 벡터이고, \\(M\\)은 고정 크기 메모리이다. \\(X\\) 및 \\(X_{r}\\)은 고정 크기 메모리이다. (W\\) 및 \\(W_{0}\\)는 메모리에 대한 읽기/쓰기 가중치이다. \\ (W_{M}\\)는 메모리로부터 디코더로 판독을 인터페이스한다.\n' +
      '\n' +
      '## 3 메모리 동작\n' +
      '\n' +
      '쓰기, 읽기, 생성 동작은 \\(\\mathbf{Z}\\) 인코딩에 작용하는 세 가지 기본 메모리 동작, 쓰기, 읽기 및 생성은 (Pham et al., 2021)과 같이 캐스팅된다. 자세한 내용은 알고리즘 1을 참조하십시오.\n' +
      '\n' +
      '인코딩의 초기 집합\\(\\mathbf{Z}_{0}\\)과 쓰기 가중치\\(\\mathbf{W}_{0}\\)이 주어지면, 메모리 행렬과 키 공분산 행렬을 초기화한다.\n' +
      '\n' +
      '\\mathbf{M}_{0}=\\mathbf{W}_{0}^{\\dagger}\\mathbf{Z}_{0},\\quad\\mathbf{C}_{0}=\\mathbf{W}_{0}^{\\top}\\mathbff{W}_{0}\\tag{2}\\mathbf{W}_{0}\n' +
      '\n' +
      '메모리\\(\\mathbf{M}_{i-1}\\)을 순차적으로 갱신하기 위해, 새로운 부호화 집합을 추가하거나 이전에 작성된 부호화 집합을 잊기 위해, 메모리 행렬과 키 공분산 행렬을 함께 갱신한다. as follows:\n' +
      '\n' +
      '\\mathbf{C}_{i}=\\mathbf{C}_{i-1}+\\alpha_{i}\\mathbf{W}_{i}^{\\top}\\mathbf{W}_{i}\\tag{3}\\\\mathbf{M}_{i-1}+\\alpha_{i}\\mathbf{C}_{i}^{i}\\mathbf{W}_{i}^{m}_{i-1}(\\mathbf{Z}_{i}\\mathbf{M}_{i-1}}\\tag{4}\\mathbf{W}_{i}\\mathbf{W}_{i}\\mathbf{W}_{i}\\mathbf{W}_{i}\\mathbf{W}_{i}\\mathbf{W}_{i}\\mathbf{W}_{i}\\mathbf{W}_{i}\\mathbf{W}_{i}\\mathbf\n' +
      '\n' +
      '기억에 새로운 인코딩을 쓸 때 우리는 \\(\\alpha_{i}=1\\)을 사용한다. 이전에 어떤 \\(i_{write}<i\\)에서 \\(\\alpha_{i_{write}}=1\\)로 메모리에 기록된 인코딩을 잊어버릴 때 \\(\\alpha_{i}=-1\\)을 사용한다. Eq. (4) 데이터가 성장하는 시퀀스에 대한 최소 제곱 솔루션으로 유지되도록 메모리를 순차적으로 업데이트한다. 부호화에 대하여 \\(\\mathbf{M}_{i-1}\\)이 최소제곱해라고 가정하면, 즉,\n' +
      '\n' +
      '\\text{argmin}_{\\mathbf{M}_{i-1}=\\text{argmin}_{\\mathbf{M}}\\sum_{j=0}^{i-1}||\\mathbf{Z}_{j}-\\mathbf{W}_{j}\\mathbf{M}||_{2}^{2}, \\tag{5}\\text{argmin}_{\\mathbf{M}\\sum_{j=0}^{i-1}||\\mathbf{Z}_{j}\\mathbf{M}||_{2}^{2}, \\tag{5}\\text{m}}\\sum_{j=0}^{i-1}||\\mathbf{Z}_{j}\\mathbf{W}_{j}\\mathbf{M}||_{2}^{2}, \\tag{5}\\text{m}\\text{argmin}_{\\mathbf{M}\\text{m}\n' +
      '\n' +
      '그리고 Eq. (4) \\(\\alpha_{i}=1\\)을 갖는 \\(\\mathbf{M}_{i}\\)도 마찬가지로 \\(\\mathbf{Z}_{0:i}\\)(Meng et al., 2023)과 관련하여 최소 제곱 해임을 보장한다. 이 경우, \\(\\alpha_{i}=-1\\)와 \\(\\mathbf{Z}_{i}=\\mathbf{Z}_{i_{forget}}\\)의 경우, \\(i_{forget}<i\\), Eq. (4) \\(\\mathbf{M}_{i}\\)이 데이터에서 \\(\\mathbf{Z}_{i_{forget}}\\)을 제거한 최소제곱해, 즉,\n' +
      '\n' +
      '\\text{argmin}_{\\mathbf{M}_{i}=\\text{argmin}_{\\mathbf{M}}\\sum_{j=0,j\\neq i_{forget}}^{i-1}|| \\mathbf{Z}_{j}-\\mathbf{W}_{j}\\mathbf{M}||_{2}^{2}, \\tag{6}\\tag{6}}}\n' +
      '\n' +
      '가중치는 현재 메모리 측면에서 (following (Pham et al., 2021))^{\\dagger}\\(\\mathbf{W}_{i}=\\mathbff{Z}_{i}\\mathbff{M}_{i-1}^{\\dagger}\\) 또는 고정 기준 메모리 측면에서 (\\(\\mathbff{W}_{i}=\\mathbff{Z}_{i}(\\mathbf{M}^{(\\mathrm{ref}))^{\\dagger}\\)일 수 있다. \\(\\mathbff{W}_{i}=\\mathbff{Z}_{i}(\\mathrm{ref})^{\\dagger}\\) (\\mathbf{M}^{(\\mathrm{ref})}\\)는 모든 순차적인 업데이트(즉, \\(i\\)-독립적)에 걸쳐 변하지 않고, 추론 동안에만 사용되며, 추론 동안 마주치는 데이터의 에피소드를 사용하여 (선택적으로) 구성될 수 있다. 우리가 이전에 쓰여진 주어진 인코딩을 메모리에서 제거하고자 할 때, \\(\\mathbf{M}^{(\\mathrm{ref})}\\)의 고정된 성질은 원래의 쓰기 키 \\(\\mathbf{W}_{i_{write}}\\)를 시퀀스 \\(i_{forget}>i_{write}}\\)의 후점에서 다시 연산할 수 있도록 하여 정보를 메모리에 위치시키고 제거할 수 있도록 한다.\n' +
      '\n' +
      '```\n' +
      'Functionwrite(\\(\\mathbf{Z}\\)): //(\\mathbf{M}=\\mathbf{Z}=e(\\mathbf{X}\\)return\\(\\mathbff{M}\\) Functionread(\\(\\mathbff{M}=\\mathbff{M}=\\mathbf{M}=\\mathbf{Z}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{M}=\\mathbf{ (\\mathbf{Z}=e(\\mathbf{M}^{\\dagger}) Compute mean addressing weight \\(\\mathbf{Z}=\\mathbf{M}\\)return\\(\\mathbf{M}\\)functiongenerate(\\(\\mathbf{Z}=\\mathbf{W}\\text{read}))\n' +
      '```\n' +
      '\n' +
      '**알고리즘 1** 기본 메모리 동작(Pham et al., 2021)\n' +
      '\n' +
      '##4 스코프 검출기\n' +
      '\n' +
      '또한, 착신 질의가 메모리에 기입된 사실들에 가까운지를 검출하기 위해 스코프 검출 메커니즘을 선택적으로 사용하는데, 이는 개념적으로 SERAC(Mitchell et al., 2022)와 유사하다. 쿼리가 인-스코프인 경우, 메모리로부터의 대응하는 판독은 메모리-조건부 디코딩을 위해 디코더로 전달되고 그렇지 않으면 쿼리는 조건없는 디코딩을 받는다. 우리는 두 가지 다른 시나리오를 고려한다.\n' +
      '\n' +
      '**외부 인코딩-기반 스코프 검출기(ESD)**: 샘플 임베딩들은 1.1B 문장 쌍들에 대해 트레이닝된 그리고 384의 출력 공간 차원을 갖는 외부 문장 인코더(MiniLM1)로부터 추정된다. ESD는 인코딩된 팩트들을 자신의 스코프 저장소에 벡터들로서 저장한다. 테스트 시간에서, 인코딩된 입력 문장이 주어지면, 1-최근접 이웃 코사인 유사성이 계산되고 검출 스코어로서 작용한다. 임의의 다중 문장 입력은 먼저 고립된 문장들로 분할되고, 이들 각각은 개별적으로 처리되고 최대 유사성이 취해진다. EasyEdit 데이터 세트의 3800개의 양성 및 음성 샘플에서 측정된 이 ESD 모델은 2.9%의 검출 등오차율과 0.974의 F1 점수를 달성한다.\n' +
      '\n' +
      '각주 1: [https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n' +
      '\n' +
      '**내부 인코딩 기반 스코프 검출기(ISD)**: Larimarencoder \\(e\\)는 CounterFact 샘플들을 내장하는데 사용된다. 그런 다음 인코딩은 이진 범위 분류기를 훈련하는 데 사용되며, 여기서 양성 샘플은 원래 사실의 재구문에서 나오고 음성 데이터는 이웃 사실에 해당한다.\n' +
      '\n' +
      '## 5 Results\n' +
      '\n' +
      '벽시계 시간\n' +
      '\n' +
      '표 1은 단일 A100 GPU 상의 EasyEdit 프레임워크(Yao et al., 2023) 내에서 계산된 10개의 편집에 걸친 각 편집 방법에 대한 벽 시계 시간을 나타낸다. 연구 결과, 기존 LLM 편집 기준선인 ROME(Meng et al., 2022)와 GRACE(Hartvigsen et al., 2022)에 비해 Larimar가 4-10배 빠른 것으로 나타났다. 부록의 표 7은 (Yao et al., 2023)에 도시된 바와 같이, 다른 기존의 베이스라인들 내에서 편집-시간 비교를 더 제공하여, 고속 편집에 대한 라리마의 이점을 확립한다. 표 1은 훈련 또는 추적 자유 방식으로 편집을 처리하는 라리마의 능력을 추가로 나열하여 고속 편집, 선택적 망각 처리 및 순차적 편집 설정 기능을 유지한다.\n' +
      '\n' +
      '단일 팩트 편집\n' +
      '\n' +
      '본 논문에서는 Larimar의 성능을 CounterFact 데이터세트(Meng et al., 2022)에서 최근 제안된 지식 편집 기법들과 비교 분석한다. 모델이 단순히 대상 단어를 암기하는 것이 아니라 새로운 사실을 학습할 수 있는지 평가하기 위한 21,919개의 기록이 포함되어 있다. 다른 작업(Meng et al., 2022; Zheng et al., 2023)에 이어, 우리는 이 데이터세트의 처음 2000개의 샘플을 사용하고 표 2의 Larimar-1.3B 및 Larimar-6B에 대한 단일 팩트 편집 결과에 대한 평균을 보고한다. 기준선에 대한 성능 점수는 (Meng et al., 2022; Zheng et al., 2023)에서 나왔다(기준선 방법에 대한 세부 사항은 관련 작업 및 부록 참조). LLM을 편집에 대해 훈련하거나 LLM 내에서 원래 사실을 인과적으로 추적하고 편집을 반영하기 위해 관련 매개변수를 업데이트하는 것과 달리, 우리는 편집을 위해 라리마의 원샷 메모리 업데이트를 활용한다. 상기 관심있는 편집(들)이 기입됨에 따라 상기 메모리 후방이 업데이트되고, 이어서 상기 업데이트된 메모리가 질의되는, 방법. 그런 다음 메모리로부터의 판독-아웃은 편집을 출력하기 위해 디코더를 컨디셔닝한다.\n' +
      '\n' +
      '표 2에서 사용된 평가 메트릭은 다음과 같다. _Edit Success_는 편집된 사실 \\((s,r,o^{*})\\), (주제, 관계, 객체)와 수정된 객체가 원래의 객체 \\((s,r,o^{c})\\에 기초한 것보다 더 높은 확률을 갖는 경우의 백분율이다. 구체적으로, \\(S\\) 열은 \\(\\mathbb{P}[o^{*}]>\\mathbb{P}[o^{c}]\\) 경우의 백분율을 측정하는 반면, \\(M\\)은 언어 모델의 로짓 공간에서 \\(\\mathbb{P}[o^{*}]] -\\mathbb{P}[o^{c}]\\)의 평균이다. Paraphrase_는 \\((s,r,o^{*}))에 대해 동일한 성능을 측정하지만 패러프레이즈된 프롬프트를 사용한다. _ Neighborhood_는 원래 객체에 대한 지식을 유지할 수 있는 모델의 능력을 평가하지만 이웃 주체의 맥락에서 \\(s^{\\prime}\\): \\((s^{\\prime},r,o^{c})\\). 여기서 \\(S\\) 열은 \\(\\mathbb{P}[o^{c}]>\\mathbb{P}[o^{*}]\\인 경우의 백분율을 반영하는 반면, \\(M\\)은 \\(\\mathbb{P}[o^{c}]] -\\mathbb{P}[o^{*}]\\인 경우의 백분율을 반영한다.\n' +
      '\n' +
      '알 수 있는 바와 같이, 기존의 편집 기준선과 비교할 때, 라리마는 새로운 사실을 성공적으로 편집하는 것과 이웃 프롬프트를 처리하는 능력(ROME와 동등하게, GPT-2XL을 기반으로 할 때, 그리고 GPT-J를 기반으로 할 때, 더 나은 성능)에서 유사한 성능을 달성하는 반면, 일반화를 개선할 여지가 남아 있다. 기존의 문맥 내 편집 접근법(PROMPT 및 IKE 기준)과 비교할 때(Zheng et al., 2023), Larimar는 코퍼스에서 검색되는 디코더에 대한 편집 및 그 패러프레이즈뿐만 아니라 이웃한 사실들의 다중 문맥 내 시연들을 필요로 하지 않는다. 그러나 부록(표 8)에서 알 수 있듯이 라리마가 팩트당 하나의 추가 패러프레이즈에 접근할 때 메모리에 기록함으로써 일반화 성능이 76.5에서 82.8로 증가한다. 이 설정에서 팩트당 평균 추가 패러프레이즈 수는 하나이며 메모리에서 볼 수 없는 패러프레이즈 프롬프트로 모델을 쿼리했다. 또한, 부록의 절제 실험은 라리마르 인코딩 또는 외부 LLM으로부터의 인코딩에 대해 훈련된 스코프 검출기가 더 나은 패러프레이즈 일반화 및 이웃 특이성을 돕는다는 것을 보여준다. 논문 전체에서 라리마는 다음과 같이 구성된다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r r r r r} \\hline \\hline  & \\multicolumn{2}{c}{**Edit Success**} & \\multicolumn{2}{c}{**Paraphrase**} & \\multicolumn{2}{c}{**Neighborhood**} \\\\ \\cline{2-7}\n' +
      '**Editor** & S & M & S & M & S & M \\\\ \\hline GPT-2 XL & 22.2 & -4.8 & 24.7 & -5.0 & **78.1** & **5.0** \\\\ \\hline FT* & **100.0** & 98.8 & 87.9 & 46.6 & 40.4 & -6.2 \\\\ FT+L* & 99.1 & 91.5 & 48.7 & 28.9 & 70.3 & 3.5 \\\\ KN & 28.7 & -3.4 & 28.0 & -3.3 & 72.9 & 3.7 \\\\ KE & 84.3 & 33.9 & 75.4 & 14.6 & 30.9 & -11.0 \\\\ KE-CF & **99.9** & 97.0 & 95.8 & 59.2 & 6.9 & -63.2 \\\\ MEND & 99.1 & 70.9 & 65.4 & 12.2 & 37.9 & -11.6 \\\\ MEND-CF & **100.0** & **99.2** & **97.0** & **65.6** & 5.5 & -69.9 \\\\ ROME & **100.0** & 97.9 & **96.4** & **62.7** & **75.4** & **4.2** \\\\\n' +
      '**Larimar-1.3B** & **100.0** & **99.8** & 41.7 & 0.4 & 74.7 & 1.6 \\\\ \\hline \\hline GPT-J & 16.3 & -7.2 & 18.6 & -7.4 & **83.0** & **7.3** \\\\ \\hline FT & **100.0** & **99.9** & **96.6** & **71.0** & 10.3 & -50.7 \\\\ FT+L & 99.6 & 95.0 & 47.9 & 30.4 & 78.6 & 6.8 \\\\ MEND & 97.4 & 71.5 & 53.6 & 11.0 & 53.9 & -6.0 \\\\ ROME & **99.9** & **99.4** & **99.1** & **74.1** & 78.9 & 5.2 \\\\ PROMPT & 99.7 & 80.9 & 91.0 & 32.9 & 37.9 & -2.8 \\\\ IKE (w/ 32 demonstrations) & **100.0** & 91.7 & 95.2 & 64.5 & 77.0 & **35.2** \\\\ IKE (w/o paraphrases) & **100.0** & - & 73.8 & – & 83.4 & – \\\\ IKE (w/o neighbors) & **100.0** & – & 99.8 & – & 11.5 & – \\\\\n' +
      '**Larimar-6B** & 99.6 & 96.0 & 76.5 & 22.4 & **80.2** & 3.9 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 기준선과 라리마를 비교하는 CounterFact 데이터 세트에 대한 단일 사실 편집 성능. 상위 2개의 최상의 시스템이 강조 표시됩니다. 다른 방법들과 달리, 라리마는 메모리-조건 디코딩을 갖는 동적 메모리 업데이트들을 사용하고, 편집 샘플들(ROME) 상의 트레이닝(FT, FT+L, MEND) 또는 트레이싱 플러스 디코더 업데이트(ROME) 또는 코퍼스로부터 검색된 (파라프레이즈된) 편집들 및 이웃 샘플들의 컨텍스트 내 시연들(IKE)을 필요로 하는 방법들과는 대조적으로, 편집 샘플들에 대한 그래디언트 업데이트를 필요로 하지 않는다.\n' +
      '\n' +
      '달리 언급되지 않는 한, 스코프 검출기. 자세한 내용은 부록을 참조하십시오.\n' +
      '\n' +
      '또한 읽기 이해를 통한 관계 추출을 위한 QA 데이터 세트인 ZsRE 벤치마크(Levy et al., 2017)에서 Larimar를 평가하였으며, 그 결과는 표 12의 부록에 표시되어 있다. GPT-2 XL 기반 기준선에 대한 성능 점수는 Meng et al., 2022에서 인용된 반면 GPT-J에 대한 ROME의 성능은 우리가 독립적으로 추정했다. 이 평가는 CounterFact 평가와 달리 \\(\\mathbb{I}[(o^{*}=\\text{argmax}_{\\text{o}}\\mathbb{P}[o]]]\\의 점수를 매기기 위해 정확한 일치 카운트를 사용한다. 기준선과 비교하여 라리마는 ZsRE에서 효과적인 편집 및 유사한 이웃 특이성을 보여주며, 약간 더 낮은 일반화로 GPT-2 및 GPT-J 디코더에 걸쳐 일관된 결과를 유지하여 모델 진단 편집 기능을 강조한다.\n' +
      '\n' +
      '### 순차적인 사실 편집\n' +
      '\n' +
      '다중 순차 편집 후 이전 편집을 잊는 문제를 해결하는 (Hartvigsen et al., 2022)의 설정에 따라 라리마의 순차 편집 수행 능력을 평가했다. 하트비겐 등 사전 학습된 언어 모델(GPT2-XL)로 키-값 쌍의 편집 코드북을 업데이트하기 위해 어댑터를 통합한 연속 편집 방법을 도입하여 순차 편집 시 메모리 보존을 보여준다. 우리는 테스트를 위해 ZsRE 검증 데이터 세트에서 각각 5개의 재구문이 있는 200개의 사실의 하위 집합이 선택되는 이 실험 설정에 라리마를 적응시킨다. Larimar에서는 Eq를 통해 전역 메모리를 업데이트하여 순차적인 편집을 처리한다. (4) 다시 들어오는 편집에 대한 그라디언트 기반 업데이트가 필요하지 않습니다. 각각의 편집에 대해, 대응하는 답변과 연결된 재구문 질의의 인코딩은 메모리에 기록된다. Rarimar의 성능을 GRACE와 비교하여 평가하였다. Rarimar의 평균 F1 스코어인 편집 유지율(ERR)은 기록된 각 사실에 대해 인코딩된 쿼리\\(\\mathbf{Z}_{\\mathrm{query}}\\)으로 메모리에 질의할 때 1000번의 순차 편집 후 평균 F1 스코어이다. 라리마르는 질문-답변 데이터에 대해 세밀하게 조정되지 않는다; 대신에, 우리는 각각의 질문-답변 쌍을 메모리에 사실로서 기록하고 원래의 질문으로 메모리에 질의한다. 우리는 별도의 언어 모델을 사용하여 위키텍스트의 1000개의 무작위 테스트 샘플에 대해 라리마르 디코더의 복잡성을 평가하여 테스트 유지율(TRR)에 대해 보고한다. 이에 비해 기준선 모델은 NQ 데이터의 1000개 무작위 샘플의 평균 F1 점수로부터 TRR을 계산한다. 결과는 원래 테스트 세트 성능을 유지하면서 라리마의 GRACE와 유사한 ERR 성능을 보여준다. 특히, 라리마르-1.3B는 GPT-2 XL에서 GRACE보다 약 10배 이상 빠른 편집 속도를 달성한다.\n' +
      '\n' +
      '또한 GRACE와 비교하여 라리마르의 일반화를 재구문 프롬프트로 평가했다. 우리는 (i) 각각 10개의 변형을 가진 1000개의 ZsRE 팩트로 구성된 데이터 세트를 편집 및 보류 세트로 나누고 (ii) 더 많은 재구문과 더 적은 (\\(\\approx 500\\)) ZsRE 팩트로 구성된 편집/보류 데이터 세트를 모두 사용한다. 그림 3에 묘사된 우리의 분석은 동일한 데이터 세트의 GRACE와 비교하여 편집 세트를 사용한 메모리 쓰기 수에 대한 홀드아웃 세트의 평균 F1 점수를 조사한다.2 라리마르는 다가오는 편집에 대한 지식이 없기 때문에 거의 0에 가까운 F1로 시작하며, 대조적으로 GRACE는 편집 세트에 대한 훈련에서 사전 지식을 가지고 있다. 편집 순서가 커짐에 따라 라리마는 600여 개의 편집에서 GRACE의 일반화 성능을 능가한다.\n' +
      '\n' +
      '각주 2: 우리는 T5의 블록 4를 편집하기 위해 \\(\\epsilon_{\\mathrm{init}}=3.0\\)으로 GRACE를 사용한다(Hartvigsen et al., 2022).\n' +
      '\n' +
      '이 실험에서 우리는 \\(K=1000\\)을 사용하여 기록할 사실의 수에 비례하는 메모리 크기를 설정한다. 또한 읽기 및 쓰기 가중치를 계산하기 위한 대안적인 방법(부록 E 참조)을 확인하였는데, 가우시안 컨벌루션(Gaussian Convolution)을 사용하여 가장 유사한 내용에 해당하는 각 인코딩 \\(\\mathbf{z}\\)을 기준 메모리 \\(\\mathbf{M}^{(\\mathrm{ref})}\\)의 메모리 위치(들)에 저장하고, 사실당 재구문의 수가 상대적으로 적은 경우 (Pham et al., 2021)의 의사 역법보다 더 나은 성능을 보였다(부록 E 참조).\n' +
      '\n' +
      '### Selective Forgetting\n' +
      '\n' +
      '이 절의 목적은 작성된 \\(N\\) 사실에서 특정 사실을 선택적으로 지울 수 있는지 확인하는 것이다.\n' +
      '\n' +
      '그림 2: 반사실 데이터 세트에 대한 일괄 편집 정확도. 기준 성능들은 (Meng et al., 2023)로부터 취해진다. Green: MEMIT, Orange: ROME, Magenta: MEND, Black: Larimar-6B.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r} \\hline \\hline\n' +
      '**Editor** & **Test Retention Rate** & **Edit Retention Rate** \\\\ \\hline MEND & 0.25 & 0.27 \\\\ GRACE & 0.69 & 0.93 \\\\\n' +
      '**Larimar-1.3B** & 14.6* & **0.97** \\\\ Larimar-6B & 15.9* & 0.92 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: ZsRE 데이터 세트에 대한 순차적 편집, 라리마르가 오래된 편집을 잊지 않는다는 것을 보여준다. *우리는 별도의 언어 모델에 의해 추정된 위키텍스트에 대한 복잡성을 라리마에 대한 테스트 유지율로 보고하는 반면, NQ 테스트 세트 상의 평균 F1은 GPT2-XL 상의 MEND 및 GRACE에 대해 보고된다(Hartvigsen et al., 2022).\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:7]\n' +
      '\n' +
      '### 긴 입력 문맥에 대한 일반화\n' +
      '\n' +
      '우리는 기초 디코더 사전 훈련 코퍼스에 존재하지 않는 데이터를 사용하여 긴 컨텍스트로 팩트 리콜을 수행한다. 이를 위해 2021년, 2022년, 2023년 CNN Fast Facts(CNN, 2023)로부터 사실들을 선별하였다.\n' +
      '\n' +
      '입력된 텍스트를 Larimar의 학습 문맥 윈도우의 범위 내에 있는 \\(T\\) 청크들로 나누고, 이 청크들 각각을 별도의 메모리 \\(M_{i},i=1..T\\)에 저장한다. 질의가 주어지면, 우리는 이러한 각각의 기억에서 주소를 지정하고 읽는다. 그런 다음 이러한 메모리로부터의 판독은 연속적인 메모리의 기초를 형성하고, 이어서 조회되고 다시 판독된다. 이 프로세스는 최종 메모리에서의 판독 횟수가 라리마의 입력 트레이닝 컨텍스트 윈도우와 유사할 때까지 계속된다. 잠재 기억 공간에서 이러한 재귀적 탐색과 판독을 사용하여 새로운 상위 수준의 메모리를 구성하는 것은 상대적으로 작은 에피소드 길이에 대해 훈련된 라리마르의 메모리로 긴 컨텍스트를 처리하기 위해 수행된다. 최종 후계자 메모리에서 검색된 \\(Z_{r}\\)은 복호기로 전달되어 응답을 예측한다. 기억 위계는 해마에서도 발견되고 학습에 연루된 것으로 생각된다는 점에 유의해야 한다(Collin et al., 2015).\n' +
      '\n' +
      '표 6은 더 긴 훈련 컨텍스트로 훈련된 대부분의 경쟁 기준 LLM 중 일부와 비교하여도 라리마의 리콜 성능이 입력 컨텍스트 길이가 증가함에 따라 크게 저하되지 않음을 보여준다. 또한 메모리-증강 모델인 슈퍼사이징 트랜스포머(Klett and Ahle, 2023)와 비교하였으나, 메모리-조건 생성을 수행하도록 훈련되지 않았기 때문에 경쟁적 리콜 성능을 보여주지 못했다. 잠재 공간에서의 메모리 처리로 인해 Larimar는 KV 캐시 토큰 계산 횟수 측면에서 베이스라인 방법에 비해 효율적이다. 128개의 사실 사례에 대한 실험은 Larimar가 메모리에서 읽는 데 필요한 평균 시간이 Mistral7b 기본 모델의 경우 1.44에 비해 0.36임을 보여준다.\n' +
      '\n' +
      '컨텍스트로부터 복사를 배우는 것은 트랜스포머의 인상적인 언어 모델링 및 다른 능력의 기초가 되는 중요한 측면으로 남아 있다(Devlin et al., 2018; Raffel et al., 2020; Olsson et al., 2022). 상태 공간 모델들과 같은 비-관심 기반 아키텍처들을 갖는 LLM들은 종종 언어 모델링에서의 트랜스포머들을 과소수행한다(Gu et al., 2022; Gu and Dao, 2023). 이는 트랜스포머들과 비교할 때, 적어도 부분적으로 컨텍스트로부터 카피할 수 없는 것뿐만 아니라 더 긴 컨텍스트들로 일반화할 수 없는 것에 기인한다(Jelassi et al., 2024). 이러한 조사는 하이브리드 아키텍처에 대한 연구를 촉진했다. 여기에 제시된 결과는 라리마르에서와 같이 계층적 메모리 모델과 생성 사전 훈련된 변압기를 결합하는 것이 그 방향으로 유망한 경로가 될 수 있음을 시사한다. Larimar에서 디코더를 갖는 고정된 크기의 잠재 메모리의 종단간 트레이닝은 디코더에 명시적 상태를 추가하여 디코딩을 제어하는 것을 돕는 쓰기를 하고, 따라서 일반화된 방식으로 컨텍스트로부터 진실된 복사를 허용한다. 메모리 컨트롤은 또한 정보 유출 방지뿐만 아니라 실시간 지식 편집을 제공합니다. 디코딩하는 동안 메모리 판독에 참석하는 것은 각 토큰을 예측하기 위해 \\(O(1)\\) 메모리를 사용하여 메모리와 계산상의 이점을 제공한다.\n' +
      '\n' +
      '##6 관련 사항\n' +
      '\n' +
      '메모리-증강 NNsExternal memory augmented neural networks (MANNs)는 생성 태스크, 언어 모델링, 장기 계획 및 샘플-효율적인 RL 등에서 향상된 성능을 보여주는 입력 데이터의 장기 의존성을 더 잘 학습하는 것을 목표로 변환기 이전 시대에 이미 제안되었다(웨스턴 등, 2014; 그레이브 등, 2014; 밀러 등, 2016). MANN은 순환 신경망에 훈련 가능한 슬롯 기반 메모리를 추가한다. 어텐션 기반 판독 메커니즘은 일반적으로 메모리 콘텐츠의 가중 평균을 계산하는 데 사용된다. 이 메커니즘은 훈련 데이터에서 추정되므로 새로운 데이터로 일반화할 수 있는 방법은 불분명하다. 또는, Kanerva의 희소 분산 메모리 모델(Kanerva, 1988)에서 영감을 받은 Kanerva Machine(Wu et al., 2018)은 메모리를 생성 모델에서 전역 잠재 변수로 보고 메모리 종속 데이터 사전 및 학습 가능한 주소를 학습하는 것을 목표로 한다. 이 프레임워크에서, 메모리 업데이트 및 읽기/쓰기는 베이지안 추론으로서 고려되며, 즉, 새로운 데이터가 도착함에 따라 사후 파라미터가 업데이트된다. KM 및 그 후계자(Wu et al., 2018; Ramapuram et al., 2022; Pham et al., 2021)는 이러한 조건부 생성 메모리 모델이 변량 오토인코더(Kingma and Welling, 2013) 및 메모리 네트워크(Bornschein et al., 2017)에 비해 이미지 재구성, 노이즈 제거 및 생성 태스크에 대해 더 나은 성능을 제공한다는 것을 보여준다. 그러나 우리가 아는 한 이것은 이러한 모델이 LLM에 어떻게 적응하고 지식 업데이트를 도울 수 있는지 조사하는 첫 번째 보고서이다.\n' +
      '\n' +
      '트랜스포머는 장기 메모리에 액세스하고 업데이트하는 데 어려움을 겪는다(Fan et al., 2021). 더 나은 성능을 위해 입력 컨텍스트 길이를 확장하려는 노력은 내재된 모델 지식을 외부 사실과 통합하는 문제를 직면하고 견고성이 결여된다(Li et al., 2022; Liu et al., 2023). 외부, 미분 불가능한 메모리 및 k-최근접 이웃(kNN) 주의를 갖는 변압기를 증강하는 것은 추가적인 컨텍스트를 활용하여 언어 모델링을 개선하는 데 있어 가능성을 보여주었다(Grave et al., 2017; Khandelwal et al., 2019). 그러나, kNN-증강 모델들은 디코딩 동안 메모리를 제어하는데 있어서 어려움에 직면하여, 인코딩된 지식과 실시간 정보 사이의 충돌로 인해 사실들을 업데이트하는 데 어려움을 초래한다(Li et al., 2022; Liu et al., 2023; Zhu et al., 2020).\n' +
      '\n' +
      '편집 접근법의 포괄적인 조사를 위한 모델 편집을 참조한다(Yao et al., 2023; Zhang et al., 2024; Wang et al., 2023b). 편집 방법은 크게 \'Recognition Phase\', \'Association Phase\' 및 \'Mastery Phase\'(Zhang et al., 2024)의 세 가지로 분류할 수 있다. "인지 단계\'-타겟팅 방법"은 유사한 예제의 문맥 내 시연(Zheng et al., 2023)을 통해 또는 편집에 대한 외부 모델을 트레이닝함으로써 LLM의 정확한 사실을 출력하는 것을 돕기 위해 올바른 문맥을 시연하는 것을 고려한다(Mitchell et al., 2022). \'연관 단계\' 관련 편집 방법은 패치(추가 및 트레이닝) 오류 특정 뉴런(Huang et al., 2023)에 의해 또는 특정 LLM 계층에 편집 키-값 쌍을 저장하는 어댑터를 추가함으로써(Hartvigsen et al., 2022) 기본 LLM의 고유 파라미터를 업데이트하는 것을 고려한다. \'마스터리 단계\' 방법은 기본 LLM의 고유 파라미터를 업데이트하는 것을 고려한다. 예들은 정규화된 피네튜닝(Zhu et al., 2020) 및 하이퍼네트워크 기반 방법들(Mitchell et al., 2021; De Cao et al., 2021)이다. 최근 연구들은 또한 \'locate-then-edit\' 접근법을 탐구한다: (Meng et al., 2022a;b) 먼저 인과적 추적을 수행하여 숨겨진 상태들 중 어느 부분이 사실에 기인할 수 있는지를 검출하고, 이어서 업데이트된 사실에 직접 기입하기 위해 대응하는 가중치 파라미터들의 랭크-원 업데이트를 수행한다.\n' +
      '\n' +
      '현재 모델 편집 접근법은 유망한 반면(Yao et al., 2023), 높은 훈련 비용 및 새로운 데이터로 일반화하는 데 어려움이 있는 등 상당한 한계에 직면해 있다. 이러한 방법들은 광범위한 시간 및 메모리 요건으로 인해 종종 LLM(Large Language Models)을 효율적으로 업데이트할 수 없다(Mitchell et al., 2022). 또한, LLM들 내의 지식이 로컬화된다는 가정이 도전을 받았으며(Hase et al., 2023), 이는 간단한 파라미터 업데이트가 포괄적인 편집에 효과적이지 않을 수 있음을 나타낸다. LLM의 성능은 여러 편집으로 저하되어 지식 망각 및 왜곡과 같은 문제를 야기한다(Mitchell et al., 2022; Meng et al., 2023; Gupta et al., 2024; Li et al., 2023; Gu et al., 2024). 직접적인 모델 수정을 피하기 위해 외부 캐시 또는 메모리 기반 편집과 같은 대안이 제안되었지만, 구식 또는 민감한 지식을 선택적으로 잊는 데 어려움이 지속된다(Ishibashi and Shimodaira, 2023; Patil et al., 2023).\n' +
      '\n' +
      '위에서 언급한 작업과 달리, 우리는 생성 메모리로 대용량 언어 모델(LLM)을 증강하여 재교육 없이 동적 편집 및 적응을 가능하게 하는 새로운 접근 방식을 제시한다. 이는 LLM 파라미터들을 업데이트하는 전통적인 방법들(Meng et al., 2022a;b) 또는 외부 메모리들(Han et al., 2023; Hartvigsen et al., 2022)과 상이하며, 제어 Zheng et al.(2023)을 위한 다수의 시연들을 요구하지 않는다.\n' +
      '\n' +
      'Larimar의 망각 동작은 unlearning을 위한 LLMs를 미세 조정하기 위해 부정적인 예를 사용하지 않는다(Yu et al., 2023). Larimar 어느 것도 맞춤형 미세 조정(Eldan and Russinovich, 2023) 또는 추가 레이어 삽입(Chen and Yang, 2023)을 요구하지 않으며, 사실 망각에 대해 (Pawelczyk et al., 2023)과 같은 맥락 내 비학습 접근법에 대해 무료이다.\n' +
      '\n' +
      '## 7 Conclusions\n' +
      '\n' +
      '이 연구에서는 온라인 지식 적응을 위한 수단으로 동적으로 업데이트 가능하고 분산된 에피소드 메모리를 사용하여 LLM을 증강하는 것을 제안한다. 제안된 프레임워크는 메모리 조건 디코딩과 결합된 원샷 메모리 갱신 메커니즘을 이용하여 단일 팩트에서의 베이스라인에 비해 _accurate_, _precise_, _robust_ 및 _significantly faster_ 편집 성능을 보이고, 도전적인 순차 편집 실험을 수행한다. 본 논문에서는 동일한 메모리 갱신 메커니즘을 이용하여 효과적인 정보 삭제 메커니즘뿐만 아니라 _fast와 selective_ fact forgetting 동작을 가능하게 한다. 또한 라티마르의 메모리 공간에서 재귀적으로 읽음으로써 긴 입력 컨텍스트를 처리하기 위한 간단한 접근법을 제공하여 훨씬 더 큰 학습 컨텍스트 창으로 훈련된 최신 LLM과 비교할 때 라리마르가 긴 입력 컨텍스트에서 더 나은 사실 회상을 보여준다. 따라서 제안된 프레임워크는 LLM을 적응 가능한 에피소드 메모리 제어와 결합하여 실시간으로 LLM을 업데이트하는 간단하고 일반적이며 원칙적인 접근법을 제공한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c} \\hline \\hline Method & Train Context & \\(n_{fact}=64\\) & \\(n_{fact}=96\\) & \\(n_{fact}=128\\) & \\(n_{fact}=256\\) \\\\ \\hline mistral-7b (3-shot) & 8192 & **0.98** / 2655 & **0.96** / 3495 & 0.57 / 4334 & 0.42 / 7417 \\\\ gpt-neox-20b (3-shot) & 2048 & 0.52 / 2366 & 0.36 / 3193 & 0.33 / 4020 & 0.35 / 7231 \\\\ llama2-13b (3-shot) & 4096 & 0.97 / 2755 & 0.66 / 3628 & OOM & OOM \\\\ \\hline \\hline Supersizing Transformer & 2048 & 0.39 / 1462 & 0.39 / 2249 & 0.37 / 3072 & 0.37 / 6201 \\\\ Supersizing Transformer + filtering & 2048 & 0.72 / 1640 & 0.71 / 2375 & 0.70 / 3110 & 0.69 / 5809 \\\\ \\hline Larimar-1.3b & 384/2048 & 0.89 / 1565 & 0.88 / 2276 & **0.88** / 2988 & **0.86** / 5607 \\\\ Larimar-6b & 384/2048 & 0.82 / 1565 & 0.81 / 2276 & 0.81 / 2988 & 0.80 / 5607 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: FastFacts에 대한 새로운 팩트 추가 회수율. 라리마는 좋은 회상 성능을 보여주며 훈련된 것보다 훈련된 더 높은 컨텍스트 길이로 추론할 수 있다. 기준 모델은 작은 컨텍스트에서 좋은 리콜을 보여주지만 높은 컨텍스트에서는 리콜이 크게 저하된다.\n' +
      '\n' +
      '##8 광대역 효과와 윤리적인 고려사항\n' +
      '\n' +
      '본 논문은 기계 학습과 대형 언어 모델 분야의 발전을 목표로 하는 작업을 제시한다. 우리의 작업에는 많은 잠재적인 사회적 결과가 있으며, 우리가 특별히 강조해야 한다고 느끼는 것은 없다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: 언어 이해를 위한 깊은 양방향 변압기의 사전 훈련. _ arXiv preprint arXiv:1810.04805_, 2018.\n' +
      '* Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 단일 텍스트-텍스트 변환기를 이용한 전이학습의 한계점 탐색 The Journal of Machine Learning Research_, 21(1):5485-5551, 2020.\n' +
      '* Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 언어 모델은 소수의 학습자를 의미한다. _ 신경 정보 처리 시스템_, 33:1877-1901, 2020의 발전.\n' +
      '* Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 주목해 주세요 신경 정보 처리 시스템_, 30, 2017의 발전.\n' +
      '* Petroni et al. (2019) Fabio Petroni, Tim Rocktaschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 지식 기반으로서의 언어 모델? _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pages 2463-2473, 2019.\n' +
      '* Anil et al. (2022) Cem Anil, Yuhuai Wu, Anders Johan Andreassen, Aitor Lewkowycz, Vedant Misra, Vinay Venkatesh Ramasesh, Ambrose Slone, Guy Gur-Ari, Ethan Dyer, and Behnam Neyshabur. 대형 언어 모델에서 길이 일반화를 탐색합니다. Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyungyun Cho, Editors, _Advances in Neural Information Processing Systems_, 2022. URL[https://openreview.net/forum?id=zSkYVeX7Dc4](https://openreview.net/forum?id=zSkYVeX7Dc4).\n' +
      '* Kazemnejad et al. (2023) Amirhossein Kazemnejad, Inkit Padhi, Karthikeyan Natesan Ramamurthy, Payel Das, and Siva Reddy. 위치 인코딩이 변압기의 길이 일반화에 미치는 영향, 2023.\n' +
      '* Kirkpatrick et al. (2017) James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. _ Proceedings of the National Academy of sciences_, 114(13):3521-3526, 2017.\n' +
      '* Zhu et al. (2020) Chen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li, Felix Yu, and Sanjiv Kumar. 2020년 트랜스포머 모델의 메모리 수정\n' +
      '* Li et al. (2022) Daliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin Wang, Michal Lukasik, Andreas Veit, Felix Yu, and Sanjiv Kumar. 2022년, 제어 가능한 작업 메모리를 갖춘 대형 언어 모델입니다.\n' +
      '* Liu et al. (2023) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 중간에서 잃음: 언어 모델이 긴 컨텍스트를 사용하는 방법, 2023.\n' +
      '* Patil et al. (2023) Vaidehi Patil, Peter Hase, and Mohit Bansal. 민감한 정보를 lms에서 삭제할 수 있습니까? 탈출 공격을 방어하기 위한 목표물 2023년\n' +
      '* Dempsey et al. (2022) William P Dempsey, Zhuowei Du, Anna Nadtochiy, Colton D Smith, Karl Czajkowski, Andrey Andreev, Drew N Robson, Jennifer M Li, Serina Applebaum, Thai V Truong, et al. Regional synapse gain and loss accompanied memory formation in larval zebrafish. _ The Proceedings of the National Academy of Sciences_, 119(3):e2107661119, 2022.\n' +
      '* Autore et al. (2023) Livia Autore, James D O\'Leary, Clara Ortega-de San Luis, and Tomas J Ryan. 역방향 간섭에 의한 엔그램의 적응 표현 _ bioRxiv_, pages 2023-03, 2023.\n' +
      '* Blundell et al. (2016) Charles Blundell, Benigno Uria, Alexander Pritzel, Yazhe Li, Avraham Ruderman, Joel Z Leibo, Jack Rae, Daan Wierstra, and Demis Hassabis. 2016년 모델 없는 에피소드 컨트롤\n' +
      '* Lengyel and Dayan (2007) Mate Lengyel and Peter Dayan. 해마는 통제에 기여합니다 세 번째 길입니다 신경 정보 처리 시스템_, 20, 2007의 발전.\n' +
      '* Kumaran et al. (2016) Dharshan Kumaran, Demis Hassabis, and James L McClelland. 지능형 에이전트는 어떤 학습 시스템이 필요한가요? 상보 학습 시스템 이론이 업데이트되었습니다. _ 인지과학 분야의 동향_, 20(7):512-534, 2016.\n' +
      '* Sun et al. (2023) Weinan Sun, Madhu Advani, Nelson Spruston, Andrew Saxe, and James E Fitzgerald. 보완적 학습 시스템에서 일반화를 위한 메모리 구성. _ Nature neuroscience_, 26(8):1438-1448, 2023.\n' +
      '* Ramirez et al. (2020) Steve Ramirez, Xu Liu, Pei-Ann Lin, Jungghyup Suh, Michele Pignatelli, Roger L Redondo, Tomas J Ryan, and Susumu Tonegawa. 해마에서 잘못된 기억을 만들고 있어 Science_, 341(6144):387-391, 2013.\n' +
      '* Wu et al. (2018a) Yan Wu, Greg Wayne, Alex Graves, and Timothy Lillicrap. 카네르바 기계: 생성 분산 메모리, 2018a.\n' +
      '* Pham et al. (2021) Kha Pham, Hung Le, Man Ngo, Truyen Tran, Bao Ho, and Svetha Venkatesh. 생성 유사 역 메모리입니다. _International Conference on Learning Representations_, 2021.\n' +
      '* Meng et al. (2022a) Kevin Meng, David Bau, Alex Andonian, and Yoatan Belinkov. 사실적 연관을 gpt. _에서 위치 지정 및 편집 신경 정보 처리 시스템_, 35:17359-17372, 2022a에서의 발전.\n' +
      '* Hartvigsen et al. (2022) Thomas Hartvigsen, Swami Sankaranarayanan, Hamid Palangi, Yoon Kim, and Marzyeh Ghassemi. 유연성을 갖는 노화: 이산 키-값 어댑터를 사용한 평생 모델 편집 arXiv preprint arXiv:2211.11031_, 2022.\n' +
      '* Wang et al. (2023a) Peng Wang, Ningyu Zhang, Xin Xie, Yunzhi Yao, Bozhong Tian, Mengru Wang, Zekun Xi, Siyuan Cheng, Kangwei Liu, Guozhou Zheng, and Huajun Chen. Easyedit: 대용량 언어 모델을 위한 사용하기 쉬운 지식 편집 프레임워크, 2023a.\n' +
      '* Kingma and Welling (2013) Diederik P Kingma and Max Welling. 자동 인코딩 변량 베이지안 arXiv preprint arXiv:1312.6114_, 2013.\n' +
      '* Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever 등 언어 모델들은 비감독 멀티태스크 학습자들이다. _ OpenAI blog_, 1(8):9, 2019.\n' +
      '* Merity et al. (2016) Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 포인터 센티넬 혼합 모델 2016년\n' +
      '* Meng et al. (2023) Kevin Meng, Arnab Sen Sharma, Alex J Andonian, 요나탄 Belinkov, and David Bau. 변압기의 메모리를 대량 편집합니다. _The Eleventh International Conference on Learning Representations_, 2023.\n' +
      '* Mitchell et al. (2022) Eric Mitchell, Charles Lin, Antoine Bosselut, Christopher D Manning, and Chelsea Finn. 축척에서 메모리 기반 모델 편집 _International Conference On Machine Learning, Vol 162_. 2022년 JMLR-JOURNA MACHINE 학습 연구\n' +
      '* Yao et al. (2023) Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, and Ningyu Zhang. 대형 언어 모델 편집: 문제, 방법 및 기회. _ arXiv preprint arXiv:2305.13172_, 2023.\n' +
      '* Zheng et al. (2023) Ce Zheng, Lei Li, Qingxiu Dong, Yuxuan Fan, Zhiyong Wu, Jingjing Xu, 및 Baobao Chang. 우리는 상황 내 학습에 의해 사실적 지식을 편집할 수 있는가? 2023년.\n' +
      '* Levy et al. (2017) Omer Levy, Minjun Seo, Eunsol Choi, and Luke Zettlemoyer. 독해력을 통한 제로샷 관계 추출 arXiv preprint arXiv:1706.04115_, 2017.\n' +
      '* CNN(2023) CNN. 2023 in review fast facts, 2023. URL: \\(\\backslash\\)[https://www.cnn.com/2023/11/13/us/2023-in-review-fast-facts/index.html](https://www.cnn.com/2023/11/13/us/2023-in-review-fast-facts/index.html)\n' +
      '* Collin et al. (2015) Silvy HP Collin, Branka Milivojevic, and Christian F Doeller. 기억 계층은 인간의 해마 장축에 매핑된다. _ Nature neuroscience_, 18(11):1562-1564, 2015.\n' +
      '* Klett and Ahle (2023) Phoebe Klett and Thomas Ahle. 변압기 초속화: 넝마를 넘어 확장마인드가 늘어납니다. Normal Blog, 2023. URL: [https://blog.normalcomputing.ai/posts/2023-09-12-supersizing-transformers/supersizing-transformers.html](https://blog.normalcomputing.ai/posts/2023-09-12-supersizing-transformers/supersizing-transformers.html)\n' +
      '* Olsson 등(2022) Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2022년, 상황 학습 및 유도 헤드입니다.\n' +
      '* Gu et al. (2022) Albert Gu, Karan Goel, and Christopher Re. 2022년, 구조화된 상태 공간으로 긴 시퀀스를 효율적으로 모델링합니다.\n' +
      '* 구와 다오(2023) 알버트 구와 트리 다오. Mamba: 선택적 상태 공간을 갖는 선형-시간 시퀀스 모델링, 2023.\n' +
      '* Jelassi et al. (2024) Samy Jelassi, David Brandfonbrener, Sham M. 카케이드, 이란 말라크 나를 따라해라: 트랜스포머는 2024년 복사에서 주 우주 모델보다 낫다.\n' +
      '* Weston et al.(2014) Jason Weston, Sumit Chopra, and Antoine Bordes. 메모리 네트워크. _ ArXiv preprint arXiv:1410.3916_, 2014.\n' +
      '* Graves et al. (2014) Alex Graves, Greg Wayne, and Ivo Danihelka. 신경 튜링 기계요 arXiv preprint arXiv:1410.5401_, 2014.\n' +
      '* Miller et al. (2016) Alexander Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason Weston. 2016년, 문서를 직접 읽기 위한 키 값 메모리 네트워크.\n' +
      '* Kanerva (1988) Pentti Kanerva. _ 희소 분산 메모리_. 1988년 MIT 기자요\n' +
      '* Wu et al. (2018) Yan Wu, Greg Wayne, Karol Gregor, and Timothy Lillicrap. 생성 기억을 위한 어트랙터 역학 학습, 2018b.\n' +
      '\n' +
      '* Ramapuram et al.(2022) Jason Ramapuram, Yan Wu, and Alexandros Kalousis. Kanerva++: Kanerva 머신을 차별화 가능한 로컬 블록 할당 잠재 메모리로 확장, 2022.\n' +
      '* Bornschein et al. (2017) Jorg Bornschein, Andriy Mnih, Daniel Zoran, and Danilo J. Rezende. 생성 모델에서 가변 메모리 어드레싱, 2017.\n' +
      '* Fan et al. (2021) Angela Fan, Thibaut Lavril, Edouard Grave, Armand Joulin, and Sainbayar Sukhbaatar. 2021년 피드백 메모리로 변압기의 몇 가지 한계를 해결합니다.\n' +
      '* Grave et al. (2017) Edouard Grave, Moustapha Cisse, and Armand Joulin. 개방형 어휘를 가진 온라인 언어 모델링을 위한 무한 캐시 모델, 2017.\n' +
      '* Khandelwal et al. (2019) Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. 암기를 통한 일반화: 최근접 이웃 언어 모델_ ArXiv preprint arXiv:1911.00172_, 2019.\n' +
      '* Zhang et al. (2024) Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuanheng Ni, et al. _ arXiv preprint arXiv:2401.01286_, 2024.\n' +
      '* Wang et al. (2023b) Song Wang, Yaochen Zhu, Haochen Liu, Zaiyi Zheng, Chen Chen, and Junddong Li. 대형 언어 모델에 대한 지식 편집: 설문 조사, 2023b.\n' +
      '* Huang et al. (2023) Zeyu Huang, Yikang Shen, Xiaofeng Zhang, Jie Zhou, Wenge Rong, and Zhang Xiong. 트랜스포머-패처: 하나의 뉴런의 가치가 있는 하나의 실수. _The Eleventh International Conference on Learning Representations_, 2023. URL[https://openreview.net/forum?id=4oYUGeGBPm](https://openreview.net/forum?id=4oYUGeGBPm).\n' +
      '* Mitchell et al. (2021) Eric Mitchell, Charles Lin, Antoine Bosselt, Chelsea Finn, and Christopher D Manning. 축척에서 빠른 모델 편집 arXiv preprint arXiv:2110.11309_, 2021.\n' +
      '* De Cao et al. (2021) Nicola De Cao, Wilker Aziz, and Ivan Titov. 언어 모델에서 사실 지식을 편집합니다. _ arXiv preprint arXiv:2104.08164_, 2021.\n' +
      '* Meng et al. (2022b) Kevin Meng, Arnab Sen Sharma, Alex Andonian, 요나탄 Belinkov, and David Bau. 변압기의 메모리를 대량 편집하는 것 arXiv preprint arXiv:2210.07229_, 2022b.\n' +
      '* Hase et al. (2023) Peter Hase, Mohit Bansal, Been Kim, and Asma Ghandeharioun. 로컬리제이션이 편집에 도움이 되나요? 인과관계 기반 현지화 대 놀라운 차이. 언어 모델의 지식 편집. _30-7th Conference on Neural Information Processing Systems_, 2023. URL[https://openreview.net/forum?id=EldbU1Ztbd](https://openreview.net/forum?id=EldbU1Ztbd).\n' +
      '* Gupta et al. (2024) Akshat Gupta, Anurag Rao, and Gopala Anumanchipalli. 규모의 모델 편집은 점진적이고 치명적인 망각으로 이어집니다. _ arXiv preprint arXiv:2401.07453_, 2024.\n' +
      '* Li et al. (2023) Zhoubo Li, Ningyu Zhang, Yunzhi Yao, Mengru Wang, Xi Chen, and Huajun Chen. 2023년 대형 언어 모델에 대한 지식 편집의 함정을 공개합니다.\n' +
      '* Gu et al. (2024) Jia-Chen Gu, Hao-Xiang Xu, Jun-Yu Ma, Pan Lu, Zhen-Hua Ling, Kai-Wei Chang, and Nanyun Peng. 모델 편집은 2024년 대형 언어 모델의 일반적인 능력에 타격을 줄 수 있다.\n' +
      '* Ishibashi and Shimodaira (2023) Yoichi Ishibashi and Hidetoshi Shimodaira. 대형 언어 모델의 지식 위생, 2023년\n' +
      '* Han et al. (2023) Xiaoqi Han, Ru Li, Hongye Tan, Wang Yuanlong, Qinghua Chai, and Jeff Pan. 팩트 검색을 통해 순차적 모델 편집을 개선합니다. Houda Bouamor, Juan Pino, and Kalika Bali, editoritors, _Findings of the Association for Computational Linguistics: EMNLP 2023_, pages 11209-11224, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-emnlp.749. URL[https://aclanthology.org/2023.findings-emnlp.749](https://aclanthology.org/2023.findings-emnlp.749)\n' +
      '* Yu et al. (2023) Charles Yu, Sullam Jeoung, Anish Kasi, Pengfei Yu, 및 Heng Ji. 구배를 분할하여 언어 모델의 편향을 학습하지 않습니다. _Findings of the Association for Computational Linguistics: ACL 2023_, pages 6032-6048, 2023.\n' +
      '* 엘단과 러시노비치 (2023) 로난 엘단과 마크 러시노비치. 해리 포터가 누구죠? 2023년 llms에서 근사 미학습\n' +
      '*첸과 양(2023) 자오첸과 디이양. 잊고 싶은 것을 학습하지 않음: llms에 대한 효율적인 학습 해제 arXiv preprint arXiv:2310.20150_, 2023.\n' +
      '* Pawelczyk et al. (2023) Martin Pawelczyk, Seth Neel, and Himabindu Lakkaraju. 인-컨텍스트 언러닝: 언어 모델은 적은 수의 샷 언러닝자들이다. _ arXiv preprint arXiv:2310.07579_, 2023.\n' +
      '* Dai et al. (2021) Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. 미리 훈련된 변압기의 지식 뉴런 _ arXiv preprint arXiv:2104.08696_, 2021.\n' +
      '\n' +
      'A Baselines\n' +
      '\n' +
      'FTFine-Tuning(FT)은 훈련 손실을 최적화하기 위해 한 층에서 \\(mlp_{proj}\\)의 가중치를 조정하는 데 초점을 맞추어 조기 정지를 갖는 Adam 최적화를 사용한다.\n' +
      '\n' +
      'FT+LConstrained fine-tuning (FT+L)은 Zhu et al., 2020에서와 같이, 저자들은 각 기울기 단계에서 \\(\\epsilon\\) 범위를 초과하지 않도록 가중치를 클램핑하여 \\(L_{\\infty}\\) norm 제약조건을 적용한다. GPT-2는 층 0과 \\(\\epsilon=5\\times 10^{-4}\\), GPT-J는 \\(\\epsilon=5\\times 10^{-5}\\)을 선택하였다.\n' +
      '\n' +
      'Kn이것은 (Dai et al., 2021)에 의한 방법으로서, 그래디언트 기반 속성들을 통해 지식 표현과 연관된 뉴런들을 선택한 다음, 스케일링된 임베딩 벡터들을 추가함으로써 그 뉴런들에 대응하는 행들에서 MLP를 수정한다.\n' +
      '\n' +
      'KeKnowledge editor(KE)(De Cao et al., 2021)는 모델에 대한 랭크-1 가중치 변화를 예측하기 위해 그래디언트 정보를 사용하는 LSTM 시퀀스 모델을 학습한다. KE-CF/KE-ZsRE는 CounterFact/ZsRE 데이터세트의 트레이닝 세트에 대해 추가로 트레이닝된 모델이다.\n' +
      '\n' +
      'MendModel Editor Networks with Gradient Decomposition (MEND)(Mitchell et al., 2021)은 파라미터들의 일부 서브세트에 대해 음의 로그 우도 그래디언트의 랭크-1 분해를 학습한다. 유사하게, MEND-CF/MEND-ZsRE는 CounterFact/ZsRE 데이터세트의 트레이닝 세트에 대해 추가로 트레이닝된 모델이다.\n' +
      '\n' +
      'Meng et al., 2022에 의해 제안된 ROME(RomeRank-One Model Editing)는 MLP 모듈을 키-밸류 스토어로 취급한다. 새로운 키-값 쌍을 추가하기 위해 ROME는 MLP의 가중치에 랭크-원 수정을 적용하여 새로운 정보를 직접 추가한다.\n' +
      '\n' +
      'IKE(IkeIn-context Knowledge Editing)(Zheng et al., 2023)는 복제, 업데이트 및 리테이닝을 포함하는 세 가지 유형의 데모 포맷팅 템플릿을 정의하며, 이 템플릿은 지식 팩트를 인컨텍스트 학습(ICL)에 의해 편집하도록 안내한다. 모델의 매개 변수가 업데이트되지 않습니다.\n' +
      '\n' +
      'IKE와 유사하게 프롬프트(Zheng et al., 2023) 그러나 단순히 새로운 사실을 LLM 프롬프트에 전치한다. 모델의 매개 변수도 업데이트되지 않습니다.\n' +
      '\n' +
      'Memit MEMIT는 팩트 추적을 통해 직접 모델 편집을 목표로 하고 그 다음 매개변수 편집을 목표로 한다. ROME의 확장된 버전으로, MLP 레이어의 시퀀스의 업데이트를 통해 많은 양의 사실 데이터를 편집할 수 있다.\n' +
      '\n' +
      '표 4의 기초선 방법으로 In-Context Learning(ICL)과 비교하기 위해, \\(N\\) 사실로 구성된 프롬프트를 사용하며, 그 중 절반은 접두사 문자열(예: "[UNKNOWN])로 표시되며, 그 다음에는 질문 및 답변의 예(모델에 대한 최종 쿼리 전에), 절반은 접두사 문자열로 표시된 사실에 해당하여 사실을 잊은 것으로 취급해야 함을 나타낸다.\n' +
      '\n' +
      '### ICL 실험으로 잊기 위한 프롬프트 예제\n' +
      '\n' +
      '아래에서는 표 4의 Llama2-13B에 사용된 \\(N=20\\) 및 \\(K=6\\)에 대한 예시적인 ICL 프롬프트를 보여준다:\n' +
      '\n' +
      'Facts:\n' +
      '\n' +
      'Gaston Palewski는 프랑스어로 글을 쓴다.\n' +
      '\n' +
      'Hermann Klaatsch의 작업 영역은 해부학이다.\n' +
      '\n' +
      '[UNKNOWN] 2분 드릴이 ESPN에 데뷔한다.\n' +
      '\n' +
      '임마누엘 월러스타인은 사회학 분야에서 일한다.\n' +
      '\n' +
      '닛산이 만든 닛산 스카이라인\n' +
      '\n' +
      '대만 시민인 펑페이페이\n' +
      '\n' +
      '미치 미는 배우로 일한다.\n' +
      '\n' +
      '안토니오 팔로미노의 인생은 마드리드에서 끝났다.\n' +
      '\n' +
      '[UNKNOWN] 영화 포럼은 맨해튼에 있다.\n' +
      '\n' +
      '[UNKNOWN] 피닉스 스카이 하버 국제공항은 피닉스에 위치해 있다.\n' +
      '\n' +
      '브루클린에 형성된 아브라함과 스트라우스\n' +
      '\n' +
      '조셉 슘페터의 활동 영역은 경제학이다.\n' +
      '\n' +
      '조지 부자의 직업은 배우이다.\n' +
      '\n' +
      '[UNKNOWN] 벨라유담은 인도에서 유래했다.\n' +
      '\n' +
      '프랑스 토박이 소피 칼레\n' +
      '\n' +
      '누나부트에서 말하는 언어는 프랑스어이다.\n' +
      '\n' +
      '[UNKNOWN] Wide Country는 NBC에 데뷔할 예정이다.\n' +
      '\n' +
      '포르피리 이바노프의 모국어는 러시아어입니다.\n' +
      '\n' +
      '키밍키에서는 핀란드를 이해해요\n' +
      '\n' +
      '파코미우스 대왕이 이집트에서 굴복했습니다.\n' +
      '\n' +
      'Input: Hermann Klaatsch의 작업영역\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r} \\hline \\hline Editor & COUNTERFACT \\\\ \\hline FT & \\(35.94\\) s \\\\ SERAC & \\(5.31\\) s \\\\ CaliNet & \\(1.88\\) s \\\\ T-Patcher & \\(1864.74\\) s \\\\ KE & \\(2.20\\) s \\\\ MEND & \\(0.51\\) s \\\\ KN & \\(225.43\\) s \\\\ ROME & \\(147.2\\) s \\\\ MEMIT & \\(143.2\\) s \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: CounterFact 벤치마크로부터 10개의 편집을 수행하기 위한 각각의 편집 방법에 대한 벽 시계 시간, (Yao et al., 2023)에 보고된 바와 같다.\n' +
      '\n' +
      '표 9 및 10에서 모델의 다양한 학습 매개변수와 아키텍처 구성요소를 변경하고 CounterFact 데이터 세트에 대한 성능을 관찰하여 라리마르에 대한 절제 결과를 제공한다. 표 9에는 GPT-2 XL 기반 모델에 대한 절제 결과가 제시되어 있다. 여기에서 우리는 세 가지 다른 훈련 구성을 조사했다.\n' +
      '\n' +
      '* C1: 에피소드 길이 6, 관측 잡음 0.0001, 2개의 에폭스에 대해 훈련됨\n' +
      '* C2: 에피소드 길이 20, 관찰 노이즈 0.000001, 4 에폭스에 대해 트레이닝됨\n' +
      '* C3: 에피소드 길이 16, 관측 잡음 0.000001, 2 에폭스에 대해 훈련됨\n' +
      '\n' +
      '본 논문에서 표 12에 보고된 모델은 구성 C3를 기반으로 하며, 또한 원본 라리마르, 스코프 검출기가 없는 라리마르 및 메모리가 없는 라리마르의 세 가지 버전의 라리마르 아키텍처를 살펴보았다. 알 수 있는 바와 같이, 구성 C3는 성능에 있어서 약간의 엣지를 가졌다. 범위 탐지기를 제거하는 효과는 이웃 점수 하락에 반영된다. 이것은 이제 모델이 프롬프트를 비제약 디코더에서 메모리 제약 디코더로 재라우팅하기 때문에 예상되는데, 여기서 메모리 영향은 메모리 내 콘텐츠와 무관한 프롬프트를 커버하기 어렵게 한다. 반면에, 메모리 모듈을 제거하면 편집 성공과 패러프레이징이 크게 감소하는데, 이는 이제 모델이 도입된 지식 사실에 대한 지식이 없기 때문에 일반적인 언어 능력은 손상되지 않고 높은 이웃 점수에 반영되어 잘 수행되기 때문이다.\n' +
      '\n' +
      '표 10에서 GPT-J 기반 모델에 대한 절제 결과는 다음의 다섯 가지 훈련 구성에 대한 결과를 나타낸다:\n' +
      '\n' +
      '* C1: 에피소드 길이 5, KL 손실 없음, 5 에폭스에 대해 트레이닝됨\n' +
      '* C2: 에피소드 길이 16, 노이즈 레벨 1e-4, 8 에폭스에 대해 트레이닝됨\n' +
      '* C3: 에피소드 길이 16, 노이즈 레벨 1e-4, KL 손실 없음, 8 에폭스에 대해 트레이닝됨\n' +
      '* C4: 에피소드 길이 8, 노이즈 레벨 1e-4, 8 에폭스에 대해 트레이닝됨\n' +
      '* C5: 에피소드 길이 8, 노이즈 레벨 1e-4, KL 손실 없음, 8 에폭스에 대해 트레이닝됨\n' +
      '\n' +
      '본 논문에서 표 2에 보고된 모델은 구성 C1을 기반으로 한다. 이전과 유사하게 스코프 검출기와 메모리 블록의 제거를 포함하는 구조적 변화를 살펴보았다. 우리는 구성 C2가 최악의 성능을 보인 반면 C1은 전반적으로 더 나은 성능을 보였다는 것을 관찰했다. 또한, 실험을 통해 스코프 검출기의 이득과 메모리 장치의 효과를 다시 확인하였다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l r r} \\hline \\hline \\multicolumn{1}{l}{**Editor**} & \\multicolumn{2}{c}{**Edit Success**} & \\multicolumn{1}{l}{**Paraphrase**} & \\multicolumn{1}{l}{**Neighborhood**} \\\\ \\hline\n' +
      '**Larimar-6B w/scope** & 99.6 & 76.5 & 80.2\\\\\n' +
      'Larimar-6B+para** & 99.6 & 82.8 & 80.6\\\\\n' +
      '**Larimar-6B+para, no scope** & 99.6 & 88.7 & 16.3 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: CounterFact 데이터셋에 대한 단일 팩트 편집 가치 평가. Larimar-6B 베이스는 메모리에 단일 사실만 포함하고 범위 내 쿼리 검출기를 사용하는 베이스라인이다. Larimar-6B +para는 평균적으로 하나의 추가 패러프레이즈된 사실에 메모리를 추가하는 버전이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l r r r r r r} \\hline \\hline \\multirow{3}{*}{**Config**} & \\multirow{3}{*}{**Editor**} & \\multicolumn{6}{c}{**Metrics**} \\\\ \\cline{3-8}  & & & **Edit Success** & & **Paraphrase** & & **Neighbor** \\\\ \\cline{3-8}  & & S & M & S & M & S & M \\\\ \\hline \\multirow{3}{*}{C1} & Larimar & 100.0 & 99.7 & 38.4 & -2.9 & 74.2 & 1.6 \\\\  & No Scope & 100.0 & 99.8 & 37.8 & -3.0 & 22.4 & -34.1 \\\\  & No Memory & 23.3 & -4.4 & 26.5 & -3.5 & 77.7 & 4.7 \\\\ \\hline \\multirow{3}{*}{C2} & Larimar & 100.0 & 99.9 & 35.2 & -3.5 & 75.4 & 2.0 \\\\  & No Scope & 100.0 & 99.9 & 33.1 & -3.6 & 26.2 & -36.2 \\\\  & No Memory & 20.6 & -4.9 & 24.5 & -4.1 & 78.9 & 5.4 \\\\ \\hline \\multirow{3}{*}{C3} & Larimar & 100.0 & 99.8 & 41.9 & 0.4 & 74.8 & 1.6 \\\\  & No Scope & 100.0 & 99.9 & 41.1 & 0.4 & 14.3 & -5.8 \\\\ \\cline{1-1}  & No Memory & 21.6 & -4.8 & 25.4 & -3.8 & 78.4 & 5.0 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 9: CounterFact dataset을 이용한 Larimar-1.3B에 대한 절제 결과\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:15]\n' +
      '\n' +
      '### 순차적인 편집 실험.\n' +
      '\n' +
      '표 3과 그림 3에 보고된 순차적 편집 실험을 위해 \\(K=1000\\)을 설정하고 고정 기준 메모리 \\(\\mathbf{M}^{(\\mathrm{ref})}\\) (섹션 3 참조)를 사용하여 읽기 및 쓰기 가중치를 계산했다.\n' +
      '\n' +
      '표 3의 경우, 기준 메모리는 1000개의 에디트 각각에 대한 프롬프트를 인코딩하여 \\(\\mathbf{M}^{(\\mathrm{ref})}\\)의 한 행에 배치함으로써 구성된다.\n' +
      '\n' +
      '그림 3의 경우, 기준 메모리는 1000개의 고유한 사실들 각각에 대한 첫 번째 프롬프트를 인코딩하여(메모리에 쓰여진 편집 세트에서 여러 개의 재구문 중) \\(\\mathbf{M}^{(\\mathrm{ref})}\\)에 하나의 행에 배치함으로써 구성된다. 따라서, Eq.에서 인코딩된 재구문 프롬프트 \\(\\mathbf{z}\\)로 메모리를 질의할 때. (7) 같은 사실에 해당하는 \\(\\mathbf{M}^{(\\mathrm{ref})}\\)에서 \\(\\mathbf{z}\\)가 행 \\(k\\)에 가장 가까우면 키 벡터 요소 \\(w_{k}\\)이 이 요소에 대해 가장 크고 다른 메모리 위치에서는 억제된다. (\\(\\alpha=10^{-3}\\)을 사용하여 참조 메모리에서 더 먼 인코딩을 강력하게 억제한다. 경험적으로, 우리는 가장 가까운 이웃 인코딩이 Eq에 의해 선택되었음을 발견했다. (7) 작은 \\(\\alpha\\)는 일반적으로 동일한 사실에 대한 인코딩된 프롬프트이며, 주로 \\(\\mathbf{M}^{(\\mathrm{ref})}\\)에서 가장 가까운 이웃 행이 다른 사실에 해당하는 경우에 더 낮은 F1 점수가 발생한다. 우리는 (Pham et al., 2021), \\(\\mathbf{w}=\\mathbf{z}(\\mathbf{M}^{(\\mathrm{ref})})^{\\dagger}\\)와 같이 읽기 및 쓰기 가중치를 계산하는 것이 사실당 재구문의 수가 상대적으로 많지 않는 한 재구문 사실(그림 3 및 표 13)에서 효과적이지 않다는 것을 발견했다.\n' +
      '\n' +
      '메모리에 기록할 때, 모델이 추가 텍스트를 생성할 가능성을 줄이기 위해, 후행 기간이 지상 진리 라벨에 추가된다. F1 점수를 평가할 때, 우리는 기간(13)에 해당하는 토큰을 (타겟 및 예측된 토큰 모두에서) 제거한다. 또한 마지막 토큰으로 생성될 때 새로운 라인 문자 \'\\(\\backslash\\)n\'에 해당하는 토큰 198을 제거한다.\n' +
      '\n' +
      '그림 5에서 우리는 그림 3과 같은 작업에서 라리마의 다른 변형을 비교한다. Eq.의 가우시안 컨볼루션 방법과 비교된다. (7), 기준 메모리 행렬 의사역학을 이용한 계산 읽기 및 쓰기 가중치, \\(\\mathbf{w}=\\mathbf{z}(\\mathbf{M}^{(\\mathrm{ref})})^{\\dagger}\\)는 511개의 ZsRE 팩트와 팩트당 \\(\\approx 20\\) phrasings의 데이터셋에서는 좋은 성능을 보였지만, \\(1000\\) ZsRE 팩트당 \\(10\\) phrasings의 데이터셋에서는 훨씬 더 나쁜 성능을 보였다. (우리는 Eq.라고 가정한다.) (7)은 데이터에 이용가능한 하나 또는 소수의 패러프레이즈가 있을 때 동일한 사실에 대한 근처의 리프레이즈 인코딩을 찾는 데 더 효과적이다.\n' +
      '\n' +
      '우리의 사실 망각 실험(표 4)에서, 우리는 각 매트릭스 요소가 무작위로 샘플링되는 간단한 참조 메모리, \\(\\mathbf{M}^{(\\mathrm{ref})}_{ij}\\sim\\mathcal{N}(0,1)\\을 사용했다. 우리는 이 선택이 재구문 프롬프트로 질의할 때 덜 효과적이라는 것을 발견했는데, 이 경우 위에서 설명한 \\(\\mathbf{M}^{(\\mathrm{ref})}\\)의 추가 구조는 동일한 사실의 다른 표현의 근처의 인코딩을 찾는 데 도움이 되지만 (표 4에서와 같이) 메모리에 기록할 때 사용되는 동일한 프롬프트로 질의할 때 충분하다는 것을 발견했다. 이 경우, 우리는 메모리에 쓰여진 사실의 프롬프트를 인코딩하여 \\(\\mathbf{W}=\\mathbff{Z}_{\\mathrm{prompt}}(\\mathbf{M}^{(\\mathrm{ref})})^{\\dagger}\\) (Eq 대신)을 사용하여 쓰기 가중치를 계산한다. (7)), 및 동일한 방식으로 판독 가중치를 계산하며, 판독 프롬프트는 리프레이징 실험에서 기입 프롬프트와 상이하다.\n' +
      '\n' +
      '마지막으로, 배치 편집 실험(그림 2)에서, 인코딩된 프롬프트 \\(\\mathbffW}=\\mathbffZ}_{\\mathrm{prompt}}(\\mathbfM}^{(\\mathrm{ref})})^{\\dagger}\\)를 사용하여 쓰기 가중치를 계산하고, 라리마르의 훈련에서 얻은 메모리 행렬에 \\(\\mathbffM}^{(\\mathrm{ref})}\\)을 설정하여 쓰기 및 읽기 가중치를 계산하였다.\n' +
      '\n' +
      '실험을 통하여 \\(\\sigma_{w}=0\\)와 \\(\\xi=0\\)을 사용하였다.\n' +
      '\n' +
      '## 리프레이즈-증강 메모리를 통한 부록 F 일반화\n' +
      '\n' +
      '또한 동일한 사실에 대한 다양한 수의 볼 수 있는 재구문을 메모리에 써서 보이지 않는 재구문에 대한 일반화에 대해 라리마르-1.3B를 평가한다. 기억에 각 \\(N_{reph}\\) 사실들에 대한 \\(N_{reph}\\) 재구문을 작성한 후, 보이지 않는 \\(N_{reph}\\) 사실들로 모델을 질의하여 재현율을 추정한다. (재구문의 순차적 편집 실험에서와 같이, 우리는 메모리에 기록된 사실에 대한 프롬프트 인코딩으로부터 구성된 참조 메모리 매트릭스를 사용한다.) 표 13에서 ZsRE 검증 세트의 샘플에 대한 지상-진실 답변의 평균 회상을 보여 보이지 않는 재구문에 대한 일반화를 보여준다. 당연히 기억 속에 더 많은 재구문이 있는 사실에 대해서는 회상이 더 높다. 더 나아가\n' +
      '\n' +
      '그림 5: 라리마의 평균 F1 점수, 읽기 및 쓰기 가중치를 계산하기 위한 다양한 선택 - Eq의 가우시안 컨볼루션을 비교한다. (7) 및 (Pham et al., 2021)의 의사 역법 - 3000개의 편집의 시퀀스에 걸쳐 ZsRE로부터 보이지 않는 재구문의 보류된 세트에 대해. (검은색 곡선은 본문의 그림 3에 나와 있다.)\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:17]\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>