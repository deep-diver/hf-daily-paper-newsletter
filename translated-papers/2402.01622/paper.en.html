<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# TravelPlanner: A Benchmark for Real-World Planning with Language Agents\n' +
      '\n' +
      ' Jian Xie\\({}^{\\spadesuit}\\)\n' +
      '\n' +
      'Kai Zhang\\({}^{\\clubsuit}\\)\n' +
      '\n' +
      'Jiangjie Chen\\({}^{\\spadesuit}\\)\n' +
      '\n' +
      'Tinghui Zhu\\({}^{\\spadesuit}\\)\n' +
      '\n' +
      'Renze Lou\\({}^{\\heartsuit}\\)\n' +
      '\n' +
      'Yuandong Tian\\({}^{\\heartsuit}\\)\n' +
      '\n' +
      'Yanghua Xiao\\({}^{\\spadesuit}\\)\n' +
      '\n' +
      'Yu Su\\({}^{\\clubsuit}\\)\n' +
      '\n' +
      '\\({}^{\\spadesuit}\\)Fudan University\n' +
      '\n' +
      'The Ohio State University\n' +
      '\n' +
      '\\({}^{\\heartsuit}\\)The Pennsylvania State University\n' +
      '\n' +
      'Meta AI\n' +
      '\n' +
      'jianxie22@m.fudan.edu.cn, shawh@fudan.edu.cn, {zhang.13253, su.809}@osu.edu\n' +
      '\n' +
      '[https://osu-nlp-group.github.io/TravelPlanner](https://osu-nlp-group.github.io/TravelPlanner)\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      'Planning has been part of the core pursuit for artificial intelligence since its conception, but earlier AI agents mostly focused on constrained settings because many of the cognitive substrates necessary for human-level planning have been lacking. Recently, language agents powered by large language models (LLMs) have shown interesting capabilities such as tool use and reasoning. _Are these language agents capable of planning in more complex settings that are out of the reach of prior AI agents?_ To advance this investigation, we propose TravelPlanner, a new planning benchmark that focuses on travel planning, a common real-world planning scenario. It provides a rich sandbox environment, various tools for accessing nearly four million data records, and \\(1,\\!225\\) meticulously curated planning intents and reference plans. Comprehensive evaluations show that the current language agents are not yet capable of handling such complex planning tasks--even GPT-4 only achieves a success rate of \\(0.6\\)%. Language agents struggle to stay on task, use the right tools to collect information, or keep track of multiple constraints. However, we note that the mere possibility for language agents to tackle such a complex problem is in itself non-trivial progress. TravelPlanner provides a challenging yet meaningful testbed for future language agents.\n' +
      '\n' +
      'Machine Learning, ICML\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      'Planning is a hallmark of human intelligence. It is an evolutionary feat built upon numerous other capacities: using various tools to iteratively collect information and make decisions, recording intermediate plans (in working memory or on a physical device) for deliberation, and exploring alternative plans by running simulations, which in turn depends on a world model (Mattar & Lengyel, 2022; Ho et al., 2022). For decades, researchers have been attempting to develop AI agents to mimic humans\' planning capability (Russell & Norvig, 2010; Georgievski & Aiello, 2015; **?**), but often in constrained settings (Campbell et al., 2002; Silver et al., 2016, 2017) because many of the cognitive substrates necessary for human-level planning have been lacking. AI agents that can work robustly in the largely unconstrained settings in which humans operate remain a distant goal.\n' +
      '\n' +
      'The advent of large language models (LLMs; OpenAI (2022; 2023); Touvron et al. (2023a,b); Jiang et al. (2023)) brings new light to this classic problem. A new generation of language agents (Su, 2023; Sumers et al., 2023; Xie et al., 2023) powered by LLMs has emerged, characterized by their capability of using language as a vehicle for thought and communication. These agents have shown interesting capabilities, such as tool use (Schick et al., 2023; Patil et al., 2023; Qin et al., 2023) and various forms of reasoning (Wei et al., 2022; Yao et al., 2022; Lewkowycz et al., 2022), potentially fulfilling the role of some of the cognitive substrates that were lacking in earlier AI agents. Researchers have therefore investigated their potential in an array of planning tasks ranging from classic planning settings like Blocksworld (Valmeekam et al., 2023) to embodied agents (Huang et al., 2022; Ichter et al., 2022; Song et al., 2023; Wang et al., 2023) and web agents (Deng et al., 2023; Zhou et al., 2023a). However, the planning settings in existing work still largely follow the conventional setting that focuses on single-objective optimization with fixed ground truths. An agent is tasked with predicting from a pre-defined set of actions, just now made by an LLM-powered agent.\n' +
      '\n' +
      '_Are language agents capable of planning in more complex yet realistic settings, closer to those in which humans operate?_ To advance this investigation, we propose TravelPlanner, a new planning benchmark that focuses on a common real-world planning scenario--travel planning. This is achallenging, time-consuming task even for humans (but most people can do it successfully, with the right tools and enough time): _1)_ Planning a multi-day itinerary is inherently _long-horizon_, involving a large number of interdependent decisions on places, lodging, transportation, dining, etc. _2)_ Travel planning involves many _constraints_, ranging from explicit constraints such as budget and various user needs to implicit commonsense constraints, e.g., people cannot teletransport to another city without using some means of transportation. _3)_ Travel planning requires strong _agency_ to proactively acquire necessary information using various tools (e.g., to search flights and restaurants) from the partially observable environment and deliberate over the collected information to further the planning while being mindful of all the explicit and implicit constraints. Planning tasks of such complexity are out of the reach of prior AI agents (Russell & Norvig, 2010).\n' +
      '\n' +
      'TravelPlanner provides a rich sandbox environment with around four million data entries crawled from the Internet that can be accessed via six tools. We also meticulously curate \\(1{,}225\\) diverse user queries (along with their reference plans), each imposing a different combination of constraints. A representative example is illustrated in Figure 1.\n' +
      '\n' +
      'We comprehensively evaluate five LLMs, such as GPT-4 (OpenAI, 2023), Gemini (G Team et al., 2023), and Mixstral (Jiang et al., 2024), and four planning strategies, such as ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023), on their capability of delivering complete plans and following constraints. The main findings are as follows:\n' +
      '\n' +
      '\\(\\bullet\\) State-of-the-art LLMs cannot handle complex planning tasks like those in TravelPlanner. GPT-4 successfully produces a plan that meets all the constraints for a few tasks (\\(0.6\\)%), while all other LLMs fail to complete any tasks.\n' +
      '\n' +
      '\\(\\bullet\\) Existing planning strategies such as ReAct and Relexion, which may be effective for simpler planning settings, are insufficient for the multi-constraint tasks in TravelPlanner. They often fail to convert their reasoning into the right actions correctly and keep track of global or multiple constraints. Language agents need more sophisticated planning strategies to approach human-level planning.\n' +
      '\n' +
      '\\(\\bullet\\) Further analyses reveal many common failure modes of existing language agents, such as argument errors in tool use, being trapped in dead loops, and hallucinations.\n' +
      '\n' +
      'Although most of our findings lean negatively toward the current language agents, we should note that the mere possibility for an artificial agent to tackle such a complex task is non-trivial progress in itself. TravelPlanner provides a challenging yet meaningful testbed for future agents to hill-climb toward human-level planning in complex settings.\n' +
      '\n' +
      'Finally, a silver lining: while our well-trained human annotators averagely take \\(12\\) minutes to manually annotate a plan, a language agent can produce a plan in just \\(1{-}2\\) minutes automatically. Perhaps one day, language agents will become capable enough to help automate away many of such tedious tasks for us.\n' +
      '\n' +
      'Figure 1: Overview of TravelPlanner. Given a query, language agents are tasked with employing various search tools to gather information. Based on the collected information, language agents are expected to deliver a plan that not only satisfies the user’s needs specified in the query but also adheres to commonsense constraints.\n' +
      '\n' +
      ' \n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:3]\n' +
      '\n' +
      '\\(\\bullet\\)**Commonsense Constraints**: Agents, functioning in real-world and serving humans, should consider commonsense when designing plans. For instance, repeatedly visiting the same attraction is not typical. To evaluate agents\' understanding and utilization of commonsense during planning, we include the commonsense constraint in TravelPlanner.\n' +
      '\n' +
      '\\(\\bullet\\)**Hard Constraints**: A crucial ability for agents is to effectively satisfy personalized user needs. To evaluate this, TravelPlanner incorporates various user needs, such as budget constraints. These user needs are termed hard constraints. The hard constraint measures the agent\'s generalization ability with regard to different user needs.\n' +
      '\n' +
      '### Benchmark Construction Pipeline\n' +
      '\n' +
      'This section outlines the construction pipeline of TravelPlanner, which involves the following steps: _1)_ Environment and evaluation setup. _2)_ Diverse travel query design. _3)_ Reference plan annotation. _4)_ Quality check.\n' +
      '\n' +
      'Environment Setting.In TravelPlanner, we create a static and closed sandbox environment for consistent and unbiased evaluations. This setup ensures that all agents access the same unchanging information from our static databases, avoiding the variability and potential biases introduced by dynamic data. To offer various travel options that align with the real world, we ensure the database for each tool in TravelPlanner contains rich information. The database size of each tool is listed in Table 2. For more tool details, please refer to Appendix A.2 and A.3. Additionally, agents are instructed to use the "NotebookWrite" tool to record necessary information for planning. This tool is integrated to evaluate agents\' working memory management and prevents maximum token limit caused by context accumulation.\n' +
      '\n' +
      'Query Construction.To create diverse queries for TravelPlanner, we begin with several fundamental elements, including departure city, destination, and specific date range, randomly chosen to form the skeleton of each query. Subsequently, we adjust the duration of travel and the number of hard constraints to create different levels of complexity.\n' +
      '\n' +
      'The duration of the travel--\\(3\\), \\(5\\), or \\(7\\) days--determines the number of cities included in the plan. Specifically, \\(3\\)-day plans focus on one city, while \\(5\\) days and \\(7\\) days involve visiting one randomly chosen state, with trips to \\(2\\) cities for the \\(5\\)-day plans and \\(3\\) cities for the \\(7\\)-day plans, respectively. A greater number of days requires more frequent tool usage by language agents, thus increasing the difficulty of managing the long-horizon aspect of planning. The uncertain destination challenges agents to decide on multiple cities, where they must consider factors such as inter-city connectivity.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l} \\hline\n' +
      '**Constraint** & **Description** \\\\ \\hline \\hline \\multicolumn{3}{c}{_Environment Constraint_} \\\\ \\hline Unavailable Transportation & There is no available flight or driving information between the two cities. \\\\ Unavailable Attractions & There is no available attraction information in the queried city. \\\\ \\hline \\hline \\multicolumn{3}{c}{_Commonsense Constraint_} \\\\ \\hline Within Sandbox & All information in the plan must be within the closed sandbox; otherwise, it will be considered a hallucination. \\\\ Complete Information & No key information should be left out of the plan, such as the lack of accommodation during travel. \\\\ Within Current City & All scheduled activities for the day must be located within that day’s city(s). \\\\ Reasonable City Route & Changes in cities during the trip must be reasonable. \\\\ Diverse Restaurants & Restaurant choices should not be repeated throughout the trip. \\\\ Diverse Attractions & Attraction choices should not be repeated throughout the trip. \\\\ Non-conf. Transportation & Transportation choices within the trip must be reasonable. For example, having both “self-driving” and “flight” would be considered a conflict. \\\\ Minimum Nights Stay & The number of consecutive days spent in a specific accommodation during the trip must meet the corresponding required minimum number of nights’ stay. \\\\ \\hline \\hline \\multicolumn{3}{c}{_Hard Constraint_} \\\\ \\hline Budget & The total budget of the trip. \\\\ Room Rule & Room rules include “No parties”, “No smoking”, “No children under 10”, “No pets”, and “No visitors”. \\\\ Room Type & Room types include “Entire Room”, “Private Room”, “Shared Room”, and “No Shared Room”. \\\\ Cuisine & Cuisines include “Chinese”, “American”, “Italian”, “Mexican”, “Indian”, “Mediterranean”, and “French”. \\\\ Transportation & Transportation options include “No flight” and “No self-driving”. \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      'Table 1: Constraint description. The environment constraints are manifested through the feedback received from the environment, assessing whether the language agent can adjust its plan appropriately. The commonsense constraints and hard constraints are evaluated based on how well the language agent’s plan aligns with these specific criteria.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l} \\hline\n' +
      '**Tool** & **Data Entries** (\\#) \\\\ \\hline CitySearch & \\(312\\) \\\\ FlightSearch & \\(3\\),\\(827\\),\\(361\\) \\\\ DistanceMatrix & \\(17\\),\\(603\\) \\\\ RestaurantSearch & \\(9\\),\\(552\\) \\\\ AttractionSearch & \\(5\\),\\(303\\) \\\\ AccommodationSearch & \\(5\\),\\(064\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      'Table 2: The number of data entries in the database.\n' +
      '\n' +
      'Furthermore, we introduce diverse user needs as hard constraints to add further complexity and realism. The difficulty levels are categorized as follows:\n' +
      '\n' +
      '\\(\\bullet\\)**Easy**: Queries at this level are primarily budget-constrained for a single person. The initial budget for each query is determined using a set of crafted heuristic rules.\n' +
      '\n' +
      '\\(\\bullet\\)**Medium**: In addition to budget constraints, medium queries introduce an additional hard constraint, randomly selected from a constraint pool including cuisine type, room type, and room rule. Furthermore, the number of people varies between \\(2\\) and \\(8\\), which influences the calculation of costs for both transportation and accommodation.\n' +
      '\n' +
      '\\(\\bullet\\)**Hard**: Hard queries include additional transportation preference into the constraint pool, along with all the constraints in medium queries. Each hard query contains three hard constraints randomly selected from the constraint pool.\n' +
      '\n' +
      'This method ensures the diversity of queries. Minor changes in these elements can lead to significantly different plans. Finally, based on elements, we utilize GPT-4 (OpenAI, 2023) to generate natural language queries.\n' +
      '\n' +
      'Human Annotation.To ensure every query has at least one feasible plan, we invite \\(20\\) graduate students to meticulously annotate plans for synthesized queries. One plan is deemed eligible only if it meets all the constraints outlined in our evaluation script, which is detailed in Section 3.4. This rigorous process resulted in the creation of \\(1,225\\) validated query-plan pairs. We pay annotators an average of \\(\\$0.80\\) for each plan they annotate.\n' +
      '\n' +
      'Quality Control.To ensure the quality of each natural language query and its corresponding annotated plan, the authors performed a detailed review of every query and plan, rectifying any errors found. Additionally, to ensure the challenges, we re-calibrate each query\'s budget using the costs from corresponding human-annotated plans. This approach replaces the initial heuristic-generated budgets, which might be too high, thus reducing the number of feasible plans. Through multiple stages of human verification, we ensure the high quality of each query in TravelPlanner and the presence of at least one feasible solution.\n' +
      '\n' +
      '### Evaluation\n' +
      '\n' +
      'To ensure a comprehensive evaluation of the plans offered by agents, we assess them from multiple dimensions. Specifically, we first extract key components1, including transportation, restaurants, attractions, and accommodations, which are initially presented as natural language. These components are then organized into a formally structured plan, which will be evaluated automatically through pre-defined scripts. The evaluation criteria include the following:\n' +
      '\n' +
      'Footnote 1: In our experiments, we use GPT-4-Turbo for this extraction process. Please refer to Appendix B.3.5 for more details.\n' +
      '\n' +
      '\\(\\bullet\\)**Delivery Rate**: This metric assesses whether agents can successfully deliver a final plan within a limited number of steps. Falling into dead loops, experiencing numerous failed attempts, or reaching the maximum number of steps (\\(30\\) steps in our experimental setting) will result in failure.\n' +
      '\n' +
      '\\(\\bullet\\)**Commonsense Constraint Pass Rate**: Comprising eight commonsense dimensions, this metric evaluates whether a language agent can incorporate commonsense into their plan without explicit instructions.\n' +
      '\n' +
      '\\(\\bullet\\)**Hard Constraint Pass Rate**: This metric measures whether a plan satisfies all explicitly given hard constraints in the query, which aims to test the agents\' ability to adapt their plans to diverse user needs.\n' +
      '\n' +
      '\\(\\bullet\\)**Final Pass Rate**: This metric represents the proportion of feasible plans that meet all aforementioned constraints among all tested plans. It serves as an indicator of agents\' proficiency in producing plans that meet a practical standard.\n' +
      '\n' +
      'We do not separately assess environment constraints since their impact is inherently reflected in the "Within Sandbox" and "Complete Information" metrics. For instance, when cities lack transportation or attractions, agents typically resort to hallucination or opt not to provide an answer, reflecting the impact of environment constraints.\n' +
      '\n' +
      'For the Commonsense Constraint Pass Rate and Hard Constraint Pass Rate, we utilize two evaluation strategies: _micro_ and _macro_. The _micro_ strategy calculates the ratio of passed constraints to the total number of constraints. The **Micro Pass Rate** is defined as:\n' +
      '\n' +
      '\\[\\text{Micro Pass Rate}=\\frac{\\sum_{p\\in P}\\sum_{c\\in C_{p}}\\mathbbm{1}_{ \\text{passed}(c,p)}}{\\sum_{p\\in P}|C_{p}|}, \\tag{1}\\]\n' +
      '\n' +
      'where \\(P\\) represents the set of all plans being evaluated, \\(C_{p}\\) denotes the set of constraints applicable to a specific plan \\(p\\) in \\(P\\), and \\(\\text{passed}(X,Y)\\) is a function determining whether \\(Y\\) meets constraints \\(X\\).\n' +
      '\n' +
      'The _macro_ strategy calculates the ratio of plans that pass all commonsense or hard constraints among all tested plans. We define the **Macro Pass Rate** as:\n' +
      '\n' +
      '\\[\\text{Macro Pass Rate}=\\frac{\\sum_{p\\in P}\\frac{1}{\\text{passed}(C_{p},p)}}{|P|}. \\tag{2}\\]\n' +
      '\n' +
      'These two metrics evaluate an agent\'s capability of following individual constraints vs. all the constraints holistically.\n' +
      '\n' +
      '### Sole-Planning Setting\n' +
      '\n' +
      'While TravelPlanner is designed to assess the overall abilities of agents in tool-use and planning (two-stage mode),we also setup a simplified mode solely evaluating agents\' planning skills (sole-planning mode). In this setting, we utilize human-annotated plans to pre-determine the destination cities, and provide detailed and necessary information directly to agents, such as restaurants in the provided cities. This eliminates the need for tool calling as agents don\'t need to collect information from scratch via tools anymore.\n' +
      '\n' +
      '## 4 Experiments\n' +
      '\n' +
      'We evaluate the performance of various LLMs and planning strategies on TravelPlanner. In the two-stage mode, we use the ReAct (Yao et al., 2022) framework for information collection, which is recognized for its effective iteration with tools (Zhuang et al., 2023b) while varying the foundation LLMs. This approach allows us to assess how different LLMs perform under a uniform tool-use framework. The agents are required to give the plan directly based on the information collected by themselves, without employing any other planning strategies. In the sole-planning mode, our evaluation goes beyond varying LLMs to include different planning strategies. This aims to assess if the strategies proven effective in other planning benchmarks maintain their efficacy in TravelPlanner. All experiments are conducted in a zero-shot setting.\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      'Greedy Search.To evaluate the effectiveness of traditional rule-based strategies within TravelPlanner, we include greedy search as a baseline and set cost as the optimization objective. Please refer to Appendix B.1 for more details.\n' +
      '\n' +
      'LLMs.Due to the long context window requirement of ReAct and the massive information as text, we limit our consideration to LLMs capable of handling inputs exceeding \\(8\\)K in length. As a result, our selection includes three closed-source LLMs: **GPT-3.5-Turbo**(OpenAI, 2022), **GPT-4-Turbo**(OpenAI, 2023), and **Gemini Pro**(G Team et al., 2023), as well as two open-source LLMs: **Mistral-7B-32K**(Jiang et al., 2023) and **Mistral-8x7B-MoE**(Jiang et al., 2024). For all these models, we adopt the official instruction formats whenever available.\n' +
      '\n' +
      'Planning Strategies.To explore the effectiveness of current planning strategies, we evaluate four representative ones: **Direct**, **ZS-CoT**(Wei et al., 2022), **ReAct**(Yao et al., 2022), and **Reflexion**(Shinn et al., 2023). For the implementation details, please refer to Appendix B.1. We do not include **ToT**(Yao et al., 2023) and **GoT**(Besta et al., 2023) because they require extensive exploration of the search space, prohibitively costly for problems as complex as TravelPlanner. Also, given their performance close to ReAct in complex tasks (Zhuang et al., 2023a), the potential benefits of these methods may be limited.\n' +
      '\n' +
      '### Main Results\n' +
      '\n' +
      'In this section, we discuss the performance of various LLMs and planning strategies on TravelPlanner (Table 3). We have the following observations:\n' +
      '\n' +
      '**TravelPlanner poses a significant challenge.** In the two-stage mode, GPT-4-Turbo with ReAct achieves only \\(0.6\\)% in the final pass rate, and none of the other LLMs can pass any\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c c c c c} \\hline \\hline  & \\multicolumn{6}{c}{**Validation (\\#\\(180\\))**} & \\multicolumn{6}{c}{**Test (\\#\\(1,000\\))**} \\\\ \\cline{2-11} \\multirow{2}{*}{Delivery Rate} & \\multirow{2}{*}{\\begin{tabular}{c} Commonsense \\\\ Pass Rate \\\\ \\end{tabular} } & \\multicolumn{2}{c}{\\begin{tabular}{c} Hard Constraint \\\\ Pass Rate \\\\ \\end{tabular} } & \\multirow{2}{*}{\\begin{tabular}{c} Final \\\\ Pass Rate \\\\ \\end{tabular} } & \\multirow{2}{*}{\\begin{tabular}{c} Delivery \\\\ Pass Rate \\\\ \\end{tabular} } & \\multirow{2}{*}{\\begin{tabular}{c} Commonsense \\\\ Pass Rate \\\\ \\end{tabular} } & \\multirow{2}{*}{\\begin{tabular}{c} Hard Constraint \\\\ Pass Rate \\\\ \\end{tabular} } & \\multirow{2}{*}{\n' +
      '\\begin{tabular}{c} Final \\\\ Pass Rate \\\\ \\end{tabular} } \\\\ \\cline{2-11} \\cline{6-11}  & & & Micro & Macro & & Micro & Macro & & & & Micro & Macro \\\\ \\hline Greedy Search & 100 & \\(74.4\\) & 0 & \\(60.8\\) & \\(37.8\\) & 0 & 100 & \\(72.0\\) & 0 & \\(52.4\\) & \\(31.8\\) & 0 \\\\ \\hline \\hline \\multicolumn{11}{c}{_Two-stage_} \\\\ \\hline \\hline Mistral-7B-32K (Jiang et al., 2023) & 8.9 & 5.9 & 0 & 0 & 0 & 0 & \\(7.0\\) & \\(4.8\\) & 0 & 0 & 0 & 0 \\\\ Mistral-8x7B-MoE (Jiang et al., 2024) & \\(49.4\\) & \\(30.0\\) & 0 & \\(1.2\\) & \\(0.6\\) & 0 & \\(51.2\\) & \\(32.2\\) & 0.2 & 0.7 & 0.4 & 0 \\\\ Gemini Pro (G Team et al., 2023) & \\(28.9\\) & \\(18.9\\) & 0 & 0.5 & \\(0.6\\) & 0 & \\(39.1\\) & \\(24.9\\) & 0 & 0.6 & 0.1 & 0 \\\\ GPT-3.5-Turbo (OpenAI, 2022) & \\(86.7\\) & \\(54.0\\) & 0 & 0 & 0 & \\(91.8\\) & \\(57.9\\) & 0 & \\(0.5\\) & 0.6 & 0 \\\\ GPT-4-Turbo (OpenAI, 2023) & \\(89.4\\) & \\(61.1\\) & \\(2.8\\) & \\(15.2\\) & \\(10.6\\) & \\(0.6\\) & \\(93.1\\) & \\(63.3\\) & \\(2.0\\) & \\(10.5\\) & \\(5.5\\) & \\(0.6\\) \\\\ \\hline \\hline \\multicolumn{11}{c}{_Sole-planning_} \\\\ \\hline \\hline Direct\\({}_{\\text{GPT-3.5-Turbo}}\\) & 100 & 60.2 & 4.4 & \\(11.0\\) & 2.8 & 0 & 100 & \\(59.5\\) & 2.7 & 9.5 & 4.4 & 0.6 \\\\ CoT\\({}_{\\text{GPT-3.5-Turbo}}\\) & 100 & 66.3 & 3.3 & \\(11.9\\) & 5.0 & 0 & 100 & 64.4 & 2.3 & 9.8 & 3.8 & 0.4 \\\\ ReAct\\({}_{\\text{GPT-3.5-Turbo}}\\) & 82.2 & 47.6 & 3.9 & \\(11.4\\) & 6.7 & 0.6 & 81.6 & 45.9 & 2.5 & 10.7 & 3.1 & 0.7 \\\\ Reflexion\\({}_{\\text{GPT-3.5-Turbo}}\\) & 93.9 & 53.8 & 2.8 & \\(11.0\\) & 2.8 & 0 & \\(92.1\\) & 52.1 & 2.2 & 9.9 & 3.8 & 0.6 \\\\ Direct\\({}_{\\text{Mistral-8x7B-MoE}}\\) & 100 & 68.1 & 5.0 & \\(3.3\\) & \\(1.1\\) & 0 & \\(99.3\\) & \\(67.0\\) & \\(3.7\\) & \\(3.9\\) & \\(1.6\\) & \\(0.7\\) \\\\ Direct\\({}_{\\text{Gemini Pro}}\\) & 93.9 & 65.0 & 8.3 & 9.3 & 4.4 & 0.6 & \\(93.7\\) & \\(64.7\\) & \\(7.9\\) & \\(10.6\\) & \\(4.7\\) & \\(2.1\\) \\\\ Direct\\({}_{\\text{GPT-4-Turbo}}\\) & **100** & **80.4** & **17.2** & **47.1** & **22.2** & **4.4** & **100** & **80.6** & **15.2** & **44.3** & **23.1** & **4.4** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      'Table 3: Main results of different LLMs and planning strategies on the TravelPlanner validation and test set. The best results are marked in bold. When the collected information is insufficient, Gemini Pro tends to directly refuse to provide the plan. Interviews with annotators reveal that manually annotating a plan averagely takes around \\(12\\) minutes. However, language agents, such as GPT-3.5-Turbo, can accomplish this task in just \\(1\\) to \\(2\\) minutes, showcasing their efficiency.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:7]\n' +
      '\n' +
      'gate this, Table 5 shows agents in two-stage mode use tools less effectively compared to the reference plans. This comparison indicates that agents often fail to finish completed information collection. Consequently, they either generate made-up information or omit specific details. This leads to low pass rates for the "Within Sandbox" and "Complete Information" constraints. Additionally, this discrepancy becomes more pronounced with an increase in the duration of travel. This emphasizes the need for agents to improve their capabilities in long-horizon tasks.\n' +
      '\n' +
      '**Agents struggle with global planning scenarios.** Global constraints "Minimum Nights Stay" and "Budget" demand a holistic approach to planning, necessitating that agents not only assess their current decisions but also anticipate future implications. Current LLMs\' auto-regressive nature limits them to independently obtain outcomes from multiple future branches. This highlights the necessity and urgent need of new strategies, such as backtracking for adjusting or employing heuristic methods for forward-looking planning.\n' +
      '\n' +
      '### Case Studies\n' +
      '\n' +
      'To investigate the drawbacks of current agents in-depth, we provide several failure cases in Figure 3. We conclude with the following features:\n' +
      '\n' +
      '**Agents fail to complete a plan due to the inability to rectify persistent errors.** In tool-use scenarios, agents often fail to deliver a plan even when all preceding steps are executed correctly. Further investigation reveals that this issue often stems from incorrect date inputs. As shown in the left part of Figure 3, despite correct execution, agents repeatedly use incorrect dates. This leads to null results, as the data in the TravelPlanner sandbox is based on 2022. Such repeated failures eventually cause the agents to stop planning. This indicates a significant limitation: current agents cannot self-correct their initial and incorrect assumptions.\n' +
      '\n' +
      '**Agents produce hallucinatory answers due to information confusion.** To understand why agents provide hallucinatory answers even when supplied with sufficient information in the sole-planning mode, we conduct a detailed analysis. We observe a tendency for agents to confuse one piece of information with another. As shown in the middle part of Figure 3, agents mistakenly use the same flight number for both departure and return flights. Such errors result in hallucinations, as the information provided in the plan does not align with the data in the sandbox. This suggests that agents might be lost when faced with mass information, known as "Lost in the Middle" (Liu et al., 2023).\n' +
      '\n' +
      '**Agents struggle to align their actions with their reasoning.** To understand the reasons behind the lower delivery rate of Reflexion (Shinn et al., 2023), we examine specific examples. As illustrated in the right part of Figure 3, we observe a discrepancy between what agents think and what they do. Despite recognizing the necessity to minimize costs, they tend to randomly select items, some of which may be more expensive. This discrepancy demonstrates that agents struggle to synchronize their actions with their analytical reasoning, severely impeding their delivery rate.\n' +
      '\n' +
      '## 6 Conclusion\n' +
      '\n' +
      'We introduce TravelPlanner, a benchmark grounded in real-world scenarios, designed to assess the multi-constraint planning and tool-use abilities of current language agents. Our benchmark presents a significant challenge: even the most advanced language agent frameworks only achieve\n' +
      '\n' +
      'Figure 3: Case studies of failures. Agents fail to finalize plans due to repeated errors like incorrect dates, confusion with information details leading to hallucinatory answers, and disconnects between reasoning and actions. All cases are gained from GPT-4-Turbo based agents. For details of GPT-4-Turbo with the Reflexion strategy, please refer to Appendix B.2. We provide more cases in Appendix C.2.\n' +
      '\n' +
      'a mere 0.6% score in the final pass rate. Further analysis shows that these agents are unable to take all constraints into consideration to deliver feasible plans.\n' +
      '\n' +
      'TravelPlanner\'s intricate logic and general applicability stand as vital components in the progressive development of language agents, thus contributing to the broader quest for AI abilities. We envision TravelPlanner as a catalyst for future research, aiming to enhance agents\' performance in increasingly complex scenarios, hill-climbing towards human-level cognitive capabilities.\n' +
      '\n' +
      '## 7 Impact Statements\n' +
      '\n' +
      'TravelPlanner aims to provide an effective benchmark for complex planning in future research. Some of the data in the TravelPlanner environment is derived from publicly available data on the Internet, and the content involved does not represent the authors\' viewpoints. We realize that everyone\'s definition of commonsense may be different. Our current evaluation criteria are based on the authors\' consensus, and we encourage additional discussions to enrich our commonsense dimension, aiming for a more thorough evaluation. We will release our evaluation scripts to foster innovation and aid the development of new methods. We encourage the use of evaluation feedback in training set, such as implementing reinforcement learning techniques, to enhance learning. However, we strictly prohibit any form of cheating in the validation and test sets to uphold the fairness and reliability of the benchmark\'s evaluation process.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Alterovitz et al. (2016) Alterovitz, R., Koenig, S., and Likhachev, M. Robot planning in the real world: research challenges and opportunities. _Ai Magazine_, 37(2):76-84, 2016.\n' +
      '* Andreas (2005) Andreas, J. Language models as agent models. In Goldberg, Y., Kozareva, Z., and Zhang, Y. (eds.), _Findings of the Association for Computational Linguistics: EMNLP 2022_, pp. 5769-5779, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-emnlp.423. URL [https://aclanthology.org/2022.findings-emnlp.423](https://aclanthology.org/2022.findings-emnlp.423).\n' +
      '* AutoGPT (2023) AutoGPT. Autogpt, 2023. URL [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT).\n' +
      '* Besta et al. (2023) Besta, M., Blach, N., Kubicek, A., Gerstenberger, R., Gianinazzi, L., Gajda, J., Lehmann, T., Podstawski, M., Niewiadomski, H., Nyczyk, P., et al. Graph of thoughts: Solving elaborate problems with large language models. _arXiv preprint arXiv:2308.09687_, 2023.\n' +
      '* Brown et al. (2020) Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020.\n' +
      '* Campbell et al. (2002) Campbell, M., Hoane Jr, A. J., and Hsu, F.-h. Deep blue. _Artificial intelligence_, 134(1-2):57-83, 2002.\n' +
      '* Chen et al. (2023) Chen, H., Pasunuru, R., Weston, J., and Celikyilmaz, A. Walking down the memory maze: Beyond context limit through interactive reading. _arXiv preprint arXiv:2310.05029_, 2023.\n' +
      '* Cobbe et al. (2021) Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. Training verifiers to solve math word problems. _arXiv preprint arXiv:2110.14168_, 2021.\n' +
      '* Cross & Estrada (1994) Cross, S. and Estrada, R. Dart: an example of accelerated evolutionary development. In _Proceedings of IEEE 5th International Workshop on Rapid System Prototyping_, pp. 177-183, 1994. doi: 10.1109/IWRSP.1994.315895.\n' +
      '* Deng et al. (2023) Deng, X., Gu, Y., Zheng, B., Chen, S., Stevens, S., Wang, B., Sun, H., and Su, Y. Mind2web: Towards a generalist agent for the web. In _Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2023. URL [https://openreview.net/forum?id=kiYqb03wq](https://openreview.net/forum?id=kiYqb03wq).\n' +
      '* Team et al. (2023) G Team, G., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., et al. Gemini: a family of highly capable multimodal models. _arXiv preprint arXiv:2312.11805_, 2023.\n' +
      '* Ge et al. (2023) Ge, Y., Hua, W., Ji, J., Tan, J., Xu, S., and Zhang, Y. Openagi: When llm meets domain experts. _arXiv preprint arXiv:2304.04370_, 2023.\n' +
      '* Georgievski & Aiello (2015) Georgievski, I. and Aiello, M. Htn planning: Overview, comparison, and beyond. _Artificial Intelligence_, 222:124-156, 2015.\n' +
      '* Grafman et al. (2004) Grafman, J., Spector, L., and Rattermann, M. J. Planning and the brain. In _The cognitive psychology of planning_, pp. 191-208. Psychology Press, 2004.\n' +
      '* Hayes-Roth & Hayes-Roth (1979) Hayes-Roth, B. and Hayes-Roth, F. A cognitive model of planning. _Cognitive science_, 3(4):275-310, 1979.\n' +
      '* Ho et al. (2022) Ho, M. K., Saxe, R., and Cushman, F. Planning with theory of mind. _Trends in Cognitive Sciences_, 26(11):959-971, 2022.\n' +
      '* Huang et al. (2022) Huang, W., Abbeel, P., Pathak, D., and Mordatch, I. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In _International Conference on Machine Learning_, pp. 9118-9147. PMLR, 2022.\n' +
      '\n' +
      'Ichter, B., Brohan, A., Chebotar, Y., Finn, C., Hausman, K., Herzog, A., Ho, D., Ibarz, J., Irpan, A., Jang, E., Julian, R., Kalashnikov, D., Levine, S., Lu, Y., Parada, C., Rao, K., Sermanet, P., Toshev, A., Vanhoucke, V., Xia, F., Xiao, T., Xu, P., Yan, M., Brown, N., Ahn, M., Cortes, O., Sievers, N., Tan, C., Xu, S., Reyes, D., Rettinghouse, J., Quianbao, J., Pastor, P., Luu, L., Lee, K., Kuang, Y., Jesmonth, S., Joshi, N. J., Jeffrey, K., Ruano, R. J., Hsu, J., Gopalakrishnan, K., David, B., Zeng, A., and Fu, C. K. Do as I can, not as I say: Grounding language in robotic affordances. In Liu, K., Kulic, D., and Ichnowski, J. (eds.), _Conference on Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand_, volume 205 of _Proceedings of Machine Learning Research_, pp. 287-318. PMLR, 2022. URL [https://proceedings.mlr.press/v205/ichter23a.html](https://proceedings.mlr.press/v205/ichter23a.html).\n' +
      '* Jiang et al. (2023) Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., Casas, D. d. l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et al. Mistral 7b. _arXiv preprint arXiv:2310.06825_, 2023.\n' +
      '* Jiang et al. (2024) Jiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C., Chaplot, D. S., de las Casas, D., Hanna, E. B., Bressand, F., Lengyel, G., Bour, G., Lample, G., Lavaud, L. R., Saulnier, L., Lachaux, M.-A., Stock, P., Subramanian, S., Yang, S., Antoniak, S., Scao, T. L., Gervet, T., Lavril, T., Wang, T., Lacroix, T., and Sayed, W. E. Mistral of experts, 2024.\n' +
      '* December 9, 2022_, 2022. URL [http://papers.nips.cc/paper_files/paper/2022/hash/18abbeef8cfe9203fdf9053c5dc4fe191-Abstract-Conference.html](http://papers.nips.cc/paper_files/paper/2022/hash/18abbeef8cfe9203fdf9053c5dc4fe191-Abstract-Conference.html).\n' +
      '* Li et al. (2023) Li, M., Zhao, Y., Yu, B., Song, F., Li, H., Yu, H., Li, Z., Huang, F., and Li, Y. Api-bank: A comprehensive benchmark for tool-augmented llms. In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pp. 3102-3116, 2023.\n' +
      '* Liang et al. (2023) Liang, X., Wang, B., Huang, H., Wu, S., Wu, P., Lu, L., Ma, Z., and Li, Z. Unleashing infinite-length input capacity for large-scale language models with self-controlled memory system. _arXiv preprint arXiv:2304.13343_, 2023.\n' +
      '* Liu et al. (2023a) Liu, B., Jiang, Y., Zhang, X., Liu, Q., Zhang, S., Biswas, J., and Stone, P. Llm+ p: Empowering large language models with optimal planning proficiency. _arXiv preprint arXiv:2304.11477_, 2023a.\n' +
      '* Liu et al. (2023b) Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., and Liang, P. Lost in the middle: How language models use long contexts, 2023b. arXiv:2307.03172.\n' +
      '* Liu et al. (2023c) Liu, X., Yu, H., Zhang, H., Xu, Y., Lei, X., Lai, H., Gu, Y., Ding, H., Men, K., Yang, K., et al. Agentbench: Evaluating lms as agents. _arXiv preprint arXiv:2308.03688_, 2023c.\n' +
      '* Lu et al. (2023) Lu, P., Peng, B., Cheng, H., Galley, M., Chang, K.-W., Wu, Y. N., Zhu, S.-C., and Gao, J. Chameleon: Plug-and-play compositional reasoning with large language models. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023. URL [https://openreview.net/forum?id=HtqnV5Cj3q](https://openreview.net/forum?id=HtqnV5Cj3q).\n' +
      '* Mattar & Lengyel (2022) Mattar, M. G. and Lengyel, M. Planning in the brain. _Neuron_, 110(6):914-934, 2022.\n' +
      '* McDermott (1992) McDermott, D. Robot planning. _AI magazine_, 13(2):55-55, 1992.\n' +
      '* Nakajima (2023) Nakajima, Y. Task-driven autonomous agent utilizing gpt-4, pinecone, and langchain for diverse applications, 2023.\n' +
      '* Nakano et al. (2021) Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., et al. Webgpt: Browser-assisted question-answering with human feedback. _arXiv preprint arXiv:2112.09332_, 2021.\n' +
      '* OpenAI (2022) OpenAI. Chatgpt, 2022. URL [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt).\n' +
      '* OpenAI (2023) OpenAI. Gpt-4 technical report. _arXiv preprint arXiv:2303.08774_, 2023. URL [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774).\n' +
      '* Park et al. (2023) Park, J. S., O\'Brien, J., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. Generative agents: Interactive simulacra of human behavior. In _Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology_, pp. 1-22, 2023.\n' +
      '* Patel et al. (2021) Patel, A., Bhattamishra, S., and Goyal, N. Are NLP models really able to solve simple math word problems? In _Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, pp. 2080-2094, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.168. URL [https://aclanthology.org/2021.naacl-main.168](https://aclanthology.org/2021.naacl-main.168).\n' +
      '* Patil et al. (2023) Patil, S. G., Zhang, T., Wang, X., and Gonzalez, J. E. Gorilla: Large language model connected with massive apis. _arXiv preprint arXiv:2305.15334_, 2023.\n' +
      '\n' +
      '* Pinedo (2005) Pinedo, M. _Planning and scheduling in manufacturing and services_. Springer, 2005.\n' +
      '* Qin et al. (2023) Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., Lin, Y., Cong, X., Tang, X., Qian, B., et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. _arXiv preprint arXiv:2307.16789_, 2023.\n' +
      '* Roy & Roth (2015) Roy, S. and Roth, D. Solving general arithmetic word problems. In Marquez, L., Callison-Burch, C., and Su, J. (eds.), _Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing_, pp. 1743-1752, Lisbon, Portugal, September 2015. Association for Computational Linguistics. doi: 10.18653/v1/D15-1202. URL [https://aclanthology.org/015-1202](https://aclanthology.org/015-1202).\n' +
      '* Russell & Norvig (2010) Russell, S. J. and Norvig, P. _Artificial intelligence a modern approach_. London, 2010.\n' +
      '* Schick et al. (2023) Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Hambro, E., Zettlemoyer, L., Cancedda, N., and Scialom, T. Toolformer: Language models can teach themselves to use tools. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023. URL [https://openreview.net/forum?id=Yacmpz84TH](https://openreview.net/forum?id=Yacmpz84TH).\n' +
      '* Shen et al. (2023) Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y. HuggingGPT: Solving AI tasks with chatGPT and its friends in hugging face. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023. URL [https://openreview.net/forum?id=yHd7scY6Ci](https://openreview.net/forum?id=yHd7scY6Ci).\n' +
      '* Shinn et al. (2023) Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K. R., and Yao, S. Reflexion: Language agents with verbal reinforcement learning. In _Thirty-seventh Conference Neural Information Processing Systems_, 2023.\n' +
      '* Silver et al. (2016) Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., et al. Mastering the game of go with deep neural networks and tree search. _nature_, 529(7587):484-489, 2016.\n' +
      '* Silver et al. (2017) Silver, D., Hasselt, H., Hessel, M., Schaul, T., Guez, A., Harley, T., Dulac-Arnold, G., Reichert, D., Rabinowitz, N., Barreto, A., et al. The predictron: End-to-end learning and planning. In _International Conference on Machine Learning_, pp. 3191-3199. PMLR, 2017.\n' +
      '* Song et al. (2023) Song, C. H., Wu, J., Washington, C., Sadler, B. M., Chao, W.-L., and Su, Y. Llm-planner: Few-shot grounded planning for embodied agents with large language models. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pp. 2998-3009, 2023.\n' +
      '* Su (2023) Su, Y. Language agents: a critical evolutionary step of artificial intelligence. _yusu.substack.com_, Sep 2023. URL [https://yusu.substack.com/p/language-agents](https://yusu.substack.com/p/language-agents).\n' +
      '* Sumers et al. (2023) Sumers, T. R., Yao, S., Narasimhan, K., and Griffiths, T. L. Cognitive architectures for language agents. _arXiv preprint arXiv:2309.02427_, 2023.\n' +
      '* Touvron et al. (2023a) Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Roziere, B., Goyal, N., Hambro, E., Azhar, F., et al. Llama: Open and efficient foundation language models. _arXiv preprint arXiv:2302.13971_, 2023a. URL [https://arxiv.org/abs/2302.13971](https://arxiv.org/abs/2302.13971).\n' +
      '* Touvron et al. (2023b) Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al. Llama 2: Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09288_, 2023b.\n' +
      '* Valmeekam et al. (2023) Valmeekam, K., Olmo, A., Sreedharan, S., and Kambhampati, S. Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.\n' +
      '* Wang et al. (2022) Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., and Anandkumar, A. Voyager: An open-ended embodied agent with large language models. _arXiv preprint arXiv:2305.16291_, 2023.\n' +
      '* Wei et al. (2022) Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. _Advances in Neural Information Processing Systems_, 35:24824-24837, 2022.\n' +
      '* Weng (2023) Weng, L. Llm-powered autonomous agents. _lilianweng.github.io_, Jun 2023. URL [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/).\n' +
      '* Xie et al. (2023) Xie, T., Zhou, F., Cheng, Z., Shi, P., Weng, L., Liu, Y., Hua, T. J., Zhao, J., Liu, Q., Liu, C., Liu, L. Z., Xu, Y., Su, H., Shin, D., Xiong, C., and Yu, T. Openagents: An open platform for language agents in the wild, 2023.\n' +
      '* Xu et al. (2023) Xu, Q., Hong, F., Li, B., Hu, C., Chen, Z., and Zhang, J. On the tool manipulation capability of open-source large language models, 2023.\n' +
      '* Yao et al. (2022) Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K. R., and Cao, Y. React: Synergizing reasoning and acting in language models. In _The Eleventh International Conference on Learning Representations_, 2022.\n' +
      '* Yao et al. (2023) Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., and Narasimhan, K. R. Tree of thoughts: Deliberate problem solving with large language models. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023. URL [https://openreview.net/forum?id=5Xc1ecx01h](https://openreview.net/forum?id=5Xc1ecx01h).\n' +
      '\n' +
      '* Yuan et al. (2023) Yuan, S., Chen, J., Fu, Z., Ge, X., Shah, S., Jankowski, C., Xiao, Y., and Yang, D. Distilling script knowledge from large language models for constrained language planning. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp. 4303-4325, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.236. URL [https://aclanthology.org/2023.acl-long.236](https://aclanthology.org/2023.acl-long.236).\n' +
      '* Zheng et al. (2024) Zheng, B., Gou, B., Kil, J., Sun, H., and Su, Y. Gpt-4v(ision) is a generalist web agent, if grounded. _arXiv preprint arXiv:2401.01614_, 2024.\n' +
      '* Zhong et al. (2023) Zhong, W., Guo, L., Gao, Q., and Wang, Y. Memorybank: Enhancing large language models with long-term memory. _arXiv preprint arXiv:2305.10250_, 2023.\n' +
      '* Zhou et al. (2023a) Zhou, S., Xu, F. F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Bisk, Y., Fried, D., Alon, U., et al. Webarena: A realistic web environment for building autonomous agents. _arXiv preprint arXiv:2307.13854_, 2023a. URL [https://webarena.dev](https://webarena.dev).\n' +
      '* Zhou et al. (2023b) Zhou, W., Jiang, Y. E., Cui, P., Wang, T., Xiao, Z., Hou, Y., Cotterell, R., and Sachan, M. Recurrentgpt: Interactive generation of (arbitrarily) long text. _arXiv preprint arXiv:2305.13304_, 2023b.\n' +
      '* Zhuang et al. (2023a) Zhuang, Y., Chen, X., Yu, T., Mitra, S., Bursztyn, V., Rossi, R. A., Sarkhel, S., and Zhang, C. Toolchain*: Efficient action space navigation in large language models with a* search. _arXiv preprint arXiv:2310.13227_, 2023a.\n' +
      '* Zhuang et al. (2023b) Zhuang, Y., Yu, Y., Wang, K., Sun, H., and Zhang, C. ToolQA: A dataset for LLM question answering with external tools. In _Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2023b. URL [https://openreview.net/forum?id=pV1xY2RK6I](https://openreview.net/forum?id=pV1xY2RK6I).\n' +
      '\n' +
      '## Appendices\n' +
      '\n' +
      'Within this supplementary material, we elaborate on the following aspects:\n' +
      '\n' +
      '* Appendix A: Benchmark Details\n' +
      '* Appendix B: Experiment Details\n' +
      '* Appendix C: Case Presentation\n' +
      '\n' +
      '## Appendix A Benchmark Details\n' +
      '\n' +
      '### Dataset Distribution\n' +
      '\n' +
      'In Table A.1, we list the detailed group distribution on training, validation and test set.\n' +
      '\n' +
      '### Tool Description\n' +
      '\n' +
      'In Table A.2, we list the detailed tool description. The original data for each tool is sourced from publicly available Internet data. We then modify this data, which includes adding, deleting, and altering certain keys and values to suit our requirements. In this way, we effectively avoid the problem of data contamination. For more details, please refer to Appendix A.3.\n' +
      '\n' +
      '### Environment Database Construction\n' +
      '\n' +
      'FlightSearchFor FlightSearch, we source original data from the Kaggle Flight Status Prediction dataset2. From this dataset, we extract data spanning from 2022-03-01 to 2022-04-01. We specifically included fields like "FlightDate", "DepTime", "ArrTime", "ActualElapsedTime", "Distance", "OriginCityName", and "DestCityName" while discarding other values. To incorporate "Price" into our dataset, we generate this value by multiplying the "Distance" by a random factor\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l} \\hline \\hline Tool & Data Entries(\\#) & Description \\\\ \\hline CitySearch & \\(312\\) & Search cities in the given state. \\\\ FlightSearch & \\(3\\),\\(827\\),\\(361\\) & Search flight information for a specific date between two cities. \\\\ DistanceMatrix & \\(17\\),\\(603\\) & Search the driving distance, time, and possible cost between two cities. \\\\ RestaurantSearch & \\(9\\),\\(552\\) & Search restaurants in the given city. \\\\ AttractionSearch & \\(5\\),\\(303\\) & Search attractions in the given city. \\\\ AccommodationSearch & \\(5\\),\\(064\\) & Search accommodations in the given city. \\\\ NotebookWrite & - & Write the selected data entry into the Notebook tool with a short description. \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      'Table A.2: Tool description and the number of data entries in the database.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l l} \\hline \\hline  & Days & Easy & Medium & Hard \\\\ \\hline \\multirow{3}{*}{Training (\\#\\(45\\))} & 3-day & \\(5\\) & \\(5\\) & \\(5\\) \\\\  & 5-day & \\(5\\) & \\(5\\) & \\(5\\) \\\\  & 7-day & \\(5\\) & \\(5\\) & \\(5\\) \\\\ \\hline \\multirow{3}{*}{Validation (\\#\\(180\\))} & 3-day & \\(20\\) & \\(20\\) & \\(20\\) \\\\  & 5-day & \\(20\\) & \\(20\\) & \\(20\\) \\\\  & 7-day & \\(20\\) & \\(20\\) & \\(20\\) \\\\ \\hline \\multirow{3}{*}{Test (\\#\\(1\\),\\(000\\))} & 3-day & \\(122\\) & \\(104\\) & \\(82\\) \\\\  & 5-day & \\(116\\) & \\(114\\) & \\(121\\) \\\\ \\cline{1-1}  & 7-day & \\(110\\) & \\(115\\) & \\(116\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      'Table A.1: Dataset distribution.\n' +
      '\n' +
      'ranging from 0.2 to 0.5.\n' +
      '\n' +
      'DistanceMatrixWe utilize the Google Distance Matrix API3 to calculate the driving distance and estimated travel time between two cities. For the "self-driving" and "taxi" modes of transportation, we calculate the \'Price\' by multiplying the \'Distance\' by factors of 1 and 0.15, respectively. To ensure consistency and reliability of data, we store the search results in our database, thereby creating a fixed dataset for our evaluations.\n' +
      '\n' +
      'Footnote 3: [https://developers.google.com/maps/documentation/distance-matrix/overview?hl=en](https://developers.google.com/maps/documentation/distance-matrix/overview?hl=en)\n' +
      '\n' +
      'RestaurantSearchOur restaurant data is sourced from the Kaggle Zomato Restaurants Dataset4. From this dataset, we extract the "Restaurant Name" and "Average Cost" for each establishment. Subsequently, we randomly assign these restaurants to various cities. To align with the constraint requirements of TravelPlanner, we also randomly categorize each restaurant under the following cuisines: "Chinese", "American", "Italian", "Mexican", "Indian","Mediterranean", "Middle Eastern", "Korean", "Asian", "French".\n' +
      '\n' +
      'Footnote 4: [https://www.kaggle.com/datasets/shrutinheta/zomato-restaurants-data](https://www.kaggle.com/datasets/shrutinheta/zomato-restaurants-data)\n' +
      '\n' +
      'AttractionSearchFor AttractionSearch, we employ the Google Places API5 to gather information about attractions in each city. In TravelPlanner, we retain essential details such as "Name", "Address", "Phone", "Website", "Latitude", and "Longtitue" for each attraction. To maintain data consistency and reliability, we store these search results in our database, creating a standardized dataset for our analyses.\n' +
      '\n' +
      'Footnote 5: [https://developers.google.com/maps/documentation/places/web-service/overview?hl=en](https://developers.google.com/maps/documentation/places/web-service/overview?hl=en)\n' +
      '\n' +
      'AccommodationSearchOur accommodation data is obtained from the Kaggle Airbnb Open Data Dataset6. From this dataset, we extract key details "NAME", "room type", "price", "minimum nights", "review rate number", and "maximum occupancy". Items are then randomly assigned to various cities. To meet the specific constraint requirements of TravelPlanner, we also assign each item random room rules, including "No parties", "No smoking", "No children under 10", "No pets", and "No visitors".\n' +
      '\n' +
      'Footnote 6: [https://www.kaggle.com/datasets/arianazmoudeh/airbnbopendata](https://www.kaggle.com/datasets/arianazmoudeh/airbnbopendata)\n' +
      '\n' +
      '## Appendix B Experiment Details\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      'Greedy SearchTo assess the effectiveness of traditional search algorithms in TravelPlanner, we integrate a greedy search approach, focusing on minimizing costs. For 5 or 7-day travel plans, the first one or two cities in the returned city search result are selected as destinations. The transportation choice is based on the lowest cost option among flights, taxis, and self-driving. The diet component involves selecting the restaurant with the lowest average cost. The cheapest accommodation is chosen for lodging. For attractions, we opt for a random selection for each day of the itinerary.\n' +
      '\n' +
      'Planning StrategyCurrent planning strategies have shown effectiveness in traditional tasks like mathematical problem-solving, but their capability to handle the more complex and constrained scenarios like TravelPlanner remains to be seen. To explore this, we evaluate four distinct planning strategies on TravelPlanner: _1)_**Direct**: In this method, the query is input directly into the model along with instructions detailing the task and relevant information gathered. _2)_**ZS-CoT**(Wei et al., 2022): This strategy enhances the reasoning process by requiring intermediate steps. Building on the Direct method, we add the prompt "Let\'s think step by step" to elicit reasoning. _3)_**ReAct**(Yao et al., 2022): This strategy incorporates environmental feedback into the reasoning process. Thus, it enhances the language agent\'s reasoning ability by offering additional information. In TravelPlanner, we provide the cost associated with each entire day\'s plan as environmental feedback. _4)_**Reflexion**(Shinn et al., 2023): This approach utilizes a reflection model to provide high-level insights on previous erroneous attempts. Such reflective guidance aids language agents in identifying and correcting flawed reasoning. In order to control the cost, we conduct tests on Direct using four different models, while the other strategies are evaluated using GPT-3.5-Turbo. Detailed instructions for each strategy are available in Appendix B.3.\n' +
      '\n' +
      '### GPT-4-Turbo with Reflexion strategy in sole-planning mode.\n' +
      '\n' +
      'We provide the results of GPT-4-Turbo with Reflexion strategy on validation set in Table B.3.\n' +
      '\n' +
      '### Prompt List\n' +
      '\n' +
      '#### b.3.1. Tool-use Prompt\n' +
      '\n' +
      'We tailor the ReAct (Yao et al., 2022) framework to suit our specific requirements in TravelPlanner. An example of the instruction prompt for our needs is as follows:\n' +
      '\n' +
      '``` Collectinformationforaqueryplanusinginterleaving\'Thought\',\'Action\',and\'Observation\'steps.Ensureyourgathervalidinformationrelatedtotransportation,dining,attractions,andaccommodation.AllinformationshouldbewritteninNotebook,whichwillthenbeinputintothePlannertool.Notthatthemesteduseoftoolsisprohibited.\'Thought\'canreasonaboutthecurrentsituation,and\'Action\'canhave8differenttypes: (1)FlightSearch[DepartureCity,DestinationCity,Date]: Description:Aflightinformationretrievaltool. Parameters: DepartureCity:Thecityyou\'llbeflyingoutfrom.DestinationCity:Thecityyouaimtoreach.Date:ThedateofyourtravelinYYYY-MM-DDformat.Example:FlightSearch[NewYork,London,2022-10-01]wouldfetchflightsfromNewYorktoLondononOctober1,2022. (2)DistanceMatrix[Origin,Destination,Mode]: Description:Estimatethedistance,timeandcostbetweentwocities. Parameters: Origin:Thedeparturecityofyourjourney.Destination:Thedestinationcityofyourjourney.Mode:Themethodoftransportation.Choicesinclude\'self-driving\'and\'taxi\'.Example:DistanceMatrix[Paris,Lyon,self-driving]wouldprovideddrivingdistance,timeandcostbetweenParisandLyon. (3)AccommodationSearch[City]: Description:Discoveraccommodationsinyourdesiredcity.Parameter:City-Thenameofthecitywhereyou\'reseekingaccommodation.Example:AccommodationSearch[Rome]wouldpresentalistofhotelroomsinRome. (4)RestaurantSearch[City]: Description:Explorediningoptionsinacityofyourchoice.Parameter:City-Thenameofthecitywhereyou\'reseekingrestaurant.Example:RestaurantSearch[Tokyo]wouldshowacuratedlistofrestaurantsinTokyo. (5)AttractionSearch[City]: Description:Findattractionsinacityofyourchoice.Parameter:City-Thenameofthecitywhereyou\'reseekingattractions.Example:AttractionSearch[London]wouldreturnattractionsinLondon. (6)CitySearch[State] Description:Findcitiesinastateofyourchoice.Parameter:State-Thenameofthecitywhereyou\'reseekingcities.Example:CitySearch[California]wouldreturncitiesinCalifornia. (7)NotebookWrite[ShortDescription] Description:WritesanewdataentryintotheNotebooktoolwithashortdescription.ThistoolshouldbeusedimmediatelyafterFlightSearch,AccommodationSearch,AttractionSearch\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c} \\hline \\hline  & Delivery & \\begin{tabular}{c} Commonsense \\\\ Pass Rate \\\\ \\end{tabular} & \\begin{tabular}{c} Hard Constraint \\\\ Pass Rate \\\\ \\end{tabular} & \n' +
      '\\begin{tabular}{c} Final \\\\ Pass Rate \\\\ \\end{tabular} \\\\ \\hline \\hline \\(\\text{Reflexion}_{\\text{GPT}-4-\\text{Turbo}}\\) & \\(80.6\\) & \\(62.9\\) & \\(6.1\\) & \\(52.4\\) & \\(40.0\\) & \\(3.3\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      'Table B.3. GPT-4-Turbo with Reflexion strategy on validation set.\n' +
      '\n' +
      ', RestaurantSearchorDistanceMatrix. OnlythedatastoredinNotebookcanbeseenbyPlanner.SoyoushouldwritealltheinformationyouneedintoNotebook.Parameters:ShortDescription-Abriefdescriptionorlabelforthestoreddata.Youdon\'tneedtowritealltheinformationinthedescription.Thedatayou\'vesearchedforwillbeautomaticallystoredintheNotebook.Example:NotebookWrite[FlightsfromRometoParisin2022-02-01]wouldstoretheinformationofflightsfromRometoParisin2022-02-01intheNotebook.(8)Planner[Query]Description:AsmartplanningtoolthatcraftsdetailedplansbasedonuserinputandtheinformationstoredinNotebook.Parameters:Query:Thequeryfromuser.Example:Planner[Givemea3-daytripplanfromSeattletoNewYork]wouldreturnadetailed3-daytripplan.YoushoulduseasmanyaspossiblestepstocollectengoughinformationtoinputtothePlannertool.Eachactiononlycallsonefunctiononce.Donotaddanydescriptionintheaction.Query:(query) ```\n' +
      '#### b.3.2 Direct Planning Prompt\n' +
      '\n' +
      'We provide the instruction prompt of Direct strategy as follows:\n' +
      '``` Youareaprofficient planner.Basedontheprovidedinformationandquery,pleasegivemeatdeatelplan,includingspecificssuchasflightnumbers(e.g.,F0123456),restaurantnames,andacommodationnames.Notthatalltheinformationinyourplanshouldbederivedfromtheprovideddata.Youmustadheretotheformatgivenintheexample.Additionally,alldetailsshouldalignwithcommonsense.Thesymbol\'-\'indicatesthatinformationisunnecessary.Forexample,intheprovidedsample,youdonneedtoplanafterreturningtothedeparturecity.Whenyoutraveltotwocitiesintoneday,youshouldnotetinthe\'CurrentCity\'sectionasintheexample(i.e.,fromAtoB). ```\n' +
      '\n' +
      '``` ****x Example****x\n' +
      '\n' +
      'Query:Couldyoucreateachallengingtravelplanfor7peoplefromRoanoketoIllinoisspanningaweek,fromMarch8thtoMarch14th,2022,withabudgetof$30,200?Thepreferenceisforanentireroom,andwewouldnotbethakinganyflights.Intermsofcuisine,weareinterestedinsamplingsomeItalianandChinesefood.TravelPlan:Day1:CurrentCity:fromIthacatoCharlotteTransportation:FlightNumber:F3633413,fromIthacatoCharlotte,DepartureTime:05:38,ArrivalTime:07:46Breakfast:Nagaland\'sKitchen,CharlotteAttraction:TheCharlotteMuseumofHistory,CharlotteLunch:CafeMapleStreet,CharlotteDinner:BombayVadaPav,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay2:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomareBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomBeardenPark,Charlotte.Lunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte;RomBeardenPark,CharlotteLunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteAttraction:TheMintMuseum,Charlotte3:RomBeardenPark,CharlotteLunch:BirbalJiDhaba,CharlotteDinner:PindBalluchi,CharlotteAccommodation:AffordableSpaciousRefurbishedRoominBushwick!,CharlotteDay3:CurrentCity:CharlotteTransportation:-Breakfast:OliveTreeCafe,CharlotteBreakfast: Subway, Charlotte\n' +
      '\n' +
      'Attraction: Books Monument, Charlotte.\n' +
      '\n' +
      'Lunch: Olive Tree Cafe, Charlotte\n' +
      '\n' +
      'Dinner: Kylin Skybar, Charlotte\n' +
      '\n' +
      'Accommodation: -\n' +
      '\n' +
      '****** Example Ends******\n' +
      '\n' +
      'Given information: {text}\n' +
      '\n' +
      'Query: {query}\n' +
      '\n' +
      'Travel Plan:\n' +
      '\n' +
      '#### b.3.3.React & Reflexion Planning Prompt\n' +
      '\n' +
      'The instruction prompts for the React and Reflexion planning strategies are provided as follows:\n' +
      '\n' +
      'Youare a proficient planner. Based on the provided information and query, please give me\n' +
      '\n' +
      'a detailed plan, including specifics such as flight numbers (e.g., F0123456), restaurant\n' +
      '\n' +
      'names, and hotel names. Note that all the information in your plan should be derived from\n' +
      '\n' +
      'the provided data. You must adhere to the format given in the example. Additionally, all\n' +
      '\n' +
      'details should align with common sense. Attraction visits and meals are expected to be\n' +
      '\n' +
      'diverse. The symbol \'-\' indicates that information is unnecessary. For example, in the\n' +
      '\n' +
      'provided sample, you do not need to plan after returning to the departure city. When you\n' +
      '\n' +
      'travel to two cities in one day, you should note it in the \'Current City\' section as in\n' +
      '\n' +
      'the example (i.e., from A to B). Solve this task by alternating between Thought, Action,\n' +
      '\n' +
      'and observation steps. The \'thought\' phase involves reasoning about the current situation.\n' +
      '\n' +
      'The \'Action\' phase can be of two types:\n' +
      '\n' +
      '(1) CostEnquiry[Sub Plan]: This function calculates the cost of a detailed sub plan, which\n' +
      '\n' +
      'you need to input the people number and plan in JSON format. The sub plan should\n' +
      '\n' +
      'encompass a complete one-day plan. An example will be provided for reference.\n' +
      '\n' +
      '(2) Finish[Final Plan]: Use this function to indicate the completion of the task.\n' +
      '\n' +
      'You must submit a final, complete plan as an argument.\n' +
      '\n' +
      '****** Example******\n' +
      '\n' +
      'Query: Could you create a challenging travel plan for 7 people from Roanoke to Illinois\n' +
      '\n' +
      'spanning a week, from March 8th to March 14th, 2022, with a budget of $30,200? The\n' +
      '\n' +
      'preference is for an entire room, and we would not be taking any flights. In terms of\n' +
      '\n' +
      'cuisine, we are interested in sampling some Italian and Chinese food.You can call\n' +
      '\n' +
      'CostEquiry like CostEquiry[(["people_number": 7,"day": 1,"current_city": "from Ithaca to\n' +
      '\n' +
      ' Charlotte","transportation": "Flight Number: F3633413, from Ithaca to Charlotte,\n' +
      '\n' +
      'Departure Time: 05:38, Arrival Time: 07:46","breakfast": "Nagaland\'s Kitchen, Charlotte","\n' +
      '\n' +
      'attraction": "The Charlotte Museum of History, Charlotte","lunch": "Cafe Maple Street,\n' +
      '\n' +
      'Charlotte","dinner": "Bombay Vada Pav, Charlotte","acommodation": "Affordable Spacious\n' +
      '\n' +
      'Refurbished Room in Bushwick!, Charlotte")]\n' +
      '\n' +
      'You can call Finish like Finish[\n' +
      '\n' +
      'Day: 1\n' +
      '\n' +
      'Current City: from Ithaca to Charlotte Charlotte, Departure Time: 05:38,\n' +
      '\n' +
      'Transportation: Flight Number: F3633413, from Ithaca to Charlotte,\n' +
      '\n' +
      'Arrival Time: 07:46\n' +
      '\n' +
      'Breakfast: Nagaland\'s Kitchen, Charlotte\n' +
      '\n' +
      'Attraction: The Charlotte Museum of History, Charlotte\n' +
      '\n' +
      'Lunch: Cafe Maple Street, Charlotte\n' +
      '\n' +
      'Dinner: Bombay Vada Pav, Charlotte\n' +
      '\n' +
      'Accommodation: Affordable Spacious Refurbished Room in Bushwick!, Charlotte\n' +
      '\n' +
      'Day 2:\n' +
      '\n' +
      'Current City: Charlotte\n' +
      '\n' +
      'Transportation: -\n' +
      '\n' +
      'Breakfast: Olive Tree Cafe, Charlotte\n' +
      '\n' +
      'Attraction: The Mint Museum, Charlotte;Romare Bearden Park, Charlotte.\n' +
      '\n' +
      'Lunch: Birbal Ji Dhaba, Charlotte\n' +
      '\n' +
      'Dinner: Pind Balluchi, Charlotte\n' +
      '\n' +
      'Accommodation: Affordable Spacious Refurbished Room in Bushwick!, Charlotte \n' +
      'Day 3: Current City: Charlotte Transportation: Flight Number: F3786167, from Charlotte to Ithaca, Departure Time: 21:42, Arrival Time: 23:26 Breakfast: Subway, Charlotte Attraction: Books Monument, Charlotte. Lunch: Olive Tree Cafe, Charlotte Dinner: Kylin Skybar, Charlotte Accommodation: -J ******* Example Ends *******\n' +
      '\n' +
      'You must use Finish to indict you havefinished the task. Andeach action only calls one function once. Given information: {text} Query: {query}\n' +
      '\n' +
      '#### b.3.4 Query Generation Prompt\n' +
      '\n' +
      'The instruction prompt for query generation is provided as follows:\n' +
      '\n' +
      '```\n' +
      'GivenaJSON,pleasehelpmegeneratanaturallanguagequery.IntheJSON,\'org\'denotesthedeparturecity.When\'days\'exceeds3,\'visiting_city_number\'specifiesthenumberofcitiestocoveredinthedestinationstate.Herearethreeexamples. ------EXAMPLE1--- JSON: ("org": "GuIfport","dest": "Charlotte","days": 3,"visiting_city_number": 1,"date": ["2022-03-05","2022-03-06","2022-03-07"],"people_number": 1,"constraint": {"roomrule": null,"cuisine": null,"roomtype": null},"budget": 1800} QUERY: PleasedesignatravelplandepartingGulfportandheadingtocCharlottefor3days, spanningMarch5thtoMarch7th,2022,withabudgetof$1800. ------EXAMPLE2----- JSON: ("org": "Omaha","dest": "Colorado","days": 5,"visiting_city_number": 2,"date": ["2022-03-14","2022-03-15","2022-03-16","2022-03-17","2022-03-18"],"people_number": 7,"constraint": {"roomrule": "pets","cuisine": null,"roomtype": null},"budget": 35300} QUERY: Couldyouprovidea5-daytravelitineraryforagroupof7,startinginOmahaandexploring2citiesinColoradobetweenMarch14thandMarch18th,2022?Ourbudgetissetat$35,300,andit\'sessentialthatouraccommodationsbepet-friendlysincewe\'rebringingourpets. ------EXAMPLE3----- JSON: ("org": "Indianapolis","dest": "Georgia","days": 7,"visiting_city_number": 3,"date": ["2022-03-01","2022-03-02","2022-03-03","2022-03-04","2022-03-05","2022-03-06","2022-03-07"],"people_number": 2,"constraint": {"roomrule": null,"cuisine": ["Bakery","Indian"],"roomtype": "entireroom","transportation": "selfdriving"},"budget": 6200} QUERY: I\'mlookingforaweek-longtravelitineraryfor2individuals.OurjourneystartsinIndianapolis,andweintendtoexplore3distinctcitiesinGeorgiafromMarch1sttoMarch7th,2022.Ourbudgetiscappedat$6,200.Forouraccommodations,we\'dpreferanentireroom.Weplanto navigateourjourneyviaself-driving.Intermsoftfood,we\'reenthusiastsofbakeryitems,andwe\'dalsoappreciateindulgingingenuineIndiancuisine. ------EXAMPLESEND------ JSON: {json} QUERY:\n' +
      '```\n' +
      '\n' +
      '#### b.3.5 Key Components Extraction Prompt\n' +
      '\n' +
      'The instruction prompt for plan key components extraction is provided as follows:\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:19]\n' +
      '\n' +
      '"2022-03-13", "2022-03-14", "2022-03-15", "2022-03-16", "2022-03-17" ],  "people_number": 5, "roomrule": "pets", "cuisine": [  "Mexican",  "Italian",  "Mediterranean",  "Indian"  ],  "roomtype": "entireroom",  "transportation": null,  "budget": "15100,  "query": "Can you help with generating a 7-day travel plan for a party of 5? We\'re  setting off from Indianapolis and planning to explore 3 cities in Colorado from March  11th to March 17th, 2022. We have a budget of $15,100 for this trip. We\'ll be bringing  our pets, so pet-friendly accommodations are a must. We\'re also hoping to find places  that offer Mexican, Italian, Mediterranean, and Indian cuisines. Entire rooms for  accommodations would be ideal.",  "level": "hard",  "annotated plan": [  {  "days": 1,  "current_city": "from Indianapolis to Grand Junction(Colorado)",  "transportation": "Self-driving, from Indianapolis to Grand Junction(Colorado), , duration: 19 hours 21 mins, distance: 2,132 km, cost: 106",  "breakfast": "-",  "attraction": "-",  "lunch": "-",  "dinner": "Nokkadwala, Grand Junction(Colorado)",  "accommodation": "Lovely 1 BD on the Upper West Side, Grand Junction(Colorado)  "  },  {  "days": 2,  "current_city": "Grand Junction(Colorado)",  "transportation": "-",  "breakfast": "Om Ji Bhature Wale, Grand Junction(Colorado)",  "attraction": "Museum of the West, Museums of Western Colorado, Grand Junction (Colorado);"Eurcek! MCConnell Science Museum, Grand Junction(Colorado);",  "lunch": "Penta Cafe, Grand Junction(Colorado)",  "dinner": "Kings Kulfi, Grand Junction(Colorado)",  "accommodation": "Lovely 1 BD on the Upper West Side, Grand Junction(Colorado)  " },  {  "days": 3,  "current_city": "from Grand Junction(Colorado) to Alamosa(Colorado)",  "transportation": "Self-driving, from Grand Junction(Colorado) to Alamosa(  Colorado),  Colorado), duration: 4 hours 37 mins, distance: 397 km, cost: 19",  "breakfast": "Punjab Da Pind, Grand Junction(Colorado)",  "attraction": "Alamosa Colorado Welcome Center, Alamosa(Colorado);Toivo Malm  Trail System, Alamosa(Colorado);",  "lunch": "Emperor\'s Louinge - The Taj Mahal Hotel, Alamosa(Colorado)",  "dinner": "Cafe Dalal Street, Alamosa(Colorado)",  "accommodation": "Sunny Chelsea Studio, Alamosa(Colorado)"  },  {  "days": 4,  "current_city": "Alamosa(Colorado)",  "transportation": "-","breakfast": "Good Luck Cafe, Alamosa(Colorado)", "attraction": "Alamosa Archery Range, Alamosa(Colorado);Alamosa Riparian Park, Alamosa(Colorado);Alamosa Sub, Alamosa(Colorado);", "lunch": "Shri Durga Dosa Corner, Alamosa(Colorado)", "dinner": "Lahore, Alamosa(Colorado)", "accommodation": "Sunny Chelsea Studio, Alamosa(Colorado)" }, { "days": 5, "current_city": "from Alamosa(Colorado) to Denver(Colorado)", "transportation": "Self-driving, from Alamosa(Colorado) to Denver(Colorado), duration: 3 hours 38 mins, distance: 377 km, cost: 18", "breakfast": "Hamburg To Hyderabad, Alamosa(Colorado)", "attraction": "Denver Zoo, Denver(Colorado);", "lunch": "The Fatty Bao - Asian Gastro Bar, Denver(Colorado)", "dinner": "Woods Spice, Denver(Colorado)", "accommodation": "Peaceful, beautiful home away, Denver(Colorado)" }, { "days": 6, "current_city": "Denver(Colorado)", "transportation": "-", "breakfast": "The Urban Socialite, Denver(Colorado)", "attraction": "Denver Art Museum, Denver(Colorado);Denver Museum of Nature & Science, Denver(Colorado);", "lunch": "Breaktyp, Denver(Colorado)", "dinner": "Chawla\'su5b8a, Denver(Colorado)", "accommodation": "Peaceful, beautiful homeaway, Denver(Colorado)" }, { "days": 7, "current_city": "from Denver(Colorado) to Indianapolis", "transportation": "Self-driving, from Denver(Colorado) to Indianapolis, duration: 15 hours 37 mins, distance: 1,747 km, cost: 87", "breakfast": "Starve Stalkers, Denver(Colorado)", "attraction": "-", "lunch": "-", "dinner": "-", "accommodation": "-" } } }\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:22]\n' +
      '\n' +
      '**Query:** Please curate a 3-day travel plan for a solo traveler from Tulsa to Houston from March 23rd to March 25th, 2022, with a total travel budget of $1,000.\n' +
      '\n' +
      '**Plan:**\n' +
      '\n' +
      '(\n' +
      '\n' +
      '"day": 3,\n' +
      '\n' +
      '"current, cty": "from Houston to Tulsa",\n' +
      '\n' +
      '"transportation": "Flight Number: F4013298, from\n' +
      '\n' +
      ' Houston to Tulsa, **Departure Time: 08:20, Arrival**\n' +
      '\n' +
      'Time: 09:43**\n' +
      '\n' +
      '"breakfast": "Earthen Spices, Houston",\n' +
      '\n' +
      '"attraction": "The Museum of Fine Arts,"\n' +
      '\n' +
      '"Rouson,"Hermann Park, Houston","\n' +
      '\n' +
      '"Blunch": "Chewla, Houston",\n' +
      '\n' +
      '"dinner": "-",\n' +
      '\n' +
      '"accommodation": -"\n' +
      '\n' +
      ').\n' +
      '\n' +
      '**Analysis:**\n' +
      '\n' +
      'In this example, the language agent scheduled an 8:20 AM flight departure from Houston but still planned a subsequent trip and lunch in Houston. This plan is illogical, as it overlooks the fact that the agent would no longer be in the city post-flight.\n' +
      '\n' +
      '**Figure C.3**. Case 6 (Two-stage mode).\n' +
      '\n' +
      '**Query:** Could you help develop a week-long travel itinerary suitable for a group of 6 people, departing from Baton Rouge and planning to visit 3 different cities in Texas? The travel dates are set from March 17th to March 23rd, 2022. Our travel budget has been adjusted to $14,600. Bearing in mind that we have children under ten years old, our accommodations need to allow young children and we prefer to occupy entire rooms. We also prefer not to self-drive during this trip.\n' +
      '\n' +
      '**Plan:**\n' +
      '\n' +
      '(\n' +
      '\n' +
      '"days": 1,"\n' +
      '\n' +
      'current_city": "from Baton Rouge to Texarkana",\n' +
      '\n' +
      '"breakfast": "-"\n' +
      '\n' +
      '"Inuch": "Big City Bread Cafe, Texarkana",\n' +
      '\n' +
      '"dinner": "Posts Cafe, Texarkana",\n' +
      '\n' +
      ').\n' +
      '\n' +
      'days": 2,\n' +
      '\n' +
      '"current_city": "Texarkana",\n' +
      '\n' +
      '"transportation": "-"\n' +
      '\n' +
      '"breakfast": "Big City Bread Cafe, Texarkana",\n' +
      '\n' +
      '...)\n' +
      '\n' +
      '**Analysis:**\n' +
      '\n' +
      'In this scenario, the language agents select the same restaurant for both lunch on the first day and breakfast on the second day, a choice that seems to defy commonsense.\n' +
      '\n' +
      '**Figure C.4**. Case 7 (Direct strategy in sole-planning mode).\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:24]\n' +
      '\n' +
      '**Query:**Please assist in crafting a travel plan for a solo traveler, Bourneytung from Detroit to San Diego for 3 days, from March 5th to March 7th, 2022. The travel plan should accommodate a total budget of $3,000.\n' +
      '\n' +
      '**Trajectory:**\n' +
      '\n' +
      'Action 1: CostEnquiry(\'people_number\'; 1, "day"; 1,_")\n' +
      '\n' +
      'Observation 1: Cost: The cost of your plan is 1412.0 dollars.\n' +
      '\n' +
      'Though 2: The cost for the first day is $1412, which includes the flight and activities in San Diego. The remaining budget is $1588..\n' +
      '\n' +
      'Action 2: CostEnquiry(\'people_number\'; 1, "day"; 2,_")\n' +
      '\n' +
      'Observation 2: Cost: the cost of your plan is $271.0 dollars.\n' +
      '\n' +
      'Though 3: The cost for the second day is $721, which includes meals, attractions, and the same accommodation as the first day. The total spent so far is $2133, leaving a remaining budget of $867.\n' +
      '\n' +
      'Action 3: CostEnquiry(\'people_number\'; 1, "day"; 3,_")\n' +
      '\n' +
      'Observation 3: Cost: The cost of your plan is 1114 dollars.\n' +
      '\n' +
      'Though 4: The cost for the third day is $1114, which includes the return flight and activities in San Diego before departure. **The total cost for all three days is now $3247, which exceeds the budget of $3000.** To stay within budget, adjustments need to be made to the third day\'s plan, possibly by choosing a less expensive lunch option and ensuring no additional costs are incurred after the return flight since the traveler will not need accommodation or meals in Detroit for the evening flight.\n' +
      '\n' +
      'Action 4: CostEnquiry(\'people_number\'; 1, "day"; 3,_")\n' +
      '\n' +
      'Observation 4: Cost: The cost of your plan is 1105 dollars.\n' +
      '\n' +
      'Though 5: The revised cost for the third day is $1105, which includes a more affordable lunch option. **The total cost for all three days is now $3238, which is still slightly over the budget of $3000**. To further reduce costs, 1 can look for a less expensive breakfast option on the third day.\n' +
      '\n' +
      'Action 5: CostEnquiry(\'people_number\'; 1, "day"; 3,_")\n' +
      '\n' +
      'Observation 5: Cost: The cost of your plan is 1083 dollars.\n' +
      '\n' +
      'Though 6: The revised cost for the third day is now $1083 after choosing a less expensive breakfast option. The total cost for all three days is $3216, which is closer to the budget but still slightly over, since the flight and accommodation costs are fixed, the only remaining option to adjust would be the attractions or lunch on the second day. However, given the small amount by which the budget is exceeded, it may be acceptable to slightly exceed the budget due to the variability of daily expenses and the possibility of finding deals on-site. The traveler should be prepared for a small buffer in their budget.\n' +
      '\n' +
      '**Action 6: Finish**\n' +
      '\n' +
      'In this example, the language agent acknowledges that the total cost exceeds 3,000 but, after several unsuccessful modifications, settles for the existing solution. It primarily attempts to adjust timing plans, which are less expensive, rather than addressing the more costly transportation and accommodation. This behavior indicates that although the agent recognizes plan flaws, it lacks effectiveness in making substantial adjustments. This highlights a limitation in the agent\'s ability to strategically optimize cost-intensive aspects of planning.\n' +
      '\n' +
      'Figure 7: Case 10 (Reflexion strategy in sole-planning mode).\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>