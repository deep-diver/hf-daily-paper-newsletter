<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '[MISSING_PAGE_FAIL:1]\n' +
      '\n' +
      '######3.1.1. **정책 위반 후보자 선택 가능\n' +
      '\n' +
      '우리는 초기, 더 큰 후보 풀을 선택하기 위해 콘텐츠와 배우 유사성을 사용한다. 콘텐츠 유사성을 위해 그래프 기반 레이블 전파 기법을 활용하여 미리 학습된 임베딩을 기반으로 소스 이미지(과거 사람 또는 모델 레이블 이미지)로 알려진 정책 위반 이미지에서 유사한 이미지로 레이블을 전파한다. 임베딩 공간에서의 거리가 임계값보다 작은 두 이미지는 유사한 것으로 간주된다. 우리는 알려진 정책 위반 콘텐츠의 이웃을 수집하기 위해 유사성 그래프를 구축한다. 행위자 유사성을 위해 정책 위반 활동이 있는 계정에서 후보 광고 이미지를 수집한다.\n' +
      '\n' +
      '주어진 임계값보다 큰 점수를 가진 후보 이미지를 선택하기 위해 어떤 경우에는 미리 훈련된 비LLM 모델을 사용한다. 후보 선택을 위해 미리 훈련된 모델을 사용하는 것은 라벨링에 사용하는 것보다 정밀도 요구 사항이 낮다.\n' +
      '\n' +
      '*Reducing Pool by Deduping, Filtering, Sampling.**\n' +
      '\n' +
      '구글 광고는 중복되거나 거의 중복되는 내용을 많이 포함하고 있어 유사한 내용을 처리하는 데 기계 자원을 낭비한다. 이를 피하기 위해 먼저 LLM이 과거에 이미 검토한 이미지를 제거하기 위해 크로스 데이 디듀싱을 실행합니다. 그런 다음 LLM에 고유한 이미지만 보내기 위해 배치 내 디듀싱을 실행합니다. 또한 비활성 이미지와 이미 레이블이 지정된 이미지를 필터링합니다. 다양한 샘플링을 수행하기 위해 그래프 기반 최대 커버리지 샘플링을 사용하여 다양성을 가진 이미지를 샘플링한다.\n' +
      '\n' +
      '### 대용량 언어모델 튜닝 및 레이블링\n' +
      '\n' +
      'LLM을 주어진 작업에 적응시키기 위해, 프롬프트 엔지니어링(Deng et al., 2017) 및 파라미터 효율적인 튜닝(Deng et al., 2017; Chen et al., 2017)과 같은 상이한 전략을 사용할 수 있다. 신속한 엔지니어링은 LLM에 대해 질문되는 질문을 신중하게 설계하는 것을 포함하는 반면, 매개변수 효율적인 조정은 당면한 작업에 매개변수를 조정하기 위해 라벨이 붙은 데이터 세트에서 더 적은 매개변수로 LLM을 미세 조정하는 것을 포함한다. 본 연구에서는 LLM의 인컨텍스트 학습(Chen et al., 2017)의 능력을 활용하여, 신속한 엔지니어링과 매개변수 효율적인 튜닝의 조합을 사용하여 정책을 잘 수행하는 LLM을 준비했습니다.\n' +
      '\n' +
      '수동으로 선별된 프롬프트에 대한 모델의 성능을 검증하기 위해 정책 전문가가 먼저 프롬프트 엔지니어링을 수행했다. 예를 들어, 비가족 안전 정책의 경우 "이미지에 성적으로 암시하는 내용이 포함되어 있습니까?"와 같은 질문을 LLM에 요청할 수 있다. 그런 다음 LLM의 예측은 이진 예/아니오 정책 레이블로 구문 분석됩니다. LLM의 정확도는 프롬프트에 따라 다르기 때문에 정책 전문가들은 작업에서 가장 성능이 좋은 프롬프트를 선택하기 위해 작은 라벨이 붙은 데이터 세트에서 다양한 프롬프트를 만들고 평가했으며, 이 프롬프트는 소프트 프롬프트 튜닝(Chen et al., 2017)과 함께 사용하여 생산 시스템에서 사용하는 최종 프롬프트를 생성했다. 소프트 프롬프트 튜닝 동안, 라벨링된 트레이닝 세트 상의 정답들을 향해 LLM을 밀도록 작은 해석 불가능한 프롬프트가 트레이닝된다. 이는 문헌에서 LLM 성능을 크게 향상시키는 것으로 나타났으며(Chen et al., 2017), 우리는 실험에서 동일한 것을 관찰했다.\n' +
      '\n' +
      '신속한 엔지니어링 및 튜닝은 정책_당 한 번만 수행되는 일회성 비용입니다. 프롬프트가 구성되면 시스템의 모든 추론 실행에 사용할 수 있습니다. LLM으로 분류하려는 각 후보에 대해 프롬프트와 이미지를 연결하고 레이블링을 위해 LLM에 전달한다.\n' +
      '\n' +
      '### 레이블 전파 및 피드백 루프\n' +
      '\n' +
      '이전 단계의 LLM 레이블 후보로부터 각 이미지의 레이블을 과거 트래픽에서 본 저장된 이미지에서 유사한 이미지로 전파한다. 선택된 LLM 레이블 이미지를 알려진 이미지로 저장하고 들어오는 이미지가 거의 중복으로 간주할 만큼 유사하면 레이블을 지정한다.\n' +
      '\n' +
      'LLM에 의해 직접 또는 라벨 전파를 통해 간접적으로 라벨링된 모든 라벨링된 이미지는 리뷰 후보 선택 단계에서 판독되고, 콘텐츠 유사성 기반 확장을 위해 초기 알려진 이미지에서 입력으로 사용되어 유사한 이미지를 LLM 리뷰의 다음 라운드에 대한 잠재적 후보로서 식별한다.\n' +
      '\n' +
      '##4. 결과 및 논의\n' +
      '\n' +
      '지난 30일 동안 수집한 광고 이미지 4억 장이 넘는 파이프라인을 운영했습니다. 깔때기를 통해 볼륨을 LLM에서 검토하는 0.1% 또는 400k 이미지 미만으로 줄였다. 라벨 전파 후, 포지티브 라벨이 있는 광고의 수는 두 배로 증가했다. 이 파이프라인은 다중 모드 비LLM 모델보다 약 두 배 많은 이미지를 레이블링하는 동시에 "Non-Family Safe" 광고 정책에서 정밀도를 능가한다. 전반적으로 이 파이프라인은 이 정책에 대한 이미지 광고 중 정책 위반 노출의 15% 이상을 제거하는 데 도움이 되었다.\n' +
      '\n' +
      '우리는 이 기술을 비디오, 텍스트 및 랜딩 페이지와 같은 더 많은 광고 정책과 양식으로 확장하고 있습니다. 또한 더 나은 휴리스틱을 탐색하여 깔때기, 더 나은 LLM 프롬프트를 튜닝하고 고품질 임베딩을 통해 유사성을 전파하는 등 모든 파이프라인 단계의 품질을 개선하고 있다.\n' +
      '\n' +
      '## 5. 회사 초상화\n' +
      '\n' +
      '**구글 LLC**는 AI 최초 다국적 기업으로 세계의 정보를 정리하여 보편적으로 접근 가능하고 유용하게 만드는데 주력하고 있다. 구글은 온라인 광고, 검색 엔진 기술, 클라우드 컴퓨팅, 가전제품 분야에서 사업을 운영하고 있다.\n' +
      '\n' +
      '##6. 발표자 전기\n' +
      '\n' +
      '**Wei Qiao**: Wei는 Google Ads Content and Targeting Safety Team의 기술 선두입니다. 그는 효율적인 광고 콘텐츠 조정을 위해 시스템과 워크플로우를 구축하기 위한 노력을 주도하고 있습니다. 연락처 이메일: Weiqiao@google.com.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* (1)\n' +
      '* Anil et al. (2023) Rohan Anil, Andrew M Dai, Othan Fiat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Tarquga, Paige Bailey, Zhiting Chen, et al. 2023. Palm iE technical report. arXiv preprint arXiv:2308.10403 (2023).\n' +
      '* Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbaib, Jared D Kaplan, Prafulla Dhariwal, Arvind Neekalmann, Pranav Shyam, Grish Sastry, Amanda Askell, et al. 2020. 언어 모델은 소수 샷 학습자이다. _ 신경 정보 처리 시스템들_33(2020), 1877-1901의 진보들.\n' +
      '* Chen et al. (2023) Xi Chen, Josip Diolong, Piotr Padevski, Basti Munafox, Sprouix Changpiayo, Jialin Wu, Carlos Bjouzie Ruiz, Sebastian Goodman, Xiao Wang, Yi Tay, et al. 2023. PaL-K: On Scaling up up Multilingual Vision and Language Model. _ arXiv preprint arXiv:2305.18658_(2023).\n' +
      '* Flu et al. (2021) Edward Flu, Felong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weihu Chen. 2021. 로라: 대형 언어 모델의 저순위 적응. _ arXiv preprint arXiv:2106.0985_(2021).\n' +
      '* Lester et al. (2021) Brian Lester, Rami Al-Rfou, and Noah Constat. 2021. Parameter-Efficient Prompt Tuning을 위한 Scale의 Power. In _Conference on Empirical Methods in Natural Language Processing_. [https://aps.sme/microcholaz.org/COVID232396808] (https://aps.sme/microcholaz.org/COVID232396808)\n' +
      '* 레이놀즈와 맥도넬(2021) 라린 레이놀즈와 카일 맥도넬. 2021. 대형 언어 모델을 위한 프롬프트 프로그래밍: 수-샷 패러다임을 넘어서다. In_Extended Abstracts of 2021 CHI Conference on Human Factors in Computing Systems_. 1-7\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>