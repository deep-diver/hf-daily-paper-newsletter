<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '[MISSING_PAGE_FAIL:1]\n' +
      '\n' +
      '#### 3.1.1. **Selecting Possible Policy Violating Candidates.**\n' +
      '\n' +
      'We use content and actor similarity to select an initial, larger pool of candidates. For content similarity, we leverage a graph-based label propagation technique to propagate labels from known policy-violating images as the source images (from past human or model labeled images) to similar images based on pre-trained embeddings. Two images whose distance in the embedding space is less than a threshold are considered similar. We build a similarity graph to collect the neighbors of known policy-violating content. For actor similarity, we collect candidate ad images from the accounts with policy-violating activities.\n' +
      '\n' +
      'To select candidate images with scores larger than the given thresholds, we use pre-trained non-LLM models in some cases. Using pre-trained models for candidate selection has lower precision requirements than using them for labeling.\n' +
      '\n' +
      '#### 3.1.2. **Reducing the Pool by Deduping, Filtering, Sampling.**\n' +
      '\n' +
      'Google ads contains a lot of duplicate or near-duplicate content, which wastes machine resources on processing similar content. To avoid this, we first run cross-day deduping to remove images already reviewed by LLMs in the past. Then we run intra-batch deduping to only send unique images to LLMs. We also filter out inactive images and those already labeled. To perform diversified sampling, we use graph based maximal coverage sampling to sample images with diversity.\n' +
      '\n' +
      '### Large Language Model Tuning and Labeling\n' +
      '\n' +
      'To adapt an LLM to a given task, one can use different strategies, such as prompt engineering (Deng et al., 2017) and parameter efficient tuning (Deng et al., 2017; Chen et al., 2017). Prompt engineering involves carefully designing the questions that are asked of the LLM, while parameter efficient tuning involves fine-tuning an LLM with fewer parameters on a labeled dataset to adjust its parameters to the task at hand. In our work, we took advantage of the ability of LLMs to do in-context learning (Chen et al., 2017), and used a combination of prompt engineering and parameter efficient tuning to prepare an LLM that performs well on our policy.\n' +
      '\n' +
      'To validate the model\'s performance on manually curated prompts, policy experts first performed prompt engineering. For example, for a Non-Family Safe policy, we might prompt the LLM with a question such as "Does the image contain sexually suggestive content?". The LLM\'s predictions are then parsed into a binary yes/no policy label. Because the LLM\'s accuracy varies depending on the prompt, our policy experts crafted and evaluated various prompts on a small labeled dataset in order to select the best-performing prompt for our task, which was then used in combination with soft-prompt tuning (Chen et al., 2017) to create the final prompt used by our production system. During soft-prompt tuning, a small uninterpretable prompt is trained to nudge the LLM towards the correct answers on a labeled training set. This has been shown in the literature to significantly improve LLM performance (Chen et al., 2017), and we observed the same in our experiments.\n' +
      '\n' +
      'Note that prompt engineering and tuning are one-time costs, performed _only once per policy_. Once the prompt is constructed, it can be used for all inference runs of our system. For each candidate we want to classify with an LLM, we concatenate the prompt and the image and pass them to the LLM for labeling.\n' +
      '\n' +
      '### Label Propagation and Feedback Loop\n' +
      '\n' +
      'From LLM labeled candidates of the previous stage, we propagate the label of each image to the similar images from stored images we\'ve seen in the past traffic. We store selected LLM labeled images as known images and label incoming images if they are similar enough to be considered as near duplicates.\n' +
      '\n' +
      'All labeled images, whether directly by LLMs or indirectly labeled through label propagation, are then read in the review candidate selection stage, and used as input in the initial known images for content similarity based expansion, to identify similar images as potential candidates for the next round of LLM review.\n' +
      '\n' +
      '## 4. Results and Discussions\n' +
      '\n' +
      'We ran our pipeline over 400 million ad images collected over the last 30 days. Through funneling, we reduced the volume to less than 0.1%, or 400k images, which are reviewed by an LLM. After label propagation, the number of ads with positive labels doubled. This pipeline labeled roughly twice as many images as a multi-modal non-LLM model, while also surpassing its precision on the "Non-Family Safe" ad policy. Overall, this pipeline helped remove more than 15% of the policy-violating impressions among image ads for this policy.\n' +
      '\n' +
      'We are expanding this technique to more ad policies and modalities, such as videos, text, and landing pages. We are also improving the quality of all pipeline stages, including funneling by exploring better heuristics, tuning better LLM prompts, and propagating similarity through higher-quality embeddings.\n' +
      '\n' +
      '## 5. Company Portrait\n' +
      '\n' +
      '**Google LLC** is an AI-first multinational company focused on organizing the world\'s information and making it universally accessible and useful. Google operates businesses in online advertising, search engine technology, cloud computing, and consumer electronics.\n' +
      '\n' +
      '## 6. Presenter Biography\n' +
      '\n' +
      '**Wei Qiao**: Wei is a technical lead in Google Ads Content and Targeting Safety team. He is leading efforts to build the systems and workflows for efficient ads content moderation. Contact email: weiqiao@google.com.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* (1)\n' +
      '* Anil et al. (2023) Rohan Anil, Andrew M Dai, Othan Fiat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Tarquga, Paige Bailey, Zhiting Chen, et al. 2023. Palm iE technical report. arXiv preprint arXiv:2308.10403 (2023).\n' +
      '* Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbaib, Jared D Kaplan, Prafulla Dhariwal, Arvind Neekalmann, Pranav Shyam, Grish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. _Advances in neural information processing systems_ 33 (2020), 1877-1901.\n' +
      '* Chen et al. (2023) Xi Chen, Josip Diolong, Piotr Padevski, Basti Munafox, Sprouix Changpiayo, Jialin Wu, Carlos Bjouzie Ruiz, Sebastian Goodman, Xiao Wang, Yi Tay, et al. 2023. PaL-K: On Scaling up a Multilingual Vision and Language Model. _arXiv preprint arXiv:2305.18658_ (2023).\n' +
      '* Flu et al. (2021) Edward Flu, Felong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weihu Chen. 2021. Lora: Low-rank adaptation of large language models. _arXiv preprint arXiv:2106.0985_ (2021).\n' +
      '* Lester et al. (2021) Brian Lester, Rami Al-Rfou, and Noah Constat. 2021. The Power of Scale for Parameter-Efficient Prompt Tuning. In _Conference on Empirical Methods in Natural Language Processing_. [https://aps.sme/microcholaz.org/COVID232396808](https://aps.sme/microcholaz.org/COVID232396808)\n' +
      '* Reynolds and McDonell (2021) Larin Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond the few-shot paradigm. In _Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems_. 1-7.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>