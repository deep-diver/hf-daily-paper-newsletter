<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# GeneOH 확산: 잡음제거 확산을 통한 일반화 가능한 손-물체 상호작용 잡음제거\n' +
      '\n' +
      'Xueyi Liu\\({}^{1,3}\\) Li Yi\\({}^{1,2,3}\\)\n' +
      '\n' +
      '싱화대학({}^{1}\\) 상하이 AI 연구소({}^{2}\\) 상하이 기지연구소\n' +
      '\n' +
      '프로젝트 웹사이트: meowuu7.github.io/GeneOH-확산\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '이 작업에서 우리는 손-물체 상호작용(HOI)을 잡음제거하는 어려운 문제를 해결한다. 잘못된 상호 작용 시퀀스가 주어지면, 목적은 지각적으로 사실적인 시퀀스에 대한 상호 작용 아티팩트를 제거하기 위해 부정확한 손 궤적을 정제하는 것이다. 이 도전은 새로운 상호작용 및 다양한 잡음 패턴에 대한 강력한 일반화의 필요성과 함께 부자연스러운 손 포즈 및 잘못된 손-객체 관계를 포함한 복잡한 상호작용 잡음을 포함한다. 우리는 새로운 접근 방식인 **제네오 확산**를 통해 이러한 문제를 해결하며 두 가지 핵심 디자인을 통합한다. 접촉 중심 표현 GeneOH는 HOI 프로세스를 정보적으로 매개변수화하여 다양한 HOI 시나리오에 걸쳐 향상된 일반화를 촉진한다. 새로운 노이즈 제거 기법은 백색화된 노이즈 공간에서 깨끗한 데이터 매니폴드로 노이즈 데이터 샘플을 투영하도록 훈련된 표준 노이즈 제거 모델과 백색화된 노이즈 공간과 정렬되도록 먼저 확산시키고 표준 노이즈 제거기를 통해 청소함으로써 다양한 노이즈 패턴으로 입력 궤적을 처리할 수 있는 "디노이징 비아 확산" 전략으로 구성된다. 상당한 도메인 변화가 있는 4개의 벤치마크에 대한 광범위한 실험은 우리의 방법의 우수한 효과를 보여준다. GeneOH Diffusion은 또한 다양한 다운스트림 응용에 대한 가능성을 보여준다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '물체와 상호작용하는 것은 우리 일상의 필수적인 부분이며, 이러한 상호작용 동안 손을 정확하게 추적하는 것은 게임, 가상 및 증강 현실, 로봇 공학 및 인간-기계 상호작용과 같은 다양한 응용 분야에 중요해졌다. 그러나 이 작업은 복잡한 역학 및 손 물체 폐색과 같은 수많은 요인으로 인해 매우 복잡하고 배치되지 않았다. 최상의 노력에도 불구하고, 기존의 추적 알고리즘은 종종 그럴듯하고 현실적인 결과를 생성하는 데 어려움을 겪는다.\n' +
      '\n' +
      '다운스트림 작업의 요구 사항을 더 잘 충족시키기 위해 일반적으로 시끄러운 추적 결과를 개선해야 한다. 오류가 있는 손-물체 상호작용(HOI) 시퀀스가 주어지면, HOI 잡음 제거는 프로를 목표로 한다.\n' +
      '\n' +
      '도 1: 제한된 데이터에 대해서만 훈련된, **GeneOH Diffusion**은 새로운 물체, 손동작 및 보이지 않는 잡음 패턴과의 새로운 잡음 상호작용을 청소할 수 있다(_Fig). (a)_), 이산 조작 모드로 다양한 정제된 궤적을 생성한다(_그림). (b)_), 많은 응용을 위한 실용적인 도구이다(_Fig). (c)_).\n' +
      '\n' +
      '관통과와 같은 아티팩트가 없는 자연스러운 상호 작용 시퀀스를 유도한다. 본 연구에서는 객체 포즈가 정확하게 추적된다고 가정하고 손 궤적의 정련에 초점을 맞춘다(Zhou et al., 2022; Grady et al., 2021; Zhou et al., 2021; Zhang et al., 2021). 이러한 설정은 합성 모션들을 세정하는 것(Tendulkar et al., 2023; Huang et al., 2022; Ghosh et al., 2023; Wu et al., 2022), 모션-리타겟팅된 궤적들을 정제하는 것(Hecker et al., 2008; Tak and Ko, 2005; Aberman et al., 2019), 및 가상 객체 조작들(Oh et al., 2019; Kato et al., 2000; Shaer et al., 2010)과 같은 많은 실용적인 요구들과 함께 중요하다. 초기 접근법은 수동으로 설계된 사전(Dewaele et al., 2004; Hackenberg et al., 2011)에 의존했지만 복잡한 소음을 처리하는 데 부적절하다는 것이 입증되었다. 더 최근의 노력들은 데이터로부터 잡음제거 전적을 학습하는 것으로 옮겨갔지만(Zhou et al., 2022; Zhou et al., 2021; Grady et al., 2021), 기존의 설계들은 여전히 만족스러운 해결책을 제공하는 데 미치지 못한다.\n' +
      '\n' +
      'HOI 노이즈 제거를 위한 데이터 전거를 활용하는 것은 몇 가지 어려움에 의해 도전을 받는다. 첫째, 상호작용 잡음은 매우 복잡하여 부자연스러운 손 포즈, 잘못된 손-객체 공간 관계, 일관되지 않은 손-객체 시간 관계를 포함한다. 둘째, 손 움직임, 손-객체 관계 및 잡음 패턴은 상이한 HOI 트랙에 걸쳐 극적으로 변할 수 있다. 예를 들어, 비디오에서 추정된 손 궤적에 나타나는 노이즈 패턴은 부정확한 캡처 또는 주석으로 인한 것과 현저하게 다르다. 잡음 제거 모델은 종종 이러한 도메인 외 데이터에 직면하며 이를 능숙하게 처리할 것으로 예상된다. 그러나 이러한 배포 이동은 데이터 기반 모델에 상당한 문제를 제기한다. 효과적인 솔루션이 부족하면 이전 작업은 항상 이러한 복잡한 상호 작용 소음을 청소할 수 없거나 잘못된 상호 작용을 보이지 않도록 일반화할 수 없다.\n' +
      '\n' +
      '본 논문에서는 이러한 문제를 해결하기 위해 일반화 가능성과 실제 적용 가능성이 강한 강력한 잡음 제거 방법인 **GeneOH Diffusion**을 제안한다(도 1 참조). 본 논문에서 제안하는 방법은 두 가지 핵심 아이디어를 중심으로 문제를 해결한다: 1) 상호작용 영역에 의해 유도된 좌표계에서 중요한 HOI 정보를 인코딩하고 표준화하여 상호 작용을 정보적으로 매개변수화하고 일반화를 촉진할 수 있는 효과적인 HOI 표현을 설계하는 것; 2) 도메인 일반화 가능한 잡음 제거를 위해 백색화된 잡음 공간에서 데이터 다양체로 잡음 데이터를 투영하는 표준 잡음 제거기를 학습한다. 노이즈를 제거하기 위한 고차원 HOI 프로세스를 매개변수화하는 만족스러운 표현은 상호작용 프로세스를 충실하게 표현하고, 노이즈를 강조하며, 일반화 기능을 향상시키기 위해 서로 다른 HOI 트랙을 잘 정렬할 수 있어야 한다. 따라서, 우리는 **GeneOH**, **일반화된 접촉 중심 핸드-**O**ject 공간적 및 시간적 관계를 소개한다. GeneOH는 손 궤적, 손-객체 공간 관계 및 손-객체 시간 관계를 포함하는 상호 작용을 정보적으로 인코딩한다. 나아가 접촉 중심 관점을 채택하고 혁신적인 표준화 전략을 통합한다. 이 접근법은 다양한 HOI 시나리오에 걸쳐 일반화를 촉진하면서 서로 다른 시퀀스 간의 격차를 효과적으로 줄인다. 새로운 잡음 분포에 대한 잡음 제거 모델의 일반화 능력을 향상시키기 위해 두 번째 노력은 잡음 제거 방식 측면에 중점을 둔다. 본 논문에서는 백색화된 잡음 공간에서 데이터 매니폴드로의 매핑을 기술하는 정규 잡음 제거 모델을 학습할 것을 제안한다. 백색화된 잡음 공간은 다양한 잡음 스케일에서 가우시안 잡음을 통해 훈련 데이터세트 내의 깨끗한 데이터로부터 확산된 잡음 데이터를 포함한다. 표준 잡음 제거기를 사용하여 "확산 경유 잡음 제거" 전략을 활용하여 도메인 일반화 가능한 방식으로 다양한 잡음 패턴을 가진 입력 궤적을 처리한다. 먼저 가우시안 노이즈를 통해 확산시켜 백색화된 노이즈 공간에 입력을 정렬한다. 이어서, 확산된 샘플을 정준 잡음 제거 모델에 의해 세정한다. 잡음 제거 모델의 일반화 능력과 잡음 제거 궤적의 충실성 사이의 균형을 맞추기 위해 확산 과정에서 추가된 잡음의 크기를 결정하는 하이퍼-파라미터를 도입하여 확산된 샘플이 원래 입력에 충실하도록 한다. 또한, 단일 단계를 통해 상호 작용 잡음을 청소하는 방법을 배우는 대신, 입력이 각각 GeneOH의 특정 구성 요소 하나를 청소하는 데 집중하는 세 단계를 통해 순차적으로 정제되는 점진적 잡음 제거 전략을 고안한다.\n' +
      '\n' +
      '고품질 MoCap 데이터셋인 GRAB(Taheri et al., 2020), 부정확한 깊이 감지와 부정확한 시력 추정으로 인한 잡음이 포함된 실제 상호작용 데이터셋인 HOI4D(Liu et al., 2022), 동적 움직임과 접촉 변화를 특징으로 하는 데이터셋인 ARCTIC(Fan et al., 2023)의 3가지 데이터셋에 대해 광범위한 실험을 수행하여 본 방법의 현저한 효과와 일반화 가능성을 보여준다. GRAB에 대해서만 훈련할 때 우리의 디노이저는 포괄적인 양적 및 질적 비교에 의해 입증된 바와 같이 새롭고 어려운 잡음 패턴을 가진 HOI4D와 도전적인 상호 작용을 가진 ARCTIC로 일반화할 수 있다. 향후 연구를 지원하기 위해 코드를 공개하겠습니다. 요약하면, 우리의 기여는 다음과 같습니다.\n' +
      '\n' +
      '* 새로운 HOI 시나리오에 대한 강력한 공간적 및 시간적 잡음 제거 능력 및 전례 없는 일반화를 갖는 HOI 잡음 제거 프레임워크;* HOI 프로세스를 충실하게 캡처하고, 부자연스러운 아티팩트를 강조하며, 상이한 객체 및 상호작용에 걸쳐 HOI 트랙을 정렬할 수 있는 GeneOH라는 HOI 표현;\n' +
      '* 점진적 잡음 제거 전략을 통해 다양한 잡음 패턴에 걸쳐 일반화하고 복잡한 잡음을 모두 제거할 수 있는 효과적이고 도메인 일반화 가능한 잡음 제거 방법.\n' +
      '\n' +
      '##2 관련 작품\n' +
      '\n' +
      '손-물체 상호작용은 인간의 행동을 이해하는 데 중요한 주제이다. 이러한 방향을 향한 선행 연구들은 주로 데이터 수집에 초점을 맞추고 있다(Taheri et al., 2020; Hampali et al., 2020; Guzov et al., 2022; Fan et al., 2023; Kwon et al., 2021), 재구성(Tiwari et al., 2022; Xie et al., 2022; Qu et al., 2023; Ye et al., 2023), 상호작용 생성(Wu et al., 2022; Tendulkar et al., 2023; Zhang and Tang, 2022; Ghosh et al., 2023; Li et al., 2023), 및 움직임 정제(Zhou et al., 2022; Grady et al., 2021; Zhou et al., 2021b; Nunez, 2022). HOI 잡음 제거 작업은 상호 작용 잡음이 있는 HOI 시퀀스에서 부자연스러운 현상을 제거하고자 한다. 실제 응용 시나리오에서 노이즈 제거 모델은 도메인 외 상호 작용을 자주 만나 일반화할 것으로 예상된다. 이 문제는 이후 도메인 일반화, 일반적인 기계 학습 토픽(Sicilia et al., 2023; Segu et al., 2023; Wang et al., 2023; Zhang et al., 2023; Jiang et al., 2022; Wang et al., 2022; Blanchard et al., 2011; Muandet et al., 2013; Dou et al., 2019)과 관련되며, 여기서 광범위한 솔루션들이 문헌에서 제안되었다. 그중에서도 도메인 불변성을 활용하여 문제를 해결하는 것이 유망한 해결책이다. 우리의 작업은 높은 수준에서 이러한 접근 방식과 관련이 있다. 그러나 HOI 노이즈 제거 작업에 대한 도메인 불변 정보는 무엇이며 모델이 노이즈 제거를 위해 이러한 정보를 활용하도록 유도하는 방법은 매우 까다롭다. 우리는 불변 표현을 설계하고 도메인 일반화 가능한 디노이징을 위한 표준 디노이저를 배우는 데 중점을 둔다. 더욱이, 우리는 또한 역 문제를 해결하기 위해 데이터 사전들을 레버리지하기를 원하는 흥미로운 작업들과 관련이 있다(Song et al., 2023; Mardani et al., 2023; Tumanyan et al., 2023; Meng et al., 2021; Chung et al., 2022). 우리의 작업을 위해 일반화할 수 있는 잡음 제거 전과가 무엇인지, 데이터에서 이를 배우는 방법, 다양한 분포에서 노이즈 입력을 정제하기 전에 활용하는 방법에 대한 몇 가지 근본적인 질문에 답해야 한다. 우리는 방법 섹션에서 우리의 해결책을 설명할 것이다.\n' +
      '\n' +
      '## 3 Hand-Object Interaction Denoising Diffusion을 통한 잡음제거\n' +
      '\n' +
      '[\\(K\\) 프레임들을 갖는 잘못된 손-물체 상호작용 시퀀스(\\hat{\\mathcal{H},\\mathbf{O})=\\{(\\hat{\\mathbf{H}}_{k},\\mathbf{O}_{k})\\}_{k=1}^{K}\\)가 주어지면, 우리는 물체 포즈 궤적(\\(\\{\\mathbf{O}_{k}}_{k=1}^{K}\\)이 정확한 추종(Zhou et al., 2022; Zhou et al., 2021; Grady et al., 2021; Zhang et al., 2021)을 가정하고 잡음이 많은 손 궤적(\\(\\hat{\\mathbf{H}}_{k}}_{k=1}^{K}\\)을 청소하는 것을 목표로 한다. 이러한 설정은 다양한 도메인에서의 실제적인 적용 가능성을 고려할 때 상당히 중요하다(Tendulkar et al., 2023; Ghosh et al., 2023; Li et al., 2023; Wu et al., 2022; Hecker et al., 2008; Oh et al., 2019; Shaer et al., 2010). 세척된 손 궤적은 부자연스러운 손 포즈, 잘못된 공간 관통, 일관성 없는 시간적 손-객체 관계가 없어야 한다. 손 궤적은 시각적으로 일관된 동작과 조작을 지원하기 위한 물체와의 적절한 접촉을 제시해야 한다. 이 문제는 복잡한 상호 작용 잡음과 새로운 물체, 손 움직임 및 보이지 않는 잡음 패턴으로 인한 서로 다른 상호 작용에 대한 상당한 도메인 갭으로 인해 본질적으로 잘못 배치되었다.\n' +
      '\n' +
      '우리는 1) HOI 프로세스를 충실하게 매개변수화하고 복잡한 HOI의 분포를 단순화하고 다양한 상호 작용에 걸쳐 모델 일반화를 촉진할 수 있는 새로운 HOI 표현을 설계함으로써 위의 어려움을 해결한다(섹션 3.1 및 2) 점진적인 잡음 제거 전략을 통해 복잡한 잡음을 제거하고 다양한 입력 잡음 패턴에 걸쳐 일반화할 수 있는 효과적인 잡음 제거 스킴을 고안한다(섹션 3.2).\n' +
      '\n' +
      '### GeneOH : 일반화된 접촉 중심 손-객체 공간 및 시간 관계\n' +
      '\n' +
      '효과적이고 일반화 가능한 HOI 잡음 제거 모델을 설계하려면 표현 설계에 진지한 노력이 필요하다. 그것은 객체와의 상호 작용에 대한 표현적 모델링과 새로운 객체와 상호 작용에 대한 모델의 일반화를 지원하는 것 사이의 균형을 이루는 것을 포함한다. 이상적인 HOI 표현은 상호 작용 과정을 정확하게 포착하고 공간 관통과 같은 비정상적인 현상을 강조하며 다양한 상호 작용 시퀀스에 걸쳐 정렬을 촉진해야 한다.\n' +
      '\n' +
      '이를 달성하기 위해 GeneOH를 소개합니다. HOI 프로세스를 충실하게 표현하기 위해 손 궤적, 손-객체 공간 관계, 손-객체 시간 관계를 통합한다. 다양한 상호 작용에 걸쳐 정렬을 향상시키기 위해 효과적인 정규화 전략이 추가로 도입된다. 손 궤적과 물체 궤적은 접촉 인식 방식으로 \\(\\mathcal{J}=\\{\\mathbf{J}_{k}\\}_{k}_{k=1}^{K}\\), 상호작용 영역 시퀀스 \\(\\mathcal{P}=\\{\\mathbf{P}_{k}\\}_{k}_{k=1}^{K}\\)으로 표현되는 손 키포인트들의 궤적으로 콤팩트하게 표현된다. 그런 다음 GeneOH의 디자인을 자세히 설명하겠습니다.\n' +
      '\n' +
      '**일반화된 접촉점.** 상호작용 영역은 "일반화된 접촉점"으로 지칭되는, 손 궤적에 가까운 물체 표면으로부터 샘플링된 점들에 기초하여 확립된다. 손의 궤적까지의 거리가 임계 값인 \\(r_{c}\\)을 초과하지 않는 (5mm로 설정) 물체 표면 점들로부터 샘플링된 \\(\\mathbf{P}\\in\\mathbb{R}^{N_{o}\\times 3}\\)으로 표시된 \\(N_{o}\\) 점들이다. 모든 프레임에 걸쳐 이 점들의 시퀀스는 \\(\\mathcal{P}=\\{\\mathbf{P}_{k}\\}_{k=1}^{K}\\)으로 표현되며, 여기서 \\(\\mathbf{P}_{k}\\)은 프레임에서의 점들을 나타낸다. 각 \\(\\mathbf{P}_{k}\\)은 6D 포즈와 연관되는데, \\(\\mathbf{R}_{k}\\)으로 표시된 물체의 방향(또는 관절형 물체에 대한 첫 번째 부분의 방향)과 \\(\\mathbf{P}_{k}\\)으로 표시된 물체의 중심(\\(\\mathbf{t}_{k}\\)으로 표시된다.\n' +
      '\n' +
      '**표준화된 손 궤적.** 손 움직임을 효과적으로 모델링하기 위해 표현에 손 궤적을 포함한다. 특히, 우리는 손 키포인트를 활용하여 간결하고 표현적인 표현을 제공하기 때문에 손을 모델링한다. 우리는 21개의 손 키포인트의 시퀀스로 손 궤적을 표현하며, \\(\\mathcal{J}=\\{\\mathbf{J}_{k}\\in\\mathbb{R}^{N_{h}\\times 3}\\}_{k}_{k=1}^{K}\\), 여기서 \\(N_{h}=21\\)으로 표시된다. 또한 객체 포즈의 영향을 제거하기 위해 일반화된 접촉점의 포즈를 이용하여 손 궤적\\(\\mathcal{J}\\)을 정규화하여 GeneOH에서 표준화된 손 궤적을 생성한다.\n' +
      '\n' +
      '**일반화된 접촉 중심 손-객체 공간 관계.** GeneOH에서 손-객체 공간 표현을 추가로 소개한다. 표현은 장점을 계승하기 위해 손 키포인트와 일반화된 접촉점을 기반으로 한다. 일반화된 접촉점 \\(\\mathbf{o}_{k}\\in\\mathbff{P}_{k}\\)에 중심을 둔 공간 관계는 \\(\\mathbf{o}_{k}\\)에서 각 손 키포인트 \\(\\mathbf{h}_{k}\\in\\mathbff{J}_{k}\\), _i.e.,_\\(\\mathbff{h}_{k}-\\mathbff{o}_{k}\\in\\mathbff{J}_{k}\\), 객체 점 법선 \\(\\mathbf{n}_{k}\\), 객체 점 위치 \\(\\mathbf{o}_{k}\\)으로 구성된다. 이러한 통계는 교차 상호작용 정렬을 장려하기 위해 일반화된 접촉점의 6D 포즈를 사용하여 후속적으로 표준화된다. 형식적으로 \\(\\mathbf{o}_{k}\\)에 중심을 둔 공간 표현은 \\(\\mathbf{s}_{k}^{\\mathbf{o}}=((\\mathbf{o}_{k}-\\mathbf{t}_{k})\\mathbf{R}_{k}^{T},\\mathbf{n}_{n}\\mathbf{R}_{k}^{T},\\{(\\mathbf{h}-\\mathbf{o}_{k})\\mathbf{R}_{k}^{T},\\{(\\mathbf{h}-\\mathbf{o}_{k})\\mathbf{R}_{h}^{t}\\in\\mathbf{J}\\})으로 정의된다. 공간관계\\(\\mathcal{S}\\)는 일반화된 접점마다 \\(\\mathbf{s}_{k}^{\\mathbf{o}\\)으로 구성된다. \\(\\mathcal{S}=\\{\\mathbf{s}_{k}^{\\mathbf{o}}|\\mathbf{o}_{k}\\in\\mathbf{P}_{k}\\}_{k=1}^{K}\\. 객체 정규 및 손-객체 상대 오프셋을 인코딩함으로써, \\(\\mathcal{S}\\)은 관통과 같은 부자연스러운 손-객체 공간 관계를 드러낼 수 있다.\n' +
      '\n' +
      '**일반화된 접촉 중심 손-객체 시간 관계.** 일치하지 않는 손-객체 움직임으로 인한 잘못된 조작과 같은 시간적 오류를 드러내는 데 있어 위의 두 표현의 한계를 고려하여 HOI 시간 정보를 명시적으로 매개변수화하기 위해 손-객체 시간 관계를 추가로 도입한다. 우리는 다시 손 모양을 표현하기 위해 손 특징점\\(\\mathbf{J}\\)과 일반화된 접촉점\\(\\mathbf{P}\\)을 취하여 물체 모양에 대한 일반화 지원의 장점을 이용한다. 시간 관계는 프레임 \\(k\\)에서 각 손 점 \\(\\mathbf{o}\\)과 각 손 키 점 \\(\\mathbf{ho}=\\mathbf{v}_{k}_{k,\\perp}^{\\mathbf{ho}}=e^{-k\\cdot d_{k,\\perp}^{\\mathbff{ho}}}k_{k,\\perp}^{\\mathbff{ho}}}k_{a}\\\\(\\mathbff{h}}=e^{-k\\mathbf{ho}\\\\(\\mathbff{o}\\))의 상대 속도를 부호화하고, 표상에서 \\(\\mathbff{v}_{v}_{k,\\perp}^{\\mathbf{ho}}=e^{-k\\mathbf{o}\\)의 두 정규화된 통계량을 유도한다. 여기서 \\(k\\), \\(k_{a}\\), \\(k_{b}\\)은 양의 하이퍼파라미터이며, \\(e^{-k\\cdot d_{k}^{\\mathbf{ho}}\\)이라는 용어는 손과 물체점 사이의 거리와 음의 관계가 있다. 이 표준화 및 인코딩 전략은 모델이 두 가지 유형의 상대 속도에 대해 다른 잡음 제거 전략을 학습하도록 유도하고, 객체 포즈를 인수분해하여 교차 상호작용 일반화를 향상시키며, 매우 가까운 손-객체 포인트 쌍 간의 상대 이동을 강조하는 것을 목표로 한다. 시간 표현 \\(\\mathcal{T}\\)은 모든 프레임들에 걸친 각각의 손-객체 포인트 쌍의 상기 통계들을 함께 조합하여 정의된다:\n' +
      '\n' +
      '\\mathcal{T}=\\{\\{\\mathbf{v}_{k}^{\\mathbf{o},\\{d_{k}^{\\mathbf{ho},\\mathbf{v}_{k}^{\\mathbf{ho},e_{k,\\parallel}^{\\mathbf{ho}|\\mathbf{h}_{k}\\in\\mathbff{j}_{k}\\in\\mathbf{p}_{k}\\in\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathbf{p}_{k}\\n\\mathb\n' +
      '\n' +
      '그것은 물체 속도, 손-물체 거리 및 상대 속도를 인코딩함으로써 시간적 오차를 드러낸다.\n' +
      '\n' +
      '도 2: **GeneOH**의 세 가지 성분.\n' +
      '\n' +
      '** GeneOH 표현.** 전체 표현인 GeneOH는 형식적으로 정의된 GeneOH\\(=\\{\\mathcal{\\tilde{J},\\mathcal{S},\\mathcal{T}\\})의 세 가지 구성 요소로 구성된다. 도 2는 설계를 예시한다. 상호 작용 과정을 충실하게 포착하고, 해당 통계를 인코딩하여 노이즈를 드러낼 수 있으며, 신중하게 설계된 표준화 전략을 채택하여 일반화에 도움이 된다. 토치(TOCH, Zhou et al., 2022)는 손-객체 시간 관계 또는 손 모양을 명시적으로 파라미터화하지 않고, 일반화를 용이하게 하기 위해 공간 표준화를 주의 깊게 고려하지 않으며, 이는 그것의 잡음 제거 능력을 제한하고 고주파 손 포즈 세부사항의 손실로 이어질 수 있다. ManipNet(Zhang et al., 2021)은 시간적 관계를 인코딩하지 않고, 접촉 중심 표준화를 통합하지 않아, 상호작용 프로세스를 캡처하기에 부적절하고 일반화 목적에 덜 효과적이다.\n' +
      '\n' +
      '### GeneOH 확산: 잡음제거확산을 통한 점진적 HOI 잡음제거\n' +
      '\n' +
      'GenOH는 상호작용 프로세스를 충실하게 인코딩하고, 노이즈 제거를 용이하게 하기 위한 오류를 강조하며, 다양한 상호작용 시퀀스 간의 격차를 줄이는 데 탁월하지만, 효과적인 노이즈 제거 모델을 설계하는 것은 훈련 중 보이지 않는 분포에서도 복잡한 상호작용 노이즈에 의해 여전히 도전적이다. 이전의 방법들은 전형적으로 특정 패턴들로 제한되는 노이즈 데이터를 클린 데이터 매니폴드에 매핑하도록 트레이닝된 패턴-특정 잡음 제거 모델들을 채용한다(Zhou et al., 2022; 2021). 그러나 이러한 방법은 과적합에 취약하여 실험에서 입증된 바와 같이 보이지 않는 노이즈 패턴과의 상호 작용에 직면할 때 개념적으로 잘못된 결과를 초래한다.\n' +
      '\n' +
      '```\n' +
      '0: 순방향 확산 함수 Diffuse\\((,t)\\), 잡음 제거 모델 \\(\\text{denoise}(\\cdot,t)\\), 입력 잡음점 \\(\\hat{x}\\), 확산 단계 \\(t_{\\text{diff}}\\)\n' +
      '0: 잡음 제거된 데이터 \\(x\\).\n' +
      '1:functionDenoise\\(\\hat{x}^{t_{\\text{diff}}}\\), \\(t_{\\text{diff}}\\)\n' +
      '2:for\\(t\\) from \\(t_{\\text{diff}}\\) to \\(\\mathbf{1}\\)do\n' +
      '3:\\(\\hat{x}^{t-1}\\sim\\text{denoise}(\\hat{x}^{t},t)\\)\n' +
      '4:return\\(\\hat{x}^{0}\\)\n' +
      '5:\\(\\hat{x}\\leftarrow\\)Diffuse(\\(\\hat{x},t_{\\text{diff}}\\))\n' +
      '6:return\\(x\\leftarrow\\text{Denoise}(\\hat{x},t_{\\text{diff}})\\)\n' +
      '```\n' +
      '\n' +
      '**알고리즘 1**확산을 통한 잡음제거\n' +
      '\n' +
      '새로운 상호작용 잡음에 의해 야기되는 도전을 완화하기 위해, 우리는 표준 잡음 제거 모델을 학습하고 도메인 일반화 가능한 잡음 제거를 위해 이를 활용하는 새로운 잡음 제거 패러다임을 제안한다. 그것은 백색화된 잡음 공간으로부터 데이터 매니폴드로의 다양한 잡음 스케일에서의 잡음 데이터로부터 매핑을 기술한다. 백색화된 잡음 공간은 확산 기반 생성 모델들에서 순방향 확산 프로세스와 유사한 풍미인 분산 스케줄에 따라 데이터에 가우스 잡음을 점진적으로 추가하는 _확산 프로세스_를 통해 깨끗한 데이터로부터 확산된 잡음 데이터 샘플들로 채워진다(Song et al., 2020; Ho et al., 2020; Rombach et al., 2022; Dhariwal and Nichol, 2021). 표준 잡음 제거기를 사용하여 "확산 경유 잡음 제거" 전략을 활용하여 일반화할 수 있는 방식으로 다양한 잡음 패턴을 가진 입력 궤적을 처리한다. 먼저 확산 과정을 통해 입력 궤적\\(\\hat{x}\\)을 백색화된 잡음 공간에 더 가까운 다른 샘플\\(\\hat{x}\\)로 확산시킨다. 그리고 확산된 샘플\\(\\hat{x}\\)을 데이터 매니폴드에 투영한다. 디노이징의 일반화 능력과 디노이징된 결과의 정확도의 균형을 맞추기 위해 확산된 \\(\\tilde{x}\\)는 입력에 충실할 필요가 있다. 그리고 확산 단계 수를 결정하는 확산 타임스텝\\(t_{\\text{diff}}\\)을 소개한다. 이 과정은 그림 3의 오른쪽 부분에 시각적으로 묘사되어 있으며, 자세한 내용은 알고리즘 1에 요약되어 있으며, 확산 기반 생성 모델에서 잡음 제거 모델의 기능과 점수 함수의 훈련으로 구현한다. 입력의 노이즈를 단계적으로 제로로 제거하는 다단계 확률적 디노이저입니다. 이러한 방식으로 잡음 제거기는 다양한 스케일에서 잡음을 유연하게 처리할 수 있고, 잘못 배치된 모호한 잡음 제거 문제에 대한 여러 해결책을 제공할 수 있다.\n' +
      '\n' +
      '도메인 일반화 가능한 잡음 제거 전략을 기반으로 한 단계에서 이질적인 상호 작용 잡음을 제거하기 위해 단일 데이터 기반 모델을 설계하는 것은 여전히 실현 가능하지 않다. 상호작용 잡음은 서로 다른 원인에 기인하는 불균일한 스케일에서 다양한 종류의 잡음을 포함한다. 따라서 대응하는\n' +
      '\n' +
      '그림 3: **progressive HOI denoosing**는 입력 잡음 궤적을 세 단계를 통해 점진적으로 정화한다. 각 단계는 _"디노이징 비아 확산"_ 전략을 통해 _canonical denoiser_를 통해 GeneOH의 특정 부분을 디노이징함으로써 궤적을 정제하는 데 집중한다.\n' +
      '\n' +
      '노이즈-투-데이터 매핑은 매우 높은 차원이며, 제한된 데이터로부터 학습하는 것은 매우 어렵다. 복잡성을 해결하기 위한 유망한 해결책은 점진적인 접근 방식을 취하고 여러 전문가를 학습하는 것이며, 각각은 특정 유형의 시끄러운 정보를 청소하는 데 중점을 둔다. 그러나 다단계 공식은 새로운 어려움을 가져온다. 현재 단계가 이전 단계에서 달성한 자연스러움을 손상시키는 것을 방지하기 위해 각 단계에서 청소해야 할 정보에 대한 신중한 고려가 필요하다. 다행히도, GeneOH 표현에 대한 우리의 디자인은 이 문제에 대한 해결책을 촉진한다. HOI 정보는 \\(\\mathcal{\\tilde{J}}\\), \\(\\mathcal{S}\\), \\(\\mathcal{T}\\)의 3개의 비교적 균질한 부분으로 표현될 수 있다. 또한, 세 단계에 걸친 \\(\\mathcal{\\tilde{J}\\), \\(\\mathcal{S}\\), \\(\\mathcal{T}\\) 표상을 잡음제거함으로써 손의 궤적을 순차적으로 개선시킬 수 있다. 이 속성에 대한 공식적인 증명은 부록 A.2에 나와 있다.\n' +
      '\n' +
      '진보적 HOI 잡음 제거.** 표현의 한 측면을 청소하는 데 전념하는 3단계 잡음 제거 접근법(그림 3에서 생략됨)을 설계한다. 각 단계에서 해당 표현에 대한 정규 잡음 제거 모델을 학습하고 "확산 경유 잡음 제거" 전략을 사용하여 잡음 제거를 수행한다. 입력\\(\\text{GeneOH}^{\\text{input}=\\{\\mathcal{\\tilde{J}^{\\text{input},\\mathcal{\\tilde{S}^{\\text{input},\\mathcal{\\tilde{T}^{\\text{input}}\\})이 주어지면, 첫 번째 디노이징 단계인 **MotionDiff**는 잡음의 정준손 궤적을 \\(\\mathcal{\\tilde{J}^{\\text{input}}\\(\\mathcal{\\tilde{J}^{\\text{stage}_{1}})으로 디노이징한다. 하나의 스테이지가 제거된 손궤적\\(\\mathcal{J}^{\\text{stage}_{1}}\\)은 객체포즈를 이용하여 디-정규화(\\mathcal{\\tilde{J}^{\\text{stage}_{1}}\\)함으로써 쉽게 계산될 수 있다. GeneOH\\({}^{\\text{input}}) 또한 이에 따라 GeneOH\\({}^{\\text{stage}_{1}=\\{\\mathcal{\\tilde{J}^{\\text{stage}_{1}},\\mathcal{\\tilde{J}^{\\text{stage}_{1}},\\mathcal{\\tilde{J}^{\\text{stage}_{1}}}으로 갱신될 수 있다. 그리고 두 번째 단계인 **SpatialDiff**는 잡음의 공간적 관계(\\mathcal{\\tilde{S}}^{text{stage}_{1}})와 \\(\\mathcal{\\tilde{S}}^{text{stage}_{2}}}})를 제거한다. 2단계 디노이즈된 손궤적\\(\\mathcal{\\tilde{S}}^{\\text{stage}_{2}}\\)은 손-객체 상대 오프셋으로부터 변환될 수 있다. (\\mathcal{J}^{\\text{stage}_{2}}=\\text{Average}((\\mathbf{h}_{k}-\\mathbf{o}_{k})+\\mathbf{o}_{k}|\\mathbf{o}_{k}\\in\\mathbf{P}_{k}\\}\\). 이후 GeneOH\\({}^{\\text{stage}_{1}}}=\\{\\mathcal{\\tilde{J}^{\\text{stage}_{2}},\\mathcal{\\tilde{S}^{\\text{stage}_{2},\\mathcal{\\tilde{J}^{\\text{stage}_{2}}})로 갱신된다. 마지막으로 마지막 단계인 **TemporalDiff**는 \\(\\mathcal{\\tilde{T}}^{\\text{stage}_{2}}\\)을 \\(\\mathcal{T}^{\\text{stage}_{3}}\\)으로 명명하였다. 상대속도와 같은 시간적 정보는 \\(\\mathcal{T}\\)에 중복적으로 부호화되기 때문에, 유도된 시간적 표현이 \\(\\mathcal{T}^{\\text{stage}_{3}\\)과 일치하도록 \\(\\mathcal{J}^{\\text{stage}_{2}}\\)을 최적화하여 3단계 디노이즈된 손의 궤적 \\(\\mathcal{J}^{\\text{stage}_{3}\\)을 계산한다. 그리고 최종 잡음 제거 출력으로 \\(\\mathcal{J}^{text{stage}_{3}\\)을 \\(\\mathcal{J}\\)으로 표기한다. 부록 A.2에서 입증된 바와 같이 각 단계는 이전 단계 이후에 달성된 자연성을 훼손하지 않는다.\n' +
      '\n' +
      '손 메쉬 궤적에 적합한다. 잡음 제거된 궤적\\(\\mathcal{J}\\)과 물체 궤적에 의해 MANO 파라미터\\(\\{\\mathbf{r}_{k},\\mathbf{t}_{k},\\beta_{k},\\theta_{k}\\{k=1}^{K}\\)를 통해 표현되는 파라미터화된 손 시퀀스는 손 메쉬 궤적에 적합하도록 최적화된다. 자세한 내용은 부록 A.3에 설명되어 있다.\n' +
      '\n' +
      '## 4 Experiments\n' +
      '\n' +
      '우리는 우리의 방법의 효과를 입증하기 위해 광범위한 실험을 수행한다. 동일한 훈련 데이터 세트에서 모든 모델을 훈련하고 도메인 이동 수준이 다른 4개의 테스트 세트를 도입하여 노이즈 제거 능력과 일반화 능력을 평가한다(섹션 4.2 참조). 또한, 섹션 4.3에서 단일 입력에 대해 다수의 합리적인 솔루션을 생성하는 디노이징 방법의 능력을 입증한다. 마지막으로, 우리는 우리가 지원할 수 있는 다양한 애플리케이션을 보여준다(섹션 4.4). 다른 훈련 세트_를 사용하는 또 다른 일련의 실험이 부록 B.1에 제시되어 있다.\n' +
      '\n' +
      '### Experimental Settings\n' +
      '\n' +
      '**Training dataset.** 모든 모델은 GRAB dataset에 대해 학습된다(Taheri et al., 2020). 우리는 TOCH(Zhou et al., 2022)에서 사용되는 교차 객체 분할 전략과 훈련 세트에서 훈련 모델을 따른다. 우리의 잡음 제거 모델은 훈련에 지상 진실 시퀀스만 필요하다. 잡음 대응물이 요구되는 경우, 손 MANO 변환, 회전 및 포즈 파라미터에 가우시안 잡음을 각각 0.01, 0.1, 0.5로 설정하여 각 시퀀스를 섭동한다.\n' +
      '\n' +
      '** 평가 데이터 세트.** 우리는 4개의 별개의 테스트 세트, 즉 가우스 노이즈가 있는 GRAB 테스트 세트, 베타 분포에서 샘플링된 노이즈가 있는 GRAB(베타) 테스트 세트(\\(B(8,2)\\)), 깊이 감지 오류 및 부정확한 포즈 추정 알고리즘으로 인한 실제 노이즈 패턴이 있는 HOI4D 데이터 세트(Liu et al., 2022), 가우스 노이즈가 있지만 접촉 변경과 도전적인 이중 및 동적 상호작용을 포함하는 ARCTIC 데이터 세트(Fan et al., 2023)에 대한 모델과 기준선을 평가한다. 합성 잡음이 포함된 잡음 궤적은 해당 분포에서 샘플링된 잡음을 MANO 매개변수에 추가함으로써 생성된다.\n' +
      '\n' +
      '** 메트릭.** 우리는 두 세트의 평가 메트릭을 소개한다. 첫 번째 세트는 이전 작업(Zhou et al., 2022)에 따른 잡음이 많은 입력으로부터 GT 궤적을 복구하는 모델의 능력을 평가하는 데 중점을 두고 있으며, _Mean Per-Joint/Vertex Position Error(MPJPE/MPVPE)_를 포함하고, 잡음 제거된 손 관절 또는 꼭지점과 해당 GT 위치 사이의 평균 거리를 측정하고 잡음 제거된 궤적에 의해 유도된 접촉 맵과 GT 사이의 유사성을 평가하는 _Contact IoU(C-IoU)_이다. 두 번째 세트는 _Solid Intersection Volume (IV)_ 및 _Penetration Depth_, 관통도 측정, _Proximity Error_, 잡음 제거된 궤적과 GT 사이의 손-객체 근접도의 차이 평가, _HO Motion Consistency_, 손-객체 모션 일관성을 평가하는 등 잡음 제거된 결과의 품질을 정량화한다. 자세한 계산은 부록 C.2에 나와 있다.\n' +
      '\n' +
      '**Baselines.** HOI denoising problem, TOCH(Zhou et al., 2022)에 대한 종래기술과 우리의 모델을 비교한다. "TOCH(w/ MixStyle)"라고 명명된 변형은 TOCH와 일반 도메인 일반화 방법 MixStyle(Zhou et al., 2021)을 결합하여 추가로 생성된다. TOCH가 GRAB 및 GRAB(Beta)의 훈련 세트에 대해 훈련되는 또 다른 변형인 "TOCH(w/Aug.)"는 보이지 않는 잡음 패턴에 대한 견고성을 향상시키기 위해 추가로 도입된다.\n' +
      '\n' +
      '**평가 설정** 모델을 평가할 때 0에서 99까지의 시드를 사용하여 무작위로 샘플링된 100개의 잡음 제거된 궤적에서 입력 잡음 궤적에 가장 가까운 궤적을 선택하고 결정론적 잡음 제거 모델의 경우 단일 실행에서 성능을 보고한다. 우리 모델은 단일 입력에 대해 여러 솔루션을 제공할 수 있기 때문에 품질을 측정하는 두 번째 메트릭 세트에 부록_에서 표준 편차가 있는 _평균의 형태로 모델의 성능을 추가로 보고한다.\n' +
      '\n' +
      '### HOI Denoising\n' +
      '\n' +
      '우리는 모델을 평가하고 GRAB, GRAB(베타), HOI4D 및 ARCTIC의 네 가지 테스트 세트에 대한 이전 작업과 비교했다. GRAB 테스트 세트에서는 모든 객체가 훈련 중에 보이지 않아 상호 작용 분포의 변화를 초래했다. GRAB(Beta) 테스트 세트에서 객체 모양, 상호 작용 패턴 및 노이즈 패턴은 트레이닝 세트의 것과 다르다. HOI4D 데이터 세트는 실제 노이즈와 함께 새로운 객체 및 관찰되지 않은 상호 작용과의 상호 작용 시퀀스를 포함한다.\n' +
      '\n' +
      '그림 4: **정성적 비교. 애니메이션 결과는 당사 웹사이트와 비디오를 참조하십시오. 침투를 해결하기 위한 다른 방법 다양한 배 잡기 다양한 조작 전략\n' +
      '\n' +
      '그림 5: **확률적 잡음 제거**는 이산 모드로 다양한 결과를 생성할 수 있다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:8]\n' +
      '\n' +
      '**노이즈 리타겟드 손 동작을 정제한다.** 도 6의 오른쪽 부분에서, 노이즈 리타겟드 손 궤적을 청소할 때 노이즈 제거 모델의 적용을 보여준다. 우리의 모델은 직접적인 리타겟팅으로 인한 시퀀스에 존재하는 침투를 해결하는 데 탁월하다. 대조적으로, TOCH의 결과는 여전히 눈에 띄는 침투로 고통받는다.\n' +
      '\n' +
      '## 5 Abablation Study\n' +
      '\n' +
      '**일반화된 접촉 중심 매개변수.** GeneOH는 일반화된 접촉점을 활용하여 손-객체 관계를 정규화한다. 이 설계의 효율성을 평가하기 위해 전체 객체 표면에서 샘플링된 점을 매개변수로 사용하는 "우리의(w/o 캐논)"이라는 절제된 모델을 생성한다. 표 2에서 상호작용 영역 주변의 매개변수화에 대한 설계가 보이지 않는 상호작용에 대한 모델의 일반화 능력을 성공적으로 향상시킬 수 있음을 관찰할 수 있다.\n' +
      '\n' +
      '**확산을 통한 잡음 제거.**"확산을 통한 잡음 제거" 전략이 모델의 일반화 능력을 향상시키는 데 미치는 영향을 추가로 조사하기 위해 잡음 제거 모델을 오토인코더 구조로 대체하여 제거한다. 그 결과는 표 2에 요약되어 있으며, "Ours(w/o Diffusion)"와 TOCH의 비교는 GeneOH 표현의 우수성을 강조한다.\n' +
      '\n' +
      '** 손-객체 공간 및 시간 잡음 제거.** 복잡한 상호 작용 잡음을 제거하기 위해 세 단계로 구성된 점진적 잡음 제거 전략을 제안한다. 단일 잡음 제거 단계는 복잡한 상호 작용 잡음이 있는 경우 합리적인 결과를 생성하지 못하기 때문에 이러한 다단계 접근법이 중요하다. 스테이지 디노이징의 효과를 검증하기 위해, 시간 디노이징 모듈을 제거함으로써 "Ours (w/o TemporalDiff)"와 시간 디노이징 모듈과 공간 디노이징 모듈을 제거함으로써 "Ours (w/o SpatialDiff)"의 두 가지 절제된 버전을 만들었다. 그림 7과 표 2는 부자연스러운 손-물체 관통을 제거하고 일관된 손-물체 운동을 시행하는 데 그들의 효과를 보여준다.\n' +
      '\n' +
      '_절제 연구에 대한 양적 및 질적 결과_는 부록 B.2에 포함되어 있다.\n' +
      '\n' +
      '##6 결론 및 한계\n' +
      '\n' +
      '본 연구에서는 일반화 가능한 HOI 노이즈 제거 문제를 해결하기 위해 GeneOH 확산을 제안한다. 우리는 1) 일반화에 친화적인 유익한 HOI 표현을 설계하고 2) 도메인 일반화 가능한 노이즈 제거를 위한 표준 노이즈 제거 모델을 학습함으로써 문제를 해결한다. 실험은 우리의 높은 잡음 제거 능력과 일반화 능력을 보여준다.\n' +
      '\n' +
      '**Limitations.** 주요 한계는 정확한 객체 포즈 궤적의 가정에 있다. HOI 시퀀스가 야생 비디오에서 추정되면 유지되지 않을 수 있다. 객체 포즈와 손 포즈를 동시에 다듬는 것은 가치 있고 실용적인 연구 방향이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c} \\hline \\hline \\multirow{2}{*}{Method} & TV & Penetration Depth & HO Module \\\\  & (\\(\\text{cm}^{-1}\\)) & (\\(\\text{mm}^{-1}\\)) & Consistency (\\(\\text{mm}^{-1}\\)) \\\\ \\hline Input & 2.26 & 2.47 & 46.45 \\\\ \\hline Ours (w/o SpatialDiff) & 2.94 & 3.45 & 31.67 \\\\ Ours (w/o TemporalDiff) & **2.72** & **1.00** & 34.25 \\\\ Ours (w/o Diffusion) & 3.16 & 3.83 & 18.65 \\\\ Ours (w/o Comm.) & 2.36 & 3.57 & 12.66 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: HOI4D 데이터세트에 대한 **절제 연구**,\n' +
      '\n' +
      '도 6: 비디오**(왼쪽)로부터 추정된 **잡음 손 궤적을 정제하고 **리타겟된 손 궤적을 청소하는 **애플리케이션**(오른쪽)\n' +
      '\n' +
      '도 7: **SpatialDiff** 및 **TemporalDiff** 단계의 효과.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* A. Aberman, R. Wu, D. Lischinski, B. Chen, and D. Cohen-Or (2019)Learning character-agnostic motion for motion retargeting in 2d. ArXiv:1905.01680. 인용: SS1.\n' +
      '* G. Blanchard, G. Lee, and C. Scott(2011)Generalizing several related classification tasks from new nonlabeled sample. 신경 정보 처리 시스템24의 발전. 인용: SS1.\n' +
      '* H. Chung, B. Sim, D. Ryu, and J. C. Ye(2022) Improving diffusion models for inverse problems using manifold constraints. ArXiv:2206.00941. 인용: SS1.\n' +
      '* G. Dewaele, F. Devernay, and R. Horaud (2004) Hand motion from 3d point trajectory and smooth surface model. 유럽 Conference on Computer Vision, pp. 495-507. Cited by: SS1.\n' +
      '* P. Dhariwal and A. Nichol (2021)Diffusion model beat gans on image synthesis. The Advances in Neural Information Processing Systems34, pp. 8780-8794. Cited by: SS1.\n' +
      '*Q. Dou D. Coelho de Castro, K. Kamnitsas, and B. Glocker (2019) domain generalizedization via model-agnostic learning of semantic features. 신경 정보 처리 시스템32. 인용: SS1.\n' +
      '*Z. 팬오 타헤리, D. 치오나스, M. 코카바 Kaufmann, M. J. Black, and O. Hilliges (2023)ARCTIC: 손재주 있는 양손 물체 조작을 위한 데이터세트. In Proceedings IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Vol., pp. 3. Cited by: SS1.\n' +
      '* A. Ghosh, R. 다브랄 Golyanik, C. Theobalt, and P. Slusallek (2023)Imos: intent-driven full-body motion synthesis for human-object interaction. Computer Graphics Forum, Vol. 42, pp. 1-12. Cited by: SS1.\n' +
      '* P. Grady, C. Tang, C. D. Twigg, M. 보승 Brahmbhatt, and C. C. Kemp(2021)Contactopt: 컨택트를 최적화하여 파악력을 향상시킵니다. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1471-1481. Cited by: SS1.\n' +
      '* V. 구조프 새틀러, 및 G. 폰스-몰(2022) 착용형 센서로부터 시각적으로 그럴듯한 인간-객체 상호작용 캡처. ArXiv:2205.02830. 인용: SS1.\n' +
      '* G. Hackenberg, R. 맥콜과 W. Broll(2011) 실시간 3D 제스처 제어를 위한 경량 손바닥 및 손가락 추적. 2011 IEEE Virtual Reality Conference, pp. 19-26. Cited by: SS1.\n' +
      '* S. 함팔리 래드 M. 오베르웨거와 V Lepetit(2020)Honnotate: 손 및 물체 포즈의 3d 주석을 위한 방법. CVPR에서 인용됨: SS1.\n' +
      '* C. Hecker, B. Raabe, R. W. Enslow, J. DeWeese, J. Maynard, and K. van Prooijen (2008) 실시간 모션 리타겟팅은 매우 다양한 사용자 생성 형태에 대한 것이다. ACM Transactions on Graphics (TOG)27 (3), pp. 1-11. Cited by: SS1.\n' +
      '* J. Ho, A. Jain, and P. Abbeel(2020) 디노이징 확산 확률 모델. Advances in Neural Information Processing Systems33, pp. 6840-6851. Cited by: SS1.\n' +
      '* S. 황진 왕평리 유영 주원 양, S. Zhu(2023) 3D 장면에서의 확산 기반 생성, 최적화 및 계획. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 16750-16761. Cited by: SS1.\n' +
      '*J. Jiang, Y Shu, J. Wang and M. Long(2022)Transferability in deep learning: a survey. ArXiv:2201.05867. 인용: SS1.\n' +
      '* H. Kato, M. 빌링허스트, 아이 푸피레프, 케이 이마모토, K. 타치바나(2000) 테이블-탑 ar 환경에서 가상 객체 조작. In Proceedings IEEE and ACM International Symposium on Augmented Reality (ISAR 2000), pp. 111-119. Cited by: SS1.\n' +
      '\n' +
      '* Kwon et al. (2021) Taein Kwon, Bugra Tekin, Jan Stuhmer, Federica Bogo, and Marc Pollefeys. H2o: 첫 번째 사람 상호 작용 인식을 위해 두 손이 물체를 조작한다. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pp. 10138-10148, 2021.\n' +
      '* Li et al.(2023) Quanzhou Li, Jingbo Wang, Chen Change Loy, and Bo Dai. 암시적 신경 표현을 갖는 태스크 지향 인간-객체 상호작용 생성. _ arXiv preprint arXiv:2303.13129_, 2023.\n' +
      '* Liu et al. (2022) Yunze Liu, Yun Liu, Che Jiang, Kangbo Lyu, Weikang Wan, Hao Shen, Boqiang Liang, Zhoujie Fu, He Wang, and Li Yi. Hoi4d: 카테고리-레벨 인간-객체 상호작용을 위한 4d 자기중심 데이터세트. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pp. 21013-21022, 2022.\n' +
      '* Mardani et al. (2023) Morteza Mardani, Jiaming Song, Jan Kautz, and Arash Vahdat. 확산 모델의 역문제 해결에 대한 변분적 관점 arXiv preprint arXiv:2305.04391_, 2023.\n' +
      '* Meng et al. (2021) Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon. Sdedit: 유도 이미지 합성 및 확률 미분 방정식으로 편집. _International Conference on Learning Representations_, 2021.\n' +
      '* Muandet et al. (2013) Krikamol Muandet, David Balduzzi, and Bernhard Scholkopf. 불변 피쳐 표현을 통한 도메인 일반화 In _International conference on machine learning_, pp. 10-18. PMLR, 2013.\n' +
      '* Nunez(2022) Johnny Nunez. _ 시공간 손 포즈 잡음 제거 모델의 비교 박사학위 논문, 유니버시타트 데 바르셀로나, 2022년\n' +
      '* Oh et al. (2019) 주영오, 박형박, 정민박. 모바일 증강현실을 위한 터치와 헤드 인터랙션을 결합한 가상 객체 조작 Applied Sciences_, 9(14):2933, 2019.\n' +
      '* Qu et al. (2023) Wentian Qu, Zhaopeng Cui, Yinda Zhang, Chenyu Meng, Cuixia Ma, Xiaoming Deng, and Hongan Wang. 희소 뷰로부터의 손-객체 상호작용을 위한 새로운 뷰 합성 및 포즈 추정. _ arXiv preprint arXiv:2308.11198_, 2023.\n' +
      '* Rombach et al. (2022) Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. 잠재 확산 모델을 사용한 고해상도 이미지 합성 In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pp. 10684-10695, 2022.\n' +
      '*Romero et al. (2022) Javier Romero, Dimitrios Tzionas, and Michael J Black. 신체화된 손: 손과 몸을 함께 모델링하고 캡처합니다. _ arXiv preprint arXiv:2201.02610_, 2022.\n' +
      '* Segu et al. (2023) Mattia Segu, Alessio Tonioni, and Federico Tombari. 딥 도메인 일반화를 위한 배치 정규화 임베딩. _ 패턴인식_, 135:109115, 2023.\n' +
      '* Shaer et al. (2010) Orit Shaer, Eva Hornecker et al. Tangible User Interface: 과거, 현재, 미래 방향_ Human-Computer Interaction_, 3(1-2):4-137, 2010의 설립 및 동향(r).\n' +
      '* Sicilia et al. (2023) Anthony Sicilia, Xingchen Zhao, and Sung Jae Hwang. 도메인 일반화를 위한 도메인 적대 신경망: 작동 시 및 개선 방법. _ Machine Learning_, pp. 1-37, 2023.\n' +
      '* Song et al. (2023) Bowen Song, Su Min Kwon, Zecheng Zhang, Xinyu Hu, Qing Qu, and Liyue Shen. 하드 데이터 일관성을 통한 잠재 확산 모형의 역문제 해결 arXiv preprint arXiv:2307.08123_, 2023.\n' +
      '* Song et al. (2020) Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. 확률 미분 방정식을 통한 점수 기반 생성 모델링. _ arXiv preprint arXiv:2011.13456_, 2020.\n' +
      '* Taheri et al. (2020) Omid Taheri, Nima Ghorbani, Michael J Black, and Dimitrios Tzionas. 그랩: 사물에 대한 전신 인간 파악 데이터 세트입니다. In _Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part IV 16_, pp. 581-600. Springer, 2020.\n' +
      '\n' +
      '*탁과 고(2005) 탁세윤과 고형석. 물리 기반 모션 리타겟팅 필터. _ ACM Transactions on Graphics (TOG)_, 24(1):98-117, 2005.\n' +
      '* Tendulkar et al. (2023) Purva Tendulkar, Didac Suris, and Carl Vondrick. 플렉스: 전신 파지 없이 전신 움켜쥐기. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pp. 21179-21189, 2023.\n' +
      '* Tevet et al. (2022) Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, and Amit H Bermano. 인체 움직임 확산 모델 _ ArXiv:2209.14916_, 2022.\n' +
      '* Tiwari et al. (2022) Garvita Tiwari, Dimitrije Antic, Jan Eric Lenssen, Nikolaos Sarafianos, Tony Tung, and Gerard Pons-Moll. Pose-ndf: 신경 거리 필드들로 인간 포즈 다양체들을 모델링한다. In _Computer Vision-ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23-27, 2022, Proceedings, Part V_, pp. 572-589. Springer, 2022.\n' +
      '* Tumanyan et al.(2023) Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. 텍스트 기반 이미지 대 이미지 변환을 위한 플러그 앤 플레이 확산 기능 In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pp. 1921-1930, 2023.\n' +
      '* Wang et al. (2022) Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and Philip Yu. 보이지 않는 도메인으로 일반화: 도메인 일반화에 대한 조사 _ IEEE Transactions on Knowledge and Data Engineering_, 2022.\n' +
      '* Wang et al.(2023) Pengfei Wang, Zhaoxiang Zhang, Zhen Lei, and Lei Zhang. 도메인 일반화를 위한 선명도 인식 그래디언트 매칭 In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pp. 3769-3778, 2023.\n' +
      '* Wu et al. (2022) Yan Wu, Jiahao Wang, Yan Zhang, Siwei Zhang, Otmar Hilliges, Fisher Yu, 및 Siyu Tang. 사가: 접촉으로 온몸을 움켜쥐는 확률론적. In _Computer Vision-ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23-27, 2022, Proceedings, Part VI_, pp. 257-274. Springer, 2022.\n' +
      '* Xie et al. (2022) Xianghui Xie, Bharat Lal Bhatnagar, and Gerard Pons-Moll. Chore: 단일 rgb 이미지로부터 접촉, 인간 및 물체 재구성. In _Computer Vision-ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23-27, 2022, Proceedings, Part II_, pp. 125-145. Springer, 2022.\n' +
      '* Yang et al. (2021) Lixin Yang, Xinyu Zhan, Kailin Li, Wenqiang Xu, Jiefeng Li, and Cewu Lu. Cpf: 손-객체 상호작용을 모델링하기 위해 접촉 전위 필드를 학습하는 단계. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pp. 11097-11106, 2021.\n' +
      '* Ye et al.(2023) Yufei Ye, Poorvi Hebbar, Abhinav Gupta, and Shubham Tulsiani. 일상적인 손-객체 상호작용 클립의 확산-유도 재구성. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pp. 19717-19728, 2023.\n' +
      '* Zhang et al. (2021) He Zhang, Yuting Ye, Takaaki Shiratori, and Taku Komura. Manipnet: 손-객체 공간 표현을 사용한 신경 조작 합성. _ ACM Transactions on Graphics(ToG)_, 40(4):1-14, 2021.\n' +
      '* Zhang et al. (2023) Ruipeng Zhang, Qinwei Xu, Jiangchao Yao, Ya Zhang, Qi Tian, and Yanfeng Wang. 일반화 조정과 함께 연합 도메인 일반화. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pp. 3954-3963, 2023.\n' +
      '* Zhang & Tang(2022) Yan Zhang and Siyu Tang. 3D 장면에서 오디세우스의 방황. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pp. 20481-20491, 2022.\n' +
      '* Zhou et al. (2021) Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. 믹스 스타일로 도메인 일반화 2021a _ICLR_에서.\n' +
      '* Zhou et al. (2021) Kanglei Zhou, Zhiyuan Cheng, Hubert PH Shum, Frederick WB Li, 및 Xiaohui Liang. Stgae: 손동작 잡음 제거를 위한 시공간 그래프 자동 인코더. In _2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)_, pp. 41-49. IEEE, 2021b.\n' +
      '\n' +
      '* Zhou et al. (2022) Keyang Zhou, Bharat Lal Bhatnagar, Jan Eric Lenssen, and Gerard Pons-Moll. 토치: 움직임 개선을 위한 손과 시공간 객체 대응. _European Conference on Computer Vision (ECCV)_. 2022년 10월 스프링거\n' +
      '* Zhou et al. (2018) Qian-Yi Zhou, Jaesik Park, and Vladlen Koltun. Open3D: 3D 데이터 처리를 위한 최신 라이브러리. _ arXiv:1801.09847_, 2018.\n' +
      '\n' +
      '**개요*****부록**은 본논문을 지원하기 위한 자료목록을 제공한다.\n' +
      '\n' +
      '**추가적인 기술설명(Sec. A) **\n' +
      '* 본문을 보완하기 위해 추가적인 설명을 한다.\n' +
      '* _ the GeneOH representation (Sec. A.1)_ 우리는 표현 디자인에 대한 더 많은 통찰력, GeneOH가 오류를 강조할 수 있는 이유 및 이전 작업에서 설계된 표현과 비교하는 방법에 대해 논의한다.\n' +
      '* _GeneOH Diffusion (Sec. A.2)_ 우리는 백색화된 잡음 공간, 확산 과정, 다단계 확률적 잡음 제거 과정, "확산을 통한 잡음 제거" 전략, 그리고 _progressive denoising_에 대해 더 이야기하며, 각 잡음 제거 단계가 이전 단계 이후에 달성된 자연스러움을 깨지 않고 입력을 성공적으로 청소할 수 있는 이유에 대한 논의와 함께 이야기한다.\n' +
      '* _ Hand mesh trajectory (Sec. A.3.)_ 피팅 과정에 대한 세부 정보를 제공합니다.\n' +
      '* ** 추가 실험 결과(Sec. B) **\n' +
      '*포함하는 방법의 효과를 뒷받침하기 위해 본 절에서 더 많은 실험 결과를 포함한다\n' +
      '* _HOI denoising results (Sec. B.1)_ 우리는 이중 조작이 있는 _long 시퀀스를 포함하여 GRAB, GRAB(베타), HOI4D 및 ARCTIC 데이터 세트에 대한 더 많은 잡음 제거 결과를 포함한다. 또한, 학습 데이터셋이 _ARCTIC 데이터셋_의 학습 집합으로 변경되는 _another series of experiments_의 결과를 논의한다.\n' +
      '* _Ablation studies (Sec. B.2)_ 우리는 절제 연구의 더 많은 양적 및 질적 결과를 제공한다.\n' +
      '* _Applications(Sec. B.3)_ 우리는 우리 모델이 지원할 수 있는 응용 프로그램에 대한 더 많은 결과를 제공합니다.\n' +
      '* _Failure case (Sec. B.4)_ 우리는 우리 방법의 한계와 실패 사례에 대해 논의한다.\n' +
      '*_실제 손-물체 상호작용 궤적에서의 잡음과 인공 잡음의 구별 분석(Sec. B.5)._ 우리는 실제 잡음 패턴과 인공 잡음의 차이에 대해 논의한다.\n' +
      '* _User study (Sec. B.6)_ 우리는 또한 잡음 제거된 결과의 품질을 추가로 평가하기 위한 사용자 연구를 포함한다.\n' +
      '**Experimental Details(Sec. C) **\n' +
      '* 우리는 복잡도 분석뿐만 아니라 데이터 세트, 메트릭, 기준선, 모델, 훈련 및 평가 설정, 실행 시간에 대한 세부 사항을 설명한다.\n' +
      '\n' +
      '우리는 우리의 작품을 소개하기 위해 비디오와 웹사이트를 포함한다. 웹사이트와 비디오에는 _animated denoised results_가 포함되어 있다. 도전에 대한 직관적인 이해, 모델의 효과 및 이전 접근법에 대한 우월성을 위해 이러한 리소스를 탐색하는 것이 매우 좋습니다.\n' +
      '\n' +
      '## 부록 추가 기술설명\n' +
      '\n' +
      '### GeneOH 표현\n' +
      '\n' +
      '\\(\\mathcal{T}\\)에 대한 표준화 설계에 대한 더 많은 통찰력을 다음과 같이 설명한다.\n' +
      '\n' +
      '**시간 관계 \\(\\mathcal{T}\\)에 대한 표준화 설계**시간 관계 \\(\\mathcal{T}\\)은 각 손-객체 포인트 쌍 \\(\\mathbf{h},\\mathbf{o})\\)의 각 프레임 \\(k\\)에서 손-객체 상대속도 \\(\\mathbf{v}_{k}^{\\text{ho}\\)을 평균하여 움직임 관계를 나타낸다. 또한, 대상체 정준을 통해 상대속도를 2개의 통계량(\\(\\mathbf{v}_{k}^{\\text{ho}\\)으로 분해하고, 대상체 접면에 수직이고 대상점 법선과 평행이고 대상체 접면에 놓인 \\(\\mathbf{v}_{k,\\parallel}^{\\text{ho}\\)으로 정규화한다. 이 분해는 모델이 두 가지 유형의 상대 속도에 대해 다른 잡음 제거 전략을 학습하고 객체 포즈를 인수분해하여 교차 상호작용 일반화를 향상시킬 수 있게 한다. 그러나, 상대 속도에만 의존하는 것은 손-물체 상호작용에서 움직임 잡음을 드러내기에는 불충분하다. 법선 방향과 평행한 동일한 상대 속도는 손이 물체로부터 멀리 떨어져 있을 때는 깨끗한 상태에 대응할 수 있지만, 접촉했을 때는 잡음 상태에 대응할 수 있다. 이를 해결하기 위해 각 손-물체 쌍 사이의 거리와 상대 속도를 다음과 같은 공식을 사용하여 두 개의 통계량(\\{(e_{k,\\perp}^{\\text{ho}},e_{k,\\parallel}^{\\text{ho}})\\}\\)으로 인코딩한다.\n' +
      '\n' +
      'bf{v}_{k,\\perp}^{\\mathbf{ho}} = e^{-k\\cdot d_{k}^{\\mathbf{ho}}\\,k_{b}^{\\mathbf{ho}\\|_{2} \\tag{2}\\\\[e_{k,\\parallel}^{\\mathbf{ho}} = e^{-k\\cdot d_{k,\\parallel}^{mmathbf{ho}\\|_{2}}\\,k_{a}\\|\\mathbf{v}^{k,\\mathbf{ho}}\\\\tag{3}\\\\t}\n' +
      '\n' +
      '여기서 \\(k\\), \\(k_{a}\\), \\(k_{b}\\)은 양의 하이퍼파라미터이며, \\(e^{-k\\cdot d_{k}^{\\mathbf{ho}}\\)이라는 용어는 손과 물체점 사이의 거리와 반비례한다. 이 공식은 표현에서 매우 가까운 손-객체 점 쌍에 대한 통계가 강조될 수 있게 한다.\n' +
      '\n' +
      '**왜 GeneOH가 에러를 강조할 수 있는가?** 공간 에러에 대해, 우리는 주로 손과 물체 사이의 기하학적 관통을 고려한다. GeneOH의 손-물체 공간관계\\(\\mathcal{S}\\)는 물체 정규값과 손-물체 상대 오프셋을 매개변수로 하여 침투를 나타낸다. 구체적으로, 각 손-객체 포인트 쌍 \\((\\mathbf{h}_{k},\\mathbf{o}_{k})\\)에 대해, \\(\\mathbf{o}_{k}\\)의 객체 정규 \\(\\mathbf{n}_{k}\\)과 상대 오프셋 \\(\\mathbf{h}_{k}-\\mathbf{o}_{k}\\) 사이의 내적은 객체 포인트와 손 포인트 사이의 부호화된 거리를 나타낸다. 각 핸드 포인트\\(\\mathbf{h}_{k}\\)에 대해, 모든 일반화된 접점까지의 서명 거리를 공동으로 고려하여 객체 메시까지의 서명 거리를 밝힐 수 있다. 손점\\(\\mathbf{h}_{k}\\)은 객체_if를 관통하고, 객체 메쉬와의 부호 거리가 음수_일 경우에만 공간 관계 파라미터화\\(\\mathcal{S}\\)이 침투 현상을 나타낼 수 있다.\n' +
      '\n' +
      '시간 오차의 경우, 우리는 주로 일관성 없는 손-물체 동작을 고려한다. 일관된 손-물체 동작이 무엇을 나타내는지에 관한 통일된 정의나 진술은 없다. 직관적으로, 손은 물체를 조작할 수 있어야 하며, 여기서 매우 가까운 손-객체 포인트 쌍들 사이의 충분한 접촉 및 일관된 모션이 요구된다. 매우 가까운 손-물체 쌍에 대해서는 물체 표면에서의 슬라이딩 운동은 허용되지만 수직 침투 이동 경향은 허용되지 않는다. 위의 기대와 부자연스러운 상황은 손-물체 상대 속도 및 손-물체 거리와 같은 간단한 통계로부터 드러날 수 있다. 거리는 그들이 서로 가까운지 여부를 알려줄 수 있다. 상대 속도는 그들의 이동 불일치를 드러낼 수 있다. 탄젠트 평면에 놓여 있는 분해된 상대 속도와 탄젠트 평면에 수직인 상대 속도는 각각 표면 슬라이딩 경향과 침투 경향을 나타낸다. 거리 관련 가중치 항 \\(e^{-k_{f}d_{k}^{\\mathbf{ho}}\\)은 서로 매우 가까운 손-물체 쌍을 강조할 수 있다. 따라서 GeneOH에 사용된 시간 관계 표현 \\(\\mathcal{T}\\)은 시간 자연성과 잘못된 현상을 성공적으로 나타낼 수 있다. 따라서 \\(\\mathcal{T}\\)의 분포를 학습하면 시간적 자연성이 무엇이고 잡음 표현을 어떻게 청소하는지를 모델을 가르칠 수 있다.\n' +
      '\n' +
      '** GeneOH 표현**은 강성 또는 관절형 객체를 포함하는 상호작용 시퀀스를 파라미터화하는 데 적용될 수 있다. 그것은 손동작과 손-객체 공간 및 시간 관계를 모두 주의 깊게 통합하는데, 이전 작품에서 디자인에 비해 더 표현적이고 포괄적이다(Zhou et al., 2022; 2021; Zhang et al., 2021). 또한 공간 및 시간 상호 작용 오류를 강조할 수 있습니다. 위의 장점은 GeneOH가 HOI 노이즈 제거 작업에 적합하도록 만든다.\n' +
      '\n' +
      '토치(TOCH, Zhou et al., 2022)는 이전 작업들을 다시 검토하면서, 손-중심 포즈들 또는 손-객체 시간 관계들을 명시적으로 인코딩하지 않고, 교차-상호작용 정렬에 대한 신중한 고려 없이 손들을 객체 상에 접지시킨다. ManipNet(Zhang et al., 2021)은 그들의 관계를 나타내기 위해 손-객체 거리를 취한다. 그러나 이것은 그들의 공간적 관계를 드러내기에는 충분하지 않다. 이 작업에서는 표준화도 신중하게 고려되지 않는다.\n' +
      '\n' +
      '### GeneOH Diffusion\n' +
      '\n' +
      '우리는 다음 텍스트에서 세 가지 잡음 제거 단계에 대해 더 자세히 설명한다.\n' +
      '\n' +
      '백색화된 소음 공간 이 공간은 훈련 데이터를 랜덤 가우시안 잡음 쪽으로 확산시킴으로써 구성된다. 확산 타임스텝(diffusion timestep)\\(1\\leq t_{\\text{diff}}\\leq T\\) 여기서 최대 타임스텝은 입력이 순수한 가우시안 잡음으로 확산되는 정도를 조절한다. 이것은 훈련 중에 확산 모델들에 의해 모델링된 공간이다. 본 연구에서 채택한 확산함수도 확산모델의 정방향 확산과정과 정확히 동일하다. 보다 구체적으로, 데이터 포인트 \\(x\\)가 주어지면, \\(t_{\\text{diff}}\\) 확산은 다음 식을 통해 \\(x\\)와 동일한 크기를 갖는 랜덤 가우시안 잡음 \\(\\mathbf{n}\\)의 선형 조합에 의해 \\(x_{t}\\)으로 변환될 것이다:\n' +
      '\n' +
      '\\[x_{t}=\\sqrt{\\alpha_{t}}x+\\sqrt{1-\\bar{\\alpha}_{t}}\\mathbf{n}, \\tag{4}\\]\n' +
      '\n' +
      '여기서 \\(\\alpha_{t}=1-\\beta_{t},\\bar{\\alpha_{t}=\\Pi_{s=1}^{t}\\alpha_{s_{t}\\left\\beta_{t}\\right\\})는 정방향 공정 분산이다. \\(x_{t}\\)의 분포는 정규분포이다. \\(x_{t}\\sim\\widetilde{\\mathcal{N}(\\sqrt{\\bar{\\alpha}_{t}x,(1-\\sqrt{\\bar{\\alpha}_{t})\\mathbf{I})\\.\n' +
      '\n' +
      '직관적으로, 잡음 공간은 모든 가능한 타임스텝 \\(1\\leq t\\leq T\\)에 걸쳐 모든 가능한 \\(x_{t}\\)을 포함한다. \\ (x_{t}\\)이 작을수록 \\(t\\)은 \\(x\\)과 더 유사할 것이다. 실제로 \\(T\\)을 1000, \\(\\beta_{1}=0.001,\\beta_{T}=0.02\\)으로 설정하고 이들 사이에 선형 보간하여 분산 시퀀스 \\(\\beta_{t}\\}\\)을 생성한다. 훈련 중 \\(t\\)은 \\(\\{t\\t\\in\\mathbb{Z},1\\leq t\\leq T\\}\\에서 균일하게 샘플링된다.\n' +
      '\n' +
      '다단계 확률적 잡음제거 모델은 잡음 스케일 \\(t\\)을 입력으로 하고 잡음 스케일 \\(t-1\\)을 가진 잡음 샘플로 다시 잡음제거하는 \\(\\text{denoise}(\\cdot,t)\\)으로 학습한다. \\(t=1\\)일 때, 잡음 제거된 결과는 모델에 의해 묘사된 깨끗한 데이터 다양체에 있으며 최종 잡음 제거된 결과로 간주된다. Denoise\\((\\cdot,t)\\)는 입력 잡음 샘플의 잡음 성분을 예측하기 위해 점수 함수\\(\\epsilon_{\\theta}(\\cdot,t)\\)를 평균한다. 점수 함수 \\(\\epsilon_{\\theta}(\\cdot,t)\\)는 최적의 네트워크 가중치 \\(\\theta\\)를 포함하고 있으며 훈련 중에 배워야 할 것이다. \\\\ (\\epsilon_{\\theta}(\\cdot,t)\\)는 잡음 성분\\(\\hat{\\mathbf{n}}\\)만을 예측한다. 그 후, 다음 식을 통해 \\(\\tilde{x}_{t}\\)와 예측된 \\(\\hat{\\mathbf{n}\\)에 기초하여 \\(\\tilde{x}_{t-1}\\)을 샘플링하기 위해 사후 샘플링 프로세스를 활용한다.\n' +
      '\n' +
      '\\frac{1}{\\sqrt{\\alpha_{t}}(\\tilde{x}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\tilde{\\alpha}_{t}}\\epsilon_{\\theta}(\\tilde{x}_{t},t))+\\sigma_{t}\\mathbf{z}, \\tag{5}\\tqrt{t}}\n' +
      '\n' +
      '여기서 \\(\\mathbf{z}\\in\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\), \\(\\sigma_{t}^{2}=\\beta_{t}\\). 따라서 잡음 제거 모델은 각 단계에서 사후 분포의 평균만 식별하고 잡음 제거된 결과는 예측된 평균과 미리 정의된 분산으로 분포에서 샘플링해야 하기 때문에 다단계 확률적 잡음 제거 모델이다.\n' +
      '\n' +
      '**"디노이징 비아 확산" 전략.** 잡음 \\(\\hat{x}\\)을 갖는 입력 궤적은 다음 식을 사용하여 확산 타임스템 \\(t_{\\text{diff}}\\)을 갖는 가우시안 잡음을 통해 \\(\\tilde{x}\\)으로 확산된다:\n' +
      '\n' +
      '\\tilde{x}=\\tilde{x}_{t_{\\text{diff}}=\\tilde{x}_{t_{\\text{diff}}=\\sqrt{\\tilde{\\alpha}_{t_{\\text{diff}}}x+\\sqrt{1-\\tilde{\\alpha}_{t_{\\text{diff}}} \\mathbf{n}, \\tag{6}\\tag{6}}}\n' +
      '\n' +
      '여기서 \\(\\mathbf{n}\\in\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\)는 랜덤 가우시안 잡음이다.\n' +
      '\n' +
      '노이즈 스케일\\(t\\)을 갖는 잡음 샘플\\(\\tilde{x}_{t}\\)을 고려할 때, 잡음 제거 모델\\(\\text{denoise}(\\cdot,t)\\)은 스코어 함수를 통해 잡음 성분을 예측한다:\n' +
      '\n' +
      '\\[\\hat{\\mathbf{n}}=\\epsilon_{\\theta}(\\tilde{x}_{t},t). \\tag{7}\\]\n' +
      '\n' +
      '그리고 Eq. 이후의 후방 분포로부터 샘플링하여 잡음 스케일 \\(t-1\\)을 갖는 \\(\\tilde{x}_{t}\\)을 \\(\\tilde{x}_{t-1}\\)으로 잡음제거한다. 예측된 평균\\(\\tilde{x}_{t}-\\frac{1-\\alpha_{t}{\\sqrt{1-\\alpha_{t}}\\hat{\\mathbf{n}\\)과 사전 정의된 분산\\(\\sigma_{t}^{2}\\)이 있는 5.\n' +
      '\n' +
      '**MotionDiff: Canonicalized Hand trajectory denoising.** 이 denoising stage는 "denoising via diffusion" 전략에 따라 하나의 stage-denoised \\(\\tilde{\\mathcal{J}}^{\\text{input}}\\)에 대한 확산 모델을 적용하여 입력 잡음 상호작용 시퀀스의 Canonicalized Hand trajectory\\(\\tilde{\\mathcal{J}}^{\\text{stage}_{1}}\\)에서 잡음을 제거한다. 이를 위해, 잡음 표현\\(tilde{\\mathcal{J}}^{\\text{input}}\\)은 확산 모델을 사용하여 \\(t_{m}\\) 단계에 대한 잡음을 추가한 후 \\(t_{m}\\) 단계에 대한 잡음 제거를 통해 확산된다. 화음 좌표공간에서 생성된 한 단계 디노이즈된 손궤적\\(\\mathcal{J}^{\\text{stage}_{1}}\\)은 일반화된 접촉점들의 포즈를 이용하여 디노이즈된 표준화된 손궤적\\(\\tilde{\\mathcal{J}^{\\text{stage}_{1}}\\)을 디-칸칼라이징함으로써 얻어진다. GeneOH\\({}^{\\text{input}\\) 또한 이에 따라 GeneOH\\({}^{\\text{stage}_{1}=\\{\\tilde{\\mathcal{J}^{\\text{stage}_{1}},\\tilde{\\mathcal{J}^{\\text{stage}_{1}},\\tilde{\\mathcal{J}^{\\text{stage}_{1}}}}으로 갱신될 수 있다.\n' +
      '\n' +
      '**SpatialDiff: hand-object spatial denoising.** hand-object spatial denoising 모듈은 이전 MotionDiff 스테이지가 출력한 하나의 stage-denoised interaction sequence의 noisy hand-object spatial relations\\(\\tilde{\\mathcal{S}}^{\\text{stage}_{1}}\\) 상에서 동작한다. 표현 \\(tilde{\\mathcal{S}^{\\text{stage}_{1}}\\)는 \\(t_{s}\\) 확산 단계에 대해 잡음을 추가하여 확산시키고, 이어서 잡음제거를 또 다른 \\(t_{s}\\) 단계로 확산시킨다. 일단 일반화된 접촉점\\(\\mathbf{o}_{k}\\)을 중심으로 한 손-객체 상대 오프셋\\(\\{\\left(\\mathbf{h}_{k}-\\mathbf{o}_{k}\\right)\\}\\)을 포함하는 잡음 제거된 표현\\(\\mathcal{S}^{\\text{stage}_{2}\\)을 얻으면, 이를 두 단계의 잡음 제거된 손 시퀀스로 변환하는 간단한 방법을 채택한다. 구체적으로, 우리는 다음과 같이 각 객체 포인트로부터 잡음 제거된 핸드 오프셋들을 평균화한다:\n' +
      '\n' +
      '\\text{Average}\\{(\\mathbf{h}_{k}-\\mathbf{o}_{k})+\\mathbf{o}_{k}|\\mathbf{o}_{k}\\in\\mathbf{P}_{k}\\}. \\tag{8}\\}\n' +
      '\n' +
      '이후 GeneOH\\({}^{\\text{stage}_{1}}}=\\{\\tilde{\\mathcal{J}}^{\\text{stage}_{2}},\\mathcal{S}^{\\text{stage}_{2},\\tilde{\\mathcal{J}^{\\text{stage}_{2}}}}으로 갱신된다.\n' +
      '\n' +
      '**TemporalDiff: Hand-object temporal denoising.** 두 단계 디노이징 시퀀스의 잡음인 Hand-object temporal relations \\(\\tilde{\\mathcal{J}}^{\\text{stage}_{2}}\\)을 제거하기 위해 진행한다. "디노이징 비아 확산" 절차는 이를 달성하기 위해 시간적 관계에 적용된다. 그런 다음 우리는 잡음 제거된 시간 표현에 포함된 정보를 3단계 잡음 제거된 궤적에 증류하기 위해 추가 최적화를 추가한다. 상기 목적은 다음과 같이 공식화된다:\n' +
      '\n' +
      '\\(\\mathcal{J}^{\\text{stage}_{2}}(\\underset{\\mathcal{J}^{\\text{stage}_{2}},\\mathcal{P})\\rightarrow\\mathcal{T}(\\mathcal{J}^{\\text{stage}_{2}},\\mathcal{P})-\\mathcal{T}^{\\text{stage}_{3}}\\|,\\tag{9}\\]에서 \\(f_{J},\\mathcal{P})\\rightarrow\\mathcal{T}(\\cdot,\\cdot)\\). 손-물체 거리, _i.e._, \\(\\{d^{\\mathbf{ho}}_{k}\\}), 상대속도\\(\\{\\mathbf{v}^{\\mathbf{ho}}_{k}\\}) 및 두 개의 상대속도 관련 통계량(\\(\\{\\mathbf{e}^{\\mathbf{ho}}_{k,\\parallel},\\mathbf{e}^{\\mathbf{ho}}_{k,\\perp}\\})에 따라 거리를 계산한다. 최적의 손 궤적을 찾기 위해 아담 최적화기를 사용한다. 최적화된 궤적은 최종 잡음 제거된 궤적으로 간주된다.\n' +
      '\n' +
      'stage-wise denoising strategy.\\(\\mathcal{I}=\\{(\\mathcal{H}_{k},\\mathbf{O}_{k})\\}_{k=1}^{K}\\in\\mathcal{M}\\)는 상호작용 시퀀스를 나타내며, 여기서 \\(\\mathcal{M}\\)은 모든 상호작용 시퀀스를 포함한다. \\(\\mathcal{M}_{\\mathcal{I}\\),\\(\\mathcal{M}_{\\mathcal{S}\\) 및\\(\\mathcal{M}_{\\mathcal{T}\\)은 각각 세 개의 잡음제거 단계로 묘사된 다양체를 나타낸다. \\(\\mathcal{I}_{\\mathcal{J}\\),\\(\\mathcal{I}_{\\mathcal{S}}\\) 및\\(\\mathcal{I}_{\\mathcal{T}\\)은 각각 하나의 스테이지 디노이즈된 궤적, 2개의 스테이지 디노이즈된 궤적 및 3개의 스테이지 디노이즈된 궤적을 나타낸다. 또한, \\(\\mathcal{R}^{c}_{\\mathcal{J}\\), \\(\\mathcal{R}^{c}_{\\mathcal{S}\\) 및 \\(\\mathcal{R}^{c}_{\\mathcal{T}\\)은 각각 모든 자연 정준화된 손 궤적, 자연 손-객체 공간 관계 및 올바른 손-객체 시간 관계의 집합을 나타낸다. \\(\\mathcal{R}_{\\mathcal{J}\\),\\(\\mathcal{R}_{\\mathcal{S}\\) 및\\(\\mathcal{R}_{\\mathcal{T}\\)은 각각 모든 표준화된 손 궤적, 손-객체 공간 관계 및 손-객체 시간 관계의 집합을 나타낸다. 교호작용 궤적\\(\\mathcal{I}\\rightarrow\\mathcal{J}\\)을 정규화된 손궤적으로 변환하는 함수를 \\(f_{\\mathcal{I}\\rightarrow\\mathcal{J}\\)으로, \\(\\mathcal{I}\\)을 손-객체 공간관계로 변환하는 함수를 \\(f_{\\mathcal{I}\\rightarrow\\mathcal{S}\\)으로, 그리고 \\(\\mathcal{I}\\)을 손-객체 시간관계로 변환하는 함수를 \\(f_{\\mathcal{I}\\rightarrow\\mathcal{T}\\)으로 표현하였다.\n' +
      '\n' +
      '작업에서 고려되는 모든 상호작용 궤적에 대해 다음과 같은 가정을 한다.\n' +
      '\n' +
      '추정**: 공간 잡음이 없는 첫 번째 프레임을 갖는 임의의 궤적\\(\\mathcal{I}\\)에 대해, 우리는 동일한 첫 번째 프레임을 갖는 자연 궤적\\(\\mathcal{I}^{\\prime}\\, 즉 \\(\\mathcal{I}^{\\prime}[1]=\\mathcal{I}[1]\\)을 찾을 수 있다.\n' +
      '\n' +
      '3개의 완전 훈련된 잡음제거 모델은 각각 \\(\\tilde{\\mathcal{J}\\), \\(\\mathcal{S}\\) 및 \\(\\mathcal{T}\\)의 집합에 해당하는 입력 표현을 매핑할 수 있어야 한다. 그런 다음 3개의 잡음 제거 단계에 의해 묘사된 상호작용 다양체와 3개의 잡음 제거 모델에 의해 모델링된 이전 자연 데이터 사이의 관계는 다음과 같은 관계를 갖는다.\n' +
      '\n' +
      '\\(f_{\\mathcal{I}\\in\\mathcal{M}_{\\mathcal{J}\\) if and only if \\(f_{\\mathcal{I}\\rightarrow\\mathcal{J}(\\mathcal{I})\\in\\mathcal{R}^{c}_{\\mathcal{J}\\);\n' +
      '*(\\mathcal{I}\\in\\mathcal{M}_{\\mathcal{S}\\) if and only if \\(f_{\\mathcal{I}\\rightarrow\\mathcal{S}(\\mathcal{I})\\in\\mathcal{R}^{c}_{\\mathcal{S}\\);\n' +
      '(f_{\\mathcal{I}\\in\\mathcal{M}_{\\mathcal{T}\\) if and only if \\(f_{\\mathcal{I}\\rightarrow\\mathcal{T}(\\mathcal{I})\\in\\mathcal{R}^{c}_{\\mathcal{T}\\) 및 첫 번째 프레임 \\(\\mathcal{I}[1]\\)은 공간 잡음이 없다.\n' +
      '\n' +
      '\\(\\tilde{\\mathcal{J}\\),\\(\\mathcal{S}\\),\\(\\mathcal{T}\\)의 관계를 바탕으로 다음과 같은 주장을 할 수 있다.\n' +
      '\n' +
      '청구항 1**: 기존의 함수\\(f_{\\mathcal{S}\\rightarrow\\mathcal{R}\\tilde{\\mathcal{J}}) 및 \\(f_{\\mathcal{T}\\rightarrow\\mathcal{S}}(\\mathcal{T},\\mathcal{I}\\mathcal{S}\\mathcal{S}})\\), 우리는 다음과 같은 결론을 얻었다.\n' +
      '\n' +
      '_Proof._______ 각 프레임에서의 표준화된 손 키포인트(\\(k\\), 즉 \\(\\bar{\\mathbf{J}}_{k}\\)는 각 표준화된 손 키포인트(\\bar{\\mathbf{J}}_{k}=\\{(\\mathbf{h}_{k}-\\mathbf{t}_{k})\\mathbf{R}_{k}^{T}|\\mathbf{h}_{k}\\in\\mathbf{J}_{k}\\}\\)로 구성되며, 이는 프레임에서의 표준화된 손-객체 공간 관계로부터 유도될 수 있다. 구체적으로, 각 \\(\\mathbf{o}_{k}\\in\\mathbf{P}_{\\mathbf{k}\\)에 대해, \\((\\mathbf{h}_{k}-\\mathbf{t}_{k})\\mathbf{R}_{k}^{T}=(\\mathbf{h}_{k}-\\mathbf{o}_{k})\\mathbf{R}_{k}^{T}+(\\mathbf{o}_{k}-\\mathbf{t}_{k})\\mathbf{R}_{k}^{T}\\). 각 물체점\\(\\mathbf{o}_{k}\\in\\mathbf{P}_{k}\\)에서 변환된 궤적으로부터 프레임\\(k\\)에서의 독특한 정준화된 손 궤적을 결정할 수 있다. 각기 다른 \\(\\mathbf{o}_{k}\\)에서 비롯된 정준화된 손 궤적의 여러 가설로부터의 변환함수에 따라, 손-객체 공간관계 \\(\\mathcal{S}\\rightarrow\\mathcal{J}:\\mathcal{S}\\rightarrow\\mathcal{R}\\mathcal{J}\\)을 정준화된 손 궤적으로 변환하는 함수 \\(\\tilde{\\mathcal{J}\\)이 존재한다.\n' +
      '\n' +
      '마찬가지로, 객체 포인트 \\(\\mathbf{o}_{k}\\in\\mathbf{P}_{k}\\)의 프레임에서의 손-객체 시간적 관계 및 시작 프레임에서의 자연스러운 손 키포인트 \\(1\\bar{\\mathbf{J}_{1}\\), 각 손-객체 쌍에 대한 상대 속도 \\(\\mathbf{h}_{k},\\mathbf{o}_{k})\\), 두 개의 속도 관련 통계 \\(\\mathbf{e}^{\\mathbf{ho}}_{k}\\(d^{\\mathbf{ho}}}_{k}\\), 두 개의 속도 관련 통계 \\(\\mathbf{e}^{\\mathbf{ho}}}_{k}\\(d^{\\mathbf{o}}}}_{k}\\)로부터 손-객체 거리 \\(\\mathbf{e}^{\\mathbf{ho}}}_{k}\\(d^{\\mathbf{o}}}_{k}\\)을 유도할 수 있다. 손-물체 상대 위치(\\{(\\mathbf{h}_{1}-\\mathbf{o}_{1})|\\mathbf{h}_{1}\\in\\mathbf{J}_{1}\\})가 주어지면, 다음 각 프레임에서의 손-물체 상대 위치(k+1(1\\leq k\\leq K-1)\\)는 손-물체 상대 속도(\\{\\mathbf{v}^{\\mathbf{ho}}_{k}|\\mathbff{o}_{k}\\\\(\\mathbff{h}_{h}_{1}-\\mathbf{o}_{k})=(\\mathbf{h}_{k}-\\mathbf{v}^{\\mathbf{ho}_{k}\\)를 통해 반복적으로 유도될 수 있다. 따라서 시간적 관계\\(\\mathcal{T}\\rightarrow\\mathcal{S}:\\mathcal{R}\\mathcal{T}\\rightarrow\\mathcal{R}\\mathcal{S}\\)을 손-객체의 공간적 관계\\(\\mathcal{S}\\)으로 변환할 수 있는 함수\\(f_{\\mathcal{T}\\rightarrow\\mathcal{S}}:\\mathcal{R}\\mathcal{S}\\)이 존재한다.\n' +
      '\n' +
      '이 성질을 바탕으로 점진적으로 구성된 3개의 다양체 사이의 관계에 대해 다음과 같은 주장을 할 수 있다.\n' +
      '\n' +
      '청구항 2**:_2단계 잡음 제거된 궤적의 첫 번째 프레임을 가정하자\\(\\mathcal{I}_{\\mathcal{S}[1]\\)은 공간 잡음이 없고, 이는 거의 항상 참인 것이다\\(\\mathcal{M}_{\\mathcal{T}\\subseteq\\mathcal{M}_{\\mathcal{S}\\subseteq\\mathcal{M}_{\\mathcal{J}\\)을 갖는다. Proof.: _For \\(\\mathcal{I}\\in\\mathcal{M}_{\\mathcal{S}\\) with GeneOH representation \\(\\{\\bar{\\mathcal{J},\\mathcal{S},\\mathcal{T}\\}), assume \\(\\mathcal{I}\\notin\\mathcal{M}_{\\bar{\\mathcal{J}\\)\n' +
      '\n' +
      '* _From_\\(\\mathcal{I}\\in\\mathcal{M}_{\\mathcal{S}}\\)_, we have_\\(\\mathcal{S}\\in\\mathcal{R}^{c}_{\\mathcal{S}}\\)_;_\n' +
      '*__\\(\\mathcal{R}^{c}_{\\mathcal{S}})_의 정의에 기초하여, 모든 자연 상호작용으로부터 유도된 공간 관계의 집합인, 자연 상호작용_\\(\\mathcal{I}^{\\prime}\\)_이 존재하여, 자연 상호작용_\\(f_{\\mathcal{I}\\to\\mathcal{S}(\\mathcal{I}^{\\prime})=\\mathcal{S}\\)_;\n' +
      '* _Since_\\(\\mathcal{I}^{\\prime}\\)_은 자연스러운 상호작용이며, 우리는_\\(\\bar{\\mathcal{J}^{\\prime}=f_{\\mathcal{I}\\to\\mathcal{J}(\\mathcal{I}^{\\prime}) \\in\\mathcal{R}^{c}_{\\bar{\\mathcal{J}}\\)_;_\n' +
      '* _Since_\\(\\bar{\\mathcal{J}}=f_{\\mathcal{S}\\to\\bar{\\mathcal{J}}(\\mathcal{S})=\\bar{\\mathcal{J}^{\\prime}\\)_, we have_\\(\\bar{\\mathcal{J}\\in\\mathcal{R}^{c}_{\\bar{\\mathcal{J}}\\)_;_\n' +
      '* _ assumed fully-trained denoising model에 기초하여, 우리는_\\(\\mathcal{I}\\in\\mathcal{M}_{\\bar{\\mathcal{J}}\\)_.__\n' +
      '\n' +
      '결론은 \\(\\mathcal{I}\\notin\\mathcal{M}_{\\bar{\\mathcal{J}}\\)의 가정과 모순된다. 따라서 \\(\\mathcal{M}_{\\mathcal{S}\\subseteq\\mathcal{M}_{\\bar{\\mathcal{J}}\\)는 참이다.__\n' +
      '\n' +
      '첫 번째 프레임이 공간 잡음이 없는 GeneOH 표현\\(\\bar{\\mathcal{J},\\mathcal{S},\\mathcal{T}\\)을 갖는 a\\(\\mathcal{I}\\notin\\mathcal{M}_{\\mathcal{S}\\)을 갖는 a\\(\\mathcal{I}\\in\\mathcal{M}_{\\mathcal{T}\\)을 가정한다.\n' +
      '\n' +
      '* _From_\\(\\mathcal{I}\\in\\mathcal{M}_{\\mathcal{M}}\\)_, we have the_\\(\\mathcal{T}\\in\\mathcal{R}^{c}_{\\bar{\\mathcal{J}}\\)_;_\n' +
      '*__\\(\\mathcal{R}^{c}_{\\bar{\\mathcal{J}})_의 정의, 모든 자연 상호작용으로부터 유도된 시간적 관계의 집합 및 가정_1_에 기초하여, 첫 번째 프레임이_\\(\\mathcal{I}\\)_와 동일한 자연 상호작용_\\(\\mathcal{I}^{\\prime}\\)_가 존재하여,_\\(f_{\\mathcal{I}\\to\\mathcal{T}(\\mathcal{I}^{\\prime})=\\mathcal{T}\\;\n' +
      '* _Since_\\(\\mathcal{I}^{\\prime}\\)_는 자연스러운 상호작용이며, 우리는_\\(\\mathcal{S}^{\\prime}=f_{\\mathcal{I}\\to\\mathcal{S}}(\\mathcal{I}^{\\prime})\\in\\mathcal{R}^{c}_{\\mathcal{S}\\)_;_\n' +
      '* _Since_\\(\\mathcal{S}=f_{\\mathcal{T}\\to\\mathcal{S}}(\\mathcal{T},\\mathcal{I}[1])=f_{\\mathcal{T}\\to\\mathcal{S}}(\\mathcal{T},\\mathcal{I}^{\\prime}[1])=\\mathcal{S}^{\\prime}\\, 우리는_\\(\\mathcal{S}\\in\\mathcal{R}^{c}_{\\mathcal{S}}_;\n' +
      '* _ assumed fully-trained denoising model에 기초하여, 우리는_\\(\\mathcal{I}\\in\\mathcal{M}_{\\mathcal{S}}\\)_._\n' +
      '\n' +
      '결론은 \\(\\mathcal{I}\\notin\\mathcal{M}_{\\mathcal{S}\\)의 가정과 모순된다. 따라서 \\(\\mathcal{M}_{\\mathcal{T}\\subseteq\\mathcal{M}_{\\mathcal{S}\\)는 성립한다. \\ (\\blacksquare\\)_\n' +
      '\n' +
      '단계별 GeneOH 확산은 입력 상호작용 \\(\\mathcal{I}\\in\\mathcal{M}\\)을 청소하는 다음 단계로 기능한다:\n' +
      '\n' +
      '입력상호작용이 주어지면, \\(\\bar{\\mathcal{J}\\)에 대한 잡음제거 모델은 \\(\\bar{\\mathcal{J}\\)을 다른 \\(\\bar{\\mathcal{J}^{1}\\in\\mathcal{R}^{c}_{\\bar{\\mathcal{J}}\\)에 매핑한다. 기존에는 상호작용\\(\\mathcal{I}^{1}\\) s.t.\\(\\bar{\\mathcal{J}^{1}=f_{\\mathcal{I}\\to\\bar{\\mathcal{J}(\\mathcal{I}^{1})\\)이 존재했는데, 이는 또한 \\(\\bar{\\mathcal{J}^{1}\\) 및 물체 궤적\\(\\{\\mathbf{O}_{k}\\}_{k=1}^{K}\\)에서 유도된 궤적과 정확히 동일하다. 따라서, 첫 번째 잡음 제거 단계 이후, 우리는 \\(\\mathcal{I}^{1}\\in\\mathcal{M}_{\\bar{\\mathcal{J}}\\)을 갖는다.\n' +
      '* Given \\(\\mathcal{S}^{1}\\), \\(\\mathcal{S}\\)에 대한 잡음제거 모델은 \\(\\mathcal{S}^{1}\\)을 \\(\\mathcal{S}^{2}\\in\\mathcal{R}^{c}_{\\mathcal{S}}\\)으로 매핑한다. 기존에는 상호작용\\(\\mathcal{I}^{2}\\) s.t.\\(\\mathcal{S}^{2}=f_{\\mathcal{I}\\to\\mathcal{S}(\\mathcal{I}^{2})\\)가 존재하였다. 따라서 2차 잡음제거 단계 이후에는 \\(\\mathcal{I}^{2}\\in\\mathcal{M}_{\\mathcal{S}}\\)을 갖는다.\n' +
      '그 후, \\(\\mathcal{T}\\)에 대한 잡음제거 모델은 \\(\\mathcal{T}^{2}=f_{\\mathcal{I}\\to\\mathcal{T}(\\mathcal{I}^{2})\\)에서 \\(\\mathcal{T}^{3}\\in\\mathcal{R}^{c}_{\\mathcal{T}}\\)로 매핑된다. 그 후, 상호작용 \\(\\mathcal{I}^{3}\\)은 다음과 같은 단계로 구성된다:\n' +
      '* \\(\\mathcal{T}^{3}\\)와 \\(\\mathcal{I}^{2}[1]\\)를 \\(\\mathcal{S}^{3}}=f_{\\mathcal{T}\\to\\mathcal{S}(\\mathcal{T}^{3},\\mathcal{I}^{2}[1])을 통해 \\(\\mathcal{S}^{3}\\)을 구성하는 단계;\n' +
      '* \\(\\mathcal{S}^{3}\\)으로부터 \\(\\bar{\\mathcal{J}^{3}\\)을 통해 \\(\\bar{\\mathcal{J}^{3}}=f_{\\mathcal{S}\\to\\mathcal{J}}(\\mathcal{S}^{3}});\n' +
      '* \\(\\bar{\\mathcal{J}}^{3}\\) 및 물체 궤적 \\(\\{\\mathbf{O}_{k}\\}_{k}_{k=1}^{K}\\)으로부터 \\(\\mathcal{I}^{3}\\)을 구성한다. \\(\\mathcal{T}^{3}=f_{\\mathcal{I}\\to\\mathcal{T}(\\mathcal{I}^{3})\\in\\mathcal{R}^{c}_{\\mathcal{T}\\) 및 \\(\\mathcal{I}^{3}[1]=\\mathcal{I}^{2}[1]\\\\(\\mathcal{I}^{3}\\in\\mathcal{M}_{\\mathcal{T}\\)을 갖는다.\n' +
      '\n' +
      '따라서, 세 개의 잡음 제거 단계는 입력 잡음 상호작용을 이전의 큰 매니폴드에 포함된 점진적으로 더 작은 매니폴드에 점진적으로 매핑한다. 공식적으로 우리는\n' +
      '\n' +
      '\\[\\text{GeneOH Diffusion}(\\cdot):\\mathcal{M}_{\\bar{\\mathcal{J}}\\to\\mathcal{M}_{\\mathcal{S}\\to\\mathcal{M}_{\\mathcal{T}.\\tag{10}\\}\n' +
      '\n' +
      'HOI 궤적에 맞는 것\n' +
      '\n' +
      '인터랙션 시퀀스가 노이즈 제거되면, 최종 핸드 메시들을 획득하기 위해 핸드 MANO(Romero et al., 2022) 파라미터들의 시퀀스를 피팅하도록 진행한다. 목적은 잡음 제거된 궤적\\(\\mathcal{J}\\)에 잘 맞도록 일련의 MANO 파라미터\\(\\{\\mathbf{r}_{k},\\mathbf{t}_{k},\\beta_{k},\\theta_{k}\\}_{k=1}^{K}\\)를 최적화하는 것이다. 손 궤적\\(\\mathcal{J}\\)은 일련의 손 키포인트로 구성되어 있으므로 위의 최적화를 허용하기 위해 MANO 파라미터로부터 키포인트를 유도해야 한다. 운 좋게도 이 과정은 미분 가능하며 \\(\\mathcal{J}^{recon}(\\{\\mathbf{r}_{k},\\mathbf{t}_{k},\\beta_{k},\\theta_{k}\\}_{k=1}^{K})\\)을 사용하여 이를 나타낸다. 따라서 MANO 핸드에 대해 다음 재구성 손실을 최적화할 수 있습니다.\n' +
      '\n' +
      '\\|\\mathcal{L}_{recon}=\\|\\mathcal{J}-\\mathcal{J}^{recon}(\\{\\mathbf{r}_{k}, \\mathbf{t}_{k},\\beta_{k},\\theta_{k}\\}_{k=1}^{K})\\|, \\tag{11}\\}\n' +
      '\n' +
      '여기서 거리 함수는 각각의 프레임에서 손 키포인트들 사이의 단순 평균 제곱 오차(MSE)이다. 손 파라메터\\(\\{\\beta_{k},\\theta_{k}\\}\\})를 정규화하고 시간적 평활도를 구현하기 위해 추가적인 정규화 손실을 다음과 같이 정의한다.\n' +
      '\n' +
      '[\\mathcal{L}_{reg}=\\frac{1}{K}\\sum_{k=1}^{K}(\\|\\beta_{k}\\|_{2}+\\|\\theta_{k}\\|_{2})+\\frac{1}{K-1}\\sum_{k=1}^{K-1}\\|\\theta_{k+1}-\\theta_{k}\\|_{2}. \\tag{12}\\heta_{k}\\heta_{k}\\heta_{12}\\heta_{2}\n' +
      '\n' +
      '전체 최적화 목표는 다음과 같이 공식화됩니다.\n' +
      '\n' +
      '\\[\\text{minimize}_{\\{\\mathbf{r}_{k},\\mathbf{t}_{k},\\beta_{k},\\theta_{k}\\}_{k=1}^{K}}(\\mathcal{L}_{recon}+\\mathcal{L}_{reg}), \\tag{13}\\}\n' +
      '\n' +
      '그리고 우리는 피팅 문제를 해결하기 위해 Adam Optimizer를 사용한다.\n' +
      '\n' +
      '## 부록 B 추가 실험 결과\n' +
      '\n' +
      '제안된 방법의 잡음 제거 효과와 강력한 일반화 능력을 더욱 뒷받침할 수 있는 추가적인 실험 결과를 제시한다.\n' +
      '\n' +
      '### HOI Denoising\n' +
      '\n' +
      '첫 번째 평가 메트릭 세트에 대해 표 4는 본문의 표보다 우리의 방법, 절제된 버전 및 기준선 모델과의 비교에 대한 더 많은 평가를 제시한다. 두 번째 평가 메트릭 세트에 대해 표 5는 더 많은 결과와 비교를 요약한다. "우리들", "우리들 w/o 캐논", "우리들 w/o SpatialDiff", "우리들 w/o TemporalDiff"를 포함한 확률적 잡음 제거 방법의 경우 무작위 시드 세트를 각각 11, 22 및 77로 설정한 세 개의 독립 실행에서 얻은 결과의 평균과 표준 편차를 보고한다. 이러한 통계는 이러한 방법으로 생성된 평균 결과 품질에 대한 보다 포괄적인 관점을 제공한다. 평가 방법은 100개의 독립 실행 중 입력 궤적에 가장 가까운 결과가 평가 메트릭을 보고하기 위해 선택되는 본문에 존재하는 것과 다르다는 점에 유의하십시오.\n' +
      '\n' +
      '**GRAB 테스트 세트에 대한 더 많은 결과 - 새로운 객체와의 새로운 상호 작용.** 그림 8은 보이지 않는 객체와의 새로운 상호 작용에 대한 다른 잡음 제거 모델의 일반화 능력을 비교하기 위해 GRAB 테스트 세트에 대한 정성적 평가를 보여준다.\n' +
      '\n' +
      '**GRAB(베타) 테스트 세트에 대한 더 많은 결과 - 새로운 객체와의 새로운 상호작용 및 보이지 않는 합성 잡음 패턴.** 도 9는 보이지 않는 객체, 관찰되지 않는 상호작용 및 새로운 합성 잡음에 대한 상이한 잡음 제거 모델의 일반화 능력을 비교하기 위해 GRAB(베타) 테스트 세트에 대한 정성적 평가를 나타낸다.\n' +
      '\n' +
      '**HOI4D 데이터 세트에 대한 더 많은 결과 - 새로운 객체와의 새로운 상호작용 및 보이지 않는 실제 노이즈 패턴.** 그림 10은 보이지 않는 객체, 관찰되지 않는 상호작용 및 새로운 실제 노이즈에 대한 다양한 잡음 제거 모델의 일반화 능력을 비교하기 위해 HOI4D 테스트 세트에 대한 정성적 평가를 보여준다.\n' +
      '\n' +
      '**TOCH(w/MixStyle)에 의해 생성된 유선 핸드 궤적.** 훈련 중에 보이지 않는 새로운 노이즈 패턴을 가진 상호작용 시퀀스에 대한 TOCH를 사용한 실험을 통해, 우리는 딱딱한 핸드 포즈, 매끄럽지 않은 궤적, 큰 노이즈 패턴을 가진 결과들로부터 이상한 핸드 궤적을 자주 관찰한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c|c c c c c c} \\hline \\hline  & Laptop & Pliers & Scissors & Bottle & Bowl & Chair & Mug & ToyCar & Kettle \\\\ \\hline \\#Seq. & 155 & 187 & 93 & 214 & 217 & 167 & 249 & 257 & 58 \\\\ Starting Frame & 120 & 150 & 50 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: **HOI4D 데이터세트.** 시퀀스 수와 시작 프레임의 인덱스를 포함하여 실험에 사용된 HOI4D 데이터세트의 범주별 통계.\n' +
      '\n' +
      '<그림 9>와 <그림 4>와 같은 연기는 일반적인 영역 일반화 기법으로는 이러한 현상을 완화할 수 없다. 그림 12는 개선된 버전인 MixStyle을 사용한 TOCH도 유사한 부자연스러운 결과를 산출한다는 것을 보여준다. 이는 새로운 잡음 분포가 잡음 제거 모델이 새로운 잡음 상호 작용 시퀀스로 일반화하는 데 어려운 장애물을 제시함을 시사한다. 대조적으로, 우리의 방법은 이동된 잡음 분포를 처리하는 데 그러한 어려움을 갖지 않는다.\n' +
      '\n' +
      '** HOI4D 데이터셋에 대한 TOCH 및 TOCH(w/Aug.)의 결과.** 도 11은 TOCH(w/Aug.)의 결과를 우리의 방법과 비교한다. 가위를 여는 예에서 TOCH는 매우 이상한 "날고 있는 손" 궤적을 생성하며, 직관적인 이해를 위해 비디오를 참조하세요. 개선된 버전에 의해 생성된 결과는 "날고 있는 손" 아티팩트를 나타내지 않지만 여전히 매우 이상하고 뻣뻣하며 매우 부자연스러운 손 포즈로 고통받고 올바른 조작을 수행할 수 없다. 토이카 예제에 대한 TOCH와 TOCH(w/8월)의 결과는 이 경우 우리의 실험이 실제로 이러한 두 모델에서 매우 유사한 결과를 얻기 때문에 매우 유사하다. 그들은 둘 다 이상한 손 모양과 매우 부자연스러운 궤적에 의해 고민하고 있다.\n' +
      '\n' +
      '**ARCTIC 데이터 세트에 대한 더 많은 결과 - 동적 객체 움직임 및 연락처 변경을 포함하는 새로운 객체와의 새로운 상호 작용.** 도 13은 연락처 변경과 함께 잡음 및 동적 상호 작용을 제거하는 우리의 잡음 제거 모델의 능력을 테스트하기 위해 ARCTIC 테스트 세트에 대한 정성적 평가를 보여준다.\n' +
      '\n' +
      '또한 그림 14에 쌍방향 조작이 있는 더 긴 서열에 대한 결과 샘플을 포함한다.\n' +
      '\n' +
      '**다중 상태 잡음 제거 v.s. 1단계 잡음 제거** 복잡한 상호 작용 잡음에 의해 제기된 문제를 해결하기 위해 이 작업에서 다단계 잡음 제거 전략을 활용합니다. A.2절에서는 비자연적 상호작용을 포함하는 매니폴드에서 자연스러운 손동작이 있는 궤적의 매니폴드, 매니폴드로 점진적으로 입력 궤적을 투영하는 단계별 노이즈 제거 전략을 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c c c} \\hline \\hline Dataset & Method & MPJPE & MPVPE & C-IoU \\\\  & & (\\(mm\\), \\(\\downarrow\\)) & (\\(mm\\), \\(\\downarrow\\)) & (\\%, \\(\\uparrow\\)) \\\\ \\hline \\multirow{6}{*}{GRAB} & Input & 23.16 & 22.78 & 1.01 \\\\  & TOCH & 12.38 & 12.14 & 23.31 \\\\  & TOCH (w/ MixStyle) & 13.36 & 13.03 & 23.70 \\\\  & TOCH (w/ Aug.) & 12.23 & 11.89 & 22.71 \\\\  & Ours (w/o SpatialDiff) & **7.83** & **7.67** & 26.09 \\\\  & Ours (w/o TemporalDiff) & _8.27_ & _8.13_ & **26.55** \\\\  & Ours (w/o Diffusion) & 8.52 & 8.38 & _26.44_ \\\\  & Ours (w/o Canon.) & 10.15 & 10.07 & 24.92 \\\\  & Ours & 9.28 & 9.22 & 25.27 \\\\ \\hline \\multirow{6}{*}{GRAB (Beta)} & Input & 17.65 & 17.40 & 13.21 \\\\ \\cline{2-5}  & TOCH & 24.10 & 22.90 & 16.32 \\\\ \\cline{1-1}  & TOCH (w/ MixStyle) & 22.79 & 21.19 & 16.28 \\\\ \\cline{1-1}  & TOCH (w/ Aug.) & 11.65 & _10.47_ & _24.81_ \\\\ \\cline{1-1}  & Ours (w/o Diffusion) & 12.16 & 11.75 & 22.96 \\\\ \\cline{1-1}  & Ours (w/o Canon.) & _10.89_ & 10.61 & 24.68 \\\\ \\cline{1-1}  & Ours & **9.09** & **8.98** & **26.76** \\\\ \\hline \\multirow{6}{*}{ARCTIC} & Input & 25.51 & 24.84 & 1.68 \\\\ \\cline{1-1} \\cline{2-5}  & TOCH & 14.34 & 14.07 & 20.32 \\\\ \\cline{1-1}  & TOCH (w/ MixStyle) & _13.82_ & _13.58_ & _21.70_ \\\\ \\cline{1-1}  & TOCH (w/ Aug.) & 14.18 & 13.90 & 20.10 \\\\ \\cline{1-1}  & Ours & **11.57** & **11.09** & **23.49** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: ** 정량적 평가 및 비교.** 평가 메트릭의 _첫 번째 세트를 사용하여 서로 다른 테스트 세트에 대한 방법, 기준선 및 절제된 버전의 성능 비교. **가장 좋은 값에 대한 굵은 빨간색** 숫자와 두 번째로 성능이 좋은 값에 대한 _italic blue_ 값입니다.\n' +
      '\n' +
      '정확한 공간적 관계와 일관된 시간적 관계를 가진 궤적의 다양체에 대한 것이다. 하나의 단계에서 자연스러운 상호작용 다양체에 입력을 투영하기 위해 마지막 투영 단계를 사용하는 것만이 가능한지 의문을 제기할 수 있다. 우리의 실험 관찰은 단일 단계에서 그러한 복잡한 잡음을 제거하는 것이 어렵다는 것을 보여준다. 이러한 복잡한 잡음을 제거하기 위한 효과적인 매핑은 신경망에 대해 학습하기 매우 어렵다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c c c c c c} \\hline \\hline \\multirow{2}{*}{Dataset} & \\multirow{2}{*}{Method} & \\multicolumn{2}{c}{MPPE} & \\multicolumn{2}{c}{MVPE} & \\multicolumn{2}{c}{C-tol} & \\multicolumn{2}{c}{IV} & \\multicolumn{2}{c}{Penetration Depth} & \\multicolumn{2}{c}{Proximity Error} & \\multicolumn{2}{c}{HO Motion Consistency} \\\\  & & \\((mm,\\downarrow)\\) & \\((mm,\\downarrow)\\) & \\((\\%,\\uparrow)\\) & \\((cm^{3},\\downarrow)\\) & & \\((mm,\\downarrow)\\) & \\((mm^{2},\\downarrow)\\) \\\\ \\hline \\multirow{4}{*}{GRAB} & GT & - & - & - & 0.50 & 1.33 & - & 0.51 \\\\  & Input & 23.16 & 22.78 & 1.01 & 4.48 & 5.25 & 13.29 & 881.23 \\\\  & \\multirow{4}{*}{Ours (GRAB)} & **9.28** & **9.22** & **25.27** & **1.23** & **1.74** & **2.53** & 0.57 \\\\  & & Ours (ARTCIT) & 11.47 & 11.29 & 24.79 & 1.48 & 1.80 & 2.60 & **0.55** \\\\ \\hline \\multirow{4}{*}{HOHD} & Input & - & - & - & 2.26 & 2.47 & - & 46.45 \\\\  & \\multirow{4}{*}{Ours (GRAB)} & - & - & - & 1.99 & 2.15 & - & 9.81 \\\\  & & Ours (ARTCIT) & - & - & - & **1.54** & **1.96** & - & **9.33** \\\\ \\hline \\multirow{4}{*}{ARCITC} & GT & - & - & - & 0.33 & 0.92 & 0 & 0.41 \\\\  & Input & 25.51 & 24.84 & 1.68 & 2.28 & 4.89 & 15.21 & 931.69 \\\\ \\cline{1-1}  & \\multirow{4}{*}{Ours (GRAB)} & 11.57 & 11.09 & 23.49 & 1.35 & 1.93 & 2.71 & **0.92** \\\\ \\cline{1-1}  & & Ours (ARTCIT) & **19.34** & **10.07** & **25.08** & **1.21** & **1.64** & **2.62** & 1.10 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: ARCTIC 트레이닝 세트에 대해 트레이닝된 모델의 **정량적 평가. 가장 좋은 값에 대한 굵은 빨간색 숫자입니다. “GT”는 “Ground-Truth”의 약자이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c c c c} \\hline \\hline Dataset & Method & \\multicolumn{2}{c}{IV} & \\multicolumn{2}{c}{Penetration Depth} & \\multicolumn{2}{c}{Proximity Error} & \\multicolumn{2}{c}{HO Motion Consistency} \\\\  & & \\((cm^{3},\\downarrow)\\) & \\((mm,\\downarrow)\\) & \\((mm,\\downarrow)\\) & \\((mm,\\downarrow)\\) & \\((mm^{2},\\downarrow)\\) \\\\ \\hline \\multirow{4}{*}{GRAB} & GT & 0.50 & 1.33 & 0 & 0.51 \\\\  & Input & 4.48 & 5.25 & 13.29 & 881.23 \\\\ \\cline{1-1}  & \\multirow{4}{*}{TOCH} & 2.09 & 2.17 & 3.12 & 20.37 \\\\  & & TOCH (w/ MixStyle) & 2.28 & 2.62 & 3.10 & 21.29 \\\\ \\cline{1-1}  & \\multirow{4}{*}{Ours (w/o SpatialDiff)} & 1.94 & 2.04 & 3.16 & 22.58 \\\\ \\cline{1-1}  & & Ours (w/o SpatialDiff) & 2.15-0.02 & 2.29+0.03 & 6.71+1.09 & 12.16+0.67 \\\\ \\cline{1-1}  & & Ours (w/o TemporalDiff) & **0.86\\(\\pm\\)**0.02 & **1.54\\(\\pm\\)**0.02 & 3.93\\(\\pm\\)0.31 & 9.36\\(\\pm\\)0.68 \\\\ \\cline{1-1}  & & Ours (w/o Diffusion) & _1.07_ & _1.70_ & _2.63_ & 10.05 \\\\ \\cline{1-1}  & & Ours (w/o Canon.) & 1.57\\(\\pm\\)0.02 & 1.83\\(\\pm\\)0.03 & 2.91\\(\\pm\\)0.28 & _1.30\\(\\pm\\)_0.03 \\\\ \\cline{1-1}  & & Ours & 1.22\\(\\pm\\)0.01 & 1.72\\(\\pm\\)0.01 & **2.44\\(\\pm\\)**0.18 & **0.41\\(\\pm\\)**0.01 \\\\ \\hline \\multirow{4}{*}{GRAB (Beta)} & GT & 0.50 & 1.33 & 0 & 0.51 \\\\  & Input & 2.19 & 4.77 & 5.83 & 27.58 \\\\ \\cline{1-1}  & \\multirow{4}{*}{TOCH (w/ MixStyle)} & 2.33 & 2.77 & 5.60 & 25.05 \\\\ \\cline{1-1}  & & TOCH (w/ MixStyle) & 2.01 & 2.63 & 4.65 & 17.37 \\\\ \\cline{1-1}  & & TOCH (w/ Aug.) & 1.52 & 1.86 & 3.07 & 13.09 \\\\ \\cline{1-1}  & & Ours (w/o Diffusion) & 1.98 & 2.06 & _3.00_ & 11.99 \\\\ \\cline{1-1}  & & Ours (w/o Canon.) & _1.79\\(\\pm\\)_0.02 & _1.73\\(\\pm\\)_0.03 & 3.19\\(\\pm\\)0.15 & _1.28\\(\\pm\\)_0.03 \\\\ \\cline{1-1}  & & Ours & **1.18\\(\\pm\\)**0.00 & **1.69\\(\\pm\\)**0.01 & **2.78\\(\\pm\\)**0.14 & **0.54\\(\\pm\\)**0.00 \\\\ \\hline \\multirow{4}{*}{HOH4D} & Input & 2.26 & 2.47 & - & 46.45 \\\\ \\cline{1-1}  & \\multirow{4}{*}{TOCH} & 4.09 & 4.46 & - & 35.93 \\\\ \\cline{1-1}  & & TOCH (w/ MixStyle) & 4.31 & 4.96 & - & 25.67 \\\\ \\cline{1-1}  & & TOCH (w/ Mix_Style) & 4.20 & 4.51 & - & 25.85 \\\\ \\cline{1-1}  & & Ours (w/o Diffusion) & 3.16 & 3.83 & - & 18.65 \\\\ \\cline{1-1}  & & Ours (w/o Canon.) & _2.37\\(\\pm\\)_0.02 & _3.57\\(\\pm\\)_0.03 & - & _12.80\\(\\pm\\)_0.79 \\\\ \\cline{1-1}  & & Ours & **1.99\\(\\pm\\)**0.02 & **2.14\\(\\pm\\)**0.02 & - & **9.75\\(\\pm\\)**0.88 \\\\ \\hline \\multirow{4}{*}{ARCITC} & GT & 0.33 & 0.92 & 0 & 0.41 \\\\ \\cline{1-1}  & & Input & 2.28 & 4.89 & 15.21 & 931.69 \\\\ \\cline{1-1}  & & TOCH & 1.84 & 2.01 & 4.31 & 18.50 \\\\ \\cline{1-1}  & & TOCH (w/ MixStyle) & 1.92 & 2.13 & 4.25 & _18.02_ \\\\ \\cline{1-1}  & & TOCH (w/ Aug.) & _1.75_ & _1.98_ & 5.64 & 22.57 \\\\ \\cline{1-1}  & & Ours & **1.35**\\(\\pm\\) 0.01 & **1.91**\\(\\pm\\) 0.02 & **2.69**\\(\\pm\\) 0.11 & **0.85**\\(\\pm\\) 0.00 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: ** 정량적 평가 및 비교.** 평가 메트릭_의 두 번째 세트를 사용하여 서로 다른 테스트 세트에 대한 방법, 기준선 및 절제된 버전의 성능 비교. **최고의 값에 대한 굵은 빨간색 숫자와 두 번째로 성능이 좋은 값에 대한 _italic blue_ 값입니다. “GT”는 “Ground-Truth”의 약자입니다.\n' +
      '\n' +
      '**ARCTIC에서 다른 데이터 세트로 일반화.** 본 방법의 일반화 능력을 추가로 평가하기 위해 ARCTIC 데이터 세트에서 모델을 훈련하고(데이터 분할 및 기타 설정을 위해 섹션 C 참조) GRAB, HOI4D 및 ARCTIC(테스트 분할)에 대해 평가하는 새로운 일련의 실험을 수행한다. 표 6은 그 성능을 포함하고 있다. GRAB에 훈련된 모델이 ARCTIC에 좋은 성능을 가지고 일반화될 수 있지만, ARCTIC를 훈련 세트로 사용할 때 감소된 도메인 갭이 실제로 성능을 향상시킬 수 있음을 관찰할 수 있다. 예를 들어, 도 15는 ARCTIC 트레이닝 세트에 트레이닝된 모델이 GRAB에 트레이닝된 모델이 고전할 예제에 대해 분명히 더 잘 수행할 수 있음을 보여준다(실패 사례에 대한 논의는 섹션 B.4 참조). 마이크로파를 잡기 위해 손이 넓게 열려야 하는 시퀀스의 경우 GRAB로 훈련된 모델은 소음을 매우 효과적으로 청소할 수 없어 명백한 관통과 순간적인 흔들림이 있는 부자연스러운 손 궤적을 가진 결과를 생성한다. 그러나 ARCTIC 데이터셋에 학습된 모델은 이러한 노이즈를 제거하고 자연스러운 궤적을 많이 생성할 수 있다. 게다가, 이것에 대한 훈련은\n' +
      '\n' +
      '그림 8: **GRAB 테스트 세트에 대한 평가 및 비교.** 입력 및 잡음 제거된 결과는 시간 증가 순서로 4개의 키프레임을 통해 3개의 뷰에서 표시된다. 애니메이션 결과는 당사 웹사이트와 비디오**를 참조하십시오.\n' +
      '\n' +
      '데이터 세트는 관절형 객체 및 관절형 모션이 있는 HOI4D 데이터 세트에서 모델의 성능에 도움이 될 수 있다.\n' +
      '\n' +
      '### Ablation Studies\n' +
      '\n' +
      '이 섹션에는 본문에서 선택한 결과를 보완하기 위해 더 많은 절제 연구 결과가 포함된다. 표 4와 5는 절제된 모델에 대한 보다 포괄적인 정량적 평가와 전체 모델과의 비교를 제시한다.\n' +
      '\n' +
      '**일반화된 접촉 중심 파라미터화.** 표 4 및 5에 제시된 결과와는 별도로, 도 16은 그러한 접촉 중심 설계가 없는 절제된 버전이 큰 물체 움직임을 갖는 조작 시퀀스에 대해 잘 일반화할 수 없는 시각적 예를 제공한다. 우리는 여전히 여기에 존재하는 세 프레임 모두에서 명백한 침투를 관찰할 수 있다.\n' +
      '\n' +
      '**지상 진실 복구 및 고주파 포즈 세부 사항 모델링에 대한 잡음 제거 능력.** 다양한 솔루션을 모델링하는 능력과 함께 확률적 잡음 제거 프로세스는 또한 모델이 지상 진실 시퀀스에 가까운 샘플을 포함할 가능성이 더 높은 넓은 공간을 탐색할 수 있도록 한다. 그림 17은 복구된 손 포즈와 연락처 정보 모두에 대해 TOCH의 결과보다 지상-진실 시퀀스에 더 충실함을 보여준다.\n' +
      '\n' +
      '또한, HOI 표현 GeneOH의 힘과 새로운 잡음 제거 방식을 사용하여 결과에서 고주파 모양 세부 사항을 모델링할 수 있다. 그러나 TOCH의 결과는 종종 평평한 손 자세를 나타낼 것이다. 이것은 그것의 고차원 표현들로부터 기인할 수 있다\n' +
      '\n' +
      '도 9: **GRAB(Beta) 테스트 세트에 대한 평가 및 비교.** 애니메이션 결과는 **저희 웹사이트 및 비디오**를 참조하시기 바랍니다.\n' +
      '\n' +
      '도 10: **HOI4D 데이터세트에 대한 평가.** 애니메이션 결과는 **저희 웹사이트 및 비디오**를 참조하시기 바랍니다.\n' +
      '\n' +
      '그리고 결정론적, 1단계 노이즈 대 데이터 매핑 관계를 모델링하는 노이즈 제거 전략의 제한된 능력.\n' +
      '\n' +
      '### Applications\n' +
      '\n' +
      '이 절에서는 노이즈 제거 모델의 더 많은 응용 프로그램을 설명합니다.\n' +
      '\n' +
      '**생성 네트워크에 의해 생성된 잡음 파악을 정제한다.** 잡음 상호 작용 시퀀스를 정제하는 것 외에도, 우리의 방법은 도 6에 도시된 바와 같이 생성 네트워크에 의해 생성된 불확정 정적 파악을 정제하는 효과적인 후처리 도구로서 작용할 수 있다. 여기에 도시된 예는 (Wu et al., 2022)에 의해 생성된 상호 작용 결과로부터 취해진 파악이다.\n' +
      '\n' +
      '그림 11: HOI4D 데이터 세트에 대한 **비교.** 우리는 우리의 방법을 기준 TOCH 및 개선된 버전 TOCH(w/8월)와 비교한다.\n' +
      '\n' +
      '도 12: TOCH(w/ MixStyle).**(_First line_:) Ours 결과. (_Second line_:) TOCH(w/ MixStyle)의 결과. 노이즈 입력은 훈련에서 사용된 것과 다른 베타 분포에서 샘플링된 노이즈에 의해 교란된다.\n' +
      '\n' +
      '도 14: **양손 조작과의 긴 상호작용 시퀀스에 대한 평가.** 모델은 여기서 시끄러운 오른손 궤적 및 시끄러운 왼손 궤적을 모두 정화한다. 애니메이션 결과는 당사 웹사이트와 비디오**를 참조하십시오.\n' +
      '\n' +
      '도 13: **ARCTIC 데이터세트에 대한 평가.** 모델은 여기서 시끄러운 오른손 궤적을 청소한다. 노이즈 입력과 잡음 제거된 궤적 모두에 표시된 왼손은 GT 모양이다. 애니메이션 결과는 당사 웹사이트와 비디오**를 참조하십시오.\n' +
      '\n' +
      '잡음 제거 능력 외에도 고품질 상호 작용 시퀀스와 정적 파악이 있는 잡음 제거된 데이터는 다양한 다운스트림 작업을 더욱 도울 수 있다. 여기서는 파지 합성과 조작 합성 과제를 예로 든다.\n' +
      '\n' +
      '** 파지 합성.** GRAB 테스트 세트에서 4개의 객체와 해당 파지 포즈를 선택하여 합성 네트워크를 훈련한다. 그런 다음 네트워크를 사용하여 보이지 않는 객체에 대한 파악을 생성합니다. 그림 18에 표시된 결과는 자연스럽고 접촉을 인식한다. 대조적으로, 생성된 파지들은 그림 18의 가장 왼쪽 부분에 도시된 바와 같이 그럴듯하지 않다.\n' +
      '\n' +
      '**조작 합성.** 조작 합성 작업을 통해 잡음 제거된 상호 작용 데이터의 품질을 추가로 조사한다. 최근 조작 합성 작업 1에서 제안된 표현과 네트워크 구조를 기반으로 잡음 제거된 데이터를 사용하여 조작 합성 네트워크를 학습한다. 그 다음, 네트워크는 대응하는 조작 시퀀스를 생성하기 위해 새로운 오브젝트 시퀀스를 입력으로서 취한다. 그림 19와 같이 우리 데이터의 품질은 학습 기반 합성 모델에 매우 적합하다. 그것은 보이지 않는 물체 궤적에 대한 다양하고 고품질의 조작 시퀀스를 생성할 수 있다.\n' +
      '\n' +
      '각주 1: [https://github.com/cams-hoi/CAMS](https://github.com/cams-hoi/CAMS)\n' +
      '\n' +
      '위의 두 응용 프로그램은 고품질 상호 작용 데이터 세트 생성을 지원하는 데 있어 노이즈 제거 모델의 잠재적 가치를 나타낸다.\n' +
      '\n' +
      '### Failure Cases\n' +
      '\n' +
      '그림 20은 고장 사례를 요약한 것이다. 우리의 방법은 때때로 물체를 잡기 위해 손이 넓게 열려야 할 때, 정준화된 손 궤적과 상호작용 영역 주변의 정준화된 손-객체 공간 관계가 잡음 제거 모델에 매우 새로울 수 있다. 그런 다음 모델은 관찰에서 침투를 완전히 청소할 수 없다. 2) 노이즈 입력이 그림 20에 제시된 갑작스러운 분리 및 파지 등과 같은 매우 이상한 손 동작을 포함할 때, 모델은 그러한 아티팩트를 제거할 수 있지만 여전히 궤적을 완벽하게 청소할 수 없어 잡음이 제거된 결과에 표시된 관통부를 남긴다. 3) 손이 극도로 얇은 형상을 가진 보이지 않는 물체를 열고 있을 때, 우리는 여전히 결과로부터 미묘한 관통을 관찰할 수 있다.\n' +
      '\n' +
      '도 16: **일반화된 접촉 중심 파라미터화의 효과.**(_First line:_) Ours(w/o Canon.)의 결과. (_Second line:_) 전체 모델의 결과.\n' +
      '\n' +
      '도 15: ARCTIC에 트레이닝된 모델과 GRAB에 트레이닝된 모델 간의 **비교.** ARCTIC 트레이닝 세트에 트레이닝된 모델은 감소된 도메인 갭 덕분에 대응하는 테스트 시퀀스에 보다 쉽게 일반화될 수 있다.\n' +
      '\n' +
      '실제 손-물체 상호작용 궤적에서 소음과 인공소음의 구분 분석\n' +
      '\n' +
      '웹사이트와 비디오에 나타난 시각화 및 애니메이션 결과로부터, 실제 잡음이 있는 손-객체 상호작용 궤적들(예를 들어, 잡음이 있는 HOI4D 데이터세트로부터의 손 궤적들 및 상호작용 비디오들로부터 추정된 손 궤적들)에서 나타나는 잡음과 인공 잡음 사이의 구별은 다음과 같이 요약될 수 있다:\n' +
      '\n' +
      '* HOI4D에서의 궤적은 항상 부자연스러운 손 포즈, 지터링 모션, 콘택트 누락 및 큰 관통을 나타낸다;\n' +
      '* 재충전된 손동작은 항상 큰 관통부를 겪는다;\n' +
      '* HOI 비디오로부터 추정된 손 궤적은 통상 관통부 및 누락된 접촉부를 갖는다;\n' +
      '* 일반적인 특징은 실제 시끄러운 손 궤적이 항상 시간 일관적인 아티팩트를 제공한다는 것이다. 그러나, 각 프레임에 독립적으로 추가된 인공 잡음이 있는 잡음 궤적은 일반적으로 시변 침투 및 부자연스러운 자세를 나타낸다.\n' +
      '\n' +
      '또한, 표 1에 요약된 바와 같이, 관통(IV, 관통 깊이), 손-물체 근접(C-IoU, 근접 오차) 및 모션 일관성을 드러내기 위한 메트릭을 포함하여, 그들의 입력 잡음 궤적에 대해 계산된 다양한 메트릭을 비교함으로써 상이한 종류의 잡음 패턴 간의 차이를 드러낼 수 있다.\n' +
      '\n' +
      '추가 분석.** 우리는 비디오에서 추정된 궤적(손의 궤적을 청소하는 데 적용되는 노이즈 입력, Sec. 4.4)에서 얻은 노이즈 손 자세 파라미터(\\(\\hat{\\theta}^{gt}\\))와 GT 값(\\(\\theta^{gt}\\)) 사이의 차이(\\(\\hat{\\theta}^{gt}\\))를 추가로 시각화하고, 인공 가우시안 노이즈를 갖는 마노 자세 파라미터(\\(\\hat{\\theta}^{\\textbf{n}\\))와 GT 값과의 차이(\\(\\hat{\\theta}^{\\textbf{b}\\))와 베타 분포에서 도출된 인공 노이즈를 갖는 파라미터(\\(\\hat{\\theta}^{\\textbf{b}\\))를 추가로 시각화한다. PCA 알고리즘(Scikit-learn package에서 구현)을 사용하여 2차원 평면에 투영함으로써, 그림 21의 256개의 예에서 그들의 위치를 시각화한다. 우리가 볼 수 있듯이, 실제 잡음 패턴은 인공 잡음과 매우 다르다. 이 경우, 비디오들로부터 추정된 손 궤적의 잡음은 인스턴스-특정 패턴들을 추가로 나타낸다.\n' +
      '\n' +
      '그림 17: ** 지상-진실 상호작용을 복구하는 능력에 대한 모델과 TOCH 간의 비교.** 지상 진실에 가까운 손 포즈(노란색 원으로 강조됨) 및 접촉(녹색 원으로 강조됨)으로 샘플을 포괄하는 넓은 공간을 탐색할 수 있다. 우리는 고주파 포즈를 모델링할 수 있다. 그러나, TOCH의 결과는 평범한 포즈들을 포함하고, 그라운드-진실 형태로 나타난 벤딩 핑거들을 회복할 수 없다.\n' +
      '\n' +
      '도 18: ** 파지 합성.** 보이지 않는 물체에 대한 합성 파지.\n' +
      '\n' +
      '### User Study\n' +
      '\n' +
      '노이즈된 결과의 품질을 기본 모델의 품질과 더 잘 액세스하고 비교하기 위해 장난감 사용자 연구를 수행했다. 우리는 무작위로 순열된 순서로 18개의 잡음이 있는 궤적에 대해 잡음 제거된 결과와 TOCH의 결과를 포함하는 웹사이트를 설정했다. 이 작업에 익숙하지 않거나 CS에 배경이 없는 20명의 사람들에게 각 클립에 선호도를 나타내는 1에서 5까지의 점수를 매기도록 요청받는다. 구체적으로, "1"은 비디오에서 증명된 손 동작과 인간의 행동 사이의 상당한 차이를 나타내며, 관통 및 동작 불일치와 같은 명백한 물리적 비현실적인 현상을 나타낸다; "3"은 증명된 동작이 그럴듯하고 인간의 행동과 유사하지만 여전히 물리적 아티팩트를 겪는다; "5"는 결함이 없이 그럴듯하고 인간과 유사한 고품질 동작을 의미한다. "2"는 품질이 "1"보다 좋지만 "3"보다 나쁘다는 것을 의미한다. 유사하게, "4"는 결과가 "3"보다 낫지만 "5"보다 나쁘다는 것을 의미한다.\n' +
      '\n' +
      '각 클립에 대해, 우리는 우리의 방법과 TOCH에 의해 달성된 평균 점수를 계산한다. 모든 클립에 대한 평균 및 중간 점수는 표 7에 요약되어 있다. 우리의 점수는 기준 모델보다 훨씬 우수하다.\n' +
      '\n' +
      '도 19: **조작 합성. 보이지 않는 노트북 객체에 대한 조작 시퀀스를 합성합니다. 여기에 왼쪽에서 오른쪽으로 표시된 프레임은 시간이 증가하는 순서로 표시됩니다.**\n' +
      '\n' +
      '도 20: _unseen 및 large object_, _very strange hand-object temporal relations_ 및 _unseen object with extremely thin geometry_에 의해 야기되는 **Failure case.\n' +
      '\n' +
      '## 부록 C 실험 상세\n' +
      '\n' +
      '### Datasets\n' +
      '\n' +
      '**GRAB 훈련 세트.** **본문**에 제시된 모든 실험에 사용된 훈련 세트이다. 우리는 GRAB(Taheri et al., 2020) 데이터 세트를 분할하기 위해 (Zhou et al., 2022)에서 사용되는 교차 객체 분할 전략을 따른다. 1308개의 조작 시퀀스를 포함하는 트레이닝 분할은 트레이닝 데이터세트를 구성하는 데 사용된다. 또한 손목이 물체에서 15cm 이상 떨어진 프레임도 걸러냅니다. 각 훈련 시퀀스에 대해 60개의 프레임이 있는 클립으로 슬라이스하여 훈련 세트를 구성한다. 길이가 60 미만인 서열은 훈련 또는 테스트를 위해 포함되지 않는다. 트레이닝 시 잡음이 있는 시퀀스가 필요한 모델의 경우, MANO 파라미터에 가우시안 노이즈를 추가하여 깨끗한 시퀀스로부터 잡음이 있는 시퀀스를 생성한다. 구체적으로, 가우시안 잡음은 각각 0.01, 0.1 및 0.5의 표준 편차로 손 MANO 병진, 회전 및 포즈 파라미터에 추가된다.\n' +
      '\n' +
      '**ARCTIC 훈련 데이터세트.**ARCTIC에 훈련된 모델을 다른 데이터세트로 일반화하고자 하는 실험에서 모든 모델의 훈련세트이다. 색인 "s01", "s02", "s04", "s05", "s06", "s07", "s08", "s09", "s10"을 사용하여 피험자의 공개적으로 사용 가능한 시퀀스를 기반으로 평가를 위해 "s01"에서 조작 시퀀스를 취하고 훈련을 위해 다른 피험자의 조작 시퀀스를 취한다. 각 시퀀스에 대해 윈도우 크기가 60이고 스텝 크기가 60으로 설정된 작은 클립으로 슬라이스하고 손목에서 가장 가까운 물체점까지의 최대 거리가 15cm보다 큰 클립을 필터링한다. 모든 트레이닝 클립의 수는 2524개이다. 오직 오른손의 궤적만이 트레이닝에 사용된다.\n' +
      '\n' +
      '다음 텍스트에는 평가를 위한 4개의 별개의 테스트 세트, 즉 GRAB, GRAB(베타), HOI4D 및 ARCTIC에 대한 자세한 내용이 포함되어 있다.\n' +
      '\n' +
      '**GRAB**(Taheri et al., 2020). 246개의 조작 시퀀스를 포함하는 GRAB 데이터세트의 테스트 분할은 테스트 세트를 구성하는 데 사용된다. 각 테스트 시퀀스에 대해 스텝 크기 30을 사용하여 60프레임의 클립으로 슬라이스하고 각 테스트 시퀀스에 대해 가우스를 추가하여 노이즈 시퀀스를 생성한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline \\hline  & GeneOH Diffusion & TOCH \\\\ \\hline Average Score & **3.96** & 1.98 \\\\ \\hline Medium Score & **4.00** & 1.55 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: **사용자 연구.**\n' +
      '\n' +
      '도 21: 비디오로부터 추정된 손 궤적의 mano 포즈 파라미터와 GT 값 간의 차이, 인공 가우시안 잡음(\\(\\hat{\\theta}^{\\textbf{n}}\\))을 갖는 mano 포즈 파라미터와 GT 값 간의 차이, 베타 분포로부터 유도된 인공 잡음을 갖는 파라미터 간의 차이(\\(\\hat{\\theta}^{\\textbf{b}}\\))에 대한 시각화. 분석은 256개의 궤적에 대해 수행된다. 각각의 궤적에 대해, 모든 프레임들에 걸친 차이 벡터들은 함께 연결되고 단일 벡터로 평탄화된다.\n' +
      '\n' +
      'sian noise to the MANO parameters. 가우스 잡음은 각각 0.01, 0.1 및 0.5의 표준 편차로 손 MANO 병진, 회전 및 포즈 파라미터에 추가된다.\n' +
      '\n' +
      '**GRAB(Beta).** GRAB(Beta) 테스트 세트는 GRAB 테스트 분할로부터의 조작 시퀀스로부터 구성된다. 각 시퀀스에 대해, 잡음 시퀀스는 MANO 파라미터들에 베타 분포(\\(B(8,2)\\))로부터의 잡음을 추가하여 생성된다. 구체적으로, 베타 분포(\\(B(8,2))에서 무작위로 잡음을 샘플링한다. 그런 다음 샘플링된 잡음을 0.01, 0.05, 0.3으로 하여 각각 병진, 회전 및 손 포즈 매개변수에 노이즈 벡터를 추가했다.\n' +
      '\n' +
      '**HOI4D**Liu 등(2022). HOI4D 데이터 세트의 경우 랩톱, 가위 및 플라이어를 포함한 3개의 관절 범주에서 객체를 조작하는 인간과의 상호 작용 시퀀스와 테스트를 위해 의자, 보틀, 볼, 케틀, 머그 및 토이카와 같은 6개의 단단한 데이터 세트를 선택한다. 각 범주에 포함된 인스턴스의 수는 표 3에 자세히 설명되어 있으며, 각 시퀀스에 대해 시작 프레임을 지정하고 테스트 클립으로 시작 프레임 길이가 60개인 클립을 가져간다. 각 카테고리에 대한 시작 프레임 세트는 표 3에 나열되어 있다.\n' +
      '\n' +
      '**ARCTIC**Fan et al. (2023). 평가를 위한 ARCTIC 테스트 세트는 관절 조작과 같은 능숙한 조작이 항상 오른손에 의해 수행된다는 것을 관찰하기 때문에 오른손을 취한다. 예를 들어, 도 4의 예에서 도시된 바와 같이, 왼손은 오른손이 먼저 뚜껑을 터치한 다음 베이스를 터치한 다음 뚜껑을 열고 닫는 동안 조작 중에 접촉 변화가 없는 캡슐 기계를 잡는다. _ 그러나 우리는 그림 1에 표시된 "비디오로부터의 정제 추정" 예제의 두 번째 시퀀스에서 입증된 바와 같이 왼손 동작을 정제할 수 있다. 평가를 위해 "s01", 총 34의 조작 시퀀스를 취한다. 각 테스트 시퀀스에 대해 단계 크기 30을 사용하여 각 시퀀스에서 슬라이스된 윈도우 크기 60의 클립으로부터 정량적 결과를 평가하며, 훈련 데이터 세트를 구성하기 위해 사용된 것과 유사한 필터링 전략을 테스트 클립에도 적용한다. 정성적 평가에 사용된 클립의 기본 길이는 90이며, 이는 윈도우 크기가 60인 인접한 두 개의 클립으로 구성된 결과이며, 잡음 시퀀스는 오른손 MANO 파라미터에 가우시안 노이즈를 추가하여 얻는다. 구체적으로, 가우시안 잡음은 각각 0.01, 0.05 및 0.3의 표준 편차로 손 MANO 병진, 회전 및 포즈 파라미터에 추가된다.\n' +
      '\n' +
      'ARCTIC의 객체 템플릿 메쉬는 우리의 방법과 일부 베이스라인 모델 모두에서 요구되는 정점 노말들을 제공하지 않기 때문에, 우리는 정점 노말들을 계산하기 위해 Open3D Zhou et al.(2018)에서 구현된 "compute_vertex_normals" 함수를 사용한다.\n' +
      '\n' +
      '### Metrics\n' +
      '\n' +
      '우리는 두 가지 평가 메트릭 세트를 포함한다. 첫 번째 집합은 이전 작업 Zhou et al.(2022)의 평가 프로토콜을 따르고 다음에서 자세히 설명하는 것처럼 잡음이 있는 관측으로부터 GT 궤적을 복구하는 모델의 능력을 평가하는 데 중점을 둔다.\n' +
      '\n' +
      '**Mean Per-Joint Position Error (MPJPE).** 잡음 제거된 3D 손 관절과 대응하는 지상-진실 관절 사이의 평균 유클리드 거리를 계산한다.\n' +
      '\n' +
      '**MPVPE(Mean Per-Vertex Position Error).** 잡음 제거된 3D 손 정점들과 대응하는 지상-진실 정점들 사이의 평균 유클리드 거리를 측정한다.\n' +
      '\n' +
      '**연락처 IoU(C-IoU).** 이 메트릭은 정제된 연락 맵과 지상-진실 연락 맵 사이의 유사성을 평가한다. 이진접촉맵은 \\(\\pm 2\\)mm 이내의 대응거리를 임계화하여 얻는다. Zhou et al. (2022)에 소개된 대응관계에 의존하지 않는 본 논문에서 제안하는 방법은 Zhou et al. (2022)가 제공하는 컴퓨팅 과정을 이용하여 대응관계를 계산한다.\n' +
      '\n' +
      '잡음 제거된 궤적이 자연스러운 손-객체 공간 관계와 일관된 손-객체 움직임을 나타내는지 여부를 측정하기 위해 두 번째 평가 메트릭 세트를 소개한다.\n' +
      '\n' +
      '**Solid Intersection Volume (IV).** Zhou et al.(2022)에 따라 이 메트릭을 평가한다. 그것은 손과 물체 사이의 침투를 정량화한다. 손 메쉬와 객체 메쉬를 복셀화하여 교차 영역의 부피를 교차 부피로 계산한다.\n' +
      '\n' +
      '**Per-Vertex Maximum Penetration Depth(Penetration Depth).** 각 프레임에 대해 각 손 꼭지점의 객체로의 최대 침투 깊이를 계산한다. 그런 다음 모든 프레임에 걸쳐 이러한 값을 평균하여 정점당 최대 침투 깊이를 얻는다.\n' +
      '\n' +
      '**근접 오차.** 메트릭은 GRAB, GRAB(베타) 및 ARCTIC를 포함한 지상-진실 참조가 있는 데이터세트에서만 평가된다. 잡음 제거된 손 메쉬의 각 정점에 대해, 객체 점들에 대한 최소 거리와 대응하는 지상-진실 정점의 객체 점들에 대한 최소 거리 사이의 차이를 계산한다. 근접 오차는 모든 정점에 대한 이러한 차이를 평균하여 구한다. 전체 메트릭은 모든 프레임에 걸쳐 프레임당 메트릭을 평균함으로써 얻어진다. 구체적으로, \\(d^{\\mathbf{h}}_{k,min}\\)는 프레임 \\(k\\)에서 손 키포인트 \\(\\mathbf{h}_{k}\\)에서 물체점까지의 최소 거리를 나타낸다. 형식적으로는 \\(d^{\\mathbf{h}}_{k,min}=\\min\\{d^{\\mathbf{ho}_{k}=\\|\\mathbf{h}_{k}-\\mathbf{o}_{k}\\|_{2}|\\mathbff{h}_{k}\\in\\mathbf{J}_{k},\\mathbf{o}_{k}\\in\\mathbf{P}_{k}\\}\\\\mathbf{h}_{k}\\n\\mathbf{h}_{k}\\n\\mathbf{h}_{k}\\n\\mathbf{p}_{k}\\})로 정의된다. (d^{\\mathbf{h}}_{k,min}\\)는 잡음 제거된 궤적의 키포인트 \\(\\mathbf{h}\\)의 양을 나타내고, \\(d^{\\mathbf{h}}_{k,min}\\)는 지상진실 궤적의 키포인트 \\(\\mathbf{h}\\)의 양을 나타낸다. 그 다음, 전체 메트릭은 근접 오차\\(=\\text{mean}\\{\\|d^{\\mathbf{h}}_{k,min}-d^{\\mathbf{h}}_{k,min}\\|_{2}|\\mathbf{h}_{k}\\in\\mathbff{J}_{k}\\}|1\\leq k\\leq K\\\\\\text{mean}\\{\\|d^{\\mathbf{h}}_{k}\\}|1\\leq K\\\\text{mean}\\{\\|d^{\\mathbf{h}}_{h}}_{k,min}-d^{\\mathbf{h}}_{k}\\in\\mathbf{J}_{k}\\}|1\\leq k\\leq K\\\\\\text{mean}\\{\\|d^{\\mathbf{h}}_{k}\\\\leq K\\\\text{mean}\\{\\|d^{\\mathbf{h}}_{k}\\\\leq K\\\\\n' +
      '\n' +
      '**Hand-Object Motion Consistency(HO Motion Consistency)** 이 메트릭은 손과 물체 움직임 사이의 일관성을 평가합니다. 객체가 정적이 아닌 각 프레임에 대해, 가장 가까운 손-객체 포인트 쌍 \\((\\mathbf{h}_{k},\\mathbf{o}_{k})=\\text{argmin}\\{d^{\\mathbf{ho}}_{k}|(\\mathbf{h}_{k}\\in\\mathbff{J}_{k},\\mathbf{o}_{k}\\in\\mathbff{P}_{k})\\}\\}\\}을 식별한다. 우리는 손과 물체의 움직임 사이의 불일치 정도를 정량화하기 위해 \\(\\|e^{-100\\|\\mathbff{h}_{k}-\\mathbf{o}_{k}\\|_{2}}\\Delta\\mathbff{h}_{k}-\\Delta\\mathbff{o}_{k}\\|_{2}^{2}\\)의 식을 사용한다. 여기서, \\(\\Delta\\mathbf{h}_{k}\\)와 \\(\\Delta\\mathbf{o}_{k}\\)는 각각 인접한 프레임 사이의 손 포인트와 물체 포인트의 변위를 나타낸다. 우리는 모든 프레임에 대해 메트릭을 평균하여 전체 메트릭을 얻는다.\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      '본문의 간략한 소개를 보완하기 위해 비교된 기준선에 대해 보다 구체적으로 설명하면 다음과 같다.\n' +
      '\n' +
      '**TOCH.** HOI denoising problem, TOCH(Zhou et al., 2022)에 대한 종래기술과 우리의 모델을 비교한다. TOCH는 오토인코더 구조를 활용하고 잡음이 많은 궤적을 해당 깨끗한 궤적에 매핑하도록 학습한다. 입력 잡음 궤적을 깨끗한 데이터 매니폴드에 투영함으로써 잡음 제거 작업을 수행할 수 있다. 저자가 제공한 공식 코드를 교육 및 평가에 활용합니다.\n' +
      '\n' +
      '**TOCH(w/ MixStyle).** 또한, 새로운 상호 작용에 대한 TOCH의 일반화 능력을 향상시키기 위해, 일반 도메인 일반화 방법 MixStyle(Zhou et al., 2021)로 보완하여, "TOCH(w/ MixStyle)"라는 변종을 생성한다.\n' +
      '\n' +
      '**TOCH(w/Aug.).** GRAB 및 GRAB(Beta) 데이터세트의 트레이닝 세트에 대해 TOCH가 트레이닝되는 다른 변형, "TOCH(w/Aug.)"는 보이지 않는 노이즈 패턴에 대한 견고성을 향상시키기 위해 추가로 도입된다.\n' +
      '\n' +
      '### Models\n' +
      '\n' +
      '**우리의 방법에서 사용된 잡음 제거 모델.** 우리는 잡음 제거 모델의 기능과 훈련을 확산 기반 생성 모델에서 점수 함수의 함수로 실현한다. 인체 움직임 확산(Human Motion Diffusion, Tevet et al., 2022)의 구현에 적응하여 표현 2의 각 부분에 대한 세 가지 잡음 제거 모델을 구현한다. (Tevet et al., 2022)에서 구현된 잡음 데이터\\(\\mathbf{x}_{t}\\)로부터 시작 데이터 포인트\\(\\mathbf{x}_{0}\\)를 예측하기 위해 잡음 제거 함수를 훈련하는 대신 잡음(\\(\\mathbf{x}_{t}-\\mathbf{x}_{0}\\)을 예측한다. 또한 기본 훈련 프로토콜을 따릅니다.\n' +
      '\n' +
      '각주 2: [https://guytevet.github.io/mdm-page](https://guytevet.github.io/mdm-page)\n' +
      '\n' +
      '우리는 주로 노이즈 제거 모델의 기본 골격으로 MLP와 트랜스포머를 채택한다. 자세한 구조는 해당 통계의 유형과 치수에 따라 달라집니다. **보충 자료의 코드는 모든 세부 사항을 제공합니다.** 그래서 여기에 자세히 나열하려는 노력을 아끼지 않습니다.\n' +
      '\n' +
      '디노이징 모델을 활용하여 "디노이징 비아 확산" 전략을 통해 입력을 청소할 때, 확산 단계는 모션디프의 경우 400, 공간디프의 경우 200, 시간디프의 경우 100으로 경험적으로 설정된다.\n' +
      '\n' +
      '**우리의 (w/o Diffusion).** 이 절제된 버전에서는 공간 및 시간 표현을 청소하기 위한 잡음 제거 오토인코더를 설계한다. 각 표현\\(\\tilde{\\mathcal{J},\\mathcal{S},\\mathcal{T}\\)에 대해, 잡음제거를 위해 오토인코더를 이용한다. 그 후, 잡음 제거된 표현들을 복원하기 위해 MANO 파라미터\\(\\{\\mathbf{r}_{k},\\mathbf{t}_{k},\\beta_{k},\\theta_{k}\\})를 피팅하여 최종 손 메쉬를 얻는다. 재구성된 손 궤적을 \\(\\mathcal{J}^{recon}\\), 재구성된 손-객체 공간 상대적 위치를 \\(\\mathcal{S}^{recon}\\), 시간적 표현을 \\(\\mathcal{T}^{recon}\\)으로 가정하면, 재구성 손실은 다음과 같이 공식화된다:\n' +
      '\n' +
      '\\lambda_{1}\\|\\mathcal{L}^{rep}_{recon}=\\lambda_{1}\\|\\mathcal{J}-\\mathcal{J}^{recon}\\|_{2}+\\lambda_{2}\\|\\mathcal{S}-\\mathcal{S}^{recon}\\|+\\lambda_{3}\\|\\mathcal{T}-\\mathcal{T}^{recon}\\|, \\tag{14}\\mathcal{S}^{recon}\\|+\\lambda_{3}\\|\\mathcal{T}-\\mathcal{T}^{recon}\\|, \\tag{14}\\mathcal\n' +
      '\n' +
      '여기서 \\(\\lambda_{1},\\lambda_{2},\\lambda_{3}\\)는 재구성 손실에 대한 계수이다. 우리는 \\(\\lambda_{1},\\lambda_{2},\\lambda_{3}=1\\)로 설정하였다. 우리의 실험에서. 공간 표현들 사이의 거리 함수는 각각의 점 쌍 사이의 상대적인 위치들 상에서 계산된다. 시간적 표현 사이의 거리는 손-물체 거리, _i.e., \\(\\{d_{k}^{\\text{ho}}\\}) 및 두 개의 상대 속도 관련 통계량(\\(\\{e_{k,\\parallel}^{\\text{ho}}, e_{k,\\perp}^{\\text{ho}}\\})에 따라 계산된다. 정규화 손실과 함께\n' +
      '\n' +
      '[\\mathcal{L}_{reg}=\\frac{1}{K}\\sum_{k=1}^{K}(\\|\\beta_{k}\\|_{2}+\\|\\theta_{k}\\|_{2})+\\frac{1}{K-1}\\sum_{k=1}^{K-1}\\|\\theta_{k+1}-\\theta_{k}\\|_{2}, \\tag{15}\\frac{1}\\sum_{k=1}^{K-1}\\|\\theta_{k+1}-\\frac{1}\\sum_{k=1}^{K-1}\\heta_{k}\\|_{2},\\tag{15}\\heta_{k}\\heta_{k}\\heta_{k}\\heta_{k}\\heta_{2},\\tag{15}\\heta_{k}\\heta_{k}\\heta_{k}\n' +
      '\n' +
      '상기 총 최적화 목표는 다음과 같이 공식화되고,\n' +
      '\n' +
      '\\[\\text{minimize}_{\\{\\mathbf{r}_{k},\\mathbf{t}_{k},\\beta_{k},\\theta_{k}\\}_{k=1}^{K}}(\\mathcal{L}^{rep}_{recon}+\\mathcal{L}_{reg}), \\tag{16}\\}\n' +
      '\n' +
      '그리고 우리는 문제를 해결하기 위해 애덤 옵티마이저를 사용합니다.\n' +
      '\n' +
      '**TOCH(w/ MixStyle).** MixStyle 레이어를 구현하기 위해 제공된 공식 코드를 사용한다. 우리는 TOCH 모델의 모든 두 인코더 계층 사이에 MixStyle 계층을 추가한다(Zhou et al., 2022). 혼합 스타일의 구성은 기본 설정과 동일하게 유지됩니다.\n' +
      '\n' +
      '**TOCH(w/Aug.).** 모델은 GRAB 트레이닝 세트로부터 쌍을 이루는 노이즈-클린 데이터 쌍에 대해 트레이닝된다. 각 훈련 시퀀스는 가우시안 분포의 잡음과 Beta\\(B(8,2)\\) 분포의 잡음으로 섭동한다. 병진, 회전 및 손 포즈에 대한 가우시안 잡음 척도는 각각 0.01, 0.1 및 0.5이다. 병진, 회전, 손 포즈에 추가된 베타 노이즈의 척도는 0.01, 0.05, 0.3이다.\n' +
      '\n' +
      '**Grasp synthesis network.** (Wu et al., 2022)에서 제안한 WholeGrasp-VAE network를 HandGrasp-VAE network3에 적응한다. 전신 마커를 사용하는 대신, 손 손바닥으로부터 총 32개의 포인트로 구성된 손 앵커 포인트(Yang et al., 2021)를 사용한다. 손 앵커와 물체 점 모두에 대한 접촉 지도를 식별하기 위해 거리 임계값 _i.e._, 2mm를 설정하고 손/물체까지의 최소 거리를 접촉으로 점의 상태를 표시한다. 훈련 중에는 손잡기 설정에서 전신이 고려되지 않기 때문에 지면 접촉 손실을 추가하지 않습니다. 네트워크를 훈련하기 위해 GRAB 테스트 세트를 훈련을 위해 쌍안경, 와인글라스, 프라이팬 및 머그가 포함된 하위 집합으로 추가로 분할한다. 그런 다음 네트워크를 사용하여 보이지 않는 객체에 대한 파악을 합성합니다. 각 객체에 대해 100개의 파악을 선택하여 학습 데이터셋을 구성한다.\n' +
      '\n' +
      '각주 3: [https://github.com/JiahaoPlus/SAGA](https://github.com/JiahaoPlus/SAGA)\n' +
      '\n' +
      '**조작 합성 네트워크.** 조작 합성 네트워크를 훈련시키기 위해 랩톱 범주에 대해 잡음 제거된 조작 궤적을 활용한다. 학습 데이터는 100개의 조작 시퀀스로 구성된다.\n' +
      '\n' +
      '### 훈련 및 평가\n' +
      '\n' +
      '**\\(\\mathcal{\\bar{J}}\\)에 대한 잡음 제거 모델은 훈련 세트 내의 모든 상호작용 시퀀스의 표준화된 손 궤적\\(\\mathcal{\\bar{J}}\\)에 대해 훈련된다. * 우리는 중앙 집중화 및 스케일링을 위해 각 프레임에서 해당 포인트에 인스턴스별 정규화 연산을 적용한다. 구체적으로, 우리는 모든 프레임에 걸쳐 모든 점에 대해 계산된 평균 및 표준 편차 통계를 활용한다. 보다 상세하게, 먼저 모든 프레임들에 대해 모든 키포인트들을 연결하여, 연결된 키포인트들 \\(\\mathbf{J}^{concat}\\):\n' +
      '\n' +
      '\\[\\bar{\\mathbf{J}}_{\\text{concat}=\\text{Concat}\\bar{\\mathbf{J}}_{k},\\text{ dim}=0\\}_{k=1}^{K}, \\tag{17}\\}\n' +
      '\n' +
      '여기서 각 프레임 \\(k\\)에 대한 \\(\\bar{\\mathbf{J}}_{k}\\in\\mathbb{R}^{N_{h}\\times 3}\\). 그런 다음, 평균과 표준 편차를 \\(\\bar{\\mathbf{J}}^{\\text{concat}}}}) 비아에서 계산한다.\n' +
      '\n' +
      'bf{\\mathbf{\\mathbf{\\mathbf{\\mathbf{\\mathbf{\\mathbf{\\mathbf{\\mathbf{\\mathbf{\\mathbf{\\mathbf{\\mathbf}}}}}}=\\text{Std}(\\bar{19}\\text{concat}},\\text{bf{\\mathbf{\\mathbf{\\mathbf{\\mathbf}}}}}}}}} \\(\\mu^{\\bar{\\mathbf{J}},\\sigma^{\\bar{\\mathbf{J}})\\)는 각 프레임에서의 \\(\\(k\\), _i.e.,_bar{\\mathbf{J}}_{k}\\)을 정규화하기 위해 사용된다.\n' +
      '\n' +
      '\\[\\bar{\\mathbf{J}}_{k}\\leftarrow\\frac\\bar{\\mathbf{J}_{k}-\\mu^{\\mathbf{J}}{\\sigma^{\\mathbf{J}}. \\tag{20}\\\n' +
      '\n' +
      '**\\(\\mathcal{S}\\)**에 대한 잡음 제거 모델. 유사하게, 손-물체 공간 관계(\\(\\mathcal{S}\\)에 대한 잡음 제거 모델은 트레이닝 세트의 모든 상호작용 시퀀스로부터 표현 \\(\\{\\mathcal{S}\\}\\)을 사용하여 트레이닝된다. 정규화된 손-객체 상대위치 \\(\\{(\\mathbf{h}_{k}-\\mathbf{o}_{k})\\mathbf{R}_{k}^{T}\\}\\}에 인스턴스당 정규화를 적용한다. 정규화는 인스턴스별 개체별 점 방식으로 수행됩니다. 일반화된 접촉점 \\(\\mathbf{P}\\)의 각 물체점 \\(\\mathbf{o}\\)에 대해, 우리는 모든 프레임 \\(k\\)에서 \\(\\{\\mathbf{h}_{k}-\\mathbf{o}_{k}\\}\\)의 평균과 표준편차를 계산한다. 우리는 먼저 연접된 공간 관계에 대한 모든 프레임 및 모든 핸드 키포인트에 대한 상대적인 위치를 연접하고, 이를 다음과 같이 표시한다.\n' +
      '\n' +
      '\\[\\mathbf{s}_{\\text{concat}}^{\\mathbf{o}=\\text{Concat}\\{\\{\\mathbf{h}_{k}-\\mathbf{o}_{k}\\},\\text{dim}=0\\}_{k=1}^{K}. \\tag{21}\\}\n' +
      '\n' +
      '그런 다음, \\(\\mathbf{s}_{\\text{concat}}^{\\mathbf{o}}}}) 비아 상에서 평균 및 표준 편차를 계산한다.\n' +
      '\n' +
      '\\text{Average}(\\mathbf{s}_{\\text{concat}}^{\\mathbf{o}},\\text{dim}=0)\\tag{22}\\[\\sigma^{\\mathbf{o}} =\\text{Std}(\\mathbf{s}_{\\text{concat}}^{\\mathbf{o},\\text{dim}=0)\\tag{23}\\tigma^{\\mathbf{o}}\n' +
      '\n' +
      '이러한 통계량\\((\\mu^{\\mathbf{o}},\\sigma^{\\mathbf{o}})\\)는 상대적인 위치\\(\\{\\mathbf{h}_{k}-\\mathbf{o}_{k}\\}\\}), _i.e.,_\n' +
      '\n' +
      '[(\\mathbf{h}_{k}-\\mathbf{o}_{k})\\leftarrow\\frac{(\\mathbf{h}_{k}-\\mathbf{o}-\\mu^{\\mathbf{o}}{\\sigma^{\\mathbf{o}}}. \\tag{24}\\frac{(\\mathbf{h}_{k}-\\mathbf{o}}}\\mu^{\\mathbf{o}}}\n' +
      '\n' +
      '**\\(\\mathcal{T}\\)에 대한 디노이징 모델** 손-물체 시간 관계 \\(\\mathcal{T}\\)에 대한 디노이징 모델을 트레이닝할 때, 먼저 \\(\\cdot)\\)의 엔코딩 기능과 \\(\\mathcal{T}\\)의 디코드 기능으로 구성된 오토인코더를 트레이닝한다. 이것은 입력으로서 \\(\\mathcal{T}\\)을 취하고, 손-물체 거리 \\(\\{d_{k}^{\\mathbf{ho}\\}\\)와 상대 속도 관련 양 \\(\\{e_{k,\\perp}^{\\mathbf{ho}},e_{k,\\parallel}^{\\mathbf{ho}\\}\\}\\}을 디코딩한다. 그리고 엔코딩된 잠재(\\\\text{encode}(\\mathcal{T})\\}\\}에 대해 잡음제거 모델을 학습시킨다. 이 접근법은 시간적 표현을 위한 정규화 전략을 설계할 필요성을 회피한다. 본 논문에서는 위치 엔코더와 시간 관계 표현 부호화를 위한 트랜스포머 엔코더 모듈이 결합된 PointNet 구조 블록을 채택한다. 입력 시간 표현 \\(\\hat{T}\\in\\mathbb{R}^{K}\\times N_{\\times}\\times 69}\\)이 주어지면, PointNet 인코더 블록은 잠재 차원이 \\((32,32,32), (64,64,64), (128,128,128), (256,256,256)\\)인 3개의 인코딩 레이어를 갖는 4개의 PointNet 블록을 각각 통과한다. 변압기 인코더 모듈은 파라미터 "num_heads"가 4, feedforward 잠재 차원이 1024, dropout rate가 0, 잠재 차원이 256으로 구성되어 있으며, 디코더는 각각의 통계(d_{k}^{\\mathbf{ho}, e_{\\perp,k}^{\\mathbf{ho}, e_{\\parallel,k}^{\\mathbf{ho}})를 개별적으로 디코딩하기 위해 완전히 연결된 레이어를 포함한다.\n' +
      '\n' +
      '**Train-time rotation augmentation.** Canonicalized Hand trajectory representation \\(\\tilde{\\mathcal{J}}\\)에 대해, 열차-time random rotation augmentation은 전체 Canonicalized Hand trajectory에 하나의 random rotation matrix를 적용한다. 손-물체 공간 표현(\\(\\mathcal{S}\\)에도 동일한 랜덤 회전 행렬(\\mathbf{R}_{\\text{md}\\)이 추가된다. 표준화된 객체 위치, 법선 및 손-객체 오프셋 벡터를 변환하는데 사용된다:\n' +
      '\n' +
      'md}=((\\mathbf{o}_{k}-\\mathbf{t}_{g}}\\mathbf{R}_{k}^{T}\\mathbf{R}_{text{md},\\mathbf{n}_{k}\\mathbf{R}_{k}^{T}\\mathbf{R}_{k}}\\mathbf{h}_{k}}\\mathbf{R}_{k}\\text{md}}\\mathbf{h}_{k}\\mathbf{R}_{j}\\text{md}}\\mathbf{n}_{k}\\mathbf{r}_{n}\\mathbf{n}\\mathbf{n}\\mathbf{R}_{k}}\\mathbf{r}_{k}\\mathbf{j}\\text{md}}\\mathbf{h}_{k}\\mathbf{j}_{k}\\mathbf{\n' +
      '\n' +
      '마찬가지로, 동일한 랜덤 회전 행렬 \\(\\mathbf{R}_{\\text{md}\\)을 사용하여 객체 속도 벡터를 시간 표현 \\(\\mathcal{T}\\)에서 \\(\\mathbf{v}_{k}^{\\mathbf{o}}\\(\\mathbf{v}_{k}^{\\mathbf{o}}\\mathbf{R}_{\\text{md}\\)으로 변환한다.\n' +
      '\n' +
      '### 복잡성과 실행 시간 토론\n' +
      '\n' +
      '손 키포인트의 수를 \\(|\\mathcal{J}|\\), 일반화된 접촉점의 수 \\(|\\mathcal{P}|\\), 복잡도, 평균 추론 시간 및 추론 중 각 잡음 제거 단계에 대한 순방향 확산 단계의 수로 표현하면 표 8과 같다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c} \\hline \\hline  & MotionDiff & SpatialDiff & TemporalDiff \\\\ \\hline Average inference time (s) & 0.52 & 16.61 & 7.04 \\\\ \\hline Complexity & \\(\\mathcal{O}(|\\mathcal{J}|)\\) & \\(\\mathcal{O}(|\\mathcal{P}||\\mathcal{J}|)\\) & \\(\\mathcal{O}(|\\mathcal{P}||\\mathcal{J}|)\\) \\\\ \\hline \\#Forward diffusion steps & 400 & 200 & 100 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: **복잡도 및 추론 시간 동안의 실행 시간.**\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>