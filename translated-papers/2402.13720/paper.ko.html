<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# Euroboros: Large Model Enhanced Drafting을 이용한 투기적 복호화\n' +
      '\n' +
      'Weilin Zhao\n' +
      '\n' +
      'Yuxiang Huang\n' +
      '\n' +
      'Xu Han\n' +
      '\n' +
      'Chaojun Xiao\n' +
      '\n' +
      'Zhiyuan Liu\n' +
      '\n' +
      'Maosong Sun\n' +
      '\n' +
      '동등한 기여도 \\({}^{1}\\)NLP 그룹, 컴퓨터 공학과, 인공지능 연구소, 베이징 정보 과학 기술 국가 연구 센터, 베이징 칭화 대학교. Weilin Zhao \\(<\\)zw123@mails.tsinghua.edu.cn\\(>\\), Yuxiang Huang \\(<\\)huang-yx21@mails.tsinghua.edu.cn\\(>\\), Xu Han \\(<\\)hanxu2022@tsinghua.edu.cn\\(>\\), Zhiyuan Liu \\(<\\)liuzy@tsinghua.edu.cn\\(>\\)에 해당한다.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '추측 디코딩과 같은 드래프팅-이후 검증 디코딩 방법들은 대규모 언어 모델들(LLM)의 추론을 가속화하기 위해 널리 채택되는 트레이닝-프리 방법들이다. 토큰들을 순차적으로 디코딩하기 위해 자기회귀 프로세스를 사용하는 대신에, 투기적 디코딩은 초기에 효율적인 작은 모델로 드래프트들을 생성한다. 그런 다음 LLM은 시간 오버헤드를 최소화하기 위해 비자기회귀 방식으로 검증 및 수정을 수행해야 한다. 더 긴 드래프트를 생성하면 검증되면 훨씬 더 큰 속도 향상을 가져올 수 있지만 실패할 경우 상당한 시행착오 비용이 발생합니다. 높은 검증 실패 확률로 인해, 기존의 디코딩 방법들은 한 번에 검증을 위해 너무 많은 콘텐츠를 드래프트할 수 없어, 최적이 아닌 추론 가속을 달성한다. 본 논문에서는 LLM의 검증 과정에서 구 후보 풀을 구성하여 작은 모델의 초안 생성을 위한 후보들을 제공하는 Ouroboros를 소개한다. 이로써, Ouroboros는 초안의 효율성과 효율성을 더욱 향상시킬 수 있다. 일반적인 텍스트 생성 태스크에 대한 실험 결과는 Ouroboros가 Lookahead 디코딩과 추측 디코딩에 비해 각각 최대 \\(1.9\\times\\) 및 \\(2.8\\times\\)의 속도 향상을 달성함을 보여준다. Ouroboros의 소스 코드는 [https://github.com/thunlp/Ouroboros](https://github.com/thunlp/Ouroboros]에서 사용할 수 있다.\n' +
      '\n' +
      '머신러닝, ICML\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      'GPT-4(Achiam et al., 2023)와 같은 대형 언어 모델(LLM)은 NLP 분야에서 상당한 돌파구에 도달하고 복잡한 NLP 작업을 처리하는 포괄적인 능력을 나타낸다(Lewkowycz et al., 2022; Nakano et al., 2021; Driess et al., 2023). 또한, 수백억 개의 파라미터를 갖는 다양한 오픈 소스 LLM(Touvron et al., 2023; 01; ai, 2023; Bi et al., 2024)도 유망한 태스크 성능을 보여주었다. 병렬 컴퓨팅 디바이스들 및 분산 트레이닝 알고리즘들(Shoeybi et al., 2019; Rasley et al., 2020)의 최근의 진보로부터, LLM들의 트레이닝 시간이 상당히 단축되었다. 그러나 LLM의 추론은 여전히 병렬화가 어렵다. 이 모델들은 모두 토큰을 하나씩 디코딩하기 위해 자기 회귀 프로세스를 사용하기 때문이다. 따라서, 단순히 자기 회귀 디코딩 프로세스를 채택하는 것은 ChatGPT(OpenAI, 2022)와 같은 LLM의 다양한 실시간 응용 시나리오에서 높은 추론 효율 요구 사항을 충족할 수 없다.\n' +
      '\n' +
      'LLM들의 추론을 무손실 가속화하기 위해, 다양한 드래프팅-그-검증 디코딩 방법들이 제안되었다(Fu et al., 2023; Xia et al., 2023; Leviathan et al., 2023; Chen et al., 2023a). 추론을 가속화하기 위한 목표 모델이 주어지면, 이러한 디코딩 방법들은 먼저 초안을 빠르게 근사한 다음 비-자기회귀 병렬 방식으로 초안을 검증한다. 이러한 프레임워크 하에서 어떻게 효율적으로 효과적으로 초안을 생성할 것인가는 LLM 추론을 가속화하는 중요한 요소가 되었다. 한 번에 다수의 토큰을 생성하기 위해 추가적인 디코딩 모듈을 설계하는 데 일부 노력이 투입되지만, 값비싼 트레이닝이 필요하다(Cai et al., 2024). 따라서, 룩어헤드 디코딩(Fu et al., 2023) 및 추측 디코딩(Xia et al., 2023; Leviathan et al., 2023; Chen et al., 2023a)과 같은 트레이닝-프리 방법들은 증가하는 관심을 받는다. Lookahead 디코딩은 다수의 n-gram 후보들을 병렬로 생성하고, n-gram 후보들을 드래프트들로서 사용하는 반면, 추측 디코딩은 작은 모델을 사용하여 드래프트들을 빠르게 생성한다.\n' +
      '\n' +
      '이러한 훈련 없는 드래프팅-그리고-검증 디코딩 방법의 성공에도 불구하고, 우리는 그들의 두 가지 한계를 관찰한다: **(1) 불충분한 드래프트.** 드래프팅 자체에 수반되는 시간 오버헤드 때문에, 긴 드래프트를 작성하는 것은 이러한 드래프트가 실패할 때 높은 에러 비용을 초래할 수 있다. 그러나 너무 짧은 드래프팅도 잠재적인 가속을 놓칩니다. 일단 긴 초안이 검증되면, LLM 추론을 가속화하는 이점은 매우 명백하다. **(2) 미활용 검증**. 현재의 검증 메커니즘은 드래프트에서 첫 번째 잘못된 토큰만 수정하고 후속 토큰을 사용할 수 없는 것으로 폐기할 수 있으므로 이러한 폐기된 토큰의 활용을 위한 여지를 남긴다. 우리의 파일럿 관찰에 기초하여, 많은 폐기된 토큰이 정확하게 예측된다. 예를 들어, "사과와 바나나를 마시는 것을 좋아한다"라는 초안이 주어졌을 때, 현재의 검증 메커니즘은 단순히 "드링크"를 "먹다"로 정정하고 "드링크" 후에 모든 올바른 토큰을 폐기한다. 이러한 임의로 폐기된 토큰을 활용하는 것도 LLM 추론을 가속화하는 데 큰 도움이 될 수 있다.\n' +
      '\n' +
      '기존의 드래프팅-앤-검증 디코딩 방법들의 위와 같은 두 가지 한계를 극복하기 위해, 본 논문에서는 보다 효율적인 디코딩 프레임워크인 Ouroboros를 소개한다. 추측 디코딩과 유사하게, 타겟 모델이 주어지면, Ouroboros는 타겟 모델을 사용하여 드래프트를 검증하고 훨씬 더 작은 모델을 사용하여 드래프트를 생성한다. 그런 다음, Ouroboros는 초안 생성을 돕기 위해 여러 개의 유익한 구로 구성된 구 후보 풀을 설계한다. 한편으로, 토큰 레벨보다는 어구 레벨에서의 드래프팅은 드래프팅 단계를 더 긴 드래프트들을 생산하는데 더 효율적으로 만들 수 있다. 반면에, 풀에서 문구를 연결하는 것은 낮은 비용과 높은 품질로 드래프트를 훨씬 더 길게 연장할 수 있다. 검증 단계에서 Ouroboros는 검증된 토큰과 폐기된 토큰을 모두 포함하는 완전한 검증 결과를 활용하여 후보 영감을 생성하고 후보 풀을 업데이트한다. 후보 풀을 업데이트하는 것은 드래프팅의 속도와 품질을 더욱 향상시키는 데 도움이 된다. 보다 구체적으로, Ouroboros의 주요 노력은 다음과 같다:\n' +
      '\n' +
      '(1) Ouroboros는 목표 모델과 초안 모델 사이에 후보 풀을 공유한다. 드래프팅 단계 동안, 더 작은 드래프트 모델은 먼저 어구 후보 풀을 사용하여 어구 레벨에서 문장 초안을 생성한다. 그리고, 문장 초안의 마지막 토큰에 따라, 후보 풀로부터 문장 초안과 연결될 수 있는 top-k개의 후보 어구들을 선택한다. Ouroboros는 문장 초안과 \\(k\\) 구문을 연결함으로써 다음 검증 단계를 위해 \\(k\\) 더 긴 초안을 생성한다.\n' +
      '\n' +
      '(2) Ouroboros는 검증 결과를 충분히 활용한다. 올바른 것으로 검증된 초안 접두사를 생성 결과로 사용합니다. 초안에서 고품질로 검증된 부분 문자열은 향후 반복에서 초안 단계를 가속화하기 위한 후보 영감에 사용된다. Ouroboros는 초안 작성을 강화하기 위해 목표 모델을 사용하는 첫 번째 프레임워크이다.\n' +
      '\n' +
      '그림 1: Ouroboros의 구조. 입력 접두사 ABCD를 고려할 때, 최적화하고자 하는 목표 모델이 연속적인 문자로 시퀀스를 계속하고 EFGHIJKLMN을 생성할 것이라고 가정하며, 더 작은 모델은 EFGHWKLMN을 출력할 수 있다. \\\\ (\\Box\\) 각 반복에서 우리는 먼저 마지막 토큰(이 경우 D)을 사용하여 D. \\(\\varo\\) 옆에 있을 수 있는 일부 후보를 검색한다. 더 작은 모델을 사용하여 해당 후보를 검증하고 보정 후 시퀀스 EFG를 생성한다. \\ (\\varo\\) 상기 절차는 여러 번 수행되며, 여기서 ABCDEFG는 HIWK를 생성하고, ABCDEFGHWK는 LMN을 생성한다. \\\\ (\\varo\\) 이후, 더 작은 모델에 기초하여 생성된 시퀀스들은 문장 초안 EFGHWKLMN에 결합되고, 마지막 토큰 N으로 시작하는 일부 후보들은 초안 접미사로서 검색된다. \\varo\\ (\\varo\\) 타겟 모델은 이들을 동시에 검증한다. (1) 타겟 모델은 I의 다음 토큰이 W가 아닌 J가 되어야 한다는 것을 발견하여, **EFGHIJ**가 세대로 사용될 수 있다. (2) KLMN인 W 이후의 초안 토큰들은 잘못된 컨텍스트 W에 기초하기 때문에 현재의 반복에서 생성으로서 사용될 수 없다. 그러나 목표 모델의 출력과 매우 일치하므로 고품질 후보 KLMN 및 LMNO를 생성할 수 있으며, 이는 **EFGHIJ** 이후 미래 세대에 영감을 줄 수 있다. (3) 저품질 후보 접미사 NOXQ와 NRSY는 각각 NOPQ와 NOPT로 변경되어 대상 모델에 의해 고정된다. 정제된 후보들 둘 다 적어도 하나의 토큰이 정정되고, 향후 반복들에서 생성 속도를 높이는 것을 도울 수 있다.\n' +
      '\n' +
      ' (3) 빈 후보 풀로 시작하는 추위가 최적이 아닌 성능을 산출함을 알 수 있다. 본 논문에서는 상황 지역성을 소개하고, 유사 태스크에 의해 미리 채워진 후보 풀을 초기화로 사용하여 생성을 수행한다. 이를 통해 추가 속도를 높일 수 있습니다.\n' +
      '\n' +
      'Ouroboros를 구현하고 코드 생성(Chen et al., 2021; Austin et al., 2021), 텍스트 요약(See et al., 2017; Hermann et al., 2015), 기계 번역(Bojar et al., 2016) 등 다양한 텍스트 생성 태스크에 대해 충분한 실험을 수행한다. 실험 결과, Ouroboros는 태스크 수행에 전혀 손실이 없으며, 추가적인 모델 미세 조정 없이 상당한 추론 가속을 달성할 수 있음을 보여준다. 최근 경쟁 복호화 방법에 비해 Ouroboros는 Lookahead 복호화에 비해 최대 1.9\\(\\times\\)의 가속도를, 추측 복호화에 비해 2.8\\(\\times\\)의 가속도를, 나이브 자기회귀 복호화에 비해 3.9\\(\\times\\)의 가속도를 달성하였다.\n' +
      '\n' +
      '## 2 Ouroboros\n' +
      '\n' +
      '### Overall framework\n' +
      '\n' +
      '전형적인 자기회귀 복호 과정의 경우, 추론에 사용되는 n개의 토큰(x_{1\\cdots n}\\)과 LLM(\\mathcal{T}\\)을 포함하는 입력 프리픽스가 주어지면, 복호 과정은 \\(y_{1\\cdots n}=\\mathcal{T}(x_{1\\cdots n})\\)으로 공식화될 수 있으며, 여기서 \\(y_{1\\cdots n}\\)은 입력으로서 \\(x_{1\\cdots n}\\)을 갖는 모델 \\(\\mathcal{T}\\)의 출력이다. 그리고 나서, \\(y_{n}\\)을 디코딩된 토큰으로 출력하고, 다음 토큰을 디코딩하기 위한 입력 프리픽스로 \\(x_{1\\cdots n}\\)과 \\(y_{n}\\)을 연결한다. 이러한 자기회귀 방식에 따라 하나의 토큰을 디코딩하는 것은 모델\\(\\mathcal{T}\\)의 전체 순방향 패스를 한 번 필요로 하며, 이는 \\(\\mathcal{T}\\)의 크기가 클 때 매우 비싸다.\n' +
      '\n' +
      '그림 1과 같이 목표 모델 \\(\\mathcal{T}\\)의 추론을 가속화하기 위해 Ouroboros는 디코딩 파이프라인을 드래프팅과 검증의 두 단계로 구분하고 두 단계가 공유하는 구 후보 풀 \\(\\mathcal{P}\\)을 설계한다. 오로보로스는 초안 모델로 \\(\\mathcal{T}\\)을 사용하는 것보다 초안 단계를 충분히 효율적으로 만들기 위해 \\(\\mathcal{T}\\)보다 훨씬 작은 모델 \\(\\mathcal{S}\\)을 선택하여 초안을 생성한다. 초안 작성 단계에서 Ouroboros는 먼저 입력 접두사 \\(x_{1\\cdots n}\\)을 주어 \\(\\gamma\\) 토큰이 포함된 문장 초안 \\(d_{1\\cdots\\gamma}\\)을 생성하기 위해 \\(\\mathcal{S}\\)을 사용한다. Generaly, \\(d_{1\\cdots\\gamma}\\)를 생성하는 것은 \\(\\gamma\\) 단계의 자기회귀 복호화를 수행해야 한다. 구문 후보 풀(\\(\\mathcal{P}\\)의 도움으로, Ouroboros는 구문 초안으로 후보 풀의 구문을 사용하여 \\(d_{1\\cdots\\gamma}\\)을 구성한다. 구별로 \\(d_{1\\cdots\\gamma}\\) 구를 구성하는 것이 토큰별로 구성하는 것보다 효율적이다.\n' +
      '\n' +
      '일반적인 드래프팅-이후 검증 디코딩 방법과는 달리, Ouroboros에서 타겟 모델 \\(\\mathcal{T}\\)에 대해 생성된 드래프트는 문장 초안과 여러 후보 접미사 \\(\\{c^{(1)}_{1\\cdots\\beta}, c^{(2)}_{1\\cdots\\beta},\\cdots\\}\\)의 두 세그먼트로 구성된다. 각 후보 접미사 \\(c^{(i)}_{1\\cdots\\beta}\\)에는 \\(\\beta\\) 토큰이 포함되어 있으며, 또한 풀 \\(\\mathcal{P}\\)에서 샘플링된다. Ouroboros는 문장 초안과 후보 접미사를 연결하여 더 긴 초안을 형성한다. 하나의 문장 초안을 다수의 후보 접미사와 연결함으로써, 동일한 접두사를 공유하는 다수의 초안을 형성할 수 있다. 예를 들어, 초안 "나는 먹는 것을 좋아한다"와 후보 접미사 "사과를 먹는다"와 "바나나를 먹는다"를 연결하여 각각 더 긴 초안 "나는 사과를 먹는 것을 좋아한다"와 "바나나를 먹는 것을 좋아한다"를 구축할 수 있다.\n' +
      '\n' +
      '여러 개의 더 긴 초안을 구성하는 것은 이러한 초안 중 하나가 검증 단계를 통과할 확률을 증가시켜 더 긴 초안을 사용하여 \\(\\mathcal{T}\\)의 추론을 가속화할 수 있다. 그러나 이러한 긴 초안을 하나씩 확인하는 비용도 견딜 수 없습니다. 다행히도, 한 번에 생성된 여러 개의 긴 초안이 접두사(문장 초안)를 공유하기 때문에, Ouroboros는 정교한 트랜스포머 주의 마스킹 메커니즘을 구축하여 \\(\\mathcal{T}\\)의 하나의 순방향 패스만으로 모든 긴 초안의 검증을 완료한다.\n' +
      '\n' +
      '전통적인 검증은 검증된 프리픽스를 드래프트에 유지하고 디코딩된 토큰으로 출력하는 반면, 이후의 모든 실패한 토큰은 폐기한다. 타깃 모델\\(\\mathcal{T}\\)이 문장 초안과 여러 후보 접미사를 모두 포함하는 초안을 검증한 후, Ouroboros는 실패한 토큰에 기초하여 후보 영감을 생성하고 후보 접미사에 대한 후보 정제를 수행한다. 후보 영감과 후보 정제 모두 구절 후보 풀(\\(\\mathcal{P}\\)을 향상시켜 더 좋고 빠른 드래프트 생성을 촉진할 수 있다.\n' +
      '\n' +
      '다음으로 Ouroboros를 문장 초안 생성, 더 긴 초안 구축, 합성 초안 검증, 후보 영감 및 정교화의 4가지 부분으로 분해하고, 이 4가지 부분을 구분하여 소개하기로 한다.\n' +
      '\n' +
      '더 긴 초안 건설\n' +
      '\n' +
      '드래프팅 단계에서 모델\\(\\mathcal{S}\\)은 \\(\\gamma\\) 토큰으로 초안\\(d_{1\\cdots\\gamma}\\)을 작성하고 타겟 모델\\(\\mathcal{T}\\)은 초안을 검증하고 검증된 토큰을 출력한다. 각 입력 토큰에 대해 생성 LLM은 다음 토큰을 예측한다. 즉, \\(d_{1\\cdots\\gamma}\\)을 검증하는 것은 \\(d_{\\gamma}\\)이 \\(\\mathcal{T}\\)의 입력에 포함될 필요가 없다. 그러나 추측과 같은 일반적인 드래프팅-앤-검증 방법은\n' +
      '\n' +
      '그림 2: Ouroboros의 맞춤형 주의 마스킹.\n' +
      '\n' +
      '디코딩(Leviathan et al., 2023; Chen et al., 2023a), \\(d_{\\gamma}\\)은 드래프트가 완전히 정확할 때 여분의 그라운드 진리 토큰을 생성할 수 있도록 타겟 모델 \\(\\mathcal{T}\\)에 입력으로서 전달된다. 이상의 결과는 다양한 하드웨어 장치의 병렬 연산 능력으로 인해 \\(\\gamma-1\\) 토큰 또는 \\(\\gamma\\) 토큰을 병렬로 실행하는 데 드는 시간 비용은 거의 변하지 않지만 추가 접미사를 입력하면 전체 초안이 승인되면 추가 속도가 향상될 수 있음을 나타낸다.\n' +
      '\n' +
      '따라서 본 논문에서는 길이\\(\\beta\\)의 구들로 구성된 후보 풀\\(\\mathcal{P}\\)을 이용하여 다수의 드래프트 접미사를 생성할 것을 제안한다. 우리는 목표 모델\\(\\mathcal{T}\\)과 작은 모델\\(\\mathcal{S}\\)의 어휘 공간\\(\\mathcal{V}\\)을 나타낸다. \\(\\mathcal{V}\\)에서 각 토큰 \\(v\\)에 대해 정의합니다.\n' +
      '\n' +
      '\\[\\mathcal{P}(v)\\coloneqq\\{c_{2\\cdots\\beta}|c_{1\\cdots\\beta}\\in\\mathcal{P}\\wedge c_{1}=v\\}. \\tag{1}\\}\n' +
      '\n' +
      '직관적으로 \\(\\mathcal{P}(v)\\)는 토큰 \\(v\\)으로 시작하는 어구 접미사 집합이다. 모든 어구를 \\(\\mathcal{P}(v)\\)로 암기하는 것은 너무 비싸기 때문에, Ouroboros는 각 토큰에 대해 후보 어구의 크기를 \\(W\\)으로 제한하기 위해 \\(|\\mathcal{P}(v)|\\leq W\\)을 제한하고, \\(\\mathcal{P}(v)\\)에서 후보 어구를 갱신하기 위해 가장 최근에 사용된 LRU 대체 기법을 사용한다. 문장 초안 \\(d_{1\\cdots\\gamma}\\)이 주어지면 \\(\\mathcal{P}(d_{\\gamma})\\)에 삽입된 \\(K\\)의 새로운 후보 접미사를 선택한다. 우리는 \\(\\{c^{(1)}_{2\\cdots\\beta},c^{(2)}_{2\\cdots\\beta},\\cdots,c^{(K)}_{2\\cdots\\beta}\\})를 사용하여 선택된 후보 접미사를 나타낸다.\n' +
      '\n' +
      '### 합성초안 검증\n' +
      '\n' +
      '입력 접두사 \\(x_{1\\cdots n}\\), 문장 초안 \\(d_{1\\cdots\\gamma}\\) 및 \\(K\\) 후보 접미사 \\(c^{(1)}_{2\\cdots\\beta},c^{(2)}_{2\\cdots\\beta},\\cdots,c^{(K)}_{2\\cdots\\beta}\\)를 기반으로 그림 2와 같이 맞춤형 어텐션 마스킹을 이용하여 병렬 검증을 수행하고, 병렬 검증을 수행한다.\n' +
      '\n' +
      '{split}&\\cdots,\\hat{d}_{1\\cdots\\gamma},\\{\\hat{c}^{(K)}_{2\\cdots\\beta},\\cdots,\\hat{c}^{(K)}_{2\\cdots\\beta}\\\\\\&=\\mathcal{T}(x_{1\\cdots n},d_{1\\cdots\\gamma},\\{c^{(1)}_{2\\cdots\\beta},\\cdots,c^{(K)}_{2\\cdots\\beta}})\\end{split}\\tag{2}\\\\cat{c}^{(K)}_mathcal{T}(x_{1\\cdots n},d_{1\\cdots\\gamma},\\cdots,c^{(K)}_{2\\cdots\\beta}},\\cdots,\\hat{c}^{(K)}_{2\\cdots\n' +
      '\n' +
      'Eq(2)에서 \\(\\hat{d}_{1\\cdots\\gamma+1}\\)은 \\(\\{x_{n},d_{1\\cdots\\gamma}\\}\\)에 해당하는 다음 토큰 예측에 의해 예측되며, 여기서 \\([\\cdot,\\cdot]\\)은 연결연산이다. \\(\\hat{d}_{1\\cdots\\gamma+1}\\)은 연결연산이다. (\\hat{c}^{(i)}_{2\\cdots\\beta}\\)는 모든 \\(1\\leq i\\leq K\\)에 대해 \\([d_{\\gamma},\\hat{c}^{(i)}_{2\\cdots\\beta-1}]\\)에 해당하는 다음 토큰 예측에 의해 예측된다. 식 (2)의 모든 계산은 목표 모델 \\(\\mathcal{T}\\)의 단일 순방향 통과만을 사용하여 수행된다. 그 결과 \\(\\hat{d}\\), \\(\\hat{c}^{(i)}\\)는 각각 \\(d\\) 및 \\(c^{(i)}\\)의 기준 출력으로 사용되었다.\n' +
      '\n' +
      '두 토큰 시퀀스의 가장 긴 공통 접두사 길이를 \\(\\text{len}(\\text{LCP}(x_{1\\cdots n},y_{1\\cdots n}))으로 정의한다.\n' +
      '\n' +
      '\\[\\text{len}(\\text{LCP}(x_{1\\cdots n},y_{1\\cdots n}))=\\arg\\max_{1\\leq l\\leq n}\\{l|x_{1\\cdots l}=y_{1\\cdots l}\\}. \\tag{3}\\}\n' +
      '\n' +
      '그리고 \\(l_{d}=\\text{len}(\\text{LCP}(d_{1\\cdots\\gamma},\\hat{d}_{1\\cdots\\gamma}))을 정의한다. 드래프트가 잘못 검증되었음을 의미하는 \\(l_{d}<\\gamma\\)이면, 정합된 프리픽스를 \\(\\mathcal{T}\\)의 생성 결과로 사용하고 첫 번째 잘못된 토큰은 \\(\\hat{d}\\)을 사용하여 수정한다. 보다 구체적으로 \\(\\hat{d}_{1\\cdots(l_{d}+1)}\\)를 생성 결과로 출력한다. 그렇지 않으면, 초안은 정확한 것으로 검증된다(즉, \\(l_{d}=\\gamma\\)). 그런 다음 가장 오래 일치하는 후보\\(c^{(\\text{best})}\\)를 선택해야 한다.\n' +
      '\n' +
      '\\[\\text{best}=\\arg\\max_{1\\leq i\\leq K}\\text{len}(\\text{LCP}(c^{(i),\\hat{c}^{(i))}\\tag{4}\\text{\n' +
      '\n' +
      'Denote \\(l_{c}=\\text{len}(\\text{LCP}(c^{(best)},\\hat{c}^{(best)}))\\)이 가장 좋은 후보의 일치된 길이이고, 최종 디코딩 결과는 \\([\\hat{d}_{1\\cdots\\gamma},\\hat{c}^{(best)}_{1\\cdots(l_{c}+1}]]이다.\n' +
      '\n' +
      '```\n' +
      '입력: 입력 id \\(x\\), 더 작은 모델 \\(\\mathcal{S}\\), 목표 모델 \\(\\mathcal{T}\\), 후보 풀 \\(\\mathcal{P}\\)은 길이 \\(\\beta\\), 문장 초안 길이 \\(\\gamma\\), 후보 접미사 양 \\(K\\)의 구절을 저장한다. 출력: 생성된 토큰, 업데이트된 후보 풀. while EOS not generateddo /* Sentence Draft Generation */\\(d\\coloneq[]\\ while Let(\\(d\\)) \\(<\\gamma\\)do \\(\\mathcal{C}\\coloneq\\mathcal{P}(x,d,\\)l.last.token()) \\(\\mathcal{\\hat{C}\\coloneq\\mathcal{S}(x,d,\\)l.\\ (\\mathcal{C})\\) Lookahead Decoding과 같은 Update \\(\\mathcal{P}\\) Get \\(\\hat{c}^{(best)}\\) from \\(\\mathcal{C}\\) and accept length \\(l_{c}\\) \\(d\\coloneqq[d,\\hat{c}^{(best)}}_{1\\cdots(l_{c}+1}]\\)while/*Longer Draft Construction */\\(\\mathcal{C}\\coloneq\\text{top-k}(d.\\) last.token())\\), /*Synthetic Draft Verification */\\(\\hat{d},\\hat{\\mathcal{C}\\coloneq\\mathcal})\\) if\\(d=\\hat{d}\\)then Get \\(\\hat{c}^{(best)\\) and accept length \\(l_coloneqq[x,\\hat{d},\\hat{c}^{(best)}}}_{1\\cdots(l_{d}+2)then \\(\\gamma-\\beta-2)\\)to\\(\\gamma-\\beta-2)\\) if\\(d\\coloneqq[x,\\hat{d}_{1\\cdots(l_beta-2)\\)to\\(\\gamma-\\beta+2)\\)to\\(\\gamma-\\beta+2)\\)to\\(\\gamma-\\beta+2)\\)to\\(\\gamma-\\beta inert\\((\\hat{d}_{i\\cdots i+\\beta-1})\\) endif endif for endif /* Candidate Refinement */\\(\\mathcal{P}.\\) replace\\((\\mathcal{C},\\hat{\\mathcal{C}}) endwhile\n' +
      '```\n' +
      '\n' +
      '**Algorithm 1**Ouroboros\n' +
      '\n' +
      '문장 초안 생성\n' +
      '\n' +
      '입력 프리픽스 \\(x_{1\\cdots n}\\)이 주어지면, 마지막 토큰 \\(x_{n}\\)의 모든 후보는 \\(c^{(1)}_{2\\cdots\\beta},\\cdots,c^{(W)}_{2\\cdots\\beta})로 표기되어 드래프팅 속도를 높이기 위해 사용된다. 그림 2에서 맞춤형 주의 마스크를 사용하여 계산할 수 있다.\n' +
      '\n' +
      '{split}&\\cdots,\\{\\hat{c}^{(1)}_{2\\cdots\\beta},\\cdots,\\hat{c}^{(W)}_{2\\cdots\\beta}\\\\\\&=\\mathcal{S}(x_{1\\cdots n},[],\\{c^{(1)}_{2\\cdots\\beta},\\cdots,c^{(W)}_{2\\cdots\\beta}}},\\end{split}\\tag{5}\\}} 그리고 최장일치 후보 \\(c^{(\\text{best})}\\)을 이용하여 선택한다.\n' +
      '\n' +
      '\\[\\text{best}=\\arg\\max_{1\\leq i\\leq K}\\text{len}(\\text{LCP}(c^{(i),\\tilde{c}^{(i))}}\\tag{6}\\text{\n' +
      '\n' +
      'Denote \\(l_{c}=\\text{len}(\\text{LCP}(c^{(best)},\\tilde{c}^{(best)}))\\), 생성 결과는 \\(\\hat{c}^{(best)}_{1\\cdots(l_{c}+1)}\\)이 될 것이다.\n' +
      '\n' +
      'Eq.에서 더 작은 모델 \\(\\mathcal{S}\\)의 동일한 순방향 패스 내에서. (5), Lookahead Decoding은 또한 후보 풀 \\(\\mathcal{P}\\)을 갱신하기 위해 새로운 후보들을 생성하기 위해 추가 입력들을 추가하는데, 우리는 공간 제약으로 인해 세부적으로 들어가지 않을 것이며 Fu et al.(2023)을 참조할 수 있다.\n' +
      '\n' +
      '그림 1과 알고리즘 1에 도시된 바와 같이, 더 작은 모델의 드래프팅은 다수의 라운드를 수행하고 출력들은 긴 문장 초안에 연접된다.\n' +
      '\n' +
      '### 후보자 영감과 정제\n' +
      '\n' +
      '위의 전략은 저렴한 비용으로 더 긴 초안을 생성하고, 따라서 더 많은 검증 결과를 얻는 데 도움이 됩니다. 그러나 기존의 draft-then 검증 알고리즘들은 첫 번째 unmatch 위치 \\(l_{d}+1\\)을 \\(\\hat{d}_{l_{d}+1}\\)만큼만 고정시키고, \\(l_{d}+1\\) 이후의 위치들에 대한 검증 결과는 폐기되어 검증 결과의 활용도가 떨어진다. 우리는 #Match-k\\((x_{1\\cdots n},y_{1\\cdots n}))) 두 토큰 시퀀스의 길이 \\(k\\)의 공통 부분 문자열의 개수를 다음과 같이 정의한다.\n' +
      '\n' +
      '\\[\\text{\\#Match-k}(x_{1\\cdots n},y_{1\\cdots n})=\\big{|}\\{i|x_{i\\cdots i+k-1}=y_{i\\cdots i+k-1}\\}\\big{|}. \\tag{7}\\}\\}\n' +
      '\n' +
      '우리는 표 1에서와 같이 MBPP(Austin et al., 2021), CNN/DM(See et al., 2017; Hermann et al., 2015) 및 WMT16(Bojar et al., 2016)의 세 가지 데이터 세트에 대한 투기적 디코딩을 테스트하고 드래프트-앤-검증의 LCP 길이가 일반적으로 매칭된 토큰의 수보다 작다는 것을 알아낸다. 또한, 그림 3과 같이 버려진 초안 토큰(d_{(l_{d}+2)\\cdots}\\)과 참조 토큰(\\hat{d}_{(l_{d}+2)\\cdots}\\) 사이에 많은 공통 부분 문자열이 존재한다는 것을 알 수 있다. 우리는 우리가 유효한 후보들을 생성하는 것을 돕기 위해 공통 접두사 후에 그러한 매치 포지션들을 활용할 수 있다. 우리는 이것을 _inspiration_라고 부른다.\n' +
      '\n' +
      '따라서, 우리는 우리의 문장 초안에 후보 영감을 적용한다. 공통 프리픽스 \\(d_{1\\cdots l_{d}}\\)을 사용하여 출력 \\(\\hat{d}_{1\\cdots(l_{d}+1)}\\)을 생성하는 검증 단계와 유사하게, 공통 부분 문자열을 사용하여 후보를 생성할 수 있다. 접두사 후 주어진 부분 문자열 매칭 \\(d_{i\\cdots j}=\\hat{d}_{i\\cdots j}\\)에 대해, \\(l_{d}<i<j\\)의 새로운 후보 \\(\\hat{d}_{i\\cdots j+1}\\)을 생성할 수 있다. 우리는 영감으로서 길이\\(\\beta\\)의 새로운 후보들만을 수집하는데, 이는 길이\\(\\beta-1\\)의 공통 부분 문자열에 해당한다.\n' +
      '\n' +
      '문장 초안의 검증 결과를 더 잘 활용하는 후보 영감과 유사하게, 우리는 그들의 검증 결과에 기초하여 후보 접미사를 더 정제한다. 우리는 이전 반복에서 생성된 \\(\\mathcal{P}\\)의 후보들이 이전 문맥에 기반하고, 생성이 진행됨에 따라 시대에 뒤떨어질 수 있다는 직관에 기초하여 후보 정제를 설계한다. 따라서, 후보가 후보 접미사로 선택되는 경우, 더 새로운 컨텍스트에 잘 맞지 않을 수 있다. 그런 다음 이 후보들을 \\(\\mathcal{T}\\)에 의해 검증된 수정된 결과로 직접 업데이트하여 후보 추정을 위한 더 나은 사전 정보를 제공한다. 구체적으로, 풀(\\mathcal{P}\\)에서 구 후보들 \\(c^{(i)}\\)은 모든 \\(1\\leq i\\leq K\\)에 대한 기준 출력 \\(\\hat{c}^{(i)}\\)으로 대체된다.\n' +
      '\n' +
      '### Warm Start\n' +
      '\n' +
      '이전의 연구는 빈 초기화된 후보 풀(\\(\\mathcal{P}\\)(Fu et al., 2023)로 생성을 시작함으로써 생성 초기에 모델이 불충분한 추론 속도를 갖도록 한다. 우리는 그것을 냉담한 시작이라고 부른다. 우리는 이전 세대에서 생성된 글로벌 후보를 후보 풀의 워밍업으로 사용할 수 있음을 발견했다.\n' +
      '\n' +
      '## 3 Experiment\n' +
      '\n' +
      '### Experimental Settings\n' +
      '\n' +
      'Ouroboros로 인한 전반적인 가속도를 평가하기 위해 코드 생성, 산술 추론, 문서 요약, 기계 번역 등 다양한 전형적인 텍스트 생성 작업에 대해 Ouroboros를 평가한다.\n' +
      '\n' +
      '데이타세트 코드 생성을 위해 Ouroboros on HumanEval(Chen et al., 2021)과 MBPP(Austin et al., 2021)의 검증 집합을 평가한다. HumanEval에는 164개의 항목이 있으며 텍스트 프롬프트와 텍스트 프롬프트로 구성됩니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c|c|c} \\hline \\hline Yi-base 34b/6b & MBPP & CNN/DM & WMT-16 \\\\ \\hline len(LCP(\\(d,\\hat{d}\\))) & 12.7 & 8.4 & 5.3 \\\\ \\#Match-1(\\(d,\\hat{d}\\)) & 18.9 & 17.8 & 17.0 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 평균 일치 토큰은 가장 긴 공통 접두사 길이와 비교된다. Lee-base 34b/6b (01-ai, 2023)에 대한 실험으로 드래프트 길이 \\(\\gamma\\) = 20인 Speculative Decoding을 사용하였다.\n' +
      '\n' +
      '그림 3: 버려진 검증 토큰의 길이\\(k\\)의 평균 부분 문자열 수, 즉 #Match-k\\((d_{(l_{d}+2)\\cdots\\gamma},\\hat{d}_{(l_{d}+2)\\cdots})\\). Lee-base 34b/6b (01-ai, 2023)에 대한 실험으로 드래프트 길이 \\(\\gamma\\) = 20인 Speculative Decoding을 사용하였다.\n' +
      '\n' +
      '파이썬 함수의 접두사. MBPP의 유효성 검사 세트는 90개의 엔트리를 가지며, 여기서 전체 함수는 주어진 텍스트 프롬프트 및 테스트 케이스들로 예측될 것으로 예상된다. HumanEval과 MBPP의 최대 생성 길이는 512로 설정하였으며, 산술 추론, 문서 요약 및 기계 번역을 위해 GSM8K(Cobbe et al., 2021), CNN/DM(참조 et al., 2017; Hermann et al., 2015) 및 WMT16(Bojar et al., 2016)에서 각각 우리의 방법을 평가한다. GSM8K와 CNN/DM의 엔트리 100개와 WMT16의 독일어부터 영어 번역 부분집합까지의 엔트리 100개를 무작위로 샘플링하였으며, GSM8k, CNN/DM, WMT16의 최대 생성길이는 각각 256, 128, 64로 설정하였다.\n' +
      '\n' +
      '모델들 HumanEval 및 MBPP의 경우, 실험을 위한 백본 모델로 Yi-base-34b/6b(01-ai, 2023), DeepSeek-coder-34b/7b(Bi et al., 2024) 및 CodeLlama-instruct-34b/7b(Roziere et al., 2023)를 사용한다. GSM8K, CNN/DM 및 WMT16의 경우, Yi-base-34b/6b 및 Llama-2-chat-70b/7b(Touvron et al., 2023)를 사용한다. 이 모든 모델은 최근에 대표적이고 인기 있는 LLM입니다.\n' +
      '\n' +
      '**평가 방법들.** 우리의 실험들의 베이스라인들은 그리디 디코딩, 룩어헤드 디코딩(Fu et al., 2023) 및 추측 디코딩(Leviathan et al., 2023; Chen et al., 2023)이다. 본 논문에서는 그리디 디코딩과 비교하여 디코딩 속도(tok/s)와 속도 증가율을 보고한다. 우리는 따뜻한 시작이 있든 없든 Ouroboros를 시험한다. 따뜻한 시작이 온일 때, 후보 풀은 모든 데이터 엔트리들 사이에서 공유되고, 따뜻한 시작이 오프일 때, 각각의 데이터 엔트리는 생성 전에 새로운 풀을 구성한다. 디코딩 속도는 위의 각 데이터세트의 모든 엔트리에서 측정된다. 우리 실험의 더 많은 하이퍼파라미터는 부록 B에 포함된다.\n' +
      '\n' +
      '### Overall Results\n' +
      '\n' +
      '그림 4는 모든 백본 모델 및 데이터셋 구성에서 Ouroboros가 Greedy 디코딩, Lookahead 디코딩 및 추측 디코딩을 능가함을 보여준다. Ouroboros는 최대 생성길이가 512인 최대 61.2 tok/s 생성속도를 얻을 수 있으며, 이는 탐욕복호와 비교하여 3.9\\(\\times\\), 추측복호와 Lookahead복호에 비해 2.8\\(\\times\\) 그리고 1.9\\(\\times\\)의 속도이다. 웜스타트가 없는 Ouroboros도 다른 세대 알고리즘보다 빠르고 웜스타트는 세대 속도를 높일 수 있어 컨텍스트 지역성이 세대를 가속화할 수 있음을 나타낸다.\n' +
      '\n' +
      '표 2는 Ouroboros가 또한 전형적인 자연 언어 작업에서 상당한 속도를 얻을 수 있으며, 여기서 Lookahead 디코딩 및 추측 디코딩은 제한된 가속만을 얻을 수 있다. 따뜻한 시작이 있는 우로보로가 가장 빠르고, 따뜻한 시작이 없는 우로보로도 모든 구성에서 큰 마진만큼 다른 알고리즘을 능가할 수 있어 상황 지역성에 관계없이 우로보로의 효과를 입증할 수 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l|c c|c c} \\hline \\hline \\multirow{2}{*}{Task} & \\multirow{2}{*}{Algorithm} & \\multicolumn{2}{c|}{Yi 34b/6b} & \\multicolumn{2}{c}{Llama-2 70b/7b} \\\\  & & tok/s & speed-up & tok/s & speed-up \\\\ \\hline \\multirow{4}{*}{GSM8k} & Greedy & 15.33 & 1.00 & 8.96 & 1.00 \\\\  & Speculative & 16.99 & 1.11 & 16.86 & 1.88 \\\\  & Lookahead & 25.14 & 1.64 & 13.77 & 1.54 \\\\  & Ouroboros & 26.41 & 1.72 & 22.18 & 2.48 \\\\  & Ouroboros\\({}^{\\dagger}\\) & **28.23** & **1.84** & **24.03** & **2.68** \\\\ \\hline \\multirow{4}{*}{CNN/DM} & Greedy & 14.62 & 1.00 & 8.12 & 1.00 \\\\  & Speculative & 17.82 & 1.22 & 12.77 & 1.57 \\\\  & Lookahead & 18.77 & 1.28 & 9.47 & 1.17 \\\\  & Ouroboros & 21.24 & 1.45 & 14.62 & 1.80 \\\\  & Ouroboros\\({}^{\\dagger}\\) & **22.65** & **1.55** & **14.67** & **1.81** \\\\ \\hline \\multirow{4}{*}{WMT16} & Greedy & 14.78 & 1.00 & 9.52 & 1.00 \\\\  & Speculative & 17.48 & 1.18 & 14.72 & 1.55 \\\\ \\cline{1-1}  & Lookahead & 17.98 & 1.22 & 14.65 & 1.54 \\\\ \\cline{1-1}  & Ouroboros & 19.75 & 1.34 & 19.11 & 2.01 \\\\ \\cline{1-1}  & Ouroboros\\({}^{\\dagger}\\) & **19.94** & **1.35** & **19.27** & **2.02** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: GSM8K, CNN/DM 및 WMT16 상의 디코딩 속도(tok/s) 및 속도-업 비율. "\\({}^{\\dagger}\\)을 갖는 "Ouroboros"는 웜 스타트 온을 나타내는 반면 "Ouroboros"는 웜 스타트 오프를 의미한다. 가장 빠른 디코딩 방법은 **굵은** 글꼴로 강조 표시되고 두 번째로 큰 결과는 밑줄 친 글꼴로 표시된다.\n' +
      '\n' +
      '도 4: HumanEval 및 MBPP 상의 디코딩 속도. 오로보로의 음영되지 않은 부분은 따뜻한 시작이 없는 결과이고, 음영된 부분은 따뜻한 시작에 의한 추가 개선이다.\n' +
      '\n' +
      '### 절제에 관한 연구 및 분석\n' +
      '\n' +
      '우로보로스가 더 높은 생성 속도를 달성하는 방법에 대한 더 깊은 통찰력을 제공하기 위해 다음과 같은 질문에 답하기 위해 절제 연구와 분석을 수행한다.\n' +
      '\n' +
      '**후보 접미사, 후보 영감, 후보 정교화의 효과는?**후보 접미사, 후보 영감, 후보 정교화의 각 메커니즘에 의해 소개되는 구체적인 속도 향상을 입증하기 위해, 절제 결과는 표 3에 나와 있다. 표에서 후보 영감은 후보 접미사가 켜질 때 긍정적인 영향을 미치고, 공유된 후보와 후보 정교화는 모든 상황에서 긍정적인 영향을 미친다. 각 메커니즘은 속도 향상을 가져올 수 있으므로 세 가지 메커니즘 모두 Ouroboros 프레임워크 설계에 효과적이다.\n' +
      '\n' +
      '**몇 개의 후보 접미사가 필요한가?** Leviathan et al. (2023); Fu et al. (2023)의 가설에 따르면, 모델 추론 동안 더 많은 토큰을 병렬로 검증하는 것은 추론 속도에 영향을 미치지 않을 것이다. 그러나 실제 모델 추론 시나리오에서 더 많은 후보 접미사가 검증 속도를 늦출 수 있다. 가능한 속도 향상 및 느린 검증을 위해 더 많은 후보 접미사 간의 절충안이 제공됩니다. 따라서, 우리는 후보 풀에서 상위\\(k\\)개의 최신 후보들만을 선택한다. 도 5에서, 가장 좋은 \\(k\\) 값이 존재하며, 더 적은 또는 더 많은 후보들이 더 느린 디코딩 속도를 야기한다.\n' +
      '\n' +
      '**컨텍스트 로컬리티가 웜 스타트를 통해 생성을 어느 정도 가속화할 수 있는가?**컨텍스트 로컬리티는 한 작업 내에서 지속적으로 생성할 때 매우 높게 유지되지만 다른 데이터 세트에 따라 다를 수 있다. 예를 들어, 후보 풀은 HumanEval 및 MBPP와 같은 코드 생성 데이터세트 상에서 실행될 때 코드 조각들을 포함해야 하지만, 텍스트를 생성하는 자연 언어 조각들을 포함할 수 있다. 한 유형의 언어 조각이 다른 유형의 언어 생성을 가속화할 수 있는지 여부는 여전히 의문으로 남아 있다. 우리는 따뜻한 시작을 통해 지역성이 생성을 어느 정도 및 어떻게 가속화할 수 있는지 추가로 조사하기 위해 다음 실험을 수행한다.\n' +
      '\n' +
      '코드 생성, 산술 추론, 문서 요약 및 기계 번역에 해당하는 MBPP, GSM8K, CNN/DM 및 WMT16의 4가지 데이터세트와 각 데이터세트의 20개 항목을 선택하여 서로 다른 도메인을 포함하는 새로운 데이터세트를 구성한다. 우리는 상황 지역성을 변경할 수 있는 다중 평가 순서로 Ouroboros를 평가한다. 연속 번호 CN은 그림 6과 같이 동일한 데이터 세트에서 몇 개의 엔트리가 연속적으로 테스트되는 지로 정의한다. "셔플" 구성에서 데이터 엔트리의 순서를 무작위화한다. CN이 높을수록 더 나은 지역성을 나타내며 "셔플" 구성은 최악의 지역성을 가져야 한다. 다양한 CN 구성 또는 무작위 셔플링에서 생성 속도를 측정한다.\n' +
      '\n' +
      '표 4는 맥락 지역성이 실제로 따뜻한 시작의 효과에 영향을 미친다는 것을 보여준다. 따뜻한 시작과 함께, CN=20은 셔플 설정에 비해 더 빠른 디코딩으로 이어진다. 그러나 상황적 지역성으로 인한 효과는 따뜻한 시작을 켤지 여부보다 작다. 낮은 CN의 속도는 웜 스타트 적용 시 셔플 설정과 유사하지만 둘 다 콜드 스타트 설정에 비해 약 3 tok/s 빨라 후보 풀이 여러 작업에 걸쳐 여전히 효과적임을 증명한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c|c c c c c} \\hline \\hline Setting & shuffle & CN=20 & shuffle & CN=20 & CN=10 & CN=4 & CN = 1 \\\\ \\hline Warm Start & off & off & on & on & on & on \\\\ \\hline tok/s & 32.68 & 32.53 & 35.39 & 36.00 & 35.32 & 34.83 & 35.36 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 상황 지역성과 따뜻한 시작에 대한 절제 연구 결과. “CN”은 연속된 숫자를 의미한다.\n' +
      '\n' +
      '그림 5: 후보 접미사에서 상위 k개의 후보를 선택하는 효과는 따뜻한 시작 없이 Yi-34b/6b를 사용하여 HumanEval에 대해 테스트되었다. 후보 풀 크기는 20입니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c|c} \\hline \\hline Candidate & Candidate & Candidate & Candidate \\\\ Inspiration & Suffixes & Refinement & HumanEval \\\\ \\hline  & & & 49.90 \\\\ ✓ & & & 48.90 \\\\  & ✓ & & 55.92 \\\\ ✓ & ✓ & & 56.97 \\\\  & ✓ & ✓ & 57.23 \\\\ ✓ & ✓ & ✓ & 58.18 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 웜 스타트 없이 Yi-34b/6b를 사용하여 HumanEval에 대한 각 성분의 절제 연구. 후보 접미사가 없는 경우에는 "후보 정제"를 적용할 수 없습니다.\n' +
      '\n' +
      '그림 6: 절제 연구는 맥락적 지역성과 따뜻한 시작에 관한 것이다. 실험에서 태스크 1,2,3,4는 각각 MBPP, GSM8K, CNN/DM 및 WMT16이다.\n' +
      '\n' +
      '##4 관련 업무\n' +
      '\n' +
      '이 절에서는 효율적인 디코딩, 효율적인 구현 및 모델 압축을 포함하여 효율적인 LLM 추론을 달성하기 위한 기존의 노력을 소개한다. 효율적인 구현과 모델 압축은 모두 우리의 방법과 직교하며, 추가 속도를 위해 결합될 수 있다는 점에 유의한다.\n' +
      '\n' +
      '### Efficient Decoding\n' +
      '\n' +
      '자기회귀 복호화에 의한 효율성 문제를 완화하기 위해 비자기회귀 복호화 방법이 제안되었다. 토큰을 하나씩 생성하는 대신, 비자동 회귀 방법은 한번에 다수의 토큰을 병렬로 생성한다(Wei et al., 2019; Guo et al., 2020; Ghazvininejad et al., 2019). 이러한 비자동 회귀 방법은 추론 효율의 향상을 가져오고 모델 성능에도 상당한 타격을 준다. 이를 위해, 드래프팅-앤-검증 방법들이 제안되었다(Stern et al., 2018; Xia et al., 2023; Leviathan et al., 2023; Chen et al., 2023). 초안 작성 후 검증 방법은 연속 생성에서 LLM을 피하고 대신 비자동 회귀 병렬 방식으로 초안을 검증하는 데 사용하여 모델 성능을 감소시키지 않고 추론을 크게 가속화한다.\n' +
      '\n' +
      '드래프팅-앤-검증 방법의 핵심은 드래프트를 빠르고 잘 생성하는 것이다. 추론을 가속화하기 위한 목표 모델이 주어지면, 일부 노력은 초안을 효율적으로 생성하기 위해 목표 모델을 사용하기 위해 탐색한다. 블록 와이즈(Stern et al., 2018) 및 메두사(Cai et al., 2024)는 LLMs의 상부에 다수의 여분의 출력 헤드를 추가하고, 다수의 드래프트 토큰을 병렬로 생성하도록 파인-튜닝한다. 병렬 디코딩(Santilli et al., 2023) 및 PaSS(Monea et al., 2023)는 패딩 토큰 또는 학습 가능한 패딩 토큰과 같은 보조 입력 접미사를 추가하여 드래프트 출력 접미사를 생성한다. Lookahead Decoding (Fu et al., 2023)은 Jacobi-iteration을 이용하여 n-gram pool을 생성하고, 마지막으로 생성된 token으로 시작하는 n-gram을 draft로 사용한다. 또한, 추측 디코딩(Xia et al., 2023; Leviathan et al., 2023; Chen et al., 2023)과 같은 몇몇 방법들이 있어서, 드래프트들을 생성하기 위해 타겟 모델보다 작은 모델을 사용한다. 초안 모델을 표적 모델과 추가로 정렬하기 위해, 증류 기술이 적용된다(Miao et al., 2023; Zhou et al., 2023). 심지어 훨씬 더 작은 모델들이 드래프트 모델을 고속화하기 위해 드래프트로서 사용될 수 있어, 다단계 추측 디코딩을 형성한다(Spector and Re, 2023; Chen et al., 2023). 상이한 모델들을 사용하는 것과는 별개로, 자기-추측(Zhang et al., 2023) 및 PPD(Yang et al., 2023)는 모델 계층들의 일부를 초안 모델로 선택한다.\n' +
      '\n' +
      '더 나은 초안 생성 외에도, 전통적인 삼각형 주의 마스킹은 완전한 순방향 패스를 사용하여 하나의 초안 문장만을 검증할 수 있다. 트리 스타일 검증(Miao et al., 2023; Cai et al., 2024)은 특정 어텐션 마스킹을 설계하여 한번에 다수의 가능한 드래프트를 검증하고 가장 긴 매칭된 드래프트를 알아낸다. Lookahead 디코딩(Fu et al., 2023)은 또한 맞춤 어텐션 마스킹을 사용하여 n-그램 자코비-반복 및 드래프트 검증을 병렬로 수행한다.\n' +
      '\n' +
      '### Efficient Implementation\n' +
      '\n' +
      '효율적인 LLM 추론을 달성하기 위한 가장 직접적인 해결책은 (GPU와 같은) 하드웨어 장치를 이용하기 위해 LLM을 효율적으로 구현하는 것이다. 플래시 디코딩(Dao et al., 2023)은 디코딩 시퀀스를 다수의 작은 블록들로 분할하고 GPU HBM 대신에 고속 GPU SRAM에서 블록-와이즈 계산을 수행함으로써 LLM들 내의 트랜스포머 어텐션 계산을 가속화한다. PageAttention(Kwon et al., 2023)은 페이징된 가상 메모리 관리를 사용하여 디코딩 프로세스 동안 디코딩 캐시를 조직함으로써, 추론의 메모리 액세스 오버헤드를 감소시키기 위해 GPU 메모리 대역폭을 효과적으로 활용한다. 텐서 병렬성(Shoeybi et al., 2019)은 분산 GPU에 행렬을 샤딩하고 분산 방식으로 행렬 곱셈을 수행함으로써 추론을 가속화한다. 일부 노력은 기본 운영자(Nvidia, a; Wang et al., 2021; Nvidia, b)를 최적화하여 LLM을 구현하고 유망한 결과를 달성한다.\n' +
      '\n' +
      '### Model Compression\n' +
      '\n' +
      '모델 압축 방법은 모델 실행에 필요한 연산 수를 줄이기 위해 제안된다. 구조 프루닝(Fan et al., 2020; Wang et al., 2020; Zhang et al., 2021; Xia et al., 2022) 및 비구조 프루닝(Han et al., 2015; Chen et al., 2020; Xu et al., 2021) 기후 비필수 파라미터. 양자화(Zafrir et al., 2019; Frantar et al., 2023; Lin et al., 2023; Kim et al., 2023; Stock et al., 2021) 방법들은 파라미터들을 저비트 표현들로 양자화한다. 조기-exiting(Elbayad et al., 2019; Bae et al., 2023) 방법들은 얕은 층들에서의 출력 결과가 신뢰 임계값에 도달할 때 추론 프로세스를 종료한다. MoEfication(Zhang et al., 2022; Song et al., 2023)은 밀집된 모델을 희소 활성화된 모델로 전환한다.\n' +
      '\n' +
      '##5 결론, 한계 및 향후 작업\n' +
      '\n' +
      '본 논문에서는 양방향 가속 전략인 Ouroboros 알고리즘을 제안한다. 우리는 더 빠른 대형 모델 생성을 위해 더 작은 모델의 드래프팅을 가속화하고, 효과적인 드래프팅을 위한 영감을 제공하기 위해 대형 모델을 사용한다. 실험 결과, Ouroboros는 기존 방법(Lookahead Decoding 및 Speculative Decoding)에 비해 \\(1.9\\times\\) 및 \\(2.8\\times\\)의 속도 향상을 달성하는 반면, 모델 학습은 필요하지 않으며, 생성 품질에 전혀 영향을 미치지 않는 것을 확인하였다. 우리는 탐욕스러운 디코딩 시나리오에서만 Ouroboros를 구현하고 테스트하지만 Ouroboros는 랜덤 샘플링을 쉽게 지원할 수 있으므로 향후 작업으로 남아 있다. 실험에서는 디코더 전용 모델 구조에만 초점을 맞춘다. 그러나 Ouroboros는 확장 가능한 프레임워크로 다양한 모델 구조에 적용할 수 있으며 메두사와 같은 기존 알고리즘과 결합할 수 있다.\n' +
      '\n' +
      '## Acknowledgements\n' +
      '\n' +
      '이 작업은 ModelBest & OpenBMB에 의해 지원됩니다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* O. A. Abadi, S. L. 애거월 Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. 알트만 Anadkat, et al. (2023)Gpt-4 기술 보고서. ArXiv:2303.08774. 인용: SS1.\n' +
      '* J. Austin, A. Odena, M. 나명 보즈마, H. 미칼레우스키, D. 다한, E. 장, C. 카이, M. 테리, Q Le, et al. (2021)Program synthesis with large language models. ArXiv:2108.07732. 인용: SS1.\n' +
      '* S. 배종고, 송희선, 그리고 S 윤(2023) 동기화된 병렬 디코딩을 갖는 자기회귀 언어 모델들을 위한 빠르고 강력한 조기-출구 프레임워크. EMNLP의 Proceedings, Cited by: SS1.\n' +
      '*X. 비덕천 천덕천 대청동 동규 부주영 Fu, et al.(2024)DeepSeek llm: scaling open-source language models with longtermism. ArXiv:2401.02954. 인용: SS1.\n' +
      '* O. r. 보야르, R. 채터지, 페더만, Y 그레이엄, B 해도우, M. Huck, A. Jimeno Yepes, P. Koehn, V. 로가체바, C. 몬즈, M. 네그리 A. 네벌 니브스 포펠 포스트, R. 루비노, C. 스카튼, L 종, M. 투치경 Verspoor, M. 잠피에리(2016) 기계 번역에 관한 2016년 컨퍼런스의 결과. In Proceedings of the First Conference on Machine Translation, pp. 131-198. Cited by: SS1.\n' +
      '*T. 채영 이종욱 Geng, H. Peng, J. D. Lee, D. Chen, and T. Dao(2024)STDIN 추론 가속 프레임워크는 다수의 디코딩 헤드를 갖는다. ArXiv:2401.10774. 인용: SS1.\n' +
      '*C. 첸, S. 보르헤오, G. 어빙, J. 레스파우, L. Sifre, and J. Jumper (2023) Accelerating large language model decoding with speculation sampling. ArXiv:2302.01318. 인용: SS1.\n' +
      '* M. 천진욱 Wuan, H. P. D. O. Pinto, J. Kaplan, H. Edwards, Y. 부르다 Joseph, G. Brockman, et al.(2021)Evalating large language models trained on code. ArXiv:2107.03374. 인용: SS1.\n' +
      '*T. 천재홍 장승 유영 장장 왕, M. Carbin(2020) 사전 훈련된 버트 네트워크에 대한 복권 가설. In Proceedings of NeurIPS, pp. 15834-15846. Cited by: SS1.\n' +
      '*Z. 천진 Yang, J. Lin, C. Sun, J. Huang, and K. C. Chang(2021) Cascade speculative drafting for the faster llm inference. ArXiv:2312.11462. 인용: SS1.\n' +
      '*K. 코비, V 고사라주 바이에른 M. 천현준 카이저 플래퍼트, J 트워렉, J 힐튼, R. Nakano, C. Hesse, and J. Schulman (2021)Training verifiers to solve math word problems. ArXiv:2110.14168. 인용: SS1.\n' +
      '*T. Dao, D. Haziza, F. Massa, and G. Sizov(2023)Flash-decoding for long-context inference. 인용: SS1.\n' +
      '* D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter, A. Wahid, J. Tompson, Q. Vuong, et al. (2023)Palm-e: embodied multimodal language model. ArXiv:2303.03378. 인용: SS1.\n' +
      '* M. 엘바야드, J. 구, E. 그레이브, M. Auli(2019)Depth-adaptive transformer. ICLR의 Proceedings, Cited by: SS1.\n' +
      '* A. Fan, E. Grave, 및 A. Joulin(2020) 구조화된 드롭아웃으로 온 디맨드 변압기 깊이를 감소시키는 단계. ICLR의 Proceedings, Cited by: SS1.\n' +
      '* E. Frantar, S. 애쉬부스, T Hoefler, and D. Aistarh (2023)Gptq: exact quantization for generatingative pre-trained transformer. ICLR의 Proceedings, Cited by: SS1.\n' +
      '*Y. Fu, P. Bailis, I. Stoica, and H. Zhang(2023)Breaking the sequential dependency of llm inference using lookahead decoding. 참고: 번호 2023-11-21-lookahead-decoding by 인용: SS1.\n' +
      '* M. 가즈비닌자드, 오. 리비 류, L. Zettlemoyer (2019)Mask-predict: 조건부 마스킹 언어 모델의 병렬 디코딩. ArXiv:1904.09324. 인용: SS1.\n' +
      '* J. Guo, L. Xu, 및 E. Chen(2020)은 비-자기회귀 신경망 기계 번역을 위한 시퀀스-대-시퀀스 모델을 공동으로 마스킹하였다. In Proceedings of ACL, pp. 376-385. Cited by: SS1.\n' +
      '* S. 한, J. Pool, J. Tran, and W. J. Dally (2015)는 효율적인 신경망을 위해 가중치와 연결 모두를 학습한다. In Proceedings of NeurIPS, pp. 1135-1143. Cited by: SS1.\n' +
      '* K. M. Hermann, T. 코시스키, E. 그레펜스테트, L. W. 에스페홀트 계민 Suleyman, 그리고 P. Blunsom (2015)은 읽고 이해하는 기계를 가르친다. In Proceedings of NeurIPS, pp. 1693-1701. Cited by: SS1.\n' +
      '* S. 김찬호퍼 A. Gholami Z. 동진 이성 신명우 마호니, 그리고 K. Keutzer(2023)SqueezeLLM: dense-and-sparse quantization. ArXiv:2306.07629. 인용: SS1.\n' +
      '* J. K. K. Hermann, T. 코시스키, E. 그레펜스테트, L. W. 에스페홀트 계민 Suleyman, 그리고 P. Blunsom (2015)은 읽고 이해하는 기계를 가르친다. In Proceedings of NeurIPS, pp. 1693-1701. Cited by: SS1.\n' +
      '* J. K. Hermann, T. 코시스키, E. 그레펜스테트, L. W. 에스페홀트 계민 Suleyman, 그리고 P. Blunsom (2015)은 읽고 이해하는 기계를 가르친다. In Proceedings of NeurIPS, pp.\n' +
      '\n' +
      '* Kwon et al. (2023) Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C. H., Gonzalez, J. E., Zhang, H., and Stoica, I. pagedattention으로 서빙하는 대형 언어 모델에 대한 효율적인 메모리 관리. In _Proceedings of SOSP_, 2023.\n' +
      '* Leviathan et al. (2023) Leviathan, Y., Kalman, M., and Matias, Y. 추측 디코딩을 통한 변압기로부터의 빠른 추론. In _Proceedings of ICML_, pp. 19274-19286, 2023.\n' +
      '* Lewkowycz et al. (2022) Lewkowycz et al. (2022) Lewkowycz, A., Andreassen, A., Dohan, D., Dyer, E., Michalewski, H., Ramaseh, V., Slone, A., Anil, C., Schlag, I., Gutman-Solo, T., et al. arXiv preprint arXiv:2206.14858_, 2022.\n' +
      '* Lin et al. (2023) Lin, J., Tang, J., Tang, H., Yang, S., Dang, X., and Han, S. Awq: llm 압축 및 가속을 위한 활성화 인식 가중치 양자화. _ arXiv preprint arXiv:2306.00978_, 2023.\n' +
      '* Miao et al. (2023) Miao, X., Oliaro, G., Zhang, Z., Cheng, X., Wang, Z., Wong, R. Y. Y., Chen, Z., Arfeen, D., Abhyankar, R., and Jia, Z. 시편: 추측 추론 및 토큰 트리 검증과 함께 서빙하는 생성 llm 가속. _ arXiv preprint arXiv:2305.09781_, 2023.\n' +
      '* Monea et al. (2021) Monea, G., Joulin, A., and Grave, E. Pass: Parallel speculative sampling _ arXiv preprint arXiv:2311.13581_, 2023.\n' +
      '* Nakano et al. (2021) Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., et al. Webgpt: Browser-assisted question- answerering with human feedback. _ arXiv preprint arXiv:2112.09332_, 2021.\n' +
      '* Nvidia(2021) Nvidia. Fastertransformer, a. URL[https://github.com/NVIDIA/FasterTransformer](https://github.com/NVIDIA/FasterTransformer).\n' +
      '* Nvidia(2021) Nvidia. Tensorrt-llm, b. URL[https://github.com/NVIDIA/TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM).\n' +
      '* OpenAI(2022) OpenAI, T. 채팅: 대화를 위한 언어 모델 최적화. _ 2022년 오픈AI_\n' +
      '* Rasley et al. (2020) Rasley, J., Rajbhandari, S., Ruwase, O., and He, Y. 딥-스피드: 시스템 최적화는 1,000억 개 이상의 파라미터를 갖는 딥 러닝 모델을 트레이닝할 수 있게 한다. In _Proceedings of SIGKDD_, pp. 3505-3506, 2020.\n' +
      '* Roziere et al. (2023) Roziere, B., Gehring, J., Gloeckle, F., Sootla, S., Gat, I., Tan, X. E., Adi, Y., Liu, J., Remez, T., Rapin, J., et al. Code llama: Open foundation models for code. _ arXiv preprint arXiv:2308.12950_, 2023.\n' +
      '* Santilli et al.(2023) Santilli, A., Severino, S., Postolache, E., Maiorca, V., Mancusi, M., Marin, R., and Rodola, E. Accelerating transformer inference for translation via parallel decoding. 2023년\n' +
      '* See et al. (2017) See, A., Liu, P. J., and Manning, C. D. Get to the point: Summarization with pointer-generator networks. In _Proceedings of ACL_, pp. 1073-1083, 2017.\n' +
      '* Shoeybi et al. (2019) Shoeybi, M., Patwary, M., Puri, R., LeGresley, P., Casper, J., and Catanzaro, B. Megatron-lm: training multi-billion parameter language models using model parallelism. _ ArXiv preprint arXiv:1909.08053_, 2019.\n' +
      '* Song et al. (2023) Song, Y., Mi, Z., Xie, H., and Chen, H. Powerinfer: Fast large language model serving with a consumer-grade gpu. _ arXiv preprint arXiv:2312.12456_, 2023.\n' +
      '* Spector & Re(2023) Spector, B. and Re, C. Accelerated llm inference with stage speculative decoding. _ arXiv preprint arXiv:2308.04623_, 2023.\n' +
      '* Stern et al. (2018) Stern, M., Shazeer, N., and Uszkoreit, J. Blockwise parallel decoding for deep autoregressive models. volume 31, 2018.\n' +
      '* Stock et al. (2021) Stock, P., Fan, A., Graham, B., Grave, E., Gribonval, R., Jegou, H., and Joulin, A. Training with quantization noise for extreme model compression. In _Proceedings of ICLR_, 2021.\n' +
      '* Touvron et al. (2023) Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al. Llama 2: Open foundation and fine-tuned chat models. _ arXiv preprint arXiv:2307.09288_, 2023.\n' +
      '* Wang 등(2021) Wang, X., Xiong, Y., Wei, Y., Wang, M., and Li, L. Light-Seq: 변압기를 위한 고성능 추론 라이브러리. In _Proceedings of NAACL_, pp. 113-120, 2021.\n' +
      '* Wang et al. (2020) Wang, Z., Wohlwend, J., and Lei, T. 대형 언어 모델의 구조적 가지치기입니다. In _Proceedings of EMNLP_, pp. 6151-6162, 2020.\n' +
      '* Wei et al. (2019) Wei, B., Wang, M., Zhou, H., Lin, J., Xie, J., and Sun, X. 비-자기회귀 신경망 기계 번역을 위한 모방 학습 _ ArXiv preprint arXiv:1906.02041_, 2019.\n' +
      '* Xia et al.(2023) Xia, H., Ge, T., Wang, P., Chen, S. -Q., Wei, F., and Sui, Z. 추측 디코딩: seq2seq 생성을 가속화하기 위한 추측 실행을 이용하고 있다. In _Proceedings of EMNLP_, pp. 3909-3925, 2023.\n' +
      '* Xia et al. (2022) Xia, M., Zhong, Z., and Chen, D. Structured pruning learning compact and accurate models. In _Proceedings of ACL_, pp. 1513-1528, 2022.\n' +
      '* 사전 훈련 및 미세 조정 패러다임 하에서. In _Proceedings of NAACL_, pp. 2376-2382, 2021.\n' +
      'Yang, S., Lee, G., Cho, J., Papailiopoulos, D., and Lee, K. 예측 파이프라인 디코딩: 정확한 llm 디코딩을 위한 컴퓨트-레이턴시 트레이드 오프 _ arXiv preprint arXiv:2307.05908_, 2023.\n' +
      '* Zafrir et al. (2019) Zafrir, O., Boudoukh, G., Izsak, P., and Wasserblat, M. Q8bert: 양자화된 8bit bert. In _Proceedings of EMC2-NIPS_, pp. 36-39, 2019.\n' +
      '* Zhang et al. (2023) Zhang, J., Wang, J., Li, H., Shou, L., Chen, K., Chen, G., and Mehrotra, S. Draft & verify: self-speculative decoding을 통한 Lossless large language model acceleration. _ arXiv preprint arXiv:2309.08168_, 2023.\n' +
      '* Zhang et al. (2021) Zhang, Z., Qi, F., Liu, Z., Liu, Q., and Sun, M. 네가 필요하지 않은 것을 알아라: 주의 집중을 위한 단일 샷 메타 프루닝. volume 2, pp. 36-42, 2021.\n' +
      '* Zhang et al. (2022) Zhang, Z., Lin, Y., Liu, Z., Li, P., Sun, M., and Zhou, J. MoEfication: Transformer feed-forward layer is mixtures of experts. In _Findings of ACL_, pp. 877-890, 2022.\n' +
      '* Zhou et al. (2023) Zhou, Y., Lyu, K., Rawat, A. S., Menon, A. K., Rostamizadeh, A., Kumar, S., Kagy, J.-F., and Agarwal, R. Distillpec: 지식 증류를 통한 추측 디코딩 개선 arXiv preprint arXiv:2310.08461_, 2023.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:12]\n' +
      '\n' +
      '## Appendix A\n' +
      '\n' +
      '도 7: Ouroboros 대 Ouroboros의 예시. Lookahead Decoding, Speculative Decoding 및 Greedy Decoding. 작은 모델에 의해 파란색 단어가 생성되고, 목표 모델에 의해 검은색 단어가 생성되고, 빨간색 단어가 수락된 후보 접미사가 생성된다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>