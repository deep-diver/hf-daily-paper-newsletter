<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# T-Stitch : 사전 학습된 확산에서의 가속 샘플링\n' +
      '\n' +
      '궤적 스티칭이 있는 모델\n' +
      '\n' +
      'Zizheng Pan\n' +
      '\n' +
      '엔비디아에서 인턴으로 일했어요 1Monash University 2NVIDIA 3University of Wisconsin, Madison 4Caltech. 대응: Bohan Zhuang \\(<\\)bohan.zhuang@gmail.com\\(>\\)\n' +
      '\n' +
      'Bohan Zhuang\n' +
      '\n' +
      'De-An Huang\n' +
      '\n' +
      'Weili Nie\n' +
      '\n' +
      'Zhiding Yu\n' +
      '\n' +
      'Chaowei Xiao\n' +
      '\n' +
      'Jianfei Cai\n' +
      '\n' +
      'Anima Anandkumar\n' +
      '\n' +
      '엔비디아에서 인턴으로 일했어요 1Monash University 2NVIDIA 3University of Wisconsin, Madison 4Caltech. 대응: Bohan Zhuang \\(<\\)bohan.zhuang@gmail.com\\(>\\)\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '확산 확률 모델(DPM)로부터의 샘플링은 종종 고품질 이미지 생성에 비용이 많이 들고 일반적으로 큰 모델을 가진 많은 단계를 필요로 한다. 본 논문에서는 Sampling Trajectory Stitching (**T-Stitch**)을 제안한다. 전체 샘플링 궤적에 큰 DPM만 사용하는 대신 T-스티치는 먼저 초기 단계에서 더 작은 DPM을 더 큰 DPM의 저렴한 드롭인 대체물로 활용하고 나중에 더 큰 DPM으로 전환한다. 우리의 핵심 통찰력은 서로 다른 확산 모델이 동일한 학습 데이터 분포에서 유사한 인코딩을 학습하고 더 작은 모델이 초기 단계에서 좋은 글로벌 구조를 생성할 수 있다는 것이다. 광범위한 실험은 T-스티치가 훈련 없이 다양한 아키텍처에 일반적으로 적용 가능하며 유연한 속도와 품질 절충으로 대부분의 기존 고속 샘플링 기술을 보완한다는 것을 보여준다. 예를 들어, DiT-XL에서 초기 타임스테프의 40%는 클래스 조건 이미지넷 생성에서 성능 저하 없이 10배 더 빠른 DiT-S로 안전하게 대체될 수 있다. 또한, 본 논문에서 제안한 방법은 널리 사용되는 사전 훈련된 안정 확산 모델을 가속화할 뿐만 아니라 대중 모델 동물원에서 양식화된 SD 모델의 신속한 정렬을 향상시키기 위한 드롭인 기법으로 사용될 수 있음을 보인다. 코드는 [https://github.com/NVlabs/T-Stitch](https://github.com/NVlabs/T-Stitch)에서 해제된다.\n' +
      '\n' +
      '머신러닝, ICML\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '확산 확률 모델(DPM)(Ho et al., 2020)은 텍스트 대 이미지 생성(Rombach et al., 2022), 오디오 합성(Kong et al., 2021) 및 3D 생성(Poole et al., 2023) 등과 같은 다양한 실제 응용들 사이에서 고품질 데이터를 생성하는 데 현저한 성공을 입증했다. 그러나 높은 생성 품질을 달성하는 것은 일반적으로 수백 개의 잡음 제거 단계를 포함하는 큰 DPM에서 샘플링해야 하기 때문에 비용이 많이 들며, 이들 각각은 높은 계산 비용을 필요로 한다. 예를 들어, 고성능 RTX 3090을 사용하더라도 DiT-XL(Peebles and Xie, 2022)로 8개의 이미지를 생성하는 것은 100개의 노이즈 제거 단계로 16.5초가 소요되며, 이는 더 낮은 생성 품질을 가진 작은 대응물 DiT-S(1.7s)보다 느리다.\n' +
      '\n' +
      '최근의 연구들은 두 가지 방법으로 DPM의 샘플링을 빠르게 함으로써 추론 효율 문제를 해결한다: (1) 단계당 계산 비용을 줄이거나 (2) 샘플링 단계의 수를 줄이다. 전자의 접근법은 양자화를 통한 모델 압축(Li et al., 2023) 및 프루닝(Fang et al., 2023)에 의해 행해질 수 있거나, 또는 경량 모델 아키텍처들을 재설계함으로써 행해질 수 있다(Yang et al., 2023; Lee et al., 2023). 두 번째 접근법은 다수의 디노이징 단계들을 더 적은 단계들로 증류함으로써(Salimans and Ho, 2022; Song et al., 2023; Zheng et al., 2023; Luo et al., 2023; Sauer et al., 2023) 또는 미분 방정식 솔버를 개선함으로써(Song et al., 2021; Lu et al., 2022; Zheng et al., 2023). 양방향 모두 큰 DPM의 효율성을 향상시킬 수 있지만, 각 잡음 제거 단계의 계산 비용은 동일하게 유지된다고 가정하며, 프로세스 전반에 걸쳐 단일 모델이 사용된다. _ 그러나 우리는 노이즈 제거 프로세스의 서로 다른 단계가 상당히 뚜렷한 특성을 나타내며 전체적으로 동일한 모델을 사용하는 것이 효율성을 위한 차선책 전략임을 관찰한다._\n' +
      '\n' +
      '**Our Approach.** in this work, we propose _Trajectory Stitching_(**T-Stitch**), the simple but effective strategy to improve the efficiency of DPMs having complement existing efficient sampling methods by dynamic allocation computation using different denoising steps. _ 우리의 핵심 아이디어는 이전 작업에서와 같이 모든 단계에서 동일한 모델을 사용하는 대신 다른 노이즈 제거 단계에서 다른 크기의 DPM을 적용하는 것이다._ 먼저 초기 디노이징 단계에서 더 작은 DPM을 적용하고 이후 디노이징 단계에서 더 큰 DPM으로 전환함으로써 생성 품질을 희생시키지 않으면서 전체 계산 비용을 줄일 수 있음을 보여준다. 그림 1은 DiT-S가 DiT-XL보다 계산적으로 훨씬 저렴한 두 가지 DiT 모델(DiT-S 및 DiT-XL)을 사용한 접근법의 예를 보여준다. T-stitch에서 DiT-XL 대신 DiT-S로부터 스텝의 비율이 증가함에 따라, 우리는 추론 속도를 계속 증가시킬 수 있다. 실험 결과, 초기 40%의 단계들이 DiT-S를 사용하더라도 FID에서 생성 품질의 저하가 없으며, 이는 약 1.5\\(\\times\\)_lossless_ speedup으로 이어진다.\n' +
      '\n' +
      '우리의 방법은 두 가지 핵심 통찰력을 기반으로 한다: (1) 최근 작업은 동일한 데이터 분포에 대해 훈련된 서로 다른 DPM에 걸쳐 공통 잠재 공간을 제안한다(Song et al., 2021b; Roeder et al., 2021). 따라서, 상이한 DPM은 유사한 샘플링 궤적을 공유하는 경향이 있으며, 이는 상이한 모델 크기 및 심지어 아키텍처에 걸쳐 스티칭하는 것을 가능하게 한다. (2) 주파수 관점에서, 잡음 제거 프로세스는 초기 단계들에서 저주파 성분들을 생성하는 것에 초점을 맞추고, 이후 단계들은 고주파 신호들을 타겟팅한다(Yang et al., 2023). 소형 모델은 고주파 디테일에 대해 효과적이지 않지만, 초기에는 여전히 좋은 글로벌 구조를 생성할 수 있다.\n' +
      '\n' +
      '종합적인 실험을 통해 T-스티치가 생성 품질의 큰 손실 없이 대규모 DPM을 실질적으로 가속화한다는 것을 입증한다. 이 관찰은 아키텍처 및 확산 모델 샘플러의 스펙트럼에 걸쳐 일관적이다. 이는 또한 T-Stitch가 임의의 재-트레이닝 없이 널리 사용되는 대형 DPM들에 직접 적용될 수 있음을 의미한다(_e.g._, Stable Diffusion (SD)) (Rombach et al., 2022). 도 2는 상대적으로 더 작은 사전 훈련된 SD 모델로 스타일화된 Stable Diffusion을 고속화한 결과를 나타낸다(Kim et al., 2023). 놀랍게도, 우리는 T-스티치가 속도를 향상시킬 뿐만 아니라 스타일화된 모델에 대한 프롬프트 정렬을 개선한다는 것을 발견했다. 이는 양식화된 모델들(_e.g._, ghibli, inkpunk)의 미세 조정 프로세스가 그들의 신속한 정렬을 저하시키기 때문일 수 있다. T-스티치는 이미지를 스타일화하는 데 특화된 대형 SD 모델에 대한 신속한 정렬을 보완하기 위해 소형 SD 모델을 결합하여 효율성과 생성 품질을 모두 개선한다.\n' +
      '\n' +
      'T-Stitch는 기존의 고속 샘플링 접근법에 대해 _complementary_라는 점에 유의한다. 큰 DPM에 의해 취해지는 궤적의 부분은 여전히 그것에 의해 취해지는 단계들의 수를 감소시키거나, 또는 압축 기술들로 그것의 계산 비용을 감소시킴으로써 가속될 수 있다. 또한, T-Stitch는 재학습의 오버헤드 없이 품질 효율성 절충안을 효과적으로 개선할 수 있지만, 궤적 스케줄이 주어진 스티칭된 DPM을 미세 조정하면 T-Stitch의 생성 품질이 더욱 향상될 수 있음을 보여준다(A.12절). 적용되는 타임스텝에서만 대형 DPM을 미세 조정함으로써, 대형 DPM은 고주파 디테일을 제공하는 데 더 잘 전문화되고 발전 품질을 더욱 향상시킬 수 있다. 또한, 우리는\n' +
      '\n' +
      '도 1: DDIM 100 타임스텝 및 분류기 없는 안내 척도 1.5에 기초하여, 초기에 더 많은 DiT-S 스텝들을 점진적으로 스티칭하고 마지막에 더 적은 DiT-XL 스텝들을 스티칭할 때 클래스-조건부 이미지넷 상의 **Top:** FID 비교 5000개의 이미지들을 샘플링함으로써 FID가 계산된다. **Bottom:** 더 빠른 샘플링을 달성하기 위해 더 많은 DiT-S 단계들을 스티칭하는 일례로서, 여기서 시간 비용은 하나의 RTX 3090 상에서 초(들) 단위로 8개의 이미지들을 생성함으로써 측정된다.\n' +
      '\n' +
      '도 2: 모델 동물원에서 작은 SD를 직접 채택함으로써, T-스티치는 큰 스타일 SD로 속도, 스타일 및 이미지 콘텐츠를 자연스럽게 보간하며, 이는 또한 위의 예들에서 프롬프트 정렬, _예를 들어, "뉴욕시" 및 "열대 해변"을 잠재적으로 개선한다.\n' +
      '\n' +
      'T-Stitch에 의해 생성된 트레이닝-프리 파레토 프론티어는 모델 스티칭을 통해 신경망 모델들 간의 보간을 위해 설계된 트레이닝-기반 방법들에 대한 품질-효율 트레이드-오프를 개선한다(Pan et al., 2023a,b). T-스티치는 단지 두 개의 모델 사이즈에만 한정되는 것은 아니며, 상이한 DPM 아키텍처에도 적용가능하다는 점에 유의한다.\n' +
      '\n' +
      '우리의 주요 기여도를 다음과 같이 요약한다.\n' +
      '\n' +
      '* 초기 디노이징 단계에서는 작은 DPM을 적용하고 이후 단계에서는 큰 DPM을 적용하여 DPM의 추론 속도를 향상시키기 위한 간단하면서도 매우 효과적인 접근 방법인 T-Stitch를 제안한다. 재교육 없이 우리는 개별 대형 DPM보다 더 나은 속도와 품질 절충을 달성하고 사소한 손실 없는 속도 향상도 달성합니다.\n' +
      '* 우리는 우리의 방법이 일반적으로 다른 모델 아키텍처 및 샘플러에 적용 가능하고 기존의 고속 샘플링 기술에 상보적이라는 것을 입증하기 위해 광범위한 실험을 수행한다.\n' +
      '* 특히, 재-트레이닝 오버헤드 없이, T-스티치는 실제 애플리케이션에서 널리 사용되는 안정한 확산 모델을 가속화할 뿐만 아니라 텍스트-이미지 생성을 위한 스타일화된 SD 모델의 신속한 정렬을 향상시킨다.\n' +
      '\n' +
      '##2 관련 작품\n' +
      '\n' +
      '**효율적인 확산 모델.** 성공에도 불구하고, DPM은 수백 개의 타임스텝과 대형 데노이저(_e.g_., U-Net)로 인해 느린 샘플링 속도(Rombach et al., 2022; Ho et al., 2020)로 인해 어려움을 겪고 있다. 샘플링 프로세스를 신속하게 하기 위해, 프루닝(Fang et al., 2023) 및 양자화(Shang et al., 2023; Li et al., 2023b)와 같은 확산 모델들에 네트워크 압축 기법들을 직접 이용함으로써 일부 노력들이 이루어졌다. 한편, 많은 연구는 증류(Salimans and Ho, 2022; Zheng et al., 2023; Song et al., 2023; Luo et al., 2023; Sauer et al., 2023), 암시적 샘플러(Song et al., 2021a) 및 개선된 미분 방정식(DE) 솔버(Lu et al., 2022; Song et al., 2021b; Jolicoeur-Martineau et al., 2021; Liu et al., 2022)에 의해 달성될 수 있는 샘플링 단계를 감소시키기 위해 모색하고 있다. 또 다른 작업 라인은 병렬 샘플링에 의한 샘플링을 가속화하는 것도 고려한다. 예를 들어, (Zheng et al., 2023)은 모든 단계를 동시에 예측하기 위해 연산자 학습을 활용하도록 제안하였다. (Shih et al., 2023)은 ParaDiGMS를 제안하여 다중 타임스텝에서의 드리프트를 병렬적으로 계산하였다. 위의 방법들에 대한 보완적인 기술로서, 제안된 궤적 스티칭은 초기 잡음 제거 단계에서 미리 훈련된 작은 DPM을 활용하여 큰 DPM 샘플링을 가속화하는 반면, 이후 단계에서는 큰 DPM을 위한 충분한 공간을 남긴다.\n' +
      '\n' +
      '**확산 모델의 다수의 전문가.** 이전의 관찰은 DPM들에서의 합성 행동이 상이한 타임스탬프들에서 변할 수 있다는 것을 밝혀냈으며(Balaji et al., 2022; Yang et al., 2023), 이는 일부 작업들이 더 나은 성능을 위해 상이한 타임스탬프들에서 전문가들의 앙상블을 제안하도록 영감을 주었다. 예를 들어, (Balaji et al., 2022)는 상이한 잡음 제거 간격으로 전문가 잡음 제거자 앙상블을 훈련시켰다. 그러나, 다수의 큰 데누아들을 할당하는 것은 모델 파라미터들을 선형적으로 증가시키고 계산 비용을 감소시키지 않는다. (Yang et al., 2023)은 웨이브렛 변환을 위한 게이팅 메커니즘을 디노이저에 통합하여 주파수 역학을 서로 다른 단계에서 제어하는 lit latent diffusion 모델(_i.e_., LDM)을 제안했는데, 이는 주파수 전문가의 앙상블이라고 볼 수 있다. 동일한 정신에 따라, (Lee et al., 2023)은 각각의 주파수 범위에 특화시키기 위해 상이한 잡음 제거 간격으로 상이한 작은 잡음제거기를 할당하였다. 그럼에도 불구하고 대부분의 기존 작업은 모든 타임스텝에 걸쳐 동일한 크기의 모델을 채택하며, 이는 서로 다른 크기의 모델 간의 속도와 품질 균형을 거의 고려하지 않는다. 대조적으로, 우리는 작은 DPM과 큰 DPM 사이의 유연한 트레이드 오프를 탐색하고 초기 노이즈 제거 단계가 훨씬 효율적인 작은 DPM에 의해 충분히 처리될 수 있음을 보여준다.\n' +
      '\n' +
      '**스티치 가능한 신경망.**스티치 가능한 신경망(SN-Net)(Pan et al., 2023a)은 모델 스티칭(Lenc and Vedaldi, 2015; Bansal et al., 2021; Csiszarik et al., 2021; Yang et al., 2022)의 아이디어에 의해 동기화되고, 여기서 미리 트레이닝된 모델 패밀리 내의 상이한 스케일의 미리 트레이닝된 모델들은 상당한 성능 저하 없이 간단한 스티칭 층들(_i.e_., 1 \\(\\times\\) 1 convs)과 함께 분할 및 스티칭될 수 있다. 인사이트를 기반으로 SN-Net은 크기가 다른 모델들 사이에 몇 개의 스티칭 레이어를 삽입하고, 속도-성능 트레이드오프가 다른 수많은 네트워크(_i.e_, 스티치)를 얻기 위해 조인트 트레이닝을 적용한다. SN-Netv2(Pan et al., 2023b)의 다음 작업은 그 공간을 확대하고 다운스트림 밀집 예측 작업에 대한 효과를 입증한다. 본 논문에서는 SN-Netv2와 제안한 기법을 비교하여 DPM의 속도 및 품질 절충 측면에서 모델 스티칭에 비해 궤적 스티칭의 장점을 보인다. 당사의 T-스티치는 더 좋고 간단하며 일반적인 솔루션입니다.\n' +
      '\n' +
      '## 3 Method\n' +
      '\n' +
      '### Preliminary\n' +
      '\n' +
      '**확산 모델.** 우리는 연속 시간 내에 스코어 기반 확산 모델의 클래스를 고려한다(Song et al., 2021b). 그리고 Karras et al., 2022). [\\(p_{data}(\\mathbf{x}_{0})\\)는 데이터 분포를 나타내고 \\(\\sigma(t)\\colon[0,1]\\to\\mathbb{R}_{+}\\)는 사용자가 지정한 잡음 레벨 스케줄로 \\(t\\in\\{0,...,T\\}\\)과 \\(\\sigma(t-1)<\\sigma(t)\\)을 나타낸다. \\(\\mathbf{x};\\sigma)\\)는 \\(\\sigma^{2}\\)-분산 가우시안 잡음을 주입하여 잡음이 제거된 샘플의 분포를 나타낸다. 확산모델은 고분산 가우시안 잡음\\(\\mathbf{x}_{T}\\)을 시작으로 점차 디노이즈\\(\\mathbf{x}_{T}\\(\\mathbf{x}_{T-1},\\mathbf{x}_{T-2},...,\\mathbf{x}_{0}\\}\\)을 적은 잡음 샘플로 변환하며, 여기서 \\(\\mathbf{x}_{t}\\sim p(\\mathbf{x}_{t;\\sigma(t))\\)를 갖는다. 또한, 이 반복 과정은 데이터에 대한 로그 확률 밀도의 기울기인 점수\\(\\nabla_{x}\\log p_{t}(x)\\)를 알면 확률 흐름 상미분 방정식(ODE)을 풀어서 수행할 수 있다.\n' +
      '\n' +
      '\\[d\\mathbf{x}=-\\hat{\\sigma}(t)\\sigma(t)\\nabla_{\\mathbf{x}}\\log p(\\mathbf{x}; \\sigma(t))\\,dt,\\tag{1}\\t\n' +
      '\n' +
      '여기서 \\(\\hat{\\sigma}(t)\\)는 \\(\\sigma(t)\\)의 시간미분을 나타낸다. 기본적으로 확산 모델은 점수 함수에 대한 모델을 학습하는 것을 목표로 하며, 이는 다음과 같이 재매개변수화될 수 있다.\n' +
      '\n' +
      '\\[\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x})\\approx(D_{\\theta}(\\mathbf{x}; \\sigma)-\\mathbf{x})/\\sigma^{2}, \\tag{2}\\\n' +
      '\n' +
      '여기서 \\(D_{\\theta}(\\mathbf{x};\\sigma)\\)는 학습 가능한 디노이저이다. 잡음 데이터 포인트\\(\\mathbf{x}_{0}+\\mathbf{n}\\)와 컨디셔닝 신호\\(\\mathbf{c}\\)이 주어지면, 여기서 \\(\\mathbf{n}\\sim\\mathcal{N}\\left(\\mathbf{0},\\sigma^{2}\\mathbf{I}\\right)\\)는 깨끗한 데이터\\(\\mathbf{x}_{0}\\)을 예측하는 것을 목표로 한다. 실제로, 모드는 잡음 제거 점수 매칭의 손실을 최소화함으로써 트레이닝되고,\n' +
      '\n' +
      '\\mathbb{E}_{(\\mathbf{x}_{0},\\mathbf{c})\\sim p_{\\text{data},}(\\sigma,\\mathbf{n})}\\sim p(\\sigma,\\mathbf{n})}\\left[\\lambda_{\\sigma}\\|D_{\\mathbf{\\theta}(\\mathbf{x}_{0}+\\mathbf{n};\\sigma,\\mathbf{c})-\\mathbf{x}_{0}\\|_{2}^{2}\\right], \\tag{3}\\tag{3}\\tag{n}\\left[\\lambda_{\\sigma}\\sigma}\\|D_{\\mathbf{\\theta}(\\mathbf{x}_{0}+\\mathbf{n};\\sigma,\\mathbf{c})-\\mathbf{x}_{0}\\|_{2}^{2}\\right],\n' +
      '\n' +
      '여기서 \\(\\lambda_{\\sigma}\\colon\\mathbbb{R}_{+}\\to\\mathbb{R}_{+}\\)는 가중치 함수(Ho et al., 2020), \\(p(\\sigma,\\mathbf{n})=p(\\sigma)\\,\\mathcal{N}\\left(\\mathbf{n};\\mathbf{0},\\sigma ^{2}\\right)\\), \\(p(\\sigma)\\)는 잡음 레벨 \\(\\sigma\\)에 대한 분포이다.\n' +
      '\n' +
      '이 연구는 확산모델에서 데누아저(D\\)에 초점을 맞춘다. 일반적인 관행에서, 이들은 일반적으로 각각의 타임스텝에서 높은 FLOP를 소비하는 상이한 아키텍처를 갖는 큰 파라미터화된 신경 네트워크이다. 이하에서는 이 네트워크를 지칭하기 위해 "디노이저" 또는 "모델"을 혼용하여 사용한다. 우리는 효율성 증가에 대한 궤적 스티칭의 이점을 탐색하기 위해 사전 훈련된 DiT 모델 패밀리로 시작한다. 그런 다음 U-Net(Rombach et al., 2022) 및 U-ViT(Bao et al., 2023)와 같은 다른 아키텍처에 대한 일반적인 기술임을 보인다.\n' +
      '\n' +
      '**분류자 없는 안내.**컨디셔닝 안내를 제공하기 위해 추가적인 네트워크가 필요한 분류자 기반 데누아저(Dhariwal and Nichol, 2021)와 달리, 분류자 없는 안내(Ho and Salimans, 2022)는 컨디셔닝 신호를 널 임베딩으로 대체하여 하나의 네트워크에서 조건부 모델과 무조건 모델을 공동으로 훈련시키는 기술이다. 샘플 생성 동안 조건 모델과 무조건 모델 모두의 예측을 공동으로 고려하여 샘플이 컨디셔닝 신호와 더 정렬되도록 유도하기 위해 유도 스케일 \\(s\\geq 0\\)을 채택하고,\n' +
      '\n' +
      '\\[D^{s}(\\mathbf{x};\\sigma,\\mathbf{c})=(1+s)D(\\mathbf{x};\\sigma,\\mathbf{c})-sD(\\mathbf{x};\\sigma. \\tag{4}\\sigma)\n' +
      '\n' +
      '최근 연구는 분류기 없는 지침이 생성 품질의 명확한 개선을 제공한다는 것을 입증했다. 본 연구에서는 인기도에 따라 분류기 없는 안내로 학습된 확산 모델을 고려한다.\n' +
      '\n' +
      '### Trajectory Stitching\n' +
      '\n' +
      '**왜 다른 사전 훈련된 DPM들은 샘플링 궤적을 따라 직접 스티칭될 수 있는가?** 우선, 동일한 모델 패밀리의 DPM들은 일반적으로 동일한 형태의 잠재 잡음 입력 및 출력을 취한다 (\\(\\mathbf{e.g.}\\), \\(4\\times 32\\times 32\\). 다른 노이즈 제거 단계에서 다른 DPM을 적용할 때 치수 불일치가 없습니다. 더 중요한 것은, (Song et al., 2021)에서 지적된 바와 같이, 동일한 데이터세트 상에서 트레이닝되는 상이한 DPM들은 종종 유사한 잠재 임베딩들을 학습한다. 그림 3과 같이 초기 노이즈 제거 샘플링 단계에서 잠복 잡음에 대해 특히 해당되며, 여기서 다른 DiT 모델의 출력 잠복 잡음 간의 코사인 유사성은 초기 단계에서 거의 100%에 도달한다. 이는 큰 확산 모델의 샘플링 속도를 가속화하기 위해 초기에 미리 훈련된 작은 모델을 활용하는 새로운 단계 수준의 스티칭 전략인 궤적 스티칭(T-Stitch)을 제안하도록 동기를 부여한다.\n' +
      '\n' +
      '** 모델 선택의 원칙.** 그림 4는 다양한 속도 품질 절충에 대해 제안된 T-스티치의 프레임워크를 보여준다. 원칙적으로, 우리가 달성할 수 있는 빠른 속도 또는 최악의 발전 품질은 궤적의 가장 작은 모델에 의해 대략 구속되는 반면, 가장 느린 속도 또는 최상의 발전 품질은 가장 큰 디노이저에 의해 결정된다. 따라서, 우리가 속도를 높이고자 하는 큰 확산 모델을 고려할 때, 우리는 1) 분명히 더 빠른 작은 모델, 2) 충분히 최적화된 작은 모델, 3) 큰 모델과 동일한 데이터 세트에 대해 훈련되거나 적어도 유사한 데이터 분포(\\(\\mathbf{e.g.}\\), 사전 훈련 또는 미세 조정된 안정적인 확산 모델)를 학습한 작은 모델을 선택한다.\n' +
      '\n' +
      '**쌍별 모델 할당.** 기본적으로 T-스티치는 실제로 매우 잘 수행되므로 샘플링 궤적에서 쌍별 데노어를 채택한다. 구체적으로, 먼저 잡음 제거 구간을 궤적에서 샘플링 단계의 범위로 정의하고, 전체 단계 수 \\(T\\)에 대한 비율을 \\(r\\)으로 표시하며, 여기서 \\(r\\in[0,1]\\)이다. 다음으로, 우리는 모델 할당을 계산 예산 할당 문제로 취급한다. 그림 3을 통해 \\(T\\)이 0으로 흐를 때 서로 다른 스케일드 디노이저 사이의 잠재 유사도가 계속 감소하는 것을 관찰할 수 있다. 이를 위해, 할당 전략은 초기 간격에서 값싼 대체품으로 작은 디노이저를 채택하고 이후 간격에서는 큰 디노이저를 적용한다. 특히 작은 데노이저\\(D_{1}\\)와 큰 데노이저\\(D_{2}\\)가 있다고 가정하자. 그리고 나서 첫 번째 \\(\\lfloor r_{1}T\\rceil\\) 단계를, 마지막 \\(\\lfloor r_{2}T\\rceil\\) 단계를 \\(\\lfloor r_{2}T\\rceil\\) 단계로 \\(\\lfloor\\cdot\\rceil\\)은 반올림 연산을 나타내며, \\(r_{2}=1-r_{1}\\)은 반올림 연산을 나타낸다. 우리는 \\(r_{1}\\)을 증가시킴으로써 작은 디노이저와 큰 디노이저 사이의 계산 예산을 자연스럽게 보간하여 유연한 품질과 효율성 절충점을 얻는다. 예를 들어, 그림 1에서 구성 \\(r_{1}=0.5\\)은 10.06 FID 및 \\(1.76\\times\\) 속도 향상을 달성하는 트레이드 오프를 고유하게 정의한다.\n' +
      '\n' +
      '**더 많은 절충안을 위한 더 많은 데누아.** T-스티치가 쌍별 설정에 국한되지 않는다는 점에 유의하십시오. 사실, 우리는 샘플링 궤적에 더 많은 데누아들을 채택하여 더 빠른 속도와 품질의 상충 관계와 더 나은 파레토 프론티어를 얻을 수 있다. 예를 들어, 중간 간격에서 중간 크기의 데노이저를 사용하여 각 데노이저의 분율을 변경하여 더 많은 구성을 얻을 수 있다. 실제로 시간 비용과 같은 계산 예산이 주어지면 섹션 A.1에서 논의한 바와 같이 사전 계산된 룩업 테이블을 통해 이러한 제약을 충족하는 몇 가지 구성을 효율적으로 찾을 수 있다.\n' +
      '\n' +
      '**Remark.** 기존 멀티 전문가 DPM에 비해 T-Stitch는 _prerained_ 모델 패밀리에서 _different size_의 모델을 직접 적용한다. 따라서 계산 예산이 주어지면 훈련 없이 혜택을 받으면서 다른 단계에 걸쳐 다른 리소스를 할당하는 방법을 고려합니다. 또한, 추측 디코딩(Leviathan et al., 2023)은 큰 언어 모델 샘플링을 가속화하기 위해 작은 모델을 활용하는 우리와 유사한 동기를 공유한다. 그러나 이 기술은 자기회귀 모델을 위해 특별히 설계된 반면 확산 모델에 동일한 샘플링 전략을 적용하는 것은 간단하지 않다. 한편, 본 논문에서 제안하는 방법은 DPM의 특성을 이용하여 효과적인 속도 향상을 달성한다.\n' +
      '\n' +
      '## 4 Experiments\n' +
      '\n' +
      '본 절에서는 먼저 편리한 모델 패밀리를 제공하기 때문에 DiT(Peebles and Xie, 2022)를 기반으로 한 T-Stitch의 효과를 보여준다. 그리고 U-Net과 Stable Diffusion 모델로 확장한다. 마지막으로, 우리는 T-스티치가 일반적으로 많은 시나리오에서 적용 가능함을 입증하기 위해 다양한 샘플링 단계와 샘플러로 기술을 축소한다.\n' +
      '\n' +
      '### DiT Experiments\n' +
      '\n' +
      '구현 세부사항.** DiT에 이어, 256\\(\\times\\)256 이미지 및 패치 크기 2에서 사전 훈련된 DiT-S/B/XL을 기반으로 클래스 조건부 이미지넷 실험을 수행한다. 사전 훈련된 모델의 자세한 비교는 표 3에 나와 있다. T-스티치가 훈련되지 않기 때문에 두 모델 설정에 대해 섹션 3.2에 설명된 할당 전략에 따라 모델을 샘플링 궤적에 직접 할당한다. 세 모델 설정에 대해 한 번에 모델당 0.1씩 분율을 증가시켜 가능한 모든 구성 세트를 열거하며, 이는 결국 DiT-S/XL, DiT-S/B, DiT-S/XL 및 세 모델 조합 DiT-S/B/XL의 쌍별 조합을 포함하는 66개의 구성 세트를 생성한다. 기본적으로, 우리는 1.5의 분류기 없는 유도 척도를 채택하는데, 이는 우리의 설정에서 또한 목표 모델인 DiT-XL에 대한 최상의 FID를 달성하기 때문이다.\n' +
      '\n' +
      '**평가 메트릭.** 우리는 다양성과 충실도를 모두 포착함에 따라 전체 샘플 품질을 측정하기 위해 FID(Frechet Inception Distance)(Heusel et al., 2017)를 기본 메트릭으로 채택한다(낮은 값은 더 나은 결과를 나타낸다). 또한, 백본 인셉션 네트워크(Szegedy et al., 2016)가 사전 훈련된 ImageNet에서 견고한 성능 척도로 남아 있기 때문에 인셉션 스코어를 보고한다. 우리는 ADM(Dhariwal and Nichol, 2021)의 참조 배치와 샘플 5,000개의 이미지를 사용하여 FID를 계산한다. 보충 자료에서 우리는 더 많은 이미지(예, 50K)를 샘플링하는 것이 우리의 관찰에 영향을 미치지 않는다는 것을 보여준다. 기본적으로, 시간 비용은 단일 RTX 3090에서 8개의 이미지를 초 단위로 생성함으로써 측정된다.\n' +
      '\n' +
      '**결과.** 미리 훈련된 모델 패밀리를 기반으로 먼저 DiT-XL/S, DiT-XL/B 및 DiT-B/S를 포함한 두 모델 조합으로 T-스티치를 적용한다. 각 설정에 대해 상대적으로 작은 모델로 샘플링 단계를 시작한 다음 큰 모델이 마지막 타임스텝을 처리하도록 한다. 그림 5에서 우리는 다른 조합에 대한 FID 비교를 보고한다. 일반적으로 초기 40-50% 단계에서 더 작은 모델을 사용하면 모든 조합에 대해 약간의 성능 저하가 발생한다는 것을 관찰한다. 게다가, 최고의/최악의 성능은 대략적으로 가장 작고 가장 큰 모델들에 의해 제한된다.\n' +
      '\n' +
      '그림 4: **궤적 스티칭**(T-스티치): 미리 훈련된 소형 및 대형 DPM을 기반으로 초기 노이즈 제거 샘플링 단계에서 백분율이 다른 보다 효율적인 소형 DPM을 활용하여 다양한 속도 품질 절충을 달성할 수 있다.\n' +
      '\n' +
      '도 3: 상이한 DiT 모델들 간의 상이한 잡음 제거 단계들에서 잠재 임베딩들의 유사성 비교. 결과들은 32개의 이미지들에 걸쳐 평균화된다.\n' +
      '\n' +
      '사전 훈련된 모델 패밀리입니다.\n' +
      '\n' +
      '또한, T-Stitch는 중간 노이즈 제거 간격으로 중간 크기의 모델을 채택하여 더 빠른 속도와 품질 절충을 달성할 수 있음을 보여준다. 예를 들어, DiT-S, DiT-B, DiT-XL의 세 가지 다른 크기의 DiT 모델을 기반으로 시작에서 DiT-S로 시작하여 중간 노이즈 제거 간격으로 DiT-B를 사용하고 마지막으로 DiT-XL을 채택하여 미세한 로컬 세부 사항을 그린다. 그림 6은 3-모델 조합이 FID와 인셉션 점수 모두에 대해 부드러운 파레토 프론티어를 효과적으로 획득함을 나타낸다. 특히, 시간비용이 \\(\\sim\\)10s일 때, FID(9.21 vs. 9.19)와 Inception Score(243.82 vs. 245.73)가 비슷한 1.7\\(\\times\\)의 속도향상을 얻을 수 있었다. 우리는 섹션 A.4에서 분류기가 없는 다양한 안내 척도를 사용하는 효과를 보여준다.\n' +
      '\n' +
      '### U-Net Experiments\n' +
      '\n' +
      '이 절에서는 T-Stitch가 데누아르의 건축적 선택과 보완적이라는 것을 보여준다. 우리는 많은 확산 모델에서 널리 채택되어 널리 퍼진 U-Net을 실험한다. 잠재 확산 모델(LDM)로부터 클래스 조건 이미지넷 구현을 채택한다(Rombach et al., 2022). 이를 바탕으로 네트워크 채널 폭을 256에서 64로, 컨텍스트 차원을 512에서 256으로 축소하여 15.8\\(\\times\\)의 작은 LDM-S를 구현하였다. 두 사전 훈련된 모델 간의 자세한 비교는 표 4에 나와 있다.\n' +
      '\n' +
      '**결과.** 표 1의 U-Net을 사용한 T-Stitch에 대한 결과를 보고한다. 일반적으로 DDIM 및 100 타임스텝에서 FID 및 인셉션 점수가 비슷하거나 훨씬 더 우수한 효율적인 LDM-S에 의해 첫 번째 \\(\\sim\\)50% 단계를 수행할 수 있음을 발견했다. 동시에 궤적에서 더 많은 LDM-S 단계를 점진적으로 사용할 때 시간 비용이 대략 선형적으로 감소하는 것을 관찰한다. 전반적으로, U-Net 실험은 우리의 방법이 다양한 디노이저 아키텍처에 적용 가능함을 나타낸다. 우리는 A.16절에서 생성된 이미지 예를 제공하고 T-스티치가 A.10절에서 다른 모델 패밀리에서도 적용될 수 있음을 보여준다.\n' +
      '\n' +
      '### 텍스트 대 이미지 안정 확산\n' +
      '\n' +
      'Diffusers(von Platen et al., 2022)에 대한 공개 모델 동물원의 이점을 통해, 우리는 어떠한 훈련 없이 임의의 큰 사전 훈련되거나 스타일링된 SD 모델의 샘플링 속도를 가속화하기 위해 작은 SD 모델을 직접 채택할 수 있다. 본 절에서는 모델 동물원에서 기존 SD 모델을 가속화하기 위해 T-Stitch를 적용하는 방법을 보여준다. (Kim et al., 2023)의 이전 연구는 원래의 SD v1.4를 가지치기한 다음 지식 증류를 적용하여 크기가 다른 여러 SD 모델을 생성했다. 그런 다음 안정적인 확산 실험을 위해 가장 작은 모델 BK-SDM Tiny를 직접 채택한다. 기본적으로 PNDM(Liu et al., 2022) 샘플러를 사용하여 50단계 미만 7.5의 안내 척도를 사용한다.\n' +
      '\n' +
      '**결과.** 표 2에서 원본 SD v1.4에 T-Stitch를 적용하여 결과를 보고한다. FID 및 Inception Score 외에 텍스트 프롬프트와 이미지의 정렬을 측정하기 위한 CLIP 스코어도 보고한다. 전반적으로, 우리는 더 나은 FID를 달성하면서 인셉션 점수 및 CLIP 점수의 현저한 성능 저하 없이 BK-SDM 타이니가 초기 30% 단계를 수행할 수 있음을 발견했다. 향후 작업에서 더 우수하고 빠른 소형 모델이 더 나은 품질과 효율성 절충을 달성하는 데 도움이 될 수 있다고 믿습니다. 또한, T-Stitch가 다른 대형 SD 모델과 호환된다는 것을 입증한다. 예를 들어, 그림 7과 같이 원래 SD v1.4 아래에서 유사한 이미지 품질을 얻으면서 유망한 속도를 달성한다. 또한 Inkpunk style1과 같은 다른 양식화된 SD 모델을 사용하여 두 모델 간의 자연스러운 스타일 보간을 관찰한다. 더 중요한 것은 일반적인 작은 SD에서 작은 단계의 일부를 채택함으로써 InkPunk Diffusion의 "park"와 같은 프롬프트에 이미지가 더 정렬되는 데 도움이 된다는 것을 발견했다. 이 경우, 우리는 이러한 양식화된 SD에서의 미세조정이 예상외로 신속한 정렬을 손상시킬 수 있다고 가정하며,\n' +
      '\n' +
      '그림 5: DiT-XL/S, DiT-XL/B 및 DiT-B/S의 두 모델 조합의 T-스티치. 분류기 없는 유도 척도가 1.5인 DDIM 100 타임스테프를 채택한다.\n' +
      '\n' +
      '그림 6: DiT-S, DiT-B 및 DiT-XL의 세 가지 모델을 기반으로 한 T-스티치. 분류기 없는 1.5의 유도 척도로 DDIM 100 타임스테프를 채택하였으며, 파레토 프론티어를 라인 단위로 강조한다.\n' +
      '\n' +
      '일반적인 사전 훈련된 SD의 지식을 채택하는 동안 초기 글로벌 구조 생성을 보완할 수 있다. 전반적으로, 이것은 T-스티치의 또 다른 실용적인 사용을 강력하게 지원한다: _빠른 스케치 및 보다 신속한 정렬을 위해 초기에 작은 일반 전문가를 사용하는 반면 세부 사항을 인내심 있게 설명하기 위해 다음 단계에서 양식화된 SD를 허용한다._ 또한 T-스티치가 섹션 A.11의 ControlNet, SDXL, LCM과 호환됨을 보여준다.\n' +
      '\n' +
      '### Ablation Study\n' +
      '\n' +
      '** 단계가 다른 T-스티치의 효과.** 샘플링 단계의 수에 대한 효율성 증가를 조사하기 위해 DDIM 및 DiT-S/XL을 기반으로 실험을 수행한다. 그림 9와 같이 T-Stitch는 서로 다른 스텝 수와 확산 모델 샘플러를 사용할 때 일관된 효율 이득을 얻는다. 특히, 큰 성능 저하 없이 DiT-S가 40%의 초기 단계를 안전하게 수행할 수 있음을 발견했다. 이것은 작은 DPM이 주로 저주파 성분을 생성하는 초기 잡음 제거 단계를 충분히 처리할 수 있음을 나타낸다. 따라서 미세 로컬 디테일의 고주파 발생을 보다 유능한 DiT-XL에 맡길 수 있다. 이것은 그림 17의 생성 예에 의해 추가로 입증되며, 여기서 우리는 다양한 총 단계 수에 걸쳐 DiT-S 단계의 모든 분획에서 샘플링된 이미지를 제공한다. 전반적으로, 우리는 T-스티치가 경쟁적이지 않고 샘플링 단계를 줄이는 데 중점을 둔 다른 빠른 확산 접근법을 보완하고 있음을 보여준다.\n' +
      '\n' +
      '**다른 샘플러를 가진 T-Stitch의 효과.** 여기서 우리는 T-Stitch가 더 적은 타임스텝에서 더 나은 생성 품질을 달성하기 위해 고급 샘플러(Lu et al., 2022)와도 호환된다는 것을 보여준다. 이를 위해 DDPM(Ho et al., 2020), DDIM(Song et al., 2021) 및 DPM-Solver++(Lu et al., 2022)와 같은 직교 기법을 사용하여 T-Stitch의 효과를 입증하기 위해 널리 사용되는 샘플러를 실험한다. 그림 8에서 DiT-S를 사용하여 다양한 샘플러 및 단계에서 DiT-XL의 초기 단계를 점진적으로 대체한다. 일반적으로 초기 샘플링 단계에서 일관된 효율성 이득을 관찰하며, 이는 우리의 방법이 DPM 샘플링을 가속화하기 위한 기존 샘플러와의 보완 솔루션임을 강력하게 정당화한다.\n' +
      '\n' +
      'T-Stitch vs. SN-Net과 같은 모델 스티칭.** 이전 작업들(Pan et al., 2023;b)은 상이한 복잡도 및 성능 트레이드-오프를 갖는 수많은 _architectures_를 획득하기 위한 모델 스티칭의 파워를 입증했다. 따라서 이러한 아키텍처 중 하나를 샘플링을 위한 데노이저로 채택함으로써 SN-Net은 자연스럽게 유연한 품질과 효율성 절충을 달성한다. Pareto 프론티어에서 T-Stitch의 장점을 보이기 위해 SN-Netv2(Pan et al., 2023)에서 제안한 모델 스티칭의 프레임워크와 비교하기 위한 실험을 수행한다. 우리는 섹션 A.8에서 구현 세부 사항을 제공한다. 그림 10에서 T-스티치를 DDIM 샘플러와 100단계를 기반으로 한 모델 스티치와 비교한다. 전반적으로 두 방법 모두 유연한 속도와 품질 절충을 얻을 수 있지만 T-스티치는 분명히 더 나은 이점을 달성한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c c c c c c c c} Fraction of LDM-S & 0\\% & 10\\% & 20\\% & 30\\% & 40\\% & 50\\% & 60\\% & 70\\% & 80\\% & 90\\% & 100\\% \\\\ \\hline FID & 20.11 & 19.54 & 18.74 & 18.64 & 18.60 & 19.33 & 21.81 & 26.03 & 30.41 & 35.24 & 40.92 \\\\ Inception Score & 199.24 & 201.87 & 202.81 & 204.01 & 193.62 & 175.62 & 140.69 & 110.81 & 90.24 & 70.91 & 54.41 \\\\ Time Cost (s) & 7.1 & 6.7 & 6.2 & 5.8 & 5.3 & 4.9 & 4.5 & 4.1 & 3.6 & 3.1 & 2.9 \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: T-Stitch with LDM (Rombach et al., 2022) and LDM-S on class-conditional ImageNet. 모든 평가는 DDIM과 100개의 타임스텝을 기반으로 한다. 분류기 없는 3.0의 유도 척도를 채택하였으며, RTX 3090에서 8개의 영상을 생성하여 시간 비용을 측정하였다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c c c c c c c c} Fraction of BL-SMD Tiny & 0\\% & 10\\% & 20\\% & 30\\% & 40\\% & 50\\% & 60\\% & 70\\% & 80\\% & 90\\% & 100\\% \\\\ \\hline FID & 13.07 & 12.59 & 12.29 & 12.54 & 13.65 & 14.98 & 15.69 & 16.57 & 16.92 & 16.80 & 17.15 \\\\ Inception Score & 36.72 & 36.12 & 34.66 & 33.32 & 32.48 & 31.72 & 31.48 & 30.83 & 30.53 & 30.48 & 30.00 \\\\ CLIP Score & 0.2957 & 0.2957 & 0.2938 & 0.2910 & 0.2860 & 0.2805 & 0.2770 & 0.2718 & 0.2692 & 0.2682 & 0.2653 \\\\ Time Cost (s) & 3.1 & 3.0 & 2.9 & 2.8 & 2.6 & 2.5 & 2.4 & 2.3 & 2.1 & 2.0 & 1.9 \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: BK-SDM Tiny를 갖는 T-Stitch (Kim et al., 2023) 및 SD v1.4. We report FID, Inception Score (IS) 및 CLIP score (Hessel et al., 2021) on MS-COCO 256\\(\\times\\)256 benchmark. 시간 비용은 하나의 RTX 3090 상에서 하나의 이미지를 생성함으로써 측정된다.\n' +
      '\n' +
      '도 7: 일반적인 사전 훈련된 소형 SD 모델에 기초하여, T-Stitch는 InkPunk Diffusion에서 다른 미세 조정/스타일화된 대형 SD 모델, "파크"를 스티칭할 때 대형 일반 SD를 동시에 가속화하고 이미지 콘텐츠와의 프롬프트 정렬을 보완한다. 디지털로 확대할 때 더 잘 볼 수 있습니다.\n' +
      '\n' +
      '다양한 메트릭에 걸친 모델 스티칭\n' +
      '\n' +
      '**훈련 기반 가속 방법과 비교하여.** DPM 샘플링을 가속화하기 위해 널리 채택된 훈련 기반 방법은 주로 경량 모델 설계(Zhao et al., 2023; Lee et al., 2023), 모델 압축(Kim et al., 2023), 및 단계 증류(Salimans and Ho, 2022; Song et al., 2023; Luo et al., 2023)를 포함한다. 이들에 비해 T-Stitch는 개별 모델 최적화에 불가지론적이기 때문에 훈련이 없고 _상보 가속 기법_이다. 실제로, T-스티치는 상이한 디노이저 아키텍처(DiT 및 U-Net, 섹션 4.1 및 섹션 4.2), 및 임의의 이미 프루닝된(섹션 A.7) 또는 스텝-증류 모델(섹션 A.18)과 넓은 호환성을 달성한다.\n' +
      '\n' +
      '**다른 훈련-자유 가속 방법들과 비교하여.** 최근 작업들(Li et al., 2023; Ma et al., 2023; Wimbauer et al., 2023)은 속도 향상을 위한 샘플링 동안 중간 특징 맵들을 U-Net에 캐싱하도록 제안되었다. T-Stitch는 또한 섹션 A.19에 도시된 바와 같이, 개별 모델이 여전히 캐싱으로 가속될 수 있기 때문에 이러한 캐시 기반 방법들에 상보적이다. 또한, T-Stitch는 또한 모델 양자화(Shang et al., 2023; Li et al., 2023), VAE 디코더 가속(Kodaira et al., 2023) 및 토큰 병합(Bolya et al., 2023)의 이점을 누릴 수 있기 때문에 이러한 캐시 기반 방법들에 상보적이다(섹션 A.20).\n' +
      '\n' +
      '## 5 Conclusion\n' +
      '\n' +
      '우리는 기존의 사전 훈련된 대규모 확산 모델 샘플링을 가속화하기 위한 효과적이고 일반적인 접근 방법인 Trajectory Stitching을 제안했으며, 이는 초기 잡음 제거 과정에서 사전 훈련된 소규모 대응물을 직접 활용하여 개별 대규모 DPM을 사용하는 것보다 더 나은 속도와 품질 절충을 달성한다. 종합 실험을 통해 T-스티치가 다양한 모델 아키텍처, 샘플러 및 다양한 안정적인 확산 모델에서 일관된 효율성 이득을 달성했음을 입증했다. 게다가, 우리의 작업은 초기 잡음 제거 과정에서 작은 DPM의 힘을 밝혀냈다. 향후 작업은 서로 다른 노이즈 제거 간격으로 서로 다른 크기의 전문가를 재설계하거나 훈련하여 샘플링 궤적을 분리하는 것을 고려할 수 있다. 예를 들어, 글로벌 구조를 그리기 위해 초기에 더 우수하고 더 빠른 작은 DPM을 설계한 다음, 이미지 세부 사항을 정제하기 위해 후기 단계에서 큰 DPM을 구체적으로 최적화한다. 또한, 최적의 절충을 위한 더 많은 지침과 양식화된 SD에 대한 신속한 정렬에 대한 더 심층적인 분석이 도움이 될 수 있으며, 이는 향후 작업을 위해 남겨둔다.\n' +
      '\n' +
      '**제한.** T-스티치는 큰 모델과 동일한 데이터 분포에 대해 훈련된 더 작은 모델을 필요로 한다. 따라서, 충분히 최적화된 소형 모델이 요구된다. 게다가, 샘플링을 잡음제거하기 위한 추가적인 소형 모델을 채택하면_slightly_ 메모리 사용량을 증가시킬 것이다(섹션 A.14). 마지막으로, T-Stitch는 샘플링 가속을 위해 작은 모델에서 무료 점심을 제공하기 때문에 속도 향상 이득은 작은 모델의 효율성에 의해 제한된다. 실제로 작은 모델을 사용할 수 있고 큰 모델보다 훨씬 빠를 때 T-스티치를 사용하는 것이 좋다. 최근 연구(Razzhigaev et al., 2023; Podell et al., 2023)에서 DPM이 확장되고 있기 때문에, 우리는 우리의 연구가 이러한 큰 모델을 보완하기 위해 효율적인 작은 모델을 효과적으로 활용하는 데 더 많은 탐색과 채택에 영감을 주기를 바란다.\n' +
      '\n' +
      '그림 8: 1.5의 유도 척도에서 다른 샘플러를 사용한 T-스티치의 효과.\n' +
      '\n' +
      '도 10: T-스티치 vs. 모델 스티칭(M-Stitch)(Pan et al., 2023) based on DiTs and DDIM 100 steps, with a classifier-free guidance scale of 1.5.\n' +
      '\n' +
      '그림 9: **왼쪽:** 서로 다른 수의 단계 간의 FID를 비교한다. **Right:** 우리는 DDIM과 분류기-유도 척도 1.5를 기반으로 서로 다른 단계 수로 8개의 이미지를 생성하는 데 드는 시간 비용을 시각화한다. "T"는 샘플링 단계의 수를 나타낸다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:9]\n' +
      '\n' +
      '*Pan et al. (2023a) Pan, Z., Cai, J., and Zhuang, B. Stitchable neural networks. _CVPR_, 2023a.\n' +
      '* Pan et al. (2023b) Pan, Z., Liu, J., He, H., Cai, J., and Zhuang, B. Stitched vits is flexible vision backbones. _ arXiv_, 2023b.\n' +
      '* Peebles & Xie(2022) Peebles, W. 및 Xie, S. 변압기가 있는 확장 가능한 확산 모델 _ CoRR_, abs/2212.09748, 2022년\n' +
      '* Podell et al. (2023) Podell, D., English, Z., Lacey, K., Blattmann, A., Dockhorn, T., Muller, J., Penna, J., and Rombach, R. SDXL: 고해상도 영상 합성을 위한 잠재 확산 모델 개선 CoRR_, 2023.\n' +
      '* Poole et al. (2023) Poole, B., Jain, A., Barron, J. T., and Mildenhall, B. Dreamfusion: Text-to-3d using 2d diffusion. _ICLR_에서. OpenReview.net, 2023\n' +
      '* Razzhizaev et al. (2023) Razzhizaev, A., Shakhmatov, A., Maltseva, A., Arkhipkin, V., Pavlov, I., Ryabov, I., Kuts, A., Panchenko, A., Kuznetsov, A., and Dimitrov, D. Kandinsky: 이미지 이전 및 잠재 확산을 갖는 개선된 텍스트-이미지 합성. In _EMNLP Demos_, pp. 286-295, 2023.\n' +
      '* Roeder et al. (2021) Roeder, G., Metz, L., and Kingma, D. On linear identifiability of learned representations. In _ICML_, volume 139, pp. 9030-9039, 2021.\n' +
      '* Rombach et al. (2022) Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. High-resolution image synthesis with latent diffusion models. _CVPR_, pp. 10684-10695, 2022.\n' +
      '*Salimans & Ho(2022) Salimans, T. 및 Ho, J. 확산 모델의 빠른 샘플링을 위한 점진적 증류. _ICLR_에서. OpenReview.net, 2022년\n' +
      '* Sauer et al.(2023) Sauer, A., Lorenz, D., Blattmann, A., and Rombach, R. 적대적 확산 증류. _ arXiv_, 2023.\n' +
      '* Segmind(2023) Segmind. Segmind Stable Diffusion Model (SSD-1B). [https://huggingface.co/segmind/SSD-1B] (https://huggingface.co/segmind/SSD-1B), 2023.\n' +
      '* Shang et al. (2023) Shang, Y., Yuan, Z., Xie, B., Wu, B., and Yan, Y. 확산 모델에 대한 훈련 후 양자화 CVPR_, Jun 2023.\n' +
      '* Shih et al. (2023) Shih, A., Belkhale, S., Ermon, S., Sadigh, D., and Anari, N. 확산 모델의 병렬 샘플링. _ CoRR_, abs/2305.16317, 2023.\n' +
      '* Song et al. (2021a) Song, J., Meng, C., and Ermon, S. 확산 암시적 모델의 잡음 제거 _ICLR_에서. OpenReview.net, 2021a.\n' +
      '* Song et al. (2021b) Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. Score-based generative modeling through stochastic differential equations. _ ICLR_, 2021b.\n' +
      '* Song et al. (2023) Song, Y., Dhariwal, P., Chen, M., and Sutskever, I. Consistency models. _ICML_에서, 볼륨 202, 2023.\n' +
      '* Szegedy et al. (2016) Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. 컴퓨터 비전을 위한 초기 아키텍처를 재고하고 있습니다. In _CVPR_, pp. 2818-2826. IEEE Computer Society, 2016.\n' +
      '* von Platen et al. (2022) von Platen, P., Patil, S., Lozhkov, A., Cuenca, P., Lambert, N., Rasul, K., Davaadorj, M., and Wolf, T. 확산기: 최첨단 확산 모델. [https://github.com/huggingface/diffusers] (https://github.com/huggingface/diffusers), 2022.\n' +
      '* 윔바우어 등 (2023) Wimbauer et al. (2023) Wimbauer, F., Wu, B., Schonfeld, E., Dai, X., Hou, J., He, Z., Sanakoyeu, A., Zhang, P., Tsai, S. S., Kohler, J., Rupprecht, C., Cremers, D., Vajda, P., and Wang, J. Cache me if you can: Accelerating diffusion models through block caching. _ arXiv_, 2023.\n' +
      '* Yang et al. (2022) Yang, X., Zhou, D., Liu, S., Ye, J., and Wang, X. 심층 모델 재조립 NeurIPS_, 2022.\n' +
      '* Yang et al. (2023) Yang, X., Zhou, D., Feng, J., and Wang, X. 확산 확률 모델은 슬림하게 만들었습니다. In _CVPR_, pp. 22552-22562. IEEE, 2023.\n' +
      '* Zhang et al. (2023) Zhang, L., Rao, A., and Agrawala, M. 텍스트 대 이미지 확산 모델에 조건부 제어를 추가합니다. In _ICCV_, pp. 3836-3847, 2023.\n' +
      '* Zhao et al. (2023) Zhao, Y., Xu, Y., Xiao, Z., and Hou, T. Mobilediffusion: Subsecond text-to image generation on mobile devices. _ arXiv_, 2023.\n' +
      '* Zheng et al. (2023) Zheng, H., Nie, W., Vahdat, A., Azizzadenesheli, K., and Anandkumar, A. Fast sampling of diffusion models via operator learning. In _ICML_, pp. 42390-42402. PMLR, 2023.\n' +
      '\n' +
      '## 부록, 부록\n' +
      '\n' +
      '우리는 우리의 보충 자료를 다음과 같이 정리한다.\n' +
      '\n' +
      '* 섹션 A.1에서 우리는 T-스티치의 실제 배치를 위한 지침을 제공한다.\n' +
      '* 섹션 A.2에서 DiT를 기반으로 한 변액 제거 과정 중 빈도 분석을 제공한다.\n' +
      '* 섹션 A.3에서 채택된 사전 훈련된 DiT 및 U-네트의 세부 사항을 보고한다.\n' +
      '* A.4절에서는 DiTs와 T-Stitch를 기반으로 분류기가 없는 다양한 유도 척도를 사용하는 효과를 보여준다.\n' +
      '* A.5절에서는 T-Stitch 하에서의 FID 평가를 5,000개의 이미지 및 50,000개의 이미지와 비교한다.\n' +
      '* 섹션 A.6에서 T-스티치를 샘플링 단계를 직접 줄이는 것과 비교한다.\n' +
      '* 섹션 A.7에서 T-스티치가 가지치기 및 지식 증류 모델과 호환된다는 것을 보여준다.\n' +
      '* 섹션 A.8에서, 우리는 SN-Netv2 하에서 모델 스티칭 기준선의 구현 세부사항을 기술한다(Pan et al., 2023b).\n' +
      '* 섹션 A.9에서 DiT를 기반으로 샘플링 단계가 다른 T-스티치를 사용할 때 이미지 예를 보여준다.\n' +
      '* 섹션 A.10에서, 우리는 T-Stitch가 U-ViT로 DiT를 스티칭하는 상이한 사전 훈련된 모델 패밀리들, _e.g_에 적용가능하다는 것을 입증한다(Bao et al., 2023).\n' +
      '* 섹션 A.11에서 원본 SDv1.4, 스타일화된 SD, SDXL, ControlNet을 포함한 안정적인 확산 실험에서 더 많은 이미지 예를 보여준다.\n' +
      '* 섹션 A.12에서 우리는 할당된 단계에서 큰 DiT를 추가로 미세 조정함으로써 미세 조정 실험을 보고한다.\n' +
      '* 섹션 A.13에서 기본 스티칭 전략을 더 많은 기준선과 비교합니다.\n' +
      '* A.14절에서 T-Stitch의 추가 메모리 및 스토리지 오버헤드를 보고한다.\n' +
      '* 섹션 A.15에서, 우리는 DiTs를 기반으로 한 클래스 조건부 이미지넷-256에 대한 정밀도 및 재현율 메트릭을 보고한다.\n' +
      '* A.16절에서는 DiTs와 U-Nets를 사용한 T-Stitch의 이미지 예를 보여준다.\n' +
      '* 섹션 A.17에서 우리는 다른 훈련 반복에서 사전 훈련된 DiT-S를 사용하여 T-스티치 하에서 FID를 평가한다.\n' +
      '* 섹션 A.18에서, 우리는 T-스티치가 LCM(Luo et al., 2023)과 함께 2-4 단계 하에서 여전히 부드러운 속도 및 품질 트레이드 오프를 얻을 수 있음을 입증한다.\n' +
      '* 섹션 A.19에서, 우리는 T-스티치가 딥캐시(Ma et al., 2023)와 같은 캐시 기반 방법에도 보완적이어서 추가적인 속도 향상을 달성한다는 것을 보여준다.\n' +
      '* A.20절에서 T-Stitch를 평가하고 ToMe(Bolya et al., 2023)를 동시에 적용하여 이미지 예를 보인다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c c}  & Parameters (M) & FLOPs (G) & Train Iters & Time Cost (s) & FID \\\\ \\hline DiT-S & 33.0 & 5.5 & 5000K & 1.6 & 33.46 \\\\ DiT-B & 130.5 & 21.8 & 1600K & 4.0 & 12.30 \\\\ DiT-XL & 675.1 & 114.5 & - & 16.5 & 9.20 \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 클래스 조건 이미지넷 상에서 사전 훈련된 DiT 모델 패밀리의 성능 비교. FLOPs는 \\(4\\times 32\\times 32\\)의 형태로 잠재된 잡음이 주어졌을 때 한 번의 전진 과정을 통해 측정된다.\n' +
      '\n' +
      '### T-스티치의 실용적 전개\n' +
      '\n' +
      '이 섹션에서는 모델 할당 전략을 계산 예산 할당 문제로 공식화하여 T-스티치의 실제 배치에 대한 지침을 제공한다.\n' +
      '\n' +
      'Denoisers \\(\\{D_{1},D_{2},...,D_{K}\\}\\)의 집합과 그에 상응하는 계산 비용 \\(\\{C_{1},C_{2},...,C_{K}\\}\\)이 주어지면, \\(C_{k-1}<C_{k}\\), 우리는 생성 품질을 최대화하기 위해 해당 잡음 구간에 모델을 할당하는 최적의 구성 집합 \\(\\{r_{1},r_{2},...,r_{K}\\}\\)을 찾는 것을 목표로 한다.\n' +
      '\n' +
      '\\[\\max_{r_{1},r_{2},...,r_{K}} M\\left(F(D_{1},r_{1})\\circ F(D_{2},r_{2})\\cdots\\circ F(D_{K},r_{K})\\right)\\](5)\\[\\sum_{k=1}^{K}r_{k}C_{k}\\leq C_{R},\\sum_{k=1}^{K}r_{k}=1,\\tag{6}\\\\tag{6}\\\\cot\\circ F(D_{2},r_{2})\\cdots\\circ F(D_{K},r_{K})\\](5)\\[\\sum_{k=1}^{K}C_{k}\\leq C_{R},\\sum_{k=1}^{K}r_{k}=1,\\tag{6}\\].\n' +
      '\n' +
      '여기서 \\(F(D_{k},r_{k})\\)는 \\(r_{k}\\)으로 표시된 \\(k\\)번째 간격에서 디노이저 \\(D_{k}\\)을 적용하여 디노이징 과정을 의미하며, \\(\\circ\\)은 구도에, \\(M\\)은 생성 성능을 평가하기 위한 메트릭 함수를 나타내며, \\(C_{R}\\)은 계산 예산 제약이다. \\(\\{C_{1},C_{2},...,C_{K}\\}\\)이 알려져 있기 때문에 가능한 모든 분수 조합을 효율적으로 열거하고 룩업 테이블을 얻을 수 있으며, 여기서 각 분수 구성 세트는 계산 예산(_i.e._, 시간 비용)에 해당한다. 실제로 우리는 이 표에서 예산을 만족하는 몇 가지 구성 세트를 샘플링한 다음 생성 작업에 적용할 수 있다.\n' +
      '\n' +
      '잡음제거 과정에서의### 주파수 분석\n' +
      '\n' +
      '우리는 잡음 제거 과정이 초기 단계의 저주파와 후기 단계의 고주파에 초점을 맞춘다는 증거를 제공한다. DiT-XL을 기반으로 각 샘플링 단계에서 푸리에 변환된 잠재 잡음의 로그 진폭을 시각화한다. 도 11에 도시된 바와 같이, 저주파 진폭은 초기 타임스텝(_i.e._, 999에서 555까지)에서 급격히 증가하며, 이는 저주파가 집중적으로 발생함을 나타낸다. 특히, \\(t=111\\)과 \\(t=0\\)의 경우, 높은 주파수의 로그 진폭이 크게 증가하는 것을 관찰할 수 있으며, 이는 이후의 단계가 세부 개선에 초점을 맞추고 있음을 의미한다.\n' +
      '\n' +
      '### 미리 훈련된 DiTs와 U-Nets\n' +
      '\n' +
      '표 3과 표 4에서 사전 훈련된 DiT 모델 패밀리와 재현된 작은 버전의 U-Net에 대한 자세한 비교를 제공한다. 전반적으로, 섹션 3에서 앞서 언급한 바와 같이, 우리는 명확한 속도를 달성할 수 있도록 각 모델 패밀리의 모델이 서로 간에 모델 크기의 명확한 격차를 갖도록 한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c} Model & Param (M) & Train Iter & Time Cost (s) & FID \\\\ \\hline LDM-S & 25 & 400K & 2.9 & 40.92 \\\\ LDM & 394 & 200K & 7.1 & 20.11 \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 클래스 조건 이미지넷 상에서의 LDM과 LDM-S의 성능 비교.\n' +
      '\n' +
      '그림 11: DiT-XL의 잡음제거 과정에서의 주파수 분석, DDIM 10단계 및 유도 척도 4.0을 기반으로 각 단계에서 푸리에 변환된 잠재 잡음의 로그 진폭을 시각화한다. 결과들은 32개의 이미지들에 걸쳐 평균화된다.\n' +
      '\n' +
      '3-모델 T-Stitch에 대한 Classifier-free 가이드의 효과\n' +
      '\n' +
      '그림 12에서 우리는 3모델 설정에서 다른 안내 척도를 사용하여 DiT가 있는 T-스티치를 적용하여 결과를 제공한다. 일반적으로 T-Stitch는 DiT-S와 DiT-XL 사이에 매끄러운 파레토 프론티어를 보간하는 다양한 유도 척도로 일관되게 수행한다. DPM의 일반적인 관행은 이미지 생성을 제어하기 위해 다양한 지침 척도를 채택하므로 T-스티치의 광범위한 적용 가능성을 크게 강조한다.\n' +
      '\n' +
      '### FID-50K vs. FID-5K\n' +
      '\n' +
      '효율성 문제를 위해 우리는 기본적으로 5,000개의 이미지를 기반으로 FID를 보고한다. DiT를 기반으로 FID를 평가하기 위해 1.5의 안내 척도와 50,000개의 샘플 이미지를 사용하여 DDPM 250단계로 T-스티치를 적용한다. 그림 13과 같이 FID-50K와 FID-5K 사이의 관측치는 유사하며, 이는 50,000과 같은 더 많은 이미지를 샘플링하는 것이 효과에 영향을 미치지 않음을 나타낸다.\n' +
      '\n' +
      '그림 12: DiT-S, DiT-B, DiT-XL의 세 가지 모델을 기반으로 한 궤적 스티칭. 분류기 없는 유도 척도가 1.5, 2.0 및 3.0인 DDIM 100 타임스테프를 채택한다.\n' +
      '\n' +
      '그림 13: DiT-S, DiT-B, DiT-XL의 세 가지 모델을 기반으로 한 궤적 스티칭. 분류기 없는 안내 척도가 1.5인 DDPM 250 타임스텝을 채택한다.\n' +
      '\n' +
      '샘플링 단계를 직접 줄이는 것과 비교하여###\n' +
      '\n' +
      '샘플링 단계를 줄이는 것은 배치 중 다른 속도와 품질 균형을 얻기 위한 일반적인 관행이었다. T-스티치가 다른 샘플링 단계에서 일관된 효율성 이득을 얻을 수 있음을 입증했지만 그림 15에서 샘플링 단계의 수를 직접 줄이는 것과 비교하여 T-스티치로부터의 트레이드오프는 특히 T-스티치 아래의 FID가 훨씬 더 나은 50-100 단계 영역에 대해 매우 경쟁력이 있음을 보여준다. 따라서, T-Stitch는 실제적인 DPM 샘플링 속도 가속을 위한 _complementary_ 또는 대안적인 방법의 역할을 할 수 있다.\n' +
      '\n' +
      '### 모델 압축과 비교\n' +
      '\n' +
      '실제로 T-스티치는 개별 모델 최적화/압축에 직교합니다. 예를 들어, BK-SDM Tiny와 SDv1.4를 사용하면 큰 SD에서 이후의 단계에서 계산 비용을 줄이기 위해 SDv1.4에 압축을 적용할 수 있다. 그림 16에서 우리는 압축된 SD v1.4, _i.e._, BK-SDM Small을 채택함으로써 이미지 품질에 대한 트레이드 오프와 함께 시간 비용을 더욱 줄일 수 있음을 보여준다.\n' +
      '\n' +
      '도 14: DiT-S/B/XL의 T-Stitch 스케줄에 기초하여, 50% : 30% : 20%의 후반 단계에서 미리 훈련되고 미세 조정된 DiT-B 및 DiT-XL을 스티칭함으로써 이미지 품질 비교.\n' +
      '\n' +
      '그림 15: DDIM을 기반으로 T-Stitch를 사용하고 샘플링 단계를 100에서 10으로 직접 줄여 DiT-XL에 대한 FID 및 속도 향상 비교를 보고한다. "s"는 분류기가 없는 안내 척도를 나타낸다. 궤적 스티칭은 100단계 이하에서 3-모델 조합(DiT-S/B/XL)을 채택한다.\n' +
      '\n' +
      '### 모델 스티칭 기준선 구현 세부사항\n' +
      '\n' +
      '우리는 DiT-S/XL을 스티칭할 때 64의 LoRA 순위를 채택하여 134개의 스티칭 구성으로 이어진다. 스티칭된 모델은 1,700K 트레이닝 반복을 위해 8개의 A100 GPU에서 미세 조정된다. 우리는 ImageNet 특징을 Stable Diffusion AutoEncoder (Rombach et al., 2022)로 사전 추출하고 어떠한 데이터 증강도 적용하지 않는다. 기준선 DiT에 이어서, 우리는 일정한 학습률 \\(1\\times 10^{-4}\\)의 AdamW 최적화기를 채택한다. 총 배치 크기는 256으로 설정됩니다. 다른 모든 하이퍼파라미터는 기본 설정을 DiT로 사용합니다.\n' +
      '\n' +
      '샘플링 단계 수에 따른### 이미지 예제\n' +
      '\n' +
      '도 17은 T-Stitch 및 DiT-S/XL 하에서 상이한 수의 샘플링 단계를 사용하여 생성된 이미지 예를 도시한다. 그림에서 알 수 있듯이 초기 40% 단계에서 작은 모델을 채택하면 최종 생성된 이미지에 미미한 영향을 미친다. DiT-S의 비율을 점진적으로 증가시킬 때 속도와 품질 사이에는 가시적인 상충 관계가 있으며 최종 이미지는 DiT-S에서 생성된 이미지와 더 유사하다.\n' +
      '\n' +
      '미리 훈련된 모델 패밀리가 다른### T-스티치\n' +
      '\n' +
      '유사한 인코딩을 학습하기 위해 동일한 데이터 세트에서 훈련된 서로 다른 사전 훈련된 모델로서, T-Stitch는 서로 다른 사전 훈련된 모델 패밀리를 직접 통합할 수 있다. 예를 들어, U-ViT H(Bao et al., 2023)에 기초하여, 우리는 DiTs 및 U-Nets에 대해 했던 것처럼 초기 샘플링 단계에서 DiT-S를 적용한다. 놀랍게도 <표 5>와 같이 성능이 매우 우수한데, 이는 공공 모델 동물원에서 보다 다양한 모델에 적용할 수 있어 T-Stitch의 장점을 보여준다.\n' +
      '\n' +
      '### 안정확산을 위한 더 많은 예\n' +
      '\n' +
      'SD v1.4, InkPunk Diffusion and Ghibli Diffusion with a small SD model, BK-SDM Tiny (Kim et al., 2023)에 T-Stitch를 적용하여 보다 많은 예를 보인다. 모든 예에서, 우리는 Diffusers: PNDM 스케줄러, 50단계, guidance scale 7.5에서 StableDiffusionPipeline의 기본 스케줄러와 하이퍼파라미터를 채택한다. 도 25에서, SD v1.4의 샘플링 궤적에 작은 SD를 채택하는 것이 작은 분수에서 화질의 작은 영향을 달성하고 획득한다는 것을 관찰한다.\n' +
      '\n' +
      '도 16: SDv1.4 및 그 압축된 버전(_i.e._, BK-SDM Small)을 이후의 단계에서 채택함으로써 T-스티치의 비교.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c c c c c c c c} Fraction of DiT-S & 0\\% & 10\\% & 20\\% & 30\\% & 40\\% & 50\\% & 60\\% & 70\\% & 80\\% & 90\\% & 100\\% \\\\ \\hline FID & 15.04 & 13.68 & 12.44 & 12.76 & 14.19 & 17.6 & 29.4 & 53.75 & 74.14 & 84.33 & 121.95 \\\\ Time Cost (s) & 15.90 & 13.21 & 11.91 & 10.61 & 9.42 & 7.92 & 6.57 & 5.23 & 3.84 & 2.50 & 1.40 \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: DiT-S 및 U-ViT H가 있는 T-스티치, DPM-Solver++, 50단계, 안내 척도 1.5.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:16]\n' +
      '\n' +
      '### 더 많은 스티칭 기준선과 비교\n' +
      '\n' +
      '기본적으로 우리는 T-스티치를 작은 DPM에서 시작하여 마지막 노이즈 제거 샘플링 단계를 위해 큰 DPM으로 전환하도록 설계한다. 이 설계의 효과를 보여주기 위해 방법을 DiT-S 및 DiT-XL을 포함하여 표 7의 여러 기준선과 비교한다.\n' +
      '\n' +
      '잡음 제거 샘플링 동안 우리는 궤적을 따라 작고 큰 모델을 인터리빙한다. 결국, DiT-S는 50% 단계를 취하고, DiT-XL은 또 다른 50% 단계를 취한다.\n' +
      '**감소 Prob.** 디노이징 샘플링 단계 동안 DiT-S를 사용할 확률을 1에서 0으로 선형적으로 감소시킨다.\n' +
      '* **Large to Small.** 초기 50% 단계에서 대형 모델을 채택하고 마지막 50% 단계에서 소형 모델을 채택합니다.\n' +
      '***Small to Large(우리의 기본 설계).** 초기 50% 단계에서 DiT-S를 채택하고 마지막 50% 단계에서 DiT-XL을 사용하는 T-Stitch의 기본 전략.\n' +
      '\n' +
      '표 7에서 볼 수 있듯이 일반적으로 기본 설계는 유사한 샘플링 속도로 최상의 FID 및 인셉션 점수를 달성하며, 이는 그 효과를 강력하게 보여준다.\n' +
      '\n' +
      '### T-스티치의 추가 메모리 및 저장 오버헤드\n' +
      '\n' +
      '직관적으로, T-Stitch는 추가적인 메모리 및 스토리지 오버헤드를 도입할 수 있는 작은 DPM을 채택한다. 그러나 실제로 큰 DPM은 여전히 메모리 및 스토리지 소비의 주요 병목 현상이다. 이 경우, 작은 DPM으로부터의 추가적인 오버헤드는 상당히 작다. 예를 들어, 표 8에 도시된 바와 같이, DiT-XL과 비교하여, DiT-S의 50% 단계를 채택함으로써 T-Stitch는 추가적인 5% 파라미터, 4% GPU 메모리 비용, 10% 로컬 스토리지 비용만을 도입하면서, DiT-XL 샘플링 속도를 1.76\\(\\times\\)만큼 크게 가속시킨다.\n' +
      '\n' +
      '### T-스티치의 정밀도 및 리콜 측정\n' +
      '\n' +
      '일반적인 관행(Dhariwal and Nichol, 2021)에 따라 충실도를 측정하기 위해 Precision을 채택하고 다양성 또는 분포 범위를 측정하기 위해 Recall을 채택한다. 표 9에서 T-스티치가 초기 40-50% 단계에서 정밀도와 리콜에 미미한 영향을 도입하는 반면, 이후 단계에서는 FID 평가와 일치하는 명확한 상충 관계를 관찰한다는 것을 보여준다.\n' +
      '\n' +
      '### DiTs와 U-Nets 상의 T-Stitch 이미지 예\n' +
      '\n' +
      '그림 23과 24에서 각각 DiT-S/XL, LDM-S/LDM으로 T-Stitch를 적용하여 생성한 이미지 예를 제공한다. 전반적으로 초기에 작은 DPM을 채택하면 여전히 의미 있고 고품질 이미지가 생성되는 반면, 이후 단계에서는 유연한 속도와 품질 균형을 달성한다는 것을 관찰한다. null을 학습하는 DiT와 다르다는 점에 유의하십시오.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c} Method & FID & Inception Score & Time Cost \\\\ \\hline Interleave & 19.02 & 120.04 & 10.1 \\\\ Decreasing Prob & 12.94 & 163.45 & 9.8 \\\\ Large to Small & 27.61 & 72.60 & 10.0 \\\\ Small to Large (Ours) & 10.06 & 200.81 & 9.9 \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: DiT-S/XL, DDIM 100 스텝 및 1.5의 안내 스케일을 기반으로 하는 다른 궤적 스티칭 기준선과 비교하여, FID는 5K 이미지에 의해 계산된다. 메모리 및 시간 비용은 하나의 RTX 3090에서 8의 배치 크기로 측정된다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c} Name & Parameter (M) & Local Storage (MB) & Memory Cost (MB) & Time Cost (s) \\\\ \\hline DiT-S & 33 & 263 & 3088 & 1.7 \\\\ DiT-XL & 675 & 2576 & 3166 & 16.5 \\\\ T-Stitch (50\\%) & 708 (\\(\\times\\)1.04) & 2839 (\\(\\times\\)1.10) & 3296 (\\(\\times\\)1.04) & 9.4 (\\(\\times\\)1.76) \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: DiT-S, DiT-XL 및 T-Stitch 간의 로컬 스토리지 및 메모리 비용 비교. 메모리 및 시간 비용은 하나의 RTX 3090에서 8개의 이미지를 병렬로 생성함으로써 측정된다.\n' +
      '\n' +
      '분류기 없는 안내 동안 클래스 임베딩은 본질적으로 공식 구현 3에서 이러한 임베딩을 생략하며, 샘플링 동안 LDM과 LDM-S는 서로 다른 조건 없는 신호를 가지며, 이는 결국 서로 다른 분율 하에서 다양한 이미지 콘텐츠를 생성한다.\n' +
      '\n' +
      '각주 3: [https://github.com/CompVis/latent-diffusion](https://github.com/CompVis/latent-diffusion)\n' +
      '\n' +
      '훈련반복에 따른 DiT-S의### 효과\n' +
      '\n' +
      '실험에서는 충분히 최적화될 수 있으므로 5,000K 반복으로 훈련된 DiT-S를 채택한다. 그림 18에서 400K 반복의 짧은 훈련 일정에서도 샘플링 궤적의 초기 단계에서 DiT-S를 채택하는 것이 전체 FID에 미미한 영향을 미친다는 것을 나타낸다. 주요 차이점은 샘플링 궤적의 후반부에 있다. 따라서 초기 노이즈 제거 샘플링 단계가 더 쉽게 학습되고 계산 효율이 높은 소형 모델에 의해 처리될 수 있음을 의미한다.\n' +
      '\n' +
      '###LCM과의 호환성\n' +
      '\n' +
      'T-스티치는 단계 증류(Luo et al., 2023; Song et al., 2023)와 같은 확립된 훈련 기반 방법을 통해 이미 가속화된 DPM을 더욱 가속화할 수 있다. 예를 들어, 도 32 및 도 33에 도시된 바와 같이, LCM(Luo et al., 2023)으로부터 증류된 SDXL이 주어지면, T-Stitch는 상대적으로 더 작은 SD를 채택함으로써 높은 이미지 품질로 2 내지 4 단계 하에서 더 빠른 속도를 달성할 수 있다. 표 10, 표 11에서 우리는 LCM 증류 SDXL과 SSD-1B를 스티칭하여 포괄적인 FID, 인셉션 점수 및 CLIP 점수 평가를 보고하며, 여기서 T-스티치가 SDXL과 SSD-1B 사이의 품질을 부드럽게 보간한다는 것을 보여준다. 마지막으로, T-Stitch에서 더 우수하고 빠른 소형 모델이 향후 작업에서 더 많은 이득을 얻는 데 도움이 될 것이라고 가정한다.\n' +
      '\n' +
      'DeepCache와의 호환성\n' +
      '\n' +
      '이 섹션에서는 DeepCache(Ma et al., 2023)와 같은 최근의 캐시 기반 방법(Ma et al., 2023; Wimbauer et al., 2023)이 T-Stitch와 효과적으로 결합되어 더 많은 이점을 얻을 수 있음을 입증한다. 기본적으로 T-스티치가 미리 훈련된 SD에서 직접 떨어짐에 따라 DeepCache를 채택하여 소형 및 대형 확산 모델을 동시에 가속화할 수 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c c c c c c c} Fraction of DiT-S & 0\\% & 10\\% & 20\\% & 30\\% & 40\\% & 50\\% & 60\\% & 70\\% & 80\\% & 90\\% & 100\\% \\\\ \\hline FID & 9.20 & 9.17 & 8.99 & 9.03 & 8.95 & 10.06 & 12.46 & 18.04 & 25.44 & 30.11 & 33.46 \\\\ Precision & 0.81 & 0.81 & 0.81 & 0.81 & 0.80 & 0.76 & 0.72 & 0.67 & 0.62 & 0.59 & 0.58 \\\\ Recall & 0.74 & 0.74 & 0.74 & 0.74 & 0.75 & 0.75 & 0.74 & 0.73 & 0.69 & 0.65 & 0.63 \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 9: DiT-S/XL에 기초한 정밀도 및 리콜 평가, DDIM 100단계 및 안내 척도는 1.5이다.\n' +
      '\n' +
      '도 18: DDPM, 250 단계 및 1.5의 안내 척도에 기초하여, DiT-XL을 가속하기 위한 T-Stitch에서 상이한 사전 훈련된 DiT-S의 효과. 예를 들어, "400K"는 400K 반복들에서 DiT-S의 사전 훈련된 가중치들을 나타낸다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:19]\n' +
      '\n' +
      '도 21: T-Stitch와 DeepCache를 결합하는 이미지 예(Ma et al., 2023). 우리는 T-Stitch의 작은 모델로 BK-SDM Tiny를 채택하고 이미지 상단에 백분율을 보고한다. 모든 이미지들은 디퓨저들(von Platen et al., 2022): 7.5의 안내 스케일을 갖는 50 단계들에서 디폴트 설정들에 의해 생성된다.\n' +
      '\n' +
      '도 19: T-Stitch와 DeepCache를 결합한 효과(Ma et al., 2023). 우리는 50단계 하에서 MS-COCO 256\\(\\times\\)256 벤치마크에 대한 FID, Inception Score 및 CLIP 스코어(Hessel et al., 2021)를 보고한다. 1개의 RTX 3090에서 1개의 영상을 생성하여 시간 비용을 측정하였으며, 소형 모델과 대형 모델로 각각 BK-SDM Tiny와 SDv1.4를 채택하였다. DeepCache의 경우, 우리는 3의 균일한 캐시 간격을 채택한다.\n' +
      '\n' +
      '도 20: T-Stitch와 ToMe를 결합한 효과(Bolya et al., 2023). 우리는 50단계 하에서 MS-COCO 256\\(\\times\\)256 벤치마크에 대한 FID, Inception Score 및 CLIP 스코어(Hessel et al., 2021)를 보고한다. 1개의 RTX 3090에서 1개의 영상을 생성하여 시간 비용을 측정하였으며, 소형 모델과 대형 모델로 각각 BK-SDM Tiny와 SDv1.4를 채택하였다. ToMe의 경우 0.5의 토큰 병합 비율을 채택한다.\n' +
      '\n' +
      '도 22: T-Stitch와 ToMe를 결합한 이미지 예(Bolya et al., 2023). 우리는 T-Stitch의 작은 모델로 BK-SDM Tiny를 채택하고 이미지 상단에 백분율을 보고한다. 모든 이미지는 디퓨저(von Platen et al., 2022)에서 기본 설정에 의해 생성된다(von Platen et al., 2022): 가이드 스케일이 7.5인 50단계. ToMe에서 0.5의 토큰 병합 비율을 채택한다.\n' +
      '\n' +
      '도 23: DiT-S 및 DiT-XL 상의 T-스티치의 이미지 예. 유도척도가 4.0인 DDIM과 100단계를 채택하였으며, 좌측에서 우측으로 갈수록 LDM-S 단계의 분율을 점진적으로 증가시킨 후, 원래의 LDM이 나중에 잡음제거 단계를 처리하도록 하였다.\n' +
      '\n' +
      '도 24: U-Net 기반 LDM 및 LDM-S 상의 T-스티치의 이미지 예. 유도척도가 3.0인 DDIM과 100단계를 채택하였으며, 좌측에서 우측으로 갈수록 LDM-S 단계의 분율을 점진적으로 증가시킨 후, 원래의 LDM이 나중에 잡음제거 단계를 처리하도록 하였다.\n' +
      '\n' +
      '도 25: Stable Diffusion v1.4 및 BK-SDM Tiny 기반의 T-Stitch. 우리는 이미지 위에 BK-SDM 파벌에 주석을 달았다.\n' +
      '\n' +
      '도 26: Inkpunk-Diffusion SD a BK-SDM Tiny 기반의 T-Stitch. 우리는 이미지 위에 BK-SDM 파벌에 주석을 달았다.\n' +
      '\n' +
      '도 27: Ghibli-Diffusion SD 및 BK-SDM Tiny 기반의 T-Stitch. 우리는 이미지 위에 BK-SDM 파벌에 주석을 달았다.\n' +
      '\n' +
      '그림 28: 안정적인 확산 v1.4 및 BK-SDM 타이니에 기반한 보다 복잡한 프롬프트를 갖는 T-스티치. 우리는 이미지 위에 BK-SDM 파벌에 주석을 달았다.\n' +
      '\n' +
      '도 29: SDXL(Podell et al., 2023) 및 SSD-1B(Segmind, 2023)에 기초한 보다 복잡한 프롬프트를 갖는 T-Stitch. 우리는 이미지 위에 SSD-1B의 비율에 주석을 달았다. RTX 3090에서 하나의 영상을 생성하여 시간 비용을 측정한다.\n' +
      '\n' +
      '그림 30: SDXL 기반 ControlNet을 사용한 T-Stitch. 우리는 이미지 위에 SSD-1B의 파벌에 주석을 달았다. 하나의 RTX 3090에 하나의 영상을 생성하여 시간 비용을 측정한다.\n' +
      '\n' +
      '도 31: 안정한 확산 v1.4 및 BK-SDM 타이니를 기반으로, 우리는 하나의 GPU 상에서 **8 연속 런**(a for-loop)에 대한 BK-SDM의 상이한 분율에 의해 이미지를 생성한다. T-Stitch는 강인한 영상 생성을 위해 안정적인 성능을 보여준다. 디지털 버전으로 가장 잘 보고 확대합니다.\n' +
      '\n' +
      '도 33: 증류된 모델에 기초한 T-스티치: **4 샘플링 단계** 하에서 LCM-SDXL(Luo et al., 2023) 및 LCM-SSD-1B(Luo et al., 2023)이다. 우리는 이미지 위에 LCM-SSD-1B의 부분에 주석을 달았다. 시간 비용은 RTX 3090에서 밀리초 단위로 하나의 이미지를 생성함으로써 측정된다.\n' +
      '\n' +
      '도 32: 증류된 모델에 기초한 T-스티치: **2 샘플링 단계** 하에서 LCM-SDXL(Luo et al., 2023) 및 LCM-SSD-1B(Luo et al., 2023)이다. 우리는 이미지 위에 LCM-SSD-1B의 부분에 주석을 달았다. 시간 비용은 RTX 3090에서 밀리초 단위로 하나의 이미지를 생성함으로써 측정된다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>