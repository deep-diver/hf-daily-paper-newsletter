<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# FAX: JAX에서 확장가능하고 미분가능한 연합 프리미티브\n' +
      '\n' +
      ' 키이스 러쉬 재커리 찰스 & 재커리 개럿\n' +
      '\n' +
      'Google Research\n' +
      '\n' +
      'WA USA 시애틀\n' +
      '\n' +
      '{krush,zachcharles,zachgarrett}@google.com\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '우리는 데이터 센터와 교차 장치 애플리케이션 모두에서 대규모 분산 및 연합 계산을 지원하도록 설계된 JAX 기반 라이브러리인 FAX를 제시한다. FAX는 JAX의 샤딩 메커니즘을 활용하여 Pathways(Barham et al., 2022)를 포함한 TPU 및 최신 JAX 런타임의 네이티브 타겟팅을 가능하게 한다. FAX는 연합 연산을 위한 빌딩 블록을 JAX의 프리미티브로 임베딩한다. 이를 통해 세 가지 주요 이점이 가능합니다. 첫째, FAX 계산은 XLA HLO로 변환될 수 있다. 둘째, FAX는 연합 자동 미분(Rush et al., 2023)의 완전한 구현을 제공하며, 연합 연산들의 표현을 크게 단순화한다. 마지막으로 FAX 계산은 기존의 생산 교차 장치 연합 계산 시스템으로 해석될 수 있다. 우리는 FAX가 데이터 센터에서 연합 계산을 위해 쉽게 프로그래밍 가능하고 수행 가능하며 확장 가능한 프레임워크를 제공한다는 것을 보여준다. FAX는 [https://github.com/google-research/google-research/tree/master/fax](https://github.com/google-research/google-research/tree/master/fax)에서 이용할 수 있다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '추상적으로 작성된 컴퓨팅 집약 프로그램을 대규모 분산 컴퓨팅 환경에 걸쳐 확장할 수 있는 능력은 현대 기계 학습(ML)의 성공에 중요한 요소이다. 이것은 종종 단일 컴퓨팅 노드에 맞추기에 너무 큰 큰 언어 모델을 포함하는 ML 계산에 중요하다. 현대 ML 소프트웨어의 또 다른 핵심 측면은 계산이 작성되고 최적화될 수 있는 일반적인 용이성이다. 자동 차별화(AD) 및 Just-in-time(JIT) 컴파일과 같은 기술은 PyTorch(Paszke et al., 2019), TensorFlow(Abadi et al., 2016), JAX(Bradbury et al., 2018)와 같은 프레임워크가 더 크고 복잡한 ML 워크로드로 확장될 수 있게 했다.\n' +
      '\n' +
      '본 연구에서는 이러한 장점인 샤딩, 사용하기 쉬운 JIT 컴파일 및 AD를_federated learning_(FL)에 사용되는 계산 유형에 제공하는 소프트웨어 라이브러리 FAX를 설명한다. FL은 클라이언트가 데이터를 공유하지 않고 ML 태스크에서 협업하는 분산 학습 패러다임이다. 이는 우리가 _federated computationations_라고 지칭하는 FL에 대한 컴퓨테이션들이 종종 주기적 동기화(McMahan et al., 2017)와 병행하여 많은 클라이언트 트레이닝 모델들을 수반한다는 것을 의미한다.\n' +
      '\n' +
      'FL 애플리케이션은 온-디바이스 클라이언트(예를 들어, 크로스-디바이스 FL(Kairouz et al., 2021))를 포함할 수 있지만, 수행 데이터 센터 소프트웨어는 여전히 중요하다. 첫째, 데이터 센터에서 거의 전적으로 수행되는 FL 연구를 가속화할 수 있다. 둘째, FL 알고리즘은 특정 학습 목표를 위해 데이터 센터에서 사용될 수 있다. 예를 들어, FL 알고리즘은 이종 데이터 소스를 통해 메타 학습(Finn et al., 2017)할 수 있거나(Jiang et al., 2019; Charles et al., 2023), 차등 프라이버시와 결합하여 그룹 레벨 프라이버시 보장을 획득할 수 있다(McMahan et al., 2018). 마지막으로 프로덕션 FL은 데이터 센터 시뮬레이션을 사용하여 프로덕션으로 변환할 알고리즘을 결정하는 것을 포함할 수 있다. 이러한 프로세스는 종종 복잡하고, 데이터 센터 및 생산 시스템 기대치에서의 미스매치가 어려울 수 있다(Minec et al., 2023). 연합 계산을 위한 이상적인 저작 표면은 수행 가능하고 확장 가능한 데이터 센터 계산, 쉽고 확장 가능한 알고리즘 표현, 생산 연합 시스템으로 자동 번역 등 여러 기능을 동시에 제공한다.\n' +
      '\n' +
      '본 논문에서는 데이터 센터에서 확장 가능한 분산 및 연합 연산을 정의하기 위한 라이브러리인 FAX를 제시한다. FAX는 연합 프로그래밍 모델(섹션 2)을 JAX의 프리미티브 메커니즘(섹션 3)을 통해 JAX에 내장한다. 이를 통해 FAX는 샤딩 및 JIT 컴파일과 같은 강력한 기능을 XLA에 사용할 수 있습니다. 예를 들어, FAX는 디바이스의 물리적 및 논리적 메시에 걸쳐 클라이언트, 모델 및 클라이언트 내 데이터에 걸쳐 동시에 계산을 샤드할 수 있다. FAX는 또한 GSPMD(Xu et al., 2021) 및 Pathways(Bahram et al., 2022)와 같은 분산 데이터 센터 훈련의 발전을 활용할 수 있다. JAX의 프리미티브 메커니즘은 또한 순방향 및 역방향 모드 분화를 가능하게 한다. FAX는 이를 활용하여 연합 자동 차별화(Federated Automatic Differentiation, 연합 AD) 프레임워크의 완전한 구현을 제공한다(Rush et al., 2023). 이를 통해 사용자는 데이터 위치에 대한 정보를 보존하면서 연합 계산을 통해 구별할 수 있다.\n' +
      '\n' +
      '섹션 4에서 위의 이점을 경험적으로 강조하여 FAX가 언어 모델의 효율적이고 확장 가능한 연합 교육을 가능하게 함을 보여준다. 마지막으로, 섹션 5에서 FAX 계산이 보나위츠 외(2019) 및 폴릭 외(2021)에 의해 논의된 것과 같은 생산 FL 시스템에서 사용 가능한 파이썬 독립 계산 그래프로 해석될 수 있음을 보여준다. FAX의 디자인은 jax.grad와 같은 기능적 변형이 FAX의 능력을 XLA HLO로 낮추거나 생산 FL 시스템으로 단계적으로 유지하는 것을 보장한다.\n' +
      '\n' +
      '연합 학습 및 그 이상이다. 우리는 FL을 사용하여 시스템 설계, 구현 및 FAX의 API에 대한 논의를 고정하지만 FAX는 데이터 센터에서 광범위한 ML 계산을 표현, 샤드 및 실행하는 데 사용할 수 있다. 이는 FedAvg(McMahan et al., 2017), FedOpt(Reddi et al., 2020), branch-train-merge(Li et al., 2022), DiLoCo(Douillard et al., 2023), 및 PAPA(Jolicoeur-Martineau et al., 2023)를 포함하는 많은 병렬 및 분산 알고리즘을 포함한다. FAX는 데이터 최소화를 필요로 하지 않거나 이질적인 데이터에 대해 동작하지 않는 알고리즘을 포함하는 광범위한 계산에 유용하다.\n' +
      '\n' +
      '관련 작업.연합 학습을 목표로 하는 많은 프레임워크가 FAX보다 앞서 있다. 철저하게 하려는 의도 없이, 이러한 프레임워크는 적어도: TensorFlow-Federated (Ingerman and Ostrowski, 2019); PySytf (Ziller et al., 2021); FedJAX (Ro et al., 2021); FedScale (Lai et al., 2022); FedML (He et al., 2020); Flower (Beutel et al., 2020); FLUTE (Dimitriadis et al., 2022); FL_Pytorch (Burlachenko et al., 2021); FATE (Liu et al., 2021); 및 기타를 포함한다. 이러한 프레임워크는 최적화 연구자부터 데이터를 공유하지 않고 모델을 협력적으로 훈련하고자 하는 기업에 이르기까지 다양한 청중과 애플리케이션을 대상으로 한다.\n' +
      '\n' +
      '이러한 각 프레임워크는 고유한 장점을 가지고 있지만 FAX에 대한 동기는 세 가지 동시 욕구에 고정되어 있으며, 이는 우리가 아는 한 이러한 프레임워크 중 어느 것도 동시에 충족되지 않는다. (1) 대규모 모델에 대한 확장 가능한 데이터 센터 성능(현대 표준에 따르면 심지어 로드하는 데 수십 또는 수백 기가바이트의 메모리가 소요될 수 있는 모델을 의미함), (2) 연합 AD 구현, (3) 모바일 장치에서 연합 계산을 실행하는 생산 시스템으로 가는 경로.\n' +
      '\n' +
      '##2 시스템 설계\n' +
      '\n' +
      'FAX는 두 가지 핵심 아이디어를 염두에 두고 설계되었습니다. 먼저, 대부분의 연합 연산은 텐서플로우 연합(Ingerman and Ostrowski, 2019)의 프로그래밍 모델에서 도출된 관찰인, 이미 통합된 서브루틴에서 분산 ML 워크로드로 구축될 수 있다. FL과 ML을 구별하는 것은 데이터가 어디에 살고 어떤 서브루틴이 개인 정보 보호 장치를 필요로 하는지에 대한 회계이다. 둘째, 이 데이터 위치 어카운팅에 표준 AD 기법(예: 계산 그래프(Bauer, 1974))을 결합하여 연합 AD(Rush et al., 2023)를 구현할 수 있다. 연합형 프로그래밍 모델 및 데이터 위치 계정의 심도 있는 논의는 (Charles et al., 2022; Rush et al., 2023)을 참조한다.\n' +
      '\n' +
      '이 회계를 수행하기 위해 FAX는 _federated values_에서 작동한다. 이 값은 데이터 위치와 결합된 값이며 값의 _placement_라고 합니다. 우리는 클라이언트 배치와 서버 배치의 두 가지 배치를 고려합니다. 주어진 계산에는 잠재적으로 많은 클라이언트들이 참여한다고 가정하지만, 단지 하나의 서버일 뿐이다.1 우리는 \\(\\textit{v@P}\\)에 의해 연합된 값을 나타내며, 여기서 \\(P\\in\\textit{v@P}\\)은 데이터베이스에 있는 클라이언트의 수이다. 우리는 데이터베이스의 클라이언트 수를 \\(\\textit{v@P}\\)로 표시한다.\n' +
      '\n' +
      '\\(\\{C,S\\}\\)는 클라이언트와 서버 배치를 각각 나타낸다. \\(v@S\\)은 단일톤이고, \\(v@C\\)은 다치이다. 클라이언트 집합이 주어졌을 때 \\(M\\)은 \\(\\{v_{i}:i\\in M\\}\\)에 대해 \\(v@C\\)은 속기이다.\n' +
      '\n' +
      '연합 연산은 입력과 출력이 연합된 값인 함수이다. 이러한 기능은 임의 함수일 수 있지만 지도 축소 프레임워크에서 영감을 얻은 중요한 하위 클래스에 초점을 맞춘다. Rush 등(2023)은 다음의 연합 계산으로부터 구축될 수 있는 연합 계산을 고려하며, 이는 우리가 **연합된 빌딩 블록**이라고 지칭함:\n' +
      '\n' +
      '1. Federated_broadcast: 서버-배치된 값을 모든 클라이언트에 브로드캐스트한다. 따라서 \\(\\texttt{federated\\_broadcast}(x@S)=x@C\\).\n' +
      '2. federated_map: 주어진 배치에서 모든 값에 비-federated 함수 \\(f\\)를 적용하여 그들의 배치를 보존한다. 따라서 \\(\\texttt{federated\\_map}(f,x@P)=f(x)@P\\)가 된다.\n' +
      '3. 연합_sum: 클라이언트-배치된 값을 합하고, 서버-배치된 값을 반환한다. 따라서 \\(\\texttt{federated\\_sum}(x@C)=\\left(\\sum_{i\\in M}x_{i}\\right)@S\\이다.\n' +
      '\n' +
      '이러한 빌딩 블록들로부터 구축된 연합 계산들의 클래스는 FedAvg(McMahan et al., 2017)를 포함하는 대부분의 연합된 관심 알고리즘들을 포함한다. Rush et al.(2023)은 AD를 이 클래스로 확장한다. 이들 빌딩 블록으로부터 연합 연산 \\(f:x@S\\to y@S\\)을 구축하면, 동일한 빌딩 블록을 사용하여 \\(\\nabla f:x@S\\to dy_{/d}x@S\\)을 계산할 수 있음을 보여준다. 더욱이, 이것은 연합되지 않은 AD를 신중한 배치 조작과 결합하여 연합된 AD를 생성함으로써 프로그램 방식으로 수행될 수 있다.\n' +
      '\n' +
      '이것은 우리의 주요 관찰로 이어진다: 만약 우리가 위의 빌딩 블록들을 적절한 방식으로 JAX에 내장한다면, 우리는 (1) 수행 데이터 센터 런타임들에 의해 수용되는 데이터 구조들에 대한 연합 계산들을 낮출 수 있고, (2) JAX의 AD에 적절하게 위임함으로써 연합 AD를 구현할 수 있으며, (3) 생산 FL 시스템으로 번역을 가능하게 하기 위해 데이터 위치 정보를 보존할 수 있다. FAX는 이 작업을 수행하여 JIT 호환 방식으로 빌딩 블록을 JAX에 삽입한다. FAX는 또한 연합된 빌딩 블록들의 자코비안-벡터 및 벡터-자코비안 제품들의 구현들을 제공한다. 이를 통해 FAX는 JAX의 순방향 및 역방향 모드 AD에 위임함으로써 연합된 계산에서 순방향 및 역방향 모드 AD를 수행할 수 있다.\n' +
      '\n' +
      '**작성 표면** FAX 코드는 두 가지 일반적인 예외를 제외하고 거의 전적으로 JAX 코드이다. 먼저, 위의 연합된 빌딩 블록들이 있다. 둘째, FAX 코드는 계산 호출 중에 클라이언트가 몇 명인지 지정해야 합니다. 이를 보기 위해 모든 클라이언트에게 단순히 값을 브로드캐스트하는 Snippet 1의 코드를 고려하며, 클라이언트는 두 배의 값을 가지며, 클라이언트보다 합을 취한다.\n' +
      '\n' +
      '```\n' +
      'defbroadcast_double_and_sum(x): y=fax.federated_broadcast(x)#Sendxtoallclients. z=fax.federated_map(lambdaa:2*a,y)#Eachclientcomputes2*x. returnfax.federated_sum(z)#Sumoverclients,returns2*num_clients*x.\n' +
      '```\n' +
      '\n' +
      '스니펫 1: 불완전 FAX 프로그램입니다. 프로그램은 원하는 결과를 정확하게 계산하려면 클라이언트 수를 알아야 합니다.\n' +
      '\n' +
      '결과를 계산하려면 FAX가 고객이 몇 명인지 알아야 합니다. 사용자는 FAX 프로그램에 이 정보를 제공해야 합니다. 예를 들어, 스니펫 2는 클라이언트 수에 대한 명시적인 정보를 포함하도록 스니펫 1을 수정한다.\n' +
      '\n' +
      '```\n' +
      'defbroadcast_double_and_sum(x): y=fax.federated_broadcast(x)#Sendxtoall3clients. z=fax.federated_map(lambdaa:2*a,y)#Eachclientcomputes2*x. returnfax.federated_sum(z)#Sumoverclients,returns6*x.\n' +
      '```\n' +
      '\n' +
      '스니펫 2: 데코레이터가 클라이언트 수를 지정하는 기본 FAX 프로그램입니다.\n' +
      '\n' +
      '## 3 Implementation\n' +
      '\n' +
      '이제 JAX에서 FAX의 구현, 특히 그것이 연합 값을 나타내는 방법에 대해 논의하고 해당 값에 대한 연합 계산을 구현한다. 또한 FAX 계산이 데이터 센터 런타임에 걸쳐 효과적으로 공유되도록 보장하는 방법과 FAX가 연합 AD를 구현하는 방법에 대해 논의한다. 위의 연합 프로그래밍 모델에 초점을 맞추지만 FAX의 하위 구현은 훨씬 더 일반적인 분산 및 계층적 처리 및 샤딩 패턴에 사용할 수 있다.\n' +
      '\n' +
      '연합된 값. 우리는 먼저 연합된 배열을 나타낸다. FAX는 이러한 배열을 배치를 나타내는 추가 차원이 있는 배열로 나타낸다. 배열의 첫 번째 치수는 배치의 기본값입니다. 따라서, 서버-배치된 어레이는 카디널리티의 여분의 리딩 축을 갖는 반면, 클라이언트-배치된 어레이는 클라이언트의 수와 동일한 카디널리티의 여분의 리딩 축을 갖는다. \\((n+1)\\)차원 배열이 주어지면, \\(i\\)번째 성분 \\(x[i,...]\\)은 \\(i\\)번째 클라이언트에 의해 유지되는 \\(n\\)차원 배열이다. 그림 2는 이 표현의 예를 보여준다.\n' +
      '\n' +
      '모든 JAX 값은 본질적으로 FAX가 앞으로 전달하는 리프 노드가 어레이인 구조로 표시된다. 연합 구조는 배치된 배열의 구조이다. 연합 구조는 혼합 배치를 허용하지 않으므로 모든 잎 배열은 동일한 크기의 앞축을 가져야 한다. 예를 들어, 도 2는 다수의 리프 어레이를 갖는 클라이언트-배치 구조의 예를 제공하며, 이들 모두는 동일한 리딩 차원을 갖는다.\n' +
      '\n' +
      '연합된 계산.연합된 값은 JAX 배열로 표시되므로 FAX를 통해 정의된 연합된 계산은 JAX 배열에서 작동한다. 확장성, 데이터 센터 성능 및 연합 AD 구현 능력과 같은 FAX의 다른 목표는 FAX가 어레이에서 어떻게 작동하는지 알려준다. 우리는 JAX의 프리미티브 메커니즘을 활용하여 이를 동시에 해결한다.\n' +
      '\n' +
      '간략히 설명하자면 FAX는 데코레이터 설치 시간에 위의 연합된 빌딩 블록을 정의한다. 이러한 빌딩 블록들은 JAX에서 기능 변환에 의해 _symbolically_ 처리된다. FAX는 이러한 변환의 작용에 따라 이러한 연산자의 행동을 등록하여 JAX에 필요한 정보를 (1) XLA HLO에 도매로 더 낮은 FAX 정의 함수, (2) 최대 효율적인 방식으로 중간 텐서를 샤드하고 (3) JIT 컴파일 및 미분을 포함하는 작업에서 FAX 코드가 포함된 변환 JAX 함수에 제공한다.\n' +
      '\n' +
      '위의 연합된 값들의 표현을 감안할 때, 우리는 간단한 어레이 동작들을 통해 연합된 빌딩 블록들을 구현할 수 있다:\n' +
      '\n' +
      '1. Federated_broadcast: 그것의 선행 축 위에 어레이를 타일링한다.\n' +
      '2. 연합_map: 함수의 점을 어레이의 앞 축에 걸쳐 적용한다.\n' +
      '3. 연합_sum: 그것의 앞 축에 걸친 어레이를 합한다.\n' +
      '\n' +
      '이를 잎으로 적용하여 연합 배열 구조로 확장한다. FAX는 이러한 구현들을 JAX 하강 로직에 등록한다. 이것은 FAX 코드가 JAX가 XLA 런타임에 로직을 디스패치하는 시간만큼 JAX 코드로 완전히 대체되는 것을 보장한다. 다른 빌딩 블록들은 유사한 방식으로 프리미티브들을 등록함으로써, 또는 위의 빌딩 블록들의 관점에서 정의함으로써 FAX에 추가될 수 있다. 예를 들어, FAX는 클라이언트들에 걸쳐 평균을 취하는 연합_mean 심볼을 제공하며, 이는 연합_sum에 대한 두 개의 호출들로 낮아진다.\n' +
      '\n' +
      'FAX 계산들을 분할한다. 위의 프리미티브들을 등록함으로써, 우리는 GSPMD(Xu et al., 2021)와 같은 컴파일러들이 디바이스들에 걸쳐 FAX 계산들을 분할할 수 있음을 보장한다. 그러나 분할 계산이 가능한 한 효율적인지 확인하고 싶습니다. 많은 연합 연산들이 사소하게 병렬화될 수 있는 반면(예를 들어, 연합_map), 컴파일러들은 이러한 사용 패턴을 검출하고 효율적인 코드를 생성할 수 없을 수 있다. 그러나 위의 빌딩 블록이 컴파일러에 의해 어떻게 섀딩되는지에만 집중하면 됩니다. 이 작업이 완료되면 다양한 JAX 라이브러리에서 제공하는 모델 및 데이터 병렬성으로 자유롭게 구성할 수 있다.\n' +
      '\n' +
      'Xu et al. (2021) 및 Lepikhin et al. (2020)에 의해 언급된 바와 같이, 내부 샤딩 주석들은 분산 실행을 목표로 하는 컴파일러의 성능에 극적으로 영향을 미칠 수 있다. FAX는 정적 및 동적 샤딩 제약 조건을 사용하여 컴파일 후 결과 계산이 데이터 센터에서 효율적으로 실행되도록 합니다. 섹션 4에서 볼 수 있듯이 이러한 주석 없이 GSPMD와 같은 컴파일러는 특히 클라이언트의 수가 증가함에 따라 FAX 계산을 최적으로 샤드하지 않는다.\n' +
      '\n' +
      '연합 자동 차별화.연합된 빌딩 블록을 JAX 프리미티브로 임베딩하는 마지막 이점은 연합 AD를 구현하는 간단한 방법을 제공한다는 것이다. 우리는 이러한 프리미티브에 대한 벡터-자코비안 제품(VJP)과 자코비안-벡터 제품(JVP)의 작용을 정의하기만 하면 된다. Rush et al.(2023)은 이러한 제품들을 계산하는 방법을 논의하고, 그들의 계산이 어떠한 새로운 연합 빌딩 블록도 필요로 하지 않는다는 것을 보여준다. 즉, 이러한 프리미티브들의 JVP들 및 VJP들은 동일한 프리미티브들의 집합으로 표현될 수 있다. JVP 및 VJP를 사용하면 이제 JAX의 AD에 전적으로 의존하여 이러한 프리미티브를 포함하는 계산에서 순방향 및 역방향 모드 AD를 수행할 수 있다. 자세한 내용은 섹션 5를 참조하십시오.\n' +
      '\n' +
      '##4 확장성 및 효율성\n' +
      '\n' +
      '이제 FAX의 확장성과 효율성에 대한 수치적 증거를 제시한다. 우리는 3억 5천만(350M), 10억(1B), 80억(8B) 매개 변수를 가진 변압기 언어 모델에 대해 여러 라운드의 FedAvg를 수행한다. 우리는 인과 언어 모델링 손실과 512의 시퀀스 길이를 사용하며, 코호트의 각 클라이언트는 8의 배치 크기로 자신의 데이터에 대해 4개의 로컬 SGD 단계를 수행한다. 우리는 Dataset Grouper(Charles et al., 2023)를 통해 FedCCNews 데이터세트에 대해 훈련한다. 실험의 규모를 설명하기 위해 표 1에는 처리된 최대 토큰 수와 각 모델에 대해 라운드당 업데이트된 모델 매개변수가 포함되어 있다.\n' +
      '\n' +
      '그림 3: 배치된 배열에서 작동하는 FAX 빌딩 블록의 상위 수준 묘사입니다.\n' +
      '\n' +
      '모든 실험에 대해 우리는 일부 수의 TPUv2에 대한 훈련 계산을 공유한다. TPU 칩의 총 수는 항상 코호트 크기\\(M\\)의 배수이다. 350M, 1B, 8B 모델의 경우 각각 \\(M\\), \\(4M\\), \\(8M\\) 칩을 사용한다. 이것은 우리가 코호트 크기를 두 배로 늘리면 사용된 TPU 칩의 수도 두 배로 늘린다는 것을 의미한다. 우리는 \\(M\\) 클라이언트에 걸친 계산을 완전히 조각내고, 추가로 1B 및 8B 모델에 대해 모델 병렬화를 수행한다. 모든 실험에 대해, 우리의 FAX 계산은 먼저 GSPMD(Xu et al., 2021)를 사용하여 컴파일된 다음 Pathways 런타임(Barham et al., 2022)에 위임된다.\n' +
      '\n' +
      '약 스케일링.시스템의 약 스케일링_은 워크로드와 컴퓨팅 리소스가 동시에 스케일링됨에 따라 컴퓨팅 시간이 어떻게 변화하는지를 나타낸다. 일반적으로, 현대의 ML 시스템은 거의 일정한 약한 스케일링 성능을 얻기 위해 시도한다.2 FAX의 경우 클라이언트당 계산된 로컬 SGD 단계의 모델 크기와 수를 고정하고 워크로드 크기를 변경하기 위해 코호트 크기를 변경한다. 위에서 논의한 바와 같이, 우리는 시뮬레이션에 사용된 TPU 칩의 수를 코호트 크기와 관련하여 선형적으로 스케일링한다.\n' +
      '\n' +
      '각주 2: 동기화 비용 등의 오버헤드로 인해 일반적으로 일정한 성능이 불가능하다.\n' +
      '\n' +
      '그림 4는 FAX 기반 FedAvg의 훈련 시간이 범위 모델 크기에 걸쳐 TPU 칩의 코호트 크기와 수가 증가함에 따라 어떻게 확장되는지 보여준다. FAX는 128 또는 512의 코호트 크기까지 고정된 모델 크기에 대해 거의 일정한 런타임을 보여준다. FedAvg는 코호트에 걸친 병렬 모델 트레이닝을 포함하기 때문에, 클라이언트당 여러 단계에 대해 라운드당 워크로드 크기(총 부동 소수점 연산 측면에서)는 적어도 \\(4\\times\\)(모델 크기)\\(\\times\\)(코호트 크기)만큼 크다. 이를 보려면 각 라운드에서 각 클라이언트는 자체 로컬 모델을 4회 업데이트합니다. 표 1에 나타난 바와 같이, 각 모델 크기에 대한 가장 큰 워크로드는 라운드당 1조 개 이상의 모델 파라미터를 업데이트하는 것을 포함한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c} \\hline \\hline\n' +
      '**Model Size** & **Cohort Size** & **Tokens per Round** & **FLOPs per Round** \\\\ \\hline\n' +
      '350M & 2048 & \\(3.355\\times 10^{7}\\) & \\(2.293\\times 10^{13}\\) \\\\\\\n' +
      '1B & 512 & \\(8.389\\times 10^{6}\\) & \\(1.638\\times 10^{13}\\) \\\\\n' +
      '8B & 128 & \\(2.097\\times 10^{6}\\) & \\(3.277\\times 10^{13}\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 각 모델 크기에 대해 FedAvg로 훈련할 때 최대 코호트 크기, 처리된 토큰 수 및 총 부동 소수점 연산(FLOP) 단순화를 위해, 우리는 크기\\(M\\) 모델의 순방향 패스가 \\(M\\) FLOP를 사용하는 근사치를 사용하여 순방향 패스와 관련된 FLOP만 제시한다.\n' +
      '\n' +
      'JIT 컴파일만으로는 충분하지 않습니다.ML 연구는 종종 맞춤형 트레이닝 루프를 작성하는 것을 포함합니다. FL 연구의 경우, 이것은 종종 코호트의 클라이언트와 각 클라이언트가 보유한 배치에 걸쳐 반복하는 이중 포 루프를 작성함으로써 수행된다. 여기서 외부 루프는 데이터 의존성이 없으며, 이는 이 루프의 반복에 의해 반환되는 값이 다음 반복에 대한 입력으로서 처리되지 않음을 의미한다. 따라서 충분히 발전된 컴파일러가 이 사실을 감지하고 가능한 경우(예: 데이터 센터 환경의 리소스 제약 내에서) 클라이언트 교육을 병렬화할 수 있다고 상상할 수 있다.\n' +
      '\n' +
      '이것은 컴파일러에게 어려운 작업이 될 수 있다. 이러한 어려움을 설명하기 위해 FAX 기반 교육(클라이언트 위, 각 클라이언트의 데이터 위) 대신 더블 포 루프를 구현했다. 두 프로그램에 대해 JIT로 프로그램을 컴파일하고 GSPMD와 XLA 컴파일러 스택에 동일한 입출력 샤드를 제공했다. 이 스택은 상당히 발전되어 많은 최신 ML 모델을 훈련하는 데 사용되지만 이 루프 구현을 위한 FAX의 성능을 회복하지 못한다. 실제로, 라운드 런타임은 일정하게 유지되기보다는 예상대로 코호트 크기에 따라 선형적으로 확장되며, 이는 실험에 할당된 증가된 자원 규모를 사용할 수 없음을 나타낸다.\n' +
      '\n' +
      'GSPMD만으로는 충분하지 않다. 위의 포루프 접근법보다 연합 연산을 병렬화하는 더 나은 방법은 FAX의 빌딩 블록을 구현하고 프로그램의 자동화된 샤딩을 수행하기 위해 GSPMD(Xu et al., 2021)와 같은 컴파일러를 사용하는 것이다. 이것은 질문으로 이어진다: 약한 스케일링 동작을 얻기 위해 FAX의 내부 샤딩 주석이 필요한가, 아니면 GSPMD 단독으로 FAX 계산을 완전하고 효율적으로 병렬화할 수 있는가? FedAvg의 병렬 처리 패턴(자주 동기화되지 않는 대규모 병렬 모델 학습)의 비교적 단순한 특성을 감안할 때 특수하게 설계된 샤딩 주석을 가진 프리미티브로 연합된 빌딩 블록을 분리하는 것은 불필요하게 복잡할 것으로 예상할 수 있다.\n' +
      '\n' +
      '이를 테스트하기 위해 FedAvg의 FAX 기반 구현을 취하고 기능 추적 시간에 FAX의 내부 샤딩 주석을 모두 제거하여 이 FAX-NS(샤딩이 없는 FAX)를 나타낸다. 그런 다음 그림 4의 시뮬레이션을 다시 실행했다. 도 6은 현재 이러한 명시적인 샤딩 주석이 FAX의 약한 스케일링 행동을 보장하는 데 중요한 역할을 한다는 것을 보여준다. FAX-NS 계산 시간은 FAX 계산 시간보다 하위 선형적으로 증가했지만 훨씬 더 빨랐다. 또한, FAX-NS는 메모리 풋프린트 스케일링 문제를 나타냈다. 충분히 큰 모델 또는 코호트 크기에 대해 FAX-NS가 결국 고대역폭 메모리가 소진되었음을 발견했다. 특히, 이것은 512의 코호트 크기를 갖는 1B 모델과 모든 시험된 코호트 크기를 갖는 8B 모델, 즉 2명의 클라이언트 이상에서 발생했다.\n' +
      '\n' +
      '그림 6: 다양한 코호트 크기를 갖는 1B 모델에 대한 100 라운드의 FedAvg에 대한 총 훈련 시간. FAX-NS FAX의 샤딩 주석이 있거나 없는 FAX를 사용하여 FedAvg를 구현한다. 빨간색 X는 FAX-NS가 메모리 오류를 트리거하지 않고 샤딩될 수 없는 지점을 나타낸다.\n' +
      '\n' +
      '##5 FAX를 생산 플랫폼으로 해석\n' +
      '\n' +
      '데이터 센터 성능이 FAX의 주요 목표이지만 FAX 계산을 생산 FL 시스템에서 해석할 수 있는 아티팩트로 변환하는 옵션을 보존하고자 한다. 예를 들어, 연합_sum이 단지 jnp.sum으로서 캡처되는 경우, 이 합이 _within_ a placement(예를 들어, 서버에 배치된 값들의 합을 취함) 또는 플레이스먼트들 사이(예를 들어, 클라이언트들에 걸쳐 합을 취함 및 결과를 전달하는 것)로 의도되는지 여부를 구별하는 것이 어려울 수 있다. 아래에서는 FAX의 구현이 프로덕션 플랫폼으로 자동 번역될 수 있는 컴퓨팅 프로그램 표현을 어떻게 가능하게 하는지에 대해 논의한다.\n' +
      '\n' +
      '배치 정보를 보존.위에서 연합된 빌딩 블록을 JAX 프리미티브로 구현하고 이러한 프리미티브로부터 FAX 계산을 구축한다는 것을 상기한다. 이것은 다운스트림 생산 시스템과 통합하는 데 중요한 마지막 핵심 이점인 가치의 연합 배치에 대한 정보를 보존하는 능력과 시스템을 통해 전달되는 방법을 가지고 있다.\n' +
      '\n' +
      'JAX의 프리미티브 메커니즘은 사용자가 JAX 자체에 새로운 기호를 주입할 수 있도록 하여 jax.vmap 및 jax.grad와 같은 JAX의 기능적 변환 하에서 이러한 기호가 어떻게 작동하는지를 정의한다. 이러한 프리미티브는 JAX의 중간 데이터 구조인 jaxpr에 보존되며 일반적으로 XLA HLO로 낮아진다. 맞춤형 통역기를 사용하면 대신 jaxpr을 생성하고 소비할 수 있습니다. 이 사용자 정의 해석기는 원시 메커니즘을 통해 주입된 FAX 정의 기호를 만날 때 특수 동작을 사용할 수 있다. 이는 데이터 배치 및 장치 통신 패턴에 대한 정보를 보존하여 jaxpr을 생산 FL 플랫폼에 의해 실행될 수 있는 계산으로 변환할 수 있다.\n' +
      '\n' +
      '예제 jaxpr은 예시적인 것이다. 스니펫 3에서는 "연합 손실"을 계산하기 위한 FAX 프로그램을 정의하며, 서버는 모든 클라이언트에 모델을 브로드캐스트하고 각 클라이언트는 자체 데이터로 모델의 손실을 계산하고 서버는 평균 손실을 수신한다.\n' +
      '\n' +
      '```\n' +
      '@fax.fax_program(placements={"clients":1}) deffederated_loss(model, cohort): broadcast_model=fax.federated_broadcast(model)#Broadcastamodeltoclients client_losses=fax.federated_map_clients(#Clientslocallycomputelosses loss_fn,(broadcast_model, cohort)) returnfax.federated_mean(client_losses#Sendtheaveragelosstotheserver\n' +
      '```\n' +
      '\n' +
      '스니펫 3: FAX 프로그램을 사용하여 연합 손실 함수를 계산하는 것.\n' +
      '\n' +
      '이 처리 패턴을 나타내는 jaxpr을 얻기 위해 구체적인 인수의 형태와 유형을 제시한다. 우리의 예에서, 모델은 형상 [2]의 플로트 벡터이고, 코호트는 형상 [1, 2]의 플로트 벡터이므로 단일 클라이언트만 존재한다. 상기 loss_fn 함수는 단순화된 선형 회귀 손실로서, 설명 목적으로만 사용되며, 이에 의해 정의되는\n' +
      '\n' +
      '\\[\\texttt{loss\\_fn}(x,y):=\\frac{1}{2}(\\langle x,y\\rangle-1)^{2}.\\]\n' +
      '\n' +
      '이러한 정보를 고려할 때, JAX 및 FAX는 Snippet 3을 나타내는 jaxpr을 생성할 수 있다. 그 결과는 Snippet 4에 있다. 주요 테이크아웃은 이 jaxpr이 JAX에 FAX에 의해 등록된 프리미티브인 크로스 머신 통신을 나타내는 FAX 정의 프리미티브, broadcast_clients 및 mean_from_clients를 보존한다는 것이다. 우리는 jaxpr의 인수들을 통해 계산이 (1) 클라이언트들에게 값을 방송하고, (2) 방송 값들을 이용하여 loss_fn을 계산하고, (3) 상기 클라이언트들에 대한 평균을 취함으로써 동작함을 알 수 있다. FL은 클라이언트들이 직접 통신하는 것을 허용하지 않기 때문에, 이 평균 연산의 결과는 명확하다: 서버가 배치된 값을 산출해야 한다.\n' +
      '\n' +
      'TensorFlow Federated(Ingerman and Ostrowski, 2019)와 같은 생산 FL 시스템으로 jaxpr을 해석하는 것은 이제 간단하다: 모든 교차 기계 통신은 명시적이며, 사이 통신은 완전히 로컬이며 시스템 내의 장치에 의해 로컬로 실행되는 독립형 기능으로 추출될 수 있다.\n' +
      '\n' +
      '```\n' +
      '{lambda;a:f32[2]b:f32[1,2].let c:f32[1,2]=broadcast_clientsa d:f32[1]=dot_general[ dimension_numbers=(([1], [1], [0], [0]))) preferred_element_type=float32]cb e:f32[1]=subd1.0 f:f32[1]=subd1.0 f:f32[1]=integer_pow[y=2]e g:f32[1]=mul0.5f h:f32[1]=mean_from_clientsg in(h,}\n' +
      '```\n' +
      '\n' +
      '통합 연합 AD. 섹션 2에서 논의된 바와 같이 프리미티브 메커니즘은 FAX가 정방향 및 역방향 모드 자코비안(jax.jacfwd 및 jax.jacrev)을 계산하는 것을 포함하여 JAX의 기능적 변환 하에서 연합된 빌딩 블록의 동작을 지정할 수 있도록 한다. 이것은 FAX가 (Rush et al., 2023)에 제시된 순방향 및 역방향 모드 연합 AD 알고리즘을 완전히 구현할 수 있게 한다.\n' +
      '\n' +
      'Rush et al.(2023)은 섹션 2의 연합된 빌딩 블록들이 순방향 및 역방향 모드 자동 미분 하에서 폐쇄 세트를 형성한다는 것에 주목한다. 예를 들어, Federated_broadcast의 순방향 및 역방향 모드 Jacobians는 각각 Federated_broadcast 및 Federated_sum을 통해 계산될 수 있다. 따라서 FAX는 추가 프리미티브 없이 연합 AD를 구현할 수 있다. 이것은 연합 AD를 사용하는 FAX 계산의 jaxpr이 FAX의 프리미티브 집합과 함께 JAX의 표준 AD 심볼을 포함할 것임을 의미한다. 이것은 연합 AD를 사용한 계산이 여전히 생산 FL 시스템에 대해 해석될 수 있음을 보장한다.\n' +
      '\n' +
      '예를 들어, Snippet 5는 위의 연합 손실 계산의 역 모드 미분인 jax.grad(federated_loss)의 jaxpr을 제공한다. 다시, 우리는 시스템의 통신에 대한 정보가 보존된다는 것을 안다. jaxpr은 프리미티브 broadcast_clients, mean_from_clients 및 sum_from_clients를 포함하며, 위와 같이 사용자 정의 해석기에 의해 jaxpr을 생산 시스템으로 번역하기 위해 사용될 수 있다.\n' +
      '\n' +
      '```\n' +
      '{lambda;a:f32[2]b:f32[1]=dot_general[ dimension_numbers=(([1], [1]]=broadcast_clientsa d:f32[1]=broadcast_clients1.0 k:f32[1]=div1.0 f:f32[1]=mul0.5k m:f32[1]=dot_general[ dimension_numbers=(([], [0], [0]))) preferred_element_type=float_clientsn in(o,)}\n' +
      '```\n' +
      '\n' +
      '스니펫 5: grad_fn=jax.grad(federated_loss)에 대해 생성된 jaxpr.\n' +
      '\n' +
      '## 6 Discussion\n' +
      '\n' +
      '확장성 및 효율성과 같은 기능은 자명하지만 판독기는 특히 생산 시스템에 해석하는 데 필요한 주의를 감안할 때 연합 AD를 구현하고자 하는 _why_에 관심이 있을 수 있다. 요컨대, 연합 AD는 효율적인 알고리즘을 표현하는 것을 더 용이하게 한다(Rush et al., 2023). 유추에 의해, AD는 정교한 신경망 아키텍처의 개발을 상당히 용이하게 만들었다. 라이브러리는 개념적으로 더 간단한 전진 패스를 정의할 수 있으며 역전파를 수행하기 위해 AD에 의존할 수 있다. 결과는 종종 손으로 구현되는 그래디언트 컴퓨테이션들(Baydin et al., 2018)보다 더 빠르고 덜 에러가 발생하기 쉽다.\n' +
      '\n' +
      'FL 알고리즘 개발은 유사한 이점을 볼 수 있다. 예를 들어, Snippet 3에는 클라이언트에 대한 평균 손실을 계산하는 데 사용되는 FAX 프로그램이 포함되어 있습니다. 간단하게 jax.grad(federated_loss)를 호출함으로써, 우리는 즉시 클라이언트에 대한 평균 그래디언트를 계산하는 FAX 프로그램을 얻는다. 이를 통해, 서버에서 최적화 단계(예를 들어, Optax(DeepMind et al., 2020))를 수행하고, 즉시 FedSGD 알고리즘을 획득할 수 있다(McMahan et al., 2017). 스니펫 6은 jax.grad를 그래디언트 업데이트와 페어링하여 전체 FedSGD 알고리즘을 정의하는 것을 정확하게 그린다.\n' +
      '\n' +
      '```\n' +
      '@fax.fax_program(placements=("clients":3)) deffed.sgd_step(model, cohort, opt_state): server_grad=jax.grad(federated_loss)(model, cohort)#Computeagradient update,opt_state=optimizer.update(server_grad, opt_state) model=optax.apply_updates(model, update)#Applythemodelupdate returnmodel,opt_state\n' +
      '```\n' +
      '\n' +
      '스니펫 6: 연합 AD를 통해 FedSGD를 구현한다.\n' +
      '\n' +
      '연합 AD는 연합된 하이퍼그래디언트 하강과 같은 알고리즘, 및 클라이언트에 걸쳐 평균을 가중하는 방법을 학습하는 알고리즘을 가능하게 한다(Rush et al., 2023). 연합 AD는 또한 차분 프라이버시 및 보안 집성과 같은 프라이버시-보존 메커니즘과의 호환성을 보존한다(Bonawitz et al., 2017). 모든 FL 알고리즘이 연합 AD(FedAvg, 참조(Charles and Rush, 2022)를 통해 직접 표현될 수 있는 것은 아니지만, 우리는 연합 AD의 사용하기 쉬운 구현이 FL에서 알고리즘 개발 및 연구를 가속화할 수 있다고 믿는다.\n' +
      '\n' +
      'FFL에 대한 반복적인 참조에도 불구하고 FAX 및 연합 AD는 데이터 센터 내부 또는 외부에서 보다 일반적인 병렬 및 분산 ML에 사용할 수 있다. 연합 AD가 FL 알고리즘 개발을 돕는 것처럼, 우리는 그것이 대규모 분산 알고리즘 개발에 도움이 될 수 있다고 믿는다. 예를 들어, 서버와 클라이언트 간의 통신을 포함하는 임의의 알고리즘을 통해 구별하는 데 사용될 수 있다. 이렇게 하면 자체 조정 분산 알고리즘, 모듈형 구성 요소에 걸친 분산 학습, 위치 전반에 걸친 명시적 커뮤니케이션이 포함된 모델 아키텍처와 같은 작업에 대한 문이 열립니다.\n' +
      '\n' +
      '결론. 연합된 AD를 JAX를 통해 사용하기 쉬운 프런트 엔드와 페어링하고, 수행적 연합된 빌딩 블록 구현 및 유용한 샤딩 정보를 제공함으로써 분산 및 병렬 ML에 대한 연구를 가속화할 수 있기를 바란다. 향후 작업에는 (1) 연합 AD의 비선형 통신 프리미티브로의 일반화, (2) 계층적 데이터 배치를 포함한 보다 일반적인 데이터 배치로의 FAX 확장 및 (3) 특정 생산 시스템에 대한 성숙한 FAX 해석기가 포함된다.\n' +
      '\n' +
      '## Acknowledgments\n' +
      '\n' +
      '저자들은 원고에 대한 귀중한 피드백에 대해 니콜 미첼, 션 오겐슈타인, 브렌던 맥마한에게 감사하고 싶다. 우리는 Nicole과 Sean이 FAX에서 스트레스 테스트와 연합 알고리즘 개발에 더 많은 도움을 준 것에 대해 더 감사드리고 싶습니다. JAX에 대한 유익한 논의에 야쉬 카타리야, 임현택, 샤라드 비크람, 로이 프로스티그, 매튜 존슨에게도 감사드린다. 마지막으로 FAX를 생산 플랫폼으로 해석하는 데 도움을 주신 샤오유 씨에게 감사드립니다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Abadi et al. (2016) Martin Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek Gordon Murray, Benoit Steiner, Paul A. Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, Xiaoqiang Zheng. 텐서플로우: 대규모 기계 학습을 위한 시스템. Kimberly Keeton and Timothy Roscoe, editors, _12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016, Savannah, GA, USA, November 2-4, 2016_, pages 265-283. USENIX Association, 2016. URL[https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi](https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi].\n' +
      '* 2022_9월 1일. mlsys.org, 2022. URL[https://proceedings.mlsys.org/paper/2022/hash/98dece83da5fb0395e163467c9dae521b-Abstract.html](https://proceedings.mlsys.org/paper/2022/hash/98dece83da5fb0395e163467c9dae521b-Abstract.html).\n' +
      '* 바우어(1974) 프리드리히 L 바우어. 계산 그래프와 반올림 오차. _ SIAM Journal on Numerical Analysis_, 11(1):87-96, 1974.\n' +
      '* Baydin et al. (2018) Atilim Gunes Baydin, Barak A. Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind. 기계 학습의 자동 감별: 설문 조사. _ Journal of Machine Learning Research_, 18(153):1-43, 2018. URL[http://jmlr.org/papers/v18/17-468.html](http://jmlr.org/papers/v18/17-468.html)이다.\n' +
      '* Beutel et al. (2020) Daniel J. Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet, and Nicholas D. Lane. 꽃: 우호적인 연합 학습 연구 프레임워크. _ CoRR_, abs/2007.14390, 2020. URL[https://arxiv.org/abs/2007.14390](https://arxiv.org/abs/2007.14390).\n' +
      '* 2019_. 4. 2. mlsys.org, 2019. URL[https://proceedings.mlsys.org/book/271.pdf](https://proceedings.mlsys.org/book/271.pdf).\n' +
      '* Bonawitz et al. (2017) Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcodone, H Brendan McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth. 프라이버시 보존 기계 학습을 위한 실용적인 보안 집계입니다. 2017 ACM SIGSAC Conference on Computer and Communications Security_의 _proceedings, pages 1175-1191, 2017.\n' +
      '* Bradbury et al. (2018) James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs, 2018. URL[http://github.com/google/jax](http://github.com/google/jax).\n' +
      '* Burlachenko et al. (2021) Konstantin Burlachenko, Samuel Horvath, and Peter Richtarik. FL_PyTorch: 연합 학습을 위한 최적화 연구 시뮬레이터. _Proceedings of the 2nd ACM International Workshop on Distributed Machine Learning_, pages 1-7, 2021.\n' +
      '* Charles and Rush (2022) Zachary Charles and Keith Rush. 연합 학습으로의 응용 프로그램과 함께 반복된 벡터 필드 및 보수성. Sanjoy Dasgupta and Nika Haghtalab, editors, _Proceedings of the 33rd International Conference on Algorithmic Learning Theory_, volume 167 of _Proceedings of Machine Learning Research_, pages 130-147. PMLR, 29 Mar-01 Apr 2022. URL[https://proceedings.mlr.press/v167/charles22a.html](https://proceedings.mlr.press/v167/charles22a.html).\n' +
      '* Charles et al. (2022) Zachary Charles, Kallista Bonawitz, Stanislav Chiknavaryan, Brendan McMahan, et al. Federated select: primitive for communication-and memory-efficient federated learning. _ arXiv preprint arXiv:2208.09432_, 2022.\n' +
      '* Chen et al. (2019) Zachary Charles, Nicole Mitchell, Krishna Pillutla, Michael Reneer, and Zachary Garrett. 연합 기반 모델을 향한: 그룹 구조 학습을 위한 확장 가능한 데이터세트 파이프라인. Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, Editors, _Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023_, 2023. URL [http://papers.nips.cc/paper_files/paper/2023/hash/662bb54dc59eaac8e7c0d3fc6a0add-Abstract-Datasets_and_Benchmarks.html](http://papers.nips.cc/paper_files/paper/2023/hash/662bb54dc59eaac8e7c0d3fc6a0add-Abstract-Datasets_and_Benchmarks.html](http://papers.nips.cc/paper_files/paper/2023/hash/662bb\n' +
      '* Mind et al. (2020) DeepMind, Igor Babuschkin, Kate Baumli, Alison Bell, Surya Bhupatiraju, Jake Bruce, Peter Buchlovsky, David Budden, Trevor Cai, Aidan Clark, Ivo Danihelka, Antoine Dedieu, Claudio Fantacci, Jonathan Godwin, Chris Jones, Ross Hemsley, Tom Hennigan, Matteo Hessel, Shaobo Hou, Steven Kemaev, Euri Kemaev, Michael King, Lena Martens, Hamza Merzic, Vladimir Mikulik, Tamara Norman, George Papamakarios, John Quan, Roman Ring, Francisco Ruiz, Alvaro Sanchez, Laureant Sartran, Eren Sezener, Stephen Spencer, Srivatsan Srinivasan, Milos Stanojevic, Luyu Wang, Guangyao Zhou, and Fabio Viola. DeepMind JAX Ecosystem, 2020. URL[http://github.com/google-deepmind](http://github.com/google-deepmind].\n' +
      '* Dimitriadis et al. (2022) Dimitrios Dimitriadis, Mirian Hipolito Garcia, Daniel Madrigal Diaz, Andre Manoel, and Robert Sim. FLUTE: 고성능 연합 학습 시뮬레이션을 위한 확장 가능하고 확장 가능한 프레임워크. _ CoRR_, abs/2203.13789, 2022. doi: 10.48550/ARXIV.2203.13789. URL[https://doi.org/10.48550/arXiv.2203.13789](https://doi.org/10.48550/arXiv.2203.13789).\n' +
      '* Douillard et al. (2023) Arthur Douillard, Qixuang Feng, Andrei A. Rusu, Rachita Chhaparia, Yani Donchev, Adhiguna Kuncoro, Marc\'Aurelio Ranzato, Arthur Szlam, and Jiajun Shen. Diloco: 언어 모델의 분산 저통신 훈련. _ CoRR_, abs/2311.08105, 2023. doi: 10.48550/ARXIV.2311.08105. URL[https://doi.org/10.48550/arXiv.2311.08105](https://doi.org/10.48550/arXiv.2311.08105).\n' +
      '* Finn et al. (2017) Chelsea Finn, Pieter Abbeel, and Sergey Levine. 딥 네트워크의 빠른 적응을 위한 모델 진단 메타 학습 _International conference on machine learning_, pages 1126-1135. PMLR, 2017.\n' +
      '* He et al. (2020) Chaoyang He, Songze Li, Jinhyun So, Mi Zhang, Hongyi Wang, Xiaoyang Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, Li Shen, Peilin Zhao, Yan Kang, Yang Liu, Ramesh Raskar, Qiang Yang, Murali Annavaram, and Salman Avestimehr. Fedml: 연구 라이브러리 및 연합 머신 러닝의 벤치마크, 07 2020.\n' +
      '* Ingerman and Ostrowski (2019) Alex Ingerman and Krzysztof Ostrowski. Tensorflow Federated, 3월 2019. URL[https://blog.tensorflow.org/2019/03/introducing-tensorflow-federated.html](https://blog.tensorflow.org/2019/03/introducing-tensorflow-federated.html)을 소개한다.\n' +
      '* Jiang et al. (2019) Yihan Jiang, Jakub Konecny, Keith Rush, and Sreeram Kannan. 모델 불가지론적 메타 학습을 통한 연합 학습 개인화 개선. _ CoRR_, abs/1909.12488, 2019. URL[http://arxiv.org/abs/1909.12488](http://arxiv.org/abs/1909.12488).\n' +
      '* Jolicoeur-Martineau et al. (2023) Alexia Jolicoeur-Martineau, Emy Gervais, Kilian Fatras, Yan Zhang, and Simon Lacoste-Julien. PopulAtion Parameter Averaging (PAPA) _ arXiv preprint arXiv:2304.03094_, 2023.\n' +
      '* Kairouz et al. (2021) Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Foundations and trends(r) in machine learning_, 14(1-2):1-210, 2021.\n' +
      '* Lai et al. (2022) Fan Lai, Yinwei Dai, Sanjay S. 싱가푸람, 지아첸 류, 상펑 주, 하샤 V. Madhyastha와 Mosharaf Chowdhury. FedScale: 벤치마킹 모델 및 규모의 연합학습의 시스템 성능. In _International Conference on Machine Learning (ICML)_, 2022.\n' +
      '* Lepikhin et al. (2020) Dmitry Lepikhin, Hyouk중 Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, 및 Zhifeng Chen. GShard: 조건부 계산과 자동 샤딩으로 거대 모델을 스케일링하는 것; _ CoRR_, abs/2006.16668, 2020. URL[https://arxiv.org/abs/2006.16668](https://arxiv.org/abs/2006.16668).\n' +
      '* Liu et al. (2019)Margaret Li, 수친 Gururangan, Tim Dettmers, Mike Lewis, Tim Althoff, Noah A Smith, and Luke Zettlemoyer. Branch-train-merge: 전문가 언어 모델의 당황스러울 정도로 병렬적인 훈련. _ ArXiv:2208.03306_, 2022.\n' +
      '* Liu et al. (2021) Yang Liu, Tao Fan, Tianjian Chen, Qian Xu, 및 Qiang Yang. 운명: 데이터 보호를 통한 협력 학습을 위한 산업 등급 플랫폼. _ Journal of Machine Learning Research_, 22(226):1-6, 2021. URL[http://jmlr.org/papers/v22/20-815.html](http://jmlr.org/papers/v22/20-815.html).\n' +
      '* McMahan et al.(2017) Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguiera y Arcas. 탈중앙화된 데이터로부터 심층 네트워크의 통신 효율적인 학습. Aarti Singh and Xiaojin(Jerry) Zhu, editors, _Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017, 20-22 April 2017, Fort Lauderdale, FL, USA_, volume 54 of _Proceedings of Machine Learning Research_, pages 1273-1282. PMLR, 2017. URL[http://proceedings.mlr.press/v54/ncmahan17a.html](http://proceedings.mlr.press/v54/ncmahan17a.html).\n' +
      '* 5월 3일, 2018, Conference Track Proceedings_. OpenReview.net, 2018. URL[https://openreview.net/forum?id=BJ0hF120b](https://openreview.net/forum?id=BJ0hF120b)이다.\n' +
      '* 16, 2023_, 2023. URL[http://papers.nips.cc/paper_files/paper/2023/hash/42c40aff7814e9796266e12053b1c610-Abstract-Conference.html](http://papers.nips.cc/paper_files/paper/2023/hash/42c40aff7814e9796266e12053b1c610-Abstract-Conference.html)\n' +
      '* Paszke et al. (2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Kimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Z. 양, 재커리 드비토, 마틴 레이슨, 알리칸 테자니, 사생크 칠암쿠르티, 베노이트 스타이너, 루팡, 준제 바이, 그리고 수미트 친탈라. 파이토치: 명령적인 스타일, 고성능 딥러닝 라이브러리. 한나 M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d\'Alche-Buc, Emily B. Fox, and Roman Garnett, Editors, _Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada_, pages 8024-8035, 2019. URL[https://proceedings.neurips.cc/paper/2019/hash/bdbca288fe7f92f2bfa9f7012727740-Abstract.html](https://proceedings.neurips.cc/paper/2019/hash/bdbca288fe7f92f2bfa9f7012727740-Abstract.html](https://proceedings.neurips.cc/paper/2019/hash/bdbca288fe7f9227740-Abstract.html)\n' +
      '* Paulik et al. (2021) Matthias Paulik, Matt Seigel, Henry Mason, Dominic Telaar, Joris Kluivers, Rogier C. van Dalen, Chi Wai Lau, Luke Carlson, Filip Granqvist, Chris Vandevelde, Sudeep Agarwal, Julien Freudiger, Andrew Byde, Abhishek Bhowmick, Gaurav Kapoor, Si Beaumont, Aine Cahill, Dominic Hughes, Omid Javidbakht, Fei Dong, Rehan Rishi, and Stanley Hung. 온-디바이스 개인화를 위한 연합 평가 및 튜닝: 시스템 설계 및 애플리케이션_ CoRR_, abs/2102.08503, 2021. URL[https://arxiv.org/abs/2102.08503](https://arxiv.org/abs/2102.08503).\n' +
      '* Reddi et al. (2020) Sashank J Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konecny, Sanjiv Kumar, and Hugh Brendan McMahan. 적응형 연합 최적화 _International Conference on Learning Representations_, 2020.\n' +
      '* Ro et al. (2021) Jae Hun Ro, Ananda Theertha Suresh, and Ke Wu. FedJAX: 연합 학습 시뮬레이션과 JAX_ arXiv preprint arXiv:2108.02117_, 2021.\n' +
      '* Rush et al. (2023) Keith Rush, Zachary Charles, and Zachary Garrett. 연합 자동 미분법 _ arXiv preprint arXiv:2301.07806_, 2023.\n' +
      '* Xu et al. (2021) Yuanzhong Xu, Hyoukmedong Lee, Dehao Chen, Blake A. Hechtman, Yanping Huang, Rahul Joshi, Maxim Krikun, Dmitry Lepikhin, Andy Ly, Marcello Maggioni, Ruoming Pang, Noam Shazeer, Shibo Wang, Tao Wang, Yonghui Wu, and Zhifeng Chen. GSPMD: ML 계산 그래프에 대한 일반적이고 확장 가능한 병렬화 _ CoRR_, abs/2105.04663, 2021. URL[https://arxiv.org/abs/2105.04663](https://arxiv.org/abs/2105.04663).\n' +
      '* Xu et al. (2021) Alexander Ziller, Andrew Trask, Antonio Lopardo, Benjamin Szymkow, Bobby Wagner, Emma Bluemke, Jean-Mickael Nounahon, Jonathan Passerat-Palmbach, Kritika Prakash, Nick Rose, et al. Pysyft: easy federated learning을 위한 라이브러리. _ 연합 학습 시스템: 차세대 AI_, 페이지 111-139, 2021.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>