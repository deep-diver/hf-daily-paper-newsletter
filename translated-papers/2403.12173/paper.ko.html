<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# TnT-LLM: 대용량 언어 모델을 이용한 스케일에서의 텍스트 마이닝\n' +
      '\n' +
      'Mengting Wan\n' +
      '\n' +
      '본 문서에서 정보의 일부는 후속적으로 수정될 수 있는 사전 릴리즈된 콘텐츠에 관한 것이다. 마이크로소프트는 여기에 제공된 정보에 대해 명시적 또는 묵시적 영장을 제시하지 않는다. 이 문서는 "as-sr"로 제공된다. URL 및 기타 인터넷 웹 사이트 참조를 포함하여 이 문서에 표현된 정보 및 보기는 예고 없이 변경될 수 있습니다. 여기에 묘사된 일부 예시들은 단지 예시를 위해 제공되며 허구이다. 실제 연관이나 연결이 의도되거나 추론되어서는 안 된다. 이 문서는 마이크로소프트 제품 0 2024 마이크로소프트의 모든 지적 재산에 대한 법적 권리를 제공하지 않습니다. 모든 권한이 예약되어 있습니다.\n' +
      '\n' +
      'Tara Safavi\n' +
      '\n' +
      '수지 쿠마르 자하르솜\n' +
      '\n' +
      'Yuin Kim\n' +
      '\n' +
      'Scott Counts\n' +
      '\n' +
      'Jennifer Neville\n' +
      '\n' +
      'Siddharth Suri\n' +
      '\n' +
      'Chirag Shah\n' +
      '\n' +
      '솜원 화이트 화이트\n' +
      '\n' +
      'Longqi Yang\n' +
      '\n' +
      'Reid Andersen\n' +
      '\n' +
      'Georg Buscher\n' +
      '\n' +
      'Dhruv Joshi\n' +
      '\n' +
      'Nagu Rangan\n' +
      '\n' +
      'Microsoft Corporation\n' +
      '\n' +
      '워싱턴 대학교\n' +
      '\n' +
      '{mengting.wan,tarasafavi}@microsoft.com\n' +
      '\n' +
      '###### Abstract.\n' +
      '\n' +
      '비구조화된 텍스트를 유용한 범주 레이블로 구성된 구조화되고 의미 있는 형태로 변환하는 것은 다운스트림 분석 및 적용을 위한 텍스트 마이닝의 기본 단계이다. 그러나 레이블 분류기를 생산하고 텍스트 기반 레이블 분류기를 구축하는 대부분의 기존 방법은 여전히 도메인 전문 지식과 수동 큐레이션에 크게 의존하므로 프로세스가 비싸고 시간이 많이 소요된다. 레이블 공간이 지정되지 않고 대규모 데이터 주석을 사용할 수 없는 경우 특히 어렵습니다. 본 논문에서는 대규모 의사 레이블의 유도 및 사용을 용이하게 하는 신속한 기반 인터페이스인 LLM(Large Language Models)을 사용하여 이러한 문제를 해결한다. 우리는 주어진 사용 사례에 대해 _최소 인간 노력으로 종단 간 레이블 생성 및 할당 프로세스를 자동화하기 위해 LLM을 사용하는 2단계 프레임워크인 **TnT-LLM**을 제안한다. 첫 번째 단계에서는 LLM이 레이블 분류를 반복적으로 생성하고 정제할 수 있는 제로샷 다단계 추론 접근법을 소개한다. 두 번째 단계에서 LLM은 경량 감독 분류기가 안정적으로 구축, 배치 및 규모로 제공될 수 있도록 훈련 샘플을 산출하는 데이터 라벨러로 사용된다. 오픈 도메인 채팅 기반 검색 엔진인 빙 코파일럿(구 빙 채팅)에 대한 사용자 의도 및 대화 도메인 분석에 **TnT-LLM**을 적용한다. 인간 및 자동 평가 메트릭을 모두 사용한 광범위한 실험은 **TnT-LLM**가 최신 기준선과 비교할 때 더 정확하고 관련 라벨 분류를 생성하고 규모에서 분류에 대한 정확도와 효율성 사이의 유리한 균형을 달성한다는 것을 보여준다. 또한 실제 응용 프로그램에서 대규모 텍스트 마이닝을 위해 LLM을 사용하는 어려움과 기회에 대한 실제 경험과 통찰력을 공유한다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 마이크로소프트에서 일하면서 작업한다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '+\n' +
      '각주 †: 단검}\\) 교신저자.\n' +
      '\n' +
      '이러한 문제를 해결하기 위해 본 논문에서는 수동 접근법의 해석 가능성과 자동 텍스트 클러스터링 및 토픽 모델링의 척도를 결합한 새로운 프레임워크인 **TnT-LLM**을 제안한다. **TnT-LLM**은 조인트 **T**악소노미 **G**재생 ** 및 *텍스트 분류를 위한 엔드 투 엔드 2단계 프레임워크로, 두 단계 모두에서 대규모 언어 모델(**LLMs**)에 따른 수업의 고유한 강점에 의존한다. 먼저 분류 생성 단계에서 LLM이 주어진 사용 사례(예: 의도 탐지)에 대해 말뭉치와 관련하여 레이블 분류법을 반복적으로 생성하고 정제하도록 유도하는 제로 샷 다단계 추론 접근법을 고안한다. 둘째, 텍스트 분류 단계에서는 LLM을 데이터 증강기로 채택하여 학습 데이터 생성을 확대하고, 이를 통해 대규모 레이블링이 가능한 경량 분류기를 학습한다. 이 프레임워크는 적응 가능하고 모듈식이며, 인간의 개입이나 입력이 거의 필요하지 않으면서 다양한 사용 사례, 텍스트 코퍼스, LLM 및 분류기에 맞춤화될 수 있다. 요약하면, 우리의 주요 기여는 다음과 같다:\n' +
      '\n' +
      '* 대표적이고 해석 가능한 레이블로 분류 생성 및 텍스트 분류 프로세스를 자동화하고 확장하기 위한 종단 간 2단계 프레임워크인 **TnT-LLM**을 소개합니다.\n' +
      '* 우리는 _결정론적 자동_ 메트릭, _인간 평가_ 메트릭 및 _LLM 기반_ 평가를 포함하여 이 프레임워크의 각 단계를 검증하기 위한 일련의 정량화 및 추적 가능한 평가 전략을 제시한다.\n' +
      '* *TnT-LLM**을 사용하여 웹 스케일, 다국어, 오픈 도메인 대화 에이전트인 빙 코파일럿(이전 빙 채팅)의 대화를 분석한다. 본 연구의 결과는 제안된 프레임워크가 최신 텍스트 클러스터링 접근법에 비해 더 정확하고 관련성 있는 레이블 분류법을 생성할 수 있음을 보여준다. 또한 LLM 주석으로 훈련된 경량 라벨 분류기가 LLM을 분류기로 직접 사용하는 것보다 비교할 수 있는(및 때로는 더 나은) 성능을 달성할 수 있지만 확장성과 모델 투명성이 훨씬 더 높다는 것을 보여준다. 정량적, 정성적 분석을 통해 LLM을 대규모 텍스트 마이닝에 적용하기 위한 통찰력과 권장 사항을 제공한다.\n' +
      '\n' +
      '##2. 관련업무\n' +
      '\n' +
      '**분류 생성.**분류 생성의 이전 작업은 수동 및 자동 접근 방식에 해당합니다. 수작업 분류법은 구축 비용이 많이 드는 것을 넘어 특정 다운스트림 작업(예를 들어, 웹 검색 의도 분석(Han et al., 2017; Chen et al., 2018), 챗봇 의도 탐지(Tang et al., 2018))에 대해 개발되거나 특정 데이터 세트의 개발에 얽매이는 경향이 있다(Kang et al., 2019; Krizhevsky et al., 2019). 반면에 자동화된 접근법은 더 잘 확장되지만 레이블을 얻기 위해 말뭉치에서 용어 추출에 의존하여 해석 가능성 및/또는 범위를 방해할 수 있다(Krizhevsky et al., 2019; Wang et al., 2019) 또는 새로운 레이블을 생성하기 위해 분류법을 위한 종자 세트를 필요로 한다(Krizhevsky et al., 2019). 대조적으로,**TnT-LLM**는 자동적이고 추상적이며(즉, 라벨은 말뭉치를 설명하지만 그로부터 직접 추출될 필요는 없으며), 어떠한 종자 라벨도 필요하지 않다. 더욱이, **TnT-LLM**은 분류 생성 및 텍스트 분류를 종단 간 파이프라인에서 상호 관련된 문제로 취급하는 반면, 이전 작업은 분류를 위한 다운스트림 유용성을 고려하지 않고 생산된 분류의 품질에 주로 초점을 맞추는 경향이 있다.\n' +
      '\n' +
      '**텍스트 클러스터링 및 토픽 모델링.** 텍스트 클러스터링 및 토픽 모델링은 레이블 세트를 정의한 다음 말뭉치에 레이블을 적용하는 전통적인 접근법을 "반전"한다. 문서들의 세트가 주어지면, 그러한 접근법들은 먼저 텍스트 유사성의 다양한 정의들을 사용하여 문서들을 토픽 클러스터들로 그룹화한 다음, 사후 라벨링 또는 클러스터들을 요약한다(Han et al., 2017; Chen et al., 2018). 이론상 전통적인 접근법은 **TnT-LLM**와 동일한 목표를 달성하지만, 일반적으로 군집에 이해 가능한 레이블을 할당하지 않기 때문에 해석성의 부족으로 인해 어려움을 겪는다(Chen et al., 2018). 보다 최근에는 토픽 모델링(Krizhevsky et al., 2019; Wang et al., 2019)을 위한 LLM들을 사용함으로써 이러한 문제들을 극복하려는 시도들이 이루어지고 있지만, 이러한 접근법들은 여전히 미리 정의된 분류법(Wang et al., 2019) 또는 토픽들의 시드 세트(Krizhevsky et al., 2019)를 통한 감독을 필요로 한다.\n' +
      '\n' +
      '**LLMs as Annotators.** 최근 작업은 검색 관련성 품질 라벨링(Krizhevsky et al., 2019), 토픽 및 스탠스 검출(Chen et al., 2018) 및 다양한 계산 사회 과학 라벨링 작업(Wang et al., 2019)과 같은 노동 집약적 작업에 대한 인간 주석을 대체하기 위해 LLM을 사용하여 탐색했다. 이러한 연구는 일반적으로 LLM이 크라우드 워커(Krizhevsky et al., 2019)보다 동등하거나 훨씬 더 나은 성능을 종종 비용의 일부로 수행한다는 것을 발견했다. 같은 맥락에서 우리는 LLM의 레이블별 기능을 보다 효율적이고 가벼운 분류기로 증류하여 프로세스를 확장하는 것이 주요 목표이지만 LLM을 텍스트 분류를 위한 주석자로 사용하여 탐구한다.\n' +
      '\n' +
      '## 3. Method\n' +
      '\n' +
      '우리는 **TnT-LLM**에 대한 고수준의 개요, 1) **LLM 기반 분류 생성** 및 2) **LLM 기반 텍스트 분류**에 대해 제안된 2단계 프레임워크로 시작한다. 첫 번째 단계에서는 코퍼스의 소규모 대표 부분 집합을 샘플링하고 확률적 경사 하강(Beng et al., 2017)에서 영감을 받은 반복 방식으로 제로 샷 다단계 분류 생성을 수행한다. 두 번째 단계에서는 더 큰 데이터 세트를 샘플링하고 단계 1에서 생성된 분류법으로 LLM을 활용하여 각 인스턴스를 분류한다. 그런 다음 이러한 LLM 라벨은 경량 텍스트 분류기를 훈련시키기 위한 "의사-라벨"로 취급된다. 트레이닝이 완료되면, 경량 분류기는 전체 코퍼스를 오프라인으로 라벨링하도록 배치되고, 또한 온라인 실시간 분류를 위한 역할을 할 수 있다.\n' +
      '\n' +
      '### 1단계: 분류 생성\n' +
      '\n' +
      '**TnT-LLM**의 단계 1은 고전적인 혼합물 모델 클러스터링 프로세스(Krizhevsky et al., 2019)에서 영감을 얻었지만, 프롬프트 기반 방식으로 구현된다. 우리는 "확률적 최적화" 접근법(Krizhevsky et al., 2019)을 활용하여 중간 분류 결과를 반복적으로 업데이트하여 크고 역동적인 코퍼스 샘플을 효과적으로 처리할 수 있다. 분류법의 원하는 입도에 따라 이 단계에서 말뭉치를 대표하는 "중소" 말뭉치 샘플을 사용하여 샘플 크기가 말뭉치의 다양성을 포착하기에 충분하지만 불필요한 비용을 발생시키기에 너무 크지 않도록 제안한다.\n' +
      '\n' +
      '***단계 1: 요약.** 모든 텍스트 샘플을 정규화하고 가장 두드러진 정보를 추출하기 위해 먼저 샘플 내 각 문서의 간결하고 유익한 요약을 생성한다. 구체적으로, 요약에 대한 의도된 사용-케이스(예를 들어, 의도 검출) 및 목표 요약 길이(예를 들어, 20개 단어)에 대한 짧은 블럽을 제공함으로써 LLM이 각각의 문서를 요약하도록 프롬프트하고; 전체 프롬프트 템플릿은 보충 세부사항에서 도 8에 제공된다. 이 단계는 입력 문서의 크기와 변동성을 줄이는 동시에 사용 케이스와 가장 관련이 있는 문서의 측면을 추출하는 데 도움이 되며, 이는 표면 수준 의미론(예: 사용자 의도)에서 분명하지 않은 레이블 공간에 특히 중요하다. 이 단계는 GPT-3.5-터보처럼 비용 효율적인 LLM으로 각 입력 문서에 대해 동시에 실행될 수 있기 때문에 비교적 빠르다는 점에 유의한다.\n' +
      '**stage 2: Taxonomy Creation, Update, Review**. 다음으로 이전 단계의 요약을 사용하여 레이블 분류법을 만들고 정제한다. SGD와 유사하게 요약을 동일한 크기의 미니 배치로 나눈다. 그런 다음 세 가지 유형의 제로 샷 LLM 추론 프롬프트로 이러한 미니 배치를 순차적으로 처리한다. 첫 번째, _initial generation prompt_는 첫 번째 미니 배치를 취하고 출력으로서 초기 라벨 분류법을 생성한다. 두 번째, _탁소노미 업데이트 프롬프트_는 중간 라벨 탁소노미를 새로운 미니버치로 반복적으로 업데이트하고, 각 단계에서 세 가지 주요 작업을 수행한다: 1) 새로운 데이터에 대해 주어진 탁소노미를 평가하는 단계; 2) 평가에 기초하여 이슈 및 제안을 식별하는 단계; 및 3) 그에 따라 탁소노미를 수정하는 단계. 마지막으로, 분류법이 지정된 횟수만큼 갱신된 후, 출력 분류법의 포맷팅 및 품질을 검사하는 _review prompt_를 적용하고, 그 중 출력은 Stage 1에 의해 최종 분류법으로 간주된다. 세 가지 프롬프트 모두에서, 미니배치와 함께 원하는 라벨 분류법의 목표 및 포맷(예를 들어, 원하는 라벨 수, 라벨당 목표 워드 수)을 지정하는 사용-케이스 명령어를 제공한다. 전체 프롬프트 템플릿은 첨부 세부 정보의 그림 10에 나와 있다.\n' +
      '\n' +
      '이 과정이 자연스럽게 계층 구조에 적용된다는 점에 주목하라: 1차 분류법 생성 후 분류된 샘플의 각 하위 그룹에 대해 단계 2를 다시 실행하여 분류법에서 보다 세분화된 새로운 수준을 생성할 수 있다. 제안된 접근법의 개요는 그림 2에 나와 있다.\n' +
      '\n' +
      '**혼합물 모델에 대한 연결 및 확률적 최적화.** 여기서 텍스트 클러스터링을 위한 우리의 파이프라인과 혼합물 모델 패밀리(예를 들어, 가우시안 혼합물 모델) 사이의 유추를 제시한다. 각 텍스트 데이터 포인트 \\((x_{i})\\)는 혼합 분포 \\(x_{i}\\sim\\sum w_{k}\\mathcal{N}(\\mu_{k},\\Sigma_{k})\\)을 따르며, 여기서 \\(\\mathcal{N}(\\mu_{k},\\Sigma_{k})\\)는 \\(k\\)번째 성분의 분포, 즉 평균 \\(\\mu_{k}\\)과 분산 \\(\\Sigma_{k}\\)을 갖는 가우시안 분포를 정의한다. 코퍼스 샘플\\(\\{x_{i}\\}\\}\\)이 주어지면, 이 혼합물 모델은 로그 우도 손실의 음수를 최소화하는 것과 동등한 최대 우도 추정(MLE)을 통해 학습될 수 있다.\n' +
      '\n' +
      '{split}&\\max\\,\\prod_{i}\\Big{(}\\sum w_{k}\\mathcal{N}(\\mu_{k},\\Sigma_{k};x_{i})\\Big{}\\\\retrightarrow\\min\\,-\\sum_{i}\\log\\Big{(}\\sum w_{k}\\mathcal{N}(\\mu_{k},\\Sigma_{k};x_{i})\\Big{}\\Leftrightarrow\\min\\,\\sum_{i}\\mathcal{L}(\\theta,x_{i})\\end{split}\\tag{1}\\\\times\\times\n' +
      '\n' +
      '즉시 기반 접근법으로 다시 매핑하면 말뭉치 샘플과 사용 사례 명령을 입력으로 한다. 우리의 목표는 명령어와 관련이 있고 입력 말뭉치 샘플에 가장 잘 맞는 분류법을 "학습"하는 것이며, 이 분류법은 이름과 간단한 설명이 있는 범주 레이블로 구성되어야 한다. 우리는 혼합 모델의 정의에 따라 원하는 레이블 분류를 매개변수 집합\\(\\theta=\\{\\mathbf{\\mu},\\Sigma\\}\\)으로 나타낼 수 있으며, 여기서\\(\\mathbf{\\mu}=\\{\\mu_{k}\\}\\)은 "클러스터 중심"을 나타내는 레이블의 이름이고\\(\\Sigma=\\{\\Sigma_{k}\\}\\)은 군집\\(k\\)의 "모양"을 지정하는 설명이다. 이 연구에서 레이블 분류법을 생성하는 LLM에 의해 혼합 가중치\\((w_{k})\\)가 암시적으로 포착된다고 가정한다. 그런 다음 분류 생성 및 정제 단계를 확률적 최적화에 다음과 같이 매핑할 수 있다.\n' +
      '\n' +
      '**stage 1: Feature Representation.** 우리의 요약 단계는 고전적인 기계 학습의 featurization 단계와 유사하며, 여기서 원시 텍스트 입력은 임베딩 모델과 같은 특징 변환을 통해 벡터 공간에 투영된다. 우리의 경우, 각 데이터 포인트의 출력 요약은 원문 \\((x_{i})\\)의 간결하고 유익한 특징 표현으로 볼 수 있다.\n' +
      '***Stage 2: Stochastic Gradient Descent.** 주요 분류 생성 및 업데이트 단계는 Stochastic Gradient Descent(SGD)와의 프롬프트 최적화(Glorot et al., 2016)와 유사하며, 여기서 생성 프롬프트는 분류(즉, 파라미터 \\(\\Theta_{0}\\))를 초기화하기 위해 사용되며, 이는 이후 업데이트 프롬프트-체인을 통해 SGD를 통해 최적화된다. 각 업데이트 프롬프트에서 현재 분류법(\\(\\theta_{\\mathbf{m}}\\))이 주어진 데이터 배치(즉, Eq에 정의된 손실 함수 계산)에 어떻게 맞는지 평가한다. (1) 다음, 분류법을 갱신하기 위해 오류를 분석하고 "역전파"한다. 즉, \\(\\Theta_{m+1}=\\Theta_{m}-\\eta\\nabla\\mathcal{L}(\\Theta_{m})\\), 여기서 \\(\\eta\\)은 LLM에 의해 암시적으로 조정된다고 가정하는 학습률을 의미한다.\n' +
      '\n' +
      '### Phase 2: LLM-Augmented Text Classification\n' +
      '\n' +
      '분류법이 완성된 후, 우리는 다음으로 매우 대규모 및 실시간으로 라벨 할당을 수행하기 위해 안정적으로 배치될 수 있는 텍스트 분류기를 훈련시킨다. 학습 데이터의 주석자로서 LLM의 장점을 보여주는 최근 작업(Krizhevsky et al., 2015; Krizhevsky et al., 2015)에 이어, 우리는 LLM을 활용하여 "의사-표지된" 말뭉치 세트를 얻을 것을 제안한다.\n' +
      '\n' +
      '그림 2. LLM 구동 분류 생성 단계(1단계)의 그림이다.\n' +
      '\n' +
      '1단계에서 산출된 분류법을 사용한 다음 이러한 레이블을 사용하여 규모에서 보다 효율적인 분류기를 훈련한다. 구체적으로, LLM이 분류학에서 레이블의 범위를 포괄하는 "중대" 규모의 말뭉치 샘플에서 기본 레이블(다중 클래스 분류 작업으로서) 및 적용 가능한 모든 레이블(다중 레이블 분류 작업으로서)을 추론하도록 촉구하여 로지스틱 회귀 모델 또는 다층 퍼셉트론 분류기와 같은 경량 분류기를 구축하는 데 사용할 수 있는 대표적인 훈련 데이터 세트를 생성한다. 이러한 방식으로 LLM 분류기에서 "의사 라벨"을 유도하고 그 지식을 확장 및 서비스할 수 있는 보다 효율적이고 관리 가능한 모델로 전달할 수 있다. 이 단계의 예시적인 그림은 그림 3에 나와 있다.\n' +
      '\n' +
      '##4. 평가 스위트\n' +
      '\n' +
      '우리가 연구하는 문제의 감독되지 않은 특성과 벤치마크 표준의 부족으로 인해 종단 간 분류 생성 및 텍스트 분류에 대한 정량적 평가를 수행하는 것은 어려울 수 있다. 따라서 **TnT-LLM**을 평가하기 위한 일련의 전략을 설계한다. 우리의 평가 전략은 평가 기준의 유형과 출처에 따라 세 개의 버킷으로 분류될 수 있다. 세 가지 범주는 다음과 같다.\n' +
      '\n' +
      '**결정론적 자동 평가**: 이러한 유형의 접근법은 확장 가능하고 일관성이 있지만, 잘 정의된 금본위제 규칙 및 주석이 필요하다. 라벨 분류의 품질 및 유용성과 같은 본 논문에서 연구된 추상적인 측면을 평가하는 데 덜 적용가능하다.\n' +
      '***인간 평가**: 이러한 접근법들은 자동 평가들이 다루지 못하는 추상적인 측면들을 평가하는데 유용하다. 그러나, 그것들은 또한 시간이 많이 걸리고, 비용이 많이 들며, 데이터 프라이버시 및 컴플라이언스 제약에 직면할 수 있다.\n' +
      '**LLM 기반 평가**: 여기서, LLM은 인간 평가자와 동일하거나 유사한 작업을 수행하는 데 사용된다. 이러한 유형의 평가는 적절하게 적용되지 않으면 잠재적으로 편향 및 오류가 발생할 수 있지만 인간 평가보다 확장 가능하고 비용 효율적이다. 따라서 우리는 충분한 통계적 힘으로 결론을 추론할 수 있도록 작은 코퍼스에 대한 인간 평가 메트릭과 LLM 기반 평가를 결합하고 검증하는 것을 목표로 한다.\n' +
      '\n' +
      '##1단계 평가전략\n' +
      '\n' +
      '선행 연구(Wang et al., 2018; Wang et al., 2019)에 이어, 우리는 사용 사례 지침에 대한 커버리지, 정확도 및 관련성의 세 가지 기준에 따라 라벨 분류법을 평가한다. 이러한 메트릭을 적용하기 위해 _native_1차 레이블 할당을 구현해야 한다는 점에 유의한다. 클러스터링 기반 방법의 경우 클러스터링 알고리즘을 통해 인스턴스화된다. *TnT-LLM**의 경우, 이는 섹션 3.2에 설명된 바와 같이 라벨 할당 프롬프트에 의해 수행된다. 또한 여기에서 논의된 라벨 정확도 및 사용 사례 관련성 메트릭은 **인간** 및 **LLM** 평가자 모두에 적용 가능하다는 점에 유의한다.\n' +
      '\n' +
      '**분류 범위** 이 메트릭은 말뭉치에 대해 생성된 레이블 분류의 이해도를 측정합니다. 종래의 텍스트 클러스터링 접근법(예를 들어, 임베딩 기반 k-평균)은 종종 설계에 의해 100% 커버리지를 달성한다. LLM 기반 분류 생성 파이프라인에서 레이블 할당 프롬프트에 \'기타\' 또는 \'정의되지 않은\' 범주를 설계별로 추가하고 이 범주에 할당된 데이터 점의 비율을 측정한다. 이 비율이 낮을수록 분류 적용 범위가 높아진다.\n' +
      '\n' +
      '**라벨 정확성** 이 메트릭은 동일한 분류법의 다른 레이블에 비해 할당된 레이블이 텍스트 데이터 점을 얼마나 잘 반영하는지 정량화합니다. 혼합물 모델 클러스터링과 유사하게 기본 레이블은 텍스트가 주어졌을 때 가장 가능성이 높은 레이블이어야 한다. 우리는 인간과 LLM 평가자가 이름과 설명에 따라 라벨 적합성을 평가할 수 있다고 가정한다. 우리는 정확도를 쌍별 비교 작업으로 취급한다: 각 텍스트에 대해 동일한 분류법에서 기본 레이블과 무작위 부정 레이블을 얻고 평가자에게 이름과 설명을 기반으로 더 정확한 레이블을 선택하도록 요청한다.1 평가자가 긍정 레이블을 올바르게 식별하면 "히트"로 간주하고 평균 적중률을 레이블 정확도 메트릭으로 보고한다. 범주 레이블 간의 중첩을 명시적으로 평가하지 않으며 오히려 쌍별 레이블 정확도 메트릭에 암시적으로 반영될 것으로 예상한다.\n' +
      '\n' +
      '각주 1:레이터는 또한 쌍 외에 "없음" 옵션이 제공되지만 사용을 최소화하도록 지시됩니다.\n' +
      '\n' +
      '**사용 사례 명령과 관련.** 이 메트릭은 생성된 라벨 분류법이 사용 사례 명령과 얼마나 관련이 있는지 측정합니다. 예를 들어, "콘텐츠 생성"은 "대화에서 사용자 의도를 이해"하라는 명령과 관련이 있는 반면, "역사 및 문화"는 그렇지 않다. 이를 이진 평가 작업으로 운영합니다. 각 인스턴스에 대해 기본 레이블 이름과 설명을 인간 또는 LLM 평가자에게 제공하고 레이블이 지정된 사용 사례 명령과 관련이 있는지 여부를 결정하도록 요청합니다. 평가자에게 제시된 인스턴스를 컨텍스트로 사용하도록 지시하고 텍스트 입력의 일부 측면을 정확하게 설명하는 레이블의 능력에 조건화된 관련성을 평가합니다. 이 메트릭의 목표는 레이블 정확도를 평가하는 것이 아니라 사용 사례 명령과 관련이 있는 것처럼 보이지만 말뭉치 샘플과 관련이 없으므로 다운스트림 응용 프로그램에 쓸모가 없는 분류학에 의해 도입된 무작위성을 배제하는 것이다.\n' +
      '\n' +
      '##2단계 평가전략\n' +
      '\n' +
      '텍스트 분류를 정량적으로 평가하기 위해 다음과 같이 신뢰할 수 있는 지상-진실 주석이 있는 벤치마크 데이터 세트를 생성한다.\n' +
      '\n' +
      '**Task and Annotation Reliability.** 레이블 할당 작업 및 인간 주석의 신뢰도를 먼저 평가한다.\n' +
      '\n' +
      '도 3. LLM-증강 텍스트 분류 단계(Phase 2)의 예시.\n' +
      '\n' +
      '인간 주석을 여러 개 삽입하고 평가자 간 합의(두 평가자 간의 Cohen\'s Kappa(Cohen, 1998)와 여러 평가자 간의 Fleiss\' Kappa(Fleiss, 1998)를 계산한다. 그런 다음 투표 또는 심의를 통해 인간 주석 간의 불일치를 해결하고 각 인스턴스에 대해 합의된 인간 주석을 얻는다. 그런 다음 LLM을 추가 주석자로 사용하여 동일한 레이블 할당 작업을 수행하고 LLM 주석과 합의된 인간 레이블 간의 일치를 측정한다. 직관적으로, 이 합의는 LLM이 (대다수의) 인간 주석자와 얼마나 잘 정렬되고, 이 라벨 할당 작업에 대해 얼마나 신뢰할 수 있는지를 포착한다.\n' +
      '\n' +
      '**분류 메트릭.** 소규모 코퍼스 샘플에 인간 및 LLM 주석을 모두 적용하고 인간 주석을 지상 진실로 사용하여 기존의 다중클래스 및 다중 레이블 분류 메트릭(예: 정확도, F1)을 계산한다. 이러한 메트릭들은 라벨 분류기가 코퍼스의 작은 서브세트 상에서 인간 선호도와 어떻게 정렬되는지를 평가한다. 그런 다음 대규모 코퍼스 샘플에 LLM 주석기를 적용하고 결과 주석을 오라클로 활용하여 동일한 분류 메트릭을 계산한다. 이러한 메트릭들은 도메인들, 언어들, 및 시간 범위들과 같은 코퍼스의 상이한 양상들에 대한 스케일에서의 라벨 분류기 성능의 포괄적인 진단을 가능하게 한다.\n' +
      '\n' +
      '실제로, 우리는 작업 및 주석 신뢰성을 고려하면서 전체 평가 제품군으로 인간 평가 및 LLM 기반 메트릭을 모두 활용하는 것을 권장한다. 이 접근법은 방법 중 하나에서 발생하거나 작업 복잡성에 의해 영향을 받을 수 있는 가능한 편향을 식별하고 완화하고 평가 및 주석을 큰 말뭉치 샘플로 확증하여 보다 강력하고 유익한 평가 결과를 얻는 데 도움이 될 수 있다.\n' +
      '\n' +
      '## 5. Experiments\n' +
      '\n' +
      '우리는 오늘날의 LLM 시대에 특별한 관심의 두 가지 텍스트 마이닝 작업에 대한 **TnT-LLM**의 유용성을 보여준다: **사용자 의도 탐지** 및 **대화 도메인 레이블링**\n' +
      '\n' +
      '### Data\n' +
      '\n' +
      '대화 내용은 대화 경험을 통해 사용자를 지원하는 다국어 개방형 도메인 생성 검색 엔진인 마이크로소프트의 빙 컨슈머 코파일럿 시스템에서 가져옵니다. 우리는 8/6/2023에서 10/14/2023까지의 10주 간의 대화를 무작위로 샘플링하고 1단계에 대해 주당 1k개의 대화를 수행하며 라벨 분류, 검증 및 테스트를 각각 "학습"하기 위해 무작위 60%-20%-20% 분할을 수행한다. 그런 다음 2단계에 대해 동일한 시간 범위에서 주당 또 다른 5k 대화를 샘플링하고 동일한 열차/검증/테스트 데이터 분할을 적용한다.\n' +
      '\n' +
      '우리는 데이터의 품질과 프라이버시를 보장하기 위해 필터링의 두 단계를 수행한다. 먼저, 원본 대화 내용에서 모든 개인 정보(예: 주소, 전화번호)를 스크럽하는 사내 프라이버시 필터를 적용한다. 둘째, 주석이 노출되거나 다운스트림 분석에 노출되지 않아야 하는 유해하거나 부적절한 내용을 포함하는 모든 대화를 제거하는 내용 필터를 적용한다. 이 필터를 적용한 후 1단계에서 9,592개의 대화와 2단계에서 48,160개의 대화를 얻었으며, FastText 언어 검출기(Fleiss, 2016; Fleiss, 2017)를 활용하여 각 대화의 주요 언어를 식별하였으며, 말뭉치에서 대화의 약 절반이 영어로 되어 있다.\n' +
      '\n' +
      '이 섹션의 나머지 부분에서 다음 데이터 세트에 대한 결과를 보고할 것이다:\n' +
      '\n' +
      '* **BingChat-Phase1-L-MULTI**: 분류 생성 단계에서 사용되는 테스트 세트로서, 약 2k개의 대화를 포함한다.\n' +
      '* **BingChat-Phase2-L-MULTI**: 약 10k개의 대화를 포함하는, 라벨 할당 단계에서 사용되는 테스트 세트.\n' +
      '\n' +
      '또한 위의 데이터 세트 외에도 동일한 개인 정보 및 콘텐츠 필터가 적용된 인간 평가를 수행하기 위해 두 개의 개별 영어 전용 대화 데이터 세트를 예약한다.\n' +
      '\n' +
      '**BingChat-Phase1-S-Eng**에는 라벨 분류법을 평가하기 위한 200개의 영어 대화가 포함되어 있다.\n' +
      '**BingChat-Phase2-S-Eng**는 라벨 할당을 평가하기 위한 400개의 영어 대화를 포함한다.\n' +
      '\n' +
      '### Taxonomy Generation\n' +
      '\n' +
      '#### 5.2.1. Methods\n' +
      '\n' +
      '*TnT-LLM**의 효과를 평가하기 위해 그룹 대화에 임베딩 기반 군집링에 의존하는 기본 방법과 비교한 다음 LLM 생성 라벨을 각 군집에 할당한다. 레이블 생성기와 평가기로서 두 가지 최신 LLMs, **GPT-4(0613)** 및 **GPT-3.5-Turbo(0613)**를 사용하고, 두 가지 다른 임베딩 방법, **ada2**2 및 **Instructor-XL**(Yang et al., 2017)을 사용하여 대화를 표현한다. 우리의 실험에서 고려된 방법은 다음과 같다:\n' +
      '\n' +
      '각주 2: [https://openai.com/blog/new-and-proved-embedding-modal](https://openai.com/blog/new-and-proved-embedding-modal)\n' +
      '\n' +
      '***GPT-4(TnT-LLM)**: 레이블 분류 생성 및 할당을 수행하기 위해 GPT-4와 함께 제안된 **TnT-LLM**.\n' +
      '* **GPT-3.5(TnT-LLM)**: 레이블 분류 생성 및 할당을 수행하기 위해 GPT-3.5-터보를 갖는 제안된 **TnT-LLM**.\n' +
      '***ada2 + GPT-4**: 대화들이 **ada2** 및 K-means 알고리즘을 통해 표현되는 임베딩 기반 클러스터링 접근법을 적용하여 클러스터를 생성한다. 우리는 각 클러스터 내에서 200개의 대화를 무작위로 샘플링하고 GPT-4에 각 대화를 요약하도록 프롬프트한 다음 사용 사례 지침에 따라 이러한 요약에서 레이블 이름과 설명을 생성하도록 요청한다.\n' +
      '***ada2 + GPT-3.5-Turbo**: 상기 방법과 유사하게, GPT-3.5-Turbo를 라벨 생성기로 한다.\n' +
      '***인스트럭터-XL + GPT-4**: Instructor-XL 및 GPT-4를 각각 기본 임베딩 및 라벨 생성기로 하는 상기 임베딩 기반 방법과 유사하다.\n' +
      '***강사-XL + GPT-3.5-Turbo**: 상기 방법과 유사하며, GPT-3.5-Turbo를 라벨 생성기로 한다.\n' +
      '\n' +
      '이 섹션에서 평가된 모든 분류법은 완전 자동이며 인간의 개입을 포함하지 않는다.\n' +
      '\n' +
      'IMT2000 3GPP - 구현 세부사항\n' +
      '\n' +
      '우리는 LLM에 분류 생성을 위해 10개의 의도 범주와 25개의 도메인 범주를 생성하도록 지시한다. 마찬가지로, 우리는 임베딩 기반 베이스라인으로 10개의 의도 클러스터와 25개의 도메인 클러스터를 학습한다. 제안된 분류 생성 파이프라인에는 200의 미니 배치 크기를 사용한다. 우리는 또한 모든 임베딩 기반 클러스터링 접근법에서 K-means 알고리즘의 미니배치 버전을 적용하는데, 여기서 동일한 배치 크기가 K-means++(Chen et al., 2017) 초기화와 함께 사용된다. 클러스터링 알고리즘의 10가지 다른 시도를 실행하고 검증 세트에서 실루엣 계수(Srivastava et al., 2016)를 기반으로 가장 좋은 것을 선택한다. 또한 대화 요약, 다중 레이블 분류, 사용 사례 지침을 입력으로 하는 "모델" 선택 프롬프트를 고안한 다음 데이터에 가장 적합한 분류의 인덱스와 지시 데시데라타를 출력한다. 그런 다음 **TnT-LLM** 10개의 시험을 실행하고 검증 세트에 대한 성능을 기반으로 최상의 결과를 선택한다.\n' +
      '\n' +
      '**인간 평가.** 위에 나열된 방법에서 생성된 분류학의 품질을 평가하기 위해 저자 중 3명이 라벨 정확도와 사용 사례 관련 작업을 수행했으며 각 대화는 3명의 평가자 모두에 의해 평가되었다. 평가자는 빙 코파일럿 시스템과 원하는 사용 사례에 대해 높은 수준의 친숙도를 가지고 있었지만 방법과 생성된 라벨 간의 일치성을 알지 못했다. 쌍별 비교 레이블 정확도 작업에서 옵션의 위치도 완전히 랜덤화됩니다. 또한 인간 평가자와 동일한 평가 작업을 수행하기 위해 두 개의 LLM 시스템인 GPT-4 및 GPT-3.5-터보를 사용한다. 그러나, 우리는 LLM 시스템이 쌍별 비교 작업에 대해 위치 편향(Han et al., 2017)을 나타내는 경향이 있으며, 여기서 프롬프트에서의 위치에 기초하여 다른 옵션보다 하나의 옵션을 선호한다. 이러한 편향은 분류학적 품질이 낮고 작업이 더 어려울 때 더 분명하다. 이를 완화하기 위해 실험에서 옵션의 무작위 위치를 사용하여 여러 실행에서 결과를 평균화한다.\n' +
      '\n' +
      '#### 5.2.3. Results\n' +
      '\n' +
      '우리는 먼저 두 LLM 시스템이 사용자 의도와 대화 도메인 분류 모두에서 매우 높은 커버리지(\\(>\\)99.5%)를 달성하는 **BingChat-Phase1-L-Multi** 데이터셋에서 LLM 생성 분류법의 **커버리지**를 계산한다.\n' +
      '\n' +
      '그런 다음 작은 영어 전용 평가 데이터 세트 **BingChat-Phase1-S-Eng**에서 서로 다른 방법으로 생성된 분류학의 품질을 평가하기 위해 정확도와 관련성 평가 작업을 수행한다. 표 1의 평가자 간 일치도(Cohen\'s Kappa(Cohen, 2018)와 다중 평가자 간의 Fleiss\' Kappa(Cohen, 2018)를 보고한다. 일치도는 의도 및 도메인 정확도와 의도 관련성에 대해 _moderate_(\\(\\kappa>0.4\\))인 반면, 도메인 관련성에 대한 일치도는 _fair_(_fleiss\'\\(\\kappa=0.379\\)_이다. 흥미롭게도, 두 평가자 간의 평가자 간 일치도(Cohen\'s Kappa(Cohen, 2018))에 대해서는 GPT-4 평가자가 인간보다 인간 다수에 더 많이 동의한다. 이는 GPT-4가 일관되고 신뢰할 수 있는 평가자가 될 수 있음을 시사한다.\n' +
      '\n' +
      '각주 3: 이러한 평가 작업은 특히 낮은 품질의 분류학(예: 일부 기준 방법)에 대해 인지적으로 도전적이라는 점에 유의한다.\n' +
      '\n' +
      '그림 3(a)는 **BingChat-Phase1-S-Eng**에 대한 인간 평가에서 ** 라벨 정확도와 사용 사례 관련성**에 대한 주요 결과를 보여준다. GPT-4를 사용하여 **TnT-LLM**을 관찰하면 대부분의 경우 다른 방법을 능가한다. GPT4와 비교하여, GPT-3.5-터보는 대화 주제(도메인)를 잘 캡처하는 경향이 있지만, 종종 사용자 의도 명령과 정렬된 라벨을 생성하지 못한다는 것을 발견한다. 마찬가지로, 우리는 일부 임베딩 방법(**ada2 + GPT-4**, **강사-xl + GPT-4**)이 GPT-3.5-터보로 인스턴스화된 **TnT-LLM**와 동등하게 정확한 도메인 라벨을 생성하는 측면에서 잘 수행되지만 대화 뒤에 있는 사용자 의도를 포착하지 못한다는 것을 알게 된다. 이는 도메인 라벨이 대화의 주제 주제를 반영하기 때문일 수 있으며, 이는 비감독 임베딩에 의해 캡처된 의미 정보로부터 쉽게 도출될 수 있는 반면 의도 라벨은 사용 사례 명령에 대한 더 깊은 추론 및 이해를 필요로 하기 때문이다.\n' +
      '\n' +
      '기준선과 관련하여 GPT-4가 클러스터링에 동일한 임베딩 방법을 사용할 때 보다 정확한 레이블을 생성하는 데 있어 GPT-3.5-터보보다 일관되게 우수하다는 것을 발견했다. 의도 사용 사례의 경우, GPT-4는 GPT-3.5-터보보다 더 관련성 있는 라벨을 생성하는 반면, 도메인 사용 사례의 경우 차이가 덜 두드러지며, 이는 다시, GPT-3.5-터보가 사용자 의도에 대한 추론보다 대화에서 국소 정보를 캡처하는 데 더 우수하기 때문일 수 있다.\n' +
      '\n' +
      '마지막으로 라벨 정확도 작업에 대한 GPT-4와 인간 평가자 간의 높은 일치를 감안할 때 GPT-4를 사용하여 더 큰 다국어 데이터셋 **BingChat-Phase1-L-Multi**(그림 3(b))에서 라벨 정확도를 평가한다. 우리의 패턴과 유사한 패턴을 관찰한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c} \\hline \\hline \\multirow{2}{*}{**Metric**} & \\multirow{2}{*}{**Use Case**} & \\multicolumn{2}{c}{**Among Humans**} & \\multicolumn{2}{c}{**LLM vs. Human**} \\\\ \\cline{3-6}  & & Overall & Avg. pairwise & GPT-3.5-Turbo & GPT-4 \\\\  & & (Fleiss) & (Cohen) & (Cohen) & (Cohen) \\\\ \\hline \\multirow{3}{*}{Accuracy} & Intent & 0.476\\({}^{*}\\) & 0.477\\({}^{*}\\) & 0.376 & 0.558\\({}^{*}\\) \\\\  & Domain & 0.478\\({}^{*}\\) & 0.484\\({}^{*}\\) & 0.260 & 0.578\\({}^{*}\\) \\\\ \\hline \\multirow{3}{*}{Relevance} & Intent & 0.466\\({}^{*}\\) & 0.481\\({}^{*}\\) & 0.333 & 0.520\\({}^{*}\\) \\\\  & Domain & 0.379 & 0.399 & 0.177 & 0.288 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1. 평가자 간 신뢰도(Fleiss\'s Kappa and Cohen\'s Kappa)는 인간 평가자 간 및 LLM 평가자와 다수결 투표를 통해 해소된 인간 평가자 간 신뢰도(Fleiss\'s Kappa and Cohen\'s Kappa)이다. 중등도 이상(\\(>0.4\\))으로 간주되는 합의는 \\({}^{*}\\)으로 강조된다. 평가는 **BingChat-Phase1-S-Eng**에서 수행된다.\n' +
      '\n' +
      '그림 4. 인간 평가자와 GPT-4 평가자의 **BingChat-Phase1-S-Eng**에 대한 분류 평가 결과이며, 여기서 오차 막대는 95% 신뢰 구간을 나타낸다.\n' +
      '\n' +
      '인간 평가, 여기서 **TnT-LLM**은 가장 높은 정확도, 특히 GPT-4를 사용하는 인스턴스화를 달성한다.\n' +
      '\n' +
      '### LLM-증강 텍스트 분류\n' +
      '\n' +
      '라벨 분류 생성 단계가 끝나면 GPT-4와 함께 **TnT-LLM**에서 생성된 의도 분류 및 도메인 분류에 대해 경량 인간 보정(Liu et al., 2018)을 수행한다. 그런 다음 이러한 보정된 분류법이 레이블 할당 단계에서 활용된다. 각 분류법의 전체 레이블 및 설명 텍스트는 표 5와 표 6에 나와 있다. 상기시켜 드리자면, 이 섹션의 주요 목표는 LLM 레이블에 대해 훈련된 증류 경량 분류기가 전체 LLM 분류기와 어떻게 비교하는지 비교하는 것이며, 우리의 목표는 더 비싸지만 잠재적으로 더 강력한 LLM에 비해 정확성과 효율성의 유리한 절충을 달성하는 것이다.\n' +
      '\n' +
      '#### 5.3.1. Methods\n' +
      '\n' +
      '우리는 GPT-4를 자동화된 주석자로 적용하여 말뭉치의 각 대화에 기본 레이블과 기타 관련 레이블을 모두 할당한다. 그런 다음 GPT-4 주석이 달린 훈련 및 검증 세트를 기반으로 분류기를 훈련한다. 우리는 **ADA2**와 **INstructor-XL**의 두 가지 임베딩 방법을 사용하여 각 대화에서 특징을 추출한다. 각 임베딩 방법에 대해 GPT-4 레이블인 **Logistic Regression**, gradient boosting **LightGBM**(Liu et al., 2018), two-layer **MultiLayer****Perceptron(MLP)**(Chen et al., 2019)의 세 가지 유형의 분류기를 학습한다. 기본 레이블 분류를 위해 **로지스틱 회귀**에서 다항 로짓과 세 분류기 모두를 사용하여 다중 레이블 분류를 위한 표준 \'1-vs-all\' 체계를 사용한다.\n' +
      '\n' +
      '또한, 4명의 저자는 주어진 의도 및 도메인 분류로 400개의 영어 대화(**BingChat-Phase2-S-Eng**)에 수동으로 레이블을 지정했다. 각 대화에는 3명의 주석자가 레이블을 지정했으며 다수결로 최종 레이블이 결정되었다. 몇 가지 대화(\\(<\\)10%)에서 세 명의 주석자가 모두 기본 레이블에서 동의하지 않는 경우 네 번째 주석을 타이 브레이커로 사용했다.\n' +
      '\n' +
      '따라서 우리는 인간과 GPT-4 주석이 모두 있는 400개의 영어 대화가 있는 **BingChat-Phase2-S-Eng**와 GPT-4 주석만 있는 약 10k 대화가 있는 **BingChat-Phase2-L-Multi**의 두 가지 주석이 달린 테스트 세트를 얻는다.\n' +
      '\n' +
      '#### 5.3.2. Results\n' +
      '\n' +
      '우리는 먼저 작업 복잡성과 신뢰성을 평가하기 위해 주석자 간의 일치를 평가한다. 표 2에서 알 수 있듯이, 인간 주석자는 1차 도메인 라벨에 대한 _substantial_ agreement(\\(\\kappa>0.6\\)), 1차 의도 라벨에 대한 _moderate_ agreement(\\(Fleiss^{\\prime}\\kappa=0.553\\))를 갖는다. 이 두 값은 평가자 간의 높은 상호 이해와 지침 및 분류법의 명확성을 나타낸다. 우리는 또한 도메인 분류법이 의도 분류법(10)보다 더 많은 범주(25)를 가지고 있다는 점에 주목한다. 더 큰 분류법이 이해하기 더 어려울 것으로 예상할 수 있지만, 우리는 더 작은 의도 분류법이 인간이 동의하기 더 어렵다는 것을 알게 된다. 우리는 이것이 더 많은 추론을 필요로 하기 때문에 태스크 복잡성과 모호성에 기인하며, GPT4가 일반적으로 더 강력한 추론기로 간주되기 때문에 GPT4가 의도 검출에서 GPT-3.5-터보보다 훨씬 우수하다는 이전 평가에서의 관찰과 잘 일치한다.\n' +
      '\n' +
      '라벨 정확도 평가(표 1)와 유사하게 GPT-4는 1차 라벨 할당에서 인간보다 해결된 인간 라벨과 더 많이 일치한다. 적용 가능한 모든 라벨에 대한 인간의 일치도는 의도 및 도메인 분류 모두 _moderate_ (\\(\\kappa>0.4\\))이며, 이러한 일치도는 정확한 일치도를 기반으로 계산된다는 점을 고려할 때 놀랍게도 좋다(즉, 선택된 모든 라벨이 일치하는 경우에만 일치도를 계산한다). 그러나 GPT-4와 이 작업에 대한 인간 주석 간의 일치는 훨씬 낮다. 더 자세히 조사한 결과 GPT-4는 라벨 할당에서 인간보다 더 자유로운 경향이 있어 모든 관련 범주를 적용하여 정밀도는 낮지만 재현율은 높은 것으로 나타났다.\n' +
      '\n' +
      '그런 다음 인간 주석이 오라클인 **BingChat-Phase2-S-Eng**와 GPT-4 주석이 오라클인 **BingChat-Phase2-L-Multi**의 두 데이터 세트에 대해 증류된 임베딩 기반 분류기의 분류 성능을 평가한다. 1차 레이블 분류에 대한 결과는 표 3에 나와 있으며, 여기서 경량 임베딩 기반 분류기가 유망한 결과를 얻을 수 있음을 관찰한다. 특히, **ADA2** 임베딩은 로지스틱 회귀 분석을 통해 강력한 결과를 얻으며, 비선형성은 대부분의 경우 성능을 크게 향상시키지 못하는 것으로 판단된다. 인간 주석을 황금 표준으로 사용할 때 이러한 경량 모델의 성능이 **BingChat-Phase2-S-Eng**에서 분류기로 GPT-4를 직접 사용하는 것과 비슷하고 때로는 약간 더 우수하다는 것을 발견했다. 또한 GPT-4 주석이 오라클로 간주되는 다국어 테스트 세트 **BingChat-Phase2-L-Multi**에 대한 평가를 수행한다. 영어가 아닌 대화에서의 성능이 영어 대화에서의 성능보다 낮은 것을 관찰하며(표 3), 특히 **INstructor** 임베딩에서는 말뭉치의 특성에 맞는 적절한 임베딩 방법을 선택하는 것이 중요함을 알 수 있다.\n' +
      '\n' +
      '다중 레이블 분류 작업(표 4)에서, 우리는 증류 분류기가 GPT-4에 비해 약간의 재현율을 희생시키면서 더 높은 정밀도를 달성한다는 것을 관찰한다. 여기서, MLP 기반 분류기가 가장 높은 정확도와 정밀도를 달성함에 따라 비선형성도 더 도움이 되는 것으로 보인다.\n' +
      '\n' +
      '### 발견 및 제안 요약\n' +
      '\n' +
      '우리는 우리의 새로운 **TnT-LLM** 프레임워크가 인간의 지시나 개입이 거의 없는 비정형 텍스트 말뭉치로부터 고품질 라벨 분류학을 생성할 수 있음을 보여주었다. 실제 AI 채팅 대화에 대한 이 접근법에 대한 평가에서 비정형 텍스트에서 구조와 조직을 찾는 데 사용할 수 있음을 입증했다. 본 논문에서 제안하는 방법은 기존의 임베딩 기반 클러스터링 방법보다 우수한 성능을 보였으며, 특히 표면 수준의 의미론 이상의 깊은 추론이 필요한 경우에 더욱 우수한 성능을 보였다. 마지막으로 임베딩 기반 클러스터링이 여전히 효과적일 수 있다는 것을 발견했다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c} \\hline \\hline \\multirow{2}{*}{**Metric**} & \\multirow{2}{*}{**Use Case**} & \\multicolumn{2}{c}{**Among Humans**} & **LLM vs. Human** \\\\ \\cline{3-5}  & & Overall & Avg. pairwise & GPT-4 \\\\  & & (Fleiss) & (Cohen) & (Cohen) \\\\ \\hline \\multirow{2}{*}{Primary Label} & Intent & 0.553* & 0.559* & 0.572* \\\\  & Domain & 0.624** & 0.624** & 0.695** \\\\ \\hline \\multirow{2}{*}{\n' +
      '\\begin{tabular}{c} All Labels (exact match) \\\\ \\end{tabular} } & Intent & 0.422* & 0.427* & 0.271 \\\\  & Domain & 0.467* & 0.467* & 0.102 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2. 인간 주석자들 사이 및 LLM 주석들과 해결된 인간 주석들 사이의 평가자 간 신뢰도(Fleiss\'s Kappa and Cohen\'s Kappa). _moderate_(\\((0.4,0.6]\\))로 간주되는 합의는 *, _substantial_ 및 위(\\(>0.6\\))는 **로 강조된다.\n' +
      '\n' +
      '클러스터 세분성 및 사용 사례와 입력의 정렬과 같은 모델링 선택 또는 아티팩트에 더 취약합니다.\n' +
      '\n' +
      '우리는 LLM을 평가자 또는 평가자로 사용하는 것을 추가로 탐구하여 일부 평가 과제에 대한 인간의 집단적 의견을 효과적으로 근사화한다는 것을 보여주었다. 또한 LLM은 한 옵션에 대해 다른 옵션보다 선호도를 표시하도록 강요되는 단일 선택 질문(예: 쌍별 레이블 정확도 평가 작업)에서 탁월하지만 암시적 표준과 함께 주관적이고 미묘한 판단을 포함하는 객관식 질문에서 어려움을 겪을 수 있음을 발견했다. 인간 평가를 위한 대체 전략으로 LLM을 사용하되 인간의 선호도와 일치도를 측정하여 주의하고 검증할 것을 제안한다.\n' +
      '\n' +
      '마지막으로, 우리는 LLM을 분류기가 아닌 "주석자"로 사용하여 풍부한 데이터를 생성하는 능력을 활용하는 관점을 제안했다. LLM을 활용하여 레이블이 지정되지 않은 데이터에 대한 의사 레이블을 생성함으로써 규모에 안정적으로 배치할 수 있는 경량 분류기를 증류할 수 있다. 실험에서 이러한 분류기는 경쟁적인 결과를 달성했으며 분류기로서의 GPT-4의 성능과 일치하거나 심지어 능가했다. 우리는 LLM의 잠재적 사용 사례에 대한 신중한 평가를 옹호하며 성능과 효율성의 균형을 유지하면서 기존 기계 학습 분류기의 성숙도, 속도 및 비용으로 일반화하는 힘을 모두 이용한다.\n' +
      '\n' +
      '##6. 토론 및 미래 작업\n' +
      '\n' +
      '이 작업은 텍스트 마이닝에서 AI 기술의 연구 및 적용에 상당한 영향을 미칠 가능성이 있다. 우리의 프레임워크는 LLM을 분류 생성기, 데이터 라벨러 및 평가자로 사용할 수 있는 능력을 입증했다. 이러한 자동화는 방대한 양의 비정형 텍스트를 이해하고 구조화하고 분석하는 데 의존하는 다양한 도메인 및 애플리케이션에 대한 상당한 효율성 향상과 비용 절감으로 이어질 수 있다. 또한 텍스트에서 지식을 마이닝하는 프로세스를 광범위하게 민주화하여 비전문가 사용자와 기업이 자연 언어를 통해 데이터와 상호 작용하고 해석할 수 있도록 하여 다양한 산업 및 부문에 대한 더 나은 통찰력과 데이터 기반 의사 결정을 유도할 수 있다. 또한, 우리의 프레임워크와 연구 결과는 분류 생성 및 텍스트 군집링을 위해 LLM을 활용하는 다른 작업과 관련이 있으며 이러한 시나리오에서 명령어 추적 모델의 효율적인 사용을 위한 중요한 경험적 교훈을 가지고 있다.\n' +
      '\n' +
      '이러한 초기 성공에도 불구하고, 탐험할 가치가 있는 몇 가지 중요한 도전과 미래 방향이 있습니다. 이미 언급했듯이 LLM은 비싸고 느립니다. 향후 연구에서는 하이브리드 접근법을 통해 프레임워크의 속도, 효율성 및 견고성을 개선하는 방법을 모색하고자 한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c} \\hline \\hline  & \\multirow{2}{*}{Accur.} & \\multicolumn{3}{c}{Micro} & \\multicolumn{3}{c}{Macro} \\\\ \\cline{3-8}  & & Precision & Recall & F1 & Precision & Recall & F1 \\\\ \\hline \\multicolumn{8}{c}{**User Intent**} \\\\ \\hline GPT-4 & 0.320 & 0.518 & **0.743** & 0.610 & 0.613 & **0.644** & **0.537** \\\\\n' +
      'ADA2 +** & & & & & LogisticReg & 0.388\\({}^{\\dagger}\\) & 0.574\\({}^{\\circ}\\) & 0.736\\({}^{\\circ}\\) & 0.593 & 0.607 & **0.537**\\LightGBM & 0.380\\({}^{\\dagger}\\) & 0.669\\({}^{\\dagger}\\) & 0.626 & 0.486 & 0.456\\({}^{\\dagger}\\) & 0.513 & 0.499\\({}^{\\dagger}\\)\n' +
      '**Instructor-XL +** & & & & & & \\\\ LogisticReg & 0.358 \\({}^{\\dagger}\\) & 0.559 \\({}^{\\dagger}\\) & 0.688 \\({}^{\\dagger}\\) & 0.617 & 0.583 & 0.540 & 0.51 \\\\ LightGBM & 0.335 \\({}^{\\Box}\\) & 0.557 \\({}^{\\dagger}\\) & 0.644 \\({}^{\\dagger}\\) & 0.597 & 0.571 & 0.479 & 0.465 \\\\ MLP & 0.410 \\({}^{\\dagger}\\) & **0.606**\\({}^{\\dagger}\\) & 0.642 \\({}^{\\dagger}\\) & 0.623 & 0.623 & 0.480 & 0.495 \\\\ \\hline \\multicolumn{8}{c}{**Conversation Domain**} \\\\ \\hline GPT-4 & 0.110 & 0.442 & **0.753** & 0.557 & 0.565 & **0.687** & 0.576 \\\\\n' +
      'ADA2 +** & & & & & & LogisticReg & 0.188\\({}^{\\dagger}\\) & 0.493\\({}^{\\dagger}\\) & 0.732\\({}^{\\dagger}\\) & **0.589** & 0.644 & 0.624 & **0.558**\\LightGBM & 0.182\\({}^{\\dagger}\\) & 0.469\\({}^{\\dagger}\\) & 0.517 & 0.621 & 0.490 & 0.525\\({}^{\\dagger}\\) & 0.452\\({}^{\\dagger}\\) & 0.509\\({}^{\\dagger}\\) & 0.589\\({}^{\\dagger}\\) & 0.644 & 0.624 & **0.558**\\LightGBM & 0.182\\({}^{\\dagger}\\) & 0.469\\({}^{\\dagger}\\) &\n' +
      '**Instructor-XL +** & & & & & & \\\\ LogisticReg & 0.210 \\({}^{\\dagger}\\) & 0.495 \\({}^{\\dagger}\\) & 0.714 \\({}^{\\ddagger}\\) & 0.585 & **0.655** & 0.602 & 0.574 \\\\ LightGBM & 0.172 \\({}^{\\dagger}\\) & 0.479 \\({}^{\\dagger}\\) & 0.592 \\({}^{\\dagger}\\) & 0.530 & 0.586 & 0.453 & 0.469 \\\\ MLP & **0.262**\\({}^{\\dagger}\\) & **0.550**\\({}^{\\dagger}\\) & 0.602 \\({}^{\\ddagger}\\) & 0.575 & 0.738 & 0.475 & 0.511 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4. 경량 증류 분류기는 다중 라벨 분류에서 GPT-4와 동등하거나 더 잘 수행한다: 인간 주석이 달린 금 라벨을 사용하여 BingChat-Phase2-S-Eng에 대한 결과.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline\n' +
      '**Oracle** & \\multicolumn{3}{c}{**Human Annot.**} & \\multicolumn{3}{c}{**GPT-4 Annot.**} \\\\ \\cline{3-6}  & Accur. & F1 macro & \\multicolumn{3}{c}{Accuracy} \\\\ \\cline{3-6}  & & All & English & Non-Eng. \\\\ \\hline \\multicolumn{6}{c}{**User Intent**} \\\\ \\hline GPT-4 & 0.655 & **0.640** & & & \\\\\n' +
      'ADA2 +** & & & & **0.658**\\({}^{\\circ}\\) & 0.639 & **0.746**\\({}^{\\circ}\\) & 2.35 & **0.725**\\({}^{\\circ}\\) LightGBM & 0.642\\({}^{\\Box}\\) & 0.536 & 0.702 & 0.716\\({}^{\\circ}\\) & 2.602 & 0.744 & 0.762\\({}^{\\circ}\\) & 2.45 & 0.722\\({}^{\\circ}\\)\n' +
      '**Instructor-XL +** & & & & & \\\\ LogisticReg & 0.655 \\({}^{\\Box}\\) & 0.611 & 0.687 & 0.745 \\({}^{\\circ}\\) & 8.45 & 0.619 \\({}^{\\circ}\\) \\\\ LightGBM & 0.602 \\({}^{\\ddagger}\\) & 0.455 & 0.652 & 0.705 \\({}^{\\circ}\\) & 8.11 \\({}^{\\circ}\\) & 0.589 \\({}^{\\circ}\\) \\\\ MLP & 0.650 \\({}^{\\Box}\\) & 0.593 & 0.691 & 0.750 \\({}^{\\circ}\\) & 0.521 \\({}^{\\circ}\\) & 10.15 \\\\ \\hline \\multicolumn{6}{c}{**Conversation Domain**} \\\\ \\hline GPT-4 & 0.638 & **0.603** & & & & \\\\\n' +
      'ADA2 +** & & & & LogisticReg & 0.640\\({}^{\\circ}\\) & 0.573 & **0.705** & **0.733**\\({}^{\\circ}\\) & 4.67\\LightGBM & 0.560\\({}^{\\ddagger}\\) & 0.476 & 0.633 & 0.656\\({}^{\\circ}\\) & 3.583 & 0.703 & 0.731\\({}^{\\circ}\\) & 4.85\\\\MLP & 0.650\\({}^{\\circ}\\) &\n' +
      '**Instructor-XL +** & & & & & \\\\ LogisticReg & 0.622 \\({}^{\\Box}\\) & 0.562 & 0.639 & 0.711 \\({}^{\\ddagger}\\) & 11.35 & 0.553 \\({}^{\\circ}\\) & -13.35 \\\\ LightGBM & 0.588 \\({}^{\\ddagger}\\) & 0.505 & 0.583 & 0.646 \\({}^{\\circ}\\) & 10.95 & 0.508 \\({}^{\\circ}\\) & -12.85 \\\\ MLP & 0.648 \\({}^{\\Box}\\) & 0.569 & 0.639 & 0.712 \\({}^{\\ddagger}\\) & 0.553 \\({}^{\\circ}\\) & -13.45 \\\\ \\hline \\hline \\end{tabularexplore the combination of ILMs with embedding-based methods, or model distillation that fine-tunes a smaller model through instructions from a larger one. Evaluation continues to be a crucial and open challenge for future work, and we plan to explore ways of performing more robust LLM-aided evaluations in future work, for example by fine-tuning a model to expand its reasoning capabilities beyond pairwise judgement tasks. While this work has focused largely on text mining in the conversational domain, we also hope to explore the extensibility of our framework to other domains as well. Finally, many domains have ethical considerations from the perspective of privacy and security that must be taken into account when performing large-scale automated text mining, and we hope to engage with these challenges more deeply in future work.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* C Aggarwal and Zhai(2012) Charu C Aggarwal and ChengXiang Zhai. 2012. A survey of text clustering algorithms. 텍스트 데이터를 마이닝합니다. (2012), 77-128.\n' +
      '* Arthur et al. (2007) David Arthur, Sergei Vasilvitskii, et al. 2007. k-means++: 주의 깊게 파종하는 것의 장점. In _Soda_, Vol. 7. 1027-1035.\n' +
      '* 보투(1998) 레온 보투. 1998. Online algorithm and stochastic approximation. _ 신경망에서의 온라인 학습_(1998).\n' +
      '* Cambazoglu et al. (2021) B B Baria Cambazoglu, Leila Tavakoli, Falk Scholer, Mark Sanderson, and Bruce Croft. 2021. 웹 검색에서 질문된 질문에 대한 의도 분류. In _Proceedings of the 2021 Conference on Human Information Interaction and Retrieval_. 85-94\n' +
      '* Chang et al. (2009) Jonathan Chang, Sean Gerrish, Chong Wang, Jordan Boyd-Graber, and David Blei. 2009. 텍스트 읽기: 인간이 토픽 모델을 어떻게 해석하는지 신경 정보 처리 시스템들_22의 발전들(2009).\n' +
      '* Cohen(1960) Jacob Cohen. 1960. 명목 척도에 대한 일치 계수. _ 교육 및 심리 측정_20, 1(1960), 37-46.\n' +
      '* Fleiss and Cohen (1973) Joseph I. Fleiss and Jacob Cohen. 1973. The equivalence of weighted kappa and the intraclass correlation coeffact measures of reliability. _ 교육 및 심리 측정_33, 3(1973), 613-619.\n' +
      '* Glindysr & Alizadeh (2023) Fabrizio Glindysr, Metsz Alizadeh, and Mali Kublik. 2023. Chatopt는 text-annotation 작업에서 crowd-workers보다 우수하다. _ arXiv preprint arXiv:2303.1506_(2023).\n' +
      '* Haykin (1998) Simon Haykin. 1998. _Neural networks: a comprehensive foundation_. 프렌티스 홀 PTR입니다\n' +
      '* Hotho et al. (2005) Andreas Hotho, Andreas Nurnberger, and Gerhard Paafl. 2005. brief survey of text mining. _ Journal for Language Technology and Computational Linguistics_20, 1(2005), 19-62.\n' +
      '* Joulin et al. (2016) Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Herve Jegou, and Tomas Mikolov. 2016. FastTextrap: 압축 텍스트 분류 모델_ arXiv preprint arXiv:1612.0867_(2016).\n' +
      '* Joulin et al. (2016) Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2016. 효율적인 텍스트 분류를 위한 트릭의 백_ arXiv preprint arXiv:1607.0759_(2016).\n' +
      '* Ko et al. (2017) Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: 고효율 Gradient boosting decision tree. _ 신경 정보 처리 시스템들_30의 발전들(2017).\n' +
      '* Kingma and Ba (2014) Diederik P. Kingma and Jimmy Ba. 2014. Adam: Stochastic Optimization을 위한 방법. _ CoRR_ abs/1412.6980 (2014). [https://api.semanticscholar.org/CorpusID:6628106] (https://api.semanticscholar.org/CorpusID:6628106)\n' +
      '* Lee et al. (2023) Dong-Ho Lee, Jay Pujara, Mohit Sewak, Ryon White, and Sujay Jauhar. 2023. 대용량 언어 모델을 만들어 데이터 작성자를 향상시킵니다. In _Proceedings of 2023 Conference on Empirical Methods in Natural Language Processing_, Houda Boumor, Juan Pinno, and Kalika Bali (Eds.) Association for Computational Linguistics, Singapore, 15349-15360. [https://doi.org/10.18635/v1/2023.emnlp-main.948](https://doi.org/10.18635/v1/2023.emnlp-main.948)\n' +
      '* Liu et al. (2023) Nelson F Lu, Kevin Lim, John Hewitt, Ashwin Parangangang, Michele Bevlacqua, Fabio Perroni, and Percy Liang. 2023. Lost in middle: How language models use long context. _ arXiv preprint arXiv:2307.03172_(2023).\n' +
      '* McLachlan and Barford (1988) 제프리 J McLachlan and Kay E Bastford. 1988. _Mature models: Inference and applications to clustering_, Vol. 38. M. Dekker New York.\n' +
      '* Pham et al.(2023) Chau Minh Pham, Alexander Hoyle, Simeg Sun, and Mohit Iyyer. 2023. 토픽CPT: 프롬프트 기반 토픽 모델링 프레임워크. _ arXiv preprint arXiv:2311.01449_(2023).\n' +
      '* Pryzant et al. (2023) Reid Priyzant, Dan Iker, Jerry Li, Yin Lee, Chengquang Zhu, and Michael Zeng. 2023. "경사 하강" 및 빔 탐색을 이용한 자동 프롬프트 최적화. In _Proceedings of 2023 Conference on Empirical Methods in Natural Language Processing_, Houda Boumor, Juan Pinno, and Kalika Bali (Eds.) Association for Computational Linguistics, Singapore, 7957-7968. [https://doi.org/10.18653/v1/2023.emnlp-main.494](https://doi.org/10.18653/v1/2023.emnlp-main.494)\n' +
      '* Rose and Levinson (2004) Daniel E Rose and Danny Levinson. 2004. 웹 검색에서의 사용자 목표 이해. the _Proceedings of the 13th international conference on World Wide Web_, 13-19.\n' +
      '* Rousseeuw (1987) Peter J Rousseeuw. 1987. 실루엣: 군집 분석의 해석 및 검증에 대한 그래픽 지원. _ Journal of computational and applied mathematics_20(1987), 53-65.\n' +
      '* Sandhaus (2008) Evan Sandhaus. 2008. New York times annotated corpus. _ 언어 데이터 컨소시엄, Philadelphia_ 6, 12(2008), e26752.\n' +
      '* Shah et al. (2023) Chirag Shah, Ryon W White, Reid Andersen, Georg Buscher, Scott Counts, Sarkar Singhala Sarathi Das, Ali Muncar Sathiam, Jennifer Neville, Xiaochuan Ni, et al. 2023. 대규모 언어 모델을 사용하여 사용자 의도 분류법을 생성, 검증 및 적용한다. _ arXiv preprint arXiv:2309.13063_(2023).\n' +
      '* Shang et al. (2020) Jingbong Shang, Xinyang Zhang, Liyuan Liu, Sha Li, 및 Jiawei Han. 2020. Nettaxo: 텍스트가 풍부한 모델로부터 자동화된 토픽 분류 구축. In _Proceedings of the Web Conference_2020. 1908-1919.\n' +
      '* Socher et al. (2013) Richard Socher, Alex Perelyin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In _Proceedings of the 2013 conference on empirical methods in natural language processing_. 1631-1642.\n' +
      '* Su et al. (2022) Honggin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-tau Yih, Noah A Smith, Luke Zettlemoyer, and Tao Yu. 2022. One Embedder: Any Task-Inversion-Fintend Text Embeddings. [https://arxiv.org/abs/2212.09741] (https://arxiv.org/abs/2212.09741)\n' +
      '* Tan et al. (1999) Ah-Hwee Tan et al. 1999. Text mining: The state of the art and the challenges. The _Proceedings of the PAKDD 1999 workshop on knowledge discovery from advanced database_, Vol. 8. 65-70.\n' +
      '* Thomas et al. (2023) Paul Thomas, Seth Spielman, Nick Craswell, and Bhaskar Mitra. 2023. 대용량 언어 모델은 검색된 선호도를 정확하게 예측할 수 있다. _ arXiv preprint arXiv:2309.10621_(2023).\n' +
      '* 이반사니와 쿠마르 (2020) Xvansany and Satish AP 쿠마르. 2020. Review of topic modeling methods. _ Information Systems_94(2020), 101582.\n' +
      '* Wang et al. (2023) Zihan Wang, Jingbo Shang, and Ruiqi Zhong. 2023. 언어 설명을 통한 목표 기반 설명 가능한 클러스터링 In _Proceedings of 2023 Conference on Empirical Methods in Natural Language Processing_, Houda Boumor, Juan Pinno, and Kalika Bali (Eds.) Association for Computational Linguistics, Singapore, 10626-1064. [https://doi.org/10.18653/v1/2023.emnlp-main.657](https://doi.org/10.18653/v1/2023.emnlp-main.657)\n' +
      '* Welivitz and Pur(2020) Amuradha Welivitz and Pearl Pur. 2020. A Taxonomy of Empathetic Response. 인간 사회 대화에서. _Proceedings of the 28th International Conference on Computational Linguistics_. 4886-4899.\n' +
      '* Zeng et al. (2021) Qingkai Zeng, Jinfeng Lin, Wenhhao Yu, and Cleland-Huang, and Meng Jiang. 2021. 관계 표현을 융합하여 개념 생성으로 분류 완성도를 높인다. _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_. 2104-2113\n' +
      '* Zhang et al. (2018) Chao Zhang, Fangbo Tao, Xiusi Chen, Jianting Shen, Meng Jiang, Brian Sadler, Michelle Vanni, 및 Jiawei Han. 2018. TaxoSP: Adaptive term embedding and clustering에 의한 비감독 주제 분류 구축. In _Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_. 2701-2709.\n' +
      '* Zijms et al. (2023) Cablez Zijms, William Held, Omar Shaikh, Jiaoa Chen, Zhehao Zhang, and Diyi Yang. 2023. 대용량 언어모델이 컴퓨팅 사회과학을 변환할 수 있는가? _ arXiv preprint arXiv:2305.03514_(2023).\n' +
      '\n' +
      '## 부록 A 분류학\n' +
      '\n' +
      '레이블 할당 단계에서 사용되는 사용자 의도 분류 및 대화 도메인 분류는 표 5 및 6에 제공된다. 라벨 이름과 대부분의 라벨 설명은 **TnT-LLM** 프레임워크를 통해 자동으로 생성되지만, 이러한 생성된 분류 및 추가된 인공 예에 대해 경량 인간 보정을 수행했다. 이러한 예는 순전히 예시를 위한 것이며 우리 코퍼스의 특정 데이터 포인트와 연결되지 않는다.\n' +
      '\n' +
      '## 부록 B 추가 결과\n' +
      '\n' +
      '분류 생성 단계와 레이블 할당 단계에 대해 수행된 실험의 추가 결과를 제시한다.\n' +
      '\n' +
      '### 1단계: 분류 생성\n' +
      '\n' +
      '*BingChatPhase1-S-Eng**에 대한 분류 평가 결과 외에도 제안된 **TnT-LLM** 프레임워크의 레이블 분류 결과가 다른 언어에 걸쳐 어떻게 수행되는지 조사한다. 우리는 일반적으로 영어 대화와 비영어 대화에서 그 성능의 큰 차이를 발견하지 못하는 그림 5의 GPT-4 라이터의 레이블 정확도 결과를 제시한다.\n' +
      '\n' +
      '### Phase 2: 레이블 할당\n' +
      '\n' +
      '#### b.2.1. 주석 동의서 분석\n' +
      '\n' +
      '레이블 할당 작업을 위해 인간 주석자와 LLM 주석자 간의 일치 결과에 대해 심층 조사를 수행한다. 인간 주석자의 서로 다른 쌍 사이의 일치 결과는 그림 6에 제시되어 있으며, **BingChatPhase2-S-Eng** 데이터셋의 기본 레이블에 대한 GPT-4 주석과 (해결된) 인간 주석 간의 혼동 행렬은 그림 7에 제시되어 있다. 사용자 의도에 대해서는 "Fact-based information seeking"와 "Clarification and concept explanation", "General solution and advice seeking", "Technical assistance and problem solving"의 경계에서 대부분의 불일치가 발생함을 알 수 있다. 이는 인간 주석자와 GPT-4 주석자가 사용자 질의가 얼마나 "기술적"인지 또는 얼마나 정교화가 필요한지에 대한 판단이 다르다는 것을 시사한다. 우리의 모든 인간 주석자는 높은 기술 전문성을 가지고 있으며, 이는 일반 인구와 다른 암묵적 표준을 적용하여 잠재적으로 편향된 주석을 초래할 수 있다. 도메인 레이블 할당 작업에서 유사한 패턴을 관찰하는데, "일반 디지털 지원"과 "소프트웨어 개발 및 하드웨어 문제"가 종종 혼동되고, GPT-4 주석자는 인간 주석을 오라클로 간주할 경우 "소프트웨어 개발 및 하드웨어 문제"에 대해 높은 오양성률을 보인다. 이러한 종류의 분석이 인간 주석과 LLM 주석 모두에서 잠재적인 편향을 식별하고 줄이는 데 도움이 될 수 있으므로 분류학에서 라벨 설명의 명확성과 라벨 주석의 일관성을 향상시킬 수 있다고 주장한다.\n' +
      '\n' +
      '#### b.2.2.2 전체 분류 결과\n' +
      '\n' +
      '우리는 그림 11에서 대화의 기본 레이블을 예측한 전체 다중 클래스 분류 결과, 그림 12에서 적용 가능한 모든 레이블을 예측한 전체 다중 레이블 분류 결과, 그림 13에서 언어 분류 결과를 제시한다. 우리는 섹션 5.3의 결론이 여전히 유지됨을 확인한다.\n' +
      '\n' +
      '## 부록 C 구현 상세\n' +
      '\n' +
      '### 배관설계 및 상세기술\n' +
      '\n' +
      '우리는 이 섹션에서 LLM 기반 프레임워크의 세부 사항에 대해 논의한다. 이러한 설계 세부 사항의 근거는 제안된 프레임워크가 실행 가능하고 견고하며 정량적 메트릭을 통해 검증될 수 있도록 하는 것이다.\n' +
      '\n' +
      '**실행가능성 및 견고성.** 주요 과제는, 특히 상태들이 이전 출력들에 의존하는 프롬프트 체인이 관련될 때, 프레임워크를 어떻게 신뢰성 있게 실행하는가이다. 이를 해결하기 위해 "<output-output taxonomy in markdown table format</output>"과 같이 미리 정의된 xml 태그를 사용하여 프롬프트에 출력 형식을 명시적으로 명시한다. 이를 통해 프롬프트 체인의 각 단계에서 얻은 결과를 분석하고 다음 단계로 공급할 수 있다. 또한 각 레이블의 이름, 설명 및 인덱스가 포함된 미리 정의된 스키마가 있는 마크다운 테이블로 분류법을 포맷하도록 LLM에 지시한다. LLM에 할당된 레이블의 이름과 인덱스를 함께 출력하도록 요청함으로써 레이블 할당 출력의 일관성을 개선하고 잠재적인 후처리 노력을 줄인다.\n' +
      '\n' +
      '그러나 LLM이 항상 형식 지침을 완벽하게 따르지 않을 수 있음을 인정한다. 따라서 파이프라인 실행의 강건성을 높이기 위해 다음과 같은 전략을 제안한다. 특히 LLM 프롬프트의 각 유형에 대해 몇 가지 보호 테스트를 설계한다. 이러한 테스트들은: 1) 프롬프트로부터의 출력이 성공적으로 파싱될 수 있는 지정된 포맷을 준수하는지 여부를 체크하는 단계; 2) 출력이 특히 요약 프롬프트에 대해 프롬프트에서 지정된 올바른 언어(영어)에 있는지 여부를 검증하는 단계; 3) 출력이 출력 분류법에서 라벨의 최대 수와 같은 프롬프트 명령에서 주어진 주요 검증가능한 요건을 충족하는지 여부를 보증하는 단계를 포함한다. 이러한 메트릭들은 LLM 시스템의 **명령-추종** 능력을 측정할 뿐만 아니라, 또한 제공한다\n' +
      '\n' +
      '도 5. GPT-4 평가자의 다국어 대화(**BingChat-Phase1-L-Multi**)에 대한 언어별 분류 평가 결과.\n' +
      '\n' +
      '그림 6. 레이블 할당 작업에서 인간 주석자 간의 쌍별 일치(Cohen\'s Kappa)입니다.\n' +
      '\n' +
      '프레임워크의 실행 가능성을 높이기 위한 품질 보증 테스트 제품군입니다.\n' +
      '\n' +
      '또한 각 LLM 호출에 대해 최대 재시도 횟수(실험에서 5)와 기준 온도를 지정합니다. LLM 호출의 결과가 가드레일 테스트를 통과할 수 없는 경우 온도를 0.1 증가시키고 한계에 도달할 때까지 다시 시도할 수 있도록 한다. LLM이 재시도 할당량을 소진한 후 지침을 따르지 않는 경우가 여전히 있지만, 경험적으로 이 전략이 LLM 기반 프레임워크의 실행 가능성을 크게 증가시킨다는 것을 발견했다.\n' +
      '\n' +
      '**"모델" 선택.** 고전적인 기계 학습 최적화에서 확률적 경사 하강법을 적용하는 관행으로부터 영감을 얻는다. 본 논문에서 제안하는 분류체계 생성 및 갱신 파이프라인은 전역으로의 수렴을 보장하지는 않지만, 외부 검증 단계를 활용하여 \'조기 정지\' 기준을 적용할 수 있는 기존의 확률적 최적화 관행을 시뮬레이션한다.\n' +
      '\n' +
      '각주 4: 이러한 종류의 단일 선택 또는 쌍별 선택 평가에서 잠재적인 위치 편향[16]을 완화하기 위해 우리는 항상 각 옵션의 위치를 무작위화하고 모든 실험에서 평가를 여러 번 실행합니다.\n' +
      '\n' +
      '**효율성 분석 및 표본 크기 제안.** 우리 파이프라인의 효율성은 말뭉치 표본 크기와 각 단계에 대한 LLM 시스템의 선택에 달려 있다. 분류 생성 단계(1단계)는 전체 말뭉치를 대표하는\'mall-to-medium\' 크기의 말뭉치 샘플을 사용하는 것을 제안한다. 표본 크기(\\(N\\))는 말뭉치의 다양성을 포착하기에 충분히 커야 하지만 불필요한 계산 비용을 발생시키기에 너무 크지는 않아야 한다. 실험에서 약 10k의 샘플 크기가 100개 이하의 레이블이 있는 고품질 분류를 생성하기에 충분하다는 것을 발견했다. 이 단계에서 가장 계산 집약적인 단계는 요약 단계로 전체 코퍼스 샘플에 대한 요약을 생성하기 위해 최소 \\(N\\)번의 LLM 호출이 필요하다. 입력 텍스트가 짧고 규범적이거나 더 저렴하거나 더 전문화된 요약 모델로 대체되는 경우 이 단계는 건너뛸 수 있다. 생성 및 업데이트 프롬프트 체인은 높은 추론 능력과 큰 컨텍스트 윈도우를 갖는 LLM 시스템을 필요로 한다. 실험에서 GPT-4(32k 컨텍스트 윈도우 포함)와 GPT-3.5-터보(16k 컨텍스트 윈도우 포함)를 사용했으며 적절한 배치(배치 크기 200)로 효율성을 달성할 수 있었다. GPT-3.5-터보가 GPT-4보다 5x-10x 더 빠르지만 최종 라벨 분류 결과의 품질을 손상시킬 수 있음을 관찰했다.\n' +
      '\n' +
      '레이블 할당 및 분류기 개발 단계(2단계)는 분류에서 레이블의 범위를 포괄하는\'medium-to-large\' 크기의 말뭉치 샘플을 사용하는 것을 권장하며, 필요한 샘플 크기는 분류 작업의 어려움과 사용된 표현 모델의 효과에 따라 달라지며, 이 단계에서는 전체 샘플에 LLM을 적용하므로 모델 개발을 위한\'medium\' 크기의 샘플부터 시작하여 필요에 따라 증가시키는 것을 제안한다.\n' +
      '\n' +
      '그림 7: **인간 주석자와 GPT-4 주석자가 할당한 기본 라벨의 혼동 행렬.**\n' +
      '\n' +
      '### Experiment Details\n' +
      '\n' +
      '**LLM Configurations.** 본 연구에서 적용된 모든 프롬프트에 대해 다음과 같은 고정 파라미터 구성을 사용했다: frequency_penalty=0, presence_penalty=0, top_p=0.5. LLM의 발전력을 유도하기 위해 분류 생성 프롬프트 체인에 대해 의도적으로 더 높은 온도를 적용한다. 기본 온도는 "세대" 프롬프트의 경우 0.5, "업데이트" 프롬프트의 경우 0.2로 설정됩니다. 실험의 다른 모든 프롬프트에 대해 기본 온도를 0으로 설정합니다.\n' +
      '\n' +
      '**하이퍼파라미터 선택.** 섹션 5.3에 제시된 분류기에 대해 다음과 같이 유효성 검증 세트에 대한 정확도 성능을 기반으로 그리드 검색을 수행한다.\n' +
      '\n' +
      '**Logistic Regression**: \\(\\ell_{2}\\) regularizer를 적용하고 \\(\\lambda\\)을 \\([0.01,0.1,1,10]\\) 중에서 선택한다.\n' +
      '* **LightGBM**: 공식 **LightGBM** 패키지에서 기본 잎 수(31)를 사용하고 최대 깊이는 \\([3,5,7,9]\\)에서 선택한다.\n' +
      '**MLP**: 가중치 감쇠를 \\(1e-5\\)로 설정하고 학습률 0.001로 설정한 Adam(King and Ba, 2014) 최적화기를 적용하였으며, 은닉층의 크기는 \\([32,64,128,256]\\)에서 선택하였다.\n' +
      '\n' +
      '**교육 후 결과.** 섹션 5.2 및 5.3에 보고된 결과 외에도 실험에 적용된 두 LLM 시스템의 교육 후 능력도 평가한다. 제안된 분류 생성 파이프라인의 첫 번째 요약 단계(섹션 3.1의 1단계)에 대해 1) 프롬프트에서 미리 정의된 형식(형식 검사)을 기반으로 출력이 성공적으로 파싱될 수 있는지, 2) 프롬프트에서 지정된 언어(즉, 영어)를 준수하는지 주로 평가한다. 우리는 GPT-4가 형식과 언어 검사의 100%를 통과하면서 완벽하게 수행했다는 것을 발견했다. 반면, GPT-3.5-터보는 형식점검의 경우 실패율이 매우 낮았으며(-0.01%), 언어점검의 경우 실패율이 약간 높았다 (2% 내외). 그러나 GPT-3.5-터보 출력의 0.3%가 엄격한 형식 검사를 통과했지만 명령어를 XML 태그에 복사했음을 알 수 있다. 성공률에 따른 전반적인 지시가 높고 분류 생성 파이프라인이 입력 배치의 사소한 교란에 상대적으로 강력하기 때문에 후속 단계에서 GPT-3.5-터보에 대한 지시 후 테스트를 통과하지 못한 대화는 폐기한다. 분류 생성 및 업데이트 단계(섹션 3.1의 단계 2)에 대해, 프롬프트 체인이 10개의 에포크 런 각각에 대해 성공적으로 완료될 수 있는지 평가하며, 이는 모든 중간 분류 결과 1)을 성공적으로 파싱(즉, 포맷 체크)할 수 있고, 2) 미리 정의된 분류 크기 제한(즉, 생성된 라벨의 최대 수)을 준수해야 한다. GPT-4는 다시 완벽하게 수행되어 두 분류학 모두에 대해 10개 시대 중 10개를 완성했다. 그러나 GPT-3.5-터보는 주로 \'업데이트\' 단계에서 분류 크기 제한을 지속적으로 초과하기 때문에 이 단계에서 고전했다. 결국 의도 분류는 10개 에폭 중 4개, 도메인 분류는 10개 에폭 중 1개만 완성하였다. 네이티브 레이블 할당 단계에서는 GPT-4와 GPT-3.5-터보가 모두 100%에 가까운 형식 검사를 통과할 수 있음을 알 수 있다.\n' +
      '\n' +
      '## 부록 D 프롬프트 템플릿\n' +
      '\n' +
      '이 섹션에서는 대화 요약(그림 8), 레이블 할당(그림 9), 분류 생성(그림 10a), 업데이트(그림 10b) 및 검토(그림 10c)에 사용된 프롬프트 템플릿을 제시한다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:14]\n' +
      '\n' +
      '그림 11. 1차 레이블 예측 결과.\n' +
      '\n' +
      '그림 12. 적용 가능한 모든 레이블을 예측한 결과.\n' +
      '\n' +
      '## 6. Conclusion\n' +
      '\n' +
      '도 13. 언어별 결과(영어 대 비영어 대화) 주요 레이블과 GPT-4 주석을 큰 다국어 테스트 세트의 오라클로 사용할 수 있는 모든 것을 예측하는 것.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l} \\hline \\hline Label Name & Label Description \\\\ \\hline Website Navigation Requests & User seeks to visit a very specific website or web page by providing a URL, or keywords that ”indicate the name or domain of the website”, e.g., ”amazon.com”, ”gmail login”. \\\\ Fact-Based Information Seeking & User seeks factual and descriptive information on a specific topic, product, or service. These user queries can be answered by retrieving the factual information that ”already exists in the sources” and require ”a high level of specificity” and ”low level of subjectivity”, e.g., ”What is the capital of France?”. \\\\ Clarification and Concept Explanation & User asks AI to explain various topics or concepts, or seeks clarification or confirmation on a matter, by providing a question that requires more than a factual or a descriptive answer, but rather “an interpretation, definition, or elaboration”, e.g., ”What is the difference between AI and machine learning?”. \\\\ General Solution and Advice Seeking & User seeks general solutions, advice, instructions, or steps on a ”non-technical” topic, product, or service, by providing a problem, goal, or scenario that requires more than a factual or descriptive answer, but rather ”a recommendation, suggestion, or guidance”, e.g., ”What should I buy for my friend’s birthday?”. \\\\ Technical Assistance and Problem Solving & User seeks help with ”technical” issues or problem-solving related to a product, service, or system, by providing a description of the issue, error, or challenge that requires more than a factual or descriptive answer, but rather ”a diagnosis, solution, or workaround”, e.g., ”How to fix the bug in my code?”. \\\\ Language Translation Requests & User requests translation or interpretation of a phrase or sentence “from one language to another”, e.g., ”Hello” in Spanish”. \\\\ Content Creation and Storytelling Requests & User requests the ”creation of original content” such as images, stories, instructions, summaries, or narratives on a specific topic or theme, e.g., ”Create an image of a unicorn in a forest”. \\\\ Planning and Scheduling & User seeks assistance with planning an event, trip, or schedule, e.g., ”Plan a birthday party for my mom”. \\\\ Data Analysis and Calculation Requests & User asks for quantitative data analysis, calculations, or statistical interpretations, by providing the source of the data and the desired operation or result, e.g., ”Calculate the average of these numbers”, ”Analyze the sales data for last quarter”. \\\\ Greetings and Social Interactions & User greets the AI agent or engages in social interactions, by providing a salutation, expression, or remark, or requesting to play games with the AI, which ”does not require a factual, descriptive, or technical answer”, but rather an engaging, polite or humorous response, e.g., “Hello, how are you?”, ”You’re very smart”. \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5. 라벨 할당 실험에 사용된 사용자 의도 분류. 제시된 모든 예는 인공적이며 우리 말뭉치의 특정 데이터 포인트와 연결하지 않는다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l} \\hline \\hline Label Name & Label Description \\\\ \\hline Academic Resources & Requests for educational resources, explanations of “general” academic concepts, and academic advice, e.g., \\\\  & *Best college for computer science*, “How to prepare for the SAT?”. \\\\  & *Requests for translations, text editing, or discussions about grammar, syntax, and other linguistic concepts, e.g., “Translate “Hello’ to French”, “What is the difference between ‘affect’ and ‘effect’?”. \\\\  & Mathematics, Logics and Data Science \\\\  & *Queries and discussions related to concepts, theories, and problems in the fields of mathematics and logics, or related to machine learning and data science, e.g., “How to calculate standard deviation?”, “What is the difference between boosting and bagging?”. \\\\  & *Queries and discussions related to concepts, theories, and problems in the fields of physics and chemistry, e.g., “What is the speed of light?”, “What is the atomic number of carbon?”. \\\\  & *Discussions about “business operations”, “industry developments”, and related information, e.g., “What is the best business strategy for a startup?”, “Generate a FAQ page for a healthcare product website”. \\\\  & *Economics and Finance \\\\  & *Discussions about economic concepts and theories, financial products, investment advice, and related queries, e.g., “What is the current inflation rate?”, “What is the best investment strategy in 2024?”. \\\\  & *Requests for job applications, career advice, and related information, e.g., “What is the best career path for a data scientist?”. \\\\  & *Queries about legal terms, regulations, and related information, e.g., “What is the legal drinking age in the US?”, “What are the regulations for AI development in EU countries?”. \\\\ Art, Design and Creativity & *Requests for ‘image creation and creative writing”, or discussions about “art, design and creative concepts*, e.g., “Create a logo for my company”, “What is the difference between modern art and contemporary art?”. \\\\  & *Discussions about movies, music, games, game development, and other forms of entertainment, e.g., “Who is the director of the movie “Oppenheimer’?”. \\\\  & *Requests for playing games, or engaging in “interactive activities with the AI’, e.g., “Play a game with me”, “Tell me a joke”. \\\\  & *Coverstations about “personal” hobbies, lifestyle choices, and individual interests, e.g., “How to learn to play the guitar as a beginner?”. \\\\  & *Sports and Fitness \\\\  & *Conversations about “sports events”, “fitness advice”, and related topics, e.g., “Who will play in the NBA finals?”, “Training tips for marathon”. \\\\  & *Conversations about food recommendations, nutritional information, and cooking advice., e.g., “How to make a pizza?”. \\\\  & *Health and Wellness \\\\  & *Discussions about health conditions, treatments, and wellness information, e.g., “Is cancer curable?”, “Best practices to improve sleep quality”. \\\\  & *General Digital Support \\\\  & *Conversations related to the AI’s abilities, limitations, functionality, task requests, and technical support for “general” digital products or services, e.g., “What can Bing Chat do?”, “How to take a screenshot on mackob?”. \\\\  & *Software Development and Hardware Issues \\\\  & *Conversations about “coding”, “software configuration*, “development tools*, and specific software or “hardware issues* and their solutions, e.g., “How to install python on mackob?”, “How to fix a broken external hard drive?”. \\\\  & *Home and Household Issues \\\\  & *Queries about home maintenance, household issues, and related advice, e.g., “How to clean a microwave oven?”. \\\\  & *Animals and Nature \\\\  & *Queries about animals, nature, and related information, e.g., “What is the pH value of water?”, “What is the average lifespan of a cat?”. \\\\  & *Geography, Climate and Environment \\\\  & *Geography, Climate and Environment \\\\  & *Geography, Climate and Environment \\\\  & *History and Culture \\\\  & *History and Culture \\\\  & *Personal Counseling and Emotional Support \\\\  & *Social and Political Issues \\\\  & *Product and Shopping Queries \\\\  & *Travel and Tourism \\\\  &\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>