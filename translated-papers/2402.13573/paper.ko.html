<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# ToDo: 고해상도 영상의 효율적인 생성을 위한 토큰 다운샘플링\n' +
      '\n' +
      ' Ethan Smith\\({}^{1}\\)\n' +
      '\n' +
      'Nayan Saxena\\({}^{1}\\)\n' +
      '\n' +
      'Aninda Saha\\({}^{1}\\)\n' +
      '\n' +
      '\\({}^{1}\\)Leonardo AI\n' +
      '\n' +
      '{ethan, nayan.saxena, aninda}@leonardo.ai\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '이미지 확산 모델의 성공에 중요한 요소이지만, 2차 계산 복잡도는 우리가 합리적인 시간 및 메모리 제약 내에서 처리할 수 있는 이미지의 크기를 제한한다. 본 논문은 자주 중복된 특징을 포함하는 생성 이미지 모델에서 조밀한 주의의 중요성을 조사하여 더 첨예한 주의 메커니즘에 적합하도록 한다. 본 논문에서는 키와 값 토큰의 토큰 다운샘플링에 의존하여 일반적인 크기의 경우 최대 2배, 높은 해상도의 경우 최대 4.5배 이상의 안정적인 확산 추론을 가속화하는 새로운 훈련 없는 ToDo 방법을 제안한다. 본 논문에서 제안한 방법이 기존의 방법보다 효율적인 처리율과 충실도의 균형을 유지하는 것을 보인다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '트랜스포머와 그 핵심 구성요소인 관심은 최근 몇 년 동안 생성 모델의 성공과 개선에 필수적이다[23]. 그들의 글로벌 수용 분야들, 입력 컨텍스트에 기초하여 동적으로 계산하는 능력 및 큰 용량들은 많은 작업들에 걸쳐 이들을 유용한 빌딩 블록들로 만들었다[14]. 트랜스포머 아키텍처의 주요 단점은 시퀀스 길이에 따른 계산 복잡도의 2차 스케일링으로 시간과 메모리 요구 사항 모두에 영향을 미친다는 것이다. (2048\\times 2048\\) 해상도에서 안정적인 확산 영상을 생성하고자 할 때, 가장 큰 U-Net 블록의 어텐션 맵은 (\\(1\\) 배치\\(\\times 8\\) 헤드\\(\\times(256^{2}\\) 토큰\\()^{2}\\times 2\\) 바이트로 계산되는 반 정밀도에서 약 69GB의 메모리 비용을 발생시킨다. 이것은 대부분의 소비자 GPU의 능력을 초과한다[15]. 플래시 어텐션에 사용되는 커널과 같은 특수 커널은 속도가 크게 향상되고 메모리 비용이 감소했지만[11], 시퀀스 길이에 따른 불리한 2차 스케일링으로 인한 문제는 지속적이다.\n' +
      '\n' +
      '계산 효율성의 추구에서, 희박한 주의의 개념이 주목을 받았다. Token Merging (ToMe) [1]과 같은 방법들과 잠재 이미지 확산 모델들 [1]에서의 적용은 높은 유사성을 갖는 토큰들을 응축함으로써 요구되는 계산 시간을 감소시켰고, 따라서 더 적은 토큰들로 정보의 본질을 유지한다. 유사하게, Neighborhood Attention[17] 및 Focal Transformers[21]와 같은 접근법들은 질의 토큰들이 선택된 이웃에만 참석하는 메커니즘들을 도입하여, 수용 필드와 계산 부하 사이의 트레이드-오프를 밸런싱한다. 이러한 전략은 주의 메커니즘의 출력을 효율적으로 근사화하는 것을 목표로 한다. 수행 가능하지만 이러한 방법은 일반적으로 훈련 시간 수정이 성공해야 하며 최적화를 활용하기 위해 상당한 물류 오버헤드가 발생한다.\n' +
      '\n' +
      '희소 주의력 프레임워크를 보완하여 주의력 근사화 방법은 주의력 연산을 단순화하기 위해 수학적 특성을 활용하여 대안적인 방법을 제공한다. 소프트맥스를 보다 계산 친화적인 비선형성[3]으로 대체하는 것부터 주의력[1]을 완전히 선형화하는 것, 차원 감소를 위한 커널 트릭을 활용하는 것(1)에 이르는 기술이 주의력을 효율적으로 근사화하기 위해 탐색되었지만 일반적으로 모델에 대한 훈련도 필요하다.\n' +
      '\n' +
      '이러한 작업을 기반으로 사전 훈련 요구 사항을 해결하기 위한 새로운 사후 방법을 제안한다.\n' +
      '\n' +
      '그림 1: 우리 방법의 시각화. 주어진 잠재 또는 이미지로부터, 우리는 질의 토큰들의 전체 세트를 유지하는 주의에서 사용되는 키들 및 값들에 대해 스트라이드 방식으로 그리드 상의 위치들을 서브샘플링한다. 데모 비디오 링크가 있습니다.\n' +
      '\n' +
      '추론을 가속화하는 것으로, 토큰 다운샘플링(ToDo)이라고 합니다. 우리의 접근 방식인 ToDo는 이미지에서 인접한 픽셀이 이웃과 유사한 값을 나타내는 경향이 있다는 관찰에서 영감을 받았다. 따라서 본 논문에서는 이미지 처리 과정에서 그리드 기반 서브샘플링과 유사하게 토큰을 줄이기 위해 다운샘플링 기법을 사용한다. 이전 방법 ToMe[18]과 비교하여, 본 방법은 병합 프로세스를 단순화할 뿐만 아니라, 완전한 유사성 계산이 필요하지 않기 때문에 계산 오버헤드를 상당히 감소시킨다. 요약하면, 우리의 주요 기여는 다음과 같습니다.\n' +
      '\n' +
      '* 안정확산에 대한 추론을 최대 4.5배 더 빠르게 가속할 수 있는 훈련 없는 방법으로 처리량과 충실도의 균형을 맞추는 기존 방법을 능가한다.\n' +
      '* U-Net 내의 주의력 특징에 대한 심층 분석 및 충실도를 실질적으로 해치지 않으면서 주의력이 희박하게 근사화될 수 있는 이유에 대한 가설.\n' +
      '\n' +
      '## 2 Methods\n' +
      '\n' +
      '### Background\n' +
      '\n' +
      '이미지 생성을 위한 확산 모델 확산 모델[14]은 자체 주의 계층[13]을 활용하는 변압기 기반 블록이 있는 U-Net 아키텍처[15]를 사용한다. 이 설정은 공간 차원을 일련의 토큰으로 평평하게 만들고, 이 토큰은 잡음 제거된 이미지를 예측하기 위해 여러 개의 변압기 블록을 통해 공급된다.\n' +
      '\n' +
      '원래 ToMe[18] 프레임워크에서 원래 토큰 병합 기법은 소스(src)와 목적지(dst) 집합으로 분류된다. 병합 과정은 src 집합에서 가장 유사한 토큰들을 식별하고 dst 집합으로 병합하여 총 토큰 수를 \\(r\\)만큼 효과적으로 줄인다. 이 병합은 \\(x_{text{merged}}=\\frac{1}{r}\\sum_{i=1}^{r}x_{i}\\)으로 정의되며, 여기서 \\(x_{i}\\)은 병합될 개별 토큰들을 나타낸다.\n' +
      '\n' +
      '전반적으로, 독창적인 ToMe 방법은 어텐션 레이어들에 입력되기 전에 유사한 토큰들의 병합을 통한 계산 부하의 감소에 기초한다. 이 프로세스는 가장 높은 유사성을 나타내는 토큰이 병합되는 유사성 행렬의 계산을 포함한다. 이어서, 언머징 프로세스는 병합된 토큰 정보를 원래의 토큰 위치들에 다시 재분배하는 것을 목표로 한다. 그러나 이 접근법은 두 가지 중요한 병목 현상을 도입한다.\n' +
      '\n' +
      '***Computational Complexity:** 유사도 행렬 계산, \\(\\mathcal{O}(n^{2})\\) 복잡도는 그 자체로 비용이 많이 들며, 특히 공정의 모든 단계에서 필요할 때 더욱 그러하다.\n' +
      '* ** 품질 저하:** ToMe 고유의 병합-언머지 사이클은 특히 더 높은 병합 비율에서 이미지 디테일의 상당한 손실을 초래할 수 있다.\n' +
      '\n' +
      '훈련 무료 향상\n' +
      '\n' +
      '토큰 다운샘플링(ToDo) 방법론은 기존의 ToMe 접근 방식을 확장하여 안정적인 확산 모델에 적용할 때 계산상의 병목 현상과 품질 저하 문제를 해결한다. 우리는 ToDo의 두 가지 주요 수정 사항, 즉 공간적 연속성에 기반한 최적화된 토큰 병합 방법과 병합 해제 필요성을 완화시키는 정제된 주의 메커니즘을 소개한다.\n' +
      '\n' +
      '공간적 연속성을 통한 최적화된 병합 이미지 토큰의 고유한 공간적 연속성을 활용하는 새로운 토큰 병합 전략을 소개한다. 근접한 공간적 근접성에 있는 토큰들이 더 높은 유사성을 나타낸다는 것을 인식함으로써, 쌍별 유사성의 광범위한 계산 없이 병합을 위한 기초를 제공한다. 따라서 본 논문에서는 Nearest-Neighbor 알고리즘 [1]을 이용하여 다운샘플링 함수 \\(D(\\cdot)\\)를 사용한다. 이 접근법은 그림 1과 같이 스트라이드 컨볼루션과 유사하다. 형식적으로, \\(T=\\{t_{1},t_{2}\\dots t_{n}\\}\\)은 공간 관계를 반영하는 2차원 격자로 배열된 이미지 토큰의 원래 집합을 나타낸다. 제안된 다운샘플링 연산인 \\(D\\)을 \\(T\\)에 적용하여 병합된 토큰의 축소 집합을 생성한다.\n' +
      '\n' +
      '\\[T^{\\prime}=D(T)=\\{D(t_{1}),D(t_{2})\\dots D(t_{m})\\}\\enspace,\\text{where }m<n\\]\n' +
      '\n' +
      '이러한 향상은 ToMe에 내재된 쌍별 유사성 계산과 관련된 계산 오버헤드를 완화시킨다. 공간적으로 인접한 토큰들이 유사할 가능성이 높다는 가정을 이용하여, 보다 계산적으로 효율적인 \\(\\mathcal{O}(n^{2})의 다운샘플링 연산 대신 \\(\\mathcal{O}(n)\\)의 유사도 계산의 필요성을 우회한다.\n' +
      '\n' +
      '기존의 토큰 병합 방법에서 병합되지 않는 프로세스에 내재된 정보 손실을 완화하기 위해 다운샘플링을 이용한 향상된 어텐션 메커니즘을 트랜스포머 아키텍처 내에서 어텐션 메커니즘에 대해 개선한다[16]. 이러한 수정은 원래의 질의들을 보존하면서 주의 메커니즘의 키들, \\(K\\) 및 값 \\(V\\)에 다운샘플링 연산 \\(D(\\cdot)\\)을 적용하는 것을 수반한다. 수정된 어텐션 함수는 다음과 같이 수학적으로 아티큘레이션될 수 있으며, \\(d_{k}\\)는 키의 차원을 나타내어 소프트맥스 연산 내에서 적절한 스케일링을 보장한다.\n' +
      '\n' +
      '\\[\\text{Attention}(Q,K,V)=\\text{softmax}\\bigg{(}\\frac{Q\\cdot D(K)^{T}}{\\sqrt{d_{k}}\\cdot D(V)\\bigg{}\\]\n' +
      '\n' +
      '이러한 개선은 쿼리들의 무결성이 보존되는 것을 보장함으로써, 어텐션 계산과 관련된 행렬들의 차원을 감소시키면서 어텐션 프로세스의 충실도를 유지한다.\n' +
      '\n' +
      '## 3 Experiments\n' +
      '\n' +
      '실험적 평가를 위해 본 연구의 중심인 더 큰 이미지 차원에 대한 우수한 처리로 주목받는 Finetuned DreamshaperV7 모델[15]을 사용한다. 모든 실험은 많은 사용자에게 표준이 되었기 때문에 추론을 위해 플로트16 정밀도와 플래시 주의[1]를 활용하여 단일 A6000 GPU에서 수행된다. 우리는 50개의 확산 단계와 7.5[13]의 유도 척도가 있는 DDIM 샘플러[14]를 사용한다. 각 실험에는 토큰 병합이 없는 표준 세대를 참조하는 기준선과 ToMe에 대해 ToDo를 비교하는 평균 10세대가 포함된다. 벤치마킹된 해상도는 토큰이 제거된 비율을 나타내는 0.75와 0.89의 두 토큰 병합 비율에 대한 \\(1024\\times 1024\\), \\(1536\\times 1536\\) 및 \\(2048\\times 2048\\)을 포함한다. 이는 각각 2x 및 3x 다운샘플에 해당한다. 그림 2의 비교를 위해 4x 다운샘플에 해당하는 \\(2048\\times 2048\\) 이미지에 대해 0.9375의 병합 비율을 사용한다.\n' +
      '\n' +
      '이미지 품질 및 처리량은 생성된 이미지의 충실도와 세부 보존을 평가하기 위해 기준선에서 각 방법의 편차를 정량화하기 위해 평균 제곱 오차(MSE)를 사용했으며 이미지 선명도와 텍스처 보존을 평가하기 위한 표준인 하이 패스 필터(HPF)를 사용했다[11]. 그림 2와 표 1에 의해 입증된 우리의 분석에서는 우리의 방법이 MSE 측면에서 기준선을 밀접하게 반영할 뿐만 아니라 유사한 HPF 값을 유지하므로 그림 3에 표시된 것처럼 더 높은 처리량을 보장하면서 이미지 기능을 유지하는 효율성을 강조한다.\n' +
      '\n' +
      '잠재적 특징 중복성은 인접한 잠재 특징 간의 유사성을 평가하여 안정적인 확산 U-Net에서 잠재 특징 중복성을 조사했다. 다양한 단계 및 잡음 수준에서 잠재 표상을 추출하여 \\(3\\times 3\\) 영역 내에서 상위 3개의 유사성을 갖는 토큰의 비율과 \\(3\\times 3\\) 및 \\(5\\times 5\\) 영역 내에서 상위, 평균 및 하위 유사성을 갖는 토큰의 비율을 중심으로 코사인 유사도 행렬을 구성하였다. 그림 4에서 볼 수 있듯이 숨겨진 특징 및 주목할만한 경향 내에서 이웃 토큰 간의 높은 유사성을 관찰했다. 유사성 경향은 뚜렷한 패턴 없이 다른 깊이에 따라 다양했는데, 이는 아마도 디노이징이 진행됨에 따라 공간 압축이 증가하고 결과적으로 값이 감소하는 정보 중복성이 감소했기 때문일 수 있으며, 확산 모델은 초기에 광범위한 세부 정보를 생성하고 나중에 정제하기 때문일 수 있다.\n' +
      '\n' +
      '## 4 Conclusion\n' +
      '\n' +
      '본 논문에서 제안하는 ToDo 기법은 특히 고주파 성분에서 효율적인 처리량과 충실도 사이의 균형을 유지할 수 있음을 보이고, U-Net 내의 주변 특징들이 중복될 수 있음을 보이고, 또한 본 논문에서 제안하는 기법이 다른 관심 기반 생성 이미지 모델들, 특히 많은 수의 토큰에서 동작하는 모델들에 도움이 될 수 있음을 가정한다. 향후 연구는 본 연구의 방법의 차별성을 탐색하고 이를 활용하여 이전에 보이지 않았던 더 큰 이미지 차원에서의 안정적인 확산을 효율적으로 미세화할 수 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c} \\hline \\hline\n' +
      '**Method** & **Merge Ratio** & **MSE** & **HPF** \\\\ \\hline _Baseline_ & - & - & _4.846_ \\\\ ToMe & 0.75 & \\(2.686\\times 10^{-2}\\) & 4.022 \\\\  & 0.89 & \\(2.671\\times 10^{-2}\\) & 4.003 \\\\ ToDo (ours) & 0.75 & \\(6.247\\times 10^{-3}\\) & **4.887** \\\\  & 0.89 & \\(9.207\\times 10^{-3}\\) & **4.733** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 다양한 주의 방법의 메트릭은 \\(1536\\times 1536\\) 해상도에서 10세대에 걸쳐 서로 다른 프롬프트의 평균을 냈다. MSE는 기준선에 대한 평균 제곱 오차를 나타내는 반면 HPF는 평균 절대 크기 후 하이 패스 필터링을 나타낸다.\n' +
      '\n' +
      '그림 4: 확산 타임스템에 걸쳐 \\(3\\times 3\\) 영역에서 토큰 간의 가장 낮은 코사인 유사성과 \\(1024\\times 1024\\)에서 서로 다른 프롬프트의 10세대에서 추출된 U-Net 위치. 50개 중 타임스텝은 노이즈 감소를 나타내며; Depth 0은 초기 해상도이고 Depth 1은 2x 다운샘플링 후이다. 업/다운은 인코더/디코더 블록을 나타낸다.\n' +
      '\n' +
      '그림 3: 다양한 병합 비율에서 다른 주의 방법을 사용하여 해상도에 걸친 추론 처리량, 기준선에 대한 상대적 성능 증가를 나타내는 막대와 함께.\n' +
      '\n' +
      '그림 2: 주의집중 방법의 질적 비교: \\(1024\\times 1024\\)에서 25%, \\(1536\\times 1536\\)에서 11%, \\(2048\\times 2048\\)에서 6%로 합병 후 4096의 일관된 토큰 수를 유지했다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '*[1]I. Bankman (2008) Handbook of medical image processing and analysis. 세비에르 인용: SS1.\n' +
      '*[2]D. Bolya and J. Hoffman (2023) Token merging for fast stable diffusion. 컴퓨터 비전을 위한 효율적인 딥러닝을 위한 CVPR 워크숍 인용: SS1.\n' +
      '*[3]D. 볼야, C. Fu, X. Dai, P. Zhang, C. Feichtenhofer, 그리고 J. Hoffman (2023) 토큰 병합: 당신의 베엣이지만 더 빠르다. 학습 표상에 대한 국제 회의: SS1에 의해 인용됩니다.\n' +
      '*[4]D. 천진리, 그리고 K Xu(2020) Arelu: attention-based rectified linear unit. 인용: SS1.\n' +
      '*[5]K. 초롬스키 리코셔스토프, 도한, 엑스 송아건 Sarlos, P. Hawkins, J. Davis, A. Mohiuddin, L. 케이저, D. 벨레인저, L. 콜웰과 A. 웰러(2022)는 출연자들과 관심을 재고한다. 인용: SS1.\n' +
      '*[6]T. 다도용 Ermon, A. Rudra, and C. Re(2022) FlashAttention: IO-awareness와 함께 빠르고 메모리 효율적인 정확한 주의력. 신경 정보 처리 시스템의 발전, 인용: SS1.\n' +
      '*[7]R. C. 곤잘레스(2009) 디지털 영상 처리. 피어슨 교육 인도 인용: SS1.\n' +
      '*[8]A. 하사니 월튼, 제이리, 수 Li, H. Shi(2023) Neighborhood attention transformer. 인용: SS1.\n' +
      '*[9]A. Katharopoulos, A. V. V. Pappas, N. Pappas, and F. Fleuret (2020) Transformers is rnns: fast autoregressive transformer with linear attention. 인용: SS1.\n' +
      '*[10]S. 칸민 나세르 하야트 와카스 자미르, F 샤바즈 칸, M. Shah (2022-07) 비전 속의 트랜스포머: 설문조사. ACM Computing Surveys54(10s), pp. 1-41. Cited by: SS1.\n' +
      '*[11]S. 류영 탄락 Huang, J. Li, and H. Zhao (2023) Latent consistency model: 몇 단계 추론을 통해 고해상도 영상을 합성한다. ArXiv:2310.04378. 인용: SS1.\n' +
      '*[12]R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer (2021) High-resolution image synthesis with latent diffusion models. 인용: SS1.\n' +
      '*[13]O. 론너버거, 피셔, 티 Brox(2015) U-net: 바이오메디컬 이미지 세그멘테이션을 위한 컨볼루션 네트워크. In Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18, pp. 234-241. Cited by: SS1.\n' +
      '*[14]Y. 송승호 Ermon(2019) 데이터 분포의 기울기를 추정하여 생성 모델링을 한다. 신경 정보 처리 시스템 32. 인용: SS1.\n' +
      '*[15]J. 송창몽 Ermon(2020-10) Denoising Diffusion implicit model. ArXiv:2010.02502. 인용: SS1.\n' +
      '*[16]H. T. Team(2024) 추론 속도를 높입니다. 인용: SS1.\n' +
      '*[17]A. 바스와니 N. 쉐이저 파마르, J. 우즈코리트, L. 존스, A. N. 고메즈, L. Kaiser와 I. Polosukhin (2023) 주의만 있으면 됩니다. 인용: SS1.\n' +
      '*[18]J. 양창리 대병효 Yuan, and J. Gao (2021) Focal self-attention for local-global interaction in vision transformer. CoRRabs/2107.00641. 인용: SS1.\n' +
      '*[19]B. 장진우 판현희 Weng, and C. Shen (2023) A survey on efficient training of transformer. ArXiv:2302.01107. 인용: SS1.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>