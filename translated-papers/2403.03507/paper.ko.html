<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# GaLore: Gradient Low-Rank Projection에 의한 메모리 효율적인 LLM 트레이닝\n' +
      '\n' +
      'Jiawei Zhao\n' +
      '\n' +
      'Zhenyu Zhang\n' +
      '\n' +
      'Beidi Chen\n' +
      '\n' +
      'Zhangyang Wang\n' +
      '\n' +
      'Anima Anandkumar\n' +
      '\n' +
      'Yuandong Tian\n' +
      '\n' +
      '캘리포니아 공대 2 메타 AI 균등 조언\n' +
      '\n' +
      '각주 1: 계산은 LLaMA 아키텍처, BF16 수치 형식 및 2048의 최대 시퀀스 길이를 기반으로 한다.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '대규모 언어 모델(LLM)을 훈련하는 것은 주로 가중치의 크기 및 최적화 상태 증가로 인해 상당한 메모리 문제를 제시한다. 로우-랭크 적응(LoRA)과 같은 공통 메모리-감소 접근법들은 트레이닝가능한 로우-랭크 매트릭스를 각 층에서 동결된 사전-트레이닝된 가중치에 추가하여, 트레이닝가능한 파라미터들 및 최적화기 상태들을 감소시킨다. 그러나, 이러한 접근법들은 일반적으로 사전-훈련 및 미세-조정 단계들 모두에서 전체-순위 가중치들을 갖는 훈련을 저-순위 서브공간으로 제한하고 훈련 역학들을 변경하기 때문에, 전체-순위 웜 스타트(full-rank warm start)를 필요로 할 수 있다. 본 연구에서는 LoRA와 같은 일반적인 저순위 적응 방법보다 _full-parameter_ 학습이 가능하지만 _memory-efficient_가 높은 훈련 전략인 Gradient Low-Rank Projection(**GaLore**)을 제안한다. 이 방법은 최대 19.7B 토큰의 C4 데이터 세트를 사용하여 LLaMA 1B 및 7B 아키텍처를 사전 훈련하고 GLUE 태스크에서 RoBERTa를 미세 조정하면서 최적기 상태에서 최대 65.5%의 메모리 사용량을 줄입니다. 우리의 8비트 GaLore는 BF16 기준선에 비해 최적화 메모리가 최대 82.5%, 총 훈련 메모리가 63.3% 더 감소한다. 특히, 모델 병렬, 체크포인팅 또는 오프로딩 전략 없이 24GB 메모리(예: NVIDIA RTX 4090)를 사용하는 소비자 GPU에서 7B 모델을 사전 훈련하는 가능성을 처음으로 입증한다.\n' +
      '\n' +
      '머신러닝, ICML\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '대형 언어 모델(LLM)은 대화형 AI 및 언어 번역을 포함한 여러 분야에서 인상적인 성능을 보여왔습니다. 그러나, 사전 훈련 및 미세 조정 LLM은 엄청난 양의 계산량을 필요로 할 뿐만 아니라 메모리 집약적이다. 메모리 요건은 수십억 개의 훈련 가능한 파라미터뿐만 아니라, 파라미터 저장 자체보다 클 수 있는 그들의 구배 및 최적화 상태(예를 들어, Adam에서의 구배 운동량 및 분산)를 포함한다(Raffel et al., 2023; Touvron et al., 2023; Chowdhery et al., 2022). 예를 들어, 단일 배치 크기로 처음부터 LLaMA 7B 모델을 사전 훈련하려면 최소 58GB 메모리(훈련 가능한 매개변수의 경우 14GB, 애덤 최적화 상태 및 무게 기울기의 경우 42GB, 활성화 1의 경우 2GB)가 필요하다. 이것은 24GB 메모리를 가진 엔비디아 RTX 4090과 같은 소비자 수준의 GPU에서 교육을 실현 가능하지 않게 만든다.\n' +
      '\n' +
      '각주 1: 계산은 LLaMA 아키텍처, BF16 수치 형식 및 2048의 최대 시퀀스 길이를 기반으로 한다.\n' +
      '\n' +
      '그레디언트 체크포인팅(Chen et al., 2016), 메모리 오프로딩(Rajbhandari et al., 2020) 등과 같은 엔지니어링 및 시스템 노력 외에도, 연구자들은 또한 사전 훈련 및 미세 조정 동안 메모리 사용량을 줄이기 위한 다양한 최적화 기술을 개발하고자 한다.\n' +
      '\n' +
      '도 1: 활성화 체크포인팅 및 메모리 오프로딩 없이, 단일 디바이스 상에서 256의 토큰 배치 크기를 갖는 LLaMA 7B 모델을 사전 트레이닝하는 메모리 소비. 자세한 내용은 섹션 5.5를 참조하십시오.\n' +
      '\n' +
      'PEFT(Parameter-efficient fine-tuning) 기법들은 모델의 파라미터들 모두를 미세 조정할 필요 없이 상이한 다운스트림 애플리케이션들에 대한 사전 훈련된 언어 모델들(PLM)의 효율적인 적응을 허용한다(Ding et al., 2022). 그 중 보급된 Low-Rank Adaptation(LoRA Hu et al. (2021))_reparameterizes_weight matrix \\(W\\in\\mathbb{R}^{m\\times n}\\)을 \\(W=W_{0}+BA\\)에 넣는데, 여기서 \\(W_{0}\\)은 냉동 풀-랭크 행렬이고 \\(B\\in\\mathbb{R}^{m\\times r}\\), \\(A\\in\\mathbb{R}^{r\\times n}\\)은 부가적인 저-랭크 어댑터이다. Rank\\(r\\ll\\min(m,n)\\), \\(A\\) 및 \\(B\\)은 더 적은 수의 훈련 가능한 파라미터들을 포함하고 따라서 더 작은 최적화 상태들을 포함한다. LoRA는 동결된 사전 훈련된 가중치인 \\(W_{0}\\)의 미세 조정을 위해 메모리 사용량을 줄이기 위해 광범위하게 사용되어 왔다. 그 변형 ReLoRA는 또한 미리 학습된 저순위 어댑터를 사용하여 \\(W_{0}\\)을 주기적으로 업데이트함으로써 사전 훈련에 사용된다(Lialin et al., 2023).\n' +
      '\n' +
      '그러나 최근 많은 연구에서 이러한 저순위 재매개변수화의 한계를 보여주고 있다. 파인-튜닝을 위해, LoRA는 풀-랭크 파인-튜닝으로서 비교가능한 성능에 도달하는 것으로 나타나지 않는다(Xia et al., 2024). 처음부터 사전-트레이닝을 위해, 낮은-순위 서브공간에서 최적화하기 전에, 워밍업으로서 풀-순위 모델 트레이닝이 필요한 것으로 도시된다(Lialin et al., 2023). 두 가지 가능한 이유가 있는데, (1) 최적의 가중치 행렬은 낮은 순위가 아닐 수 있고, (2) 재매개변수화는 기울기 훈련 역학을 변화시킨다.\n' +
      '\n' +
      '**우리의 접근법:** 위의 과제를 해결하기 위해, 우리는 LoRA와 같은 일반적인 저순위 적응 방법보다 _full-parameter_ 학습을 허용하지만 _memory-efficient_가 더 많은 훈련 전략인 Gradient Low-rank Projection(**GaLore**)을 제안한다. 우리의 핵심 아이디어는 가중치 행렬(W\\)의 기울기(G\\in\\mathbb{R}^{m\\times n}\\)의 느린 변화 저순위 구조를 이용하는 것이지, 가중치 행렬 자체를 저순위로 근사화하려는 것이 아니다.\n' +
      '\n' +
      '우리는 먼저 훈련 중에 기울기 행렬 \\(G\\)이 낮은 순위가 된다는 것을 이론적으로 보여준다. 그런 다음, 기울기 행렬 \\(P^{\\top}GQ\\)을 저순위 형태로 투영하기 위해 두 개의 투영행렬 \\(P\\in\\mathbb{R}^{m\\times r}\\)과 \\(Q\\in\\mathbb{R}^{n\\times r}\\)을 계산하는 GaLore를 제안한다. 이 경우, 컴포넌트-와이즈 구배 통계에 의존하는 최적화기 상태들의 메모리 비용은 실질적으로 감소될 수 있다. 때때로 \\(P\\) 및 \\(Q\\)(예: 매 200회 반복)의 업데이트는 최소의 상각 추가 계산 비용을 발생시킨다. GaLore는 표 1과 같이 LoRA보다 메모리 효율이 높다. 실제로, 이것은 사전 트레이닝 동안 LoRA에 비해 최대 30%의 메모리 감소를 산출한다.\n' +
      '\n' +
      '우리는 GaLore가 LLM 사전 훈련과 미세 조정 모두에서 잘 작동한다는 것을 보여준다. C4 데이터 세트에서 LLaMA 7B를 사전 훈련할 때, 8비트 최적화기 및 레이어별 가중치 업데이트 기술과 결합된 8비트 GaLore는 최적화기 상태의 메모리 비용이 10% 미만으로 전체 순위 대응물과 유사한 성능을 달성한다.\n' +
      '\n' +
      '특히, 사전 훈련의 경우, GaLore는 ReLoRA와 같은 풀 랭크 훈련 준비 작업을 요구하지 않고 전체 훈련 동안 낮은 메모리를 유지한다. GaLore의 메모리 효율성 덕분에, 처음으로 값비싼 메모리 오프로딩 기술들 없이 24GB 메모리를 갖는 단일 GPU 상에서(예를 들어, NVIDIA RTX 4090 상에서) LLaMA 7B를 처음부터 트레이닝하는 것이 가능하다(도 1).\n' +
      '\n' +
      'GaLore는 또한 GLUE 벤치마크에서 사전 훈련된 LLM을 기존 저순위 방법보다 비슷하거나 더 나은 결과로 미세 조정하는 데 사용된다. 4등급의 GLUE 태스크에서 RoBERTaBase를 미세 조정할 때, GaLore는 85.89의 평균 점수를 달성하고, 85.61의 점수를 달성하는 LoRA를 능가한다.\n' +
      '\n' +
      '구배 투영법으로서, GaLore는 최적화기의 선택과 무관하며 알고리즘 1과 같이 두 줄의 코드만으로 기존의 것에 쉽게 꽂을 수 있다. 우리의 실험(그림 3) 그것은 AdamW, 8비트 Adam 및 Adafactor와 같은 인기 있는 최적화기들을 위해 작동함을 보여준다. 게다가, 그것의 성능은 그것이 도입하는 매우 적은 하이퍼-파라미터들에 둔감하다. 또한 GaLore의 수렴 분석뿐만 아니라 기울기 업데이트의 낮은 순위에 대한 이론적 정당성을 제공한다.\n' +
      '\n' +
      '##2 관련 작품\n' +
      '\n' +
      'Low-Rank AdaptationHu et al. (2021)은 Low-Rank Adaptation (LoRA)을 제안하여 Low-Rank 어댑터로 미리 훈련된 모델을 미세 조정하였다. 이 방법은 각 레이어에 대해 낮은 순위의 가중치 어댑터를 유지함으로써 메모리 풋프린트를 감소시킨다. 그 성능을 향상시키기 위해 제안된 LoRA의 몇몇 변형들이 있다(Renduchintala et al., 2023; Sheng et al., 2023; Xia et al., 2024), 멀티-태스크 학습을 지원하고(Wang et al., 2023), 그리고 메모리 풋프린트를 더 감소시키기 위해 제안된 LoRA의 몇몇 변형들이 있다(Dettmers et al., 2023). Lialin et al. (2023)은 사전 트레이닝을 위해 설계된 LoRA의 변형인 ReLoRA를 제안했지만, 표준 베이스라인으로서 비교가능한 성능을 달성하기 위해 풀-랭크 트레이닝 워밍업을 필요로 한다.\n' +
      '\n' +
      '하위 공간 학습 최근 연구에 따르면 학습은 주로 상당히 낮은 차원의 매개변수 하위 공간 내에서 발생한다(Larsen et al., 2022; Gur-Ari et al., 2018). 이러한 결과는 모델 가중치가 낮은 하위 공간 내에서 최적화되는 _subspace learning_이라는 특수한 유형의 학습을 촉진한다. 이 개념은 메타 학습 및 연속 학습을 포함하여 기계 학습의 다양한 영역에서 널리 사용되었다(Lee and Choi, 2018; Chaudhry et al., 2020).\n' +
      '\n' +
      'Projected Gradient DescentGaLore는 PGD(Projected Gradient descent)의 전통적인 주제(Chen and Wainwright, 2015; Chen et al., 2019)와 밀접한 관련이 있다. 주요 차이점은, GaLore는 다층 신경망 작업을 훈련할 때 자연스럽게 나타나는 특정 기울기 형태(예: 특정 구조를 가진 행렬)를 고려하여 많은 속성(예: Lemma 3.1, 정리 3.2, 정리 3.6)을 증명한다는 것이다. 대조적으로, 전통적인 PGD는 대부분 목적을 일반적인 블랙박스 비선형 함수로 취급하고 벡터 공간의 기울기만 연구한다.\n' +
      '\n' +
      '적응 최적화 알고리즘들에 대한 기울기 통계의 메모리 비용을 줄이기 위한 몇몇 연구들이 있었다 (Shazeer & Stern; Anil et al.; Dettmers et al., 2021). 보조인자(Shazeer & Stern)는 행-열 외부 곱에 의해 2차 통계량을 인수분해함으로써 하위 선형 메모리 비용을 달성한다. GaLore는 메모리 비용을 줄이기 위해 저순위 인수분해를 활용한다는 측면에서 Adafactor와 유사성을 공유하지만, GaLore는 기울기의 저순위 구조에 초점을 맞추고, Adafactor는 2차 통계의 저순위 구조에 초점을 맞춘다. GaLore는 1차 및 2차 통계 모두에 대한 메모리 비용을 감소시킬 수 있고, 추가 메모리 감소를 달성하기 위해 Adafactor와 조합될 수 있다. 양자화는 또한 최적화 상태들의 메모리 비용을 감소시키기 위해 널리 사용된다(Dettmers et al., 2021; Li et al., 2023). 또한, Lv et al.(2023)은 훈련 동안 가중치 그라디언트를 저장하는 메모리 비용을 줄이기 위해 융합 그라디언트 계산을 제안했다.\n' +
      '\n' +
      '기존의 메모리 효율 최적화 방법들과 달리, GaLore는 최적화기들이 그들의 전체 랭크 카운터들을 알지 못하고 저 랭크 그레디언트들을 직접 수신함에 따라 독립적으로 동작한다.\n' +
      '\n' +
      '##3GaLore : Gradient Low-Rank Projection\n' +
      '\n' +
      '### Background\n' +
      '\n' +
      '시간 단계 \\(t\\), \\(G_{t}=-\\nabla_{W}\\varphi_{t}(W_{t})\\in\\mathbb{R}^{m\\times n}\\)은 역전파(음의 기울기 행렬)이다. 그러면 정규 사전 훈련 가중치 업데이트는 다음과 같이 적을 수 있다(\\(\\eta\\)는 학습률):\n' +
      '\n' +
      '[W_{T}=W_{0}+\\eta\\sum_{t=0}^{T-1}\\tilde{G}_{t}=W_{0}+\\eta\\sum_{t=0}^{T-1}\\rho_{t}(G_{t}) \\tag{1}\\t]\n' +
      '\n' +
      '여기서 \\(\\tilde{G}_{t}\\)는 가중치 매트릭스에 추가될 최종 처리된 구배이고 \\(\\rho_{t}\\)은 엔트리-와이즈 스테이트풀 구배 규칙화기(예를 들어, Adam)이다. \\(\\rho_{t}\\)의 상태는 메모리 집약적일 수 있다. 예를 들어, Adam의 경우 gradient \\(G_{t}\\)을 \\(\\tilde{G}_{t}\\)으로 정규화하기 위해 \\(M,V\\in\\mathbb{R}^{m\\times n}\\)이 필요하다.\n' +
      '\n' +
      '[M_{t} =\\beta_{1}M_{t-1}+(1-\\beta_{1})G_{t} \\tag{2}\\] \\[V_{t} =\\beta_{2}V_{t-1}+(1-\\beta_{2})G_{t}^{2}\\] (3) \\[\\tilde{G}_{t} =M_{t}/\\sqrt{V_{t}+\\epsilon} \\tag{4}\\]\n' +
      '\n' +
      '여기서 \\(G_{t}^{2}\\) 및 \\(M_{t}/\\sqrt{V_{t}+\\epsilon}\\)은 원소별 곱셈과 나눗셈을 의미한다. \\(G_{t}/\\sqrt{V_{t}+\\epsilon}\\) (\\eta\\)는 학습률이다. \\(W\\in\\mathbb{R}^{m\\times n}\\과 함께, 이것은 \\(3mn\\)의 메모리를 필요로 한다.\n' +
      '\n' +
      'Low-rank update.linear layer \\(W\\in\\mathbb{R}^{m\\times n}\\)에 대해 LoRA와 그 변형들은 low-rank adaptor \\(AB\\)을 도입하여 update matrix의 low-rank 구조를 이용한다:\n' +
      '\n' +
      '\\[W_{T}=W_{0}+B_{T}A_{T}, \\tag{5}\\]\n' +
      '\n' +
      '여기서 \\(B\\in\\mathbb{R}^{m\\times r}\\) 및 \\(A\\in\\mathbb{R}^{r\\times n}\\), 및 \\(r\\ll\\min(m,n)\\). \\(B\\in\\mathbb{R}^{m\\times r}\\) (A\\)과 \\(B\\)은 학습 가능한 저순위 어댑터이고 \\(W_{0}\\)은 고정된 가중치 매트릭스(예: 사전 훈련된 가중치)이다.\n' +
      '\n' +
      '### 중량구배의 저순위 특성\n' +
      '\n' +
      '메모리 사용량을 줄이기 위해 낮은 순위 업데이트가 제안되지만 가중치 매트릭스를 낮은 순위로 매개변수화해야 하는지 여부는 아직 미해결 문제로 남아 있다. 많은 상황에서, 이것은 사실이 아닐 수도 있다. 예를 들어, 선형회귀 \\(\\mathbf{y}=W\\mathbf{x}\\)에서 최적 \\(W^{*}\\)이 높은 순위라면, 어떤 최적화기를 사용하든지 간에 낮은 순위 가정을 \\(W\\)에 부과하는 것은 결코 최적해로 이어지지 않는다.\n' +
      '\n' +
      '놀랍게도, 가중치 매트릭스들이 반드시 로우 랭크인 것은 아니지만, 특정 그래디언트 형태들 및 연관된 네트워크 아키텍처들에 대한 트레이닝 동안 그래디언트는 실제로 로우 랭크가 된다:\n' +
      '\n' +
      '**Lemma 3.1** (Gradient becomes low-rank during training). _Let \\(m\\leq n\\) without loss of generality. 상기 그래디언트 업데이트:_\n' +
      '\n' +
      '\\[G_{t}=A-BW_{t}C,\\쿼드 W_{t}=W_{t-1}+\\eta G_{t-1}\\tag{6}\\]\n' +
      '\n' +
      '상수 \\(A\\) 및 PSD 행렬 \\(B\\) 및 \\(C\\) 및 랜덤 초기화 \\(W_{0}\\)은 높은 확률로 낮은 순위 구배를 유도한다.\n' +
      '\n' +
      '\\[\\text{stable-rank}(G_{t})\\leq 1+\\sum_{i=2}^{m}O\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{1}}{1-\\eta\\lambda_{1}\\nu_{1}}\\right}\\text{stable-rank}(G_{t})\\leq 1+\\sum_{i=2}^{m}O\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{1}}\\t}\\tag{7}\\right)\n' +
      '\n' +
      '여기서 \\(\\nu_{1}=\\lambda_{\\min}(C)\\)은 \\(C\\)의 가장 작은 고유값이고 \\(\\lambda_{1}\\leq\\ldots\\leq\\lambda_{n}\\)은 \\(B\\)의 고유값이다. 또한 \\(\\lambda_{2}>\\lambda_{1}\\)과 \\(\\nu_{1}>0\\)이면 \\(G_{t}\\)은 지수적으로 순위-\\(1\\)으로 수렴한다.\n' +
      '\n' +
      'Lemma 3.1에서 우리는 매개변수 형태(식 6)를 가정한다. 의 그라디언트인 것을 특징으로 하는 액정 표시 장치. 이것은 제한적인 가정이 아니다. 목적 \\(\\varphi(W)=\\|\\mathbf{y}-W\\mathbf{x}\\|_{2}^{2}\\)을 갖는 단순한 선형 네트워크에 대해 홀딩할 뿐만 아니라, 깊은 ReLU 네트워크들을 포함하는 "가역 네트워크들"로 알려진 보다 일반적인 비선형 네트워크들(Tian et al., 2020)에 홀딩한다:\n' +
      '\n' +
      '**정리 3.2** (Gradient Form of reversible models).: _In a chained reversible neural network \\(\\mathcal{N}(\\mathbf{x}):=\\mathcal{N}_{L}(\\mathcal{N}_{L-1}(\\ldots\\mathcal{N}_{1}(\\mathbf{x})))\\) with \\(\\ell_{2}\\)-objective \\(\\varphi:=\\frac{1}{2}\\|mathbff{y}-\\mathcal{N}(\\mathbf{x}))\n' +
      '\n' +
      '[G_{l}=\\underbrace{J_{l}^{\\top}\\mathbf{y}\\mathbf{f}_{l-1}^{\\top}}_{\\mathcal{A}-\\underbrace{J_{l}^{\\top}J_{l}}_{\\mathcal{B}W_{l}\\underbrace{\\mathbf{f}_{l-1}\\mathbf{f}_{l-1}^{\\top}_{\\mathcal{C}\\tag{8}\\tag{B}\\mathbf{f}_{l-1}}\\mathbf{f}_{l-1}^{\\top}\\mathbf{f}_{l-1}^{\\top}}_{\\tag{C}\\tag{8}}\\mathbf{f}_{l-1}}\n' +
      '\n' +
      '\\(J_{l}:=\\operatorname{Jacobian}(\\mathcal{N}_{L})\\ldots\\operatorname{Jacobian}(\\mathcal{N}_{l+1})\\) 및 \\(\\mathbf{f}_{l}:=\\mathcal{N}_{l}(\\mathcal{N}_{l-1}\\ldots\\mathcal{N}_{1}(\\mathbf{x}))\\) 작은 로짓이 있는 소프트맥스 대물렌즈의 경우에도 역전파 구배의 유사한 구조를 증명할 수 있으므로 정리 3.2도 적용할 수 있다.\n' +
      '\n' +
      'Lemma 3.3**(Gradient structure of softmax loss): _For \\(K\\)-way logsoftmax loss\\(\\varphi(\\mathbf{f}):=-\\log\\left(\\frac{\\exp(\\mathbf{y}^{\\top}\\mathbf{f})}{\\mathbf{1}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}}^{\\top}\\mathbf{1}}^{\\top}\\mathbf{1}}^{\\top}\\mathbf{1}}^{\\top}\\\n' +
      '\n' +
      '\\mathrm{d}\\varphi=\\mathbf{y}^{\\top}\\mathrm{d}\\hat{\\mathbf{f}-\\gamma\\mathbf{f}\\hat{\\mathbf{f}\\hat{\\mathbf{f}}/K+O(\\hat{\\mathbf{f}}^{2}/K)\\mathrm{d}\\hat{\\mathbf{f}\\tag{9}\\gamma\\mathbf{f}\\hat{\\mathbf}\\tag{f}\\gamma\\mathbf{f}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\\hat{\\mathbf}\n' +
      '\n' +
      '\\(\\gamma(\\mathbf{y},\\mathbf{f})\\approx 1\\) 및 \\(\\mathbf{y}\\)는 \\(\\mathbf{y}^{\\top}\\mathbf{1}=1\\)인 데이터 레이블이다._\n' +
      '\n' +
      '이 정보로써, 가역적 네트워크 \\(\\mathbf{f}:=\\mathcal{N}(\\mathbf{x})=J_{l}(\\mathbf{x})W_{l}\\mathbf{f}_{l-1}(\\mathbf{x})\\(W_{l}\\)의 기울기 \\(G_{l}\\)은 다음과 같은 형태를 가짐을 알 수 있다.\n' +
      '\n' +
      '\\underbrace{J_{l}P_{\\mathbf{1}^{\\perp}\\mathbf{y}_{\\mathcal{A}-\\underbrace{\\gamma J_{l}^{\\top}P_{\\mathbf{1}^{\\perp}J_{l}}_{B}W_{l}\\underbrace{\\mathbf{f}_{l-1}^{\\top}/K}_{C}\\tag{10}\\text}\n' +
      '\n' +
      '이는 \\(G_{l}=A-BW_{l}C\\)의 형태와 일치한다. 가역성에 대한 자세한 소개는 부록 A.2를 확인해 주세요.\n' +
      '\n' +
      '### Gradient Low-rank Projection(GaLore)\n' +
      '\n' +
      '그래디언트 \\(G\\)는 낮은 랭크 구조를 가질 수 있기 때문에, 우리가 그래디언트 \\(G\\)의 작은 "코어"의 그래디언트 통계를 최적기 상태에서 유지할 수 있다면, 메모리 소비를 상당히 줄일 수 있다. 이것은 우리가 제안한 GaLore 전략으로 이어진다.\n' +
      '\n' +
      '**Definition 3.4**(Gradient Low-rank Projection(**GaLore**)): Gradient Low-rank Projection(**GaLore**)는 다음과 같은 Gradient update rule을 나타낸다(\\(\\eta\\)는 학습율):\n' +
      '\n' +
      '\\[W_{T}=W_{0}+\\eta\\sum_{t=0}^{T-1}\\tilde{G}_{t},\\qquad\\tilde{G}_{t}=P_{t}\\rho_{t}(P_{t}^{\\top}G_{t}Q_{t}{t})Q_{t}^{\\top},\\tag{11}\\\\tad\\tilde{G}_{t}=P_{t}\\rho_{t}(P_{t}^{\\top}G_{t}Q_{t}^{\\top},\\tag{11}\\tad\\tad\\tilde{G}_{t}=P_{t}\\rho_{t}(P_{t}^{\\top}\n' +
      '\n' +
      '여기서 \\(P_{t}\\in\\mathbb{R}^{m\\times r}\\) 및 \\(Q_{t}\\in\\mathbb{R}^{n\\times r}\\)은 투영 행렬이다.\n' +
      '\n' +
      'LoRA와 달리 GaLore는 추가적인 저순위 어댑터를 도입하는 대신 저순위 업데이트를 명시적으로 활용하므로 훈련 역학을 변경하지 않는다.\n' +
      '\n' +
      '다음에서, 우리는 GaLore가 유사한(그러나 더 일반적인) 형태의 기울기 업데이트 규칙(Eqn. 6) 하에서 수렴한다는 것을 보여준다. 이 양식은 Eqn에 해당합니다. 8이지만 배치 크기가 더 큽니다.\n' +
      '\n' +
      '**Definition 3.5** (\\(L\\)-continuity: A function \\(\\mathbf{h}(W)\\)는 (Lipschitz) \\(L\\)-continuity, if any \\(W_{1}\\) and \\(W_{2}\\), \\(\\|\\mathbf{h}(W_{1})-\\mathbf{h}(W_{2})\\|_{F}\\leq L\\|W_{1}-W_{2}\\|_{F}\\).\n' +
      '\n' +
      '**정리 3.6**(고정 투영을 갖는 GaLore의 수렴) : _그라데이션이 다음의 형태(Eqn)를 갖는다고 가정하자. 8 with batchsize \\(>1\\):_\n' +
      '\n' +
      '\\[G=\\sum_{i}A_{i}-\\sum_{i}B_{i}WC_{i} \\tag{12}\\]\n' +
      '\n' +
      '여기서, \\(B_{i}\\) 및 \\(C_{i}\\)은 PSD 행렬이고, \\(A_{i}\\), \\(B_{i}\\) 및 \\(C_{i}\\)은 \\(L_{A}\\), \\(L_{B}\\) 및 \\(L_{C}\\) 연속성이 \\(W\\) 및 \\(\\\\W_{t}\\|\\leq D\\)에 대해 있다. \\(R_{t}:=P_{t}^{\\top}G_{t}Q_{t}), \\(\\hat{B}_{it}:=P_{t}^{\\top}B_{i}(W_{t})P_{t}\\), \\(\\hat{C}_{it}:=Q_{t}^{\\top}C_{i}(W_{t})Q_{t}\\ 및 \\(\\kappa_{t}:=\\frac{1}{N}\\sum_{i}\\lambda_{\\min}(\\hat{B}_{it})\\lambda_{\\min}(\\hat{C}_{it})\\lambda_{\\min}(\\hat{C}_{it})\\lambda_{\\min}(\\hat{C}_{it})\\hat{C}_{it}:=Q_{t}^{\\top}C_{i}(W_{t}) 우리가 상수\\(P_{t}=P\\)와 \\(Q_{t}=Q\\)을 선택하면 \\(\\rho_{t}\\equiv 1\\)을 갖는 GaLore는 다음과 같다.\n' +
      '\n' +
      '\\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-L_{B}L_{C}D^{2}\\right]\\|R_{t-1}\\|_{F}\\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-L_{B}L_{C}D^{2}\\right]\\|R_{t-1}\\|_{F}\\tag{13}\\tag{13}\\right]\n' +
      '\n' +
      '결과적으로 \\(\\min_{t}\\kappa_{t}>L_{A}+L_{B}L_{C}D^{2}\\), \\(R_{t}\\to 0\\) 및 GaLore는 고정 \\(P_{t}\\) 및 \\(Q_{t}\\)으로 수렴한다.\n' +
      '\n' +
      '**설정 \\(P\\) 및 \\(Q\\)** 이 정리는 더 빠른 수렴(큰 \\(\\kappa_{t}\\)을 위해 \\(P\\)과 \\(Q\\)이 \\(\\hat{B}_{it}\\)과 \\(\\hat{C}_{it}\\)의 첫 몇 개의 가장 큰 고유벡터에 해당하는 부분공간으로 투영되어야 함을 말해준다. 양의 반무한 행렬 \\(B\\)과 \\(C\\)의 모든 고유값은 음이 아닌 반면, 그 중 일부는 매우 작아서 수렴을 방해할 수 있다. 즉, \\(G_{t}\\)이 \\(0\\)이 되는 데 오랜 시간이 걸린다. 투영 \\(P\\)과 \\(Q\\)을 사용하면 \\(P^{\\top}B_{it}P\\)과 \\(Q^{\\top}C_{it}Q\\)은 \\(B\\)과 \\(C\\)의 가장 큰 고유 부분 공간만을 포함하므로 \\(R_{t}\\)의 수렴성을 향상시킴과 동시에 메모리 사용량을 줄일 수 있다.\n' +
      '\n' +
      '\\(\\hat{B}_{it}\\)와 \\(\\hat{C}_{it}\\)의 고유구조를 구하는 것은 어렵지만 (그들은 자코비안의 일부이다), 대신에 Singular Value Decomposition (SVD)을 통해 \\(G_{t}\\)의 스펙트럼을 사용하는 한 가지 방법이 있다:\n' +
      '\n' +
      '\\[G_{t}=USV^{\\top}\\approx\\sum_{i}s_{i}u_{i}v_{i}^{\\top} \\tag{14}\\] \\[P_{t}=[u_{1},u_{2},...,u_{r}],\\quad Q_{t}=[v_{1},v_{2},...,v_{r}] \\tag{15}\\]\n' +
      '\n' +
      '**GaLore와 LoRA의 차이.** GaLore와 LoRA 모두 이름이 "하위"인 반면, 그들은 매우 다른 훈련 궤적을 따른다. 예를 들어, \\(r=\\min(m,n)\\)일 때, \\(\\rho_{t}\\equiv 1\\)을 갖는 GaLore는 원래의 모델의 정확한 훈련 궤적을 따르며, \\(\\tilde{G}_{t}=P_{t}P_{t}^{\\top}G_{t}Q_{t}^{\\top}=G_{t}^{\\top}G_{t}Q_{t}^{\\top}=G_{t}\\. 반면에, \\(BA\\)이 전체 순위(즉, \\(B\\in\\mathbb{R}^{m\\times m}\\)와 \\(A\\in\\mathbb{R}^{m\\times n}\\)에 도달하면 \\(B\\)과 \\(A\\)을 동시에 최적화하는 것은 원래의 모델과 매우 다른 훈련 궤적을 따른다.\n' +
      '\n' +
      '기억력 효율적인 훈련을 위한##4 GaLore\n' +
      '\n' +
      'LLM 프리트레이닝과 같은 복잡한 최적화 문제의 경우, 단일 저순위 서브공간으로 전체 그래디언트 궤적을 캡처하는 것이 어려울 수 있다. 한 가지 이유는 \\(B_{t}\\)과 \\(C_{t}\\)(따라서 \\(G_{t}\\))의 주요 부분 공간이 시간이 지남에 따라 변할 수 있기 때문이다. 사실, 우리가 동일한 투영 \\(P\\)과 \\(Q\\)을 유지한다면, 학습된 가중치는 더 이상 풀-파라미터 트레이닝이 아닌 이 부분 공간들을 따라서만 커질 것이다. 다행히도, 이를 위해, GaLore는 훈련 중에 부분 공간을 전환하고 메모리 풋프린트를 증가시키지 않고 전체 순위 가중치를 학습할 수 있다.\n' +
      '\n' +
      'Low-Rank 서브스페이스의### 구성\n' +
      '\n' +
      '우리는 GaLore가 낮은 하위 공간들을 가로질러 스위칭할 수 있게 한다:\n' +
      '\n' +
      '\\[W_{t}=W_{0}+\\Delta W_{T_{1}}+\\Delta W_{T_{2}}+\\ldots+\\Delta W_{T_{n}}, \\tag{16}\\]\n' +
      '\n' +
      '여기서 \\(t\\in\\left[\\sum_{i=1}^{n-1}T_{i},\\sum_{i=1}^{n}T_{i}\\right]\\) 및 \\(\\Delta W_{T_{1}}=\\eta\\sum_{t=0}^{T_{i}-1}\\tilde{G_{t}\\)는 \\(i\\)번째 부분공간 내의 모든 \\(T_{i}\\) 업데이트의 합이다. 단계 \\(t=T_{i}\\)에서 \\(i\\)번째 부분공간으로 스위칭할 때, 수학식 14에 의해 전류 구배 \\(G_{t}\\)에 대해 SVD를 수행하여 프로젝터의 \\(P_{t}\\)과 \\(Q_{t}\\)을 다시 초기화한다. 그림 2에서 \\(\\tilde{G_{t}}\\)의 궤적이 다중 저순위 부분공간을 통해 어떻게 횡단하는지 설명한다. 실험 섹션에서 다중 저순위 부분공간을 허용하는 것이 LLM의 성공적인 사전 훈련을 달성하는 열쇠임을 보여준다.\n' +
      '\n' +
      '이상의 절차에 따라, 스위칭 주파수 \\(T\\)는 하이퍼파라미터가 된다. 절제 연구(도 5) 달콤한 점이 있음을 표시합니다. 부분공간 변화가 매우 빈번할 경우, (P_{t}\\)과 (Q_{t}\\)의 계산이 필요하므로 오버헤드가 증가하고, 정리가 3.6에서 일정한 투영의 조건을 깨뜨리며, 실제로 여러 학습 단계에 걸쳐 누적되는 최적화 상태들의 충실도에도 영향을 미칠 수 있다. 반면에, 덜 빈번한 변경은 알고리즘이 최적화하는데 더 이상 중요하지 않은 영역에 고착되게 할 수 있다(정리 3.6에서의 수렴 증명은 단지 지정된 서브공간에서의 양호한 진행을 의미할 뿐, 양호한 전체 성능을 의미하지는 않는다). 최적의 \\(T\\)은 총 훈련 반복과 작업 복잡도에 따라 다르지만, \\(T=50\\)에서 \\(T=1000\\) 사이의 값은 큰 차이가 없음을 알 수 있다. 따라서, SVD에 의해 유도된 총 계산 오버헤드는 메모리 오프로딩(Rajbhandari et al., 2020)과 같은 다른 메모리-효율적인 트레이닝 기술에 비해 무시할 수 있다(\\(<10\\%\\))\n' +
      '\n' +
      '### Memory-Efficient Optimization\n' +
      '\n' +
      '** 그라디언트 통계의 메모리 풋프린트 감소** GaLore는 Adam(Kingma & Ba, 2014)과 같은 성분별 기울기 통계에 크게 의존하는 최적화기의 메모리 비용을 상당히 감소시킨다. \\(\\rho_{t}\\equiv\\mathrm{Adam}\\)일 때, \\(G_{t}\\)을 저순위 형태로 투영함으로써, Adam의 기울기 규칙화기 \\(\\rho_{t}(R_{t})\\)는 저순위 기울기 통계량만 추적하면 된다. 여기서 \\(M_{t}\\)과 \\(V_{t}\\)은 각각 1차 운동량과 2차 운동량이다. GaLore는 다음과 같이 저순위 정규화된 기울기 \\(N_{t}\\)를 계산한다:\n' +
      '\n' +
      '\\[N_{t}=\\rho_{t}(R_{t})=M_{t}/(\\sqrt{V_{t}}+\\epsilon). \\tag{17}\\]\n' +
      '\n' +
      'GaLore는 또한 유사한 업데이트 규칙을 가지며 그래디언트 통계를 저장하기 위해 많은 양의 메모리를 필요로 하는 다른 최적화기(예를 들어, Adafactor)에도 적용될 수 있다.\n' +
      '\n' +
      '프로젝션 행렬의 메모리 사용량을 줄인다. 가장 좋은 메모리 성능 절충을 달성하기 위해, 우리는 하나의 프로젝트 행렬 \\(P\\) 또는 \\(Q\\)만을 사용하며, 그렇지 않으면 \\(m\\leq n\\)과 \\(GQ\\)을 \\(P^{\\top}G\\)으로 그래디언트 \\(G\\)을 투영한다. 우리는 알고리즘 2에서 GaLore를 Adam에 적용한 알고리즘을 제시한다.\n' +
      '\n' +
      '```\n' +
      '입력: \\(m\\leq n\\)을 갖는 층 가중치 매트릭스 \\(W\\in\\mathbb{R}^{m\\times n}\\) Step size \\(\\eta\\), scale factor \\(\\alpha\\), decay rate \\(\\beta_{1},\\beta_{2}\\), rank \\(r\\), subspace change frequency \\(T\\). 1차 모멘트 \\(M_{0}\\in\\mathbb{R}^{n\\times r}\\gets 0\\) 2차 모멘트 \\(V_{0}\\in\\mathbb{R}^{n\\times r}\\gets 0\\) 초기 단계 \\(t\\gets 0\\) 반복 \\(G_{t}\\in\\mathbb{R}^{m\\times n}\\leftarrow-\\nabla_{W}\\varphi_{t}(W_{t})} else \\(P_{t}\\gets U[\\cdot,\\cdot r})}\n' +
      '```\n' +
      '\n' +
      '**알고리즘 2**아담과 GaLore\n' +
      '\n' +
      '이 설정으로, GaLore는 훈련 중에 LoRA보다 적은 메모리를 필요로 한다. 가로어는 가중치 갱신시 항상 \\(\\Delta W_{t}\\)을 \\(W_{0}\\)으로 병합할 수 있으므로, 별도의 저순위 인수분해 \\(BA\\)를 저장할 필요가 없다. 전체적으로 GaLore는 \\((mn+mr+2nr)) 메모리를 필요로 하고 LoRA는 \\((mn+mr+2nr)) 메모리를 필요로 한다.\n' +
      '\n' +
      '그림 2: GaLore를 이용한 저순위 부공간 \\(\\Delta W_{T_{1}}\\)과 \\(\\Delta W_{T_{2}}\\)을 통한 학습. [0,T_{1}-1]\\(t_{1}\\in[0,T_{1}-1]\\)에 대해, \\(W\\)은 고정된 \\(P_{t_{1}}\\)과 \\(Q_{t_{1}}\\)에 의해 결정된 부분공간에서 투영된 기울기 \\(\\tilde{G}_{t_{1}}\\)에 의해 업데이트된다. \\(T_{1}\\) 단계 후, \\(T_{1},T_{2}-1]\\)에 대한 \\(P_{t_{2}}\\)과 \\(Q_{t_{2}}\\)을 재계산하여 부분공간을 변경하고 수렴할 때까지 과정을 반복한다.\n' +
      '\n' +
      '(mn+3mr+3nr)) 메모리. GaLore와 LoRA의 비교는 표 1과 같다.\n' +
      '\n' +
      '정리 3.6은 투영 행렬을 주의 깊게 보정할 필요가 없기 때문에 양자화 및 효율적인 매개변수화에 의해 투영 행렬의 메모리 비용을 더욱 줄일 수 있으며, 이는 향후 작업을 위해 남겨둔다.\n' +
      '\n' +
      '### 기존 기술과 결합\n' +
      '\n' +
      'GaLore는 기존의 메모리 효율적인 최적화 기술과 호환된다. 우리의 작업에서, 우리는 주로 8-비트 최적화기(Dettmers et al., 2021) 및 층별 가중치 업데이트(Lv et al., 2023)와 함께 GaLore를 적용하는 것을 고려한다.\n' +
      '\n' +
      '8-비트 최적화기.Dettmers et al. (2022)는 원래의 메모리 풋프린트의 일부에서 32-비트 최적화기 성능을 유지하는 8-비트 Adam 최적화기를 제안하였다. 기존의 8비트 Adam 구현에 GaLore를 직접 적용한다.\n' +
      '\n' +
      '계층별 가중치 업데이트.실제로, 최적화기는 전형적으로 역전파 후에 모든 계층에 대해 단일 가중치 업데이트를 수행한다. 이것은 전체 무게 구배를 메모리에 저장함으로써 수행된다. 훈련 동안 메모리 풋프린트를 더 감소시키기 위해, 우리는 레이어별 가중치 업데이트들을 GaLore에 채택하며, GaLore는 역전파 동안 가중치 업데이트들을 수행한다(Lv 등, 2023).\n' +
      '\n' +
      '### GaLore의 하이퍼파라미터\n' +
      '\n' +
      'GaLore는 Adam의 원래 하이퍼파라미터 외에 LoRA에도 존재하는 rank \\(r\\), 부공간 변화 빈도 \\(T\\)(Sec. 4.1 참조), scale factor \\(\\alpha\\) 등 매우 적은 수의 추가 하이퍼파라미터만을 도입한다.\n' +
      '\n' +
      '축척 인자 \\(\\alpha\\)는 저순위 업데이트의 강도를 제어하는데, 이는 Hu et al.(2021)의 저순위 어댑터에 추가된 축척 인자 \\(\\alpha/r\\)와 유사하다. 우리는 \\(\\alpha\\)이 우리의 경우에 순위 \\(r\\)에 의존하지 않는다는 것을 주목한다. 이는 사전 훈련 시 \\(r\\)이 작을 경우, \\(\\alpha/r\\)은 미세 조정과 달리 수렴 속도에 큰 영향을 미치기 때문이다.\n' +
      '\n' +
      '## 5 Experiments\n' +
      '\n' +
      '우리는 LLM의 사전 훈련과 미세 조정 모두에 대해 GaLore를 평가한다. 모든 실험은 NVIDIA A100 GPU2에서 수행된다.\n' +
      '\n' +
      '각주 2: GaLore의 구현이 여기에서 이용가능함\n' +
      '\n' +
      'C4에 대한 사전 훈련.그 성능을 평가하기 위해, 우리는 C4 데이터세트에서 LLaMA 기반 대규모 언어 모델을 훈련하기 위해 GaLore를 적용한다. C4 데이터세트는 Common Crawl의 웹 크롤 말뭉치의 거대하고 깨끗한 버전이며, 이는 주로 언어 모델 및 단어 표현을 사전 훈련시키기 위한 것이다(Raffel et al., 2023). 실제 사전 훈련 시나리오를 가장 잘 시뮬레이션하기 위해 최대 70억 개의 모델 크기 범위에 걸쳐 충분히 많은 양의 데이터에 대해 데이터 반복 없이 훈련한다.\n' +
      '\n' +
      'Architecture and hyperparameters.We follow the experiment setup from Lialin et al. (2023) which adopted a LLaMA-based3 architecture with RMSNorm and SwiGLU activations (Touvron et al., 2023; Zhang and Sennrich, 2019; Shazeer, 2020). 각 모델 크기에 대해 학습 속도를 제외하고 방법에 걸쳐 동일한 하이퍼파라미터 세트를 사용한다. 메모리 사용량을 줄이기 위해 BF16 형식으로 모든 실험을 실행하였으며, 동일한 양의 계산 예산 하에서 각 방법에 대한 학습률을 조정하고 최상의 성능을 보고한다. 작업 설정 및 하이퍼파라미터에 대한 자세한 내용은 부록에 나와 있습니다.\n' +
      '\n' +
      '각주 3: 우리 논문의 LLaMA 자료는 LLaMA 커뮤니티 라이선스의 대상입니다.\n' +
      '\n' +
      'GLUE 태스크에 대한 미세 조정.GLUE는 감성 분석, 질문 응답 및 텍스트 수반을 포함한 다양한 태스크에 대한 NLP 모델의 성능을 평가하기 위한 벤치마크이다(Wang et al., 2019). 우리는 GLUE 태스크를 사용하여 메모리 효율적인 미세 조정을 위해 LoRA에 대해 GaLore를 벤치마킹한다.\n' +
      '\n' +
      '저순위 방법과의 비교\n' +
      '\n' +
      '먼저 모델 크기 범위에서 아담 최적화기를 사용하여 기존의 저순위 방법과 GaLore를 비교한다.\n' +
      '\n' +
      '풀 랭크 가중치 및 최적화 상태들을 갖는 Adam 최적화기를 적용하는 풀 랭크 우리의 베이스라인 방법.\n' +
      '\n' +
      'Low-RankWe는 또한 학습 가능한 Low-Rank 인수분해에 의해 가중치를 나타내는 전통적인 Low-Rank 접근법을 평가한다: \\(W=BA\\)(Kamalakara et al., 2022).\n' +
      '\n' +
      'LoRAHu et al. (2021)은 저순위 어댑터를 갖는 미리 훈련된 모델을 미세조정하기 위해 LoRA를 제안했는데, 여기서 \\(W=W_{0}+BA\\), \\(W_{0}\\)은 고정된 초기 가중치이고 \\(BA\\)은 학습 가능한 저순위 어댑터이다. 사전 훈련의 경우 \\(W_{0}\\)은\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline \\hline  & GaLore & LoRA \\\\ \\hline Weights & \\(mn\\) & \\(mn+mr+nr\\) \\\\ Optim States & \\(mr+2nr\\) & \\(2mr+2nr\\) \\\\ \\hline Multi-Subspace & ✓ & ✗ \\\\ Pre-Training & ✓ & ✗ \\\\ Fine-Tuning & ✓ & ✓ \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: GaLore와 LoRA의 비교. \\(W\\in\\mathbb{R}^{m\\times n}\\) (\\(m\\leq n\\)), rank \\(r\\)을 가정한다.\n' +
      '\n' +
      '풀-랭크 초기화 행렬. LoRA 알파를 32로 설정하고 LoRA 드롭아웃을 기본 설정으로 0.05로 설정했습니다.\n' +
      '\n' +
      'ReLoRALialin et al.(2023)은 사전 학습을 위해 설계된 LoRA의 변형으로, 주기적으로 \\(BA\\)을 \\(W\\)으로 병합하고, 최적화 상태 및 학습률을 재설정하여 새로운 \\(BA\\)을 초기화한다. ReLoRA는 병합 빈도, 학습 속도 재설정 및 최적화 상태 재설정을 주의 깊게 조정해야 한다. 우리는 공정한 비교를 위해 전체 순위 훈련 준비 없이 ReLoRA를 평가한다.\n' +
      '\n' +
      '가로어의 경우 표 2의 모든 모델 크기에 대해 부공간 주파수 \\(T\\)를 200으로, 스케일 팩터 \\(\\alpha\\)를 0.25로 설정하였으며, 각 모델 크기에 대해 모든 저순위 방법에 대해 동일한 랭크 \\(r\\)을 선택하여 모델의 모든 다중 헤드 어텐션 레이어와 피드 포워드 레이어에 적용하였다. 기본 하이퍼파라미터(예: \\(\\beta_{1}=0.9\\), \\(\\beta_{2}=0.999\\), \\(\\epsilon=10^{-8}\\)을 갖는 Adam optimizer를 이용하여 모든 모델을 학습시킨다. 또한 가중치 파라미터와 최적화 상태에 대한 메모리를 포함하여 BF16 포맷을 기반으로 메모리 사용량을 추정한다. 표 2에 나타난 바와 같이, GaLore는 다른 저순위 방법을 능가하고 풀랭크 훈련에 필적하는 성능을 달성한다. 우리는 1B 모델 크기에 대해 GaLore가 \\(r=512\\) 대신 \\(r=1024\\)일 때 전체 순위 기준선을 능가한다는 점에 주목한다. LoRA 및 ReLoRA에 비해, GaLore는 모델 파라미터들 및 최적화 상태들을 저장하기 위한 메모리를 덜 필요로 한다. 각 모델의 상세한 훈련 설정과 각 방법에 대한 우리의 기억 추정은 부록에 나와 있다.\n' +
      '\n' +
      '메모리 효율적인 최적화기를 갖는### GaLore\n' +
      '\n' +
      '우리는 GaLore가 메모리 풋프린트를 더 줄이기 위해 다양한 학습 알고리즘, 특히 메모리 효율적인 최적화기에 적용될 수 있음을 입증한다. 우리는 GaLore를 AdamW, 8비트 Adam, 및 Adafactor optimizers(Loshchilov and Hutter, 2019; Dettmers et al., 2022; Shazeer and Stern)에 적용한다. 성능 저하를 피하기 위해 1차 통계가 있는 Adafactor를 고려한다.\n' +
      '\n' +
      'LLaMA 1B 아키텍처에 10K 훈련 단계를 적용하여 성능을 평가하고, 각 설정에 대한 학습률을 조정하여 최상의 성능을 보고한다. 도 1에 도시된 바와 같다. 셋째, GaLore를 적용하는 것은 수렴에 유의한 영향을 미치지 않는 것으로 나타났다. 512의 랭크를 갖는 GaLore를 사용함으로써, 메모리 풋프린트는 8비트 Adam 또는 Adafactor 최적화기를 사용함으로써 메모리 절감에 더하여 최대 62.5%까지 감소된다. 8비트 Adam은 다른 것보다 적은 메모리를 요구하기 때문에 8비트 Adam과 함께 8비트 GaLore를 GaLore로 표시하고 7B 모델 사전 훈련 및 메모리 측정에 대한 다음 실험을 위한 기본 방법으로 사용한다.\n' +
      '\n' +
      '### LLaMA 7B 아키텍처의 확장\n' +
      '\n' +
      '7B 모델에 대한 스케일링 능력은 GaLore가 실제 LLM 사전 훈련 시나리오에 효과적인지 입증하기 위한 핵심 요소이다. LLaMA 7B 구조에서 임베딩 크기가 4096이고 전체 레이어가 32인 GaLore를 평가하고, 총 64개의 A100 GPU와 병렬로 8-노드 트레이닝을 이용하여 19.7B 토큰으로 150K 단계의 모델을 학습한다. 계산상의 제약으로 인해, 하이퍼파라미터를 튜닝하지 않고 8비트 GaLore(\\(r=1024\\))와 8비트 Adam을 단일 시도로만 비교한다. 표 3에 나타낸 바와 같이, 150K 스텝 후에, 8비트 GaLore는 14.65의 당혹성을 달성하며, 이는 14.61의 당혹성으로 8비트 Adam에 필적한다.\n' +
      '\n' +
      '### Memory-Efficient Fine-Tuning\n' +
      '\n' +
      'GaLore는 메모리 효율적인 사전 훈련을 달성할 뿐만 아니라 메모리 효율적인 미세 조정을 위해 사용될 수 있다. 우리\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r r r} \\hline \\hline  & **60M** & **130M** & **350M** & **1B** \\\\ \\hline Full-Rank & 34.06 (0.36G) & 25.08 (0.76G) & 18.80 (2.06G) & 15.56 (7.80G) \\\\ \\hline\n' +
      '**GaLore** & **34.88** (0.24G) & **25.36** (0.52G) & **18.95** (1.22G) & **15.64** (4.38G) \\\\ Low-Rank & 78.18 (0.26G) & 45.51 (0.54G) & 37.41 (1.08G) & 142.53 (3.57G) \\\\ LoRA & 34.99 (0.36G) & 33.92 (0.80G) & 25.58 (1.76G) & 19.21 (6.17G) \\\\ ReLoRA & 37.04 (0.36G) & 29.37 (0.80G) & 29.08 (1.76G) & 18.33 (6.17G) \\\\ \\hline \\(r/d_{model}\\) & 128 / 256 & 256 / 768 & 256 / 1024 & 512 / 2048 \\\\ Training Tokens & 1.1B & 2.2B & 6.4B & 13.1B \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: C4 데이터 세트에서 다양한 크기의 LLaMA 모델을 사전 훈련하는 저순위 알고리즘과의 비교. BF16 형식을 기반으로 한 매개변수 및 최적화 상태 총계의 메모리 추정치와 함께 검증 복잡성이 보고된다. GaLore의 실제 메모리 풋프린트는 그림 1에 보고되어 있다. 도 1 및 도 4에 도시된 바와 같다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|r|r r r r} \\hline \\hline  & **Mem** & **40K** & **80K** & **120K** & **150K** \\\\ \\hline\n' +
      '**8비트 GaLore** & 18G & 17.94 & 15.39 & 14.95 & 14.65\\\\\n' +
      '8-bit Adam & 26G & 18.09 & 15.47 & 14.83 & 14.61 \\\\ \\hline Tokens (B) & & 5.2 & 10.5 & 15.7 & 19.7 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 150K 단계들에 대해 C4 데이터세트 상에서 LLaMA 7B를 사전 트레이닝한다. 검증 당혹감 및 메모리 추정치가 보고된다.\n' +
      '\n' +
      'GallLore를 사용하여 GLUE 태스크에 대해 미리 훈련된 RoBERTa 모델을 미세 조정하고 전체 미세 조정 기준선 및 LoRA와 성능을 비교한다. 우리는 LoRA를 위해 Hu et al.(2021)의 하이퍼파라미터를 사용하고 GaLore에 대한 학습률과 스케일 팩터를 조정한다. 표 4에 나타낸 바와 같이, GaLore는 메모리 풋프린트가 적은 대부분의 태스크에서 LoRA보다 우수한 성능을 달성한다. 이는 GaLore가 LLM 사전 훈련과 미세 조정 모두에 대한 전체 스택 메모리 효율적인 훈련 전략 역할을 할 수 있음을 보여준다.\n' +
      '\n' +
      '### 메모리 및 처리량 측정\n' +
      '\n' +
      '표 2는 메모리 사용 측면에서 다른 방법에 비해 GaLore의 이론적 이점을 제공하지만, 다양한 방법으로 LLaMA 모델을 훈련하는 실제 메모리 풋프린트를 256의 토큰 배치 크기로 측정한다. 훈련은 활성화 체크포인팅, 메모리 오프로딩 및 최적화 상태 분할 없이 단일 장치 설정에서 수행된다(Rajbhandari et al., 2020).\n' +
      '\n' +
      '**24G 메모리를 가진 소비자 GPU에 대해 7B 모델을 훈련한다.** 도 4에 도시된 바와 같이, 8-비트 GaLore는 BF16 베이스라인 및 8-비트 Adam보다 상당히 적은 메모리를 필요로 하며, GPU 당 작은 토큰 배치 크기(최대 500 토큰)로 LLaMA 7B를 사전-트레이닝하기 위해 22.0G 메모리만을 필요로 한다. 이 메모리 풋프린트는 NVIDIA RTX 4090과 같은 단일 GPU의 24GB VRAM 용량 내에 있으며, 활성화 체크포인팅이 활성화되면 GPU당 토큰 배치 크기를 최대 4096까지 증가시킬 수 있으며, GPU당 배치 크기가 작지만 모델 병렬성에 비해 GPU간 통신에 훨씬 낮은 대역폭을 요구하는 데이터 병렬성으로 확장할 수 있다. 따라서, GaLore가 RTX 4090s와 같은 소비자 GPU 상의 탄성 트레이닝(Lin et al.) 7B 모델에 사용될 수 있을 가능성이 있다.\n' +
      '\n' +
      '구체적으로, 우리는 그림 1에서 메모리 분해를 제시한다. 이는 8비트 GaLore가 BF16 Adam 베이스라인 및 8비트 Adam에 비해 각각 37.92G(63.3%) 및 24.5G(52.3%)의 총 메모리를 감소시킨다는 것을 보여준다. 8-비트 Adam에 비해 8-비트 GaLore는 (1) 낮은 순위 기울기 투영은 최적화 상태 저장의 9.6G(65.5%) 메모리를 감소시키고, (2) 레이어별 가중치 업데이트를 사용하면 가중치 기울기 저장의 13.5G 메모리를 감소시킨다.\n' +
      '\n' +
      '**GaLore.**의 Throughput overhead.** 또한 8비트 GaLore 및 기타 방법으로 사전 훈련 LLaMA 1B 모델의 Throughput을 측정하며, 여기서 결과는 부록에서 찾을 수 있다. 특히, 현재 8비트 GaLore의 구현은 1019.63 토큰/초를 달성하며, 이는 8비트 Adam 구현과 비교하여 17%의 오버헤드를 유발한다. 가로어에 대한 레이어별 가중치 업데이트를 비활성화하면 1109.38토큰/초를 달성하여 처리량이 8.8% 향상됩니다. 우리는 우리의 결과가 훈련 처리량에 상당한 영향을 미칠 수 있는 오프로딩 전략이나 체크포인팅을 요구하지 않는다는 점에 주목한다. 우리는 향후 작업을 위해 GaLore 구현의 효율성을 최적화하는 것을 남긴다.\n' +
      '\n' +
      '##6 삭제에 관한 연구\n' +
      '\n' +
      '사전 훈련 중에 몇 개의 부분 공간이 필요한가요?\n' +
      '\n' +
      '그림 1과 같이 아공간의 너무 빈번한 변화와 너무 느린 변화가 수렴에 해를 끼친다는 것을 관찰한다. 5(좌측).\n' +
      '\n' +
      '도 4: 256의 토큰 배치 사이즈로 평가된, 다양한 모델 사이즈들에서 상이한 방법들에 대한 메모리 사용량. 8비트 GaLore(유지 그레이드)는 레이어별 가중치 업데이트들을 비활성화하지만 트레이닝 동안 가중치 그라디언트들을 저장한다.\n' +
      '\n' +
      '도 3: 10K 단계들에 대한 C4 데이터세트 상에서 LLaMA 1B를 사전 트레이닝하기 위한 상이한 최적화기들에 GaLore를 적용하는 것. 교육 단계에 대한 검증 복잡성이 보고됩니다. 우리는 1B 모델 차원이 2048인 512와 1024의 순위를 가진 각 최적화기에 GaLore를 적용한다.\n' +
      '\n' +
      '그 이유는 Sec. 4.1에서 논의되었으며 작은 \\(r\\)에 대해 더 널리 퍼져 있는데, 이러한 경우 잘못된 부분공간에서 최적화 단계를 낭비하지 않기 위해 적절한 시간에 부분공간 전환이 이루어져야 하는 반면 큰 \\(r\\)의 경우 구배 업데이트가 더 많은 부분공간을 커버하여 더 많은 쿠션을 제공하기 때문이다.\n' +
      '\n' +
      '하위공간의 순위가 수렴에 어떤 영향을 미치는가?\n' +
      '\n' +
      '일정 범위의 순위 값 내에서 순위를 낮추는 것은 수렴 속도에 약간만 영향을 주어 선형에 가까운 느린 속도를 유발한다. 도 1에 도시된 바와 같다. 도 5(오른쪽)에서, 80K 스텝을 사용하는 128의 랭크를 갖는 트레이닝은 20K 스텝을 사용하는 512의 랭크를 갖는 트레이닝보다 더 낮은 손실을 달성한다. 이것은 GaLore가 메모리와 계산 비용 사이의 절충에 사용될 수 있음을 보여준다. 기억이 제한된 시나리오에서 순위를 줄이면 성능을 보존하기 위해 더 많은 단계를 훈련하는 동안 기억 예산 내에 머물 수 있다.\n' +
      '\n' +
      '## 7 Conclusion\n' +
      '\n' +
      '본 논문에서는 대용량 언어 모델을 위한 메모리 효율적인 사전 학습 및 미세 조정 전략인 GaLore를 제안한다. GaLore는 대규모 LLM 사전 훈련과 미세 조정을 위해 효율성과 성능을 모두 유지하면서 최적화 상태에서 메모리 사용량을 최대 65.5%까지 크게 줄인다.\n' +
      '\n' +
      '본 논문에서는 (1) 비전 트랜스포머 및 확산 모델과 같은 다른 유형의 모델 훈련에 GaLore를 적용하는 것, (2) 양자화 또는 특수 파라미터화를 통해 저메모리 프로젝션 매트릭스를 채택함으로써 메모리 효율을 더욱 향상시키는 것, (3) 저대역폭 소비자 등급 하드웨어에 대한 탄성 데이터 분산 훈련의 가능성을 탐색하는 것을 포함하는 GaLore에 대한 몇 가지 오픈 문제를 식별한다.\n' +
      '\n' +
      '우리는 우리의 연구가 저순위 기울기 투영의 관점에서 기억력 효율적인 LLM 훈련 전략에 대한 향후 연구에 영감을 주기를 바란다. 우리는 GaLore가 소비자 등급의 하드웨어와 제한된 자원으로 커뮤니티가 대규모 언어 모델을 훈련시키는 귀중한 도구가 될 것이라고 믿는다.\n' +
      '\n' +
      '## 8 충격성명\n' +
      '\n' +
      '본 논문은 LLM 사전학습과 미세조정의 환경적 영향을 줄이기 위해 대규모 언어모델(LLM)의 메모리 효율성을 향상시키는 것을 목표로 한다. 더 낮은 메모리로 하드웨어에서 더 큰 모델의 훈련을 가능하게 함으로써, 우리의 접근법은 LLM 훈련과 관련된 에너지 소비 및 탄소 발자국을 최소화하는 데 도움이 된다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Anil et al. (2020) Anil, R., Gupta, V., Koren, T., and Singer, Y. 메모리 효율적인 적응 최적화\n' +
      '*Chaudhry et al. (2020) Chaudhry, A., Khan, N., Dokania, P., and Torr, P. Continual Learning in Low-rank Orthogonal Subspaces. In _Advances in Neural Information Processing Systems_, volume 33, pp. 9900-9911. Curran Associates, Inc., 2020.\n' +
      '* Chen et al. (2019) Chen, H., Raskutti, G., and Yuan, M. 일반화된 저순위 텐서 회귀 분석을 위한 볼록하지 않은 투영 경사 하강 Journal of Machine Learning Research_, 20(5):1-37, 2019. ISSN 1533-7928.\n' +
      '* Chen et al. (2016) Chen, T., Xu, B., Zhang, C., and Guestrin, C. Training Deep Nets with Sublinear Memory Cost, April 2016.\n' +
      '* Chen & Wainwright (2018) Chen, Y. and Wainwright, M. J. Fast low-rank estimation\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c|c c c c c c c|c} \\hline \\hline  & **Memory** & **CoLA** & **STS-B** & **MRPC** & **RTE** & **SST2** & **MNLI** & **QNLI** & **QQP** & **Avg** \\\\ \\hline Full Fine-Tuning & 747M & 62.24 & 90.92 & 91.30 & 79.42 & 94.57 & 87.18 & 92.33 & 92.28 & 86.28 \\\\ \\hline\n' +
      '**GaLore (rank=4)** & 253M & 60.35 & **90.73** & **92.25** & **79.42** & **94.04** & **87.00** & **92.24** & 91.06 & **85.89** \\\\ LoRA (rank=4) & 257M & **61.38** & 90.57 & 91.07 & 78.70 & 92.89 & 86.82 & 92.18 & **91.29** & 85.61 \\\\ \\hline\n' +
      '**GaLore (rank=8)** & 257M & 60.06 & **90.82** & **92.01** & **79.78** & **94.38** & **87.17** & 92.20 & 91.11 & **85.94** \\\\ LoRA (rank=8) & 264M & **61.83** & 90.80 & 91.90 & 79.06 & 93.46 & 86.94 & **92.25** & **91.22** & 85.93 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 미리 훈련된 RoBERTa-Base를 사용하여 GLUE 벤치마크에서 메모리 효율적인 미세 조정을 위한 GaLore 평가. 우리는 모든 과제의 평균 점수를 보고한다.\n' +
      '\n' +
      '그림 5: 130M 모델에 대한 GaLore의 절제 연구. **좌측:** 가변 서브스페이스 업데이트 주파수 \\(T\\) ** 오른쪽:** 다양한 하위 공간 순위 및 훈련 반복.\n' +
      '\n' +
      '예상 경사 하강: 일반 통계 및 알고리즘 보증, 2015년 9월.\n' +
      '* Chowdhery et al.(2022) Chowdhery, A., Narang, S., Devlin, J., Bosma, G., Tsyashchenko, S., Schuh, P., Shi, K., Maynez, J., Ghemawat, S., Dounes, P., Tay, Y., Prabhakaran, B., Firat, O., Catasta, M., Dai, J., Meier-Hellstern, K., M. PaLM: 2022년 10월 Pathways를 이용한 스케일링 언어 모델링.\n' +
      '* Dettmers et al. (2021) Dettmers, T., Lewis, M., Shleifer, S., and Zettlemoyer, L. 블록별 양자화를 통한 8비트 옵티마이저_ arXiv:2110.02861[cs]_, October 2021.\n' +
      '* Dettmers et al. (2022) Dettmers, T., Lewis, M., Shleifer, S., and Zettlemoyer, L. 2022년 6월 블록별 양자화를 통한 8비트 옵티마이저입니다.\n' +
      '* Dettmers et al. (2023) Dettmers, T., Pagnoni, A., Holtzman, A., and Zettlemoyer, L. QLoRA: Quantized LLMs의 효율적인 Finetuning, May 2023.\n' +
      '* Ding et al. (2022) Ding, N., Qin, Y., Yang, G., Wei, F., Yang, Z., Su, Y., Hu, S., Chen, Y., Chan, C.-M., Chen, W., Yi, J., Zhao, W., Wang, X., Liu, Z., Zheng, H.-T., Chen, J., Liu, Y., Tang, J., Li, J., and Sun, M. 델타 튜닝: 2022년 3월 사전 훈련된 언어 모델을 위한 매개변수 효율적인 방법에 대한 포괄적인 연구\n' +
      '* Gur-Ari et al. (2018) Gur-Ari, G., Roberts, D. A., and Dyer, E. Gradient Descent Happens in a Tiny Subspace, December 2018.\n' +
      '* Hu et al. (2021) Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. LoRA: 2021년 10월, 대규모 언어 모델의 낮은 순위 적응.\n' +
      '* Kamalakara et al. (2022) Kamalakara, S. R., Locatelli, A., Venkitesh, B., Ba, J., Gal, Y., and Gomez, A. N. Exploring Low Rank Training of Deep Neural Networks, September 2022.\n' +
      '* Kingma & Ba(2014) Kingma, D. P. and Ba, J. Adam: Method for Stochastic Optimization. _ arXiv:1412.6980[cs]_, 2014년 12월.\n' +
      '* Larsen et al. (2022) Larsen, B. W., Fort, S., Becker, N., and Ganguli, S. 우리가 심층 네트워크를 훈련시키기 위해 얼마나 많은 자유도가 필요한가: 손실 풍경 관점, 2022년 2월.\n' +
      '*Lee & Choi(2018) Lee, Y. 및 최승 2018년 6월, 학습한 계층별 미터법 및 하위 공간을 사용한 기울기 기반 메타 학습.\n' +
      '* Li et al. (2023) Li, B., Chen, J., and Zhu, J. Memory Efficient Optimizers with 4-bit States. [https://arxiv.org/abs/2309.01507v3] (https://arxiv.org/abs/2309.01507v3), September 2023.\n' +
      '* Lialin et al. (2023) Lialin, V., Shivagunde, N., Muckatira, S., and Rumshisky, A. ReLoRA: High-Rank Training Through Low-Rank Updates, December 2023.\n' +
      '* Lin et al.(2019) Lin, H., Zhang, H., Ma, Y., He, T., Zhang, Z., Zha, S., and Li, M. 탄성 분산 훈련을 위한 동적 미니 배치 SGD: 리소스의 림보에서 학습. URL[http://arxiv.org/abs/1904.12043](http://arxiv.org/abs/1904.12043)\n' +
      '* Loshchilov & Hutter (2019) Loshchilov, I. and Hutter, F. Decoupled Weight Decay Regularization, January 2019.\n' +
      '* Lv et al. (2023) Lv, K., Yang, Y., Liu, T., Gao, Q., Guo, Q., and Qiu, X. 제한된 리소스를 가진 대규모 언어 모델에 대한 전체 매개변수 미세 조정, 2023년 6월.\n' +
      '* Raffel et al. (2023) Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, September 2023.\n' +
      '* Rajbhandari et al. (2020) Rajbhandari, S., Rasley, J., Ruwase, O., and He, Y. 2020년 5월 트리온 매개변수 모델을 통한 메모리 최적화\n' +
      '* Renduchintala et al. (2023) Renduchintala, A., Konuk, T., and Kuchaiev, O. Tied-Lora: Weight tieing으로 LoRA의 파라미터 효율을 향상시키는 것, 2023년 11월.\n' +
      '* Shazeer(2020) Shazeer, N. GLU 변종 변압기 개선 2020년 2월\n' +
      '* Shazeer & Stern(2020) Shazeer, N. 및 스턴, M. 보조인자: 하위 선형 메모리 비용이 포함된 적응형 학습 속도입니다.\n' +
      '* Sheng et al. (2023) Sheng, Y., Cao, S., Li, D., Hooper, C., Lee, N., Yang, S., Chou, C., Zhu, B., Zheng, L., Keutzer, K., Gonzalez, J. E., and Stoica, I. S-LoRA: Serving Th thousands of Concurrent LoRA Adapters, November 2023.\n' +
      '* Tian et al. (2020) Tian, Y., Yu, L., Chen, X., and Ganguli, S. 듀얼 딥 네트워크를 이용한 자기 지도 학습의 이해 arXiv preprint arXiv:2010.00578_, 2020.\n' +
      '* Tian et al.(2024) Tian, Y., Wang, Y., Zhang, Z., Chen, B., and Du, S. Joma: mlp와 주의의 관절 동역학을 통해 다층 변압기를 복조하는 것 _ ICLR_, 2024.\n' +
      '* Touvron et al. (2020) Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S., Lachaux, M. - A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Scheletn, A., Silva, R., Smith, E. M., Subramanian, R., Tan, E. E., Tang, B., Taylor, R., Williams, A., Kuan, J. X., Zu, P., Yan, Z., Zarov, I., Zambadur, M., Fan, A., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T. Llama 2: 오픈 파운데이션 및 미세 조정 채팅 모델, 2023년 7월.\n' +
      '* Wang et al. (2019) Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. R. GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding, February 2019.\n' +
      '* Wang et al. (2023) Wang, Y., Lin, Y., Zeng, X., and Zhang, G. MultiLoRA: Democraticatizing LoRA for Better Multi-Task Learning, November 2023.\n' +
      '* Xia et al. (2024) Xia, W., Qin, C., and Hazan, E. Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning, January 2024.\n' +
      '* Zhang & Sennrich (2019) Zhang, B. and Sennrich, R. 2019년 10월 루트 평균 제곱근 계층 정규화\n' +
      '\n' +
      '## 부록 A 증명서\n' +
      '\n' +
      '### Gradient becomes low-rank\n' +
      '\n' +
      '**Lemma A.1** (Gradient becomes low-rank during training). _Let \\(m\\leq n\\) without loss of generality. 상기 그래디언트 업데이트:_\n' +
      '\n' +
      '\\[G_{t}=A-BW_{t}C,\\쿼드 W_{t}=W_{t-1}+\\eta G_{t-1}\\tag{6}\\]\n' +
      '\n' +
      '상수 \\(A\\) 및 PSD 행렬 \\(B\\) 및 \\(C\\) 및 랜덤 초기화 \\(W_{0}\\)은 높은 확률로 낮은 순위 구배를 유도한다.\n' +
      '\n' +
      '\\[\\text{stable-rank}(G_{t})\\leq 1+\\sum_{i=2}^{m}O\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{1}}{1-\\eta\\lambda_{1}\\nu_{1}}\\right}\\text{stable-rank}(G_{t})\\leq 1+\\sum_{i=2}^{m}O\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{1}}\\t}\\tag{7}\\right)\n' +
      '\n' +
      '여기서 \\(\\nu_{1}=\\lambda_{\\min}(C)\\)은 \\(C\\)의 가장 작은 고유값이고 \\(\\lambda_{1}\\leq\\ldots\\leq\\lambda_{n}\\)은 \\(B\\)의 고유값이다. 또한 \\(\\lambda_{2}>\\lambda_{1}\\)과 \\(\\nu_{1}>0\\)이면 \\(G_{t}\\)은 지수적으로 순위-\\(1\\)으로 수렴한다.\n' +
      '\n' +
      '증거가 있어요\n' +
      '\n' +
      '\\[G_{t}=A-BW_{t}C=A-B(W_{t-1}+\\eta G_{t-1})C=G_{t-1}-\\eta BG_{t-1}C\\tag{18}\\]\n' +
      '\n' +
      '\\(B=UD_{B}U^{\\top}\\)와 \\(C=VD_{C}V^{\\top}\\)을 \\(B\\)과 \\(C\\)의 고유분해라고 하자. \\\\ (D_{B}=\\operatorname{diag}(\\lambda_{1},\\ldots,\\lambda_{m})\\)와 \\(D_{C}=\\operatorname{diag}(\\nu_{1},\\ldots,\\nu_{n})\\)은 오름차순으로 정렬된 고유값(\\(\\lambda_{1}\\leq\\lambda_{m}\\)과 \\(\\nu_{1}\\leq\\lambda_{n}\\)이다. (H_{t}:=U^{\\top}G_{t}V\\)를 정의한다. \\(\\operatorname{rank}(H_{t})=\\operatorname{rank}(G_{t})\\) 이 분명하고 우리는 다음과 같다.\n' +
      '\n' +
      '\\[H_{t}:=U^{\\top}G_{t}V=H_{t-1}-\\eta D_{B}H_{t-1}D_{C}\\tag{19}\\]\n' +
      '\n' +
      '\\(h_{t,ij}\\)이 \\(H_{t}\\)의 \\(ij\\) 성분이라고 가정하면, 위의 식으로부터 다음과 같다.\n' +
      '\n' +
      '\\[h_{t,ij}=h_{t-1,ij}-\\eta\\lambda_{i}\\nu_{j}h_{t-1,ij}=(1-\\eta\\lambda_{i}\\nu_{j})h_{t-1,ij}=(1-\\eta\\lambda_{i}\\nu_{j})^{t}h_{0,ij}\\tag{20}\\]\n' +
      '\n' +
      '그런 다음 큰 고유값에 해당하는 첫 번째 행 \\(i\\)과 열 \\(j\\)에 대해 \\(h_{t,ij}\\to 0\\)과 \\(\\operatorname{rank}(H_{t})\\)이 작아진다.\n' +
      '\n' +
      '좀 더 정확하게 하기 위해, 안정적인 순위를 고려하라:\n' +
      '\n' +
      '\\[\\text{stable-rank}(G_{t})=\\text{stable-rank}(H_{t})=\\frac{\\|H_{t}\\|_{F}^{2}}{\\|H_{t}\\|_{2}^{2}}\\tag{21}\\text{t}\n' +
      '\n' +
      '그럼 우린...\n' +
      '\n' +
      '\\[\\|H_{t}\\|_{F}^{2}=\\sum_{i=1}^{m}\\sum_{j=1}^{n}(1-\\eta\\lambda_{i}\\nu_{j}^{2t}h_{0,ij}^{2} \\tag{22}\\\\tag{n}(1-\\eta\\lambda_{i}\\nu_{j})\n' +
      '\n' +
      'and\n' +
      '\n' +
      '\\[\\|H_{t}\\|_{2}^{2}\\geq\\sum_{j=1}^{n}H_{t,1j}^{2}=\\sum_{j=1}^{n}(1-\\eta\\lambda_{1}\\nu_{j}^{2t}h_{0,1j}^{2}\\tag{23}\\tag{23}\\textq\\sum_{j=1}^{n}(1-\\eta\\lambda_{1}\\nu_{j}}^{n}(1-\\eta\\lambda_{1}\\nu_{j}}^{2t}h_{0,1j}^{2}\\tag{23}\\textq\\sum_{j=1}^{n}(1-\\eta\\lambda_{1}\\nu_{j}}}^{n}(1-\\eta\\lambda_{1}\\nu_{j}}}^{n}\n' +
      '\n' +
      '높은 확률로 \\(h_{0,1j}^{2}\\geq\\epsilon_{0}^{2}\\), \\(|h_{1i}^{2}|\\leq c_{0}\\)이 경계되므로, 우리는 다음과 같다.\n' +
      '\n' +
      '\\leq 1+\\frac{c_{0}^{2}{\\epsilon_{0}^{2}}\\frac{\\sum_{i=2}^{m}\\frac{\\sum_{j=1}^{n}(1-\\eta\\lambda_{i}\\nu_{j}}{\\sum_{j=1}^{n}(1-\\eta\\lambda_{1}\\nu_{j}}}{\\sum_{j=1}^{n}(1-\\eta\\lambda_{1}\\nu_{j}}}^{2t}}\\tag{24}\\t}\n' +
      '\n' +
      '중간 부등식을 이용하여 \\(a,b,c,d>0\\)에 대한 \\(\\frac{a}{b}\\leq\\frac{a+c}{b+d}\\leq\\frac{c}{d}\\)을 구하였으며, 따라서 \\(i\\geq 2\\)번째 행에 대한 \\(\\lambda_{i}\\geq\\lambda_{1}\\)이 성립함을 알 수 있었다.\n' +
      '\n' +
      '\\frac{\\sum_{j=1}^{n}(1-\\eta\\lambda_{i}\\nu_{j})^{2t}{\\sum_{j=1}^{n}(1-\\eta\\lambda_{1}\\nu_{j})^{2t}\\leq\\max_{j}\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{j}}{1-\\eta\\lambda_{i}\\nu_{j}}}{2t}}\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{1}}{1-\\eta\\lambda_{1}\\nu_{1}}}{2t}\\leq\\tag{25}\\right)^{2t}\\leq\\max_{j}\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{1}}}{1-\\eta\\lamb\n' +
      '\n' +
      '및 결론은 다음과 같다.\n' +
      '\n' +
      '### Reversibility\n' +
      '\n' +
      '**Definition A.2** (Reversiblity (Tian et al., 2020)): 입력 \\(\\mathbf{y}=\\mathcal{N}(\\mathbf{x})\\)을 출력 \\(\\mathbf{y})에 매핑하는 네트워크 \\(\\mathcal{N}\\)는, \\(\\mathbf{y}=K(\\mathbf{x};W)\\mathbf{x}\\)가 존재한다면, \\(\\mathbf{y}=K(\\mathbf{x};W)\\mathbf{x}\\) 및 역전파 구배 \\(\\mathbf{g}_{\\mathbf{g}=K^{\\top}(\\mathbf{x};W)\\mathbf{g}_{\\mathbf{y}\\)를 만족하며, 여기서 \\(\\mathbf{g}_{\\mathbf{y}\\)는 출력 \\(\\mathbf{y}\\)에서 역전파 구배이다. 여기서 \\(\\mathbf{x};W)\\)는 네트워크 \\(\\mathcal{N}\\)에서 입력 \\(\\mathbf{x}\\)과 가중치 \\(W\\)에 따라 달라진다.\n' +
      '\n' +
      '많은 층들은 (바이어스가 없는) 선형 층, 가역 활성화(예를 들어, ReLU, 누출 ReLU, 다항식 등)를 포함하여 가역적이라는 점에 유의한다. 나아가, 이들을 결합하여 보다 복잡한 아키텍처를 구성할 수 있다:\n' +
      '\n' +
      '특성 1**.: \\(\\mathcal{N}_{1}\\) 및 \\(\\mathcal{N}_{2}\\)이 가역적인 네트워크라면, (**Parallel**) \\(\\mathbf{y}=\\alpha_{1}\\mathcal{N}_{1}(\\mathbf{x})+\\alpha_{2}\\mathcal{N}_{2}(\\mathbf{x}))\\)은 상수 \\(\\alpha_{1}\\) 및 \\(\\mathbf{x}\\)에 대해 가역적이며, (**Composition**) \\(\\mathbf{y}=\\mathcal{N}_{2}(\\mathbf{x}))\\은 가역적이다.\n' +
      '\n' +
      '이 성질로부터 ResNet 구조 \\(\\mathbf{x}+\\mathcal{N}(\\mathbf{x})\\)가 가역적임을 알 수 있다. \\(\\mathcal{N}\\)에 바이어스 없는 선형층과 가역적 활성화가 포함되어 있다면, 이는 실제로 흔히 있는 일이다. 자세한 분석은 (Tian et al., 2020)의 부록 A를 확인하시기 바랍니다. 자기 주의와 같은 아키텍처의 경우, 한 가지 가능성은 JoMA(Tian et al., 2024)를 활용하여 분석하고, 우리는 향후 작업을 위해 떠난다.\n' +
      '\n' +
      '체인형 가역 네트워크의 구배는 다음과 같은 구조를 갖는다:\n' +
      '\n' +
      '**정리 3.2** (Gradient Form of reversible models).: _In a chained reversible neural network \\(\\mathcal{N}(\\mathbf{x}):=\\mathcal{N}_{L}(\\mathcal{N}_{L-1}(\\dots\\mathcal{N}_{1}(\\mathbf{x})))) with \\(\\ell_{2}\\)-objective \\(\\varphi:=\\frac{1}{2}\\|mathbff{y}-\\mathcal{N}(\\mathbf{x}))\n' +
      '\n' +
      '\\underbrace{J_{l}^{\\top}\\mathbf{y}\\mathbf{f}_{l-1}^{\\top}_{\\Lambda}-\\underbrace{J_{l}^{\\top}J_{l}}_{\\hat{\\mathbf{g}}W_{l}\\underbrace{\\mathbf{f}_{l-1}\\bm{f}_{l-1}^{\\top}_{C}\\tag{8}\\tambda}\n' +
      '\n' +
      '\\(J_{l}:=\\operatorname{Jacobian}(\\mathcal{N}_{L})\\dots\\operatorname{Jacobian}(\\mathcal{N}_{l+1})\\) 및 \\(\\mathbf{f}_{l}:=\\mathcal{N}_{l}(\\mathcal{N}_{l-1}\\dots\\mathcal{N}_{1}(\\mathbf{x}))\\)\n' +
      '\n' +
      '증거: 계층화된 가역 네트워크에 대해 우리는\n' +
      '\n' +
      '\\mathcal{N}(\\mathbf{x})=\\mathcal{N}_{L}(\\mathcal{N}_{L-1}(...\\mathcal{N}_{1}(\\mathbf{x})))=K_{L}(\\mathbf{x})K_{L-1}(\\mathbf{x})\\dots K_{1}(\\mathbf{x})\\mathbf{x}\\tag{26}\\mathbf{x}}\n' +
      '\n' +
      '\\(\\mathbf{f}_{l}:=\\mathcal{N}_{l}(\\dots\\mathcal{N}_{l-1}(\\mathbf{x}))))와 \\(J_{l}:=K_{L}(\\mathbf{x})\\dots K_{l+1}(\\mathbf{x})\\)을 구하고, 선형층 \\(l\\\\(\\mathcal{N}(\\mathbf{x})=J_{l}W_{l}_{l-1}\\mathbf{l-1}\\)을 구할 수 있다. 따라서, 가중치 행렬 \\(W_{l}\\)을 갖는 선형 층 \\(l\\)에 대해, 우리는:\n' +
      '\n' +
      '\\mathbf{y}-\\mathcal{N}(\\mathbf{y}-J_{l}W_{l}\\mathbf{f}{l-1})\\mathbf{f}{l}^{\\top}N}(\\mathbf{y}-J_{l}W_{l}\\mathbf{l}{l-1})\\mathbf{r}(\\mathbf{y}-J_{l}\\mathbf{l}{l}\\text{terms not related to}\n' +
      '\n' +
      '이것은 \\(W_{l}\\)의 구배를 제공한다:\n' +
      '\n' +
      '[G_{l}=J_{l}^{\\top}\\mathbf{y}\\mathbf{f}_{l-1}^{\\top}-J_{l}^{\\top}J_{l}W_{l}\\mathbf{f}_{l-1}\\mathbf{f}_{l-1}^{\\top}\\tag{31}\\mathbf{f}_{l-1}^{\\top}\\mathbf{f}_{l-1}^{\\top}\\mathbf{f}_{l-1}^{\\top}\\tag{31}\\top}\n' +
      '\n' +
      'Lemma A.3**(Gradient structure of softmax loss): _For \\(K\\)-way logsoftmax loss\\(\\varphi(\\mathbf{f}):=-\\log\\left(\\frac{\\exp(\\mathbf{y}^{\\top}\\mathbf{f})}{\\mathbf{1}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}^{\\top}\\mathbf{1}}^{\\top}\\mathbf{1}}^{\\top}\\mathbf{1}}^{\\top}\\mathbf{1}}^{\\top}\\\n' +
      '\n' +
      '\\mathrm{d}\\varphi=\\mathbf{y}^{\\top}\\mathrm{d}\\hat{\\mathbf{f}}-\\gamma\\hat{\\mathbf{f}^{top}\\mathrm{d}\\hat{\\mathbf{f}}/K+O(\\hat{\\mathbf{f}^{2}/K)\\mathrm{d}\\hat{\\mathbf{f}}\\tag{9}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{f}\\tag{\n' +
      '\n' +
      '\\(\\gamma(\\mathbf{y},\\mathbf{f})\\approx 1\\) 및 \\(\\mathbf{y}\\)는 \\(\\mathbf{y}^{\\top}\\mathbf{1}=1\\)인 데이터 레이블이다._\n' +
      '\n' +
      '증명: \\(\\hat{\\mathbf{f}}:=P_{\\mathbf{1}}^{\\perp}\\mathbf{f}\\)를 네트워크 출력의 0-평균 버전으로 한다. 그리고 \\(\\mathbf{1}^{\\top}\\hat{\\mathbf{f}=0\\)와 \\(\\mathbf{f}=\\hat{\\mathbf{f}+c\\mathbf{1}\\)을 갖는다. 그러므로, 우리는:\n' +
      '\n' +
      '\\log\\left(\\frac{\\exp(c)\\exp(\\mathbf{y}^{\\top}\\hat{\\mathbf{f}})}{\\exp(\\hat{\\mathbf{f}})\\right)=\\mathbf{y}^{\\top}\\hat\\hat{x^{2}+o(x^{2}})\\log(\\exp(x)=1+x+\\frac{x^{2}+o(x^{2}})\\mathbf{f}}-\\log(\\mathbf{1}^{\\top}\\exp(\\hat{\\mathbf{f}})})\\tag{32}\\tag{32}\\text(\\exp(x)=1+x+\\frac{x^{2}+o(x^{2}})\\text(\\exp(x)=1+x+\\frac{x^{2}}+o(x^{2}})\n' +
      '\n' +
      '\\hat{\\mathbf{1}^{\\top}\\exp(\\hat{\\mathbf{f}} =\\mathbf{1}^{\\top}(\\mathbf{1}+\\hat{\\mathbf{f}+\\frac{1}{2}\\hat{\\mathbf{f}}^{2})+o(\\hat{\\mathbf{f}}^{2})=K(1+\\hat{\\mathbf{f}}^{\\top}\\hat{\\mathbf{f}}/2K+o(\\hat{\\mathbf{f}}^{2}/K)) \\tag{33}\\tag{33}\\hat{\\mathbf{f}}^{f}}\\hat{\\mathbf{f}}^{f}}/2K+o(\\hat{\\mathbf{f}}^{2}/K))\n' +
      '\n' +
      'So\n' +
      '\n' +
      '\\[-\\varphi =\\mathbf{y}^{\\top}\\hat{\\mathbf{f}}-\\log(1+\\hat{\\mathbf{f}}^{\\top}\\hat{\\mathbf{f}}/2K+o(\\hat{\\mathbf{f}}^{2}/K)-\\log K\\tag{34}\\g\n' +
      '\n' +
      'Therefore\n' +
      '\n' +
      '\\mathrm{d}\\varphi =\\mathbf{y}^{\\top}\\mathrm{f}-\\frac{\\gamma}K}\\hat{\\mathbf{f}^{\\top}\\mathrm{d}\\hat{\\mathbf{f}}^{\\top}\\mathrm{d}\\hat{\\mathbf{f}+O\\left(\\frac{\\hat{\\mathbf{f}}^{2}}K}\\mathrm{d}\\hat{\\mathbf{f}}\\tag{35}\\tag{35}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text{f}\\text\n' +
      '\n' +
      '여기서 \\(\\gamma:=(1+\\hat{\\mathbf{f}^{\\top}\\hat{\\mathbf{f}}/2K+o(\\hat{\\mathbf{f}^{2}/K))^{-1}\\approx 1\\이다.\n' +
      '\n' +
      'GaLore의 융합\n' +
      '\n' +
      '**정리 3.6**(고정 투영을 갖는 GaLore의 수렴) : _그라데이션이 다음의 형태(Eqn)를 갖는다고 가정하자. 8 with batchsize \\(>1\\):_\n' +
      '\n' +
      '\\[G=\\sum_{i}A_{i}-\\sum_{i}B_{i}WC_{i} \\tag{12}\\]\n' +
      '\n' +
      '여기서, \\(B_{i}\\) 및 \\(C_{i}\\)은 PSD 행렬이고, \\(A_{i}\\), \\(B_{i}\\) 및 \\(C_{i}\\)은 \\(L_{A}\\), \\(L_{B}\\) 및 \\(L_{C}\\) 연속성이 \\(W\\) 및 \\(\\\\W_{t}\\|\\leq D\\)에 대해 있다. \\(R_{t}:=P_{t}^{\\top}G_{t}Q_{t}), \\(\\hat{B}_{it}:=P_{t}^{\\top}B_{i}(W_{t})P_{t}\\), \\(\\hat{C}_{it}:=Q_{t}^{\\top}C_{i}(W_{t})Q_{t}\\ 및 \\(\\kappa_{t}:=\\frac{1}{N}\\sum_{i}\\lambda_{\\min}(\\hat{B}_{it})\\lambda_{\\min}(\\hat{C}_{it})\\lambda_{\\min}(\\hat{C}_{it})\\lambda_{\\min}(\\hat{C}_{it})\\hat{C}_{it}:=Q_{t}^{\\top}C_{i}(W_{t}) 우리가 상수\\(P_{t}=P\\)와 \\(Q_{t}=Q\\)을 선택하면 \\(\\rho_{t}\\equiv 1\\)을 갖는 GaLore는 다음과 같다.\n' +
      '\n' +
      '\\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-L_{B}L_{C}D^{2}\\right]\\|R_{t-1}\\|_{F}\\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-L_{B}L_{C}D^{2}\\right]\\|R_{t-1}\\|_{F}\\tag{13}\\tag{13}\\right]\n' +
      '\n' +
      '결과적으로 \\(\\min_{t}\\kappa_{t}>L_{A}+L_{B}L_{C}D^{2}\\), \\(R_{t}\\to 0\\) 및 GaLore는 고정 \\(P_{t}\\) 및 \\(Q_{t}\\)으로 수렴한다.\n' +
      '\n' +
      '증명: \\(\\mathrm{vec}(AXB)=(B^{\\top}\\otimes A)\\mathrm{vec}(X)\\) 여기서 \\(\\otimes\\)은 Kronecker 곱이고, 기울기 가정은 다음과 같이 쓸 수 있다:\n' +
      '\n' +
      '\\[g_{t}=a_{t}-S_{t}w_{t} \\tag{36}\\]\n' +
      '\n' +
      '여기서 \\(g_{t}:=\\mathrm{vec}(G_{t})\\in\\mathbbb{R}^{mn}\\), \\(w_{t}:=\\mathrm{vec}(W_{t})\\in\\mathbbb{R}^{mn}\\)는 \\(G_{t}\\) 및 \\(W_{t}\\), \\(a_{t}:=\\frac{1}{N}\\sum_{i}\\mathrm{vec}(A_{it}) 및 \\(S_{t}=\\frac{1}{N}\\sum_{i}C_{it}\\otimes B_{it}\\)의 벡터화된 버전이다.\n' +
      '\n' +
      '동일한 표기법을 사용하여, 다음을 나타내는 것이 분명하다:\n' +
      '\n' +
      '(Q\\otimes P)^{\\top}G_{t} = (Q^{\\top}\\otimes P^{\\top})\\mathrm{vec}(G_{t})=\\mathrm{vec}(R_{t})=:r_{t}\\tag{37}\\]\\mathrm{vec}(\\tilde{g}_{t}:=\\mathrm{vec}(\\tilde{G}_{t})=\\mathrm{vec}(PP^{\\top}G_{t}Q^{\\top})=(Q\\otimes P)r_{t}\\tag{38}\\t}\n' +
      '\n' +
      '그리고 \\(g_{t}\\)에 대한 재귀적 갱신 규칙을 유도한다:\n' +
      '\n' +
      '[=(a_{t}-a_{t}-S_{t}w_{t}\\tag{39}\\][=(a_{t}-a_{t-1})+(S_{t-1}-S_{t-1}w_{t}\\](40) \\[=e_{t}+a_{t-1}-S_{t-1}(w_{t-1}+\\eta\\tilde{g}_{t-1}-\\tilde{g}_{t-1}}\\tag{42}\\](41) \\[=e_{t}+g_{t-1}-\\tilde{g}_{t-1}}\\tag{42}\\](41) \\[=e_{t}+g_{t-1}-\n' +
      '\n' +
      '여기서 \\(e_{t}:=(a_{t}-a_{t-1})+(S_{t-1}-S_{t})w_{t}\\이다. 왼쪽에 \\((Q\\otimes P^{\\top}\\)을 곱하면 다음과 같다.\n' +
      '\n' +
      '[r_{t}=(Q\\otimes P)^{\\top}e_{t}+r_{t-1}-\\eta(Q\\otimes P)^{\\top}S_{t-1}(Q\\otimes P)r_{t-1}\\tag{43}\\]Let let (Q\\otimes P)^{\\top}e_{t}+r_{t-1}-\\eta(Q\\otimes P)^{\\top}S_{t-1}(Q\\otimes P)r_{t-1}\\tag{43}\\]Let Let\n' +
      '\n' +
      '[\\hat{S}_{t}:=(Q\\otimes P)^{\\top}S_{t}(Q\\otimes P)=\\frac{1}{N}\\sum_{i}(Q\\otimes P)^{\\top}(C_{it}\\otimes B_{it})(Q\\otimes P)=\\frac{1}{N}\\sum_{i}(Q^{\\top}C_{it}Q) \\otimes(P^{\\top}B_{it}P) \\tag{44}\\times\n' +
      '\n' +
      '그럼 우린...\n' +
      '\n' +
      '[r_{t}=(I-\\eta\\hat{S}_{t-1})r_{t-1}+(Q\\otimes P)^{\\top}e_{t}\\tag{45}\\]\n' +
      '\n' +
      '이제 우리는 규범을 지켜야 한다. \\(P\\)과 \\(Q\\)은 \\(P^{\\top}P=I\\)과 \\(Q^{\\top}Q=I\\)을 갖는 투영 행렬이기 때문에, 우리는 다음과 같이 한다.\n' +
      '\n' +
      '\\[\\|(Q\\otimes P)^{\\top}e_{t}\\|_{2}=\\|\\mathrm{vec}(P^{\\top}E_{t}Q}\\|_{2}=\\|P^{ \\top}E_{t}Q\\|_{F}\\leq\\|E_{t}\\|_{F}\\tag{46}\\tag{46}\\tag{\n' +
      '\n' +
      '여기서 \\(E_{t}:=\\frac{1}{N}\\sum_{i}(A_{it}-A_{i,t-1})+\\frac{1}{N}\\sum_{i}(B_{i,t-1}W_{t}C_{i,t-1}-B_{it}W_{t}C_{it})\\이다. 그래서 우리는 단지 \\(\\|E_{t}\\|_{F}\\)을 묶어야 한다. 명심해\n' +
      '\n' +
      '\\eqL_{A}\\eqL_{A}\\eqL_{A}\\eqL_{A}\\eqL_{T-1}\\eqL_{F}\\eqL_{C}D^{2}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\eqL_{C}\\\n' +
      '\n' +
      '이제 우리는 \\(\\hat{S}_{t-1}\\)의 최소 고유값을 추정한다. \\(\\underline{\\lambda}_{it}:=\\lambda_{\\min}(P^{\\top}B_{it}P)) 및 \\(\\underline{\\nu}_{it}:=\\lambda_{\\min}(Q^{\\top}C_{it}Q)\\), \\(\\lambda_{\\min}((P^{\\top}B_{it}P)\\otimes(Q^{\\top}C_{it}Q))=\\underline{\\lambda}_{it}\\underline{\\nu}_{it} 및 임의의 단위 벡터\\(\\mathbf{\\nu}\\)에 대해,\n' +
      '\n' +
      'mmathbf{v}=\\frac{1}{N}\\sum_{i}\\mathbf{\\upsilon}^{\\top}\\left[\\left(P^{\\top}B_{it}P\\right)\\otimes(Q^{\\top}C_{it}Q\\right)\\mathbf{v}\\geq\\frac{1}{N}\\sum_{i}\\underline{\\nu}_{it}\\tag{50}\\mathbf{\\upsilon}^{\\top}\\left[\\left(P^{\\top}B_{it}P\\right)\\otimes(Q^{\\top}C_{it}Q\\right]\\mathbf{v}\\geq\\frac{1}{N}\\sum_{i}\\underline{\\nu}_{it}\\tag{50}\\mathbf{\\upsilon}^{\\top}\\left[\\left(P^{\\top}B_{it}P\\right}\\otimes(Q^{\\top}C_{it}Q\\\n' +
      '\n' +
      '따라서\\(\\lambda_{\\min}(\\hat{S}_{t})\\geq\\frac{1}{N}\\sum_{i}\\underline{\\lambda}_{it}\\underline{\\nu}_{it}\\. 따라서 \\(\\lambda_{\\max}(I-\\eta\\hat{S}_{t-1})\\leq 1-\\frac{\\eta}N}\\sum_{i}\\underline{\\lambda}_{i,t-1}\\underline{\\nu}_{i,t-1}\\ulq 1-\\frac{\\eta}N}\\sum_{i}\\underline{\\lambda}_{i,t-1}\\underline{\\nu}_{i,t-1}\\ulq 따라서, \\(\\kappa_{t}:=\\frac{1}{N}\\sum_{i}\\underline{\\lambda}_{it}\\underline{\\nu}_{it}\\)과 \\(\\|r_{t}\\|_{2}=\\|R_{t}\\|_{F}\\)이라는 사실을 이용하여, 우리는 다음과 같다.\n' +
      '\n' +
      '\\\\[\\|R_{t}\\|_{F}\\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-2L_{B}L_{C}D^{2}\\right]\\|R_{t-1}\\|_{F}\\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-2L_{B}L_{C}D^{2}\\right]\\|R_{t-1}\\|_{F}\\tag{51}\\ta(\\kappa_{t-1}-L_{A}-2L_{B}L_{C}D^{2}\\right]\\|R_{t-1}\\|_{F}\\tag{51}\\eta(\\kappa_{t-1}-L_{A}-2L_{B}L_{A}-2L_{B}L_{B}L_{C}D^{2\n' +
      '\n' +
      '및 결론은 다음과 같다.\n' +
      '\n' +
      '## 사전훈련실험의 부록 B 상세\n' +
      '\n' +
      '### 아키텍처 및 하이퍼파라미터\n' +
      '\n' +
      '우리는 사전 훈련에 사용되는 LLaMA 아키텍처와 하이퍼파라미터에 대한 세부 사항을 소개한다. 표 5는 모델 크기에 걸쳐 LLaMA 모델의 가장 높은 하이퍼파라미터를 보여준다. 우리는 배치 크기가 131K 토큰인 모든 모델에 대해 256의 최대 시퀀스 길이를 사용한다. 모든 실험을 위해 훈련 단계의 첫 10%에 대해 학습 속도 워밍업을 채택하고, 학습 속도 스케줄에 코사인 어닐링을 사용하여 초기 학습 속도의 10%로 감쇠한다.\n' +
      '\n' +
      '각 모델의 크기(60M에서 1B까지)에 대한 모든 방법에 대해, \\({0.01,0.005,0.001,0.0005,0.0001\\}\\)의 집합으로부터 그들이 선호하는 학습률을 튜닝하고, 검증 복잡성에 기초하여 최상의 학습률을 선택한다. 우리는 GaLore가 하이퍼파라미터에 둔감하고 다른 모델 크기에 걸쳐 동일한 학습률로 안정적인 경향이 있다는 것을 발견했다. 모든 모델에서 GaLore는 학습률 \\(0.01\\), 스케일 팩터 \\(0.25\\), 부공간 변화 빈도 \\(200\\) 등 동일한 하이퍼파라미터를 사용한다. 우리는 \\(\\alpha\\)을 분수 학습률로 볼 수 있기 때문에 LLaMA 모델에서 대부분의 모듈(예: 다중 헤드 주의 및 피드 포워드 레이어)은 실제 학습률 \\(0.0025\\)을 갖는다는 점에 주목한다. 이는 훈련 손실의 스파이크를 피하기 위해 일반적으로 학습률 \\(\\leq 0.001\\)을 사용하는 전체 순위 기준선에 비해 비교적 큰 안정적인 학습률이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c} \\hline \\hline Params & Hidden & Intermediate & Heads & Layers & Steps & Data amount \\\\ \\hline\n' +
      '60M&512&1376&8&8&10K&\\(1.3\\,\\mathrm{B}\\) \\\\\n' +
      '130M & 768 & 2048 & 12 & 12 & 20K & \\(2.6\\,\\mathrm{B}\\) \\\\\n' +
      '350M & 1024 & 2736 & 16 & 24 & 60K & \\(7.8\\,\\mathrm{B}\\) \\\\ \\(1\\,\\mathrm{B}\\) & 2048 & 5461 & 24 & 32 & 100K & \\(13.1\\,\\mathrm{B}\\) \\\\ \\(7\\,\\mathrm{B}\\) & 4096 & 11008 & 32 & 32 & 150K & \\(19.7\\,\\mathrm{B}\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 평가를 위한 LLaMA 모델의 하이퍼파라미터. 데이터 양은 토큰에 지정됩니다.\n' +
      '\n' +
      '### Memory Estimates\n' +
      '\n' +
      '특정 컴포넌트에 대한 GPU 메모리 사용량은 직접 측정하기 어렵기 때문에, 서로 다른 모델 크기에서 각 방법에 대한 가중치 파라미터와 최적화 상태들의 메모리 사용량을 추정한다. 상기 추정은 BF16 포맷에 의해 트레이닝된, 원래 파라미터들의 수 및 저-랭크 파라미터들의 수에 기초한다. 예를 들어, 60M 모델의 경우 LoRA(\\(r=128\\))는 저순위 어댑터의 경우 \\(42.7\\)M 파라미터, 원래 가중치의 경우 \\(60M\\) 파라미터가 요구되어 가중치 파라미터의 경우 \\(0.20\\)G, 최적기의 경우 \\(0.17\\)G의 메모리 비용이 발생한다. 표 6은 본문에 보고된 총 메모리에 대한 칭찬으로, 다른 모델 크기에 대한 다른 방법에 대한 가중치 매개변수 및 최적기 상태에 대한 메모리 추정치를 보여준다.\n' +
      '\n' +
      '## 미세조정 실험부록 C 상세\n' +
      '\n' +
      'GLUE 벤치마크에서 미리 학습된 RoBERTa-Base 모델을 Hugging Face1에서 제공하는 모델을 이용하여 미세 조정하고, 배치 크기가 32인 CoLA를 제외한 모든 태스크에 대해 배치 크기가 16인 30개의 에폭에 대한 모델을 학습하고, GaLore에 대한 학습률과 스케일 팩터를 조정한다. 표 7은 GaLore를 위한 RoBERTa-Base 미세 조정에 사용되는 하이퍼파라미터를 나타낸다.\n' +
      '\n' +
      '각주 1: [https://huggingface.co/transformers/model_doc/roberta.html](https://huggingface.co/transformers/model_doc/roberta.html)\n' +
      '\n' +
      '\\begin{table}\n' +
      '\n' +
      '\\end{table}\n' +
      '표 6: 가중치 파라미터 및 최적화기 상태에 대한 메모리 추정치.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\n' +
      '\\end{table}\n' +
      '표 7: GaLore용 미세조정 RoBERTa 베이스의 하이퍼파라미터.\n' +
      '\n' +
      '## 부록 D 추가 메모리 측정\n' +
      '\n' +
      '표 8과 같이 토큰 배치 크기가 256인 C4 데이터셋에서 LLaMA 1B 모델을 사전 훈련하기 위한 다양한 방법의 메모리 사용량을 경험적으로 측정한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c c} \\hline \\hline Model Size & Layer Wise & Methods & Token Batch Size & Memory Cost & \\multicolumn{2}{c}{Throughput} \\\\  & & & & & \\#Tokens / s & \\#Samples / s \\\\ \\hline \\multirow{4}{*}{1B} & \\multirow{4}{*}{✗} & AdamW & 256 & 13.60 & 1256.98 & 6.33 \\\\  & & Adafactor & 256 & 13.15 & 581.02 & 2.92 \\\\  & & Adam8bit & 256 & 9.54 & 1569.89 & 7.90 \\\\  & & 8-bit GaLore & 256 & 7.95 & 1109.38 & 5.59 \\\\ \\hline \\multirow{4}{*}{1B} & \\multirow{4}{*}{✓} & AdamW & 256 & 9.63 & 1354.37 & 6.81 \\\\  & & Adafactor & 256 & 10.32 & 613.90 & 3.09 \\\\ \\cline{1-1}  & & Adam8bit & 256 & 6.93 & 1205.31 & 6.07 \\\\ \\cline{1-1}  & & 8-bit GaLore & 256 & 5.63 & 1019.63 & 5.13 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: LLaMA 1B 모델에 대한 메모리 및 처리량 측정.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>