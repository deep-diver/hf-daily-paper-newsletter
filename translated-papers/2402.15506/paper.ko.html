<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# AgentOhana: 효율적인 에이전트 학습을 위한 통합 데이터 및 훈련 파이프라인 설계\n' +
      '\n' +
      'Jianguo Zhang\n' +
      '\n' +
      'Equal contributions.\n' +
      '\n' +
      'Tian Lan\n' +
      '\n' +
      'Equal contributions.\n' +
      '\n' +
      'Rithesh Murthy\n' +
      '\n' +
      'Zhiwei Liu\n' +
      '\n' +
      'Weiran Yao\n' +
      '\n' +
      'Juntao Tan\n' +
      '\n' +
      'Thai Hoang\n' +
      '\n' +
      'Liangwei Yang\n' +
      '\n' +
      'Yihao Feng\n' +
      '\n' +
      'Zuxin Liu\n' +
      '\n' +
      'Tulika Awalgaonkar\n' +
      '\n' +
      '후안 카를로스 니들스\n' +
      '\n' +
      'Silvio Savarese\n' +
      '\n' +
      'Shelby Heinecke\n' +
      '\n' +
      'Huan Wang\n' +
      '\n' +
      'Caiming Xiong\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '대규모 언어 모델(LLM)에 의해 구동되는 자율 에이전트는 상당한 연구 관심을 받았다. 그러나 에이전트 기반 작업을 위해 LLM의 잠재력을 완전히 활용하면 다중 회전 궤적을 특징으로 하는 다양한 데이터 소스의 이질적인 특성으로 인해 고유한 문제가 발생한다. 본 논문에서는 이러한 문제를 해결하기 위한 종합적인 해결책으로 **AgentOhana**를 소개한다. _ AgentOhana_는 다양한 시나리오에 걸쳐 별개의 환경에서 에이전트 궤적을 집계한다. 이러한 궤적을 세심하게 표준화하고 일관된 형식으로 통합하여 에이전트 훈련에 최적화된 일반 데이터 로더의 생성을 능률화합니다. 데이터 통합을 활용하여, 우리의 훈련 파이프라인은 데이터 세트 분할 및 모델 훈련 동안 서로 다른 데이터 소스에 걸쳐 균형을 유지하고 장치 전반에 걸쳐 독립적인 무작위성을 보존한다. 또한 다양한 벤치마크에서 탁월한 성능을 보여주는 AI 에이전트 맞춤형 대형 액션 모델인 **xLAM-v0.1**을 제시한다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '대형 언어 모델(LLM)은 코드 생성, 수학적 추론, 대화 AI, 및 AI 에이전트(OpenAI, 2023; Jiang et al., 2023; Zhang et al., 2023; Liu et al., 2023; Nijkamp et al., 2023)에서 강한 능력을 보여주었다. 이 중 LLM 구동 자율 에이전트가 주목을 받고 있다. AutoGPT(Gravitas, 2023), OpenAgent(Xie et al., 2023), BOLAA(Liu et al., 2023b), XAgent(Team, 2023) 및 LangChain(Chase, 2023)과 같은 LLM 에이전트에 대한 최근 프레임워크는 에이전트 작업을 지원하도록 설계되었으며, 이들은 오픈 소스 커뮤니티에 상당한 관심을 끌었다.\n' +
      '\n' +
      '그럼에도 불구하고, 많은 기존 에이전트들은 GPT-4(OpenAI, 2023) 및 Gemini(Team et al., 2023)와 같은 폐쇄 소스 LLM API들에 의해 전력을 공급받는데, 이는 주로 대부분의 오픈 소스 모델들이 롱-호라이즌 추론을 수행하고 복잡한 에이전트 태스크들을 처리하는데 어려움을 겪기 때문이다(Liu et al., 2023a;b). 최근에는 상용 API에만 의존하지 않고 오픈 소스 모델을 교육하려는 노력이 계속되고 있다. 예를 들어, AgentLM(Zeng et al., 2023), Lemur(Xu et al., 2023) 및 Lumos(Yin et al., 2023)는 Llama-2 패밀리(Touvron et al., 2023), React(Yao et al., 2023), SelfReflection(Shinn et al., 2023; Madan et al., 2023; Wang et al., 2023b)과 같은 특별한 추론, 계획 및 행동 프롬프트 설계와 함께 에이전트에 대해 트레이닝되어 능력을 향상시킨다. 이를 위해 툴라마(Qin et al., 2023), 툴알파카(Tang et al., 2023) 및 API뱅크(Li et al., 2023)와 같은 오픈소스 에이전트 관련 데이터와 에이전트 모델을 훈련하여 추론, 도구 사용 및 계획에 대한 능력을 향상시키는 작업이 있다. 그들은 에이전트 관련 작업에 대해 인상적인 성과를 보여왔습니다.\n' +
      '\n' +
      '그러나 LLM 에이전트에 대한 데이터 환경을 탐색하는 것은 다양한 데이터 세트 모음, 특히 에이전트 관련 데이터에서 일반적으로 관찰되는 다중 턴의 상호 작용을 특징으로 하는 비표준화된 데이터 형식을 처리할 때 점점 더 복잡해진다. 데이터 세트 전반에 걸친 데이터 구조, 구문, 레이블링 규칙 및 처리 방법의 이질성은 LLM의 훈련 및 미세 조정 프로세스를 복잡하게 하는 어마어마한 도전을 제기한다. 표준화된 형식의 부족은 이질적인 데이터 소스를 조화시키는 데 복잡성을 도입하여 잠재적인 편향과 불일치를 초래한다. 이러한 문제를 해결하려면 강력한 전처리 파이프라인을 개발하고 다양한 데이터 형식에 걸친 통일 및 호환성을 보장하며 표준화되지 않은 표현에서 발생할 수 있는 편향을 완화하기 위한 전략을 구현해야 한다. 포괄적이고 다양한 데이터 세트에 대한 요구가 증가함에 따라 비표준화된 데이터 형식을 관리하는 효과적인 방법을 설정하는 것은 다양한 응용 프로그램에 걸쳐 LLM 에이전트의 강력한 성능을 보장하는 데 중요하다.\n' +
      '\n' +
      '이 작업에서 우리는 _AgentOhana_라는 이름의 첫 번째 포괄적인 에이전트 데이터 수집 및 훈련 파이프라인을 구축함으로써 기존의 격차를 해소한다. 대화형 AI 및 명령어 기반 미세 조정 분야에서 DialogStudio(Zhang et al., 2023) 및 FLAN(Longpre et al., 2023)의 주목할 만한 업적으로부터 영감을 이끌어내고, _AgentOhana_는 LLM 에이전트 궤적에서 마주치는 다양한 데이터 구조 및 형식을 수용하도록 맞춤화된다. 이 제품은 특수 프로세스를 사용하여 이질적인 데이터를 균일한 형식으로 변환하여 여러 소스에 걸쳐 원활한 통합을 달성합니다. 또한 컬렉션은 고품질 궤적을 보장하기 위해 세심한 필터링 프로세스를 거쳐 품질 관리의 추가 계층을 도입한다. 데이터 표준화 및 통합을 활용하여, 우리의 훈련 파이프라인은 데이터 세트 분할 및 모델 훈련 동안 장치 전반에 걸친 독립적인 무작위성을 보존하여 훈련 프로세스에 편향의 부주의한 도입을 방지한다. 이 포괄적인 접근 방식은 에이전트오아나가 환경 전반에 걸친 궤적을 통합할 뿐만 아니라 수집된 데이터의 전반적인 품질과 신뢰성뿐만 아니라 모델의 성능과 견고성을 향상시킨다는 것을 보장한다. 우리의 접근 방식은 AgentOhana가 연구 커뮤니티를 위한 다재다능하고 접근 가능한 리소스 역할을 하여 향후 응용 프로그램을 위한 개발 프로세스를 간소화합니다. 본 논문의 기여도는 다음과 같다.\n' +
      '\n' +
      '데이터 이질성에 대한 혁신적인 솔루션**: 우리는 다중 회전 LLM 에이전트 궤적과 관련된 이종 데이터 소스의 통합과 관련된 복잡한 문제를 해결하기 위해 설계된 선구적인 플랫폼인 _AgentOhana_를 소개한다. 이 기여는 데이터 다양성과 단편화의 장애물을 극복하는 데 중요한 진전을 나타낸다.\n' +
      '**광범위한 환경 커버리지**: _AgentOhana_는 포괄적인 시나리오 배열에 걸쳐 10개의 별개의 환경에서 에이전트 데이터를 통합하여 자신을 구별한다. 이러한 다양한 컬렉션은 광범위한 연구 기회를 촉진하여 에이전트 행동 및 상호 작용의 다양한 측면에 대한 조사를 가능하게 한다.\n' +
      '* **데이터 표준화 및 통일**: 이 작업의 핵심 성과는 LLM 에이전트 데이터를 일관된 형식으로 체계적으로 표준화 및 통일하는 것이다. 이 프로세스는 일반적인 데이터 로더의 생성을 가능하게 하여, 상이한 데이터 소스에 걸쳐 평형을 유지하고 디바이스에 걸쳐 독립적인 랜덤성을 보존하는 에이전트 트레이닝을 위해 데이터세트를 최적화한다.\n' +
      '**대형 에이전트 모델**: AI 에이전트에 맞춘 견고한 대형 액션 모델인 XLAM-v0.1을 개발했습니다. 세 가지 엄격한 벤치마크에 걸쳐 강력한 성능을 입증하는 XLAM-v0.1은 고성능 AI 에이전트의 교육을 용이하게 하는 _AgentOhana_의 잠재력을 보여준다.\n' +
      '\n' +
      '## 2 Methodology\n' +
      '\n' +
      '그림 1에 표시된 _AgentOhana_의 워크플로우에서 볼 수 있듯이, 우리는 이질적인 데이터 소스에서 궤적을 통합하기 위해 설계된 동질적인 다중 턴 데이터 형식을 채택한다. 또한, 공개 또는 근접 세계 모델을 기반으로 에이전트 궤적을 평가하고 필터링하는 _AgentRater_라는 방법을 소개한다. 마지막으로, 다양한 데이터 세트를 분산 훈련 프로세스에 원활하게 통합할 수 있도록 일반 데이터 로더를 중앙 구성 요소로 채택한다.\n' +
      '\n' +
      '다양한 데이터셋의 이질성\n' +
      '\n' +
      '에이전트 데이터의 형식은 환경에 따라 크게 달라져 데이터 통합, 교육 및 모델 분석에 상당한 어려움과 과제를 제기한다. 그림 2의 1행에 나와 있듯이 두 가지 별개의 환경의 궤적은 서로 다른 환경에서 보편적으로 관찰되는 현상인 현저하게 다른 데이터 구성 방법을 보여준다. 예를 들어, HotpotQA 환경(Liu et al., 2023b)은 전체 목표 궤적을 _prompt_ 키 하에서 단일 문자열로 통합한다. 이 설계는 단일 문자열로부터 각 단계 \\(i^{th}\\in[1,N]\\)에 대한 _user query_, _Thought_, _Model Action: i와 함께 _Env Observation: i_를 검색하기 위한 노력이 필요하다. 반대로 ToolAlpaca는 각 단계에서 프롬프트 입력, 모델 출력 및 관찰의 식별 및 매칭이 필요하며, 다음 단계로 진행하기 전에 궤적 이력의 정확한 집계가 뒤따른다. 부록 4는 네 가지 환경의 원래 궤적에 대한 더 많은 예를 보여준다.\n' +
      '\n' +
      '### 호모지니어스 멀티턴 에이전트 궤적 표준화\n' +
      '\n' +
      '확인된 문제를 해결하기 위해 그림 2의 2행에 표시된 대로 통합 에이전트 데이터 형식을 제안하여 제안된 통합 궤적 데이터 형식을 보여준다. 각 궤적의 모든 관련 내용을 캡슐화하기 위해 동질 JSON 사전 형식을 구성한다. 구체적으로, 우리의 포맷은 초기 사용자 질의를 저장하기 위한 _user query_, 해당 모델을 식별하기 위한 _model name_ 및 사용 가능한 모델 성능 점수를 기록하기 위한 _score_와 같은 모든 중요한 요소를 통합한다. 이러한 요소는 모델을 구별하는 데 사용될 수 있으며 DPO(Rafailov et al., 2023), 자체 보상(Yuan et al., 2024) 및 AI 피드백(Guo et al., 2024) LLM과 같은 최첨단 훈련 방법론을 위한 쌍별 샘플의 개발을 용이하게 할 준비가 되어 있다. 또한 보조 궤적 정보 또는 특정 노트를 _other 정보_에 저장하여 추가 분석 또는 모델 개선 이니셔티브에 대한 참조를 제공한다.\n' +
      '\n' +
      '다중 턴 에이전트 궤적 정보의 보존 및 분석을 강화하기 위해 각 상호작용 턴의 세부 사항을 캡처하는 _step_의 구조화된 정의를 제안한다. 단계는 _input_, _output_ 및 _next observation_의 세 가지 주요 구성 요소로 구성된다. _input_ 컴포넌트는 현재 프롬프트 및 과거 상호 작용의 이력 기록을 통합하여 상호 작용에 대한 포괄적인 컨텍스트 역할을 한다. _output_ 컴포넌트는 모델의 예측을 캡처하여, 그 의사 결정 및 계획을 상세히 설명한다. 다음 관찰_ 컴포넌트는 피드백 루프 및 시스템 적응에 필수적인 환경의 피드백을 기록한다.\n' +
      '\n' +
      '본 프레임워크는 _input_ 컴포넌트 내에서 상호 작용 이력을 집계하기 위해 미리 정의된 방법을 사용하며, 포괄적인 컨텍스트를 구성하기 위해 이전 단계로부터의 입력 및 출력을 효과적으로 연결한다. 구체적으로, \\(i^{th}\\) 단계에서, 입력은 단계 1의 _입력, Action: 단계 1의 출력, Observation: 단계 1의 다음 관찰,..., 단계 i-1의 입력, Action: 단계 i-1의 출력, Observation: 단계 i-1_의 다음 관찰로 포맷된다. 이 접근법은 상호작용에 대한 상세한 연대기적 설명을 보장하여 궤적에 대한 미묘한 이해를 촉진한다.\n' +
      '\n' +
      '이 _input_의 기본 집계 전략은 프레임워크에 필수적이지만 데이터 컴파일 방법의 사용자 정의도 수용한다. 사용자는 구조화된 _input_, _output_ 및 _다음 관찰_ 구성요소를 활용하여 데이터 형식을 특정 연구 또는 애플리케이션 요구에 맞게 조정하는 대체 전략을 탐구하도록 권장한다. 그림 2, 행 2는 정의된 단계 구조를 사용하여 HotpotQA 및 ToolAlpaca와 같은 환경에서 궤적의 변환을 설명하며, 여기서 _output_는 초기 프롬프트 입력에서 형식 사양과 정렬되어 프레임워크의 적응성과 실용적인 유용성을 보여준다.\n' +
      '\n' +
      '도 1: AgentOhana의 워크플로우. 균질한 다중 턴 데이터 포맷은 다양한 데이터 소스로부터 이질적인 궤적을 통합하기 위해 설계된다. _ AgentRater_는 에이전트 궤적을 평가하고 필터링한다. 마지막으로 스트리밍 데이터 로더는 다양한 데이터 세트의 통합을 가능하게 하고 데이터를 무작위로 분산 훈련 프로세스에 공급한다.\n' +
      '\n' +
      '에이전트와 환경 간의 상호 작용 포착을 표준화함으로써 이 방법론은 데이터 문서에 대한 균일한 접근을 촉진할 뿐만 아니라 AI 모델의 심층 분석 및 개선 가능성을 향상시킨다. 이는 에이전트 상호 작용, 의사 결정 프로세스 및 그 결과에 대한 세분화된 관점을 제공함으로써 달성되어 모델 성능의 보다 미묘한 이해와 개선을 가능하게 한다.\n' +
      '\n' +
      '### AgentRater\n' +
      '\n' +
      '에이전트 궤적은 일반적이고 직접적인 지시 데이터와 구별되는 데이터의 복잡한 하위 집합을 나타낸다. Alpaca(Dubois et al., 2023)와 같은 데이터 세트는 단일 턴 예를 특징으로 하고, LMSYS-Chat(Zheng et al., 2023a)은 약 2 턴을 평균화하는 다이얼로그를 포함하지만, 이들은 일반적으로 더 간단한 상호작용 패턴을 포함한다. 다이얼로그스튜디오(Zhang et al., 2023)는 멀티-턴 대화 예들을 제공하고, 이들은 주로 사용자와 시스템 사이의 대화들에 한정되며, 외부 환경들과의 상호작용들이 부족하다.\n' +
      '\n' +
      '대조적으로, 에이전트 궤적은 에이전트가 웹사이트, API 및 도구와 같은 복잡한 환경과 상호 작용하는 보다 복잡한 시나리오를 탐구한다. 이 복잡성은 에이전트의 복잡성으로 인해 높아집니다.\n' +
      '\n' +
      '도 2: (A) HotpotQA, (B) ToolAlpaca에서 AgentOhana까지의 예제 궤적.\n' +
      '\n' +
      '다른 에이전트와 통신하고 다양한 인터페이스를 탐색하며 단일 또는 제한된 교환이 아닌 일련의 상호 작용이 필요한 작업을 수행할 수 있습니다.\n' +
      '\n' +
      '에이전트 궤적에 대한 도전은 성능과 품질의 평가로 확장된다. 일부 환경은 에이전트의 궤적에 대한 피드백으로서 보상을 제공하지만, 이러한 보상은 궤적 자체의 품질을 반영하기보다는 종종 태스크의 최종 결과에 결부된다. 결과적으로, 높은 보상이 반드시 흠잡을 데 없는 궤적을 나타내는 것은 아니다. 예를 들어, 에이전트는 작업의 중간 단계에서 잘못된 작업을 생성할 수 있습니다. 여기 웹샵 환경으로부터의 부분 궤적(Yao et al., 2022): 단계 4의 _모델 출력: "click[old world style]", 단계 4의 관찰: "You\'ve clicked old world style."; 단계 5의 모델 출력: "click[rope sausage]", 단계 5의 관찰: "Invalid action"; 단계 6의 모델 출력: "\'", 단계 6의 관찰: "Invalid action"; 단계 7의 모델 출력: "click[By Now]", 단계 7의 관찰: "Your score(min 0.0, max 1.0): 1.0"_가 있으며, 여기서 에이전트는 웹샵 웹사이트 내의 다른 버튼들을 랜덤하게 클릭하거나 아이템을 구매하기 전에 빈 응답을 생성한다.\n' +
      '\n' +
      '이 문제를 완화하기 위해, 우리는 Mistral(Jiang et al., 2023)과 같은 강력한 공개 모델 또는 ChatGPT(OpenAI, 2023)와 같은 근접 세계 API를 기반으로 에이전트 궤적을 평가하는 _AgentRater_라는 방법을 설계한다. 그들이 각각을 평가하는 접근법(Zhang et al., 2023; Chen et al., 2023)과는 상이하다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c} \\hline \\hline\n' +
      '**Environments \\& Data** & **\\#Sampled Trajs** & **\\#Filtered Trajs** & **\\#Average Turns** \\\\ \\hline Webshop (Yao et al., 2022) & 11200 & 2063 & 6.8 \\\\ AlfWorld (Shridhar et al., 2021) & 954 & 336 & 13.5 \\\\ HotpotQA (Yang et al., 2018) & 1740 & 402 & 4.8 \\\\ ToolBench (Qin et al., 2023) & 83771 & 30319 & 3.1 \\\\ ToolAlpaca (Tang et al., 2023) & 3936 & 3399 & 2.5 \\\\ Operating System (Liu et al., 2023a) & 647 & 195 & 3.9 \\\\ APIbank (Li et al., 2023) & 33415 & 4902 & 1.0 \\\\ DataBase (Liu et al., 2023a) & 6376 & 538 & 2.0 \\\\ Mind2Web (Deng et al., 2023) & 23378 & 122 & 1.0 \\\\ Knowledge Graph (Liu et al., 2023a) & 2501 & 324 & 6.0 \\\\ AgentOhana & 167918 & 42600 & 3.1 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: AgentOhana의 통계량. AgentOhana는 10가지 다른 환경의 데이터로 구성되어 있다. _# 샘플링된 Trajs_는 원래 환경에서 샘플링되고 필터링된 궤적을 나타내고, _#Filtered Trajs_는 AgentRater 점수\\(>=4.0\\)를 갖는 필터 궤적을 나타내고, _#Average Turns_는 필터링된 궤적의 평균 턴 수를 나타낸다. 환경 중 _Operating System_, _DataBase_, _Mind2Web_ 및 _Knowledge Graph_는 (Zeng et al., 2023)에서 도출된다.\n' +
      '\n' +
      '도 3: AgentRater에 대한 프롬프트 템플릿으로서, 여기서 오픈-소스 모델(예를 들어, Mistral) 또는 클로즈-월드 API(예를 들어, ChatGPT)는 기준들에 기초하여 전체 에이전트 궤적을 평가한 다음 0 - 5로부터의 점수를 할당할 것이다.\n' +
      '\n' +
      '일반적인 명령어 데이타에 (명령, 입력, 응답) 쌍의 트리플렛(triplet)은 일반적으로 단회전 또는 짧은 대화가 있기 때문에 에이전트 데이타에 대한 전체 궤적을 평가한다. 그림 3은 해당 프롬프트 템플릿을 보여주며, 여기서 우리는 0-5점 및 설명으로 궤적을 평가하고 더 나은 에이전트레이터 모델을 추가로 개발하는 데 사용할 수 있다. Table 2.3은 AgentOhana의 통계량을 나타낸 것이다.\n' +
      '\n' +
      '### Generic Dataloader\n' +
      '\n' +
      '프로토콜은 트레이너를 위해 정확한 포맷으로 데이터를 로딩하는 것을 포함하기 때문에, 일반적인 데이터 로더의 구현은 전체 데이터와 트레이닝 파이프라인을 조화시키는 데 중요해진다. 이 데이터 로더는 중앙 구성요소 역할을 하여 다양한 데이터 세트를 훈련 프로세스에 원활하게 통합할 수 있습니다. 일반적인 특성은 다양한 데이터 형식에 걸쳐 유연성과 호환성을 보장하여 훈련 프레임워크에 공급하기 전에 효율적인 데이터 섭취를 가능하게 한다.\n' +
      '\n' +
      '#### 2.4.1 AgentModelDatasetBase\n' +
      '\n' +
      '우리는 개별 데이터 세트를 생성하기 위한 가상 템플릿을 제공하면서 프롬프트 포맷팅과 같은 공통 작업을 간소화하기 위해 _AgentModelDatasetBase_ 클래스를 도입했다. 데이터를 로드하는 것은 이 단계에서 간단해 보일 수 있지만 해결해야 할 몇 가지 복잡한 문제가 있습니다. 예를 들어, 섹션 2.3에 자세히 설명된 대로 기계 지원 필터를 사용하는 것 외에도 사용자는 데이터 품질에 대한 일정 수준의 제어를 선호할 수 있다. 더욱이, 상이한 데이터 세트로부터의 데이터 배치의 랜덤성은 특히 다수의 디바이스들 간의 분산 트레이닝을 다룰 때 과제를 제기할 수 있으며, 이는 강건한 데이터 세트 관리를 보장하기 위한 포괄적인 접근법을 필요로 한다.\n' +
      '\n' +
      '###### 2.4.2 맞춤형 데이터셋 생성\n' +
      '\n' +
      '다음 예제에 표시된 개별 데이터 세트는 일반적으로 스트리밍 모드를 통해 섹션 2.2에서 준비된 개별 원시 데이터를 로드하는 것으로 시작한다. 그런 다음 각 데이터 세트에 대해 필터 생성기를 선택적으로 도입하여 트레이너에게 데이터를 공급하기 직전에 데이터의 선택을 추가로 사용자 정의할 수 있다. 예를 들어, 다음의 예에서, 비교적 낮은 점수를 갖는 데이터가 추가로 평가되고 제거될 것이다. 마지막으로, 무작위성과 재현성을 보장하기 위해 통제된 시딩으로 이 데이터 세트를 무작위로 섞는다.\n' +
      '\n' +
      '```\n' +
      'classWebshopMultiTurn(AgentModelDatasetBase) : # wecanatthisstage @staticmethod def_high_score_filter_generator(data,score=0.8):fordimdata: if(!"score")>=score: yield(!"prompt":d["input","chosen":d["output"") defcreate_datasets(self,seed=None): train_data=load_dataset(...) streaming=self.args.streaming, ) train_data=IterableDataset.from_generator(self_high_score_filter_generator, gen_kwargs=(*data":train_data)) train_data=train_data.shuffle(seed=seed,buffer_size=1000) returntrain_data\n' +
      '```\n' +
      '\n' +
      '결합된 데이터세트 데이터세트를 결합하는 데 있어 우리의 주요 초점은 특히 여러 데이터세트를 다룰 때 배치 프로세스 중 무작위성을 보장하는 데 있다. 이를 위해, 데이터 병렬성이 여러 장치에 걸쳐 사용될 때 프로세스 ID를 기반으로 제어된 시드를 다양화하기 위해 _init_device_seed_ 함수를 사용한다. 시딩 프로세스를 주의 깊게 관리함으로써 무작위성을 유지하면서 장치 전반에 걸쳐 데이터를 분할, 셔플링 및 인터리빙하여 데이터의 균형 잡힌 분포를 유지하여 훈련 절차의 견고성과 재현성을 향상시키는 것을 목표로 한다.\n' +
      '\n' +
      '```\n' +
      'toolbench_multi_turn=ToolBenchMultiTurn(tokenizer,script_args) webshop_multi_turn=WebshopMultiTurn(tokenizer,script_args)... data=[toolbench_multi_turn,webshop_multi_turn,...] sample_probs=[0.1,0.1,...]\n' +
      '#adevice-dependentseedingwillbeutilizedbasedonthecombinationofthegivendefaultseedandtheprocessID seed=init_device_seed(seed=42) train_dataset,eval_dataset=\\interleave_data(data_objects=data, sample_probs=sample_probs, seed=seed)\n' +
      '```\n' +
      '\n' +
      '## 3 Experiments\n' +
      '\n' +
      '### Training\n' +
      '\n' +
      '우리는 에이전트 모델인 xLAM-v0.1의 성능을 향상시키기 위해 감독 미세 조정 접근법을 채택했으며, 이는 처음에 Mistral-8x7B-Instruct-v0.1 모델에서 사전 훈련되었다(Jiang et al., 2024). 이 미세 조정 프로세스를 실행하기 위해 우리는 AgentOhana의 기능을 활용했다. 우리의 미세 조정 절차는 4비트 양자화된 QLoRA 프레임워크(Dettmers et al., 2023)를 사용하여 8개의 Nvidia H100 GPU에서 동시에 수행되었다.\n' +
      '\n' +
      '우리의 데이터 세트 컴파일 전략은 다양한 소스에서 데이터의 균형 잡힌 분포를 가진 포괄적인 훈련 코퍼스의 생성을 보장했다. 다양한 출처에 걸쳐 이 균형을 유지하는 것은 편향을 완화하고 다양한 입력에 걸쳐 모델의 견고성을 보장했다. 또한 데이터 세트 분할 및 모델 학습 동안 장치 전반에 걸쳐 독립적인 무작위성을 세심하게 보존하여 학습 프로세스에 의도하지 않은 편향이 도입되는 것을 방지했다.\n' +
      '\n' +
      '미세 조정 프로세스를 통해 본 모델은 각 개별 데이터 세트를 평균 약 3회 횡단했다. 이 다중 에포크 훈련 요법은 데이터 세트에 대한 포괄적인 노출을 촉진하여 모델이 훈련 데이터에 존재하는 복잡한 패턴을 효과적으로 학습할 수 있게 했다.\n' +
      '\n' +
      '### Benchmarks\n' +
      '\n' +
      '이후 섹션에서는 웹샵(Yao et al., 2022), HotpotQA(Yang et al., 2018) 및 MINT-Bench(Wang et al., 2023a)의 세 가지 벤치마크에 걸쳐 수행된 실험 평가를 제시한다. 웹샵은 특정 상품 아이템 구매 경험을 시뮬레이션한 온라인 쇼핑 환경을 소개한다. HotpotQA는 다중 홉 질문 응답 작업을 포함하여 위키피디아 API를 통해 여러 위키피디아 패시지에 걸쳐 논리적 추론을 필요로 한다. 웹샵과 HotpotQA 벤치마크에 대해 BOLAA Liu et al.(2023b)에서 설정한 설정을 따른다. BOLAA의 프레임워크는 다중 에이전트 시나리오와 함께 5개의 별개의 단일 에이전트 설정을 설명하여 모델 성능을 평가하기 위한 구조화된 접근법을 제공한다. 웹샵 벤치마크의 경우, BOLAA는 900개의 사용자 쿼리로 구성되며, 그 중 200개는 테스트 하위 집합으로 사용되며 나머지는 모델 개발을 용이하게 한다. 핫팟QA의 맥락에서, BOLAA는 300개의 사용자 질문을 100개의 질문을 포함하는 각 범주로 쉬운, 중간 및 단단한 세 가지 난이도로 샘플링한다. 이러한 질문은 엄격한 평가 프로세스를 보장하기 위해 모델 테스트를 위해 독점적으로 예약되어 있습니다.\n' +
      '\n' +
      '우리는 벤치마크에 걸친 모델 성능을 정량화하기 위해 BOLAA의 지정된 평가 메트릭, 즉 평균 보상을 채택한다. 웹샵 컨텍스트 내에서, 보상 메트릭은 구매된 아이템의 속성들과 지상-진실 아이템 사이의 중첩을 평가함으로써, 사용자 선호도들을 식별하는데 있어서 모델 정확도를 측정한다. HotpotQA의 경우, 보상은 지상-진실 응답에 대한 에이전트의 예측된 답변의 정확도를 반영하여 F1 점수로 정량화된다.\n' +
      '\n' +
      'MINT-Bench(Wang et al., 2023a) 벤치마크와 관련하여, 도구를 사용하고 자연 언어 피드백을 활용하여 다중 회전 상호작용으로 태스크를 해결하는 LLMs의 능력을 평가한다. 벤치마크는 구축된 다양한 평가 데이터 세트를 통해 추론, 코딩 및 의사 결정에 초점을 맞추고, 효율적인 평가를 위해 컴팩트 서브세트로 신중하게 큐레이션한다. 벤치마크는 LLMs에게 1단계부터 5단계까지의 서로 다른 상호작용 한계를 가진 태스크를 해결하고, LLMs의 도구 증강 태스크 해결 능력을 절대 성능 성공률로 정량화하며, 이는 상호작용 단계의 함수로서 성공적인 태스크 인스턴스의 백분율을 측정한다.\n' +
      '\n' +
      '### Webshop\n' +
      '\n' +
      '표 2는 웹샵 환경 내에서 모델의 성능을 보여준다. xLAM-v0.1은 모든 에이전트 구성에서 GPT-3.5-터보 및 GPT-3.5-터보-지시 모두를 일관되게 능가한다. 또한, 6개 설정 중 5개 설정에서 GPT-4-0613을 능가하며, 후자는 우수한 계획 능력을 보여주지만 추론, 자기 반영 및 다중 에이전트 상호 작용에서 더 낮은 성능을 보여준다. 이러한 발견은 다양한 에이전트 시나리오에 걸쳐 xLAM 모델의 강력하고 다양한 기능을 강조한다.\n' +
      '\n' +
      '### HotpotQA\n' +
      '\n' +
      '표 3은 HotpotQA 환경에서 결과를 자세히 설명하며, 모든 설정에서 GPT-3.5-Turbo 및 Mistral-8x7B-Instruct-v0.1에 비해 xLAM의 우수한 성능을 강조한다. GPT-4-0613은 약간의 성능 우위를 나타내지만 모델의 예측에 대한 우리의 분석에서는 일반적으로 4단계 내에서 정답을 식별한다는 것을 보여주며, 이는 관련 질문 응답 예제의 상당한 말뭉치에 대해 훈련되어 대응물에 비해 향상된 도메인별 지식을 보유했을 수 있음을 시사한다.\n' +
      '\n' +
      '### Mint-Bench\n' +
      '\n' +
      '표 4는 도전적이고 포괄적인 MINT-벤치에 대한 테스트 결과를 나타내며 공식 리더보드1에서 도출된 기준 비교와 함께 xLAM-v0.1 모델은 세 번째를 확보한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c|c c c c c} \\hline \\multirow{2}{*}{LLM} & \\multicolumn{8}{c}{LAA Architecture} \\\\ \\cline{2-7}  & ZS & ZST & ReAct & PlanAct & PlanReAct & BOLAA \\\\ \\hline Llama-2-70b-chat (Touvron et al., 2023) & 0.0089 & 0.0102 & 0.4273 & 0.2809 & 0.3966 & 0.4986 \\\\ Vicuna-33b (Zheng et al., 2023b) & 0.1527 & 0.2122 & 0.1971 & 0.3766 & 0.4032 & 0.5618 \\\\ Mistral-8x7B-Instruct-v0.1 (Jiang et al., 2024) & 0.4634 & 0.4592 & 0.5638 & 0.4738 & 0.3339 & 0.5342 \\\\ GPT-3.5-Turbo & 0.4851 & 0.5058 & 0.5047 & 0.4930 & 0.5436 & 0.6354 \\\\ GPT-3.5-Turbo-Instruct & 0.3785 & 0.4195 & 0.4377 & 0.3604 & 0.4851 & 0.5811 \\\\ GPT-4.0613 & 0.5002 & 0.4783 & 0.4616 & **0.7950** & 0.4635 & 0.6129 \\\\ xLAM-v0.1 & **0.5201** & **0.5268** & **0.6486** & 0.6573 & **0.6611** & **0.6556** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 웹샵 환경에 대한 평균 보상. **굵은** 및 밑줄 결과는 각 설정에 대해 각각 최상의 결과와 두 번째 최상의 결과를 나타낸다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c|c c c c} \\hline \\multirow{2}{*}{LLM} & \\multicolumn{8}{c}{LAA Architecture} \\\\ \\cline{2-7}  & ZS & ZST & ReAct & PlanAct & PlanReAct \\\\ \\hline Mistral-8x7B-Instruct-v0.1 (Jiang et al., 2024) & 0.3912 & 0.3971 & 0.3714 & 0.3195 & 0.3039 \\\\ GPT-3.5-Turbo & 0.4196 & 0.3937 & 0.3868 & 0.4182 & 0.3960 \\\\ GPT-4.0613 & **0.5801** & **0.5709** & **0.6129** & **0.5778** & **0.5716** \\\\ xLAM-v0.1 & 0.5492 & 0.4776 & 0.5020 & 0.5583 & 0.5030 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: HotpotQA 환경에 대한 평균 보상. **굵은** 및 밑줄 결과는 각 설정에 대해 각각 최상의 결과와 두 번째 최상의 결과를 나타낸다.\n' +
      '\n' +
      '이 엄격한 벤치마크에서는 Lemur-70b-Chat-v1 및 AgentLM-70b와 같은 다른 에이전트 기반 모델뿐만 아니라 Claude-2 및 GPT-3.5-Turbo-0613을 포함한 일반 대형 언어 모델(LLM)을 능가하며, 이러한 결과는 다중 턴 상호작용과 태스크 해결의 복잡성을 탐색할 수 있는 우리 모델의 탁월한 능력을 강조한다.\n' +
      '\n' +
      '## 4 Conclusion\n' +
      '\n' +
      '결론적으로, _AgentOhana_의 생성은 다중 턴 LLM 에이전트 궤적의 다양한 데이터를 통합하는 데 내재된 문제를 해결하는 데 중요한 진전을 나타낸다. 통합된 데이터 및 훈련 파이프라인의 개발을 통해 다양한 데이터 구조 및 포맷의 복잡성을 처리할 수 있는 프레임워크를 구축하여 다양한 환경에 걸쳐 호환성을 보장한다. 포괄적이고 고품질의 데이터 세트를 제공함으로써 연구자와 실무자가 AI 능력의 경계를 밀어낼 수 있도록 권한을 부여함으로써 궁극적으로 LLM에 의해 구동되는 자율 에이전트의 발전에 기여하는 것을 목표로 한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* 체이스(2023) 해리슨 체이스. 랭체인. [https://github.com/hwchasel7/langchain] (https://github.com/hwchasel7/langchain), 2023.\n' +
      '* Chen et al. (2023) Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et al. Alpagasus: 더 적은 데이터로 더 나은 알파카를 훈련한다. _ arXiv preprint arXiv:2307.08701_, 2023.\n' +
      '* Deng et al. (2023) Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. Mind2web: 웹에 대한 일반 에이전트를 향합니다. _ arXiv preprint arXiv:2306.06070_, 2023.\n' +
      '* Dettmers et al.(2023) Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: 양자화된 llms의 효율적인 미세조정, 2023.\n' +
      '* Dubois et al. (2023) Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang 및 Tatsunori B. Hashimoto. Alpacaafarm: 인간 피드백으로부터 학습하는 방법에 대한 시뮬레이션 프레임워크, 2023.\n' +
      '* 그라비타 (2023) Significant Gravitas. Autogpt. [https://github.com/Significant-Gravitas/Auto-GPT] (https://github.com/Significant-Gravitas/Auto-GPT), 2023.\n' +
      '* Guo et al. (2024) Shangmin Guo, Biao Zhang, Tianlin Liu, Tianqi Liu, Misha Khalman, Felipe Llinares, Alexandre Rame, Thomas Mesnard, Yao Zhao, Bilal Piot, et al. 온라인 ai 피드백으로부터의 직접 언어 모델 정렬. _ arXiv preprint arXiv:2402.04792_, 2024.\n' +
      '* Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. _ arXiv preprint arXiv:2310.06825_, 2023.\n' +
      '* Jiang et al.(2024)\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline  & 1-step & 2-step & 3-step & 4-step & 5-step \\\\ \\hline GPT-4-0613 & nan & nan & nan & nan & 69.45 \\\\ Claude-Instant-1 & 12.12 & 32.25 & 39.25 & 44.37 & 45.90 \\\\ xLAM-v0.1 & 4.10 & 28.50 & 36.01 & 42.66 & 43.96 \\\\ Claude-2 & 26.45 & 35.49 & 36.01 & 39.76 & 39.93 \\\\ Lemur-70b-Chat-v1 (Xu et al., 2023) & 3.75 & 26.96 & 35.67 & 37.54 & 37.03 \\\\ GPT-3.5-Turbo-0613 & 2.73 & 16.89 & 24.06 & 31.74 & 36.18 \\\\ AgentLM-70b (Zeng et al., 2023) & 6.48 & 17.75 & 24.91 & 28.16 & 28.67 \\\\ CodeLlama-34b (Roziere et al., 2023) & 0.17 & 16.21 & 23.04 & 25.94 & 28.16 \\\\ Llama-2-70b-chat (Touvron et al., 2023) & 4.27 & 14.33 & 15.70 & 16.55 & 17.92 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: MINT-Bench에 대한 테스트 결과.\n' +
      '\n' +
      '* Jiang et al. (2024) Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand et al. Mixtral of experts. _ arXiv preprint arXiv:2401.04088_, 2024.\n' +
      '* Li 등(2023) Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. Apibank: tool-augmented llms의 벤치마크. _ arXiv preprint arXiv:2304.08244_, 2023.\n' +
      '* Liu et al. (2023a) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangling Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, 및 Jie Tang. 요원: 요원으로 평가, 2023a.\n' +
      '* Liu et al. (2023b) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, et al. Bolaa: Benchmarking and Orchestrating llvm-augmented autonomous agents. _ arXiv preprint arXiv:2308.05960_, 2023b.\n' +
      '* Longpre et al. (2023) Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. The fian collection: Designing data and methods for effective instruction tuning. _ arXiv preprint arXiv:2301.13688_, 2023.\n' +
      '* Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-feedback. _ arXiv preprint arXiv:2303.17651_, 2023.\n' +
      '*Nijkamp et al. (2023) Erik Nijkamp, Hiroaki Hayashi, Caiming Xiong, Silvio Savarese, and Yingbo Zhou. Codegen2: 프로그래밍 및 자연 언어에 대한 llms 훈련에 대한 교육. _ ICLR_, 2023.\n' +
      '* OpenAI(2023) OpenAI. Gpt-4 기술 보고서입니다 ArXiv_, 2023.\n' +
      '* Qin et al. (2023) Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toollm: 16000+ 실세계 apis를 마스터하기 위해 대형 언어 모델을 용이하게 한다. _ arXiv preprint arXiv:2307.16789_, 2023.\n' +
      '* Rafailov et al. (2023) Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. 직접 선호도 최적화: 언어 모델이 은밀하게 보상 모델입니다. _ arXiv preprint arXiv:2305.18290_, 2023.\n' +
      '* Roziere et al. (2023) Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jeremy Rapin, et al. Code llama: code에 대한 오픈 파운데이션 모델. _ arXiv preprint arXiv:2308.12950_, 2023.\n' +
      '* Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, and Shunyu Yao. 반사: 언어 강화 학습을 하는 언어 에이전트. 30-7차 신경 정보 처리 시스템 회의에서_, 2023.\n' +
      '* Shridhar et al. (2021) Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Cote, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht. ALFWorld: 대화형 학습을 위한 텍스트와 구현된 환경을 정렬합니다. In _Proceedings of the International Conference on Learning Representations (ICLR)_, 2021. URL[https://arxiv.org/abs/2010.03768](https://arxiv.org/abs/2010.03768).\n' +
      '* Tang et al. (2023) Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, and Le Sun. 툴라파카: 3000개의 시뮬레이션 사례가 있는 언어 모델에 대한 일반화된 도구 학습 _ arXiv preprint arXiv:2306.05301_, 2023.\n' +
      '* Team et al. (2023) Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini: High capable multiimodal model의 가족. _ arXiv preprint arXiv:2312.11805_, 2023.\n' +
      '* XAgent Team(2023) XAgent Team. XAgent: A autonomous agent for complex task solving, 2023.\n' +
      '* Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. _ arXiv preprint arXiv:2307.09288_, 2023.\n' +
      '* Touvron et al. (2023)* Wang et al. (2023a) Xingyao Wang, Zihan Wang, Jiateng Liu, Yangyi Chen, Lifan Yuan, Hao Peng, and Heng Ji. 민트: 툴 및 언어 피드백과의 멀티턴 상호 작용에서 llms를 평가하는 것. _ arXiv preprint arXiv:2309.10691_, 2023a.\n' +
      '* Wang et al. (2023b) Yu Wang, Zhiwei Liu, Jianguo Zhang, Weiran Yao, Shelby Heinecke, and Philip S Yu. Drdt: llm 기반 순차적 추천을 위한 발산적 사고를 갖는 동적 반영. _ arXiv preprint arXiv:2312.11336_, 2023b.\n' +
      '* Xie et al. (2023) Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, et al. Openagents: the open platform for language agents in wild. _ arXiv preprint arXiv:2310.10634_, 2023.\n' +
      '* Xu et al. (2023) Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian Liu, Weijia Shi, Binyuan Hui, Fan Zhou, Yitao Liu, Tianbao Xie, et al. Lemur: 자연어와 언어 에이전트에 대한 코드의 조화 arXiv preprint arXiv:2310.06830_, 2023.\n' +
      '* Yang et al. (2018) Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. 코헨, 루슬란 살라쿠티노프 크리스토퍼 매닝 HotpotQA: 다양하고 설명 가능한 다중 홉 질문 응답을 위한 데이터 세트. _Conference on Empirical Methods in Natural Language Processing (EMNLP)_, 2018.\n' +
      '* Yao et al. (2022) Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. 웹샵: 확장 가능한 실제 웹과 접지된 언어 에이전트와의 상호 작용에 대한_ 신경 정보 처리 시스템_, 35:20744-20757, 2022에서의 발전.\n' +
      '* Yao et al. (2023) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. ReAct: 추론과 언어 모델에 대한 연기의 시너지 효과 _International Conference on Learning Representations (ICLR)_, 2023.\n' +
      '* Yin et al. (2023) Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, and Bill Yuchen Lin. 루모스: 통합된 데이터, 모듈식 설계 및 오픈 소스 lms를 가진 학습 에이전트 _ arXiv preprint arXiv:2311.05657_, 2023.\n' +
      '* Yuan et al. (2024) Weizhe Yuan, Richard Yuanzhe Pang, KyungHyun Cho, Sainbayar Sukhbaatar, Jing Xu, and Jason Weston. 자급자족 언어 모델 arXiv preprint arXiv:2401.10020_, 2024.\n' +
      '* Zeng et al. (2023) Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, 및 Jie Tang. Agenttuning: llms에 대한 일반화된 에이전트 능력을 활성화한다. _ arXiv preprint arXiv:2310.12823_, 2023.\n' +
      '* Zhang et al. (2023) Jianguo Zhang, Kun Qian, Zhiwei Liu, Shelby Heinecke, Rui Meng, Ye Liu, Zhou Yu, Silvio Savarese, and Caiming Xiong. Dialogstudio: 대화 ai를 위한 가장 풍부하고 다양한 통합 데이터 세트 컬렉션을 향한다. _ arXiv preprint arXiv:2307.10172_, 2023.\n' +
      '* Zheng et al. (2023a) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric Xing, et al. Lmsys-chat-1m: 대규모 실세계 llm 대화 데이터셋. _ arXiv preprint arXiv:2309.11998_, 2023a.\n' +
      '* Zheng et al. (2023b) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. arXiv preprint arXiv:2306.05685_, 2023b.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:12]\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>