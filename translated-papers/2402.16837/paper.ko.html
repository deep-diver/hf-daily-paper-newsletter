<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 대형 언어 모델이 다중 홉 추론을 강력하게 수행하는가?\n' +
      '\n' +
      '소희 양1,2 엘레나 그리보브스카야1 노라 카스너1 모르 게바3,4 세바스티안 리델1,2\n' +
      '\n' +
      '구글 딥마인드1 UCL2 구글 리서치3 텔아비브 대학 4\n' +
      '\n' +
      '{soheeyang,egribovskaya,norakassner,pipek,sriedel}@google.com\n' +
      '\n' +
      'Corresponding authors.\n' +
      '\n' +
      '각주 1: 코드와 데이터 세트를 공개적으로 공개할 계획입니다.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '본 논문에서는 LLM (1)이 "Superstition"의 가수인 Stevie Wonder를 "Superstition"의 가수인 Stevie Wonder, _bridge entity_, 그리고 (2)가 Stevie Wonder의 어머니에 대한 지식을 이용하여 프롬프트를 완성하는 잠재 추론 경로의 증거를 찾고, LLM (1)이 "Superstition"의 가수인 Stevie Wonder를 "Superstition"의 가수인 Stevie Wonder"를 "Superstition"의 가수인 Stevie Wonder, _bridge entity_, 그리고 (2)가 "Stevie Wonder"의 어머니에 대한 지식을 이용하여 프롬프트를 완성한다. 이 두 홉을 개별적으로 분석하고 이들의 동시 발생을 잠재 다중 홉 추론을 나타내는 것으로 간주한다. 첫 번째 홉에 대해 다른 개체 대신 교량 개체를 간접적으로 언급하라는 프롬프트를 변경하면 교량 개체에 대한 LLM의 내부 회상이 증가하는지 테스트한다. 두 번째 홉에 대해 이 리콜을 증가시키면 LLM이 브리지 엔티티에 대해 알고 있는 것을 더 잘 활용하게 되는지 테스트한다. 특정 관계 유형의 프롬프트에 대한 잠재 다중 홉 추론의 강력한 증거를 찾았으며, 추론 경로는 프롬프트의 80% 이상에서 사용되었다. 그러나 활용도는 매우 맥락적이며 다양한 유형의 프롬프트에 따라 다릅니다. 또한 평균적으로 두 번째 홉과 전체 다중 홉 횡단 증거는 첫 번째 홉에 대해 다소 온건하고 상당하다. 또한, 추론의 첫 번째 홉에 대해서는 모델 크기가 증가하지만 두 번째 홉에 대해서는 모델 크기가 증가하지 않는 명확한 스케일링 경향을 발견하였다. 우리의 실험 결과는 LLMs.1의 향후 개발 및 적용을 위한 잠재적인 도전과 기회를 제안한다.\n' +
      '\n' +
      '각주 1: 코드와 데이터 세트를 공개적으로 공개할 계획입니다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '최근 연구에 따르면 Transformer-based (Vaswani et al., 2017) Large Language Models (LLMs)는 "The mother of Stevie Wonder is"_(Petroni et al., 2019; Meng et al., 2022; Geva et al., 2021, 2022, 2023; Zhu and Li, 2023)과 같은 간단한 프롬프트를 완료하기 위해 사실 정보를 그들의 파라미터에 저장하고 검색하는 것으로 나타났다. 또한, LLM들은 입력의 일부로서 필요한 정보가 명시적으로 주어질 때 현저한 _in-context_ 추론 능력을 입증하였다(Wei et al., 2022). 예를 들어, 모델들은 "Lula"를 _"Stevie Wonder의 엄마는 Lula이다. "Superstition"의 가수는 Stevie Wonder이다. "Superstition"의 가수의 엄마는 "_"이다. 이러한 연구 결과는 다음과 같은 질문을 제기한다: LLMs는 그들의 파라미터에 저장된 사실 정보를 검색하고 _not_가 입력의 일부로 주어졌을 때 _latent multi-hop reasoning_를 수행합니까? 예를 들어, LLMs가 two-hop prompt _"The mother of \'Superstition\'가 "_"일 때, 그들은 (1) "The singer of \'Superstition"이 스티비 원더를 지칭한다는 것을 파악하고 (2) Stevie Wonder의 어머니가 누구인지에 대한 지식을 사용하여 prompt를 완성하는가?\n' +
      '\n' +
      '이 질문에 답하는 것은 중요하다. 이러한 잠재 멀티홉 추론에 대한 증거는 LLM이 저장된 암묵적 지식_을 통해 연결 및 횡단할 수 있음을 시사할 것이다.\n' +
      '\n' +
      '그림 1: LLM의 잠재 다중 홉 추론을 조사한다. 첫 번째 홉에 대해, 우리는 입력 프롬프트를 브리지 엔티티(Stevie Wonder)를 참조하도록 변경하고 그것이 얼마나 자주 브리지 엔티티에 대한 모델의 내부 리콜을 증가시키는지 확인한다. 두 번째 홉에 대해, 우리는 이 리콜이 증가하면 모델 출력이 브리지 엔티티의 속성(스티비 원더의 어머니)에 대해 알고 있는 것과 더 일치하게 되는지 확인한다.\n' +
      '\n' +
      '정보만 매개 변수에 중복 저장하는 것보다. 향후 작업은 이러한 횡단 경로를 강화하여 궁극적으로 더 매개변수 효율적이고 제어 가능한 모델로 이어질 수 있다. 반대로, 증거의 부족은 트랜스포머 아키텍처나 훈련의 더 근본적인 한계를 나타낼 것이다. 그것은 또한 모델 편집에 중요한 의미를 가질 것이다: 추론된 것 대신에 복잡한 사실들을 리콜한다면, 변경들이 전파될 수 없기 때문에 기본 사실들만을 편집하는 것은 결코 충분하지 않을 것이다(Onoe et al., 2023; Zhong et al., 2023; Cohen et al., 2023).\n' +
      '\n' +
      '본 연구에서는 "Superstition"의 singer의 mother는 (1) _bridge entity_(예를 들어, Stevie Wonder)를 추론하고 (2) 그 entity의 속성(예를 들어, 그의 mother가 누구인가)을 추론함으로써 인간이 두 개의 hops로 완성할 수 있는 "__"와 같은 두 가지 사실의 구성을 표현할 수 있는 prompts로 한정한다. 그리고, LLMs가 예측된 출력을 크게 결정하는 가장 두드러진 경로는 아닐 수 있지만, 유사한 잠재된 two-hop 추론 경로를 사용하여 prompts를 처리하는 빈도를 연구한다. 이를 위해, 먼저, 도 1에 도시된 바와 같이, 이들 hops를 개별적으로 연구하고, 첫 번째 홉을 연구하기 위해, 특정 숨겨진 표현들을 어휘 공간에 투영함으로써, LLM의 브리지 엔티티의 내부 리콜을 근사화하기 위해 _entity recall score_를 제안하고, 두 번째 홉의 완성을 위한 분배와 등가 리콜 기반 one-hop prompt(예를 들어, _"Stevie Wonder의 mother is"_) 사이의 _consistency score_를 측정한다. 우리는 엔티티 리콜 점수를 증가시키기 위한 개입이 두 번째 홉 활용의 표시로서 일관성을 얼마나 자주 증가시키는지 확인한다. 마지막으로 두 단계가 얼마나 자주 일치하는지 조사한다.\n' +
      '\n' +
      '다양한 팩트 구성을 가진 잠재 2홉 추론을 연구하기 위해 위키다타(Vrandecic and Krotzsch, 2014)를 기반으로 한 TwoHopFact 데이터셋을 소개하고 52가지 팩트 구성의 45,595개의 2홉 프롬프트로 구성된다. 우리는 LLaMA-2(Touvron et al., 2023) 7B, 13B, 70B로 실험한다. 우리의 연구 결과는 다음과 같이 요약할 수 있다. 두 홉 프롬프트에 대한 광범위한 사실 구성 유형에서 우리는 다중 홉 추론의 첫 번째 홉에 대한 실질적인 증거를 찾는다. 교량 실체를 간접적으로 언급하기 위해 프롬프트를 변경하는 시간의 약 70%에서 변압기의 후기 층은 증가된 교량 실체 리콜을 보여준다. 두 번째 홉 및 전체 횡단에서는 증거가 더 약하게 나타나며, 60%의 경우 개체 회상 점수가 증가하면 일관성이 높아진다. 마찬가지로, 약 40%의 시간에서 두 홉이 함께 작동하며(임의 25% 기준선에 비해), 설명적 언급을 변경하면 개체 회상 점수가 증가하고 이 회상 점수가 증가하면 일관성이 증가한다.\n' +
      '\n' +
      '위의 집계 통계는 잠재 다중 홉 추론 경로의 매우 널리 사용되는 것을 시사하지 않지만, 사실 구성 유형의 최대 23%가 잠재 다중 홉 추론의 강력한 증거를 입증하며 사례의 80% 이상에서 발생한다는 점을 지적할 가치가 있다. 이것은 경로가 _exist_이지만 매우 맥락적임을 시사한다. 또한, 우리는 경로에 대한 매우 좁은 해석에 초점을 맞추고 있습니다 - 실제로, 우리는 그것이 레이어와 토큰에 걸쳐 더 많이 분산되기를 기대합니다. 따라서 우리가 보는 효과는 잠재된 2홉 추론을 수행하는 모델의 능력에 대한 하한일 수 있다. 우리는 또한 현저한 스케일링 거동을 발견한다: 첫 번째 홉은 파라미터 카운트에 의해 상당히 분명히 개선되지만, 두 번째 홉(및 왕복 성능)은 비교적 일정하게 유지된다. 이것은 오늘날의 건축이나 사전 훈련에 근본적인 한계를 나타낼 수 있다.\n' +
      '\n' +
      '우리의 기여는 다음과 같이 요약할 수 있다:\n' +
      '\n' +
      '* 우리는 LLMs_에서 _latent multi-hop 추론에 대한 질문을 해결하고, 조사를 위한 **프레임워크**를 설정하고, 그것의 **존재적 증거**를 보여준다.\n' +
      '* 우리는 다양한 유형의 엔티티와 관계 및 다양한 템플릿(SS4)을 사용하여 생성된 52개의 팩트 구성 유형의 45,595개의 2/1홉 프롬프트로 구성된 TwoHopFact **dataset**를 구성한다.\n' +
      '* 우리는 LLM의 기술 언급에 대한 개체 리콜 정도(SS5.1)와 LLM의 교량 개체 속성에 대한 지식 활용 정도(SS6)의 프록시로 각각 _내부 개체 리콜 점수_와 _일관성 점수_의 두 가지 새로운 **메트릭스**를 제안한다.\n' +
      '* 예상 인과 효과의 상대적 빈도(SS6.2)를 측정하여 예측을 결정하는 가장 두드러진 경로가 아닌 경우에도 잠재 추론 경로를 조사하기 위한 ** 메커니즘**을 제안한다.\n' +
      '\n' +
      '##2 관련 작품\n' +
      '\n' +
      '최근 연구에 따르면 LLM은 모델 크기에 따라 확장되는 프롬프트를 통해 현저한 문맥 내 추론 능력을 보여준다(Brown et al., 2020; Wei et al., 2022, 2022; Zhou et al., 2022). 반대로, LLMsoften은 입력의 일부로서 추론까지의 정보가 명시적으로 주어지지 않는 경우, 싱글-홉 서브-스텝에 대한 답을 알더라도 멀티-홉 추론을 올바르게 수행하지 못한다(Ofir Press et al., 2023; Dziri et al., 2023). 컨텍스트 내 추론이 어떻게 작동하는지에 대한 광범위한 조사가 있었지만(Chan et al., 2022; Akyurek et al., 2023; Dai et al., 2023; Von Oswald et al., 2023; Prystawski and Goodman, 2023; Feng and Steinhardt, 2024), 이러한 조사는 잠재 멀티홉 추론이 어떻게 작동하는지를 이해하기 위해 활발하게 수행되지 않았다.\n' +
      '\n' +
      'LLM의 잠재 추론을 조사하기 위한 작업이 있었지만, 탐색은 대부분 단순한 단일 홉 추론 작업(Meng et al., 2022; Geva et al., 2023; Chanin et al., 2023; Hernandez et al., 2024) 및/또는 제어된 경량 트레이닝/피네튜닝(Zhu and Li, 2023; Allen-Zhu and Li, 2023; Saparov et al., 2023; Berglund et al., 2024)으로 수행되었다. 또한, 잠재 추론 경로 또는 회로를 식별하는 것을 목표로 하는 많은 작업은 단순한 합성 작업 및/또는 장난감 모델에 대해 가장 두드러진 추론 경로를 찾는 데 초점을 맞추었다(난다 등, 2022; 올슨 등, 2022; Wang 등, 2023; Conny 등, 2023; Hou 등, 2023; Lieberum 등, 2023; McGrath 등, 2023). 한편, 우리는 다양한 유형의 자연스러운 두 홉 프롬프트를 사용하여 추가 훈련 없이 사전 훈련된 LLM에서 가장 두드러지지 않을 수 있는 잠재 다중 홉 추론 경로의 존재를 연구한다.\n' +
      '\n' +
      '모델 편집은 LMs에서 사실적 지식을 수정하는 방법을 검토한다(De Cao et al., 2021; Mitchell et al., 2022; Meng et al., 2022; Zhang et al., 2024). 그러나, 최근의 연구들은 주로 단일 팩트 편집에 초점을 맞춘 기존의 편집 접근법들이 편집된 팩트에 의존하는 팩트들로 편집을 전파하지 못한다는 것을 보여주었다(Onoe et al., 2023; Zhong et al., 2023; Cohen et al., 2023). 우리의 작업은 그러한 전파가 작동할 수 있는 가능성을 탐구한다. 또한, 추론 시 일관성에 영향을 미치는 경로를 조사하는 반면, 일관성에 대한 이전 작업은 일관성을 정량화하고 사후적으로 일관성을 개선하는 데 중점을 두었다(Ribeiro et al., 2019; Li et al., 2019; Asai and Hajishirzi, 2020; Elazar et al., 2021; Kassner et al., 2021, 2023; Jang et al., 2023). Sakarvadia et al. (2023)은 오류가 잠재 홉을 회상하지 못하는 것에서 비롯된다는 가설로 다중 홉 추론 정확도를 향상시키는 것을 목표로 하는 한편, 모델이 실제로 그러한 잠재 다중 홉 추론을 수행하는지에 대한 이 가설의 기초를 조사한다.\n' +
      '\n' +
      '##3 문제 정식화\n' +
      '\n' +
      '### Preliminaries\n' +
      '\n' +
      '우리는 "Stevie Wonder의 어머니는 Lula"와 같은 사실들을 주체인 \\(e\\(e,r,e^{\\prime})\\(e,r,e^{\\prime})의 세 쌍둥이로 간주한다. 구체적으로, 본 연구에서는 \\(e^{\\prime}\\)이 \\(e\\)에 대한 관계(e\\(r\\)에 대해 유일하게 또는 가장 잘 알려진 객체 개체(예: Stevie Wonder의 유일한 어미는 룰라)인 삼중항을 중심으로 \\(e^{\\prime}=r(e)\\)를 함수(e^{\\prime}=r(e)\\)로 보고, \\(r(e)\\은 함수식이고 \\(e^{\\prime}\\)는 표현식의 값이다. LLMs가 두 사실을 연결하는 \\(e_{1},r_{1},e_{2}), (e_{2},r_{2},e_{3}))\\(r_{2}(r_{1}(e_{1}))으로 표현되는 두 사실의 합성을 어떻게 처리하는지를 분석한다. 예를 표 1에 나타낸다.\n' +
      '\n' +
      'LLMs를 질의하기 위해 템플릿\\(\\tau(\\cdot)\\)을 사용하여 표현식\\(r_{2}(e_{2})\\) 또는 \\(r_{2}(r_{1}(e_{1}))\\)을 주어진 표현식의 값에 의해 정확하게 완성될 수 있는 프롬프트로 변환한다. 예를 들어, 단일 홉 표현식 \\(\\texttt{mother}(\\texttt{Stevie Wonder})\\)은 \\(\\tau(\\texttt{mother}(\\texttt{Stevie Wonder}))\\)에 의해 "Stevie Wonder의 어머니는 "_"로 변환될 수 있으며, 이는 "Lula"로 올바르게 완성될 수 있다. 마찬가지로, 2홉 표현식 \\(\\texttt{mother}(\\texttt{singer}(\\texttt{Superstition}))\\)은 \\(\\texttt{mother}(\\texttt{singer}(\\texttt{Superstition}))으로 표현될 수 있다. \\(\\texttt{mother}(\\texttt{singer}(\\texttt{Superstition})))는 \'Superstition\'의 가수의 어미는 "_"와 같은 정확한 완성도를 가진다. 반면에 \\(\\tau(r_{2}(e_{2}))\\)와 \\(\\tau(r_{2}(r_{1}(e_{1})))는 같은 답("Lula")을 갖는다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l} \\hline \\hline Notation & Example & Description \\\\ \\hline \\((e_{1},r_{1},e_{2})\\) & (Superstition, singer, Stevie Wonder) & fact triplets of named entities where \\(e_{i}\\) are named entities and \\(r_{i}\\) is a \\\\ \\((e_{2},r_{2},e_{3})\\) & (Stevie Wonder, mother, Lula) & relation function that maps \\(e_{i}\\) uniquely to \\(e_{i+1}\\), such that \\(r_{i}(e_{i})=e_{i+1}\\) \\\\ \\(e_{2}\\) & Stevie Wonder & bridge entity that connects the two fact triplets \\\\ \\(\\tau_{\\texttt{IH}}\\) & “The mother of Stevie Wonder is named” & one-hop prompt (requires one-hop reasoning) \\\\ \\(\\tau_{\\texttt{IH}}\\) & “The mother of the singer of ‘Superstition’ is named” & two-hop prompt (requires two-hop reasoning) \\\\ \\(\\mu(r_{i}(e_{1}))\\) & “the singer of ‘Superstition’ & descriptive mention of the bridge entity \\(e_{2}\\) created with \\(e_{1}\\) and \\(r_{1}\\) \\\\ \\(*\\) & “mother of song’s singer” & fact composition type \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 데이터세트의 해당 예제 표시. 갈색으로 된 텍스트는 교량 실체 \\(e_{2}\\), 스티비 원더(또는 큰따옴표로 부분 문자열로 제시될 때 교량 실체 이름)이고, 자주색으로 된 텍스트는 교량 실체 \\(\\mu(r_{1}(e_{1}))\\)), “미신의 가수”이다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:4]\n' +
      '\n' +
      'cessing two-hop prompts_. 먼저 EntRec를 프롬프트(SS5.1)에서 설명 언급 시 브리지 엔티티에 대한 LLM의 내부 리콜을 근사화하기 위한 메트릭으로 도입한다. 다음으로, 브리지 엔티티(SS5.2)를 간접적으로 언급하기 위해 입력 프롬프트를 변경할 때 이러한 리콜이 얼마나 자주 증가하는지를 측정할 것을 제안한다. 그런 다음 TwoHopFact를 사용하여 이를 평가하고 RQ1(SS5.3)을 답한다.\n' +
      '\n' +
      '#내부 개체 리콜 점수\n' +
      '\n' +
      '우리는 EntRec를 2홉 프롬프트 \\(\\tau_{\\text{2H}}\\) 내에서 브리지 엔티티 \\(e_{2}\\)의 LLM 회상을 측정하기 위한 메트릭으로 정의한다. 이는 두 홉 프롬프트에서 브리지 엔티티의 설명적 언급의 마지막 위치에서 특정 계층 \\(l\\)의 숨겨진 표현과 관련하여 정의된다. 이 숨겨진 표현은 엔티티 이름의 제1 토큰(예를 들어, "스티비 원더"의 제1 토큰)의 로그 확률을 계산하기 위해 어휘 공간에 투영된다. 형식적으로 \\(e_{2}^{(0)}\\)을 \\(e_{2}\\)의 첫 번째 토큰으로 하자.\n' +
      '\n' +
      '\\[\\text{EntRec}^{l}(e_{2},\\tau_{\\text{2H}) \\tag{1}\\] \\[=\\log\\text{softmax}(\\text{LayerNorm}(\\mathbf{x}^{l})W_{U})_{\\text{index}(e_{2}^{(0))},\\]\n' +
      '\n' +
      '여기서 \\(\\mathbf{x}^{l}\\in\\mathbb{R}^{h}\\)는 2홉 프롬프트 \\(\\tau_{\\text{2H}}\\)에서 브리지 엔티티의 서술적 언급의 마지막 토큰에서 \\(l\\)번째 트랜스포머 층으로부터의 출력이고, \\(\\text{index}(e_{2}^{(0)})\\in[0,V-1]\\)은 언매딩 매트릭스 \\(W_{U}\\in\\mathbb{R}^{h\\times V}\\)에서 \\(e_{2}^{(0)}\\)의 인덱스이다. LayerNorm은 마지막 레이어 출력 \\(\\mathbf{x}^{L-1}\\)을 다음 토큰 확률 분포를 얻기 위해 언임베딩 행렬에 투영하기 전에 사용하는 레이어 정규화이다. 이 정규화를 적용하면 EntRec\\({}^{L-1}(e_{2},\\tau_{\\text{2H}}))\\)는 서술적 언급에서 끝나는 \\(\\tau_{\\text{2H}})의 접두사의 다음 토큰으로서 \\(e_{2}^{(0)}})의 출력 확률과 호환될 수 있다. 2) 더 높은 EntRec\\({}^{l}(e_{2},\\tau_{\\text{2H}})는 \\(l\\)번째 레이어에서 브리지 엔터티의 더 강한 내부 회상으로 해석한다.\n' +
      '\n' +
      '각주 2: 우리는 엔티티의 내부 리콜을 측정하기 위해 고려하기를 원하지 않는 토큰의 빈도(Kobayashi et al., 2023)를 종종 모델링하므로 바이어스 용어를 생략한다.\n' +
      '\n' +
      '제안된 EntRec의 정의는 피험자의 마지막 토큰 위치에 구성된 표현이 피험자에 대한 정보를 인코딩하는 데 종종 중요한 역할을 한다고 보고한 이전 작업(Meng et al., 2022; Geva et al., 2023), 조기-계층 출력을 어휘 공간에 투영하는 노스탈리스트(2020) 작업 및 원-홉 프롬프트의 마지막 피험자 토큰 위치에 이러한 투영이 피험자와 의미적으로 관련된 해석 가능한 상위 순위 속성을 제공한다는 것을 보여주는 Geva et al. (2022)의 작업에서 영감을 받았다. EntRec는 개체 이름의 첫 번째 토큰에 대해서만 개체의 리콜을 평가하지만, 자동 회귀 LLM이 입력 텍스트를 처리하고 다음 토큰을 생성하는 방법과 직접 관련이 있다. 부록 C의 통제 실험은 EntRec를 내부 개체 회상을 측정하기 위한 합리적인 프록시로 검증한다.\n' +
      '\n' +
      '### Experiment\n' +
      '\n' +
      'EntRec가 주어졌을 때, 우리는 2홉 프롬프트를 \\(\\tau_{\\text{2H}}^{\\prime}\\)에서 \\(\\tau_{\\text{2H}}\\)으로 수정할 때 \\(\\tau_{\\text{2H}}^{\\prime}\\)의 내부 리콜이 \\(\\tau_{\\text{2H}}\\)에서 \\(\\tau_{\\text{2H}}\\)으로 얼마나 자주 개선되는지 측정하여 RQ1에 답한다. 구체적으로, TwoHopFact에서 EntRec\\({}^{l}(e_{2},\\tau_{text{2H}})>\\)EntRec\\({}^{l}(e_{2},\\tau_{text{2H}}^{\\prime})\\의 상대주파수를 측정한다.\n' +
      '\n' +
      '\\(\\tau_{text{2H}}^{\\prime}\\)을 구성하기 위해 우리는 \\(\\tau_{1}\\)을 \\(e_{1}^{\\prime}\\)으로 대체함으로써 \\(e_{1}}(e_{1}^{\\prime}\\)이 \\(e_{2}\\)을 가리키지 않도록, 또는 \\(r_{1}\\(r_{1}^{\\prime}\\)을 \\(r_{1}^{\\prime}\\)으로 대체함으로써 \\(\\mu(r_{1}^{\\prime}(e_{1}))이 \\(e_{2}\\)을 가리키지 않도록 하는 두 가지 방법으로 교량 실체에 대한 설명적 언급을 변경한다. 예를 들면, "the singer of \'Superstition" in \\(\\tau_{\\text{2H}}\\)을 "the singer of \'Thriller_\'" 또는 "_a plagiarist_ of \'Superstition"으로 치환하는 것을 들 수 있다. 이러한 조정을 각각 _entity substitution_ 및 _relation substitution_라고 한다.\n' +
      '\n' +
      'TwoHopFact의 각 two-hop prompt \\(\\tau_{\\text{2H}\\)에 대해, 동일한 팩트 구성 유형에서 하나의 (e_{1}^{\\prime}\\)과 미리 정의된 후보 관계 집합에서 하나의 (r_{1}^{\\prime}\\)을 무작위로 선택하여 \\(\\tau_{\\text{2H}^{\\prime}\\)을 생성한다. 그리고 나서 \\(\\tau_{\\text{2H}}^{\\prime}\\)을 \\(\\tau_{\\text{2H}}\\)으로 대체하거나 관계 치환이 \\(e_{2}\\)의 재현율을 증가시키는 경우의 상대적 빈도를 측정한다. 0.5 이상의 상대 빈도는 LLM의 첫 번째 홉 추론을 수행할 기회가 이러한 프롬프트에 대한 무작위 기회를 초과함을 시사한다.\n' +
      '\n' +
      '### Results\n' +
      '\n' +
      '추론의 첫 번째 홉에 대한 실질적인 증거가 있으며, 이는 모델 크기가 증가함에 따라 더 강력해진다.그림 2는 각 계층에서 개체 회상이 개체 및 관계 대체에 따라 증가하는 경우의 상대적 빈도를 보여준다. LLaMA-2 7B 개체 치환 결과(도 1(a))는 레이어 깊이가 증가함에 따라 첫 번째 홉 추론의 증거가 더 명확해지는 것을 보여주며, 레이어 31에서 0.71로 피크를 이룬다. 관계 치환은 레이어 20에서 0.63으로 피크를 갖는 약간 더 시끄러운 패턴을 나타낸다(도 1(e))\n' +
      '\n' +
      '모델 크기가 7B에서 13B 및 70B로 증가함에 따라 개체 대체 및 관계 대체 모두에 대해 첫 번째 홉 추론이 더 자주 발생한다. 전자의 경우, 최대 상대 주파수는 0.71(7B)에서 0.72(13B) 및 0.78(70B)로 상승한다(도 2(a)). 후자의 경우 0.63(7B)에서 0.64(13B) 및 0.76(70B)로 증가한다(도 2(b)).\n' +
      '\n' +
      '상대적으로 강력한 증거는 팩트 구성 유형의 최대 73%에서 첫 번째 홉 추론을 뒷받침하며, 팩트 구성 유형 52개 중 18/25/34 및 21/27/38은 개체 및 관계 대체에 대해 각각 0.8을 초과하는 최대 상대 빈도를 나타낸다. 또한 52개 유형 중 11개 유형이 모든 모델 크기와 대체 유형에 걸쳐 강력한 첫 번째 홉 추론 증거를 강력하게 보여준다. 예를 들어, "국가 대통령"의 최대 빈도("국가 \'아자트 u aakkh Artsakh\'가 대통령이 이끄는 국가")는 각 모형과 대체가 각각 0.97/0.92/1.0(그림 1(d))과 0.87/0.87/0.89(그림 1(h))의 최대 빈도를 보여준다. 개별 팩트 구성 유형은 레이어에 걸쳐 다양한 상대 빈도 패턴을 나타낸다.\n' +
      '\n' +
      '##6 멀티홉 추론의 초홉\n' +
      '\n' +
      '이 섹션에서는 LLM이 2-홉 프롬프트를 처리하는 동안 두 번째 홉 추론을 수행하는 경우가 얼마나 많은지 _Q2에 답한다. 추론의 두 번째 홉은 기술 언급에 의해 언급된 엔티티의 동일한 속성에 대한 2-홉 프롬프트에 응답하기 위해 브리지 엔티티의 속성(Stevie Wonder의 어머니)에 대해 알고 있는 것을 LLM이 활용하는 것으로 본다. 따라서, LLM이 두 번째 홉을 수행할 때, 브리지 엔티티의 리콜(즉, 첫 번째 홉을 해결함)과 브리지 엔티티의 속성에 대한 2-홉 프롬프트 및 대응하는 1-홉 프롬프트에 응답하는 유사성, 예를 들어, \'Superstition\'의 가수의 어머니 __와 스티비 원더의 어머니 __는 "_"이다. 즉, 모델이 2-홉 프롬프트를 프로세싱하는 동안 브리지 엔티티(예를 들어, 스티비 원더)를 더 강하게 리콜할수록, 이 프롬프트의 완료는 1-홉 프롬프트의 완료와 유사해야 한다. 이하에서는, 우리가 _consistency_라고 지칭하는 프롬프트 완성들에서 엔티티 리콜과 _similarity_ 사이에 그러한 인과적 연결이 얼마나 자주 존재하는지를 테스트하기 위한 우리의 접근법을 설명한다.\n' +
      '\n' +
      '### Consistency Score\n' +
      '\n' +
      '우리는 LLM이 두 홉 및 한 홉 프롬프트에 얼마나 일관되게 응답하는지 측정하기 위해 CnstScore를 정의한다. \\(\\mathbf{p}_{\\tau_{\\text{2H}},\\mathbf{p}_{\\tau_{\\text{1H}}\\in\\mathbbb{R}^{V}\\)는 각각 2-홉 프롬프트 \\(\\tau_{\\text{2H}})와 대응하는 1-홉 프롬프트 \\(\\tau_{\\text{1H}}\\)에 대한 출력 확률 분포라고 하자. 로 표기 \\(\\mathrm{H}(Q,P)=-\\sum_{i=0}^{V-1}P_{i}\\log Q_{i}\\)\n' +
      '\n' +
      '그림 3: LLaMA-2의 규모를 증가시킨 실험 결과. 우리 작업의 모든 실험에 대한 기술적 세부 사항은 부록 E에서 찾을 수 있다.\n' +
      '\n' +
      '그림 2: LLaMA-2의 교량 실체의 내부 재현율이 실체 치환(상행)과 관계 치환(하행)에 따라 증가하는 경우의 상대적 빈도. 상대 주파수가 0.5 이상인 경우 막대는 파란색으로 표시되고 그렇지 않은 경우 빨간색입니다.\n' +
      '\n' +
      '확률 분포\\(P\\)와 \\(Q\\) 사이의 교차 엔트로피는 다음과 같이 정의된다.\n' +
      '\n' +
      '\\tau_{\\text{2H}},\\tau_{\\text{1H}})\\tag{2}]\\[=-0.5\\mathrm{H}(\\mathbf{p}_{\\tau_{\\text{2H}},\\mathbf{p}_{\\tau_{\\text{1H}}})-0.5\\mathrm{H}(\\mathbf{p}_{\\tau_{\\text{1H}},\\mathbf{p}_{\\tau_{\\text{2H}}}}}}}}.\n' +
      '\n' +
      '이 점수는 두 확률 분포 사이의 유사성을 계산하고 교차 엔트로피를 평균하여 평가 시 대칭성을 보장한다. 평균으로부터의 대칭성은 개별 분포의 엔트로피 수준에 대한 민감도를 완화하여 양방향으로의 분기의 동등한 처리를 목표로 한다.\n' +
      '\n' +
      '2홉 프롬프트 완료 정확성 또는 그라운드 진실 답변의 확률 대신에 일관성을 사용하는 것에 주목한다. 왜냐하면, 후자의 메트릭은 대응하는 1홉 프롬프트 완료가 부정확한 경우에 대한 2홉 추론을 캡처하기에 불충분하기 때문이다. 또한, 이러한 메트릭들은 지상 진실 답변 또는 답변 후보들의 세트의 선택으로부터 잡음을 상속한다. 한편, 출력 분포의 유사도를 비교하는 것은 접지 진리의 선택에 영향을 받지 않으며, 접지 진리 응답이 원홉 프롬프트의 Top-1 세대에 있지 않은 경우에도 두 번째 홉 추론을 포착할 수 있는 방법을 제공한다.\n' +
      '\n' +
      '또한, 이러한 메트릭은 확률 분포에서 미묘한 일관성 차이를 포착할 수 없기 때문에 완료 문자열 또는 하나/2홉 프롬프트의 이진 정확도를 비교하지 않는다. 우리는 Kullback-Leibler나 Jensen-Shannon divergence보다는 cross-entropy를 선택하는데, 그 이유는 후자의 메트릭에는 일관성과는 무관하지만 교차 엔트로피 신호를 희석하여 점수를 지배할 수 있는 엔트로피 항이 포함되어 있기 때문이다. 일관성 점수가 높을수록 출력 분포 간의 유사성이 더 크다는 것을 나타냅니다. 부록 D에서는 교량 실체의 속성에 대한 모형의 지식의 활용에 대한 합리적인 근사치로 일관성 점수에 대한 실증적 증거를 제시한다.\n' +
      '\n' +
      '### Experiment\n' +
      '\n' +
      'EntRec와 CnstScore가 주어졌을 때, 우리는 \\(l\\)번째 계층에서 브리지 엔티티 \\(e_{2}\\)의 리콜이 얼마나 자주 증가하는지를 측정하여 RQ2에 답한다. 즉, EntRec\\({}^{l}(e_{2},\\tau_{\\text{2H})\\)의 증가가 CnstScore\\((\\tau_{\\text{2H}},\\tau_{\\text{1H})\\)의 증가로 이어지는지를 살펴본다.\n' +
      '\n' +
      'CnstScore\\((\\tau_{\\text{2H}},\\tau_{\\text{1H}})\\)가 EntRec\\({}^{l}(e_{2},\\tau_{\\text{2H}})\\)에 직접적으로 의존한다면 미분적분을 이용하여 해답을 구할 수 있을 것이다. 그러나 두 값 사이에는 직접적인 기능적 의존성이 없다. 대신에, 우리는 계산을 위해 \\(\\mathbf{x}^{l}\\)에 대한 두 메트릭의 공유 의존도를 활용하는데, 여기서 \\(l\\in[0,L-1)\\), 이를 EntRec\\((\\mathbf{x}^{l})\\) 및 CnstScore\\((\\mathbf{x}^{l})\\)에 대한 EntRec\\((\\mathbf{x}^{l}))으로 재정의한다. 이러한 재매개변수화를 통해 문항을 "EntRec\\(\\mathbf{x}^{l})\\)이 \\(\\mathbf{x}^{l}\\)의 변화에 의해 증가한다면, CnstScore\\(\\mathbf{x}^{l}))도 증가하는가?"로 변화시킬 수 있다.\n' +
      '\n' +
      '각주 3: CnstScore\\((\\tau_{\\text{2H}},\\tau_{\\text{1H}})\\)는 \\(\\mathbf{p}_{\\tau_{\\text{2H}}}\\)을 사용하며, 계산은 \\(\\mathbf{x}^{l}\\)을 사용한다. 그러나 \\(\\mathbf{p}_{\\tau_{\\text{1H}}\\)을 얻기 위해 \\(l=0,\\cdots,L-2\\) 층에서의 주의력 출력을 계산하기 위해 \\(\\mathbf{x}^{l}\\)만 사용된다.\n' +
      '\n' +
      '이를 탐색하기 위해 EntRec\\(\\nabla_{\\mathbf{x}^{l}}\\)EntRec\\(\\mathbf{x}^{l}}\\)으로 표현되는 가장 가파른 증가 방향으로 EntRec\\((\\mathbf{x}^{l})\\)을 조정하고, 변화의 크기에 따라 \\(\\alpha\\)\\(\\mathbf{x}^{l}}\\)을 수정하여 CnstScore\\((\\mathbf{x}^{l})\\)에 미치는 영향을 관찰한다:\n' +
      '\n' +
      '\\[\\mathbf{\\hat{x}}^{l}(\\alpha)=\\mathbf{x}^{l}+\\alpha\\nabla_{\\mathbf{x}^{l}} \\text{EntRec}(\\mathbf{x}^{l}).\\]\n' +
      '\n' +
      '이어서, \\(\\alpha)\\)의 함수 CnstScore\\((\\alpha)\\)로 표현할 수 있는 \\(\\mathbf{\\hat{x}}^{l}(\\alpha)\\),4를 이용하여 CnstScore\\((\\mathbf{x}^{l})\\)을 계산한다. 그리고 전류값에서 변화의 방향을 이해하기 위해 미분 \\(\\frac{d}{d\\alpha}\\text{CnstScore}(\\alpha)\\big{|}_{\\alpha=0}\\)을 살펴본다. 양의 도함수는 EntRec\\((\\mathbf{x}^{l})\\)의 증가가 CnstScore\\((\\tau_{\\text{2H}},\\tau_{\\text{1H})\\)의 증가로 이어지는 반면 음의 도함수는 반대임을 나타낸다. TwoHopFact에서 두 홉 프롬프트 중 양의 기울기의 상대적 빈도_를 평가하여 LLM이 추론의 두 번째 홉을 수행하는 빈도를 정량화하며, 0.5 이상의 빈도는 LLM의 두 번째 홉 추론 수행 기회가 이러한 프롬프트에 대한 무작위 확률을 초과함을 시사한다.\n' +
      '\n' +
      '각주 4: \\(\\mathbf{\\hat{x}}^{l}(\\alpha)\\)을 \\(\\mathbf{\\hat{x}}^{l}(\\alpha)\\)으로 대체하기 위해 활성화 패칭(Wang et al., 2023)을 사용한다.\n' +
      '\n' +
      '### Results\n' +
      '\n' +
      '두 번째 홉 추론의 적당한 증거가 있는데, 이는 모델 크기가 증가함에 따라 더 강해지지 않는다.그림 4는 브리지 개체 회상을 증가시키면 일관성이 증가하는 사례의 상대적 빈도를 보여준다. LLaMA-2 7B에서, 중층 및 후기층은 통계적 유의성을 갖는 0.5(랜덤 우연)보다 높은 상대 빈도를 나타내며, 층 30에서 0.64로 정점을 이룬다. 랜덤하게 초기화된 모델을 사용한 시험 결과는 랜덤성 베이스라인으로서 0.5를 검증한다(도 3(d)).\n' +
      '\n' +
      '그러나 첫 번째 홉 추론(SS5)과 달리 두 번째 홉 추론은 모델 크기가 증가함에 따라 강화되지 않으며, 7B에서 13Band 70B로 스케일링할 때 최대 상대 주파수는 그림 2(c)와 같이 0.64(7B), 0.65(13B), 0.61(70B)에서 비교적 안정적으로 유지된다. 이 발견은 Ofir Press et al.(2023)의 관찰과 일치하며, 단일-홉 질문 응답 성능은 모델 크기가 증가함에 따라 멀티-홉 성능보다 더 빠르게 개선되며, 따라서 _compositionality gap_(모델들이 모든 서브-문제들에 정확하게 답할 수 있지만 전체 해를 생성하지 못하는 빈도의 비율)는 모델 크기가 증가함에 따라 감소하지 않는다는 점에 주목할 필요가 있다.\n' +
      '\n' +
      '상대적으로 강력한 증거는 팩트 구성 유형의 최대 19%에서 두 번째 홉 추론을 뒷받침하며, LLaMA-2 7B-13B-70B의 경우 팩트 구성 유형 52개 중 107/75개가 각각 0.8을 초과하는 최대 상대 빈도를 나타낸다. 이 중 "인적 대학 설립자"와 "국가 총장"은 모든 모델 크기에 걸쳐 최대 빈도수가 각각 0.86/0.81/0.82(그림 3(g)) 및 0.84/0.89/0.82(그림 3(h))로 이러한 강력한 두 번째 홉 추론 증거를 보여준다.\n' +
      '\n' +
      '##7 잠재 다중 홉 추론\n' +
      '\n' +
      '본 절에서는 LLMs가 RQ1과 RQ2에 대한 응답을 결합하여 2-hop prompt_를 처리하면서 잠재된 다중 홉 추론을 수행하는 빈도를 측정한다. 각 2-hop prompt에 대해, 추론 첫 번째 홉과 두 번째 홉의 증거로 각각 RQ1(개체/상관 치환을 통한 개체 재현율 증가)과 RQ2(개체 재현율 증가의 일관성 증가)에 대한 성공적인 결과를 고려한다. 네 가지 가능한 결과가 발생한다: (SS) RQ1과 RQ2 모두에서 우리가 멀티 홉 추론으로 보는 성공, (FS) RQ1에서는 실패하지만 RQ2에서는 성공, (SF) RQ1에서는 성공하지만 RQ2에서는 실패, (FF) RQ1과 RQ2 모두에서 실패.\n' +
      '\n' +
      '잠재적 다중 홉 추론의 적당한 증거가 있으며, 때로는 모델 크기가 증가함에 따라 더 강력해진다.그림 5는 녹색, 파란색, 노란색 및 빨간색이 각각 SS, FS, SF 및 FF의 각 경우를 나타내는 4가지 사례의 상대적 빈도를 보여준다. LLaMA-2 7B는 랜덤 확률(0.25) 이상의 성공적인 멀티 홉 추론(녹색)을 위해 상대 주파수를 나타내며, 0.46(엔티티 치환) 및 0.38(상관 치환)에서 정점을 이룬다. 부분 다중 홉 추론(녹색 + 파란색 + 노란색)의 가능성은 이후 계층에서 0.8을 초과한다.\n' +
      '\n' +
      '개체 대체 결과는 모델 크기와 함께 증가된 다중 홉 추론을 보여주지 않는 반면(그림 2(d)), 관계 대체는 스케일링 경향을 나타낸다. 7B에서 70B까지, 최대 상대 주파수는 0.38에서 0.43으로 증가하며, 이는 더 큰 모델들이 관계적 변화들과 함께 멀티-홉 추론을 용이하게 할 수 있음을 시사한다(도 2(e)).\n' +
      '\n' +
      'LLaMA-2 7B-13B-70B의 경우, 7/3/12 유형이 개체 치환의 경우, 3/3/9 유형이 관계 치환의 경우, 최대 23%의 사실 구성 유형에서 잠재 다중 홉 추론을 지원한다. "자본 국가"의 최대 빈도("라자루스 차크라 대통령이 이끄는 국가의 국가가 명명됨")는 모든 모델 및 대체에 걸쳐 이 임계값을 각각 0.68/0.82/0.66(그림 4(d)) 및 0.74/0.82/0.68(그림 4(h))로 초과한다. 개별 유형은 전체 데이터 집합과 구별되는 다양한 패턴을 보여준다.\n' +
      '\n' +
      '##8 토론 및 결론\n' +
      '\n' +
      '본 연구는 LLM의 잠재된 멀티홉 추론 능력을 연구한다. 우리는 특정 팩트 구성에 대한 잠재 다중 홉 추론의 강력한 증거를 찾는다.\n' +
      '\n' +
      '그림 4: \\(l\\)번째 층에서 교량 실체를 더 강하게 회상하는 상대 주파수는 LLM의 일관성을 증가시킨다. 상대 주파수가 0.5 이상인 경우 막대는 파란색으로 표시되고 그렇지 않은 경우 빨간색입니다. 개입이 해당 계층에서의 일관성에 영향을 미치지 않기 때문에 마지막 계층에서 0.5의 값을 수동으로 설정한다.\n' +
      '\n' +
      '추론 경로가 있는 유형은 사례의 80% 이상에서 활용된다. 그러나 활용은 맥락성이 매우 높으며, 추론에 대한 증거가 약하거나 거의 없는 사실 구성 유형도 있다. 전체 프롬프트 세트에 걸친 두 번째 및 다중 홉 추론의 증거는 첫 번째 홉에서만 다소 온건하고 상당하다.\n' +
      '\n' +
      '또한, 모델 크기가 증가함에 따라 잠재 다중 홉 추론 경로의 첫 번째 홉에 대한 명확한 스케일링 경향을 보이지만, 두 번째 홉 추론 경로에 대한 그러한 스케일링 증거는 보이지 않는다. 이는 Ofir Press et al.(2023)이 모델 크기가 증가함에 따라 구성성 격차(모델이 모든 하위 문제에 정확하게 답할 수 있지만 전체 해를 생성하지 못하는 빈도의 비율)가 감소하지 않는 이유일 수 있다.\n' +
      '\n' +
      '우리의 분석은 최대 70B 매개변수의 LLaMA-2 모델 패밀리를 기반으로 하지만, 우리의 연구 결과는 잠재 다중 홉 추론을 촉진하기 위한 현재 스케일링 패러다임에서 잠재적인 한계를 시사한다. 따라서, 우리는 사전 훈련 데이터, 지식 검색 및 활용을 촉진하는 손실 함수 또는 LLM의 더 강한 잠재 추론 능력에 대한 내부 지식 표현에 대한 더 강한 귀납적 편향을 가진 모델 아키텍처의 선택에 대한 연구가 필요할 수 있다. 그러나 프리트레이닝 역학 및 데이터와 관련하여 멀티홉 추론의 강력한 증거로 프롬프트의 하위 집합을 분석하면 현재 프리트레이닝 및 스케일링 패러다임의 맥락에서도 이러한 능력의 출현에 대한 통찰력을 제공할 수 있다.\n' +
      '\n' +
      '전반적으로, 우리의 연구 결과는 LLM 능력에 대한 이해를 향상시키며 매개변수 효율성, 일반화 및 통제 가능성과 관련된 잠재 다중 홉 추론을 촉진하고 강화하는 것을 목표로 하는 향후 연구를 안내할 수 있다.\n' +
      '\n' +
      '## 9 Limitations\n' +
      '\n' +
      '잠재적 다중 홉 추론 경로(Latent Multi-Hop Reasoning Pathway)에서 잠재적 다중 홉 추론을 위한 하나의 경로를 연구(예를 들어, 개체 회상을 통해 두 번째 홉의 사용을 테스트함)하는 동안, LLMs(McGrath et al., 2023)에서 추론 경로의 잠재적 중복성을 고려하여 다른 경로가 존재할 수 있으며, 동일한 정보가 다른 방식으로 검색될 수 있다. 또한, 다중 홉 추론을 종단 간 측정하지 않고, 단일 계층에 대해 첫 번째 홉과 두 번째 홉에서 발생하는 변화만을 추적하는 반면, 추론의 첫 번째 홉의 효과는 다른 계층으로 전파될 수 있다. 따라서 우리가 보는 효과는 잠재된 2홉 추론을 수행하는 모델의 능력에 대한 하한일 수 있다.\n' +
      '\n' +
      'DatasetWe는 \\(e,r,e^{\\prime}=r(e)\\)이 \\(e\\)에 대한 관계식에서 유일하거나 가장 유명한 대상이 되도록 \\((e,r,e^{\\prime})\\)의 사실 삼중항을 수집하는 것을 목표로 한다. 참조 링크 수가 가장 많은 개체를 사용하고, 이를 위해 수집된 팩트 트리플렛 중 적어도 \\(e^{\\prime}\\)이 유일한 개체임을 보장하지만, 위키다타에서 유입되는 잡음이 있다. 게다가 현실적으로 방대한 실세계로 인해 \'만\'이라는 조건을 엄격히 만족시키기는 어렵다.\n' +
      '\n' +
      '도 5: LLaMA-2 모델에서 RQ1 및 RQ2의 네 가지 결과의 상대적 빈도, RQ1에 대한 개체 대체(상행) 및 관계 대체(하행)를 나타낸다. 첫 번째 홉 추론을 위한 입력 대체에 따른 개체 회상의 증가는 RQ1의 _success_ 경우이고, 두 번째 홉 추론을 위한 개체 회상의 증가에 따른 일관성 점수의 증가는 RQ2의 _success_ 경우이다. 녹색, 파란색, 노란색 및 빨간색 막대는 RQ1 및 RQ2에 대한 SS(success-success), FS, SF 및 FF의 경우를 각각 나타낸다. 우리는 개입이 해당 계층에서의 일관성에 영향을 미치지 않기 때문에 마지막 계층의 값을 RQ1에 대한 상대 빈도에 곱한 0.5로 수동으로 설정한다.\n' +
      '\n' +
      '빠르고 역동적으로 변화하는 지식.\n' +
      '\n' +
      'MetricsOur 척도는 LLMs가 입력 텍스트를 처리하고 다음 토큰을 생성하는 방법과 직접적인 관련이 있지만, 엔티티의 첫 번째 토큰만을 사용하기 때문에 근사치이다. 또한, 내부 개체 회상 점수는 표현 드리프트, 편향성, 취성 등의 단점이 있는 로짓 렌즈(노스텔라 대수학자, 2020)를 기반으로 한다(Belrose et al., 2023; Timkey and van Schijndel, 2021). 그러나 이러한 한계는 초기 출구(Din et al., 2023)와 같은 적응 계산 방법에 대해 연구된 바와 같이 초기 계층에서 예측을 정확하게 하는 것이 아니라 LLM의 내부 동역학을 연구하기 때문에 분석에 최소한의 영향을 미친다.\n' +
      '\n' +
      '## Acknowledgements\n' +
      '\n' +
      '소중한 피드백과 토의에 대해 이상우, 자스민 배스팅스, 윌리엄 코헨에게 감사드린다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Akyurek et al. (2023) Ekin Akyurek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. 2023. 상황 내 학습은 어떤 학습 알고리즘인가요? 선형 모델을 사용한 조사. _ICLR_에서.\n' +
      '* 알렌-주 및 리(2023) 제위안 알렌-주 및 위안지 리. 2023. 언어 모델의 물리학: Part 3.2, 지식 조작_ arXiv_.\n' +
      '*Asai and Hajishirzi (2020) Akari Asai and Hannaneh Hajishirzi. 2020. 일관성 있는 질문 답변을 위한 논리 유도 데이터 증강 및 정규화. _ACL_에서.\n' +
      '* Belrose et al. (2023) Nora Belrose, Zach Furman, Logan Smith, Danny Halawi, Igor Ostrovsky, Lev McKinney, Stella Biderman, and Jacob Steinhardt. 2023. 튜닝된 렌즈로 변압기들로부터 잠재 예측들을liciting. _ arXiv_.\n' +
      '* Berglund et al. (2024) Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans, A I Taskforce, and Apollo Research. 2024. 역전 저주: "a는 b이다"에 훈련된 LLM들은 "b는 a이다"를 학습하지 못한다. _ICLR_에서.\n' +
      '* Brown et al. (2020) Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. 2020. 언어 모델은 소수의 학습자이다. _NeurIPS_에서.\n' +
      '* Chan et al. (2022) Stephanie Chan, Adam Santoro, Andrew Lampinen, Jane Wang, Aaditya Singh, Pierre Richemond, James McClelland, and Felix Hill. 2022. 데이터 분포 특성은 트랜스포머에서 새로운 상황 내 학습을 유도한다. _NeurIPS_에서.\n' +
      '* Chanin et al. (2023) David Chanin, Anthony Hunter, and Oana-Maria Camburu. 2023. 대형 언어 모델에서 선형 관계 개념을 식별. _ arXiv_.\n' +
      '* Cohen et al. (2023) Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva. 2023. 언어 모델에서의 지식 편집의 파급 효과 평가. _ arXiv_.\n' +
      '* Conmy et al. (2023) Arthur Conmy, Augustine N Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adria Garriga-Alonso. 2023. 기계론적 해석성을 위한 자동화된 회로 발견을 향하여. _NeurIPS_에서.\n' +
      '* Dai et al. (2023) Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Zhifang Sui, and Furu Wei. 2023. GPT는 왜 상황 내 학습을 할 수 있는가? 언어 모델은 메타 최적화 도구로서 기울기 하강을 비밀리에 수행한다. ACL_의 _Findings.\n' +
      '* De Cao et al. (2021) Nicola De Cao, Wilker Aziz, and Ivan Titov. 2021. 언어 모델에서의 사실적 지식 편집. _EMNLP_에서.\n' +
      '* Din et al. (2023) Alexander Yom Din, Taelin Karidi, Leshem Choshen, and Mor Geva. 2023. 결론으로 점프: 선형 변환을 갖는 단축 변압기. _ arXiv_.\n' +
      '* Dziri et al. (2023) Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen Lin, Sean Welleck, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena D Hwang, Soumya Sanyal, Xiang Ren, Allyson Ettinger, Zaid Harchaoui, and Yejin Choi. 2023. 믿음 및 운명: 변압기의 구성성에 대한 한계. _NeurIPS_에서.\n' +
      '* Elazar et al. (2021) Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich Schutze, and Yoav Goldberg. 2021. 사전 훈련된 언어 모델에서의 일관성 측정 및 개선 TACL_.\n' +
      '* Feng and Steinhardt (2024) Jiahai Feng and Jacob Steinhardt. 2024. 언어 모델들은 문맥에서 엔티티들을 어떻게 바인딩하는가? _ICLR_에서.\n' +
      '* Geva et al. (2023) Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. 2023. Auto-regressive language model에서 사실적 연관성에 대한 리콜 제거. _EMNLP_에서.\n' +
      '* Geva et al. (2022) Mor Geva, Avi Caciularu, Kevin Ro Wang, and Yoav Goldberg. 2022. 트랜스포머 피드-포워드 레이어들은 어휘 공간에서 개념들을 홍보함으로써 예측들을 구축한다. _EMNLP_에서.\n' +
      '* Geva et al. (2021) Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. 2021. 트랜스포머 피드-포워드 레이어는 키-밸류 메모리이다. _EMNLP_에서.\n' +
      '* Geva et al. (2021) Evan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas, Yonatan Belinkov, and David Bau. 2024. 변압기 언어 모델에서의 관계 디코딩의 선형성. _ICLR_에서.\n' +
      '* Hou et al. (2023) Yifan Hou, Jiaoda Li, Yu Fei, Alessandro Stolfo, Wangchunshu Zhou, Guangtao Zeng, Antoine Bosselut, and Minmaya Sachan. 2023. 언어 모델의 다단계 추론 능력의 기계론적 해석에 관한 것이다. _ACL_에서.\n' +
      '* 장 등(2023) 장명준, 보살 프라사드 마점더, 줄리안 맥아울리, 토마스 루카시위츠, 오아나-마리아 캄부루. 2023. 어떻게 결정하는지 알아! 자연어 설명의 불일치를 적대적으로 감지하고 완화한다. _ACL_에서.\n' +
      '* Kassner et al. (2023) Nora Kassner, Oyvind Tafjord, Ashish Sabharwal, Kyle Richardson, Hinrich Schuetze, and Peter Clark. 2023. 합리성을 가진 언어 모델들. _EMNLP_에서.\n' +
      '* Kassner et al. (2021) Nora Kassner, Oyvind Tafjord, Hinrich Schutze, and Peter Clark. 2021. BeliefBank: 체계적인 믿음의 개념을 위해 미리 훈련된 언어 모델에 메모리를 추가하는 것. _EMNLP_에서.\n' +
      '* Kobayashi et al. (2023) Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, and Kentaro Inui. 2023. 트랜스포머 언어 모델은 예측 헤드에서 단어 빈도를 처리한다. _ACL_에서.\n' +
      '* Li et al. (2019) Tao Li, Vivek Gupta, Maitrey Mehta, and Vivek Srikumar. 2019. A logic-driven framework for consistency of neural models. _EMNLP_에서.\n' +
      '* Lieberum et al. (2023) Tom Lieberum, Matthew Rahtz, Janos Kramar, Neel Nanda, Geoffrey Irving, Rohin Shah, and Vladimir Mikulik. 2023. 회로분석 해석가능성 척도인가? 친칠라의 객관식 능력에서 나온 증거 arXiv_.\n' +
      '* McGrath et al. (2023) Thomas McGrath, Matthew Rahtz, Janos Kramar, Vladimir Mikulik, and Shane Legg. 2023. The hydra effect: Emergent self-repair in language model computation. _ arXiv_.\n' +
      '* Meng et al. (2022) Kevin Meng, David Bau, Alex Andonian, and Yoatan Belinkov. 2022. GPT 내의 사실적 연관들을 위치시키고 편집하는 단계를 포함하는, 방법. _NeurIPS_에서.\n' +
      '* Mitchell et al. (2022) Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher D Manning. 2022. 축척에서 빠른 모델 편집. _ICLR_에서.\n' +
      '* Nanda and Bloom (2022) Neel Nanda and Joseph Bloom. 2022. 트랜스포머렌즈. [https://github.com/neelnanda-io/TransformerLens] (https://github.com/neelnanda-io/TransformerLens).\n' +
      '* Nanda et al. (2022) Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. 2022. 기계론적 해석성을 통한 그로킹의 진행 방안. _ICLR_에서.\n' +
      '* 노스탈 대수학자(2020) 노스탈 대수학자. 2020. 해석 gpt: 로짓 렌즈.\n' +
      '* Press et al. (2023) Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah Smith, and Mike Lewis. 2023. 언어 모델들의 조성 갭을 측정하고 좁히는 단계. EMNLP_의 _Findings.\n' +
      '* Olsson 등(2022) Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conterly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2022. In-context learning and induction head. _ arXiv_.\n' +
      '* Onoe et al. (2023) Yasumasa Onoe, Michael J Q Zhang, Shankar Padmanabhan, Greg Durrett, and Eunsol Choi. 2023. LMs는 설명으로부터 새로운 엔티티를 학습할 수 있는가? 주입된 지식을 전파하는 데 도전합니다. _ACL_에서.\n' +
      '* OpenAI 등(2023) OpenAI,; Josh Achiam, Steven Adler, Ilge Akkaya, Florencia Leoni Aleman, Diogo Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuskin, Suchir Balaji, Valerie Balcon, Paul Baltescu, Haiming Bao, Mo Bavarian, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Irvan Bello, Jake Berdine, Gabriel Bernatet Brakman, Greg Brockman, Tim Brooks, Miles Brundage, J. Chen, J. Chen, J. Chen, J. Chen, J. Chen, J. Chen, J. Chen, J. Chen, J. Chen, J. 2023. Gpt-4 기술보고서 _ arXiv_.\n' +
      '* Petroni et al. (2019) Fabio Petroni, Tim Rocktaschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and Sebastian Riedel. 2019. 지식 기반으로서의 언어 모델? _EMNLP_에서.\n' +
      '* Prystawski and Goodman (2023) Ben Prystawski and Noah D Goodman. 2023년, 왜 차근차근 생각해? 추론은 경험의 지역성에서 나타난다. _NeurIPS_에서.\n' +
      '* Ribeiro et al. (2019) Marco Tulio Ribeiro, Carlos Guestrin, and Sameer Singh. 2019년 빨간 장미는 빨간색인가요? 질문-응답 모델의 일관성을 평가하는 중입니다. _ACL_에서.\n' +
      '* Sakarvadia et al. (2023) Mansi Sakarvadia, Aswathy Ajith, Arham Khan, Daniel Grzenda, Nathaniel Hudson, Andre Bauer, Kyle Chard, and Ian Foster. 2023. 메모리 주입: 트랜스포머 기반 언어 모델에서 추론 중 멀티홉 추론 실패 수정. _ arXiv_.\n' +
      '* Saparov et al. (2023) Abulhair Saparov, Richard Yuanzhe Pang, Vishakh Padmakumar, Nitish Joshi, Seyed Mehran Kazemi, Najoung Kim, and He He. 2023. OOD 예제를 이용하여 대형 언어 모델의 일반적인 연역적 추론 능력을 테스트한다. _NeurIPS_에서.\n' +
      '* Timkey and van Schijndel (2021) William Timkey and Marten van Schijndel. 2021. 모든 하드 및 무 바이트: 트랜스포머 언어 모델의 로그 치수는 표현 품질을 모호하게 한다. _EMNLP_에서.\n' +
      '* Touvron et al. (2017) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Cynthia Kardan, Vedan Houken, Saghar Hosseini, Rui Hungbog, Yixin Nie, Andrew Poulton, Jeremy Reixenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, E. Michael Smith, R. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. 2023. 라마 2: 오픈 파운데이션 및 파인 튜닝된 채팅 모델들_ arXiv_.\n' +
      '* Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017년, 집중만 하면 돼 _NeurIPS_에서.\n' +
      '* Oswald et al. (2023) Johannes Von Oswald, Eyvind Niklasson, Ettore Randazzo, Joao Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. 2023. 트랜스포머는 기울기 하강에 의해 컨텍스트 내를 학습한다. _ICML_에서.\n' +
      '* Vrandecic and Krotzsch (2014) Denny Vrandecic and Markus Krotzsch. 2014. Wikidata: free collaborative knowledgebase. _ ACM_의 통신.\n' +
      '* Wang et al. (2023) Kevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. 2023. Interpretability in the wild: a circuit for indirect object identification in GPT-2 small. _ICLR_에서.\n' +
      '* Wei et al. (2022a) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a. 대형 언어 모델의 새로운 능력. _ TMLR_.\n' +
      '* Wei et al. (2022b) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022b. 사고의 사슬은 큰 언어 모델에서 추론을 이끌어낸다. _NeurIPS_에서.\n' +
      '* Welbl 등(2018) Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. 2018. 문서 전반에 걸친 멀티홉 읽기 이해를 위한 데이터셋 구축. _ TACL_.\n' +
      '* Wolf et al. (2023) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. 러쉬 2020. 허깅페이스의 트랜스포머: 최첨단 자연어 처리. _ arXiv_.\n' +
      '* Yang et al. (2018) Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning. 2018. HotpotQA: 다양하고 설명 가능한 멀티홉 질문 응답을 위한 데이터셋. _EMNLP_에서.\n' +
      '* Zhang et al. (2024) Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuanheng Ni, Siyuan Cheng, Ziwen Xu, Zin Xu, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, 및 Huajun Chen. 2024. 대형 언어 모델에 대한 지식 편집에 대한 포괄적인 연구. _ arXiv_.\n' +
      '* Zhong et al. (2023) Zexuan Zhong, Zhengxuan Wu, Christopher D Manning, Christopher Potts, and Danqi Chen. 2023. MQAKE: 멀티 홉 질문을 통해 언어 모델에서 지식 편집을 평가한다. _EMNLP_에서.\n' +
      '* Zhou et al. (2022) Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, and Ed H Chi. 2022. 최소에서 최대 프롬프트는 큰 언어 모델에서 복잡한 추론을 가능하게 한다. _ICLR_에서.\n' +
      '* Zhu and Li(2023) Zeyuan Allen Zhu and Yuanzhi Li. 2023. 언어 모델의 물리학: Part 3.1, 지식 저장 및 추출_ arXiv_.\n' +
      '\n' +
      'Dataset construction\n' +
      '\n' +
      '우리는 다음과 같은 데이터 구축 파이프라인으로 위키다타(Vrandecic and Krotzsch, 2014)를 사용하여 TwoHopFact를 구축한다.\n' +
      '\n' +
      '### Data Selection\n' +
      '\n' +
      '우리는 잘 알려진 관계 및 개체를 선택하고 관계당 충분한 수의 샘플을 생성한다. 관계는 수동으로 선택됩니다. 위키다타를 질의할 때, 우리는 엔티티들을 자연어 위키피디아 제목을 갖는 단수 엔티티들로 제한하고 최대 수의 참조 링크들을 갖는 엔티티들을 선택한다. 또한 입력에서 직접 복사함으로써 \\(e_{1}=e_{2}\\)의 사소한 회상을 허용할 수 있는 \\(e_{1}=e_{2}\\)의 경우도 제외한다. 또한, 동일한 팩트 구성 유형의 팩트 중에서 교량 엔티티 \\(e_{2}\\)가 고유하도록 하여 교량 엔티티의 불균형을 완화한다. 마지막으로, 팩트 구성 유형의 불균형을 완화하기 위해 다운 샘플링을 적용한다.\n' +
      '\n' +
      '관계 선택 먼저, \\(r_{1}(e_{1})=e_{2}\\을 수집하기 위해 \\(e_{1}\\)과 \\(r_{1}\\)의 관계를 선택하여 교량 실체의 서술적 언급 유형을 결정한다. 우리가 선택한 다리 주체는 "노래의 가수"(특정 노래의 가수), "국가의 국가"(특정 국가를 가진 국가), "창립자의 조직"(특정 인물이 설립한 조직), "조직자의 CEO"(특정 단체의 CEO)와 같은 유형을 가지고 있다. 예를 들어, 일부 소설에는 많은 저자가 있을 수 있지만, "저자의 소설"은 한 명의 저자가 있는 소설만을 사용할 수 있기 때문에 교량 실체에 대한 서술적 언급의 한 유형으로 선택된다. 이 과정을 통해 19가지 유형의 교량 실체에 대한 서술적 언급을 결정한다.\n' +
      '\n' +
      '이제 "\\(\\mathrm{type}(e_{1})\\)\'s\\(\\mathrm{type}(r_{1})\\)"이 결정되었으므로, 우리는 사실구성의 유형을 결정하기 위해 관계형\\(r_{2}\\(\\mathrm{type}(r_{2})\\(\\mathrm{type}(e_{1})\\)\'s\\(\\mathrm{type}(r_{1})\\)을 결정한다. 앞 단계에서 결정된 "\\(\\mathrm{type}(e_{1})\\)\'의 \\(\\mathrm{type}(r_{1})\\)"은 국가, 조직, 학부 대학, 게임 개발자, 실제 인물(저자, 사장, CEO, 배우자, 가수), 허구 인물(주인공), 영화, 소설, 도시(본점 도시)의 범주에 속한다는 점에 유의한다. "\\(\\mathrm{type}(e_{1})\\)\'의 \\(\\mathrm{type}(r_{1})\\)"도 서술적 언급이 지칭하는 교량 실체 그 자체이다. 따라서 우리는 충분한 수의 \\((e_{2},r_{2},e_{3})\\)을 줄 가능성이 있는 \\(r_{2}\\)을 선택하는데, 여기서 \\(e_{3}\\)은 이들 \\(e_{2}\\)의 범주에 대해 \\(r_{2}\\) 관계를 만족하는 유일한 개체이다. 이전 단계에서와 같이 공통 관계를 \\(r_{2}\\)으로 선택한다. 선정된 \\(r_{2}\\)의 유형을 사용하여 "노래의 가수 어머니"(특정 소설의 소설이 탄생한 도시), "본사 도시 비디오 게임의 개발자"(특정 비디오 게임의 개발자 본사가 위치한 도시), "주인공 영화의 감독"(특정 캐릭터를 주인공으로 하는 영화의 감독) 등 52가지 팩트 구성 유형을 만들었다.\n' +
      '\n' +
      '위키다타 질의는 52개의 팩트 구성 유형 각각에 대해 하나의 수작업 질의로 위키다타 질의 서비스5를 통해 선택된 팩트 구성 유형의 팩트 트리플렛을 수집한다. 타임아웃이 발생하기 전에 API 호출이 가져올 결과가 너무 많을 경우, 참조 링크의 수로 결과를 필터링하거나 질의에 다른 조건을 추가하여 결과의 수를 줄인다. 기업의 CEO와 같이 본질적으로 변경될 수 있는 관계에 대해 2022.6년 1월 1일 시점에 정보를 검색한다.\n' +
      '\n' +
      '각주 5: [https://query.wikidata.org](https://query.wikidata.org)\n' +
      '\n' +
      '각주 6: 우리는 연구에 사용하는 LLaMA-2(Towron et al., 2023) 모델의 훈련 시간을 고려하여 이 타임스탬프를 선택한다.\n' +
      '\n' +
      '### 자연어 템플릿\n' +
      '\n' +
      '자연어 템플릿을 수동으로 만듭니다. 이를 위해 먼저 교량 실체에 대한 서술적 언급을 작성한다. 설명 멘션을 작성하기 위해 \\(r_{1}\\)-특정 _mention-구성 템플릿_\\(m_{r_{1}}(\\cdot)\\)을 수동으로 작성한다. 예를 들어, \\(m_{\\text{singer}}(\\cdot)=\\) "the singer of \'\\(\\cdots\\)"은 \\(\\mu(r_{1}(e_{1})))=\\) "the singer of \'Superstition"을 생성한다.\n' +
      '\n' +
      '다음으로 1/2홉 프롬프트 템플릿을 만듭니다. 본 논문에서는 브리지 엔터티(e_{2}\\)에 대한 언급과 함께 \\(e_{2}\\)의 관계 속성 \\(r_{2}\\)에 대한 프롬프트 질의를 형성하는 \\(r_{2}\\(t_{2}\\)을 수동으로 작성한다. 예를 들어, \\(t_{text{mother}}(\\cdot)=\\)의 "Stevie Wonder의 어머니"와 "Superstition의 가수의 어머니"의 두 홉 프롬프트를 생성한다.\n' +
      '\n' +
      '우리는 두 홉 프롬프트가 자연스러운 방법으로 \\(m_{r_{1}}\\)과 \\(t_{r_{2}}\\)에 대해 하나의 대표 템플릿을 쓴다. 템플릿이 프롬프트를 구성하는 방법에 대한 몇 가지 예는 표 2에 나와 있으며, 이후 수집된 팩트 트리플렛을 수동으로 작성된 템플릿을 사용하여 2홉 프롬프트와 1홉 프롬프트 쌍으로 변환한다. 다시\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:15]\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:16]\n' +
      '\n' +
      '♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬♬� 우리는 섹션 6.2에 설명된 대로 이 상대 빈도를 계산하지만 CnstScore 대신 확률을 사용한다.\n' +
      '\n' +
      '결과도 8은 LLM이 \\(\\mu(r_{1}(e_{1))))을 처리할 때, 대부분의 중간-후기 층에서, LLM이 \\(e_{2}^{(0)}\\)을 출력할 때, LLM의 상대적 빈도를 증가시켜 \\(\\mu(r_{1}(e_{1)))의 appositive를 생성할 수 있다는 것을 보여준다. 그 결과, \\(n\\)번째 토큰에서 EntRec가 \\(n+2\\)번째 토큰으로 생성될 수 있는 토큰의 제어성을 가짐으로써 EntRec가 \\(n+2\\)번째 토큰으로 생성될 수 있음을 간접적으로 증명한다.\n' +
      '\n' +
      '각주 7: 이 분석을 위해, 우리는 LLaMA-2에 대한 토큰화 결과의 변화를 추가하는 서술적 언급이 다음 중 하나로 끝나는 경우를 제외한다.\n' +
      '\n' +
      '그림 8: 레이어에서 개체 회상 점수를 높이는 경우의 상대 빈도는 LLaMA-2 7B에 대해 설명 언급에서 끝나는 \\(\\tau_{\\text{2H}}\\)의 접두사에 이어 쉼표의 다음 토큰으로 \\(e_{2}^{(0)}\\)을 출력하는 모델의 확률을 높인다.\n' +
      '\n' +
      '그림 7: TwoHopFact의 각 팩트 구성 유형에 대한 가장 빈번한 엔티티의 백분율. 팩트 구성 유형에 사용된 약어의 확장된 형태는 표 4에 나열되어 있다.\n' +
      '\n' +
      '## 부록 D 일관성 점수의 정당화: 사고 사슬 사례와의 비교 실험\n' +
      '\n' +
      '실험을 통해 제안된 \\(\\tau_{\\text{2H}},\\tau_{\\text{1H}})의 정의는 LLM이 교량 실체의 속성에 대해 알고 있는 것, 즉 \\(\\tau_{\\text{1H}}}에 대한 답변의 잠재 회상력을 간접증거로 활용하는 합리적인 대리임을 입증한다. 추리할 정보가 입력의 일부로서 주어지면, 예를 들어, 주어진 프롬프트가 _"스티비 원더\'의 싱어가 스티비 원더이다. 스티비 원더의 어미는 룰라라고 명명된다. \'슈퍼시션\'의 싱어의 어미는 "_"이고, LLM은 원-홉 프롬프트 _"스티비 원더의 어미는 "_"에 대한 자신의 출력을 참조하기 위해 멀티-홉 추론을 내부적으로 수행할 필요가 없을 것이며, 다만 입력으로부터 답변을 복사하기만 하면 된다. 따라서, 이러한 경우에 대한 \\(\\textsc{CnstScore}\\)는, 예를 들어, \'Superstition\'의 가수는 Stevie Wonder이고, \'Superstition\'의 가수의 어머니는 "__"이다. 따라서, 이러한 경우인지 확인하기 위해 계산되는 \\(\\textsc{CnstScore}\\)와 여러 CoT(Chain-of-Thought) 스타일 프롬프트 \\(\\tau^{\\prime}\\), 즉 \\(\\textsc{CnstScore}(\\tau^{\\prime},\\tau_{\\text{1H}})를 비교한다.\n' +
      '\n' +
      '결과 그림 9는 y축으로 작성된 프롬프트 \\(\\tau^{\\prime}\\)의 다른 스타일로 계산된 \\(\\textsc{CnstScore}\\)의 분포를 보여준다. 빨간색 사례는 우리가 작업에서 주로 연구하는 2홉 프롬프트의 일관성 점수로, 완전한 멀티홉 추론이 필요하다. 입력에서 추론할 수 있는 정보가 없기 때문에 \\(\\textsc{CnstScore}\\)는 다른 CoT 스타일 프롬프트의 경우보다 현저히 낮다. 파란색 사례는 서술적 언급이 언급하는 것을 입력으로 부여하되 LLM이 교량 실체의 속성에 대해 알고 있는 것을 내부적으로 회상하여 참조할 필요가 있는 경우이다. 그린 케이스들은 브리지 엔티티의 속성, 즉 프롬프트에 대한 답변이 입력에서 명시적으로 주어지는 경우이고, 따라서 LLM은 원-홉 프롬프트에 대한 그의 답변을 참조할 필요가 없다. 그 결과, 원홉 프롬프트에 대한 응답을 강제하는 파란색의 경우가 그렇지 않은 녹색의 경우보다 \\(\\textsc{CnstScore}\\)의 평균이 더 높은 것으로 나타났다. 빨간색과 파란색 사례의 차이는 입력 프롬프트에 서술적 언급의 정체성의 정보가 존재하는 것에서 비롯되었을 것이며, 이는 LLM이 교량 실체에 대해 알고 있는 것을 참조하기 위해 연결을 사용하는 데 도움이 되었을 것이다.\n' +
      '\n' +
      '## 부록 E 기술 세부사항\n' +
      '\n' +
      '실험을 수행하기 위해 난다와 블룸(2022)의 코드베이스를 수정한다. 실험을 위해 1-8 40GB A100 GPU를 사용합니다. 모든 실험은 24시간 이내에 실행됩니다. 우리는 HuggingFace Transformers (Wolf et al., 2020)의 모델 가중치를 사용하고, LLaMA-2 7B 및 13B에 대한 완전 정밀도 및 70B에 대한 반 정밀도를 사용한다. Wikidata를 질의하기 위한 SPARQL 질의는 GPT-4의 도움을 받아 작성된다(OpenAI 등, 2023).\n' +
      '\n' +
      '그림 9: LLaMA-2 7B에 대한 프롬프트의 다른 스타일 \\(\\tau^{\\prime}\\)에 대해 계산된 \\(\\textsc{CnstScore}\\)의 분포.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l l l} \\hline \\hline Description Mutation Type & 0 & 1 & 2 & 3 & 3 \\\\ \\hline \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & the filamentary of \\(\\sim_{\\rm in}\\), & & & \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & & \\\\ \\hline \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} & \\multirow{2}{*}{} \\\\  & & & &\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>