<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '스타일 인터액션 그래프.\n' +
      '\n' +
      '윌리엄 F. 휘트니, 토바스 Pfaff, 토바스 Pfaff, Tobias Pfaff, Lopez-Guevara, 율리아 루바, 윌리엄 F. 휘트니, 율리아 라타노바, 타티아 라티아나 로페즈-구에바, 윌리엄 F. 휘트니,\n' +
      '\n' +
      '김버리 스타헨펠트, 켈세이 R. 메 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘 멘\n' +
      '\n' +
      'Google DeepMind\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '실제 세계 객체 역학을 정확하게 시뮬레이션하는 것은 로봇 공학, 엔지니어링, 그래픽, 디자인 등 다양한 응용 분야에 필수적이다. 접촉 및 마찰과 같은 복잡한 실제 역학을 더 잘 포착하기 위해 그래프 네트워크를 기반으로 학습된 시뮬레이터가 최근 큰 약속(알렌 등 2023년, 2022년)을 보여주었다. 그러나 이러한 학습된 시뮬레이터를 실제 장면에 적용하는 것은 첫째, 학습된 시뮬레이터를 스케일링하여 각각 수백 개씩 복잡한 3D 모양을 포함할 수 있는 현실 세계 장면의 복잡성을 처리하고 둘째, 3D 상태 정보보다는 인식으로부터의 입력을 처리하는 두 가지 주요 과제가 있다. 여기서 그래프 기반의 학습된 시뮬레이터를 실행하는데 필요한 메모리를 실질적으로 감소시키는 방법을 소개한다. 이 메모리 효율적인 시뮬레이션 모델을 기반으로 실제 장면을 그래프 네트워크 시뮬레이터에 의해 처리될 수 있는 구조화된 표현으로 변환할 수 있는 편집 가능한 NeRF 형태의 지각적 인터페이스를 제시한다. 우리의 방법은 정확도를 유지하면서 이전 그래프 기반 시뮬레이터보다 실질적으로 적은 메모리를 사용하고 합성 환경에서 학습된 시뮬레이터가 여러 카메라 각도에서 캡처된 실제 세계 장면에 적용될 수 있음을 보여준다. 이는 추론 시간에 지각 정보만 사용할 수 있는 설정으로 학습된 시뮬레이터의 적용을 확대할 수 있는 길을 열어준다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '심플한 경직된 신체 역학은 로봇 공학에서 그래픽, 공학에 이르기까지 광범위한 응용으로 중요하지만 어려운 작업이다. 무조코(커만, 2015), 무조코(토도프 등), 드크(2019년)와 같은 로봇 공학에서 분석성 단단한 바디 시뮬레이터는 시뮬레이션에서 그럴듯한 예측 궤적을 생산할 수 있지만 시스템 식별은 항상 실제 세계 장면과 이러한 시뮬레이터(Wiepher et al, 2016; 스튜어트와 트링크클, 1996; 펠리 및 트링클, 2017; Fan et al, 2022; 파멜라 et al., Guevara et al, 2017) 사이의 격차를 해소하기에 충분하지 않다. 이는 부분적으로 관련 역학(Bauza and Rodriguez, 2017)에 큰 영향을 미치는 대상들의 미세화 표면 구조를 추정하는 데 어려움이 있기 때문이다. 이 근본적인 문제는 분석 해결자의 결과와 실제 실험의 결과 사이의 잘 문서화된 시뮬레이션에서 실제 간격에 기여한다.\n' +
      '\n' +
      '학습 시뮬레이터는 그래프 신경망으로 경직된 신체 역학을 나타내면서 심 대 현실 간격(올렌 등, 2023년, 2022년)을 채울 가능성을 보여주었다. 이러한 완전 학습된 시뮬레이터는 실제 세계 객체 궤적에 직접 적용될 수 있으며, 경직된 신체 접촉에 대해 어떤 분석 형태도 상정하지 않는다. 결과적으로, 그들은 상대적으로 실제 세계 궤적이 거의 없는 분석 시뮬레이터로 시스템 식별보다 더 정확하다는 것을 배울 수 있다.\n' +
      '\n' +
      '그러나 실제 세계 장면은 학습된 시뮬레이터에 대한 주요 과제를 제시한다. 먼저, 학습된 시뮬레이터는 궤적을 시뮬레이션하기 위해 일반적으로 전체 상태 정보(모든 물체의 위치, 회전 및 정확한 형태)에 대한 액세스를 가정한다. 이 정보는 센서 측정 모음에서 유추되어야 한다. 둘째, 학습된 시뮬레이터는 특히 실제 장면을 종종 구성하는 복잡한 불규칙한 물체의 종류에 대해 기억 집약적일 수 있다. 현재 최상의 성능 그래프 기반 방법은 명시적인 표면 표현, 즉 포인트 구름 또는 삼각형 메세지(Pfaff et al., 2021)에서 작동한다. 이러한 방법의 유도 그래프는 복잡한 물체 기하학에 대한 방대한 양의 GPU 메모리를 소비하는 경향이 있거나, 또는 주사위에 많은 객체가 있는 경우이다. 결과적으로, 결과는 일반적으로 상대적으로 단순한 물체 기하학을 가진 10개 미만의 물체를 포함하는 장면에 대해 표시된다.\n' +
      '\n' +
      '여기서 우리는 실제 세계 장면을 나타내고 시뮬레이션하는 이러한 문제를 해결할 수 있는 학습된 메쉬 기반 도넷 강성 바디 시뮬레이터(올렌 등 2023)에 대해 간단하고 놀랍도록 효과적인 수정(도넷*)을 제안한다.\n' +
      '\n' +
      '* 도넷*는 번역 및 회전 롤아웃 정확도를 유지하면서 훨씬 적은 메모리를 소비한다. 이를 통해 도넷이 메모리 비용 때문에 훈련할 수 없는 윤활 MOVi-C와 같은 복잡한 기하학을 가진 더 많은 물체를 갖는 데이터셋에 대해 도넷*를 학습시킬 수 있다.\n' +
      '* 우리는 NeRF 지각 프론트엔드(바론 등, 2022)를 도넷*에 연결하고, 실제 세계 장면에서 절대 실행되지 않는 복잡한 객체에 대해 그럴듯한 궤적을 시뮬레이션할 수 있음을 보여준다.\n' +
      '* 우리는 지상-진실 메쉬로 시뮬레이션된 경직된 신체 역학에 대해 도Net*를 훈련했음에도 불구하고 모델이 실제 네RF 데이터에서 얻은 시끄러운 메쉬 추정치에 강하다는 것을 보여준다.\n' +
      '\n' +
      '2개의 관련 작업.\n' +
      '\n' +
      '학습된 시뮬레이터는 학습된 기능 근사기를 사용하여 분석 시뮬레이터를 복제하려고 시도한다. 일반적으로, 그것은 지상 진리 상태 정보를 사용하여 훈련되며, 결과적으로 시각적 입력 데이터에 직접 적용될 수 없다. 상태의 표현은 방법에 따라 다르지만 포인트 구름(Li et al., 2019; 산체즈-곤졸레스 et al., 2020; 산체스카 et al., 2018; Lrowenfigner et al., 2023), 중간(Pfaff et al., 2021; Allen et al., 2023), 서명 거리 기능(SDFs)(Le Cleac\'h et al., 2023)까지 다양하다. 이어서 다층 지각론(MLP)(Li et al., 2021), 그래프 신경망(GNN)(Battaglia et al., 2018; 산체즈-Gonzalez et al., 2018), 또는 연속 컨볼루션 커널(Ummenhofer et al., 2019)과 같은 학습된 기능 근사기를 사용하여 상태의 시간적 진화를 모델링할 수 있다. 우리의 접근법은 메쉬 기반 상태 표현 옵션을 따르지만 보다 효율적인 그래프 신경망 역학 모델을 제공하는 것을 목표로 한다.\n' +
      '\n' +
      '지각하는 시뮬레이터는 이러한 학습된 시뮬레이터를 지각 데이터에 가교시키는 것을 목표로 한다. 일부 접근 방식은 "엔드 투 엔드"이며, 종종 객체 마스크(제너 등, 2019, Driess et al, 2022, Shi et al, 2022, Xue et al, 2023; Whitney et al, 2023)와 같은 지상 진리 상태 정보에 대한 액세스를 가정하는 역학 모델과 공동으로 지각 입력 시스템을 훈련시킨다. 다른 사람들은 먼저 지각 인코더 및 디코더를 학습한 다음 이를 고정하여 잠재 공간(Li et al, 2021)에서 역학 모델을 훈련시킨다.\n' +
      '\n' +
      '우리의 접근법과 관련된 대부분은 신경 방사선 분야를 사용하여 시뮬레이션이 가능하도록 2D 멀티뷰 장면에서 3D 장면을 재구성하는 방법이다. 이들 중 일부는 손으로 제작되었지만 감지할 수 있는 역학 모델(Qiao et al., 2023; 2022; Mengyu et al., 2022)을 가정하는 반면, 다른 일부는 상태 정보 구안 등(2022)과 별도로 역학 모델을 학습한다. 우리는 마찬가지로 네RF 지각 프론트 엔드를 사용하여 미리 훈련된 학습된 시뮬레이터를 실제 장면에 단순히 적용하는 것을 목표로 한다. 우리는 이 접근법이 합성 데이터에서만 시뮬레이터를 훈련하더라도 _FF-tunout_ 미세 조정으로 작동할 수 있음을 보여준다.\n' +
      '\n' +
      '## 3 Method\n' +
      '\n' +
      '### FIGNet*\n' +
      '\n' +
      '도넷*는 강성 신체 역학을 모델링하기 위해 설계된 그래프 신경망 접근 방식인 페이스 인터액션 그래픽네트웍스(도넷)(올렌 et al, 2023)의 방법을 면밀히 따른다. 도넷에서 각 객체는 메쉬 정점 \\(\\{\\\\mathcal{F}_{M}\\}\\)와 함께 삼각 메쉬 페이스 \\(\\{\\\\mathcal{F}_{M}\\}\\)로 이루어진 삼각 메쉬 \\(M\\)로 표시된다. 장면 그래프 \\(\\mathcal{G}\\)는 이어서 \\(O\\) 오브젝트로 구성되며, 각각은 자신의 삼각형 메세지 \\(M_{o}\\)로 구성된다. 주어진 시간 \\(t\\)에서 \\(M_{o}^{t}\\)는 객체의 변환 매트릭스, \\(M_{o}^{t}=R_{o}^{t}^{t}^{t}\\)를 사용하여 나타낼 수 있다. 시뮬레이션 궤적은 이러한 중간체에서 구성된 장면 그래프 \\(\\mathcal{G}=(G^{t_{0}},G^{t_{1}},G^{t_{2}},\\dots)\\의 서열로 표시된다. 그런 다음 뉴럴 네트워크 가중치(\\Theta\\)에 의해 매개변수화된 시뮬레이터 \\(S\\)는 이전 두 장면 그래프 \\(\\{G^{t},G^{t},G^{t-1}\\})를 기반으로 물리적 시스템 \\(\\bar{G}^{t+1}\\)의 다음 상태를 예측하도록 훈련된 시뮬레이터 \\(\\{G^{t+1}<\\) 즉,\\(\\{G^{t+1}. 우리는 각 객체 \\(\\{\\mathcal{V}_{M}\\}\\)에 대한 정점들의 예측된 위치에 평균 제곱 오류 손실로 훈련한다. 추론 중에 \\(S_{\\Theta}\\)를 재귀적으로 적용하여 모든 길이 \\(T\\)의 롤아웃을 산출할 수 있다.\n' +
      '\n' +
      '도넷은 두 가지 유형의 노드(\\{\\mathcal{V}_{M}\\}\\)와 객체 노드 \\(\\{\\mathcal{V}_{O}\\}\\)와 세 가지 유형의 양방향 가장자리로 구성된다.\n' +
      '\n' +
      'rmath{t}}(\\math{i}})의 위치,\\math{t}}(\\math{t}}.{i:{i)가 외부에서 이동하는지 여부(\\math{t}}.{i)를 나타내는 특징이며(\\math{t}}.{i}.{i,\\b{t}.{i:{i,\\b{t}.{t}.{i:{t}.{t}.{i,\\_{i}.{t}.{t}.{i:{t}.{t}.{t}.{i}.{t}.{t}.{t}.{t}.{t}.{i) 각각은.{t}.{t}.{t}.{t}.{t}.{t}.{i) 또는\\.{t}.{t}.{t}.{t}.{t}.{i) 즉,\\_\\.{t}.{i)의 입력이고,\\_\\.{t}.{i:{i) 객체 노드 \\(\\{\\mathcal{V}_{O}\\}\\)는 동일한 특징 설명을 사용하고 위치 \\(\\mathbf{x}_{i}^{t}\\)는 객체의 질량 중심이다.\n' +
      '\n' +
      '세 가지 유형의 양방향 에지에는 노드-노드, 객체-노드 및 페이스-페이스 에지들이 포함된다. Node-node 에지 \\(v_{m}\\to v_{m}\\)는 단일 객체 상의 표면 메쉬 노드를 서로 연결한다. 객체-코드 에지 \\(v_{o}\\to v_{m}\\)는 객체 노드 \\(v_{o}\\)를 해당 객체의 각 메쉬 정점 \\(v_{m}\\)에 연결한다. 하나의 송신자 객체 \\(f_{s}\\)에서 다른 수신기 객체 \\(f_{r}\\)에 표면 에지들이 마주한다. 그림 1을 참조하세요.\n' +
      '\n' +
      '개념적으로, 노드-노드 에지들은 객체의 표면을 따라 로컬적으로 메시지의 전파를 가능하게 한다. 다만, 경직된 신체 충돌의 경우 메쉬 복잡도에 관계없이 대상체의 일측에서 타측으로 순간적으로 충돌 정보를 전파할 필요가 있다. 객체-코드 에지들은 객체 표면에 각 메쉬 노드(v_{m}\\)에 양방향 가장자리가 있는 각 객체의 중앙에 단일 가상 객체 노드(v_{o}\\)를 갖는 것을 가능하게 한다. 마지막으로, 경직된 객체들 사이의 충돌 역학을 모델링하기 위해, 얼굴-페이스 에지들은 얼굴 상호작용들(_between_ 객체들)에 대한 정보를 전달한다. 도넷은 페이스-페이스 에지를 엔코드-프로세스-디코드 그래프 네트워크 아키텍처에 통합하는 방법에 대한 특별한 하이퍼그래프 아키텍처를 제안한다. 우리는 (알렌 등, 2023)에 대한 도넷 접근법의 추가 세부 사항을 유예한다.\n' +
      '\n' +
      '이 접근법은 경직된 신체 모양에 대해 현저하게 잘 작동하지만, 상당한 수의 노드-노드(표면 메쉬) 에지를 추가하기 때문에 각 객체 메쉬의 복잡성이 증가함에 따라 눈에 띄게 비쌉니다. 실증적으로, 노드-노드 에지들은 종종 도넷의 전체 에지들의 50\\(\\%\\) 이상을 차지한다. 도넷*는 노드-노드(표면 메쉬) 에지를 제거하는 도넷에 간단한 수정을 하여, 다른 모든 것을 동일하게 유지한다. 놀랍게도, 이것은 도넷*의 정확도에 영향을 미치지 않지만, 본 논문에서 살펴본 강성 신체 설정에 대한 메모리 및 런타임 성능을 극적으로 향상시킨다. 이것은 _콜리밀 에지_가 접촉에 관여하는 두 물체의 국소 기하학에 대한 이유 때문에 단단한 신체 역학을 위해 작동하며, 이 정보는 객체-코드 에지를 사용하여 전체 형태로 직접 방송될 수 있다.\n' +
      '\n' +
      '이 간단한 도넷으로의 변화는 훈련 중 더 큰 장면들이 가속기 메모리에 적합하기 때문에 이전에 가능한 것보다 훨씬 더 복잡한 장면을 훈련하는 능력을 풀어준다. 따라서 우리는 실제 장면에서 추출한 메쉬와 이전에 가능한 것보다 더 복잡한 물체 기하학을 갖는 시뮬레이션에 대해 도넷*를 실행할 수 있다.\n' +
      '\n' +
      '도넷*\n' +
      '\n' +
      '이 절에서는 도넷*을 현실 세계에 연결하는 데 사용되는 절차를 설명한다. 우리는 시뮬레이션을 위해 도넷*에서 요구하는 메서를 추출하고 (2)는 도 1에 필요한 메서를 그림 1에 대한 지각적 프론트로서 신경 폭격 필드(NeRF)(Mildenhall et al, 2021; Barron et al., 2022)를 레버리지하고 도 1(그림 2)에 의해 예측된 변환으로 장면을 재프레젠테이션한다. 그러나 이 접근법은 (Qiao et al., 2023)에 제시된 방법과 유사성을 공유하지만, 여기에서 학습된 시뮬레이터를 사용하여 구현을 보여준다.\n' +
      '\n' +
      '그림 1: ** 아키텍처 변화:** 도넷*은 도넷에 관한 것이다.\n' +
      '\n' +
      'NRF에서 도넷*######### 3.2.1을 NRF로 3.2.1을 도넷*.\n' +
      '\n' +
      '신경 폭주 분야를 배우는데, 먼저\\(W\\) 희미한 입력 뷰 \\(\\{I\\}_{1}^{W}\\)와 관련 카메라 인트라신틱스 \\(\\mathbf{K}\\) 및 압출학으로부터 NeRF를 배우게 된다. 이 표현은 3D 위치 \\(\\mathbf{x}=(x,y,z)\\)와 시청 방향 \\(\\mathbf{d}\\)을 방사색 \\(\\mathbf{c}\\)과 밀도 \\(\\sigma\\)으로 매핑하는 뷰 의존적 외관 함수 \\(F_{\\Phi}\\)를 모델링한다.\n' +
      '\n' +
      '\\[F_{\\Phi}:(\\mathbf{x},\\mathbf{d})\\rightarrow(\\mathbf{c},\\sigma) \\tag{1}\\]\n' +
      '\n' +
      'NRF로 표시되는 장면의 모든 물체의 기하학은 암묵적으로 \\(F_{\\Phi}\\)에 의해 캡처된다. 우리는 기하학에 대한 밀도 \\(\\sigma\\)만을 신경 쓰며, 컬러 \\(\\mathbf{c}\\)와 시청 방향 \\(\\mathbf{d}\\)를 무시할 수 있다. 우리는 표기법을 약간 남용하고 \\(F_{\\Phi}^{\\sigma}(\\mathbf{x})\\ 우두간 유사체\\\\\\\\)를 정의하여 밀도만을 평가하는 NeRF의 하위 부분을 나타낸다.\n' +
      '\n' +
      '미쉬 추출: 암묵 함수 \\(F_{\\Phi}^{\\sigma}\\)에서 개별 객체의 메쉬를 추출하려면 먼저 물체의 체적 경계를 정의해야 한다.\n' +
      '\n' +
      '우리는 \\(N\\) 이진 분할 마스크를 생성하여 시작하는데, 각각은 \\(N\\)의 뚜렷한 관점 중 하나로부터 물체의 형상을 포착한다. 각 마스크는 해당 RGB 이미지와 객체의 중심에 위치한 포인트 프롬프트로 XMEM(청, 슈팅, 2022)을 호출하여 생성된다. 그런 다음XMEM은 신속한 위치에서 각 마스크의 객체에 속하는 모든 활성 픽셀을 식별하고 라벨링하여 다양한 관점에서 물체의 모양을 포착하는 N 분할 마스크 \\(\\{\\mathbf{m}_{\\mathbf{n}}_{1}^{N}\\) 세트를 생성한다. 실증적으로, 우리는 구와 같은 단순한 물체에 대해 서로 다른 각도에서 두 가지 견해만큼 물체가 정확하게 분할될 만큼 충분하다는 것을 발견했다. 그러나 견고성을 높이기 위해 추가 뷰를 사용하거나 특히 더 복잡한 형태에 대해 더 미세한 세부 정보를 캡처할 수 있습니다.\n' +
      '\n' +
      '우리는 NeRF로부터 2D 마스크의 픽셀을 3D 포인트로 분류하기 위해 (Cen et al., 2023)에 설명된 것과 동일한 절차를 사용하여 각 마스크를 생성한 추정된 깊이 \\(z(\\mathbf{m_{n}})를 레버리지하여 2D 마스크의 픽셀을 3D 포인트로 통합한다.\n' +
      '\n' +
      '}}=z(\\mathbf{m_{n})\n' +
      '\n' +
      '그런 다음 부피 경계 \\(\\mathbf{V_{o}\\in\\mathbb{R}^{2)로 얻을 수 있다.\n' +
      '\n' +
      '\\[\\mathbf{V_{o}}=\\{\\min(\\mathbf{x_{m_{n}}}),\\max(\\mathbf{x_{m_{n}}})\\}_{1}^{N} \\tag{3}\\]\n' +
      '\n' +
      '물체 \\(M_{o}\\)의 메쉬를 부피 \\(\\mathbf{V_{o}}\\) 내에서 추출하기 위해 우리는 3월 컵스 알고리즘(morensen 및 Cline, 1998)을 사용한다. 이 알고리즘은\\(\\mathbf{x}_{j}\\in\\mathbf{V_{o}}}) 경계 내부의 J 지점 밀도 필드의 샘플을 \\(\\sigma_{\\mathbf{o}}=\\{F_{\\mathbf{f{o}}=\\{F_{\\Phi}^{\\sigma}(\\mathbf{f{f{f{o}) 및 임계값 \\(\\{\\bf{mathbf{mathbf{mathbf{mathbf{mathbf{f{f{f{f{f{f{f{f{f{f{f{f{f{f{f{f{f{f{f{i}^Phi}^{\\}^{\\}^{\\}^{\\}^{\\sigma}^{\\sigma}^{\\sigma}^{\\sigma}^{\\sigma}^{\\sigma}^{\\sigma}^{\\sigma}^{\\sigma} 생성된 메쉬에서 잠재적으로 많은 수의 정점 및 얼굴을 관리하기 위해, 우리는 잠재적으로 많은 수의 정점 및 얼굴을 관리하기 위해 수행합니다.\n' +
      '\n' +
      '그림 2: ** 기만 피프라인** 우리는 도넷*를 NeRF를 통해 실제 장면과 통합한 양방향 결합 접근법을 보여준다. 초기에, 정태적 NeRF 장면은 실세계 장면을 촬영하는 이미지 컬렉션을 사용하여 학습되어 도넷*에 필요한 메쉬들을 추출할 수 있게 된다. 롤아웃 궤적을 얻을 때, 우리는 원래 NeRF를 편집하기 위해 사용되는 단단한 신체 변환 세트를 도출한다. 자세한 내용은 하위 섹션 3.2를 참조하십시오.\n' +
      '\n' +
      '조건부 탈환 단계(결정) 우리는 가르란드와 하이버트(가랜드와 헤크베르트, 1997)의 쿼드릭 어러어 Metric Decimation 방식을 사용한다. 이 기술은 사용자 지정 대상 얼굴 수 \\(n_{f}\\)를 통해 최종 메쉬 복잡도를 제어할 수 있도록 하면서 메쉬의 주요 특징을 보존한다.\n' +
      '\n' +
      '\\[M_{o}]=\\texttt{m\\_cubes}(토끼_{\\mathbf{o}},\\sigma_{ thr),\\\\{4}\n' +
      '\n' +
      '우리가 시뮬레이션하고 싶은 움직임을 특정하기 위해 Graph를 구축하기 위해, 우리는 메쉬 \\(M_{o}\\)를 그래프의 활성 객체로 정의하며, 다른 모든 오브젝트가 정적으로 간주되었다. 그런 다음 현장 부피의 오프셋 버전((\\mathbf{V}_{\\mathbf{o}}-\\Delta\\mathbf{x}_{\\mathbf{x}_{\\mathbf{o}}}})에서 위에서 설명한 동일한 메쉬 추출 절차를 반복하여 \\(a_{i}\\)로 설정된 정적 환경을 나타내는 수동 메쉬 \\(M_{passic}\\)를 얻었다. 두 메쉬 모두 도넷 및 도넷*에 대한 초기 그래프 \\(G^{t}\\)를 구성하는 데 사용된다. 장면에서 추출한 메쉬에 대한 질량, 마찰, 탄력성 등과 같은 정적 특성을 추론하지 않는다. 대신 우리는 표 3에 제공된 기본 매개변수를 사용하여 이러한 특성을 객체 역학에서 추론하기 위해 미래 작업이 필요할 것이다.\n' +
      '\n' +
      '우리는 동일한 메쉬를 사용하여 이력 \\(G^{t-1}\\)을 생성하지만 세로로 떨어뜨리는 물체를 시뮬레이션하기 위해 \\(\\Delta z\\) 양으로 두 번 아래로 이동했다.\n' +
      '\n' +
      '도넷*에서 NeRF로 3.2.2에서 NeRF################# 3.2.\n' +
      '\n' +
      '우리는 \\(T\\) 시간 단계에 걸쳐 도넷*를 반복적으로 적용하여 롤아웃 궤적을 얻는다. 초기 그래프와 그 역사에서 시작하여 \\((G^{t+1},G^{t+2},\\cdots,G^{t+T})를 얻는다. 이것은 유사하게 \\(M_{o}^{t+1}, R_{o}^{t+2},^{t+2},\\cdots,R_{o}^{t+T})\\(M_{o}\\)에 적용되는 강성 변환의 서열로 볼 수 있다.\n' +
      '\n' +
      '각 객체(\\mathbf{V}_{\\mathbf{o}}\\)의 경계 부피와 시간 \\(t\\)에서 강성 변환(R_{t}\\)을 감안할 때, 우리는 정태적 NeRF 함수 \\(F_{\\Phi}\\)를 재사용하여 광선 굽힘(Jambon et al., 2023)을 통해 \\(F_{\\Phi}\\)에 의해 기술된 원래의 정적 NeRF를 편집함으로써 롤아웃을 렌더링할 수 있다. 우리는 광선 \\(b\\)의 벤딩을 도넷*에 의해 반환되는 강성 변환으로 제한한다.\n' +
      '\n' +
      '\\[\\hat{F_{\\Phi}}:(\\,b(\\mathbf{x},R_{o}^{t}\\,),\\mathbf{d})\\rightarrow(\\mathbf{c},\\sigma), \\tag{5}\\]\n' +
      '\n' +
      '\\(b,\\mathbf{x},R_{o}^{t}\\)가 있는 경우(b,\\mathbf{x},R_{o}^{t}\\)도 될 수 있다.\n' +
      '\n' +
      '}}\\mathbf{V}}\\\\bf{x}\\mathbf{x}}\\mathbf{x}}\\mathbf{x}}\\mathbf{x}}\\mathbf{x}}}\\mathbf{x}}\\mathbf{x}} <\\mathbf{x}} <\\mathbf{x}}}\\mathbf{x}}}\\mathbf{x}}\\mathbf{x}}}\\mathbf{x}}}\\mathbf{x}}}\\mathbf{mathbf{mathbf{x}}}}}} <\\mathbf{x}}}}}}}}} <\\mathbf{x}}}}}}}}}}}}}}}}}<\\mathbf{mathbf{x}}}}}}}}}}}}}}}}}}}}}}}}}}\n' +
      '\n' +
      'or\n' +
      '\n' +
      '(R_{o}}},R_{o}^{t})=\\begin{case}}.\n' +
      '\n' +
      '활성 객체가 롤아웃 동안 이동하거나 복사 발포할 수 있는 옵션을 가지고 있음을 의미한다.\n' +
      '\n' +
      '그런 다음 모든 시간 단계에서 선택된 시점 \\(\\hat{\\mathbf{d}}\\)에서 롤아웃 이미지의 최종 서열을 생성한다. 이것은 객체 움직임을 통합하는 형질전환된 라디턴스 필드 \\(\\hat{F_{\\Phi}}\\)와 함께 NeRF의 고전적인 볼륨 렌더링 파이프라인을 적용하는 것을 포함한다. 각 단계에서 적용된 경직된 형질전환을 기반으로 방사계를 조절하여 롤아웃 서열 \\(\\{\\hat{F_{\\Phi}})(b(\\mathbf{x},R_{t}\\),\\hat{\\mathbf{d}}_{t=1}^{k}\\) 전반에 걸쳐 객체의 동적 외관을 효과적으로 캡처한다.\n' +
      '\n' +
      '## 4 Results\n' +
      '\n' +
      '시뮬레이션된 데이터와 실제 데이터 모두에 대해 도Net*를 테스트합니다. 시뮬레이션에서, 우리는 도넷*가 표준 강성 신체 역학 벤치마크(Greff et al, 2022)에 대한 정확도를 유지하면서 메모리 소비 및 런타임에서 도넷을 능가한다는 것을 보여준다. 실제 데이터에 대해, 우리는 도넷*가 완벽한 상태 정보에 대한 시뮬레이션 훈련에도 불구하고 그럴듯한 궤적을 만들기 위해 여러 카메라로부터 수집된 실제 장면을 볼 때 실행될 수 있음을 보여준다.\n' +
      '\n' +
      '### Simulation\n' +
      '\n' +
      '시뮬레이션 결과를 위해 MOVi-B 및 MOVi-C 윤활 데이터 세트(Greff et al, 2022)를 사용한다. 두 세트 모두 궤적을 예측하기 위해 PyBullet(?) 시뮬레이터를 사용하여 여러 개의 단단한 물체를 바닥에 함께 토싱한다. MOVi-B는 11개의 서로 다른 모양에서 선택된 3-10개의 물체를 포함하는 장면으로 구성된다. 형상에는 테이팟, 기어 및 토러스 매듭이 있으며, 물체당 최대 100개의 꼭짓점이 1,000개 이상 있다. MOVi-C는 구글 스칸디드 오브제 데이터셋(다운들 등 2022)에서 촬영한 1030개의 상이한 형상들로부터 선택된 3-10개의 오브젝트들을 포함하는 장면들로 구성된다. MOVi-C 형상은 MOVi-B 모양보다 복잡하며, 최대 천 또는 수만 개의 꼭짓점을 갖는다.\n' +
      '\n' +
      '우리는 표 2의 4가지 메트릭을 보고하는데, 피크 메모리 소비, 시뮬레이션 단계당 런타임, 번역 오류 및 회전 오류이다. 50개의 롤아웃 단계 후 지반 진리 상태에 대해 변환 및 회전 뿌리 제곱 오차(RMSE)를 계산한다.\n' +
      '\n' +
      'MOVi-B의 경우, 도넷*는 번역 및 회전 오류에서 도넷의 성능과 일치하고, 번역에서 약간 더 잘 수행하며, 회전에 약간 더 악화된다. 다만, 도넷*는 도넷보다 훨씬 적은 메모리를 사용하는 동시에 20\\(\\%\\)의 더 빠른 런타임도 가진다. 이러한 메모리 소비 및 런타임의 차이는 도넷*를 보다 복잡한 MOVi-C 데이터셋(그림 3의 샘플 궤적)에서 훈련시킬 수 있도록 하며, 이는 16 A100 GPU로도 도넷을 학습시키려고 할 때 OOM 오류를 유발한다. MOVi-C에서는 메모리 소비가 더 높지만 런타임은 거의 빠르게 남아 있다. 유사하게, MOVi-C는 MOVi-B보다 복잡하기 때문에, 도넷*에 대한 번역 및 회전 오차는 더 높지만 크게 그렇지 않다.\n' +
      '\n' +
      '전반적으로, 이는 도넷*가 도넷에 대한 실행 가능한 대안임을 시사한다. 메모리 소비 및 런타임을 크게 감소시키면서 정확도를 유지하여 도넷 메모리에 적합할 수 있는 것보다 더 복잡한 데이터셋에서 도넷*를 트레이닝할 수 있습니다.\n' +
      '\n' +
      '### Real world\n' +
      '\n' +
      '우리는 도넷*와 실제 장면 입력을 연결하는 결과를 제시한다. 이것이 단지 실제 근거 진실 역학과 비교되지 않는 개념 증명, 즉 미래에 대한 증명이라는 것을 남기는 것에 주목한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c|c} Dataset & Model & Memory (MiB) & Runtime (ms) & Trans. Err. (m) & Rot. Err. (deg) & Edge Count (\\(\\#\\)) \\\\ \\hline \\multirow{2}{*}{MOVi-B} & FIGNet & 63.38 \\(\\pm\\) 3.32 & 26.38 \\(\\pm\\) 0.73 & 0.14 \\(\\pm\\) 0.01 & 14.99 \\(\\pm\\) 0.67 & 24514 \\(\\pm\\) 906 \\\\  & FIGNet* & **50.08 \\(\\pm\\) 3.37** & **19.41 \\(\\pm\\) 0.24** & 0.13 \\(\\pm\\) 0.01 & 15.96 \\(\\pm\\) 0.87 & **8630 \\(\\pm\\) 714** \\\\ \\hline \\multirow{2}{*}{MOVi-C} & FIGNet & OOM & – & – & – & – \\\\  & FIGNet* & **71.79 \\(\\pm\\) 6.39** & **20.42 \\(\\pm\\) 0.64** & **0.18 \\(\\pm\\) 0.01** & **19.82 \\(\\pm\\) 0.64** & **11401 \\(\\pm\\) 975** \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 그림 1: 윤활 MOVi-B 및 MOVi-Ci-Ci-B 및 MOVi-Ci-C 및 도넷에 대한 비교 측정값 및 그림 1:\n' +
      '\n' +
      '도넷에 대한 메모리로 나타낼 수 없는 복잡한 MOVi-C 시뮬레이션을 위한 시뮬레이션에 대한 그림 3: ** 정성적 결과***도Net* 롤아웃.\n' +
      '\n' +
      '일해. 실제 데이터에 대한 도넷과 도넷* 간의 비교를 위해 도넷 모델을 윤활 MOVi-B에 대한 시뮬레이션으로 훈련한 반면, 도Net* 모델은 윤활 MOVi-C에 대한 시뮬레이션으로 훈련했다.\n' +
      '\n' +
      '우리의 실제 결과를 위해 과일 및 바구니(자세한 내용은 부록 C)와 같은 공통 요소로 채워진 맞춤형 주방 장면과 (바론 등 알, 2022)에 소개된 정원 아웃도어 및 주방 카운터 실내 장면과 (Kerr et al, 2023)에 소개된 피규어 장면의 두 장면을 사용했다. 이러한 장면들은 서로 다른 카메라로 캡처된 360도 이미지 세트들로 구성된다. 우리는 NeRF 프론트 말단에 대해 MipNerf360(바르론 et al., 2022) 구현을 사용했다.\n' +
      '\n' +
      '우리는 하위 섹션 3.2에 설명된 전체 파이프라인을 사용하여 두 실제 세계 장면에서 정성적 그림* 롤아웃을 보여주는데, 모든 장면에서는 경계 부피 \\(\\mathbf{V}_{\\text{o}}\\) 및 후속 메쉬 \\(M_{o}\\)를 계산하기 위해 활성 물체(레드 상자의 높이라이트)의 2개 뷰를 수동으로 선택했다. 선택된 메쉬의 하향 수직 변위를 기반으로 역사를 생성함으로써, 우리는 하락과 유사한 움직임을 효과적으로 시뮬레이션하고 있다. 그림 4는 다른 물체에 떨어지는 다양한 물체의 바운싱 행동을 보여준다. 주방 장면에서 바운스(위틀) 끝에 있는 오렌지의 날카로운 회전을 주방 장면에서 어떻게 렌더링하는지, 그리고 바운스(위틀) 끝에 주황기의 날카로운 회전에 주목한다.\n' +
      '\n' +
      '그림 4: ** 정태적 실세계 장면의 현실 세계 장면에 대한 정성적 결과**_Left_: 인티얼 NeRF 렌더링이다. 원하는 활성 객체는 빨간색으로 요약되며, 빨간색 화살표는 의도된 시작 위치를 나타낸다. 우자:_ 도넷* 롤아웃은 초기 위치에서 떨어진 후 \\(k=30\\) 시간 단계(다른 관점에서 추세)에 대한 객체의 움직임을 시뮬레이션한다. 완전한 궤적은 노란색으로 추적됩니다. 여기서 \\(b_{이중}\\)를 활성 오브젝트를 의미하는 광선 굽힘 기능을 롤아웃 시작 시 시작 위치로 복제(제3.2절에서 설명한 메쉬 추출 절차에 대한 세부 정보를 위해 비디오 및 부록 B 웹사이트 참조)하는 것으로 사용했다.\n' +
      '\n' +
      '형질전환된 \\(\\hat{F_{\\Phi}}\\)는 주황색이 거꾸로 뒤집어질 때 작동한다. 우리는 긴 다리를 가진 개 피규어의 두 가지 견해를 선택하고 오리 위에 떨어지는 움직임을 시뮬레이션하는 피규어 장면에 대해 유사한 결과를 관찰할 수 있다. 우리의 인식 파이프라인은 정적 NeRF 장면을 도Net* 변환 1로 재사용함으로써 이러한 실제 장면 내에서 캡처된 객체의 낙하 움직임을 현실적으로 시뮬레이션하고 재프레젠테이션할 수 있다.\n' +
      '\n' +
      '부츠 1: 세이[https://site.google.com/view/fignetstar/](https://sat.google.com/view/fignetstar/) 비디오용 (https://sid.google.com/view/fignetstar/)\n' +
      '\n' +
      '디딤레이션의 효과 행진 큐브 알고리즘은 종종 높은 노드 카운트를 특징으로 하는 오버샘플링된 메서를 생성한다. 메쉬 탈색에 대한 제어 가능한 파라미터의 구현(\\(n_{f}\\))은 이 문제를 해결하기 위한 효과적인 전략이지만, 특히 복잡한 기하학을 포함하는 경우 탈색 정도가 시뮬레이션 품질에 부정적인 영향을 미칠 수 있다는 점에 유의하는 것이 중요하다. 도넷*를 사용하는 장점은 감소된 메모리 요구 사항에 있으며, 이는 도넷에 비해 덜 엄격한 탈색 과정을 허용한다. 이를 입증하기 위해 우리는 이를 시뮬레이션했다.\n' +
      '\n' +
      '그림 5: 도넷 및 도넷*는 서로 다른 수준의 탈색에 대한 비교: 고품질 중간체는 도넷 상의 메모리 외 문제로 이어지는 반면, 더 낮은 해상도는 시사성 궤적(예: 바구니를 관통하는 오렌지)을 초래한다. 특히, 도넷*의 성능은 메쉬 품질로 은밀하게 분해되어 견고성과 기억 효율이 향상되었음을 나타낸다. 회색 메시는 수동적인 객체를 묘사하고, 착색된 메쉬는 활성 오브젝트에 대응한다.\n' +
      '\n' +
      '두 가지 뚜렷한 수준의 탈색(그림 5)을 갖는scene이다. 이 실험은 도넷의 메모리 용량을 초과하는 인스턴스를 강조하여 그러한 시나리오에서 도넷*의 이점을 보여준다.\n' +
      '\n' +
      'NRF와 같은 파이프라인에서 추출한 실제 메세지는 주로 품질을 렌더링하는데 최적화되어 종종 소음 및 불완전한 것을 나타낸다(그림 6). 도넷* 및 도넷에 사용되는 청정 학습 데이터와 달리, 이들 메세지는 이상과는 거리가 멀다. 그럼에도 불구하고 두 모델 모두 이러한 도전적인 실제 데이터로도 롤아웃을 성공적으로 처리할 수 있다.\n' +
      '\n' +
      '## 5 Discussion\n' +
      '\n' +
      '우리는 표면 메쉬 가장자리의 제거인 도넷에 놀라울 정도로 간단한 수정을 통해 전례 없는 복잡한 장면에 대한 교육을 지원하기 위해 메모리 소비가 충분히 낮은 모델을 만들 수 있음을 보여주었다. 이것은 실제 장면을 객체 기반 메쉬 표현으로 변환하기 위해 신경 방사선 촬영 필드(NeRF)와 객체 선택(XMem)의 조합을 사용하여 도넷*를 실제 세계 장면과 인터페이스하는 능력을 잠금 해제했다. 체적 NeRF 편집과 결합하여 실제 장면을 위한 대체 물리적 선물 비디오를 시뮬레이션할 수 있도록 했다.\n' +
      '\n' +
      '우리는 이러한 비디오 편집 및 생성에 대한 명시적으로 3D 접근법이 로봇 공학 및 그래픽 애플리케이션에 상당한 약속을 가지고 있다고 믿는다. 모형이 시뮬레이션 데이터로부터 미리 학습되는 동시에 실제 장면으로 일반화할 수 있습니다. 도넷*는 특히 거의 완벽한 상태 정보(물체의 위치, 회전 및 형태)로 시뮬레이션으로 훈련되었다는 점을 고려하여 NeRF에서 추출한 시끄러운 메쉬에 놀랍도록 잘 일반화한다. 우리는 이 접근법이 사용자가 그러한 장면을 편집하고 가능한 미래의 결과를 시뮬레이션하는 데 관심이 있을 수 있는 실제 장면의 "가상화"를 포함한 향후 애플리케이션을 추가로 지원할 수 있다고 상상한다.\n' +
      '\n' +
      '도넷*와 함께 미래 업무에 대한 흥미진진한 방향들이 많다. 특히, 미리 학습된 도넷* 모델을 실제 영상으로 미세 조정하면서 본 논문의 범위를 벗어난 반면, 우리는 이것이 자연스러운 다음 단계라고 생각한다. 도넷*는 전적으로 신경망으로 구성되어 있기 때문에, 실제 세계 역학으로부터 도넷*의 가중치로 직접 미세 조정되는 것은 로봇 공학에 대한 시스템 식별의 실행 가능한 대안이 될 수 있다. 데이터 효율적인 방식으로 미세 조정 수행 방법에 대한 세부 사항을 결정하기 위해서는 향후 작업이 필요할 것이다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* 앨런 등은 (2022) 켈세이 로알렌, 타티아나 로페즈 게에바라, 율리아 루바노바, 김스타헨펠트, 알바로 산체즈-고네졸레스, 피터 바타골리아, 토바스 Pfaff. 그래프 네트워크 시뮬레이터는 불연속적이고 단단한 접촉 역학을 학습할 수 있다. 로보트 러닝_, 2022년 제6차 연례 콘퍼런스에서 URL[https://openopenreview.net/forum?id=rD1zq-I84i_](https://openreview.net/forum?id=rD1zq-I84i_)\n' +
      '* 알리엔 등은 (2023) 켈세이 R. 알렌, 율리아 루바노바, 타티아나 로페즈-게바라, 윌리엄 휘트니, 알바로 산체즈-고네졸레스, 피터 바타골리아, 토바스 Pfaff. 얼굴 상호작용 그래프 네트워크로 경직된 역학을 배우세요. "국제 학습 발표회"에서 2023년.\n' +
      '* Ba et al. (2016) 짐미 레이 Ba, 제이미 라이언 키오스, 거프리 에힌턴. 선수 정규화 _Layer 정규화 _Layer 정규화 __Layer 정규화. _Layer 정규화. arXiv 프리프린트 arXiv:1607.06450_ 2016.\n' +
      '* 바론 등 (2022) 조나단 T. 바론, 벤 마덴힐, 도르 베르빈, 프라틀 피니바산, 피터 헤드먼. Mip-nerf 360: __결합된 반편향된 신경 방사선 필드. CVPR_, 2022.\n' +
      'Battaglia, Jessica B햄rick, 빅토르 바프스트, 알바로 산체즈-고네졸레스, 비니우스 잠발디, 마테우스 말리노프스키, 안드레아 타코티, 다비드 라포, 아담 산토로, 라이언 Faulkner, 온도 유도 편향, 딥러닝 및 그래프 네트워크. arXiv 프리프린트 arXiv:1806.01261_ 2018.\n' +
      '*바우자, 로드리게스(2017) 마리아 바우자, 알베르토 로드리게스. 평면 밀기용 확률적 데이터 구동 모델입니다. _IEEE 로보틱스 및 오토메이션(ICRA)_, pp. 3008-3015, 2017.\n' +
      '* 케이엔 등은 자조홍센, 자노웨이 주, 지민 포, 첸 양, 웨이 선, 링시 시, 동정 장, 샤오펑 장, 키 톈 등이 있다. 네프가 있는 3d의 모든 것을 준비하세요. 1974년 _NeurIPS_에서.\n' +
      '* 첸 등은 (2018)* 청과 슈팅 (2022) 호게이 청과 알렉산더 지 슈팅이다. XMem: Atkinson-shiftin 메모리 모델과의 장기 비디오 객체 분할이다. 2022년 _ECCV_에서.\n' +
      '*쿠만스(2015) 에르윈 쿠만스. 불렛 물리학 시뮬레이션. E_ACM SIGGRAPH 2015 Courses_ 2015. pp. 7.\n' +
      '* 다운스 등은 앤서니 프란치스코(2022) 로라 다운스, 나이트 고에니그, 브랜든 킨만, 라이언 히크만, 크리스타 레이만, 토마스 비 맥후, 빈센트 반우크 등이 있다. 구글 스캔 오브젝트, __구글은 3d 스캔된 가정용 아이템의 고품질 데이터세트: 3d 스캔된 가정용 아이템의 고품질 데이터셋입니다. arXiv 프리프린트 arXiv:2204.11918_, 2022.\n' +
      '* 듀스 등은 (2022) 다니 데스, 지아오 황, 윤주 리, 러즈 테드라케, 마크 투세세스를 들 수 있다. 구성 신경 방사계를 사용하여 다중 객체 역학을 학습한다. __ 조성물 신경 방사계를 사용하여 다중 객체 역학을 학습한다. arXiv 프리프린트 arXiv:2202.11855_ 2022년입니다.\n' +
      '* 파젤리 등은 (2017) 니마 파젤리, 엘리엇 도를론, 에반 덩크라이트, 알베르토 로드리게스 등이다. 평면적 충격에 대한 공통 접촉 모델에 대한 실증분석이다. "_2017 IEEE 국제 로봇 공학 및 자동화(ICRA)_, pp 3418-3425. IEEE, 2017.\n' +
      '* 가슬란드와 헤크베르트(1997) 마이클 가슬란드와 폴 스헤크베르트가 있다. 사중 오차 메트릭을 이용한 표면 단순화이다. 컴퓨터 그래픽 및 상호 작용 기술_, pp. 209-216에 대한 24차 연례 회의의 _검토에서 1997년.\n' +
      '* 그레프 등은 (2022) 클루우스 그레프, 프랑수이스 벨레티, 루카스 베이어, 카를 도르치, Yilun Du, 다니엘 오리워스, 데이비드 J 플레인, 다비드 가프라가삼, 플로리안 고틀레고, 찰스 헤르만, 등. 윤활유: 확장형 데이터세트 발전기. 컴퓨터 비전 및 패턴 인식_ pp 3749-3761에 대한 IEEE/CVF 회의의 _검토에서 2022년.\n' +
      '* 과안 등은 (2022) 샹얀 과안, 화유 덩, 윤보 왕, 샤오칸 양이다. 신경유체: 입자 구동 신경 방사선 분야와 함께 유동성 역학이 2022년이다.\n' +
      '* 게바라 등은 (2017) 타티아나 로페즈 구에바라, 니콜라스 케멜름 테일러, 마이클 굿만, 수크라미안 라마모어, 카스베어 등이 있다. 적응 가능한 쏟아짐: 테칭 로봇은 빠르고 근사적인 유체 시뮬레이션을 사용하여 유출되지 않습니다. 로보트 학습 2017_, pp. 77-86에 관한 _1차 회의에서 2017.\n' +
      '* Jambon et al.(2023) 요소 Jambon, 베르나하르트 케블, 조지기오스 코파나스, 스타브로스 디올라티스, 조지 듀레타키스, 토마스 라이프키쿠러 등이다. Nerfshop: 신경 방사선 분야의 상호 작용 편집. __Nerfshop: 신경 방사 분야의 상호 작용 편집. 컴퓨터 그래픽 및 인터액티브 기술_, 6(1) 2023에 ACM의 절차를 밟는다.\n' +
      '* 얀너 등 (2019) 마이클 얀너, 세르게이 레빈 윌리엄 티. 프레먼, 조슈아 보테네바움, 첼시 핀, 지아준 우. 객체 중심 예측 및 계획과의 물리적 상호 작용에 대한 근거 2019.\n' +
      '* 커 등은 (2023) 저스틴 커, 정민킴, 켄 골드버그, 앙주 가나가와, 매튜 투키이크 등이 있다. 레프: 언어 내장 라디에이터 필드입니다. 컴퓨터 비전(ICCV)_국제회의에서 2023년.\n' +
      '* Lan et al.(2022) Lei Lan, 다니 M Kaufman, 미니첸 리, 첸판푸 장, Yin 양. 아핀 바디 역학: 패스트, 안정되고 교차로 없는 뻣뻣한 재료의 시뮬레이션: _Affine 바디 다이내믹. _ast, 안정적이며 교차로 없는 시뮬레이션. ACM Trans. Graph_, 2022.\n' +
      '* 르클락\' 등은 (2023) 사이먼 르클락시, 홍싱유, 미셸 구오, 테일러 하멜, 로하니 가오, 자준 우, 자차 맨체스터, 맥 슈워거 등이 있다. 동역학-증강 신경망 오브젝트의 서로 다른 생존 가능한 물리학 시뮬레이션 _ 동역학-증강 신경망의 다양한 물리학 시뮬레이션이다. IEEE 로봇 및 자동화 레터_, 8(5):2780-2787, 2023.\n' +
      '* 리 등은 (2019) 윤주 리, 지아준 우, 러스 테드라케, 조슈 B 테넨바움, 안토니오 토랄바 등이 있다. 강성 신체, 변형 가능한 물체 및 유체를 조작하기 위한 입자 역학을 학습한다. 2019학년도 _국제학습설명회 회의.\n' +
      '* 리 등은 (2021) 윤주리, 슈앙 리, 빈센트 시츠만, 풀킷 아크로갈, 안토니오 토랄바 등이 있다. 점운동 제어를 위한 __3d 신경 장면의 표현은 점운동 제어를 위한 __3d 신경 장면의 표현이다. arXiv 프리프린트 arXiv:2107.04004_ 2021.\n' +
      '* 링커하그너 등은 (2023) 조나스 링커하그너, 니클라스 프리미무스, 폴 마리아 솅, 프랑지스카 마티스-우렐리치, 게르하르트 니이만 등이 있다. 물리적 센서 관측치를 이용한 면적 그래프 네트워크 시뮬레이터 __, 물리적 센서 관측치를 이용한 기준 그래프 네트워크 시뮬레이터. __. arXiv 프리프린트 arXiv:2302.11864_, 2023.\n' +
      '* 로렌센과 Cline(1998) 윌리엄 E 로렌센과 하비 E Cline. 포스팅 큐브: 고해상도의 3d 표면 구성 알고리즘. i_샘 그래픽: 필드_, pp 347-353을 형성하는 개척 노력. 1998.\n' +
      '* 류 등은 (2019) 추맹유, 류링지, 정큐안, 프랑즈 에릭, 세델한스-피터, 테오발트 크리스천, 조이어 로텔프 등이 있다. 물리학은 희소 데이터로 연기 재구성을 위해 신경계에 신경장을 안내했다. __물리학은 희박한 데이터로 연기 재구성을 요구했다. 그래픽_, 41(4):119:1-119:14에 대한ACM 거래는 2022년 증가에 따라이다.\n' +
      '* 마덴힐 등은 (2021) 벤 마덴힐, 프라틀 피시니바산, 마테슬 타키크, 조나단 타브론, 라비 라마모에키, 르네네 등이 있다. 네르프: 시청 합성을 위한 신경 방사선 분야로 장면 제시: __ 뷰프(Nerf:)를 제시한다. 2021년 ACM_, 65(1):99-106의 통신.\n' +
      '* 모로우카 등은 (2018) 다롄 미라카, 청수 주랑, 에리라스 왕, 닉 하베어, 리피-피, 조시 테넨바움, 다니엘 LY비타민 등이다. 물리학 예측을 위한 유연한 신경 표현 __ 물리학 예측을 위한 유연한 신경 표현. __ 신경 정보 처리 시스템_, 2018년 31.\n' +
      '* 파마르 등 (2021) 미히르 파마르, 마테워 할름, 마이클 포사 등이 있다. 강한 접촉 역학에 대한 딥러닝의 근본적인 도전입니다. 2021년 지능형 로봇 및 시스템(IROS)_, pp 5181-5188. IEEE에 관한 _2021 IEEE/RSJ 국제 회의에서 2021년 IEEE.\n' +
      '* Pfaff 등은 (2021) 토바스 Pfaff, 메이어 포나토, 알바로 산체즈-고네졸레스, 피터 바타글리아 등이 있다. 그래프 네트워크로 메쉬 기반 시뮬레이션을 학습합니다. 2021년 _국제 학습 발표회의\'에서.\n' +
      '* Qiao 등 (2022) 이링 키오, 알렉산더 가오, 명 C. Lin. N천읍hysics: 단안 비디오의 편집 가능한 신경 기하학 및 물리학입니다. 2022년 신경정보처리시스템(NeurIPS)__Conference에서.\n' +
      '* Qiao 등은 (2023) 이라이오, 알렉산더 가오, 예란 주, 유펑, 지아빈 황, 명 C. 린 등이다. Dynamic 메쉬 인식 방사선 필드 __Dynamic 메쉬 인식 방사선 필드. _Dynamic 메쉬 인식 방사선 필드. ICCV_, 2023.\n' +
      '* 산체즈-고네졸레스 등은 (2018) 알바로 산체즈-고네졸레스, 니콜라스 하이스, 조스트 토바스 스프링렌버그, 조쉬 모렐, 마르틴 리에밀러, 라아 하델, 피터 바타골리아 등이 있다. 추론과 제어를 위한 학습 가능한 물리학 엔진으로서 그래픽 네트워크. 기계 학습_, pp. 4470-4479에 관한 _국제회의에서 2018. PMLR.\n' +
      '* 산체즈-고네졸레스(2020) 알바로 산체즈-고네졸레스, 조나단 고윈, 토바스 Pfaff, 렉스 예잉, 제레 레스코브크, 피터 바타골리아 등이 있다. 그래프 네트워크로 복잡한 물리학을 시뮬레이션하기 위해 학습합니다. 기계학습_국제회의에서는 2020년 PMLR, pp 8459-8468.\n' +
      '* 소촌베르거와 프라가(2016) 요하네스 로촌베르거와 얀-미카엘 프라흐름이다. 구조로부터 모션이 재방출되었습니다. 컴퓨터 비전 및 패턴 인식_, pp. 4104-4113에 대한 IEEE 회의의 _발표 2016.\n' +
      '*시 등은 하오첸 시, 화즈허 주, 지아오 황, 윤주 리, 지아준 우 등이 있다. 로브로프트: 그래프 네트워크가 있는 엘라스토 플라스틱 물체를 보고 시뮬레이션하고 형상화하는 학습, 2022년입니다.\n' +
      '* 스튜어트와 트링클(1996) 드 스튜어트와 JC JC 트링클. 클롱 마찰을 가진 경직된 신체 역학을 위한 암묵적인 타임스핑 방식은 쿨롱 마찰과 함께 __이다. 엔지니어링_, 39(15):2673-2691, 1996의 수치적 방법에 대한 국제 저널.\n' +
      '* 테드라케(2019) 러스 테드레이크. Drake: 로봇 공학에 대한 모델 기반 설계 및 검증, 2019. URL[https://drake.mit.edu] (https://dradrau.mit.edu).\n' +
      '* 토도프 등은 (2012) 에마뉘엘 토도프, 톰 에레즈, 유발 타사 등이다. 무조코: 모델 기반 제어를 위한 물리학 엔진입니다. 지능형 로봇 및 시스템_, pp 5026-5033, 2012 IEEE에 관한 _2012 IEEE/RSJ 국제회의에서.\n' +
      '* 우만호퍼 등은 (2019) 벤자민 우만호퍼, 루카스 프란틀, 닐 투레리, 블라디렌콜튼 등이 있다. 연속적인 설득력을 가진 라그랑지유체 시뮬레이션입니다. 2019학년도 _국제학습설명회 회의.\n' +
      '(2023) 윌리엄 F. 휘트니, 타티아나 로페즈-구에바라, 토비아스 Pfaff, 율리아 루바노바, 토마스 키프, 김버리 슈타헨펠트 및 켈세이 Relsey R. 알레. rgb-d 비디오, 2023에서 3d 입자 기반 시뮬레이터를 학습합니다.\n' +
      '* 위버 등 (2016) 피에르-브리스 위버, 러스 테드레이크, 스콧 쿠인더스마. 레깅된 로봇의 모델링 및 제어입니다. 로봇공학_, pp. 1203-1234의 _Springer 핸드북에서 2016.스프링거.\n' +
      '* Xue 등은 (2023) 하오티안 Xue, 안토니오 토랄바, 조슈아 보테네바움, 다니엘 LK 비타민, 윤주 리, 후시아유 튀 등이 있다. 3d-인트피스: 2023년 도전적인 장면에서 더 일반화된 3d-그라운드 시각 직관 물리학입니다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:12]\n' +
      '\n' +
      '자료자료도 적용\n' +
      '\n' +
      '### Hyper-parameters\n' +
      '\n' +
      '도넷*는 도 4(알렌 등, 2023)와 동일하게 학습된다.\n' +
      '\n' +
      '엔코더, 프로세서, 디코더용 MLP는 2개의 은닉 층이 있는 MLP와 128개의 은닉 및 출력 크기(출력 크기가 3인 디코더 MLP를 제외)를 사용한다. 디코더를 제외한 모든 MLP는 LayerNorm(Ba et al., 2016) 층이 그 뒤를 잇는다.\n' +
      '\n' +
      '그림 8: _Left: 피규어 및 주방 장면에 대한 물체 마스크를 생성하기 위해 선택된 뷰입니다. 상위 행은 각 오렌지 마스크 \\(\\{\\mathbf{m}_{\\mathbf{n}}\\}_{1}^{N}\\)로 RGB에서 렌더링된 이미지에 해당하며, XMEM(청 및 슈팅, 2022)에 의해 얻어지는 (가벼운 주황색에 오버레이드)이다. 하단 행은 동일한 장면에 있는 플레이트에 대해 동일한 절차를 보여준다. 상이한 뷰로부터의 부분 세그먼트는 또한 객체의 체적 경계를 구축하는 데 사용될 수 있다는 점에 유의한다. 맞아요.___{o}\\은 탈환 후 각 마스크에서 얻은 메쉬 \\(M_{o}\\)이다.\n' +
      '\n' +
      '그림 9: 주황색 체적 박스의 생성을 주방 장면의 깊이 마스크에서 식별한다.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:14]\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:15]\n' +
      '\n' +
      '그림 12: 도Net* K 윤활 MOVi-C의 롤아웃.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>