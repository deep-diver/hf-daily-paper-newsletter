<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# Bba: Large Vision-Language 모델을 이용한 추론을 위한 Bi-Modal Behavioral Alignment\n' +
      '\n' +
      'Xueliang Zhao\\({}^{\\spadesuit}\\) Xinting Huang\\({}^{\\diamsuit}\\) Tingchen Fu\\({}^{\\diamsuit}\\) Qintong Li\\({}^{\\spadesuit}\\) Shansan Gong\\({}^{\\spadesuit}\\)\n' +
      '\n' +
      'Lemao Liu\\({}^{\\diamondsuit}\\) Wei Bi\\({}^{\\diamondsuit}\\) Lingpeng Kong\\({}^{\\spadesuit}\\)**\n' +
      '\n' +
      '홍콩대학교({}^{\\diamondsuit}\\({}^{\\spadesuit}\\)텐센트 인공지능 연구실\n' +
      '\n' +
      '{xlzhao,lpk}@cs.hku.hk\n' +
      '\n' +
      '텐센트 AI 연구소에서 인턴을 하는 동안 작업을 수행했습니다.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '멀티모달 추론은 대형 시각 언어 모델(LVLM)의 중추적인 능력으로 자리 잡고 있다. 정확한 시각적 표현을 제공하는 도메인 특정 언어(DSL)와의 통합은 복잡하고 전문적인 도메인에서 보다 정확한 추론을 실행할 수 있는 기회를 제공한다. 그러나, 바닐라 사고 체인(CoT) 프롬프트 방법은 주로 다른 추론 메커니즘으로 인해 시각적 및 DSL 표현의 고유한 장점을 효과적으로 활용하는 데 어려움을 겪는다. 또한 다단계 추론 작업에서 중요한 단계를 다루는 데 부족한 경우가 많다. 이러한 문제를 해결하기 위해 본 논문에서는 복잡한 다중모달 추론 태스크를 증강할 때 DSL의 잠재력을 극대화하도록 설계된 Bi-Modal Behavioral Alignment(Bba) 프롬프트 방법을 소개한다. 이 방법은 LVLM이 시각적 및 DSL 표현을 위한 별도의 추론 체인을 생성하도록 안내함으로써 시작된다. 그 후, 불일치를 해결하여 이러한 사슬을 정렬하여 다른 양식에서 행동의 응집력 있는 통합을 달성한다. 실험 결과, Bba가 기하학 문제 해결(\\(28.34\\%\\~34.22\\%\\)), 체스 위치 이점 예측(\\(42.08\\%\\~46.99\\%\\)) 및 분자 특성 예측(\\(77.47\\%\\~83.52\\%\\))에서 GPT-4V(ision)의 성능을 실질적으로 향상시키는 것으로 나타났다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      'Domain-specific language (DSL) Bowman and Hammerlindl (2008); Edwards (1994); Weininger (1988); Weininger (1988)은 텍스트를 사용하여 정확하고 분명한 대안 형태를 제공함으로써 멀티모달 정보를 통합하는 것을 목표로 한다.1 이의 적용은 멀티모달 추론 능력을 상당히 향상시켰으며, 특히 심볼릭 강화 학습 McGrath et al. (2022); Zahavy et al. (2023); Ruoss et al. (2024) 및 다양한 과학 분야 Winter et al. (2022).\n' +
      '\n' +
      '각주 1: 그림 2는 지오메트리 도메인에 맞게 조정된 DSL의 예를 보여줍니다. DSL의 추가 인스턴스는 부록 D에서 찾을 수 있다.\n' +
      '\n' +
      '멀티모달 추론은 대규모 비전 언어 모델(LVLMs) OpenAI(2023)의 기본 기능이며, 많은 응용 분야에 중요한 Yang 등(2023)이다. LVLM이 멀티모달 태스크 Lu 등(2023); Hu 등(2023)에서 상당한 진전이 있었음에도 불구하고, 특히 DSL과 함께 복잡한 멀티모달 추론에 효과적으로 활용하는 것은 아직 미해결 상태로 남아 있다. 가장 직접적인 접근법은 텍스트 쿼리와 함께 시각적 데이터(예: 이미지) 및 해당 DSL 표현 모두를 LVLM에 공급하는 것이다. 이어서, 이들은 단계적인 추론을 처리하도록 프롬프트하는 CoT(Chain-of-Thought) Wei 등(2023)을 통해 안내된다. 그러나 이 접근법의 중요한 문제는 다른 양식에서 파생된 추론 과정이 종종 일관되지 않거나 심지어 상충된다는 것이다. 이러한 불일치는 시각적 및 DSL 표현(SS2.1)의 강도를 효과적으로 통합하는 LVLM의 능력을 제한한다. 더욱이, 이러한 모델들은 다중 단계 추론 Wu 등(2023); Liu 및 Chen(2023)을 실행하는 데 어려움을 겪으며, 이는 복잡한 문제들(SS2.2) 내의 중요한 단계들을 해결하는 데 그들의 효과를 방해한다.\n' +
      '\n' +
      '이러한 문제를 해결하기 위해 우리는 DSL을 복잡한 멀티모달 추론 작업에 능숙하게 통합하는 Bba(Bi-Modal Behavioral Alignment) 프롬프트 방법을 제안한다. Bba는 LVLM이 시각적 및 DSL 표현 모두에서 별개의 추론 체인을 생성하도록 프롬프트하는 것으로 시작하여 불일치를 해결하여 이러한 체인을 정렬하여 다양한 양식에서 파생된 행동을 조화시킨다. BBA는 두 가지 주요 이점을 제공한다. 첫째, \'후기 융합\' 전략 Ghanem et al.(2018); Owens and Efros (2018)를 채택하여 직접 시각 입력과 DSL 표현 모두 고유의 장점을 효과적으로 유지한다. 둘째, Bba는 양식에 걸친 불일치를 추론 프로세스 내에서 중요한 단계를 식별하는 데 도움이 되는 유익한 신호로 전환한다. 추론 체인이 다른 위치를 밝힘으로써 발견된 불일치를 해결함으로써 이러한 중요한 단계에 더 많은 중간 토큰을 효율적으로 할당한다.\n' +
      '\n' +
      '우리는 기하학 문제 해결, 체스 위치 이점 예측 및 분자 특성 예측의 세 가지 멀티모달 추론 과제에 대해 Bba를 평가한다. 이러한 다양한 응용 프로그램에서 BBA는 14.26%, 10.25% 및 6.30%의 각 성능 개선으로 주목할만한 상대적 개선을 보여주었다.\n' +
      '\n' +
      '##2 예비 연구\n' +
      '\n' +
      '이 연구에서 DSL을 사용할 수 있는 도메인 내에서 CoT 프롬프트의 세 가지 변형을 비교한다. 이러한 변화에는 (1) 질의에 대한 접지 응답을 위해 영상만을 이용하는 CoT\\({}_{v}\\), (2) 접지를 위해 DSL 표현에만 의존하는 CoT\\({}_{d}\\), (3) 영상과 DSL 표현을 모두 통합하는 CoT\\({}_{m}\\) 등이 있다. MATH 벤치마크인 Hendrycks et al. (2021)의 수학적 기하학 문제에 초점을 맞추고, 이미지 입력을 통합하는 총 \\(187\\) 문제를 포함한다. 그런 다음 다양한 문제 유형에 걸친 뚜렷한 성공률과 중요한 추론 단계를 위한 토큰 할당에 대한 경험적 검토를 통해 이미지와 DSL 표현을 모두 사용하여 다중 모드 추론을 수행하는 것과 관련된 어려움을 탐구한다.\n' +
      '\n' +
      '세립형에서의### 성능\n' +
      '\n' +
      '우리의 분석은 세립 문제 유형에 대한 다양한 모델의 성능을 평가하는 것으로 시작한다. 이를 위해 공간 조작, 명제 추론, 논리 추론, 대수 조작, 정량 분석의 다섯 가지 범주가 도출되었다. 분류 주석에 대한 자세한 내용은 부록 A.1에서 확인할 수 있으며, 각 범주에 대한 문제 해결률을 계산하고 비교하는 작업을 진행한다.\n' +
      '\n' +
      '그림 1은 이러한 범주에 걸친 모델의 성능을 시각적으로 비교한 것이다. 이러한 문제 유형에 따라 CoT\\({}_{v}\\)와 CoT\\({}_{d}\\)의 효과가 상당히 다르게 나타남을 알 수 있다. 구체적으로, CoT\\({}_{v}\\)은 공간 조작과 명제 추론을 포함하는 작업에서 우수한 성능을 보이는 반면, CoT\\({}_{d}\\)은 논리 추론, 대수 조작, 정량 분석에서 우수한 성능을 보인다. 이러한 성능의 변화는 각 양식에 의해 활성화된 서로 다른 추론 메커니즘에 기인할 수 있다. DSL 표현들은 로직-지향 동작들을 지원하는 상세한 정보(예를 들어, 정밀 좌표들)를 제공한다. 반면에, 이미지는 공간 추론에 더 도움이 되는 직관적인 시각적 단서를 제공한다.\n' +
      '\n' +
      '그림 1: 문제 해결과 비판적 단계 상세화에서 다른 방법의 비교 분석. Left**: 다양한 문제 유형에 걸친 문제 해결률(CoT\\({}_{d}\\)과 CoT\\({}_{v}\\)은 각각 DSL과 이미지 입력으로 인한 사고 사슬을 의미하며 CoT\\({}_{m}\\)은 두 입력을 결합한 접근 방식을 나타낸다. **Right**: 서로 다른 메서드에 걸쳐 임계 단계당 평균 토큰 수.\n' +
      '\n' +
      '작업. 이미지와 DSL 표현을 동시에 사용함에도 불구하고 CoT\\({}_{m}\\)은 모든 문제 유형에서 균일한 개선을 나타내지 않으며, 이는 양식에 걸쳐 추론 메커니즘을 정렬하는 데 어려움을 나타낸다. SS4에서 이미지와 DSL 표현에서 추론 체인을 독립적으로 유도하여 시작하는 Bba에 대해 자세히 설명한 다음 이들 체인 간의 불일치를 해결하여 이러한 체인을 정렬한다. CoT\\({}_{m}\\)과 달리 BBA는 두 양식의 장점을 효과적으로 활용하여 확인된 모든 문제 범주에서 포괄적인 개선을 달성한다.\n' +
      '\n' +
      '중요한 단계를 위한### 토큰 할당\n' +
      '\n' +
      'Feng et al. (2023); Merrill and Sabharwal (2023)은 순차 추론 태스크에서 모델의 표현력을 풀기 위한 중추로서 중간 토큰의 효과적인 할당을 나타내는 최근의 이론적 진보에 비추어, 문제 해결의 중요한 단계를 다루기 위한 중간 토큰의 할당을 파헤친다. 수학적 문제 해결의 중요한 단계는 일반적으로 중요한 개념 도약, 전략적 정리 적용 또는 후속 문제 해결 과정에 영향을 미치는 핵심 계산을 포함하는 올바른 해결책을 얻기 위해 방법의 본질적인 통찰력, 결정 또는 적용이 중요한 지점으로 정의된다. 각 문제에 대해 모든 중요 단계를 식별하고 생성된 솔루션의 각 단계를 식별된 중요 단계 중 하나에 해당하는 것으로 분류한 다음 동일한 중요 단계와 관련된 생성된 솔루션 내의 단계에 대한 토큰을 합산한다. 중요한 단계의 주석에 대한 자세한 내용은 부록 A.2에 나와 있다.\n' +
      '\n' +
      '그림 1은 입력에서 이미지와 DSL 표현을 결합하는 것만으로는 중요한 단계에 더 많은 토큰을 효과적으로 할당하기에 불충분하며, 따라서 LLM의 표현력을 감소시키고 (SS5.4에서 논의된 바와 같이) 열등한 전체 성능을 초래한다는 것을 보여준다. 우리는 이러한 한계가 복잡한 문제에 대한 해결 공간을 탐색하는 데 있어 LLM의 현재 비효율성으로 인해 발생하여 중요한 단계를 정확하게 식별하기 위한 고군분투가 발생한다고 가정한다. SS4.2에서 논의될 바와 같이 Bba는 다른 양식에서 파생된 추론 체인 간의 불일치를 발견하고 조정함으로써 중요한 단계를 식별하고 해결하는 데 더 효과적이다.\n' +
      '\n' +
      '## 3 Preliminaries\n' +
      '\n' +
      '### Problem Formulation\n' +
      '\n' +
      '본 연구는 다중 모달 추론 작업, 특히 시각적 모달리티가 이미지로 표현되는 경우와 이미지를 정확하게 묘사하는 DSL에 초점을 맞춘다. 본 연구의 목적은 특정 과제 요구 사항(예: 수학적 문제 해결)을 준수하는 이미지(v\\(v\\)와 DSL 표현(d\\)과 관련된 주어진 질문(q\\)에 대한 답을 예측하는 것이다.\n' +
      '\n' +
      'LVLM의 출현은 이 프로세스를 간소화했다. 수조 개의 토큰에 대한 광범위한 사전 훈련으로 인해 이러한 모델은 다양한 명령어를 정확하게 해석하고 해당 작업을 실행할 수 있다. 이 패러다임에서 모델 매개변수는 \\(\\mathbf{\\theta}\\)로 표시되고, 응답 \\(\\hat{a}\\)은 \\(\\hat{a}=\\arg\\max_{a}p(a\\mid q,v,d;\\mathbf{\\theta})\\)로 생성되며, 여기서 입력은 LVLM에서 원하는 응답을 이끌어내기 위해 설계된 특정 템플릿을 사용하여 잘 조작된 프롬프트로 재구성된다.\n' +
      '\n' +
      '### Chain-of-Thought Prompting\n' +
      '\n' +
      '최근, 사고 연쇄 프롬프트는 언어 모델 Wei et al.(2023)의 추론 능력을 향상시키기 위한 효과적인 기술로서 인식되었다. 이 방법은 원 과제를 이론적 생성과 답 예측이라는 두 가지 별개의 단계로 분해한다. 이론적 생성 단계에서 이론적 이론(\\hat{r}\\)은 \\(\\hat{r}=\\arg\\max_{r}p(r\\mid q,v,d;\\mathbf{\\theta})\\)로 유도되며, Kojima et al.(2022)의 단계적 분석적 사고를 개시하도록 설계된 명령어로 증강된 질의를 활용한다. 그 후, 정확한 식별을 위해 휴리스틱 문자열 매칭 방법을 사용하여 근거에서 직접 답을 추론하는 경우가 많다.\n' +
      '\n' +
      '## 4 Method\n' +
      '\n' +
      '이 연구는 다중모달 추론에서 두 가지 주요 과제를 해결하는 것을 목표로 한다: (1) 시각적 표현과 DSL 표현 모두의 고유한 강점의 통합, (2) 이러한 작업 내에서 중요한 단계의 식별 및 해결. 이러한 문제를 해결하기 위해 복잡한 다중 모드 추론 작업을 향상시키는 데 DSL의 힘을 발휘하려는 혁신적인 접근법인 Bba 프롬프트 방법을 소개한다. 그림 2는 제안된 방법론에 대한 개요를 제공한다. Bba는 시각적 및 DSL 입력과 별도로 추론 체인을 생성하기 위해 LVLM을 사용하여 시작한다. 이어서, 이들 체인은 정렬 단계를 통해 진행되며, 여기서 불일치가 식별되고 조정되어 각 양식에서 파생된 행동의 조화를 보장한다.\n' +
      '\n' +
      '도로지도(Road Map)의 나머지 부분은 SS4.1에서 시각과 DSL 표현에서 추론 체인을 도출하는 과정을 상세하게 설명하고, SS4.2에서는 이러한 추론 체인의 불일치를 진단하고 수정하는 방법과 서로 다른 양식에서 행동을 정렬하는 방법에 대해 자세히 설명한다. 마지막으로 SS4.3에서는 Bba가 추론 과정에서 중요한 단계를 효과적으로 식별하고 해결하는 방법에 대해 자세히 설명한다.\n' +
      '\n' +
      '### Bi-Modal Behavior Eliciting\n' +
      '\n' +
      '이 단계의 목적은 주어진 질문에 답하는 데 있어 시각과 DSL 표현의 고유한 장점을 효과적으로 활용하는 것이다. 이 두 양식의 추론 과정을 혼합하는 바닐라 CoT 촉진과 달리 Bba는 각 양식에서 추론 사슬을 독립적으로 유도하려고 한다. 이 접근법은 비전 기반 추론 체인이 직관적이고 공간적인 추론에서 더 신뢰할 수 있는 단계를 제공하는 반면 DSL 기반 추론 체인은 정확한 계산에서 더 큰 신뢰성을 가진 단계를 제공한다. 이 과정에 대한 형식적 정의는 다음과 같다.\n' +
      '\n' +
      '\\operatorname*{arg\\,max}_{r}p(r\\mid q,v;\\boldsymbol{\\theta})\\\\r_{\\text{d}&=\\operatorname*{arg\\,max}_{r}p(r\\mid q,d;\\boldsymbol{\\theta})\\end{split}\\tag{1}\\\n' +
      '\n' +
      '여기서 \\(r_{\\text{v}}\\) 및 \\(r_{\\text{d}}\\)은 각각 비전 및 DSL 표현으로부터 유도된 추론 체인을 나타낸다.\n' +
      '\n' +
      '### Behavior Alignment\n' +
      '\n' +
      '이 단계는 다중 모달 추론에서 두 세계의 장점을 활용하기 위해 서로 다른 모달리티의 추론 체인을 정렬하는 데 중점을 둔다. 중간 단계의 분산과 최종 답변을 포함하여 사슬 간의 불일치를 밝히기 위해 진단 검사로 이 프로세스를 시작한다. 이후 진단에서 확인된 불일치를 해결하여 정렬된 추론 체인이 생성된다. 상이한 방법들이 상충하는 결과들을 생성할 때, 그것은 종종 적어도 하나의 접근법에서 오류를 나타낸다. 그런 다음 발산점은 더 깊은 이해나 보다 세심한 원칙 적용이 필요한 곳의 중요한 지표가 된다. 이후 모델은 두 양식 모두에서 파생물을 철저히 조사하고 정확한 결론을 확인하도록 지시된다. 진단 결과는 다음과 같이 형식적으로 얻어진다:\n' +
      '\n' +
      '\\[r_{\\text{inc}=\\operatorname*{arg\\,max}_{r}p(r\\mid r_{\\text{v},r_{\\text{d}; \\boldsymbol{\\theta}), \\tag{2}\\]\n' +
      '\n' +
      '여기서 \\(r_{\\text{inc}}\\)는 진단 과정에서 확인된 불일치의 근거를 나타낸다. 다음으로, 정렬된 추론 체인의 형성은 다음과 같이 정의된다:\n' +
      '\n' +
      '\\[\\hat{r}=\\operatorname*{arg\\,max}_{r}p(r\\mid r_{\\text{v}},r_{\\text{d},r_{\\text{inc};\\boldsymbol{\\theta}}\\tag{3}\\)\n' +
      '\n' +
      '여기서 최종 근거 \\(\\hat{r}\\)는 특수 토큰 내에서 최종 답 \\(a\\)을 포함한다.\n' +
      '\n' +
      '### Discussion\n' +
      '\n' +
      'BBA의 장점은 주로 다단계 추론 문제에서 중요한 단계를 해결하는 능력에 기인할 수 있다. Bba는 주로 두 가지 이유로 인해 중요한 단계를 해결하는 데 탁월하다. (1) 중요한 단계는 다른 솔루션을 대조하여 그 차이를 드러냄으로써 더 쉽게 식별되며, (2) 이러한 차이에서 학습하면 이러한 중요한 단계에 중간 토큰을 더 효율적으로 할당할 수 있다. 인간에게서 관찰되는 인지적 학습 원리로 그려보면 그럴듯하다.\n' +
      '\n' +
      '그림 2: 제안된 Bba 방법의 인스턴스화.\n' +
      '\n' +
      '다양한 방법 간의 격차를 식별하고 교정하는 외삽은 문자르 외(2021)의 본질적인 측면에 대한 더 깊은 이해를 촉진한다. 나아가 실수를 접하고 인정하는 것은 추론 과정을 강화시켜 인간의 문제 해결 전략과 병행한다. 이는 이해를 심화시킬 뿐만 아니라 추가적인 추론 토큰의 할당을 용이하게 하여, Feng 등(2023); Merrill and Sabharwal(2023)을 해결하기 위한 모델의 용량을 증폭시킨다.\n' +
      '\n' +
      '## 5 Experiments\n' +
      '\n' +
      '### 데이터 세트 및 평가\n' +
      '\n' +
      '우리는 기하학 문제 해결, 체스 위치 이점 예측 및 분자 특성 예측의 별개의 영역에 걸쳐 있는 세 가지 다중 모드 추론 작업에 걸쳐 Bba의 효능을 평가한다.\n' +
      '\n' +
      '지오메트리 문제 해결.이 작업에는 주어진 지오메트리 문제에 대한 자유형 솔루션을 예측하는 작업이 포함됩니다. 우리는 MATH 벤치마크 Hendrycks et al.(2021)의 기하학적 서브세트를 이 작업에 활용하며, 기하학적 도형을 묘사하기 위해 사용되는 도메인-특정 언어(DSL)인 Asymptote 코드 Bowman 및 Hammerlindl(2008)을 포함하는 이들 문제들만을 선택한다. 이 과정은 우리가 **G-MATH**라고 부르는 \\(187\\) 문제의 데이터 세트를 생성했다. MATH 벤치마크의 공식 평가 스크립트는 예측된 답변과 정답을 비교하여 정확도를 계산하는 데 사용된다.\n' +
      '\n' +
      '체스 위치 어드밴티지 예측.체스 위치 어드밴티지 예측에서의 목적은 주어진 체스보드 상태가 화이트에 유리하거나, 블랙에 유리하거나, 또는 밸런스된 것으로 분류하는 것이다. 이 작업은 광범위한 분석 후 체스 엔진에 의해 결정된 체스보드 상태의 실제 값과 상관관계가 있는 모델의 능력을 평가한다. 평가를 위해 18개의 검색 깊이에서 스톡피쉬 15를 사용하여 흰색 조각에 대한 승산 확률을 평가하기 위해 \\(183\\) 게임 스니펫의 데이터 세트를 수집했다. 승산확률은 흑인에게 유리한 0-33%, 균형상태를 나타내는 34-66%, 백인에게 유리한 67-100%의 세 구간으로 구분하였다. 이 도메인에 대한 DSL로 FEN(Forsyth-Edwards Notation) 에드워드(1994)를 사용하여 이 데이터 세트를 **ChessAdv**라고 한다. 분류 정확도는 평가 메트릭으로 사용됩니다.\n' +
      '\n' +
      '분자 특성 예측.분자 특성 예측은 분자가 분자 그래프를 기반으로 특정 특성을 나타내는지 여부를 결정하는 데 중점을 둔다. *MUTAG** 벤치마크 데이터세트 Debnath et al.(1991)은 박테리아에 대한 돌연변이 유발 효과에 기초하여 두 부류로 분류되는 \\(188\\) 화학 화합물을 포함하는 이 목적을 위해 사용된다. SMILES(Simplified Molecular-Input Line-Entry System) Weininger(1988)는 분류 정확도를 평가 메트릭으로 사용하여 이 도메인에서 DSL로 사용된다.\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      '비교 평가를 위해 다음과 같은 기준선을 채택한다.\n' +
      '\n' +
      'DSL 또는 Visual-Only Methods. (1) **CoT\\({}_{v}\\)**: Implements chain-of-thought prompt Wei et al. (2023), 생략된 DSL 표현 및 이미지에만 의존하는 것; (2) **CoT\\({}_{d}\\)**: chain-of-thought prompting, 이미지를 배제하여 DSL 표현에만 집중하는 것; (3) **Plan-and-Solve**: 전체 태스크를 순차 실행 Wang et al. (2023)을 위한 관리 가능한 서브 태스크들로 분할하기 위한 계획을 수립하는 것; 및 (4) **Least-to-Most**: 복잡한 문제들을 더 단순하고 순차적인 서브문제들로 분해하고, 선행 서브문제들의 해결책을 활용하여 후속하는 것들 Zhou et al. (2022)를 용이하게 한다.\n' +
      '\n' +
      '통합 DSL 및 비주얼 메소드입니다. (1) **CoT\\({}_{m}\\)**: DSL 표현과 이미지의 조합을 사용하여 사상 연쇄 프롬프트를 도입; (2) **CCoT**: 시각적 입력과 DSL 입력을 통합하여 구성 추론을 강화하고, 장면 그래프를 DSL로 대체하여 공정한 비교를 위해 Mitra et al. (2023), (3) **DDCoT**: 추론과 인식 사이의 인지적 작업을 나누어 부정적인 공간 프롬프트와 멀티모달 추론을 도입하고, 시각적 인식 능력 Zheng et al. (2023)을 사용하여 추론을 강화한다.\n' +
      '\n' +
      'Bba와 함께 모든 기본 방법은 공정하고 일관된 비교를 보장하기 위해 gpt-4-비전-프리뷰 버전을 사용하여 **GPT-4V(비전)**오픈AI(2023)에서 구현된다.\n' +
      '\n' +
      '### Implementation Details\n' +
      '\n' +
      '기하학적 문제 해결과 체스의 위치적 이점 예측을 위해 제로 샷 프롬프트를 사용한다. 분자 특성 예측의 경우, GPT-4V(ision)에 이 특수 태스크가 제시하는 과제를 고려하여 4개의 <SMILES, 카테고리> 쌍으로 명령어를 증강한다. 이러한 SMILES 표현은 데이터 유출을 방지하기 위해 테스트 케이스에서 제외된다는 점에 유의하는 것이 중요하다. 이러한 작업에 대한 자세한 지침은 부록 B에서 찾을 수 있다. gpt-4-vision-preview와 상호 작용하기 위해 _temperature_ 및 _top_p_는 결정론적 출력을 보장하기 위해 각각 \\(0\\) 및 \\(1\\)으로 설정되고 _max_tokens_ 매개변수는 \\(2048\\)에서 캡핑된다.\n' +
      '\n' +
      '### Main Results\n' +
      '\n' +
      '표 1에 제시된 실험 결과는 (1) Bba가 비교된 모든 기준 방법을 능가하여 기하학 문제 해결, 체스 위치 이점 예측 및 분자 특성 예측에서 각각 14.26%, 10.25% 및 6.30%의 상대적 개선을 달성한다는 몇 가지 주요 관찰을 보여준다. 이러한 우수한 성능은 Bba가 시각적 표현과 DSL 표현의 결합된 강도를 활용하는 능력과 중요한 단계를 정확하게 지적하고 해결하는 능력에 기인할 수 있다; (2) DSL과 시각적 정보의 통합은 다중 모드 추론 작업에 유리하다는 것을 증명한다. 본 연구의 결과는 CoT\\({}_{m}\\)이 기하학 문제 해결에서 두 번째로 우수한 평균 성능을 달성함을 보여준다. 이 작업은 DSL과 시각적 입력이 제공하는 보완적 통찰력으로부터 현저하게 이익을 얻으며, 이러한 양식을 통합하는 가치를 나타낸다. (3) DSL 표현을 시각적 데이터와 효과적으로 병합하는 프로세스는 CCoT의 하위 성능에 의해 입증된 바와 같이 중요한 도전을 제기한다.\n' +
      '\n' +
      '## 6 Analysis\n' +
      '\n' +
      '### Ablation Study\n' +
      '\n' +
      '이 절제 연구는 표 2와 같이 세 가지 데이터 세트에 걸쳐 모델의 네 가지 변형을 평가한다. 이 변형은 전체 방법과 세 가지 변형으로 구성되며, 하나는 진단 검사 없이("-진단"), 추론 프로세스는 검증 없이 다른 양식의 분기 추론 체인에만 기반하고, 하나는 이미지 입력("-시각"), 모델의 추론 체인에 대한 평가는 DSL 표현과 내재적 지식에만 의존하며, 하나는 DSL 입력("-dsl"), 추론 체인에 대한 평가는 시각적 정보와 모델의 내재적 이해에만 의존한다.\n' +
      '\n' +
      '결과는 전체 방법이 데이터 세트에서 모든 변형보다 우수하다는 것을 보여주며, 이는 불일치를 식별하고 중요한 단계에서 문제 해결을 향상시키기 위해 진단 검사와 함께 DSL 및 시각적 입력을 결합하는 중요한 역할을 나타낸다. 특히, 시각적 입력의 배제는 가장 중요한 성능 저하를 초래하여 다중 모드 추론 작업의 효능에 대한 이미지의 중요한 기여를 강조한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c} \\hline \\hline Methods & With DSL & With Figure & **G-MATH** & **ChessAdv** & **MUTAG** & Avg. \\\\ \\hline CoT\\({}_{v}\\)(Wei et al., 2023) & ✗ & ✓ & 23.53 & 40.98 & 75.82 & 46.56 \\\\ CoT\\({}_{d}\\)(Wei et al., 2023) & ✓ & ✗ & 23.12 & 38.80 & 76.92 & 46.01 \\\\ Plan-and-Solve (Wang et al., 2023a) & ✓ & ✗ & 25.67 & 42.62 & 78.57 & 48.73 \\\\ Least-to-Most (Zhou et al., 2022) & ✓ & ✗ & 25.13 & 38.25 & 73.63 & 45.47 \\\\ \\hline CoT\\({}_{m}\\)(Wei et al., 2023) & ✓ & ✓ & 28.34 & 42.08 & 77.47 & 49.09 \\\\ CCoT (Mitra et al., 2023) & ✓ & ✓ & 26.74 & 39.34 & 68.68 & 44.75 \\\\ DDCoT (Zheng et al., 2023) & ✓ & ✓ & 29.95 & 37.70 & 73.08 & 46.74 \\\\ \\hline Bba (Ours) & ✓ & ✓ & **34.22** & **46.99** & **83.52** & **54.71** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 평균 성능을 포함하여 기하학 문제 해결(**G-MATH**), 체스 위치 이점 예측(**ChessAdv**), 분자 특성 예측(**MUTAG**)에 대한 평가 결과. 굵게 표시된 숫자는 최고의 성능을 나타냅니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c} \\hline \\hline Methods & With DSL & With Figure & **G-MATH** & **ChessAdv** & **MUTAG** & Avg. \\\\ \\hline Bba (Ours) & ✓ & ✓ & **34.22** & **46.99** & **83.52** & **54.71** \\\\ \\hline -diagnostic & ✓ & ✓ & 32.09 & 41.53 & 78.57 & 50.54 \\\\ -visual & ✓ & ✗ & 28.34 & 37.70 & 61.54 & 42.39 \\\\ -dsl & ✗ & ✓ & 27.27 & 36.07 & 75.82 & 46.20 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 최상의 성능을 가진 절제 연구 결과들이 굵은 글씨로 강조되었다.\n' +
      '\n' +
      '복잡도에 따른### 분석\n' +
      '\n' +
      '이 실험은 Bba가 다양한 문제 복잡성 하에서 어떻게 수행하는지 조사하여 생각 사슬 프롬프트의 세 가지 변형과 비교한다. 우리의 초점은 분자 그래프의 난이도를 평가하는 노동 집약적인 특성으로 인해 기하학 문제 해결과 체스 위치 이점 예측에 있다. 기하학의 경우 MATH 벤치마크 Hendrycks et al.(2021)에 의해 요약된 난이도 수준을 활용하고, 체스의 경우 스톡피쉬 15가 반환한 센티포엔을 기반으로 문제를 세 가지 난이도 수준으로 분류한다.\n' +
      '\n' +
      '표 3 및 표 4는 결과를 제시한다. BBA는 기하학 문제 해결에서 레벨 4를 제외하고 거의 모든 난이도에서 경쟁자를 지속적으로 능가한다. DSL과 이미지 입력을 통합하는 것은 CoT\\({}_{m}\\)이 일반적으로 CoT\\({}_{v}\\)과 CoT\\({}_{d}\\)의 성능을 능가하므로 유리하다는 것을 증명한다. 그러나 직접 통합을 통해 보편적인 개선을 달성하는 것은 (SS2.1에서 논의된 바와 같이) 중요한 과제를 제시한다. 기하학 문제 해결에서 DSL 표현은 더 간단한 문제에서 특히 효과적이지만 복잡성이 증가함에 따라 이러한 이점은 감소한다. 우리는 이것이 더 복잡한 문제에서 무증상 코드의 연장 때문이라고 가정한다. 예를 들어, 평균 무증상 코드 길이는 레벨 1 내지 레벨 3의 경우 \\(186.89\\)이지만 레벨 4 내지 레벨 5의 경우 \\(217.80\\)으로 증가하는 반면, FEN 표기 길이는 상이한 난이도에 걸쳐 비교적 안정적으로 유지된다.\n' +
      '\n' +
      'Self-Refine Prompting과의 비교\n' +
      '\n' +
      '이 실험은 Bba에서 진단 검사 및 정렬 단계를 대체할 수 있는 잠재적인 대안으로 반복 피드백 및 정제를 통해 이전 출력을 개선하는 기술인 Madaan et al.(2023)의 자기 정제 프롬프트의 효능을 탐구한다. 우리는 DSL과 이미지 입력을 모두 수용하면서 원래의 구현 세부 사항을 최대한 보존하기 위해 기존의 자체 정제 프롬프트 접근 방식을 채택했다. 이 실험은 세 가지 버전의 자기 정제 프롬프트(Self-Refine prompting, \\(x\\) turns)를 평가하는데, \\(x-1\\)은 정제 사이클 수를 나타내고 \\(2\\)에서 \\(4\\)까지 변한다.\n' +
      '\n' +
      '표 5는 그 결과를 제시한다. 연구 결과는 Bba가 다양한 버전의 자기 정제 촉진을 지속적으로 능가한다는 것을 보여준다. 이는 LVLM이 매개 변수 내에 포함된 지식을 기반으로 피드백을 생성하는 것보다 분기 솔루션 간의 불일치를 정확하게 지적하도록 지시하는 것의 우수성을 나타낸다. 또한 최근 연구인 Huang et al.(2023)은 우리의 연구 결과를 확증하여 LLM이 고유한 능력만을 기반으로 응답을 조정하는 데 어려움을 자주 겪는다는 것을 보여준다. 이것은 정제 반복 횟수가 증가함에 따라 셀프 정제 프롬프트의 성능이 감소함을 나타내는 우리의 결과에 의해 추가로 검증된다.\n' +
      '\n' +
      '### Case Study\n' +
      '\n' +
      '공간 제약으로 인해 사례 연구는 부록 D에 포함되어 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c} \\hline \\hline  & Level 1 & Level 2 & Level 3 & Avg. \\\\ \\hline Bba (Ours) & **57.41** & **43.21** & **41.67** & **46.99** \\\\ \\hline CoT\\({}_{m}\\) & 51.85 & 37.04 & 39.58 & 42.08 \\\\ CoT\\({}_{v}\\) & 48.15 & 38.27 & 37.50 & 40.98 \\\\ CoT\\({}_{d}\\) & 46.30 & 33.33 & 39.58 & 38.80 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 체스 위치 이점 예측 과제에 대한 평가 결과. 굵게 표시된 숫자는 최고의 성능을 나타냅니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c} \\hline \\hline  & Level 1 & Level 2 & Level 3 & Level 4 & Level 5 & Avg. \\\\ \\hline Bba (Ours) & **71.43** & **53.13** & **44.12** & 16.98 & **17.02** & **34.22** \\\\ \\hline CoT\\({}_{m}\\) & 61.90 & 37.50 & 29.41 & **24.53** & 10.64 & 28.34 \\\\ CoT\\({}_{v}\\) & 52.38 & 37.50 & 26.47 & 13.21 & 10.64 & 23.53 \\\\ CoT\\({}_{d}\\) & 47.62 & 50.00 & 29.41 & 7.69 & 6.38 & 23.12 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 기하학 문제 해결 과제에 대한 평가 결과. 굵게 표시된 숫자는 최고의 성능을 나타냅니다.\n' +
      '\n' +
      '##7 관련 업무\n' +
      '\n' +
      '### Multi-Modal CoT Prompting\n' +
      '\n' +
      '제로샷 이미지 추론을 위한 고급 방법론은 복잡한 작업을 단순하고 순차적인 사고 프로세스로 분해하여 인간 추론을 시뮬레이션하는 기법인 CoT 프롬프트를 활용한다[14, 15, 16]. LVLM과 LLM 간의 구조적 차이로 인해 더 넓은 적용을 위해 CoT를 적용하기 위한 추가 개선이 이루어졌다. 이를 위해, QVix[16]은 LLMs의 언어적 기술을 활용하여 LVLMs의 시각적 내용 분석을 강화하고, V\\({}^{*}\\)[21]는 특정 시각적 요소의 정확한 타겟팅을 강화하고, Wu et al. (2023)은 복잡한 시각언어적 작업에 대해 "Description then Decision" 전략을 채택함으로써 CoT에 제한을 제기하고, CoCoT[15]는 여러 이미지 입력에 대해 대조적 CoT 접근법을 사용하고, ViLa[14]는 물리적으로 접지된 작업 계획을 위해 지각 데이터를 CoT와 병합하고, DDCoT[15]는 관련 구성요소에 작업을 할당하고, 추론 및 인식 역할을 구별하고 시각적 인식을 추론 프로세스에 통합한다. 이러한 발전에도 불구하고 DSL을 LVLM에 원활하게 통합하기 위한 촉진 메커니즘의 전략적 사용은 개발되지 않은 잠재력을 제시하며, 이 연구는 이 특정 영역에서 개척함으로써 가교하는 것을 목표로 한다.\n' +
      '\n' +
      '## 다중 체인 프롬프팅\n' +
      '\n' +
      '사고 사슬의 진전에 따라, 여러 추론 사슬을 생성함으로써 사실성을 향상시키기 위한 일련의 노력이 이루어졌다. 이러한 진전을 바탕으로 본 연구는 자기 일관성[16], 자기 정제[17, 18, 19], 다중 에이전트 토론[14, 15, 16]의 세 가지 주요 접근법에 초점을 맞추고 있다. 자기일치성[16]은 다양한 추론 경로를 먼저 생성한 후 다수결 투표와 유사한 과정을 거쳐 가장 일관된 답변을 선택하는 방식을 포함한다. 자기 정제[17]는 LLM의 고유한 기능을 활용하여 이전 출력에 대한 피드백을 생성하여 이 피드백을 기반으로 정제한다. 그러나 최근 연구[14]는 LLM이 독립적으로 정확한 피드백을 제공하는 데 어려움을 겪고 있음을 나타내며, 이는 외부 환경[20]으로부터의 피드백이 더 효과적인 대안임을 시사한다. 다중 에이전트 토론[14]은 실제 토론 시나리오를 복제하여 각 토론 주기에 이전 반복의 결과를 통합하여 합의를 촉진하는 것을 목표로 한다. 이러한 방법은 혁신적이지만 복잡한 작업을 해결하는 데 필요한 중요한 단계를 식별하는 데 중요한 역할을 하는 여러 체인 간의 중간 불일치를 식별할 필요성을 아직 완전히 해결하지 못했다. 더욱이, 특히 독점 LVLM[19]과 함께 LLM의 다중 호출에 대한 요구 사항은 관련 비용을 크게 증가시킨다.\n' +
      '\n' +
      '우리는 부록 C의 대형 비전 언어 모델에 대한 문헌에 대한 자세한 검토를 제공한다.\n' +
      '\n' +
      '## 8 Conclusion\n' +
      '\n' +
      '결론적으로, 본 연구는 DSL을 통합함으로써 GPT-4V(ision)의 멀티모달 추론 능력을 크게 향상시키는 새로운 접근 방법인 Bi-Modal Behavioral Alignment(Bba) 프롬프트 방법을 소개한다. 시각적 및 DSL 표현을 위한 별도의 추론 체인을 생성하고 정렬함으로써 Bba는 일관되지 않은 추론 메커니즘의 문제와 다단계 추론 작업의 실행을 해결한다. 기하학 문제 해결, 체스 위치 이점 예측 및 분자 특성 예측을 포함한 다양한 영역에 걸친 우리의 실험은 Bba의 효과를 입증하여 성능에서 주목할 만한 개선을 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c} \\hline \\hline Methods & **G-MATH** & **ChessAdv** & **MUTAG** & Avg. \\\\ \\hline Bba (Ours) & **34.22** & **46.99** & **83.52** & **54.71** \\\\ \\hline Self-Refine (2 turns) & 30.48 & 43.17 & 73.63 & 48.91 \\\\ Self-Refine (3 turns) & 28.34 & 42.08 & 71.98 & 47.28 \\\\ Self-Refine (4 turns) & 28.88 & 38.80 & 68.68 & 45.29 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: Bba 대 Self-Refine prompting의 비교 분석. 굵게 표시된 숫자는 최고의 성능을 나타냅니다.\n' +
      '\n' +
      '### Ethical Considerations\n' +
      '\n' +
      '구축된 윤리 강령을 준수하기 위해 이 작업은 공개적으로 액세스할 수 있는 데이터 및 정보를 독점적으로 사용하여 개인 또는 기밀 리소스가 사용되지 않도록 한다.\n' +
      '\n' +
      '### Limitations\n' +
      '\n' +
      'BBA는 DSL을 통합하는 다중 모드 추론 분야에서 상당한 발전을 나타낸다. 그럼에도 불구하고, 자신의 능력을 완전히 활용하기 위해 몇 가지 한계를 해결하는 것이 유익하다:\n' +
      '\n' +
      '(1) Bba는 기하학, 체스 및 분자 생물학의 세 가지 별개의 영역에서 상당한 개선을 보여준다. 그러나 다른 영역, 특히 맞춤형 DSL이 없는 영역에 대한 적용은 광범위하게 탐구되지 않았다. DSL 표현을 장면 그래프[22]와 같은 대안적인 고급 표현으로 대체하여 Bba를 적용하는 것이 유리할 수 있다. 이러한 대안은 이미지 뉘앙스를 캡처하는 데 덜 정확하고 유익하지만 귀중한 연구 방향을 제공한다.\n' +
      '\n' +
      '(2) 이 작업의 주요 목적은 다른 첨단 기술을 보완하지만 구별되는 촉진 방법을 개발하는 것이다[20, 21]. 보다 적응적이고 지능적인 에이전트를 개발하기 위해 환경 피드백을 통합하고 대응할 수 있는 가능성은 향후 흥미로운 연구 방향이다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '*[1]J. Alayrac, J. Donahue, P. Luc, A. Miech, I. Barr, Y. 하손기 Lenc, A. Mensch, K 밀리컨, M. Reynolds, et al. (2022) Flamingo: a visual language model for few-shot learning. The Advances in Neural Information Processing Systems35, pp. 23716-23736. Cited by: SS1.\n' +
      '*[2]A. 아와달라, I. 가오, J. 가드너, J. 헤셀, Y. 한나피 주경호 마라테 비트턴 가드레 Sagawa, et al.(2023) Openflamingo: a open-source framework for training large autoregressive vision-language models. ArXiv:2308.01390. 인용: SS1.\n' +
      '*[3]J. E. Bouchnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch (1991) Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. 분자 궤도 에너지 및 소수성과의 상관 관계. Journal of medicinal chemistry34 (2), pp. 786-797. Cited by: SS1.\n' +
      '*[4]K. 천진 장원 정룡 장, F. Zhu, R. Zhao(2023) Shikra: 멀티모달 llm의 지시적 대화 마법을 풀다. ArXiv:2306.15195. 인용: SS1.\n' +
      '*[5]X. 천민 린남 Scharli, 그리고 D. Zhou (2023)는 큰 언어 모델들을 셀프 디버깅으로 가르친다. ArXiv:2304.05128. 인용: SS1.\n' +
      '*[6]W. Dai, J. Li, D. Li, A. Tiong, J. Zhao, W. 왕병리, P. 펑, S. Hoi(2023) InstructchipP: 명령어 튜닝을 갖는 범용 비전-언어 모델들을 향해. 외부 링크: 2305.06500 인용: SS1.\n' +
      '*[7]A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch (1991) Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. 분자 궤도 에너지 및 소수성과의 상관 관계. Journal of medicinal chemistry34 (2), pp. 786-797. Cited by: SS1.\n' +
      '*[8]Y. 두성 Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch(2023)는 다중 에이전트 토론을 통해 언어 모델에서 사실성과 추론을 향상시킨다. ArXiv:2305.14325. 인용: SS1.\n' +
      '*[9]S. J. Edwards (1994) Portable game notation specification and implementation guide. Retrieved April4, pp. 4:2011. Cited by: SS1.\n' +
      '*[10]G. 펑영 구병장 왕(2023) 사상 사슬 뒤에 숨겨진 미스터리를 밝히는 것: 이론적 관점. ArXiv:2305.15408. 인용: SS1.\n' +
      '*[11]E. 먼저, M. N. Rabe, T. 링거, Y. Brun(2023) Baldur: 대형 언어 모델을 사용한 전체 방지 생성 및 수리. ArXiv:2303.04910. 인용: SS1.\n' +
      '*[12]P. 가오재한 장장 린성호 정아주 장필루 Yue, et al.(2023) Llama-adapter v2: parameter-efficient visual instruction model. ArXiv:2304.15010. 인용: SS1.\n' +
      '*[13]B. Ghanem, J. Carlos Niebles, C. Snoek, F. Caba Heilbron, H. Alwassel, V. 에스코시아 크리슈나 Buch, and C. Duc Dao (2018) The activityNet large-scale activity recognition challenge 2018 summary. ArXiv:1808.03766. 인용: SS1.\n' +
      '*[14]D. 헨드릭스, C 번즈, S 카다바스 A. 아로라 S. Basart, E. Tang, D. Song, and J. Steinhardt (2021) Measuring mathematical problem solving with the math dataset. ArXiv:2103.03874. 인용: SS1.\n' +
      '*[15]Y. 후필린 장룡 이와 Y. 가오(2023) 당신이 도약하기 전에 보세요: 로봇 비전 언어 계획에서 gpt-4v의 힘을 공개합니다. ArXiv:2311.17842를 사전 인쇄합니다.\n' +
      '\n' +
      '지황, 신은천, 스와룹 미쉬라, 화익슈 스티븐 정, 아담스 웨이위, 신잉송, 데니 저우 등이다. 2023. 대규모 언어 모델은 아직 자기정정적 추론이 불가능하다. _ arXiv preprint arXiv:2310.01798_.\n' +
      '* Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. 대형 언어 모델들은 제로 샷 추론기들이다. _ 신경 정보 처리 시스템들_, 35:22199-22213의 진보들.\n' +
      '* Li 등(2023a) Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, 및 Ziwei Liu. 2023a. Otter: in-context 명령어 튜닝을 갖는 멀티모달 모델. _ arXiv preprint arXiv:2305.03726_.\n' +
      '* Li et al. (2023b) Juncheng Li, Kaihang Pan, Zhiqi Ge, Minghe Gao, Hanwang Zhang, Wei Ji, Wenqiao Zhang, Tat-Seng Chua, Siliang Tang, and Yueting Zhuang. 2023b. 제로샷 지시사항을 따르도록 멀티모달 lllms를 미세 조정합니다. _ arXiv preprint arXiv:2308.04152_, 3.\n' +
      '* Li et al. (2023c) Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. 2023c. Blip-2: 냉동 이미지 인코더 및 대형 언어 모델을 사용한 부트스트래핑 언어-이미지 프리트레이닝 arXiv preprint arXiv:2301.12597_.\n' +
      '* Liang et al. (2023) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi. 2023. 멀티 에이전트 토론을 통한 대규모 언어 모델에서의 발산적 사고 장려. _ arXiv preprint arXiv:2305.19118_.\n' +
      '* Liu et al. (2023a) Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. 2023a. 시각적 지시 조정을 통해 개선된 기준선입니다. _ arXiv preprint arXiv:2310.03744_.\n' +
      '* Liu et al. (2023b) Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023b. 시각적 지시 조율 arXiv preprint arXiv:2304.08485_.\n' +
      '* Liu and Chen(2023) Mengchen Liu and Chongyan Chen. 2023. 온라인 vqa. _ arXiv preprint arXiv:2312.10637_.\n' +
      '* Lu et al. (2022) Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. 2022. 설명하기 위한 학습: 과학 질문 답변을 위한 사고 체인을 통한 멀티모달 추론_ 신경 정보 처리 시스템_, 35:2507-2521의 발전.\n' +
      '* Lu et al. (2023) Yujie Lu, Xiujun Li, William Yang Wang, and Yejin Choi. 2023. Vim: Probing multimodal large language models for visual embedded instruction follow. _ arXiv preprint arXiv:2311.17647_.\n' +
      '* Madan et al. (2023) Aman Madan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. 2023. Self-refine: Self-feedback을 이용한 반복적 정제; _ arXiv preprint arXiv:2303.17651_.\n' +
      '* McGrath et al. (2022) Thomas McGrath, Andrei Kapishnikov, Nenad Tomasev, Adam Pearce, Martin Wattenberg, Demis Hassabis, Been Kim, Ulrich Paquet, and Vladimir Kramnik. 2022. 알파제로 체스 지식의 획득. _ Proceedings of the National Academy of Sciences_, 119(47):e2206625119.\n' +
      '* 메릴과 사바왈(2023) 윌리엄 메릴과 애쉬 사바왈. 2023. 사상체인을 갖는 변압기의 표현력 _ arXiv preprint arXiv:2310.07923_.\n' +
      '* Mitra et al. (2023) Chancharik Mitra, Brandon Huang, Trevor Darrell, and Roei Herzig. 2023. 대형 멀티모달 모델에 대한 구성 체인-생각 프롬프트. _ arXiv preprint arXiv:2311.17076_.\n' +
      '* Mukherjee et al. (2023) Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023. Orca: Progressive learning from complex explanation trace of gpt-4. _arXiv preprint arXiv:2306.02707_.\n' +
      '* Munzar et al. (2021) Brendan Munzar, Krista R Muis, Courtney A Denton, and Kelsey Losenno. 2021. 초등학생의 수학 문제 해결 시 나침반에 대한 인지적, 정의적 반응 Journal of Educational Psychology_, 113(1):104.\n' +
      '* OpenAI(2023) OpenAI. 2023. Gpt-4 기술 보고서\n' +
      '* Owens and Efros (2018) Andrew Owens and Alexei A Efros. 2018. 자체 감독 다중 감각 기능을 가진 시청각 장면 분석. 유럽회의의 _Proceedings on computer vision (ECCV)_, pages 631-648.\n' +
      '* Peng et al. (2023) Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and Furu Wei. 2023. Kosmos-2: Grounding multimodal large language models to world. _ arXiv preprint arXiv:2306.14824_.\n' +
      '* Ruoss et al. (2024) Anian Ruoss, Gregoire Deletang, Sourabh Medapati, Jordi Grau-Moya, Li Kevin Wenliang, Elliot Catt, John Reid, and Tim Genewein. 2024. 검색 없는 그랜드마스터급 체스 arXiv preprint arXiv:2402.04494_.\n' +
      '* Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, and Shunyu Yao. 2023. 반사: 언어 강화 학습을 갖는 언어 에이전트. IMT-2000 3GPP-신경정보처리시스템에 관한 제37차 회의\n' +
      '* Team et al. (2023) Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023. Gemini: High capable multiimodal model의 가족. _ arXiv preprint arXiv:2312.11805_.\n' +
      '* Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. 개방적이고 효율적인 기초 언어 모델 arXiv preprint arXiv:2302.13971_.\n' +
      '\n' +
      'Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajwal Bhargava, Shruti Bhosale, et al. 2023b. 라마 2: 오픈 파운데이션 및 미세 조정 채팅 모델들_ arXiv preprint arXiv:2307.09288_.\n' +
      '* Wang et al. (2023a) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, 및 Ee-Peng Lim. 2023a. 계획 및 해결 프롬프트: 대규모 언어 모델에 의한 제로 샷 사고 연쇄 추론 개선 arXiv preprint arXiv:2305.04091_.\n' +
      '* Wang et al. (2023b) Weihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Hong, Ji Qi, Yan Wang, Junhui Ji, Zhuoyi Yang, Lei Zhao, Xixuan Song, et al. 2023b. Cogylm: 사전 훈련된 언어 모델에 대한 시각적 전문가__ arXiv preprint arXiv:2311.03079_.\n' +
      '* Wang et al. (2022a) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022a. 자기일관성은 언어모델에서 사고추론의 연쇄를 향상시킨다. _ arXiv preprint arXiv:2203.11171_.\n' +
      '* Wang et al. (2022b) Yizhong Wang, Yeganek Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022b. 자가 명령어: 언어 모델을 자가 생성된 명령어와 정렬합니다. _ arXiv preprint arXiv:2212.10560_.\n' +
      '* Wang et al. (2023c) Ziyue Wang, Chi Chen, Peng Li, and Yang Liu. 2023c. vqa에 대한 이미지 정보 갭을 채우는 단계: 대형 언어 모델들이 사전적으로 질문들을 하도록 프롬프트하는 단계. _ arXiv preprint arXiv:2311.11598_.\n' +
      '* Wei et al. (2023) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-thought prompting은 큰 언어 모델에서 추론을 이끌어낸다.\n' +
      '* Weininger (1988) David Weininger. 1988. Smiles, chemical language and information system. 1. introduction to methodology and encoding rules. _ Journal of chemical information and computer sciences_, 28(1):31-36.\n' +
      '* Winter et al. (2022) Benedikt Winter, Clemens Winter, Johannes Schilling, and Andre Bardow. 2022. 미소만 있으면 된다 : 자연어 처리로 미소로부터 제한 활동 계수를 예측한다. _ Digital Discovery_, 1(6):859-869.\n' +
      '* Wu and Xie (2023) Penghao Wu and Saining Xie. 2023. V\\({}^{*}\\): 멀티모달 llms에서 핵심 메커니즘으로서 유도 시각 탐색. _ arXiv preprint arXiv:2312.14135_.\n' +
      '* Wu et al. (2023a) Yang Wu, Shilong Wang, Hao Yang, Tian Zheng, Hongbo Zhang, Yanyan Zhao, and Bing Qin. 2023a. gpt-4v(ision)의 조기 평가. arXiv preprint arXiv:2310.16534_.\n' +
      '* Wu et al. (2023b) Yifan Wu, Pengchuan Zhang, Wenhan Xiong, Barlas Oguz, James C Gee, and Yixin Nie. 2023b. 복잡한 시각언어 추론과제에 있어서 사고 사슬의 역할 arXiv preprint arXiv:2311.09193_.\n' +
      '* Xie et al. (2023) Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, et al. 2023. Openagents: the open platform for language agents in wild. _ arXiv preprint arXiv:2310.10634_.\n' +
      '*Xiong et al. (2023) Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, and Bing Qin. 2023. 대규모 언어 모델 협업의 상호 일치성 검토: 토론을 통한 심층 분석. _Findings of the Association for Computational Linguistics: EMNLP 2023_, pages 7572-7590.\n' +
      '* Yang et al. (2018) Jianwei Yang, Jiasen Lu, Stefan Lee, Dhruv Batra, and Devi Parikh. 2018. Graph r-cnn for scene graph generation. 유럽회의의 _Proceedings on computer vision (ECCV)_에서, 페이지 670-685.\n' +
      '* Yang et al. (2023a) Kaiwen Yang, Tao Shen, Xinmei Tian, Xiubo Geng, Chongyang Tao, Dacheng Tao, and Tianyi Zhou. 2023a. 좋은 질문은 제로샷 이미지 추론에 도움이 됩니다. _ arXiv preprint arXiv:2312.01598_.\n' +
      '* Yang et al. (2023b) Zhen규안 Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Chung-Ching Lin, Zicheng Liu, and Lijuan Wang. 2023b. lms의 새벽: gpt-4v(ision)를 이용한 예비 탐구. _ arXiv preprint arXiv:2309.17421_, 9(1).\n' +
      '* Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. 반응: 추론과 언어 모델에서의 연기의 시너지 효과 _ arXiv preprint arXiv:2210.03629_.\n' +
      '* Ye et al. (2023) Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, et al. 2023. mplug-owl: Modularization empowers large language models with multimodality. _ arXiv preprint arXiv:2304.14178_.\n' +
      '* Zaavy et al.(2023) Tom Zaavy, Vivek Veeriah, Shaobo Hou, Kevin Waugh, Matthew Lai, Edouard Leurent, Nenad Tomasev, Lisa Schut, Demis Hassabis, and Satinder Singh. 2023. 다양화 ai: 알파제로를 가진 창의적인 체스를 향하여 _ arXiv preprint arXiv:2308.09175_.\n' +
      '* Zhang et al. (2024) Daoan Zhang, Junming Yang, Hanjia Lyu, Zijian Jin, Yuan Yao, Mingkai Chen, 및 Jiebo Luo. 2024. CocoT: 다중 이미지 입력을 갖는 대형 멀티모달 모델에 대한 대비 체인-of-thought 프롬프트. _ arXiv preprint arXiv:2401.02582_.\n' +
      '* Zhang et al. (2023a) Renrui Zhang, Jiaming Han, Aojun Zhou, Xiangfei Hu, Shilin Yan, Pan Lu, Hongsheng Li, Peng Gao, and Yu Qiao. 2023a. Llama-adapter: zero-init attention을 갖는 언어 모델의 효율적인 미세 조정. _ arXiv preprint arXiv:2303.16199_.\n' +
      '* Zhang et al. (2023b) Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. 2023b. 언어 모델에서의 다중모달 사고 연쇄 추론 arXiv preprint arXiv:2302.00923_.\n' +
      '* Zhao et al. (2023) Haozhe Zhao, Zefan Cai, Shuzheng Si, Xiaojian Ma, Kaikai An, Liang Chen, Zixuan Liu, Sheng Wang, Wenjuan Han, 및 Baobao Chang. 2023년\n' +
      '\n' +
      'Mmicl: Multi-modal in-context learning으로 Vision-language 모델을 Empowering arXiv preprint arXiv:2309.07915_.\n' +
      '* Zheng et al. (2023) Ge Zheng, Bin Yang, Jiajin Tang, Hong-Yu Zhou, Sibei Yang. 2023. Ddcot: Duty-distinct chain-of-thought prompt for multimodal reasoning in language models. _ arXiv preprint arXiv:2310.16436_.\n' +
      '* Zhou et al. (2022) Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. 2022. 최하위 프롬핑은 큰 언어 모델에서 복잡한 추론을 가능하게 한다. _ arXiv preprint arXiv:2205.10625_.\n' +
      '* Zhu et al. (2023) Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023. Minigpt-4: 고급 대형 언어 모델로 비젼-언어 이해력 향상. _ arXiv preprint arXiv:2304.10592_.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:13]\n' +
      '\n' +
      '접근은 두 체인 간의 불일치를 정확하게 식별할 수 있다. 이 식별 프로세스는 후속적으로 최종 솔루션을 합성하기 위해 활용된다.\n' +
      '\n' +
      '그림 3: 카테고리 주석에 사용된 프롬프트의 그림입니다.\n' +
      '\n' +
      '당신의 과제는 특정한 \\(<\\)문제, \\(>\\)쌍을 분석하고, 그것을 용액 프로세스에서 절대적으로 중요한 단계 1 또는 2로 증류하는 것이다. 이러한 단계를 식별하여 문자열의 파이썬 리스트로 제시해야 한다. 당면한 문제 해결의 가장 중요한 부분을 고립시키는 데 집중하세요. 중요한 단계의 본질은 해결책에서 중추적인 역할에 있다는 것을 기억하세요: 그것은 정답에 도달하기 위해 핵심 통찰력, 결정 또는 특정 방법의 적용이 필수적인 곳입니다. 이것은 일반적으로 주요 개념적 돌파구, 정리의 전략적 구현 또는 솔루션의 방향을 크게 결정하는 결정적인 계산을 포함한다.\n' +
      '\n' +
      '문제의 복잡성을 감안할 때 식별을 한 두 단계만 제한하십시오. 일반적이거나 덜 영향을 미치는 단계를 피하십시오. 각 문자열이 솔루션 성공의 기본이 되는 단계를 간결하게 캡슐화하도록 다음 파이썬 목록 형식으로 결과를 제시합니다.\n' +
      '\n' +
      '```\n' +
      '\'python["most_critical_step_1", "most_critical_step_2"# 꼭 필요한 경우에만 포함한다...\n' +
      '```\n' +
      '\n' +
      '목록의 각 문자열은 문제를 효과적으로 해결할 수 없는 단계의 명확하고 간결한 표현이어야 하며, 전반적인 문제 해결 과정에서 그 중요성을 강조한다.\n' +
      '\n' +
      '```\n' +
      '문제:{문제}해결:{해결}출력:\'\'python\n' +
      '```\n' +
      '\n' +
      '그림 4: 중요한 단계 식별을 위해 사용된 프롬프트의 그림.\n' +
      '\n' +
      '특정 문제와 그 중요한 단계와 관련하여 제공된 예측 답변을 분석하는 작업을 수행합니다. 분석을 위해 다음 단계를 수행합니다.\n' +
      '\n' +
      '1. **예측된 답변을 분해함**: 예측된 답변을 별개의 단계로 분해함 새로운 콘텐츠를 도입하지 않고 기존의 모든 정보를 유지할 수 있도록 주의한다.\n' +
      '2. **평가 및 문서화 각 단계**: 식별된 각 단계에 대해 엄격하고 포괄적인 평가를 수행한다. 문제 해결 과정에서 중요한 단계와의 관계를 바탕으로 각 단계를 범주를 할당한다. 각 중요 단계에 대해 숫자 1, 2, 3, …, N을 사용하고 N은 전체 중요 단계의 수입니다. 단계가 중요한 단계와 관련이 없는 경우 0으로 표시하십시오.\n' +
      '3. **결과 형식**: 평가를 사전의 파이썬 목록으로 구성하며, 각각은 단계: - "단계": 평가되는 단계를 나타낸다. - "분류": 단계의 카테고리 번호.\n' +
      '\n' +
      '예시 출력 포맷:\n' +
      '\n' +
      '"python\n' +
      '\n' +
      '[{  "step": "step_1",  "classification": 2, },  {  "step": "step_2",  "classification": 0, },...  ] ] ] ] ]\n' +
      '\n' +
      'Problem: {problem}\n' +
      '\n' +
      'Solution: {solution}\n' +
      '\n' +
      '임계 단계: {critical_steps}\n' +
      '\n' +
      'Output: "python\n' +
      '\n' +
      '그림 5: 생성된 솔루션 내에서 각 단계를 분류하는 데 사용되는 프롬프트의 그림.\n' +
      '\n' +
      'System Instruction:\n' +
      '\n' +
      '기하학 문제를 해결하는 것을 중심으로 한 역할극 활동에 뛰어들어 보자. 당신은 각각 해결 과정에 기여하는 두 학생과 한 교사의 역할을 맡게 될 것이다. 다음 단계를 엄격하게 준수하고 전체적으로 동일한 형식을 유지하십시오.\n' +
      '\n' +
      '1. **학생 A로부터의 해결책(코드 기반):**학생 A는 그의 해결책의 기초를 형성할 코드로부터 지지 사실을 식별하고 추출하기 위해 구조화된 접근법을 적용하는 것으로 시작해야 한다. 이 과정은,\n' +
      '\n' +
      '(1) 학생 A는 특정 기하학적 속성을 나타내는 \'(x,y)\'와 같은 좌표, 기하학적 모양과 도형(예를 들어, 원을 그리는(원(...))\', 선분을 그리는(A-B), 레이블(예를 들어, \'라벨("A", (x,y),...)) 및 \'직각마크(...)\'와 같은 마커를 찾아야 한다. 그는 또한 지정된 길이나 각도 측정을 기록해야 한다.\n' +
      '\n' +
      '(2) 그는 기본적인 기하학적 개념을 이해하고 좌표와 도형을 사용하여 도형의 구조를 이해할 필요가 있다. 예를 들어, 세 점의 좌표는 그들이 형성하는 삼각형을 추론하는 데 도움이 될 수 있다.\n' +
      '\n' +
      '(3) 레이블은 정점 또는 중심과 같은 핵심 요소에 해당하며, 마커는 직각 또는 평행선과 같은 속성을 나타낸다. 이것들은 수치를 이해하는 데 중요하다.\n' +
      '\n' +
      '(4) 길이들 또는 각도들이 특정되면, 이러한 측정들은 도면의 상이한 부분들 사이의 관계들을 이해하는데 이용되어야 한다.\n' +
      '\n' +
      '(5) 학생 A는 좌표, 레이블 및 측정으로부터 정보를 합성해야 하며, 예를 들어 삼각형을 추론하는 것과 같이 두 변을 동일한 길이로 레이블링하면 이등변이다.\n' +
      '\n' +
      '좌표, 기하학적 형상, 라벨, 마커 및 측정을 포함하는 이러한 지원 사실을 식별하고 요약한 후, 학생 A는 그의 솔루션의 각 단계가 이러한 사실과 정렬되거나 이전에 확립된 단계로부터 논리적으로 뒤따르는 것을 보장해야 한다. 그의 대답은 기하학적 관계와 정밀한 측정에 초점을 맞춘 무증상 코드에서 추출된 사실들이 논리적으로 최종 해법으로 어떻게 이어지는지를 명확하게 보여주어야 한다.\n' +
      '\n' +
      '2. **학생 B로부터의 해결책(그림-기반):**학생 B는 도면에 묘사된 내용을 그의 주요 참조로서 명시적으로 다시 표현함으로써 그의 해결책 프로세스를 개시해야 한다. 그런 다음 그는 완전히 독립적이고 다른 접근법에 대한 자신의 약속을 구체적이고 명확하게 선언해야 한다. 그는 자신의 풀이가 새롭고 독특한 관점을 약속하면서 학생 A가 사용하는 어떤 결론, 공식 또는 중간 단계를 참조하거나 의존하지 않을 것임을 단언해야 한다. 대체 방법론에 대한 이러한 헌신은 그의 분석의 각 단계에서 적극적으로 반복되고 분명해야 한다.\n' +
      '\n' +
      '그림을 인정한 후 학생 B는 그에 고유한 구체적인 뒷받침 사실을 명시적으로 확인하고 정리하도록 하고 있다. 그는 학생 A가 사용하는 공식이나 방법과 직접적인 관련이 없는 시각적 패턴, 공간적 관계 또는 유사성과 비례성의 원리와 같은 측면에 초점을 맞추어야 한다. 그는 이러한 도형 특유의 통찰에서 논리적으로 도출될 수 있는 다른 접근 방식이나 추론 라인을 사용하여 해결책을 개발해야 한다.\n' +
      '\n' +
      '양적 분석에서 각 중간 단계를 공식화하기 전에 학생 B는 명시적으로 재평가하고 접근법이 학생 A와 독립적일 뿐만 아니라 방법론적으로 다르다는 것을 보장하기 위해 일시 중지해야 한다. 이 재평가는 접근, 원리의 적용 또는 그림의 해석 측면에서 현재 단계와 전반적인 추론 과정이 학생 A의 방법론과 어떻게 다른지에 대한 비판적 성찰을 수반해야 한다. 그는 이 확인 후 다음 단계로만 진행해야 하며, 그의 솔루션의 각 부분이 자신의 독립적인 분석과 그림에 대한 독특한 이해를 뚜렷하게 반영하도록 해야 한다.\n' +
      '\n' +
      '3. **솔루션 비교(교사 분석):** 이제 교사의 역할을 맡아 학생 A와 학생 B의 도출된 솔루션을 비교해야 한다. 최종 답변과 그들이 사용한 방법의 차이를 정확히 지적하고 요약하는 데 중점을 두어야 한다.\n' +
      '\n' +
      '4. **최종 해결방안(선생님의 결론):** 교사로서 이전 단계에서 확인된 불일치를 해결하여 최종적이고 정확한 해결방안을 개발한다. 귀하의 솔루션은 포괄적이고 명확하게 제시되어야 합니다.\n' +
      '\n' +
      'LaTeX에서 어떠한 단위도 없이 \'\\(\\backslash\\)boxed\\(\\{\\}}\\\'을 사용하여 최종 결과를 제시하는 것이 중요하다.\n' +
      '\n' +
      '그림 6: 기하학 문제 해결을 위한 시스템 수업.\n' +
      '\n' +
      '## System Instruction:\n' +
      '\n' +
      '이 작업은 두 가지 별개의 관점에서 체스 위치를 분석하는 것을 포함한다: 하나는 FEN 표기법을 기반으로 하고 다른 하나는 보드의 시각적 표현(그림)을 기반으로 한다. 목적은 이 두 가지 관점에서 세부적이고 단계별 다양한 솔루션을 개발한 다음 이러한 결과를 체계적으로 응집력 있는 최종 평가로 종합하는 것이다. 이 프로세스는 포지션에 대한 포괄적인 이해를 보장하기 위해 FEN 기반 분석과 도형 기반 분석 간의 불일치를 신중하게 해결하고 조정하는 것을 포함한다.\n' +
      '\n' +
      '## 6.2 Analyst B로부터의 분석(그림-Based):\n' +
      '\n' +
      '**시각적 평가**: 시각 패턴, 조각 이동성 및 키 사각형의 제어에 초점을 맞추어 체스판 피규어를 독립적으로 분석합니다.\n' +
      '\n' +
      '**포지션 다이나믹스 및 전술 인사이트**: 잠재적인 위협과 전략적 기회를 포함한 포지션의 다이나믹스를 피규어 기반 관점에서 평가합니다.\n' +
      '\n' +
      '사상의 결론**: 시각적 분석이 FEN 기반 분석과 어떻게 정렬되거나 분기되는지를 반영하여 포지션의 균형 또는 이점에 대한 결론을 도출합니다.\n' +
      '\n' +
      '**비교 분석(심판의 합성)**\n' +
      '\n' +
      '**관점의 조정**: 불일치 또는 합의 영역에 초점을 맞추어 두 분석가의 결론을 비교합니다.\n' +
      '\n' +
      '** 통찰력의 합성**: 각 관점이 전체 입장을 이해하는 데 어떻게 기여하는지 고려하여 두 분석 모두에서 통찰력을 통합합니다.\n' +
      '\n' +
      '**결정적 판단**: FEN 기반 및 도형 기반 분석 모두의 통찰력을 고려하여 위치의 전반적인 균형에 대한 결정적인 판단을 내립니다.\n' +
      '\n' +
      '**최종 평가(심판의 상세한 결론):**\n' +
      '\n' +
      '**단계별 분석**: 상세하고 단계별 분석을 수행하여 다양한 솔루션을 합성하고 FEN 기반 관점과 도형 기반 관점 간의 불일치를 해결합니다.\n' +
      '\n' +
      '**종합 결론**: 포지션에 대한 최종적이고 포괄적인 평가를 제공하고, 두 관점에서의 통찰력을 통합하고 포지션의 이점에 대한 명확한 판단을 내린다.\n' +
      '\n' +
      '**명확한 진술**: 화이트의 이점을 위해 "상자ed{1}\', 블랙의 이점을 위해 "상자ed{2}\', 또는 균형 잡힌 위치를 위해 "상자ed{3}\'를 사용하여, 포지션의 이점에 관한 확정적이고 형식화된 진술로 포함\n' +
      '\n' +
      '도 7. 체스 위치 이점 예측을 위한 시스템 명령어.\n' +
      '\n' +
      'System Instruction:\n' +
      '\n' +
      '화합물 분석 문제 해결을 중심으로 한 역할극 활동에 뛰어들어 보자. 당신은 각각 해결 과정에 기여하는 두 학생과 한 교사의 역할을 맡게 될 것이다. 다음 단계를 엄격하게 준수하고 전체적으로 동일한 형식을 유지하십시오.\n' +
      '\n' +
      '1. **학생 A로부터의 분석(SMILES-Based):**학생 A는 SMILES 표현으로부터 지지 사실을 식별하고 추출하기 위한 구조화된 접근법을 적용하여 시작해야 하며, 이는 그의 솔루션의 기초를 형성할 것이다. 이 과정은,\n' +
      '\n' +
      '(1) 작용기(예를 들어, 니트로기) 및 분자 프레임워크(예를 들어, 벤젠 고리)와 같은 SMILES 표현에서 중요한 구조적 특징을 인식한다.\n' +
      '\n' +
      '(2) 확인된 구조적 요소를 돌연변이 유발 또는 비 돌연변이 유발 결과를 식별하기 위한 참조 포인트 역할을 하는 분자 구조-표적 상관관계의 예시적인 예에서와 비교한다. 돌연변이원성 - c1ccc2c(c1)ccc3c2ccc(c3)[N+](=O)[O-], 비돌연변이원성 - c1ccc2ccc2c(c1)[N+][=O)[O-], 비돌연변이원성 - c1ccc2c(cccn2)c(c1)[N+](=O)[O-], 비돌연변이원성 - c1ccc2c(c1)c3ccc4c3c2c(cc4)[N+](=O)[O-], 돌연변이원성 - c1ccc2c(c1)c3ccc3c2c(cc4)[N+](=O)[O-]로 동정되었다. 이것은 화합물의 구조가 특히 살모넬라 티피무륨의 돌연변이를 유발하는 것과 관련하여 생물학적 시스템과의 상호작용에 어떻게 영향을 미칠 수 있는지 분석하는 것을 포함한다.\n' +
      '\n' +
      '화합물의 구조적 요소, 작용기, 분자 구성 및 돌연변이 유발성과의 상관관계를 포함하는 이러한 지원 사실을 식별하고 요약한 후, 스튜던트 A는 솔루션의 각 단계가 이러한 사실과 정렬되거나 이전에 확립된 단계에서 논리적으로 따르도록 해야 한다. 그의 대답은 주요 구조적 요소와 예시적인 사례와의 비교를 중심으로 SMILES 표현에서 추출된 사실이 논리적으로 최종 해결책으로 이어지는 방법을 명확하게 입증해야 한다.\n' +
      '\n' +
      '2. **학생 B로부터의 분석(그림-기반):** 그림을 인정한 후 학생 B는 이에 고유한 구체적인 뒷받침 사실을 명시적으로 확인하고 요약할 것을 요구한다. 그는 원자의 공간적 배열, 작용기의 시각적 표현, 분자 구조의 전체적인 기하학과 같은 측면에 초점을 맞추어야 한다. 학생 A가 사용하는 공식이나 방법과 직접적인 관련이 없는 이러한 측면은 뚜렷한 관점을 제공한다. 또한, 학생 B는 돌연변이 유발 - c1ccc2c(c1)ccc3c2ccc(c3)[N+](=O)[O-], 비돌연변이 유발 - c1ccc2ccc2c(c1)[N+](=O)[O-], 비돌연변이 유발 - c1ccc2c(c1)c(c1)[N+](=O)[O-], 비돌연변이 유발 - c1ccc2c(c1)c3ccc4c3c2c(cc4)[N+](=O)[O-]와 같은 분자 구조-표적 상관관계의 예시적인 사례를 사용하여 돌연변이 유발 또는 비돌연변이 유발 결과와 특정 분자 구성이 어떻게 연관되어 있는지 입증하고 분석에 중요한 참고 자료가 되어야 한다. 학생 B는 이러한 도형 특이적 통찰력과 제공된 분자 구조 표적 예제에서 논리적으로 도출할 수 있는 다른 접근법 또는 추론 라인을 사용하여 솔루션을 개발해야 한다.\n' +
      '\n' +
      '양적 분석에서 각 중간 단계를 공식화하기 전에 학생 B는 명시적으로 재평가하고 접근법이 학생 A와 독립적일 뿐만 아니라 방법론적으로 다르다는 것을 보장하기 위해 일시 중지해야 한다. 이 재평가는 접근, 원리의 적용 또는 그림의 해석 측면에서 현재 단계와 전반적인 추론 과정이 학생 A의 방법론과 어떻게 다른지에 대한 비판적 성찰을 수반해야 한다. 그는 이 확인 후 다음 단계로만 진행해야 하며, 그의 솔루션의 각 부분이 자신의 독립적인 분석과 그림에 대한 독특한 이해를 뚜렷하게 반영하도록 해야 한다.\n' +
      '\n' +
      '3. **비교분석(Teacher\'s Synthesis):** 이제 교사의 역할을 맡아 학생 A와 학생 B의 도출된 해법을 비교해야 한다. 최종 답변과 그들이 사용한 방법의 차이를 정확히 지적하고 요약하는 데 초점을 두어야 한다.\n' +
      '\n' +
      '4. **최종 평가(교원의 세부 결론):** 교사로서 이전 단계에서 확인된 불일치를 해결하여 최종적이고 정확한 해결책을 개발한다. 귀하의 솔루션은 포괄적이고 명확하게 제시되어야 합니다.\n' +
      '\n' +
      '라텍스에서 화합물의 돌연변이 유발성에 대한 최종 결과를 제시하기 위해서는 돌연변이 유발성에는 \'\\boxed{1}\', 비돌연변이 유발성에는 \'\\boxed{2}\'를 사용한다.\n' +
      '\n' +
      '그림 8: 분자 특성 예측을 위한 시스템 명령어.\n' +
      '\n' +
      '## 6 Conclusion\n' +
      '\n' +
      '그림 9: 사례 연구 1: 기하학 문제 해결.\n' +
      '\n' +
      '### Problem:\n' +
      '\n' +
      '단위 원의 중심은 $(5,0)$이고 반지름이 S2$인 두 번째 원의 중심은 그림과 같이 $(11,0)$이다. 원들에 대한 공통 내부 접선은 $Q(a,0)$에서 S$ 축과 교차한다. S$.$의 가치는 얼마입니까?\n' +
      '\n' +
      '[any]\n' +
      '\n' +
      'draw((-2,0)-(15,0),Arrows);\n' +
      '\n' +
      'draw((0,-4)-(0,5),Arrows);\n' +
      '\n' +
      'draw(Circle((5,0),1));\n' +
      '\n' +
      'draw(Circle((11,0),2));\n' +
      '\n' +
      'dot((5,0));\n' +
      '\n' +
      'dot((7,0));\n' +
      '\n' +
      'dot((1,10));\n' +
      '\n' +
      'lsealscale(0.7*Label("5,0)",(3,0),S));\n' +
      '\n' +
      'lseals("Q","(7,0),N);\n' +
      '\n' +
      'lseals(scale(0.7*Label("\\(\\backslash\\)"11,0)",(11,0),S));\n' +
      '\n' +
      'lseals("S"S",(15,0));\n' +
      '\n' +
      'lseals("S"S","(5,0),N);\n' +
      '\n' +
      'draw((1,3.46410162)-(14,-4,04145188),Arrows);\n' +
      '\n' +
      '[asy]\n' +
      '\n' +
      '### 솔루션: Student A(Code-Based):\n' +
      '\n' +
      '무증상 코드와 주어진 그림에서 우리는 다음과 같은 지지 사실을 추출할 수 있다.\n' +
      '\n' +
      '두 개의 원이 있는데, 하나는 $(5,0)$의 중심과 단위 반지름이고, 다른 하나는 $(11,0)$의 중심과 S2$ 단위의 반지름이다.\n' +
      '\n' +
      '공통 내부 접선은 점 Q(a,0)$에서 S$ 축과 교차한다.\n' +
      '\n' +
      '두 원의 중심 사이의 거리는 S11 - 5 = 68 단위이다.\n' +
      '\n' +
      'S$의 값을 구하기 위해 우리는 원에 대한 접선의 성질과 원의 중심, 접선의 점, 점의 SQS에 의해 형성된 직각삼각형을 사용할 수 있다.\n' +
      '\n' +
      '작은 원과 큰 원의 접선점을 각각 ST 1$와 ST 2$로 나타내자. 접선은 접선의 지점에서 반지름에 수직이기 때문에, 우리는 두 개의 직각 삼각형, 즉 Striangle QT_(15,0)$와 Striangle QT_(11,0)$를 가진다.\n' +
      '\n' +
      '이 직각 삼각형들에 대한 피타고라스 정리를 사용하여, 우리는 다음 방정식들을 설정할 수 있다:\n' +
      '\n' +
      'Striangle QT_(15,0)$: {(a - 1)^2}+y^2 - 2^2|\n' +
      '\n' +
      '두 직각 삼각형은 같은 수직 높이 S$를 공유하기 때문에, 우리는 Sy\'2$에 대한 두 식을 동일시하고 S$에 대해 풀 수 있다:\n' +
      '\n' +
      '(a-5)^2}+y^2-(a-1)^2}+y^2|\n' +
      '\n' +
      'a - \\(\\circ\\))^2}+y^2-(a - 1)^2}+y^2|\n' +
      '\n' +
      '따라서 S$의 값은 S.2$이다.\n' +
      '\n' +
      '**학생 B로부터의 솔루션(그림 기반):**\n' +
      '\n' +
      '나는 제공된 수치를 인정하며 이제 학생 A의 접근법과 완전히 독립적이고 다른 해결책을 진행할 것이다. 나는 학생 A가 사용한 결론, 공식 또는 중간 단계에 의존하지 않는 다른 추론 라인을 사용하는 데 전념한다.\n' +
      '\n' +
      '그림을 살펴보면 다음과 같은 근거 사실을 알 수 있다.\n' +
      '\n' +
      '접선은 점 SQS에서 S$축과 교차하며 접선점에서 원의 반지름과 직각을 이룬다.\n' +
      '\n' +
      '두 원의 중심과 접선을 잇는 선분은 SQS에서의 공통각과 접선점에서의 직각으로 인해 한 쌍의 유사한 직각삼각형을 이룬다.\n' +
      '\n' +
      '유사성과 비례성의 원리를 이용하여 유사 삼각형의 대응 변의 비율을 바탕으로 해법을 개발하겠다.\n' +
      '\n' +
      '작은 원의 중심에서 SQS까지의 거리를 S\\(\\_\\)1$로, 큰 원의 중심에서 SQS까지의 거리를 S\\(\\_\\)2$로 나타내자. 두 원의 반지름의 비율은 S12$이며, 이는 S\\(\\_\\)1$의 비율과 같아야 한다. S\\(\\\\)d\\(\\\\)1$에서. S\\(\\\\)d\\(\\\\)2$에서.\n' +
      '\n' +
      '원의 중심 사이의 거리는 S6$ 단위이므로, 우리는 S\\(\\\\)2$를 S\\(\\\\)1 + 6$로 표현할 수 있다. 이제, 비율 설정:\n' +
      '\n' +
      '\\(\\{\\) ifrac(11\\(2)\\(-\\)\n' +
      '\n' +
      '## Problem:\n' +
      '\n' +
      '체스판 그림과 제공된 FEN 표기법을 기반으로 현재 위치를 평가한다. 1) 화이트에 유리해, 2) 블랙에 유리해, 3) 밸런스야?\n' +
      '\n' +
      'FEN notation:\n' +
      '\n' +
      'mb1kbm/pp2pppp/8/2p5/4P3/SN2/PPP2PPP/RNBK1B1Rb kq - 0 5"이다. 이 FEN은 블랙이 움직일 차례임을 나타낸다. 왕측 주조권은 양측에게 상실되었지만 양측은 소강된 주조권을 유지하고 있다. 합격으로 체포될 가능성은 없다. 무브 넘버는 5로 아직 개막 단계임을 알 수 있다.\n' +
      '\n' +
      '물질 균형과 위치 요소: 물질은 짝짝이이며, 양쪽은 FEN과 누락된 캐슬 권리를 고려할 때 거래되었을 것으로 추정되는 누락된 킹사이드 룩을 제외하고 모든 조각을 가지고 있다. 흑왕은 왕측 까마귀가 없어 다소 노출되지만, 백왕도 중앙집권화되어 안전성이 다소 결여되어 있다. 화이트는 e4에 있는 폰과 d4의 잠재력으로 중심을 더 잘 제어할 수 있다. f3에 있는 화이트의 기사는 개발되었지만 블랙의 조각은 아직 활성화되지 않았다. FEN 기술에는 즉각적인 전술적 모티프가 없지만 화이트의 개발 및 중앙 통제 주도권은 곧 전술적 기회로 이어질 수 있다.\n' +
      '\n' +
      '사상의 결론: 화이트는 중앙의 더 나은 통제와 개발의 주도 때문에 약간의 위치적 이점을 가지고 있는 것으로 보인다. 그러나 이 장점은 재료가 균일하고 즉각적인 위협이 없기 때문에 중요하지 않다.\n' +
      '\n' +
      '분석가 B의 분석(그림 기반):\n' +
      '\n' +
      '시각적 평가: 시각적 표현은 양쪽이 왕가의 성에 대한 능력과 함께 h1 및 h8 룩을 잃었다는 것을 보여준다. 흑인의 왕은 h8에서 까마귀 없이 약간 더 취약해 보이며, 흰색은 e4에 중앙 졸이 있고 f3에 발달된 기사가 있어 중앙에 대한 더 많은 통제를 시사한다.\n' +
      '\n' +
      '위치 역학 및 전술 통찰력: 보드에는 즉각적인 핀, 포크 또는 꼬치가 보이지 않습니다. 화이트의 왕은 중앙집권화되어 있어 부채가 될 수 있지만, 많은 조각들이 이사회에 있기 때문에 블랙이 이를 이용할 수 있는 즉각적인 방법은 없을 수 있다. 흑인은 개발을 따라잡아야 하지만 구조적인 약점은 없다.\n' +
      '\n' +
      '사상의 결론: 그 입장은 개발과 중앙 통제에 기초한 화이트에 대한 약간의 가장자리와 거의 균형을 이루는 것처럼 보인다. 그러나 두 왕의 안전을 고려해야 하며 블랙이 움직임을 가지고 있어 잠재적으로 빠른 후속 개발이 가능할 수 있다.\n' +
      '\n' +
      '분석(심판의 합성)을 비교하는 단계:\n' +
      '\n' +
      '관점의 조정: FEN 기반 분석과 도형 기반 분석 모두 재료가 동일하고 게임이 아직 초기 단계에 있다는 점에 동의한다. 두 분석 모두 화이트의 더 나은 중앙 통제와 약간의 개발 주도, 그러나 양측의 잠재적인 왕 안전 문제에 주목한다. 시각적 분석은 왕들의 잠재적인 취약성을 강조하는 반면, FEN 기반 분석은 통제와 개발의 중요성을 강조한다.\n' +
      '\n' +
      '인사이트의 합성: 두 관점을 통합하면, 그 입장은 개발 주도 및 중앙 통제로 인해 화이트에게 약간의 주도권을 제공하지만 이러한 이점은 결정적이지 않다. 흑인의 다음 행보는 그들이 백인의 주도권을 무력화하고 그들의 지위, 특히 왕의 안전을 강화할 수 있는지 여부를 결정하는 데 중요하다.\n' +
      '\n' +
      '결정적 판단: 발달적 요인 때문에 화이트를 약간 선호하면서도 어느 쪽에도 압도적으로 유리한 입장은 아니다. 블랙이 다음 행보에 효과적으로 대응할 수 있는 능력은 이번 판단에서 중요한 역할을 한다.\n' +
      '\n' +
      '최종 평가(심판의 세부 결론):\n' +
      '\n' +
      '단계별 분석: 재료 균형이 균일하므로 재료 이점을 가지고 있는 측면이 없습니다. 화이트의 개발이 더 낫지만, 블랙은 Nc6와 d6 같은 움직임으로 빠르게 발전할 수 있다. 두 왕 모두 안전에 대한 우려가 있지만, 현재로서는 이것이 어느 쪽에도 전술적 기회를 만들어주는 것은 아니다. 즉각적인 전술적 모티프가 없다는 것은 전략적 기동과 장기적 계획에 의해 그 위치가 결정될 가능성이 높다는 것을 의미한다.\n' +
      '\n' +
      '종합적 결론: 위와 같은 점을 고려할 때, 중심부에 대한 개발 및 통제에 있어 약간의 주도성으로 인해 화이트에게 약간 유리한 입장에 그치고 있다. 그러나 블랙은 구조적 결함이 없고 정확한 플레이로 포지션의 균형을 맞출 수 있다.\n' +
      '\n' +
      '명확한 진술: 그 포지션에 대한 전반적인 평가는 화이트에게 약간 유리한 상황으로 기울어지지만, 평형은 크게 방해받지 않으며, 그 포지션이 양쪽에 대한 기회와 대체로 균형을 이룬다는 결론을 보증한다.\n' +
      '\n' +
      '따라서 해당 직책에 대한 최종 판단은 균형 있는 위치를 나타내는 \'상자{3}\'가 될 것이다.\n' +
      '\n' +
      '그림 11: 사례 연구 3: 체스 위치 이점 예측.\n' +
      '\n' +
      '## Problem:\n' +
      '\n' +
      '체스판 그림과 제공된 FEN 표기법을 기반으로 현재 위치를 평가한다. 1) 화이트에 유리해, 2) 블랙에 유리해, 3) 밸런스야?\n' +
      '\n' +
      'FEN notation:\n' +
      '\n' +
      'r3kbar/pp1n1ppp/1q2p3/2ppP3/3P4/2P5/PP3PPP/RNBQK1NR w KQkq\n' +
      '\n' +
      '## Solution:\n' +
      '\n' +
      '분석가 A(FEN-Based)의 분석\n' +
      '\n' +
      '초기 평가: FEN 표기법은 화이트가 움직일 차례임을 나타낸다. 조각의 위치는 다음과 같다: 화이트는 아직 소광력과 주교를 개발하지 않은 반면 블랙 퀸은 b6에 적극적으로 위치하여 d4 졸에 압력을 가하고 있다. 두 왕 모두 여전히 양쪽에 캐슬권이 있고, 패스 가능성이 없으며, 승부의 7수일 뿐이다.\n' +
      '\n' +
      '소재 균형과 위치 요소: 소재는 균일하지만 e5에서 화이트는 전당과의 중앙에 공간이 더 많으나 화이트의 개발 부족이 부채가 될 수 있다. 블랙은 탄탄한 전당 구조를 가지고 있으며 완성된 기사 개발은 화이트의 중심을 상대로 잠재적인 플레이가 가능하다. 화이트의 e 파일은 반 개방적이지만 현재 사용 중인 것은 아니다; 한편, 블랙의 조각들은 특히 중앙 집중화된 여왕과 어두운 사각 주교가 개발될 가능성을 고려할 때 상당히 활성화될 수 있다.\n' +
      '\n' +
      '생각 결론 FEN 분석에서 화이트의 개발 부족으로 인해 블랙에 대한 약간의 편향과 위치가 균형을 이루는 것으로 판단된다. 여전히, 어떠한 즉각적인 전술 위협도 화이트에게 개발을 완료하고 잠재적으로 중앙 공간 이점을 이용할 수 있는 약간의 재량권을 주지 않는다\n' +
      '\n' +
      '분석가 B의 분석(그림 기반)\n' +
      '\n' +
      '시각적 평가: 그림에서 화이트의 전당 구조는 e5의 전당 구조로 더 발전된 반면 블랙의 구조는 3위와 4위에 압축되어 있음을 알 수 있다. 어느 쪽도 캐스팅되지 않았고, 블랙의 여왕은 공격적으로 b6에 게시되어 있습니다. 화이트는 퀀사이드에 미개발 조각이 있으며, 이는 특히 C-파일에 블랙의 밀림을 촉발할 수 있습니다.\n' +
      '\n' +
      '위치 역학 및 전술 통찰: 시각적으로, 블랙의 위치는 조화롭게 보이며,...cxd4와 같은 동작으로 화이트의 중심에 압력을 증가시키는 가능한 계획과 함께 고급 e5 폰이 블랙의 조각의 표적이 될 수 있다. 반면에 화이트는 NS3 또는 Bd3와 같은 움직임으로 조각을 빠르게 개발하여 e5에서 졸의 중앙 공간을 활용하는 것으로 보일 수 있다.\n' +
      '\n' +
      '생각 결론: 시각적으로, 흑인은 화이트의 중앙 발톱에 대한 더 나은 조각 활동과 잠재력으로 인해 약간 우위에 있는 것으로 보입니다. 화이트는 상황을 통제하고 즉각적인 위험을 완화하기 위해 개발을 따라잡는 것이 중요하다\n' +
      '\n' +
      '분석 비교(심판의 합성)\n' +
      '\n' +
      '관점의 조정: 두 분석가는 입장이 상당히 균형 잡힌 것처럼 보인다는 것에 동의하지만, 분석가 A는 화이트의 중심 공간을 강조하는 경향이 있는 반면, 분석가 B는 화이트의 중심에 대한 블랙의 작품 활동과 잠재적 연극을 강조한다.\n' +
      '\n' +
      '인사이트의 합성: 화이트가 조각 활동에서 뒤처지는 것을 피하기 위해 조각을 빠르게 개발할 필요성이 인정된다. 양쪽 모두 우위에 있는 화이트와 잠재적인 킹사이드 플레이, 그리고 c와 d 파일을 컨트롤하는 블랙이 있습니다.\n' +
      '\n' +
      '결정적 판단: FEN 기반 및 도형 기반 분석의 통찰력을 모두 고려하여 더 적극적인 조각 배치로 인해 위치는 흑인에 대한 경향과 균형을 이룬다. 화이트의 움직임은 작품 개발과 공간 사용의 문제를 해결할 수 있는 기회를 제공한다.\n' +
      '\n' +
      '최종 평가(심판의 세부 결론)\n' +
      '\n' +
      '단계별 분석: 화이트는 d4에 대한 압력을 해결하기 위해 NS3, Bd3 또는 Be3와 같은 개발 움직임을 고려해야 한다. NS3와 같은 움직임은 신속한 개발과 안전에서 O-O를 허용한다. 반대로 블랙은 화이트의 센터에 도전하기 위해 cxd4 또는...f6과 같은 움직임으로 화이트의 일시적인 개발 지연을 활용하는 것으로 볼 것이다.\n' +
      '\n' +
      '종합적 결론: 화이트의 중심 공간 이점과 블랙의 더 나은 작품 활동을 고려하여 포지션은 양측 모두에게 기회를 제공한다. 화이트의 당면 과제는 조각을 개발하는 것이며, 블랙은 화이트의 중앙 발과 뒤처진 발전에 대항하여 연극을 만들려고 노력해야 한다.\n' +
      '\n' +
      '명확한 진술: 양쪽 분석의 전체와 양쪽의 가능성을 고려할 때, 게임은 각 플레이어가 우위를 주장할 수 있는 기회와 균형을 이루는 것으로 판단된다. 따라서 결론은 다음과 같다.\n' +
      '\n' +
      'boxed[3] Balanced\n' +
      '\n' +
      '그림 12: 사례 연구 4: 체스 위치 이점 예측.\n' +
      '\n' +
      '## Problem:\n' +
      '\n' +
      '분자 구조 그림과 제공된 SMILES 표현을 기반으로 화합물을 평가한다. 1) 돌연변이 유발인가요, 2) 비 돌연변이 유발인가요?\n' +
      '\n' +
      'SMILES representation:\n' +
      '\n' +
      'c1c(cc((c1[N+](-O)[O-])N)Br)[N+](-O)[O-]\n' +
      '\n' +
      '## Solution:\n' +
      '\n' +
      '학생 A로부터의 분석(SMILES-Based):\n' +
      '\n' +
      'SMILES 표현 \'c1c(cc((c1[N+](-O)[O-])N)Br)[N+](-O)[O-]을 살펴보면, 몇 가지 구조적 특징을 확인할 수 있다: 화합물은 \'c1c(cc((c1)]...\'로 표시된 바와 같이 벤젠 고리를 포함한다. 벤젠 고리에 부착된 두 개의 니트로기 \'[N+](-O)[O-]가 있다. 아미노기 \'N\'은 벤젠 고리에도 부착되어 있다. 벤젠 고리에는 브롬 원자 \'Br\'이 부착되어 있다.\n' +
      '\n' +
      '이러한 특징들을 제공된 예시적인 사례들과 비교한다: 화합물은 돌연변이 유발 예 \'c1ece2c(c1)ece3c2ece(c3)[N+](-O)[O-)\'와 유사한 니트로기 배열을 갖는다. 그러나, 아미노기 및 브롬 원자의 존재는 제공된 예와 구별된다.\n' +
      '\n' +
      '전체 분자 구성을 평가하는 것: 두 니트로 그룹의 존재는 DNA 구조를 불안정하게 할 수 있는 전자 철회 특성으로 인해 돌연변이 유발 가능성이 더 높다는 것을 시사할 수 있다. 반면에 아미노기는 전자 공여기이며, 이는 잠재적으로 니트로기의 돌연변이 유발 효과를 감소시킬 수 있다. 브롬 원자는 분자의 공간 방향 및 생물학적 시스템과의 상호 작용에 영향을 미칠 수 있는 부피가 큰 치환기이다.\n' +
      '\n' +
      '구조 요소 및 예시적인 사례와의 비교를 기반으로 화합물의 구성은 두 개의 니트로 그룹의 존재로 인한 돌연변이 유발 가능성을 시사한다. 그러나 아미노기와 브롬 원자의 완화 효과를 고려해야 한다. 돌연변이 유발성의 최종 결정은 이러한 효과의 균형을 고려해야 한다.\n' +
      '\n' +
      '학생 B로부터의 분석(그림 기반):\n' +
      '\n' +
      '제공된 그림을 인정하여 다음과 같이 관찰한다: 공간 배열은 벤젠 고리에 근접한 니트로기와 아미노기를 보여준다. 니트로기는 서로에 대해 메타 위치에 있으며, 이는 제공된 예에서 명시적으로 다루지 않은 구성이다. 아미노기는 니트로기 중 하나에 대해 파라 위치에 있다.\n' +
      '\n' +
      '공간적 배열을 제공된 예들과 비교하는 것: 도면은 제공된 돌연변이 유발성 또는 비-돌연변이 유발성 예들과 직접적인 상관관계를 나타내지 않는데, 이는 치환기들의 특정 배열이 고유하기 때문이다.\n' +
      '\n' +
      '접근법을 반영하여: 나의 분석은 학생 A의 SMILES 기반 분석과 다른 치환기의 공간적 배열과 잠재적인 입체 및 전자 효과에 초점을 맞추고 있다.\n' +
      '\n' +
      '전체적인 기하학 및 전자 효과를 고려할 때, 전자 공여 아미노기는 잠재적으로 니트로기의 전자 철회 효과에 대해 벤젠 고리를 안정화시킬 수 있다. 브롬 원자의 크기는 분자의 생물학적 시스템과의 상호작용을 방해하여 잠재적으로 돌연변이 가능성을 감소시킬 수 있다.\n' +
      '\n' +
      '그림 특이적 통찰력 및 작용기의 독특한 배열에 기초하여, 화합물은 제공된 돌연변이 유발 예에 비해 감소된 돌연변이 유발성을 나타낼 수 있다. 아미노기에 의한 입체 장애와 전자 기증은 돌연변이 유발성에 대한 완화 효과를 시사한다.\n' +
      '\n' +
      '분석(Teacher\'s Synthesis)을 비교:\n' +
      '\n' +
      'SMILES 표현을 기반으로 한 학생 A의 분석에서는 두 니트로 그룹의 존재로 인한 돌연변이 유발 가능성을 시사한다. 그러나 학생 A는 아미노기와 브롬 원자의 가능한 완화 효과도 고려한다.\n' +
      '\n' +
      '그림을 기반으로 한 학생 B의 분석은 공간 배열과 치환기의 입체 및 전자적 효과를 강조한다. 학생 B는 아미노기와 브롬 원자가 화합물의 돌연변이 가능성을 감소시킬 수 있음을 시사한다.\n' +
      '\n' +
      '분석의 주요 차이점은 전자 효과(학생 A) 대 공간 배열 및 입체 장애(학생 B)에 중점을 두는 것이다.\n' +
      '\n' +
      '최종 평가(교사의 세부 결론):\n' +
      '\n' +
      '두 분석을 모두 고려할 때 화합물은 두 니트로 그룹의 존재와 같은 돌연변이 유발성과 관련될 수 있는 특성을 나타낸다. 그러나 전자 공여 아미노기 및 브롬 원자에 의해 제공되는 입체 장애를 포함한 완화 인자는 돌연변이 유발 가능성이 감소했음을 시사한다.\n' +
      '\n' +
      '구조적 특징과 잠재적 효과의 균형을 맞추고 최종 평가 팀은 돌연변이 유발 가능성을 줄였다. 따라서, 상기 화합물은:\n' +
      '\n' +
      'boxed{2} Non-mutagenic\n' +
      '\n' +
      '그림 13: 사례 연구 5: 분자 특성 예측.\n' +
      '\n' +
      '## Problem:\n' +
      '\n' +
      '분자 구조 그림과 제공된 SMILES 표현을 기반으로 화합물을 평가한다. 1) 돌연변이 유발인가요, 2) 비 돌연변이 유발인가요?\n' +
      '\n' +
      'SMILES representation:\n' +
      '\n' +
      'clec(cc(c1)[N+][-O)[O-]][N+][-O][O-]\n' +
      '\n' +
      '## Solution:\n' +
      '\n' +
      '학생 A로부터의 분석(SMILES-Based):\n' +
      '\n' +
      'SMILES 표현 \'c1cc(cc(c1)[N+][-O][O-])[N+][-O][O-]\'를 살펴보면, 1은 몇 가지 중요한 구조적 특징을 식별할 수 있다: 화합물은 \'c1cc(cc(c1)[N+][-O][O-]\'로 표시된 바와 같이 벤젠 고리를 포함한다. 벤젠 고리에 부착된 두 개의 니트로기는 \'[N+][-O][O-]\' 세그먼트로 표시된다.\n' +
      '\n' +
      '이러한 구조적 요소를 제공된 예시적인 사례와 비교하는 것: 돌연변이원: c1cc2c(c1)[ccc3c2cc(c3)[N+][-O][O-]; 비돌연변이원: c1cc2c(c1)[N+][-O][O-]; 비돌연변이원: c1cc2c(cc2)[c1][N+][-O][O-]; 돌연변이원: c1cc-2c(c1)[c3cecec]c3c2c(c1)[c3]c2c(cc4)[N+][-O][O-]\n' +
      '\n' +
      '니트로기의 존재는 돌연변이 유발 화합물과 비 돌연변이 유발 화합물 모두에서 공통적인 특징임을 알 수 있다. 그러나, 돌연변이 유발 화합물은 보다 복잡한 다환 구조를 갖는 반면, 비돌연변이 유발 화합물은 보다 간단한 구조를 갖거나 질소 함유 헤테로사이클린을 함유한다.\n' +
      '\n' +
      '전체 분자 구성을 평가하면 문제의 화합물은 두 개의 니트로 그룹을 가진 단일 벤젠 고리를 가지고 있다. 이 구조는 더 간단하고 참조 화합물에서 비돌연변이성과 상관관계가 있는 다환 또는 헤테로사이클릭 특징을 포함하지 않는다. 따라서 SMILES 표현 및 참조 구조와의 비교를 기반으로 화합물의 구성은 생물학적 시스템과의 상호작용에 영향을 미칠 수 있는 단일 벤젠 고리에 2개의 전자 철회 니트로 그룹이 존재하기 때문에 돌연변이 유발 가능성을 시사한다.\n' +
      '\n' +
      '학생 B로부터의 분석(그림 기반):\n' +
      '\n' +
      '제공된 그림을 확인하면 다음과 같은 것을 관찰할 수 있다. 분자 구조는 두 개의 니트로기가 부착된 단일 벤젠 고리를 보여준다. 원자의 공간적 배열은 니트로 그룹이 서로에 대해 메타 위치에 있음을 나타낸다.\n' +
      '\n' +
      '비교를 위해 예시적인 예를 사용하여: 돌연변이원: c1cc2c(c1)[ccc3c2cc(c3)[N+][-O][O-]; 비돌연변이원: c1cc2cecn2c(c1)[N+][-O][O-]; 비돌연변이원: c1cc2c(cccn2)[N+][-O][O-]; 돌연변이원: c1cc-2c(c1)-c3cccc4c3c2c(cc4)[N+][-O][O-]\n' +
      '\n' +
      '돌연변이 유발 예는 복잡한 다환 구조를 갖는 반면 비 돌연변이 유발 예는 그렇지 않다는 점에 주목한다. 그림은 단순한 단일환 구조를 보여주며, 이는 비돌연변이성을 직접적으로 나타내지 않는다. 그러나, 니트로기의 공간적 배열은 화합물의 반응성에 영향을 미칠 수 있다. 니트로기의 메타 위치는 벤젠 고리를 잠재적으로 안정화시켜 더 활성화되는 오르토 또는 파라 위치와 같은 다른 구성과 비교하여 반응성을 감소시킬 수 있다.\n' +
      '\n' +
      '내 접근법을 반영하여, 나는 기능 그룹의 존재와 분자 복잡성을 주로 고려한 학생 A의 SMILES 기반 분석과 다른 기능 그룹의 공간적 배열과 전자 효과에 초점을 맞추고 있다. 나의 추론은 메타 위치 니트로 그룹이 니트로 그룹의 활성화 특성에도 불구하고 안정화로 인한 돌연변이 유발 가능성을 낮출 수 있음을 시사한다.\n' +
      '\n' +
      '분석(Teacher\'s Synthesis)을 비교:\n' +
      '\n' +
      'SMILES 표현을 기반으로 한 학생 A의 분석에서는 화합물이 벤젠 고리에 두 개의 니트로 그룹이 존재하기 때문에 잠재적으로 돌연변이 유발성이 있음을 시사하며, 이는 니트로 그룹도 포함하는 참조 돌연변이 유발 화합물과 유사하다.\n' +
      '\n' +
      '그림을 기반으로 한 학생 B의 분석은 니트로 그룹의 공간적 배열을 고려하여 다른 관점을 제공한다. 학생 B는 니트로 그룹의 메타 위치가 벤젠 고리를 안정화시켜 잠재적으로 돌연변이 유발성을 감소시킬 수 있음을 시사한다.\n' +
      '\n' +
      '두 분석의 주요 차이점은 분자 복잡성과 전자 효과에 대한 강조이다. 학생 A는 니트로 그룹의 존재와 돌연변이 유발성과의 상관관계에 초점을 맞추는 반면, 학생 B는 니트로 그룹의 특정 위치와 잠재적인 안정화 효과를 고려한다.\n' +
      '\n' +
      '최종 평가(교사의 세부 결론):\n' +
      '\n' +
      '두 분석을 모두 고려한 후 분자 복잡성과 전자 효과에 대한 강조를 조정하는 것이 중요하다. 니트로기의 존재는 돌연변이 유발 화합물의 일반적인 특징이지만 벤젠 고리에 대한 이러한 그룹의 특정 배열 및 전자적 영향을 간과할 수 없다.\n' +
      '\n' +
      '화합물의 메타 위치 니트로기는 실제로 벤젠 고리를 안정화시킬 수 있지만 니트로기의 활성화 특성 및 다른 화합물의 돌연변이 유발성과의 알려져 있는 연관성을 무시할 수 없다. 화합물에 비돌연변이성과 관련된 다환 또는 헤테로사이클릭 구조가 없다는 점을 감안할 때, 유사한 돌연변이 유발 화합물에 의해 설정된 선례를 고려할 때 최종 평가는 돌연변이 유발 화합물 쪽으로 기울어진다.\n' +
      '\n' +
      '따라서, 화합물의 돌연변이 유발성에 관한 최종 용액은: \'boxed{1\'이다.\n' +
      '\n' +
      '그림 14: 사례 연구 6: 분자 특성 예측.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>