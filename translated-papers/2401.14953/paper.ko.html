<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '축적기.\n' +
      '\n' +
      'Jordi Grau-Moya\n' +
      '\n' +
      '에말 분담금 1, 1, 1 에쿼탈 기여금, 1, 1 에쿼탈 기여금.com 에쿼탈 기여금.\n' +
      '\n' +
      'Tim Genewein\n' +
      '\n' +
      '1,1\n' +
      '\n' +
      'Marcus Hutter\n' +
      '\n' +
      '1,1\n' +
      '\n' +
      'Laurent Orseau\n' +
      '\n' +
      '1,1\n' +
      '\n' +
      'Gregoire Deletang\n' +
      '\n' +
      '1,1\n' +
      '\n' +
      'Elliot Catt\n' +
      '\n' +
      '1,1\n' +
      '\n' +
      'Anian Ruoss\n' +
      '\n' +
      '1,1\n' +
      '\n' +
      '세달앙 월녀 케빈 리 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 류 위 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서 서\n' +
      '\n' +
      '1,1\n' +
      '\n' +
      'Christopher Mattern\n' +
      '\n' +
      '1,1\n' +
      '\n' +
      'Matthew Aitchison\n' +
      '\n' +
      '1과 조멜 비추리 \'비말\'과 \'조젤\'을 말한다.\n' +
      '\n' +
      '식 기여금 1, 식 기여금 1, 식 기여 1, 식 기여 1, 식 기여 1, 식 기여 1, 식 기여 1, 식 기여 1, 식 기여 1, 식 기여 1, 식 기여 1, 식 기여 1 1, 식 기여 1, 식 기여 1, 식 기여 1 1, 식 기여 1, 식 기여 1이다.\n' +
      '\n' +
      '런던, 영국.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '메타-러닝은 제한된 데이터로부터 새로운 작업을 빠르게 학습하기 위해 신경망을 훈련시키는 강력한 접근법으로 부상했다. 다양한 작업에 대한 광범위한 노출은 일반적인 문제 해결을 가능하게 하는 다재다능한 표현으로 이어진다. 그러나 메타 학습의 한계는 무엇입니까? 이 연구에서 우리는 가장 강력한 보편적인 예측 변수, 즉 솔로몬오프 유도(SI)를 그 한계에 대한 메타 학습을 활용하여 신경 네트워크로 상각할 가능성을 탐구한다. 우리는 네트워크를 광범위한 패턴에 노출시키는 데 사용되는 학습 데이터를 생성하기 위해 유니버설 튜링 기계(UTM)를 사용한다. UTM 데이터 생성 과정과 메타 학습 프로토콜에 대한 이론적 분석을 제공한다. 우리는 다양한 복잡성과 보편성의 신경 아키텍처(예: LSTM, 트랜스퍼러) 및 알고리즘 데이터 생성기를 사용하여 포괄적인 실험을 수행한다. 우리의 결과는 UTM 데이터가 메타 학습에 유용한 자원이며 보편적인 예측 전략을 학습할 수 있는 신경망을 훈련시키는 데 사용될 수 있음을 시사한다.\n' +
      '\n' +
      ' 기저학습의 복잡성, 보편적인 예측, 카놀모고로로프-복합성.\n' +
      '\n' +
      '메타러닝은 제한된 데이터(Hospedales et al, 2021)로부터 AI 시스템이 새로운 작업을 빠르게 학습할 수 있도록 하는 강력한 접근법으로 부상했다. 다양한 작업 세트에 대한 모델을 학습함으로써 메타 학습은 새로운 비실증적 과제에 일반화하는 표현과 학습 전략의 발견을 장려한다. 흥미로운 사실은 최근 연구에 따르면 메타 학습은 특정 데이터 체제에 노출되었을 때 신경 네트워크가 베이지안 추론(유전자위 등, 2023; 미클릭 등, 2020; 오르테가 등)을 수행할 수 있으며 이는 불확실성에서 원칙적인 예측에 중요하다. 메타 학습의 핵심 과제는 충분히 넓은 과제 분포를 설계하여 풍부한 다양한 구조와 패턴에 모델을 노출시키는 것이다. 이러한 광범위한 노출은 "보편적" 표현으로 이어질 수 있으므로 시스템이 광범위한 문제를 해결하고 인공 지능(AGI)의 목표에 더 가까이 다가갈 수 있다.\n' +
      '\n' +
      '솔로몬오프 도입 1(SI)은 이러한 이상적인 보편적인 예측 시스템(솔로몬오프, 1964a,b) 2를 구성하기 위한 강력한 이론적 기반을 제공하며, 그 핵심은 SI가 세 가지 기본 원칙(그림 1 참조)을 우아하게 통합한다. 모든 계산 가능한 가설에 대한 고려:__비유사 전통적인 접근법에 의해 생성된 SI는 계산 가능한 가설의 전체 공간(즉, SI)을 탐구한다.\n' +
      '\n' +
      '그림 1: 메타 학습 방법론입니다.\n' +
      '\n' +
      '관찰 데이터에 대한 잠재적인 설명으로서 __컴퓨터 프로그램)은 관측 데이터에 대한 잠재적인 설명으로서. _컴퓨터 프로그램)이다. 오캄의 Razor_: SI는 더 짧은 설명으로 더 간단한 가설에 더 높은 사전 확률을 할당한다. 베이지안 업드팅_: 새로운 데이터와 함께 SI는 베이즈 규칙을 사용하여 각 가설에 대한 믿음을 개선한다. SI의 이론적 강도는 계산 가능한 경우 실제 데이터 생성 과정에 빠르게 수렴하는 능력에 있다(Hutter, 2004; Li and Vitanyi, 1992; Li et al., 2019; 순에하그 및 Hutter, 2013). 그러나 중요한 장벽은 실용적인 불일치이다. 알고리즘 가설에 대한 철저한 탐색은 엄청난 계산 자원을 요구한다. 이를 해결하기 위해 SI의 근사치(Filan et al. 2016; Schmidhuber, 2002) 및 콘텍스트 트리 위팅 알고리즘(Veness et al, 2012; Wil 문제점, 1998; Wil 문제점 등 1995)과 같이 개발되었다.\n' +
      '\n' +
      'SI의 전력을 이해하기 위해, 데이터 \\(x\\)의 무한 스트림을 생성하는 프로그램, 예를 들어 유체 역학 시뮬레이션 또는 AI 영화 생성기를 상상한다. 이 프로그램의 가능한 최단 버전(즉, Kolmogorov 복잡도(Li et al., 2019))의 길이는 \\(N\\) 비트의 길이로 모든 불필요한 요소를 제거하고 압축을 사용하여 크기를 더욱 감소시켰다고 하자. 이제 데이터 스트림 \\(x\\)을 SI로 먹여 각 비트를 예측할 수 있다면 주목할 만한 일이 발생하는데, 이후 \\(N\\) 예측 오류를 적게 만들면 SI는 미래 데이터를 완벽하게 예측할 것이다. 이는 SI가 데이터 생성 프로그램의 기본 규칙을 효과적으로 학습하기 때문에 발생한다. 각 잘못된 예측으로 가능한 다양한 설명을 제거하여 데이터 뒤에 정확한 프로그램을 빠르게 찾을 수 있습니다.\n' +
      '\n' +
      '본 논문에서는 메타 학습(그림 1 참조)을 통해 솔로몬오프 인덕션을 신경망으로 상각할 수 있는 가능성을 탐색한다. 핵심 과제는 한계에서 SI를 학습하기 위해 네트워크를 안내하는 신경 아키텍처 및 학습 데이터 분포를 찾는 것이다. 신경망은 이론적으로 보편적인 계산(Chen et al, 2017; Mali et al., 2023; Stogin et al., 2020)이 가능한 반면, 실무 훈련 방법(예: 확률적 구배 하강)은 이러한 능력을 제한할 수 있다(Deletang et al, 2022). 여기에서 우리는 단순히 전송기 및 LSTM과 같은 비장형 아키텍처를 사용하는 동시에 적절한 데이터 훈련 프로토콜을 설계하는 데 중점을 둔다. 이를 해결하기 위해 완전 일반 컴퓨터인 유니버설 튜링머신(UTM)의 데이터를 생성한다. 이 "보편적 데이터"에 대한 교육은 네트워크를 보편적 유도 전략을 배우는 것을 위해 네트워크를 안내하는 광범위한 계산 가능한 패턴으로 노출시킨다.\n' +
      '\n' +
      '주요 기여는***:**_1) UTM 데이터:_ We 사용, 처음으로 UTM 데이터를 메타-변형 신경망에 사용한다. 2) 이론적 분석:_ 우리는 한계에서 SI로 수렴하는 UTM 데이터 생성 과정 및 훈련 프로토콜에 대한 이론적 분석을 제공한다. 3) 집중 실험:_ We는 다양한 신경 아키텍처(예: LSTM, 트랜스퍼러)와 다양한 복잡성과 보편성의 알고리즘 데이터 생성기를 사용하여 포괄적인 실험을 수행한다. 우리는 [https://github.com/google-deepmind/neural_net 수집되었다_solomonoff_유도](https://github.com/google-deepmind/neural_networks_solomonoff_유도)에서 발전기를 개방했다.\n' +
      '\n' +
      '우리의 결과는 모델 크기가 증가함에 따라 성능이 향상되어 모델 스케일링이 점점 더 보편적인 예측 전략을 배우는 데 도움이 된다는 것을 보여준다. 우리는 UTM 데이터에 대해 훈련된 대형 트랜스포머가 재사용 가능한 보편적인 패턴을 획득한 다른 과제로 학습을 성공적으로 전달한다는 것을 발견하며, 가변차 마르코프 소스, 대형 LSTM 및 트랜스포머가 최적의 성능을 달성하여 SI에 필요한 프로그램보다 베이지안 혼합물을 모델링하는 능력을 강조한다.\n' +
      '\n' +
      '## 1 Background\n' +
      '\n' +
      '** 부인** An 알파벳 \\(\\mathcal{X}\\)는 유한하고 비빈도적인 심볼 세트이다. 끈 \\(x_{1:n}x_{2}\\ldots x_{n}\\ldots x_{n}\\in\\mathcal{X}^{n}\\) 길이가 \\(x_{1:n}\\)로 표시된다. (x_{1:j}\\)의 프리픽스 \\(x_{1:j}\\) 및 정수 \\(x_{1:n}\\), \\(j\\q n\\)는 \\(x_{\\q j}\\) 또는 \\(x_{\\q j}\\)로 표시되며, 빈 끈은 \\(x_{<j+1}\\)으로 표시된다. n\\, \\(x_{1:m}:=x_{1:n}\\) 및 \\(x_{n:m}:=\\epsilon\\)를 정의한다. 두 개의 스트링 \\(s\\)과 \\(r\\)의 연결은 \\(sr\\)로 표시된다. 표정 \\([\\) [A]\\!]\\)는 \\(A\\)가 사실이고 그렇지 않으면 \\(0\\)이면 \\(1\\)이다.\n' +
      '\n' +
      '** 에피메틱****입니다. 반심 측정은 무한하고 유한한 서열(P\\)에 대한 확률 측정(P\\)이며, 일부 유한 알파벳 \\(\\mathcal{X}^cup\\mathcal{X}^{{X}^{*}\\)에 대한\\(\\{0,1\\}\\)으로 가정된 일부 유한 알파벳 \\(\\{0,1\\}\\)에 대한\\(\\{0,1\\}\\)에 대한\\(\\{0,1\\}\\)에 대한\\(\\{0,1\\}\\)에 대한\\(\\{X,1\\}\\)에 대한\\(\\{X,1\\}\\)에 대한\\(\\{X,1\\}\\)에 대한\\(\\{X,1\\,1\\}\\)에 대한\\)에 대한\\(\\{X,1\\,1\\}\\)에 대한 최종 진술)의 확률 측정값이다. (\\mu(x)\\)는 \\(x\\)를 갖는 (in)무한 서열 _starts_이 존재할 확률이다. 적절한 분포가 \\(\\sum_{a\\in\\mathcal{X}}\\mu(xa)=\\mu(x)\\\\ing)를 만족하지만 반심법은 _probability 갭_을 나타내고 \\(\\sum_{a\\in\\mathcal{X}}\\mu(xa)\\leq\\mu(x)\\를 만족한다.\n' +
      '\n' +
      '** 트리링 마진** A 투링 기계(TM)는 심볼의 문자열을 입력으로 하여 기호 \\(z\\)의 문자열을 입력하고(x\\) (z\\) 및 할로팅 후), 즉,\\(T(z)=x\\)를 출력한다. 편의상 계산 단계에서 출력 문자열을 \\(s\\)로 정의하는데, 이는 빈 문자열 \\(\\epsilon\\)일 수 있는 \\(T^{s}(z)=x\\)이다. 우리는 유니버설 튜링머신(U\\)에 대해 유사한 표기법을 채택한다. 모노톤 TM(아래 정의 1 참조)은 입력 프로그램을 증가시키면서 출력열을 증분적으로 구축할 수 있는 특별한 TM이며, 이는 우리가 실험에서 활용하는 편리한 실용적인 속성이다.\n' +
      '\n' +
      '(U(q)\\)와 \\(U(q)\\(x,y\\)가 있는 모든\\(p,q,\\)에 대해 단일성(U\\)이 있음을 의미하고(p\\sqsubseteq q\\)은 \\(p\\sqsubseteq x\\)를 의미하는데, 여기서 \\(p\\)은 \\(p\\)는 \\(I\\)는 \\(I\\(x)\\(x)\\(x)\\(x,\\)는 \\(p\\(x)\\(x)\\(p\\(x)\\(p\\(x)\\(p\\(p\\)는 \\(x)\\(p\\)는 \\(y\\(p\\)는 \\(x)\\(y\\, a\\)는 \\(m\\(x)\\(y\\, a\\(x)\\(x,\\,\\(x,\\)는 \\(y\\,\\)는 \\(y\\,\\(x,\\)는 \\(y\\,\\)는 \\(I 좀 더 철저한 설명을 위해___부록 C를 참조하세요.\n' +
      '\n' +
      '①(x_{n+1:n}\\) 관찰된 서열을 감안할 때 다음 기호(x_{n+1}\\)에 대한 최적 예측은 \\(x_{n+1}|x_{n+1:{1:n})=\\mu(x_{1:n+1})/\\mu(x_{1:n}))이며, 이는\\(x_{n+1:n}) a\\(x_{n+1:n}}. 대조적으로, SI는 솔로몬오프 유니버설 우선(아래 정의 참조)으로 널리 알려진 단일 범용 기호 \\(M\\)를 사용하여 다음 기호 \\(x_{n+1}\\)를 예측한다.\n' +
      '\n' +
      '종래에는 \\(x)\\_{p: a\\_{p:U(p)\\*}2^{-\\(p)}\\)가 모든\\(p\\in\\{0,1\\}^{*}\\)에 걸쳐 있으며, 여기서 계산 \\(x*\\)은 \\(x\\)으로 시작되고(x*\\) 전체 프로그램은\\(U\\)에 의해 판독되었다.\n' +
      '\n' +
      '우리는 \\(M\\)을 사용하여 사후 예측 분포 \\(M(x_{n+1}|x_{1:n})=\\frac{M(x_{1:n}x_{n+1})}{M(x_{1:n}}}<그림 1> 참조)을 구성할 수 있다. 이는 프로그램 공간 \\(M(x_{n+1}|x_{1:n})=\\sum_{p}P(p|x_{1:n})[\\]에 대한 베이지안 추론을 수행하는 것과 같다. [U(x_{n+1:\\)]\\(프리 믹스-프리 프로그램) 및 V\\(P(p|x_{n+1:n}) 서열이 있는 모든 지속 \\(*\\)는 이전 \\(P)(p)=2^{-\\ell(p)}\\) 및 0-one 가능성 \\(P(x|p)=[\\][\\][\\][\\][p)를 사용하여 데이터를 감안할 때 프로그램에 걸쳐 베이지안 뒤쪽이다! [U(p)=x*]\\!]\\!\n' +
      '\n' +
      '(x|x_{<t})\\el.}(x|x_{<t})\\el(\\mu) <\\\\ing K(\\mu)－\\el(\\mu): \\i_{t}(\\mu) <\\\\ty K)) a\\(\\mu) <\\\\<\\\\ing: \\el(\\mu)>은 \\_{t(\\mu)\\el(\\el. 이는 불평등의 좌측에 무한합과 오른쪽이 일정함을 알 수 있다. 이전에 솔로몬오프는 본질적으로 참조 UTM의 선택을 고려할 때 최고의 보편적인 예측 변수이다.\n' +
      '\n' +
      '솔로몬오프 이전의 정규화된 버전(다른 사람(우드 등, 2013)이 있는데, 이는 반론이 아니라 적절한 측정, 즉 적절하게 정규화된 것(아래 정의 3 참조)이 있다. 그것은 \\(x\\)가 처리 가능한 하위 서열(Lattimore et al., 2011)을 포함하고 표준 솔로몬오프의 융합 특성을 사전에 유지할 때 더 좋은 특성을 가지고 있다. 이 버전의 SI는 신경 모델에 의해 학습하기에 적합하고(제대로 정규화되어 있다) 반심보다 더 효율적인 샘플링(확률 격차가 없기 때문에)을 나타내기 때문에 우리에게 관심이 있다.\n' +
      '\n' +
      '\\(M^{norm}:=1\\)의 경우, 솔로몬오프 정상화는 \\(M^{norm}=1\\), \\(M^{norm})(=\\ \\frac{M(xa)}{\\sum_{\\mathcal{X}}}}<xa)}}\\ =\\ \\frac{M^{{{{{{{{{{{{{{{{{{{{{{M^{{{M^{norm}(xa)}(xa)}(xa)}(xa)}(xa)}(xa)}.\n' +
      '\n' +
      '**Al알고리즘 데이터 유전체화 및 Chickky Hierarchy** An 알고리즘 데이터 생성 소스 \\(\\mu\\)는 단순히 무작위 입력을 먹인 TM \\(T\\)에 의해 계산 가능한 데이터 소스이다. 캡슐스키 계층(CH)로 알려진 메모리 구조를 기반으로 기계보다 자연 계층이 있으며, 이는 서열 예측 문제와 이를 해결하는 관련 오토마타 모델을 분류하고 복잡성을 증가시킨다. CH에는 4가지 수준, 즉 규칙적이고 맥락이 없고 맥락에 민감하며 재귀적으로 열거할 수 있다. 각 레벨의 문제를 해결하려면 유한 상태, 스택, 유한 테이프 및 무한 테이프와 같은 상이한 메모리 구조가 각각 필요하다. SI에 대한 합리적인 근사치는 위계의 상단에 앉아야 한다.\n' +
      '\n' +
      '활동 분포 \\(p(\\tau)\\(<\\tau)\\(x_{1:n}\\) 샘플 \\(\\tau\\), 2) 샘플 \\(\\tau\\), 3) 샘플 \\(\\pi_{\\ta}\\)을 log-loss \\-\\(\\pi_{\\ta}\\)으로 모델 \\(\\pi_{\\)을 반복하여 메타 트레이닝할 수 있다. \\pi_{\\|x_{ct}(x_{\\|x_{ct})\\ 알데히드}(x_{t}{ct})p(x_{t}|x_{t}{ct},\\t\\)\\(x_{t}{ct},\\t\\)는 \\(x_{t}|x_{t}.{t)\\(x_{t}.{ct},\\)\\(x_{t}. 첨부_\\i}(x)\\i}}(x{{t},\\i:\\i{t})에 대해 샘플링되고(x{t})\\\\i}(x{{t})\\\\i}(x{{at)\\\\<\\\\<\\<\\\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\>>>>>>>> < <\\<\\<\\<\\<\\<\\>>>>>>>)\\<\\<\\<\\<\\<\\<\\<\\<\\>>>>>>>>>>>}>>>>>>>>>>>\n' +
      '\n' +
      '솔로몬오프 인덕션 강도에 대한 결함으로 2 Meta 학습이요.\n' +
      '\n' +
      '다음으로 다음과 같은 질문에 대한 답을 제공하는 것을 목표로 한다. 먼저, _어떻게 SI를 근사할 수 있는 메타 학습 데이터를 생성할 수 있을까?_어떻게? 둘째, 대부분의 아키텍처가 제한된 서열 길이로 훈련된다는 점을 감안할 때, _어떻게 이것이 신경 모델의 메타 학습 프로토콜에 영향을 미친다. 셋째, _can은 보편성을 잃지 않고 서로 다른 프로그램 분포(흥미 프로그램 만들 가능성이 더 높은 프로그램 만들기)를 사용하고 있는가?__can은 보편성을 잃지 않고 활용?__?\n' +
      '\n' +
      '올바른 데이터 세트는 솔로몬오프 삼폴리스의 솔로모나프를 계산하세요.\n' +
      '\n' +
      '여기서 우리의 목표는 모델 \\(\\pi_{\\theta}\\)을 학습(지금은 보편성과 본질적으로 무한한 능력을 선호)할 때 \\(M\\)에 대한 근사치를 얻는 데이터 생성 과정을 정의하는 것이다. 우리는 처리 불가능하고 계산 가능한 경우를 고려한다. 모든 증명은 부록 A에서 찾을 수 있다.\n' +
      '\n' +
      '**Solomonoff Data Generator(빈입력 가능)** 모노톤 UTM \\(U\\)의 입력 테이프 상의 균일한 랜덤 비트 \\(p\\)를 클릭하면 출력 테이프 상의 (in)핀라이트 스트링 \\(x\\)의 특정 분포 \\(M\\)가 생성된다. 이것은 정확히 솔로몬오프의 사전\\(M\\)와 반심(1절 참조)이다. \\(M\\)로부터의 샘플링은 사소한 것이며, 우리는 프로그램이 작업에 해당하는 표준 메타 학습 설정과 정확히 어떻게 그리고 일치하는지 설명했으며, 우리는 단지 프로그램이 과제에 해당하는 표준 메타 학습 설정과 정확히 일치한다. (M\\)은 보다 형식적 정의 2와 동일하며, 다음과 같은 명제는 일관성을 보인다.\n' +
      '\n' +
      '**p위치 4**: _Let \\(D:=(x^{1},...,x^{J})\\)는 반측정 \\(예:\\mu\\)(M\\)에서 샘플링된 \\(J\\) 서열이다. 우리는\\(\\hat{\\mu}_{\\)\\(x)\\: \\{\\mu}=\\frac{D|}>{|D|} <\\sum_{y\\in D}[\\geq\\ell(x)\\ \\geq\\ell(x)\\ \\geq\\ell(x)\\ \\geq\\ell(x)\\ \\geq\\ell(x)\\ \\geq\\ell(x)\\ \\geq\\ell(x)\\<\\geq\\ell(x)\\)\\<\\geq\\I}[\\geq\\el(x)\\<\\geq\\i\\)\\－\\)\\－\\)\\－\\)\\－\\)\\－\\)\\－\\－\\)\\－\\－\\)\\－\\－\\－\\－\\)\\－\\－\\－\\－\\－\\－\\－\\－\\－\\－\\－\\－\\－\\－\\�\n' +
      '\n' +
      '안타깝게도 위에 \\(M\\)를 사용하는 것을 방지하는 3가지 무한대가 있습니다. 무한히 많은 프로그램이 있고, 프로그램은 영원히 루프할 수 있고, 출력 스트링들은 무한한 길이를 가질 수 있다. 따라서 우리는 이전에 솔로몬오프의 다음과 같은 계산 가능한 버전을 정의한다.\n' +
      '\n' +
      '** 정의 5**(컴퓨팅 솔로몬오프 선행)의 프로그램은 \\(\\q L\\) 및 \\(I\\) 단계(U^{s}\\) 후 또는 출력이 길이 \\(n\\)에 도달하면 종료된다. 그런 다음_를.\n' +
      '\n' +
      '①_{p\\{0,L,n\\}==\\ \\sum_{p\\{s+\\{p\\}}=x*}=2^{s+\\{p\\}}>2^{{-\\ell}}\\ \\ \\text{if}\\ \\ \\ \\ \\{if} \\ \\ \\{if(p)\\ \\ \\{if(p)\\ \\ \\ \\{s+\\{s+\\{s+\\{s+\\{s+\\{s}}}(p)}}<\\ \\ \\{-\\{-\\{-\\{-\\{if}}<\\ \\ \\{-\\{if} \\ \\{if} \\ \\{if(p)\\ \\{if} \\ \\{if(p)\\ \\{if} \\ \\{if} \\ \\{if} \\ \\{if} \\ \\{if} \\ \\{if} \\ \\{if} \\ \\\n' +
      '\n' +
      '우리는 \\(D^{J}:=(x^{1},...,x^{J})\\를 \\(M\\)에 대해 위에서 설명한 것과 동일한 사소한 방식으로 \\(M_{s,L,n}\\)에서 샘플링할 수 있지만 이제 관련된 계산은 유한하다. 샘플링된 모든 스트링은 \\(M_{s,L,n}(x):=0\\)에서 \\(x)>n\\에 대한 길이 \\(\\leq n\\)를 가지고 있다. 다음으로 메타 학습 데이터의 일치성을 보여주고 있다.\n' +
      '\n' +
      '***Prop위치 6**: \\(D^{J}:=(x^{1},...,x^{J})\\)는 측정치 \\(M_{s,L,n}\\)의 샘플이다. 그런 다음,\\(\\hat{M}_{D^{J}} <{D^{J}}[\\|{d\\sum_{y\\in D^{J}[\\|\\uq\\ell(x)\\wedge\\ y_{1:\\|\\geq\\ell(x)\\ \\geq\\ell(x)\\ \\wedge\\ y_{1:\\geq\\ell(x)\\wedge\\ y_{J}:\\geq\\ell(x)\\geq\\ell(x)\\wedge\\y\\)\\y\\i\\)\\y\\i\\y\\i\\y\\i\\i\\i\\i\\y\\i\\i\\i\\y\\i\\i\\y\\i\\y\\i\\y\\i\\y\\y\\y\\y\\y\\y\\y\\y\\y\\y\\)\\y\\y\\)\\y\\y\\y\\)\\ y_{1:\\ \\wedge\\ y_{1:\\ y_{1:\\ y_{1:\\ y_{1\n' +
      '\n' +
      'M(x)=\\lim_{s,L,n\\to\\infty}M_{s,L,n}(x)=\\sup_{s,L,n}(x)=\\sup_{s,L_{s,L,n}(x)\\)이기 때문에 우리는 특히 \\(\\hat{M}_{D^{J}_{D^{J}}_{D^{J}}}}}}}}s,L,n, M\\)에 대해\\_\\_{s, L,n})를 가지고 있다. \\(D^{J}\\)는 \\(s,L,n\\)에 의존하지만, 이는 \\(s(j), L(j),n(j)\\을 선택함으로써 쉽게 피할 수 있으며, \\(j), L(j), L(j),n(x)}(x)\\(j=1,2,3...\\)에 대해 \\(j=1,2,3...\n' +
      '\n' +
      '** 레스파크 7**: \\(M_{s,L,n}\\)는 계산 가능하지만 여전히 두 가지 불편으로 고통받고 있다. 첫째, 그로부터의 샘플링은 반평가이고 확률격차를 나타내기 때문에 비효율적이다. 둘째, 프로그램이 무한한 비인쇄 루프에서 중단되거나 종료되는지(훈련 시 확률 격차를 "흡수" 토큰으로 채우기 위해) 구별해야 한다. 정의 3과 5.__를 조합하기 전에 정규화된 계산 가능한 솔로몬오프를 추정하여 이러한 불편을 우회할 수 있다.\n' +
      '\n' +
      '우리는 다음과 같이 \\(M^{norm}_{s,L,n}(x)\\) 전에 정규화된(컴퓨팅) 솔로몬프를 추정할 수 있다.\n' +
      '\n' +
      '제안 6의 정의를 사용하는 _는 <표 6>의 정의를 사용하여, _는 그__**명제 8***명제이다.\n' +
      '\n' +
      '}}(x_{t)\\\\.}} <\\wedge\\_{ty>}} <\\u_{t]]\\.\n' +
      '\n' +
      '그 다음, 우리는 \\(t=1,...,n\\)를 초과하여 \\(\\hat{M}^{norm}_{s,L,n}(x)\\to M^{norm}_{s,L,n}(x)\\-M^{norm}(x)\\)를 얻을 수 있다.\n' +
      '\n' +
      '** 요약** 제안 4, 6 및 8은 솔로몬오프 데이터 유전체 및 각각의 변이체(컴퓨팅 및 정규화된 계산 가능)에 의해 생성된 데이터가 통계적으로 일치하고 이 데이터에 대한 메타 트레이닝이 추정기를 각각의 솔로몬프 버전(실제성과 학습가능성 가정)으로 수렴할 것이라고 명시한다.\n' +
      '\n' +
      '고정 시퀀스를 사용하여 솔로몬오프에서 모델을 훈련하세요.\n' +
      '\n' +
      '대부분의 신경 모델(특히 트랜스포머)은 고정된 길이 \\(n\\)의 훈련 시퀀스를 필요로 한다. 이로 인해 SI로의 융합을 유지하기 위해 더 짧은\\(n\\) 서열에 대한 손실 함수에 약간의 수정이 필요하다. 우리는 유한한 값뿐만 아니라 무한에 대해 다음과 같이 존재하기 때문에 \\(M^{\\cdots}_{s,L,n}\\)에서 \\(s,L,n\\)를 떨어뜨린다. 우리는 솔로몬프, \\(M^{norm}\\)의 정규화된 버전으로 수렴하는 훈련 프로토콜을 설명하는 데 중점을 둔다. 우리는 표준 비정상화 버전(\\, M\\))에 관심 있는 독자를 부록 B에게 참조한다.\n' +
      '\n' +
      '** 정규화된 솔로몬오프(M^{norm}\\)를 신경망을 갖는\\(M^{norm}\\)로 수렴하기 위해 \\(D^{J}\\)에서 \\(x^{j}\\)를 세로(n\\)로 패킹하고 \\(\\mathcal{X}\\)에서 임의의 기호가 있는 \\(n\\)에서 log-loss 짧은 값을\\(x^{j}\\)에서 \\(x^{j}\\)에서 \\(D^{j}\\)에서 \\(I\\)에서 \\(D^{j}\\)에서 \\(I\\)에서 \\(I\\)에서 \\(I\\)에서 \\(D^{j}\\)에 세로(n\\)로 패킹하고, \\(\\)에서 \\(I\\)에서 \\(I\\)에서 \\(I\\)로 패킹하여 \\(I\\)에서 \\(I\\)에서 \\(I\\)로 패킹하고, \\(I\\)에서 \\(I\\)에서 그렇게 할 때는 로그손실(제8항을 이용하는 도출을 위해 부록 B.1 참조)의 형식을 취한다.\n' +
      '\n' +
      '\\{t}}\\u_\\sum_{t}}\\hsum_{t}}\\hsum_{t{}}\\hsum_{t{J}(x_{t{)\\\\.\n' +
      '\n' +
      '이 형태에서는 마지막 브래킷이 어떻게 최소화되어 있는지 쉽게 알 수 있으므로 \\(x_{\\\\theta}(x_{t}|x_{<t})=\\hat{M}^{norm}(x_{t}|x_{<t})\\에서 손실을 최소화한다. 사슬 규칙에 따르면 신경 모델 \\(\\pi_{\\theta}(x)은 \\(\\hat{M}^{norm}(x)\\)로 수렴한다. \\(\\text{Loss}(\\theta)\\)는 \\(x^{j}\\)의 패딩에 _not_를 의존하므로 임의의 패딩은 동일한 구배 및 동일한 용액으로 이어진다.\n' +
      '\n' +
      '신경 모형이 \\(\\hat{M}^{\\cdots}\\)를 나타낼 수 있는 능력을 가지고 있다는 (현실적) 가정 아래, 학습 알고리즘은 표현을 찾을 수 있으며, 이는 신경 모델 분포 \\(\\pi_{\\theta}\\)가 \\(\\hat{\\mu}=\\hat{M}^{\\cdots}\\)로 수렴한다는 것을 의미한다. 유사하게, 신경 모델이 \\(x^{j}\\)에서 샘플링된 \\(x^{chdots}_{s(j),L(j),n}(x)\\)에 대해 훈련되면(j=1,2,3) 그것은 \\(M^{\\cdots}_{\\infty,\\infty,n}\\)로 수렴한다. 시간 경과에 따라 컨텍스트 길이 \\(n\\)가 증가하는 신경 모델의 경우 \\(\\hat{M}^{\\cdots}\\to M^{\\cdots}_{\\infty,\\infty,\\infty}\\)도 가능할 수 있다. 이론적으로 가능하지만 이를 달성하기 위해 수선해야 하는 실질적인 과제가 많은데, 그 중 하나는 프로그램을 효율적으로 샘플링하는 방법입니다.\n' +
      '\n' +
      '비유기농 삼성의 솔로몬프.\n' +
      '\n' +
      '실용적인 목적을 위해 프로그램에 대한 불균일한(아마도 학습된) 분포의 샘플링은 효율성에 유리할 수 있다. BinPhoque 언어의 경우(나중에 실험에서 사용한다는 것) 137개(부록 표 3 참조)의 요인으로 \'관심\' 프로그램의 수율을 증가시킨다. 아래에서는 보편성을 상실하는 것에 대한 우려 없이 할 수 있음을 보여준다.\n' +
      '\n' +
      '\\(X^{\\infty}\\)는\\(Q(q):=Q(\\Gamma_{q})\\, \\(Q\\)는 \\(q\\)에서 시작한다는 가능성(Q\\)은 \\(q\\)에서 출발한다. 우리는 _일반화된 솔로몬오프 반심성__을 _일반화된 솔로몬오프 반심성)으로 정의한다.\n' +
      '\n' +
      '(q)\\[M_{T}^{Q}(q)\\: T]=\\sum_{q: T(q)\\ <\\\\ \\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n' +
      '\n' +
      '보편적인 TM \\(T=U\\) 및 편향되지 않은 코인 플립스 \\(Q(q)=2^{-\\ell(q)}\\. (M_{U}\\)는 모든 하위 반컴퓨팅 세미메틱(Wood et al, 2011)에 걸쳐 베이지안 혼합물이라는 점에서 강하게 보편적이다. 다음으로, 우리는 \\(Q\\)의 매우 가벼운 조건에서 \\(M_{U}^{Q}\\)도 보편적이라는 것을 보여준다. 이 발견은 (2017년 Sterkenburg, 2017)와 유사하지만 독립적으로 발견된 증명은 더 짧고 자체 수정된다.\n' +
      '\n' +
      'M_{U}^{Q}(x)\\(Q\\) _is는 계산 가능한 측정치이고 \\(Q(q)>0\\forall q\\in X^{\\}\\) \\(Q_q_{1:n})\\(n\\to\\\\ty\\) \\(n\\to\\\\ty\\) 0\\)은 계산 가능한 측정치이고 \\(Q)는 0\\이다. 보다 정확하게는, 위의 특성을 가진 모든 범용 모노톤 TM \\(U\\) 및 모든 \\(Q\\)에 대해, \\(M_{U}^{Q}(x)=M_{V}(x)\\ \\forall x\\) s. 부록 C.___ 부록 C.__ 부록의 증명.\n' +
      '\n' +
      '*** 위의 가정에 주목하여** 우리는 근사치의 무한수 데이터 포인트 및 보편성(및 학습성)을 가정했으며, 이는 실제에서 얻기 어렵고 신경 모델의 귀납적 편향의 관련성을 감소시킨다. 그러나 유한한 데이터의 경우 유도적 편향은 강력한 일반화에 중요하다. 우리는 신경 모델의 귀납적 편향과 보편성의 효과에 대한 이론적 작업의 범위를 벗어나 다음 섹션에서 신경 네트워크 성능에 대한 실험적 증거를 간단히 제공한다.\n' +
      '\n' +
      '3개의 실험법학.\n' +
      '\n' +
      '우리는 UTM에 대해 훈련된 다양한 신경 아키텍처 및 크기와 비교 및 분석을 위해 알고리즘적으로 생성된 두 가지 다른 유형의 데이터를 평가하는 것을 목표로 한다.\n' +
      '\n' +
      '** 가변 차수 마코비세스(VOMS)** A\\(k\\)-마크코프 모델은 마지막 \\(k\\) 캐릭터를 사용하여 다음 문자 확률을 출력하기만 하면 임의의 단계 \\(t\\)에 의해 문자열에 확률을 할당한다. VOMS는 \\(k\\)의 값이 가변적인 마르코프 모델로 불균일 깊이의 나무를 이용하여 구한다. 여기서 트리는 데이터를 생성하는 프로그램과 동일하다. 생성된 데이터에 나무와 메타 디스크를 샘플링합니다. 우리는 베일-최적 예측 변수가 존재하는 _binary_ VOMS, 즉 모델을 비교하는 콘텍스트 트리 위팅(CTW) 예측 변수(문제 등, 1997, 1995)를 고려한다. CTW는 범용 w.r. \\(n\\)-마크코프 소스에 불과하며 w.r.t.와 같은 모든 계산 가능한 기능은 SI이다. VOMS에 대한 더 많은 직관에 대한 부록 D.2, 데이터를 생성하는 방법과 CTW 베이즈 최적 예측 변수를 계산하는 방법을 참조한다.\n' +
      '\n' +
      '***Chickky Hierarchy(CH) 태스크** 우리는 15개의 알고리즘 작업(예: 산술, 역전 스트링)을 Deletang et al.(2022)에서 다른 수준의 추스키 계층(모든 작업에 대한 설명을 위해 부록 D.3 참조)에 누워 있다. 이러한 작업은 비교 및 우리 모델의 알고리즘 능력을 평가하는 데 유용하다. 그들은 _개인_과제를 훈련하는 Deletang et al.(2022)와 대조적으로, 우리는 모든 과제에 대한 메타 학습 _유사한_에 관심을 갖고 있다. 모든 작업이 동일한 알파벳 \\(\\mathcal{X}\\)을 사용하는지 확인(더 작은 알파벳으로 작업의 알파벳을 확장)한다. \\{(x_{i}\\mathcal{X}_{i}\\in\\mathcal{X})\\}_{i =1}^{I}}\' 및 델타머에 대한 추가 델타 토큰을 입력하고 출력한다. 우리는 출력 심볼에 대한 후회(및 정확성) _만__을 사용하여 모델을 평가하며, 이는 일반적으로 과업 수행의 무작위적이고 비정보적이기 때문에 입력을 마스킹한다. 액션 \\(O_{z}\\)의 출력 시간 결정 집합, 즉 궤적 \\(z\\)에 대한 정확도를 \\(z\\:=\\frac{1}{|O_{z}|}\\sum_{t\\in O_{z}}[\\arg\\max_{t\\in O_{t}}[\\arg\\max_{\\i}{\\_{\\_{<t})=z_{z})으로 계산했다. 자세한 내용은 부록 D.3을 참조하세요.\n' +
      '\n' +
      '*** 유니버설 튜링 기계 데이터** 상승 섹션 2.1 및 2.2, 무작위 프로그램(구조화된 서열 생성 프로세스를 인코딩)을 생성하고 UTM에서 실행하여 출력을 생성한다. 프로그램은 원칙적으로 소의 이미지, 체스 프로그램 또는 셰익스피어의 책을 생성할 수 있지만 물론 이러한 프로그램은 샘플링될 가능성이 매우 낮다(예시적인 산출물을 위한 부록에서 그림 6 참조). UTM의 선택으로 우리는 주로 브레인 푸케라고 부르는 브린F*ck UTM(Muller, 1993)의 변이체를 구성하여 샘플링 과정을 돕고 샘플링된 모든 프로그램이 유효하도록 했다. 우리는 작업 전달 평가를 가능하게 하기 위해 출력 심볼 알파벳 크기를 체스키 작업과 동일한 \\(|\\mathcal{X}|=17\\)로 설정했다. 브레인플스크에는 단일 작업 테이프와 쓰기 전용 출력 테이프가 있습니다. 작업 테이프 포인터(WTP), WTP( _datum_) 아래의 값을 de/상승시키는 7개의 명령어가 있으며, 점프를 수행하고 데이터를 출력으로 부록한다. 우리는 모든 프로그램을 유효하게 만들기 위해 불균형 브래킷을 건너뛰습니다. 프로그램 분포를 약간 변화시키지만\n' +
      '\n' +
      '그림 2: VOMS 데이터에 대한 \\(|\\) 평가이다. **Left:** 실시예 서열과 트랜스폼러-L(레드) 및 베이즈-최적 CTW 예측기(블루)의 고도로 중첩된 예측이다. 하단 패널은 순간적이고 누적적인 후회 w.r.t. 지상진실함을 보여준다. ***중간:** Mean 누적 후회는 6k 서열(길이 256, 최대)에 대한 것이다. CTW 트리 깊이 24, 3개의 종자 및 크기(S, M, L)에 대해 서로 다른 네트워크(3개의 종자) 및 크기에 대해 배포한다. 더 큰 모델은 모든 아키텍처에 대해 더 나은 성능을 가지며 트랜스폼러-L 및 LSTM-L은 최적의 CTW 예측 변수와 일치한다. ** 네:** 길이 일반화(1024 단계) LSTM은 더 긴 길이로 일반화되는 반면, 트랜스포머는 그렇지 않다.\n' +
      '\n' +
      '이것은 정람 9에 따른 문제가 아니며, 각 유효 프로그램은 샘플링될 0이 아닌 확률을 갖는다. 프로그램은 최대 출력 길이가 \\(n=256\\) 심볼인 200개의 메모리 셀이 있는 \\(s=1000\\) 단계에 대해 섹션 2.1 및 2.2에 설명된 대로 동시에 생성 및 실행된다. 이상적으로는 SI를 최적의 기준 비교로 사용해야 하지만 컴퓨터할 수 없고 난치하기 때문에 출력을 생성하는 단축 프로그램(불필요한 브래킷을 제거하거나 자체 계산 명령)의 사전 확률을 사용하여 로그 손실에서 결합되는 (가짜 느슨하지만 비모호적인) 상단을 계산해야 한다. 브레인 푸케와 샘플링 절차에 대한 완전한 설명을 위해 부록 E를 참조하세요.\n' +
      '\n' +
      '**Neural Predictors** 우리의 신경 모델 \\(\\pi_{\\theta}\\)은 데이터 생성 소스로부터 기호 \\(x_{<t}\\)를 순차적으로 관찰하고 다음 상징 확률 \\(\\pi_{\\theta}(\\cdot|x_{<t})\\(\\cdot|x_{<t})를 예측한다. 로그-손실 \\(\\text{Loss}(\\theta):=-\\frac{1}{n}\\sum_{t=1}^{n}\\log\\pi_{\\theta}(x_{t}|x_{<t})\\)\\을 사용하여 모델을 훈련시켜 입력 서열의 손실 없는 압축(Deletang et al., 2023)을 극대화한다. 우리는 ADAM 최적기(킹마 및 2014년 Ba)와 확률적 구배 하강기를 사용한다. 배치 크기 128, 시퀀스 길이 256 및 학습 속도 \\(10^{-4}\\)로 500K 반복을 훈련한다. UTM 데이터 출처에서 우리는 로그 손실을 절단하여 정규화된 SI 버전(제2.2절)에 근사한다. 우리는 RNN, LSTM, Stack-RNN, Tape-RNN 및 트랜스포머의 다음 아키텍처를 평가한다. 우리는 Stack-RNN(Joulin and Mikolov, 2015)과 Tape-RNN(Deletang et al., 2022)이 각각 심볼을 저장하고 조작하는 스택과 테이프 메모리로 증강된 RNN이라는 점에 주목한다. 이 외부 메모리는 Deletang et al.(2022)에서 알 수 있듯이 네트워크가 더 나은 예측을 할 수 있도록 도와야 한다. 폭과 깊이를 동시에 증가시켜 건축별 3가지 모델 크기(S, M, L)를 고려한다. 모델 변동당 3개의 매개변수 초기화 종자를 훈련합니다. 모든 아키텍처 세부 사항에 대한 부록 D.1을 참조하세요.\n' +
      '\n' +
      '<x_{t} <\\\\]\\_ \\log\\__\\\\<\\)) 및 \\_\\log\\_ \\\\<\\__\\\\<\\_ \\\\_ \\\\<\\> (R_{t} <\\<\\>) \\Ｈ을 예상한 후회_, \\_{t} <\\<\\> (R_{t} <\\<\\<\\<\\<\\<\\<\\<\\>) \\<\\<\\<\\<\\<\\<\\<\\<\\<\\<\\>) \\<\\<\\<\\<\\<\\<\\<\\>) \\__\\<\\<\\<\\<\\<\\<\\<\\<\\>) \\<\\<\\<\\<\\<\\<\\<\\> <\\<\\<\\> <\\<\\> <\\<\\>) \\<\\<\\> <\\<\\>) \\_.\\<\\> (R_{t> 즉, \\<\\<\\>) \\<\\<\\<\\> 유감이 낮을수록 더 좋아집니다. 우리는 _in-d 분포_(훈련에 사용된 것과 같은 길이) 및 _out-of-d 분포_라 하는 길이 1024를 지칭하는 길이 256의 6k 서열에 대한 신경 모델을 평가한다.\n' +
      '\n' +
      '## 4 Results\n' +
      '\n' +
      '** 가변차 마르코프 소스(VOMS) 결과*** 그림 2(Left)에서 실제 샘플(블루 포인트), 접지 진리(레이), 트랜스폼러-L(레드) 및 CTW(블루) 예측과 함께 길이 256의 VOMS 데이터 소스로부터 예시 궤적을 보여준다. 우리가 볼 수 있듯이 CTW 예측기와 트랜스폼러-L의 예측은 중첩되어 있으며, 이는 트랜스퍼가 베이지안들을 구현하고 있음을 시사한다.\n' +
      '\n' +
      '그림 3 |는 **섀스키 계층화 작업**(과제당 400)의 6k 서열에 대한 평가이다. 모델 크기가 증가함에 따라 모든 아키텍처에 걸쳐 누적 후회(**Left***) 및 정확도(**중간**)가 향상된다. 전반적으로, 트랜스퍼러-L은 마진으로 최고의 성능을 달성합니다. ** 네:** 길이 일반화(1024 단계) 과제당 자세한 결과는 부록에 대한 그림 8에 나와 있다.\n' +
      '\n' +
      'SI를 수행하는 데 필요한 CTW와 같은 프로그램/나무보다 포함됩니다. 두 번째 패널과 세 번째 패널에서는 순간적인 후회와 누적 후회도 겹친다. 그림 2(중)는 분포에서 평가된 모든 신경 예측 변수의 누적 후회를 보여준다. 먼저, 우리는 모델 크기가 증가함에 따라(S, M, L에서) 누적 후회량이 감소한다는 것을 관찰한다. 가장 좋은 모델은 트랜스포머-L이 최적의 성능을 달성하는 반면, 최악의 모델은 RNN과 Tape-RNN이다. 후자의 모델은 외부 메모리를 성공적으로 레버리지 못할 가능성이 있다. LSTM-L이 최적의 성능에 가깝게 달성되는 방법에 주목한다. 우측에서 우리는 변압기가 길이 일반화에 실패하는 방법을 보여주는 분포 외 성능을 보여주는 반면 LSTM은 최고의 성능을 발휘한다. 우리의 모델이 투쟁하는 위치를 더 잘 이해하기 위해 부록 F, 그림 6(c) 및 6(d)에서 보여주므로 누적 후회는 다양한 CTW 트리 깊이와 컨텍스트 길이의 궤적에 걸쳐 평균을 냈다. 모델들은 모든 트리 심층 및 중형 컨텍스트 길이들에 대한 투쟁을 균일하게 수행한다.\n' +
      '\n' +
      '*** 체스키 계층적 결과*** 그림 3(Left)에서 누적 후회 및 정확성을 통해 체스키 계층적 과제에 대해 훈련된 모든 모델의 분포 내 성능을 보여준다. 전반적으로, 트랜스퍼러-L은 마진으로 최고의 성능을 달성합니다. 이것은 우리의 모델, 특히 트랜스퍼가 알고리즘 추론의 능력을 어느 정도 가지고 있음을 시사한다. 우리는 모델의 길이 일반화 능력을 보여주며, 이는 트랜스퍼가 더 긴 길이로 일반화할 수 없는 방법을 보여준다. 부록(그림 8)에서는 각 과제별 결과를 개별적으로 보여주고 있다.\n' +
      '\n' +
      '*** 유니버설 튜링 기계 결과*** 그림 4(Left)는 (로오스) 솔로몬오프 어퍼 바운드 (UB)를 비개인 기준선으로 하여 UTM 과제에 대한 평균 누적 후회(설명 제3절 참조)를 보여준다. 중간에 우리는 모든 모델이 상당히 좋은 정확도를 달성하는 방법을 보여준다. 이는 우리의 모델이 데이터에 존재하는 광범위한 패턴 세트를 학습할 수 있는 방법을 보여준다(예: 부록 그림 6의 UTM 궤적 참조). 일반적으로 더 큰 아키텍처는 더 낮은 누적 후회에 도달하고 모든 모델은 솔로몬오프 상단을 꺾었다. 위쪽 결합은 출력을 생성한 기본 프로그램을 사용하여 계산되는 반면 신경 모델은 이 정보를 가지고 있지 않기 때문에 결합보다 더 나은 성능은 비-개인적이다. 그림 9(부록)에서 프로그램 길이에 대한 누적 후회를 보여주고 예상대로 서열의 기본 프로그램이 우리 모델의 누적 후회도가 높을수록 프로그램 길이와 예측 난이도의 강한 상관관계를 시사한다. 놀랍게도, 그림 5에서 UTM 데이터에 대해 훈련된 트랜스포머 네트워크가 클래스키 작업으로 가장 많은 전달을 나타내고 LSTM이 VOMS 태스크로 가장 많이 전달(기본적인\' 랜덤 예측기)한다는 것을 알 수 있다. VOMS의 경우, 우리는 비교를 가능하게 하기 위해 알파벳 크기를 VOMS 태스크와 일치하는 2로 설정하는 브레인 푸케 UTM로 LSTM 및 트랜스포머 모델을 재학습했다. 모든 전달 결과는 UTM 데이터가 이러한 작업에 충분한 전달 가능한 패턴을 포함함을 시사한다.\n' +
      '\n' +
      '5가지 토론과 결의가 있습니다.\n' +
      '\n' +
      '** 대형 언어 모델(LLM)과 솔로몬오프 인덕션*** ML 커뮤니티는 지난 몇 년 동안 다양한 데이터(Hoffmann et al, 2022; Kenton and Toutanova, 2019)에 대한 막대한 모델의 훈련을 목격했다. 이러한 경향은 우리 논문의 전제, 즉 점점 더 보편적인 모델을 달성하기 위해 대형 아키텍처와 많은 양의 다양한 데이터를 필요로 하는 것과 일치한다. LLM은 기하학 내 학습 역량(Chowdhery et al., 2022; Kenton and Toutanova, 2019)이 인상적이었던 것으로 나타났다. 장거리 부착 문서에 전처리된LLM은 공유 잠재 개념(왕 등은 2023년, Xie et al, 2022)을 추론함으로써 몇 가지 예에서 새로운 작업을 학습할 수 있다. 프로컨텍스트 학습은 암묵적인 베이지안 추론(CTW 실험과 일치)을 수행하고 세계 표현과 알고리즘(Li et al, 2023, 2023),(SI를 수행해야 하는 필요)을 구축하기 때문에 그렇게 할 수 있다. 실제로 LLM의 인상적인 맥락 내 일반화 능력은 솔로몬오프 유도의 대략적인 근사의 신호라고 주장할 수 있다. 우리의 방법(보편적 데이터에 대한 학습)에 비해 미리 학습된 LLM의 장점은 LLM 데이터(책, 코드, 온라인 대화 등)가 인간에 의해 생성되므로 우리가 해결하고 싶은 과제(인간)와 매우 잘 정렬되는 반면, UTM은 반드시 인간 작업에 높은 확률을 부여하지 않는다는 것이다.\n' +
      '\n' +
      '**는 우리 논문의 UTM** Theorem 9(및 (Sterkenburg, 2017)를 학습하면 보편성을 유지하면서 UTM의 프로그램 분포를 수정/학습하는 경로가 열린다. 이는 인간 업무와 관련된 프로그램에 높은 확률을 부여하는 분포를 선호하기 때문에 실질적인 중요성이 있다. 마찬가지로 선하그와 허터(2014)의 목적은 관심 문제에 정렬된 UTM을 직접 배우는 것이다. 좋은 UTM 또는 프로그램 분포는 우리의 모델을 개선하는 데 사용되는 더 나은 합성 데이터 생성을 갖는 데 기여할 것이다. 이는 머신러닝 분야(카타오카 등, 2020; 레슬리 등, 2017; 페레스, 왕, 2017)에서 성공적으로 사용되는 데이터-증강 기술과 동등할 것이다. 우리의 정리 9가 장착된 향후 연구에서 우리는 더 많은 인간 정렬 출력을 생성하기 위해 UTM에서 샘플링 프로세스에 최적화하는 연구를 계획한다.\n' +
      '\n' +
      '*** 증가는 유니버설 건축** UTM \\(U^{s}(p)\\)의 출력(프로그램 \\(p\\))은 최대 \\(s\\) 계산 단계를 필요로 한다. 미근접 \\(M_{s,L,n}\\)는 \\(\\) 심층 및 상황 길이 \\(n\\)의 넓은 네트워크(많은 프로그램을 병렬로 표현하기 위해)를 순전히 필요로 한다. 따라서 더 큰 네트워크는 더 강한 SI 근사치에 더 잘 근사할 것이다. 계산 패턴을 재사용할 수 있다면 깊이는 깊이를 재사용할 수 있다.\n' +
      '\n' +
      '그림 4: **UTM 데이터 생성기***에는 6k 서열이 있다. **Left:*** 건축물이 클수록 누적 후회가 낮아진다. 우리는 비생활 기준 솔로몬오프 어퍼 바운드(UB)보다 더 나은 성능을 볼 수 있다. **중간:** UTM 데이터에 대한 평균 정확도는 모델이 UTM 패턴을 빠르게 학습할 수 있음을 보여준다. ** 네:** 길이 일반화(1024 단계) 프로그램 길이당 자세한 결과는 그림 9와 같다.\n' +
      '\n' +
      '그림 5: ** 전달 학습**는 3k 궤적에 대한 _UTM 훈련 모델_이다. 초스키 계층화 작업에 대해 평가된 UTM 데이터에 대해 학습된 신경 모델의 평균 누적 후회(**Left***) 및 정확도(***중간-Left**)를 평가했다. 우리는 트랜스포머 모델에서 정확도의 작은 증가(전달)를 관찰한다. CTW로의 전달은 **중간-오른쪽:** 평균 누적 후회 ** 우:** 평균 정확도; \'Naive\'는 무작위 균일한 예측 변수이다.\n' +
      '\n' +
      '아이티보다 작습니다. 트랜스포머는 \\(O(\\log T)\\(Liu et al, 2023)에서 길이 \\(T\\)의 모든 오토마타를 나타내는 재사용 가능한 "쇼트츠"를 나타내는 것으로 판단된다. 일련 계산량을 증가시키는 대안적인 방법은 이론적인 결과를 위한 연쇄 항문(Wei et al., 2022)이다(Hahn and Goyal (2023 참조). 데이터가 제한적일 때 일반화를 위해서는 귀납적 편향이 중요하다. 운 좋게도 신경망은 초기화(Dingle et al., 2018; 명나드 et al., 2023; 발레-페레즈 et al., 2018)에서 간단한 기능에 대한 암묵적인 귀납적 편향을 가지고 있어 유한 데이터 체제에서 SI를 근사화하기 위해 노력할 때 매우 편리하다.\n' +
      '\n' +
      '** 제한*** 결과는 우리의 결과의 경험적 특성을 감안할 때 신경 네트워크가 SI의 보편성을 모방한다는 것을 보장할 수 없다. 솔로몬프 유도는 계산할 수 없는/일관성이며 한계에 정확히 맞추는 무한한 시간이 필요할 것이다. 그러나 우리의 이론적 결과는 좋은 근사치가 원칙적으로 메타 학습을 통해 얻을 수 있음을 확립하는 반면, 우리의 경험적 결과는 많은 질문이 열려 있지만 메타 학습을 위한 효율적인 관련 범용 데이터 세트를 구성하는 방법, 쉽게 변경할 수 있는 보편적인 아키텍처를 얻는 방법 등 그 방향으로 실용적인 진전을 이룰 수 있음을 보여준다.\n' +
      '\n' +
      '** 연결*** 우리는 메타 학습을 솔로몬오프 유도에 근사하는 원동력으로 사용하는 것을 목표로 했다. 이를 위해 데이터 생성 과정과 훈련 손실을 주의 깊게 명시하여 수렴(SI의 다양한 버전으로)이 한계에서 달성되도록 해야 했다. 세 가지 다른 알고리즘 데이터-소식에 대한 우리의 실험은 신경 모델들이 알고리즘과 베이지안 혼합물을 구현할 수 있고 더 큰 모델이 성능을 증가시킨다는 것을 말해준다. 놀랍게도 UTM 데이터에 대해 훈련된 네트워크는 광범위한 전달 가능한 패턴을 학습했음을 시사하는 다른 영역으로 전달을 나타낸다. UTM 데이터를 사용하여 접근법을 스케일링하고 기존 대형 데이터 세트와 혼합하여 미래 시퀀스 모델을 개선할 수 있다고 믿습니다.\n' +
      '\n' +
      '** 도입성 진술*** 이론 측에서는 부록에 모든 증명서를 작성하였다. 데이터 생성을 위해 오픈 소스 저장소[https://github.com/google-deepmind/neural_networks_chiationky_hierarchy] (https://github.com/google-deepbep/neural_chclonalky_hierarchy)를 사용하여 키스키 작업에 대해 완전히 설명했으며 부록에서 UTM을 완전히 설명했다. 우리는 부록에 설명된 수정과 함께 딜랑 등(2022)(동일한 오픈 소스 저장소에서 찾을 수 있는)과 동일한 아키텍처를 사용했다. 모델 교육을 위해 JAX [https://github.com/google/jax] (https://github.com/google/jax)를 사용했다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* 보(1964) C. 보음. 테링 기계 가족 및 관련 프로그래밍 언어에서 __ 테이크링 기계 계열과 관련 프로그래밍 언어. ICC 게시물_, 1964:185-194.\n' +
      '* Catt 등은 E. Catt, D. Quarel 및 M. 허터. _Hutter. __Hutter. __Hutter. __Hutter. __Hutter. 유니버설 인공지능_에 대한 소개. 챗봇 & 홀/CRC 인공지능 및 로봇 시리즈입니다. 타일러와 프란시스코, 2024년 ISBN 9781032607153 URL[http://www.hutter1.net/ai/uaibook2.htm](http://www.hutter1.net/ai/uaibook2.htm). 400+ 페이지[http://www.hutter1.net/ai/uaibook2.htm](http://www.hutter1.net/ai/ctic/uaibook2.htm)이다.\n' +
      '* 첸 et al.(2017) Y. S. 길로이, A. 말테티, J. 5. 및 K. 야. 가중 언어 인식자로서의 __재현 신경망은 가중 언어 인식자로서의 기억 신경 네트워크이다. arXiv 프리프린트 arXiv:1711.05408_ 2017.\n' +
      '* 체스스키(1956) N. 흠스키. 언어의 설명을 위한 3가지 모델 __ _3의 언어 기술 모델. __. 정보 이론_, 2(3):113-124, 1956에 대한 IRE 거래.\n' +
      '(2022) A. 차우더리, S. 쇼위더리, S. 나랑, J. 데블린, M. 보스마, G. 미슈라, A. 로버츠, C. 션튼, S. 바햄, H. W. 정. 게르만, 팜: 경로를 사용한 스칼링 언어 모델링. __. 팜: 스칼링 언어 모델링 arXiv 프리프린트 arXiv:2204.02311_, 2022.\n' +
      '(2022) G. 데레탕, A. 루실, J Grau-Moya, T. T. 그레이우-모야, T. 진웨인, L. K Wenliang, E. Catt, C. Cundy, M.M. 허터, S. 레그, J. 비리티, et al. 신경 네트워크 및 키스키 계층입니다. Eleventh 국제 학습 발표회의_, 2022년입니다.\n' +
      '* 데레탕 등 (2023) G. 데레탕, A. 루실, P-A. 두케네, E. Catt, T. 진웨인, C. 마턴, J. 그레이모야, L. K. 원리앙, M. 아치슨, L. 오세우, M. 하터, J. 비티. 언어 모델링은 압축, 2023입니다.\n' +
      '* 딩글 등 (2018) K. 듀클, C. Q. 카마르고, A. 루이. 투입량 출력 맵은 단순한 출력에 강하게 편향되어 있다. __투입량 출력 맵은 단순 출력에 강하게 편향되어 있다. 자연 통신_, 9(1):761, 2018.\n' +
      '* 엘만(1990) J L. 엘만. 시간적으로 구조를 찾는 것은 시간적으로 구조. __. 인지. __Sci.__Sci.__Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._Sci._ 1990년.\n' +
      '(2016) D. Filan, J. Leike 및 M. M. Filan et al.(2016) D. Filan, J. Leike 및 M. 하터. 손실은 속도 제자를 위한 시간과 복잡성에 결합합니다. i_인공 지능 및 통계_에서는 2016년 PMLR 1394-1402페이지이다.\n' +
      '* 진웨인 등은 T. (2023) T. 진웨인, 지아르디아 데레탕, A. 리토스, L. K. 원리앙, E. Catt, V. V. 드레스도르, J Grau-Moya, L. 오세우, M. 하터, J. 비티. 비파괴 분포에 대한 메모리 기반 메타 학습 __기억 기반 메타 학습은 비파괴 분포에 대한 메타 학습이다. 기계학습_ 2023년 국제회의.\n' +
      '* 한, 고달(2023) M. 하나, N. 고달. 갑작스러운 인-텍스트 학습 이론은 암묵적 구조 유도로서 __ 응급 인-텍스트 학습 이론이다. arXiv 프리프린트 arXiv:2303.07971_, 2023.\n' +
      '* 호흐레테르 및 슈미트히버(1997) S. 호크로테르와 J. 슈미트후버. 장단기 기억. __장기 단기 기억. __장기 단기 기억. _. 신경 컴퓨터___Neural Comput___Neural Comput__Neural Comput__Neural Comput._Neural Comput._Neural Comput._Neural Comput._Neural Comput._Neural Comput._Neural Comput._Neural Comput. 1997년.\n' +
      '2022) J. 호프만, S. 호프만 등(2022). 보라기우드, A. 머쉬, E. 부차츠카야, T. Cai, E. Rutherford, D. d. Casas, L. Hendricks, J Welbl, A. Clark, et al 훈련은 최적 대형 언어 모델을 계산한다. arXiv 프리프린트 arXiv:2203.15556_ 2022.\n' +
      '\n' +
      '* 호스피데일레스 et al. (2021) T. 호스피데일레스, A. 안토니우, P. 미카엘리 및 A. 스토키. 신경망에서의 메타 학습 : 신경망에서의 메타 학습: A 조사: A 조사. __ 메타 학습. 패턴 분석 및 기계 지능_, 44(9):5149-5169, 2021에 대한 IEEE 거래.\n' +
      '* 홉터(2004) M. 허터. _Hutter. __Hutter. __Hutter. __Hutter. __Hutter. 유니버설 인공지능: 알고리즘 확률_에 기초한 필수 결정. 2004년 생강 사이언스&비즈니스 미디어.\n' +
      '* 홉터(2006) M. 하터. 인간 지식 압박상 2006/2020년 공개 종료[http://prize.hutter1.net/] (http://prize.hutter1.net//]\n' +
      '* 홉터(2007) M. 하터. 보편적 예측 및 베이지안 확인에서 ___보편적 예측 및 베이지안 확인. __. 이론 컴퓨터 과학_, 384(1):33-48, 2007 ISSN 0304-3975. 도이: 10.1016/j.tcs.2007.016 URL[http://arxiv.org/abs/0709.1516](http://ariv.org/abs/0709.1516])이다.\n' +
      '* 홉터(2017) M. 하터. 유니버설적 학습이론이요. C. 삼무트와 G. 웹b에서 기계학습 및 데이터 결합_의 편집자, _사이클로피디아, 1295-1304 페이지, 2판, 2017년 ISBN 978-1-4899-7686-4. 도이: 10.1007/978-1-4899-7687-7687-1_767-1_767-767-767-7687-767-767-767-7687-7687-767-7687-767-7.2467](http://ariv/7687-767-7687-767-7687-767-7.7-7687-7687-767-7.7-7687-7687-767-7.7-7687-767-7.7-767-7.7-767-7.7-767-7.7-767-7.7-767-7.7-767-7.7-767-7.7-767-\n' +
      '2007년(2007) M. Hutter et al. 허터, S. 레그, P. M. 비타니. 알고리즘 확률 __알고리즘 확률. __Alg 알고리즘 확률. __Alg 알고리즘 확률. 콜라피디아_, 2(8):2572, 2007. ISSN 1941-6016. 도이: 10.4249/콜라피디아 2572.\n' +
      '* 자울린, 미콜로프(2015) A. 자울린. T. 미콜로프가. 스택-증강 재발성 그물이 있는 알고리즘 패턴을 전달한다. 2015년 신경 정보 처리 시스템 28_의 _Advances에서.\n' +
      '* 카타오카 등 (2020) H. 카타오카, K. 오카수, A. 마쓰모토, E. 야마가타, R. 야마다, N. 인우, A. 나카무라 및 Y. 사토. 자연적인 이미지 없이 사전 훈련하세요. 2020년 컴퓨터 비전_에 대한 아시아 회의의 _검토에서.\n' +
      '* 켄톤과 투타노바(2019) J D. M-W. C. 켄톤과 L. 쿠타노바. 저: 언어 이해를 위한 깊은 양방향 변압기의 사전 훈련. NAACL-HLT_의 _수익에서 2019년 페이지 4171-4186.\n' +
      '* 킹마, Ba(2014) D. P. 킹마 및 J. Ba. 확률적 최적화를 위한 방법 __Adam: 확률적 최적화를 위한 A 방법. arXiv 프리프린트 arXiv:1412.6980_ 2014.\n' +
      '* 라티모어 등 (2011) T. 라티모어, M. 하터, V. 가반. 선택된 비트의 범용적 예측은. "알고리즘 학습론"에서 제22회 국제회의, ALT 2011, Espoo, 핀란드, 2011년 10월 5-7일, 2011년 10월 22_, 262-276페이지. 스프링거.\n' +
      '2017년 (2017) J Lemley, S. S. Lemley 등. 바즈라프칸과 P. 코코반. 스마트 증강 학습은 최적 데이터 증강 전략 __ 스마트 증강 학습 최적 데이터 증강 전략. _ 스마트 증강 학습. 아이제 액세스_, 2017년 5:5858-5869입니다.\n' +
      '* Li 등은 K. (2023a) Li, A. K. 호프킨스, D. 바우, F. 비야스, H. Pfensis 및 M. 와텐베르크. 새로운 세계 표현: 합성 작업에 대해 훈련된 시퀀스 모델을 요약한다. Eleventh 국제 학습 발표회의_, 2023a. URL[https://openreview.net/forum?id=DeG07_TcZvT] (https://openopenreview.net/forum?id=DeG07_TcZvT)\n' +
      '* Li와 비타니(1992) M. Li와 P. 비타니. 인덕티브 추론 및 카놀모로프 복잡성 _ 유도 추론 및 카놀모로프 복잡성. __ol모고로프 복잡성. 컴퓨터 및 시스템 과학_ 저널, 1992년 44(2):343-384.\n' +
      '* Li 등은 (2019) M.M. Li, P. 비타니, 예를 들어. _An는 Kolmogorov 복잡성과 그 적용_에 대한 소개이다. 식기, 4판, 2019.\n' +
      '* Li et al.(2023b) Y. Li, M. 아이디즈, D. 파파일리오포울로스 및 S. 오미악. 컨텍스트 내 학습에서 일반화 및 암묵적 모델 선택: 알고리즘으로서 변환기. __을 알고리즘으로 변환한다. arXiv 프리프린트 arXiv:2301.07067_, 2023b.\n' +
      '(2023) B. 류, J. T. Ash, S. S. S. Ash, S. S. Liu 등 (2023) B. Liu, J. T. Ash, S. 골, A. 키시남루티, C. 장. 트랜스포머들은 오토마타에게 숏컷을 배웁니다. Eleventh 국제 학습 발표회_, 2023년 URL[https://openreview.net/forum?]De4FYqjFueZ](https://openopenreview.net/forum=De4FYqjFueZ)에서 학습 설명회.net/forum?\n' +
      '\n' +
      '* 말리 등은 A. 말리, A. 오로비아, D. 코퍼 및 L. 말리 등 (2023) A. 말리, A. 오로비아, D. 코퍼 및 L. 가일을. 2차 재발성 신경망의 계산 복잡성 및 형식적 계층화에 대해 _2차 순환 신경망의 계산 복잡성 및 형식적 계층에 대해. arXiv 프리프린트 arXiv:2309.14691_, 2023.\n' +
      '* 미클릭 등 (2020) V. 미클릭, 지아르디아 딜랑, T. McGrath, T. 진웨인, M. 입자, S. 레그, P. 오리테가. 메타 훈련제는 베이즈 최적 제제를 구현한다. _Meta 훈련제를 구현한다. 신경 정보 처리 시스템_, 2020년 33:18691-18703의 발전이다.\n' +
      '* 명가드 등 (2023) C. 명가드, H. 레스, G. 발레-페레스 및 A. 루이. 딥 뉴럴 네트워크는 내장 오클람의 면도기가 있습니까? __? arXiv 프리프린트 arXiv:2304.06670_, 2023.\n' +
      '* 뮐러(1993) U. 물러. 브러플*ck. [측면://esolangs.org/wiki/Brainfuck]]. 1993년 (https://esolangs.org/wiki/Brainfuck) [온라인, 21-Sept-2023]에 접근했다.\n' +
      '2019년(2019) P. A. 오르테가, J.X 왕, M.M. 왕, M. 오리테가 등. 로웨이랜드, T. 진웨인, Z. 커트넬슨, R. 파스칸루, N. 하이스, J. 비리티, A. 프릿젤, P. 슈흐만 등은 순차적 전략의 메타 학습. arXiv 프리프린트 arXiv:1905.03030_ 2019.\n' +
      '* 페레스와 왕(2017) L. 페레스와 J. 왕. 딥러닝을 이용한 이미지 분류에서 데이터 증강의 효과 __ 딥러닝을 이용한 이미지 분류에서 데이터의 효율성은 증대된다. arXiv 프리프린트 arXiv:1712.04621_ 2017.\n' +
      '* 라스마너와 허터(2011) S. Rathmanner와 M. 하터. 보편적 유도의 철학적 치료. __ 보편 유도의 철학적 치료. 엔트로피_, 13(6):1076-1136, 2011.\n' +
      '* 슈미트후버(2002) J. 슈미트후버. 이전 속도: 새로운 단순성은 거의 최적이 아닌 계산 가능한 예측을 생성하는 측정이다. E_Proc에서. 15번째 제. 존 컴퓨터 학습 이론(COLT\'02)_, _LNAI_의 2375, 216-228 페이지, 호주 시드니, 스프링거.\n' +
      '*칩서(2012) M. 슬립어 __스퍼. _Sipser. __Sipser. __Sipser. 컴퓨팅론_에 대한 소개. 코스 테크놀로지 케이지 러닝, 보스턴, MA, 3차 편집, 2012년 ISBN 978-1-133-18779-0.\n' +
      '* 솔로몬오프(1964a) R. J. 솔로몬오프. 유도성 추론에 대한 형식적 이론이다. 부분 i._ 정보 및 대조군_, 1964a. 7(1):1-22이다.\n' +
      '* 솔로몬오프(1964b) R. J. 솔로몬오프. 유도성 추론에 대한 형식적 이론이다. ___ 부분 ii. __ 부분 ii. __ 정보 및 제어_, 7(2):224-254, 1964b.\n' +
      '* Sterkenburg (2017) T. F. Sterkenburg. 알고리즘 확률의 일반화된 특성화는 알고리즘 확률의 일반화된 특성이다. __ 컴퓨터 시스템_, 61:1337-1352의 고려.\n' +
      '* Stogin et al. (2020) J Stogin, A. 말리 및 C. L. Giles. 자극적으로 안정적인 뉴럴 네트워크 튜링 머신 __ 안정 신경 네트워크 튜닝 머신. arXiv 프리프린트 arXiv:2006.03651_ 2020.\n' +
      '* 선에하그 및 허터(2013) P. 선에하그 및 M. 하터. 솔로몬오프 유도 및 아스피리의 원칙. I_Alg 알고리즘 가능성 및 프렌즈에서. 베이지안 예측 및 인공지능: 레이 솔로몬오프 85기념회의, 멜버른, VIC, 호주, 2011년 11월 30일-12월 2일, 2011년 11월 2일, 386-398페이지. 스프링거.\n' +
      '* 선에하그 및 허터(2014) P. 선에하그 및 M. 하터. 오캄을 전 세계에 추론하거나 강요하는 것으로 이해한다. E_Proc에서. 7번째 제. 인공지능 일반정보(AGI\'14)_, _LNAI_의 부피 8598, 2014년 캐나다 퀘벡 시 186-195 페이지. 스프링저. ISBN 978-3-319-09273-7. 도이: 10.1007/978-319-319-09274-4_18.\n' +
      '(2019) M.M.* 스즈건. 수즈건, S. 게르만, Y. 벨링코프, S. M. Shieber. 메모리-증강 순환 신경망은 일반화된 다이크 언어를 학습할 수 있다. __기억-증강 순환 신경망은 일반화된 다이크 언어를 학습할 수 있다. CoRR_ 2019.\n' +
      '* 발레-페레즈 등 (2018) G. 발레-페레스, C. Q. 카마르고 및 A. 루이. 파라미터-기능 맵이 단순한 기능에 편향되어 있기 때문에 딥러닝은 일반화되어 있다. __ arXiv 프리프린트 arXiv:1805.08522_ 2018.\n' +
      '\n' +
      'A. 바소와이, N. 세제, N. 파마, J. 우스즈코레이트, L. 존스, A. N. 고메스, L. 카이저, 나 폴로숙신. 당신이 필요로 하는 모든 것에 관심이 있습니다. 2017년 신경 정보 처리 시스템 30_의 _Advances에서.\n' +
      '* Veness et al. [2012] J. Veness, P. Sunehag, and M. Hutter. On ensemble techniques for aixi approximation. In _International Conference on Artificial General Intelligence_, pages 341-351. Springer, 2012.\n' +
      '* Wang et al. [2023] X. Wang, W. Zhu, and W. Y. Wang. Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning. _arXiv preprint arXiv:2301.11916_, 2023.\n' +
      '* Wei et al. [2022] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. _Advances in Neural Information Processing Systems_, 35:24824-24837, 2022.\n' +
      '* Willems et al. [1997] F. Willems, Y. Shtarkov, and T. Tjalkens. Reflections on "the context tree weighting method: Basic properties". _Newsletter of the IEEE Information Theory Society_, 47(1), 1997.\n' +
      '* Wil 문제점 [1998] F. Wil 문제는요. 맥락-트리 가중법: 확장. __연장. 1998년 정보 이론_, 44(2):792-798에 대한 IEEE 거래.\n' +
      '* Willems et al. [1995] F. M. Willems, Y. M. Shtarkov, and T. J. Tjalkens. The context-tree weighting method: Basic properties. _IEEE transactions on information theory_, 41(3):653-664, 1995.\n' +
      '* Wood et al. [2011] I. Wood, P. Sunehag, and M. Hutter. (Non-)equivalence of universal priors. In _Proc. Solomonoff 85th Memorial Conference_, volume 7070 of _LNAI_, pages 417-425, Melbourne, Australia, 2011. Springer. ISBN 978-3-642-44957-4. doi: 10.1007/978-3-642-44958-1_33. URL [http://arxiv.org/abs/1111.3854](http://arxiv.org/abs/1111.3854).\n' +
      '* Wood et al. [2013] I. Wood, P. Sunehag, and M. Hutter. (non-) equivalence of universal priors. In _Algorithmic Probability and Friends. Bayesian Prediction and Artificial Intelligence: Papers from the Ray Solomonoff 85th Memorial Conference, Melbourne, VIC, Australia, November 30-December 2, 2011_, pages 417-425. Springer, 2013.\n' +
      '* Xie et al. [2022] S. M. Xie, A. Raghunathan, P. Liang, and T. Ma. An explanation of in-context learning as implicit bayesian inference. In _International Conference on Learning Representations_, 2022. URL [https://openreview.net/forum?id=RdJVFRHjUMI](https://openreview.net/forum?id=RdJVFRHjUMI).\n' +
      '\n' +
      '## 6 Appendix\n' +
      '\n' +
      '### Solomonoff samples\n' +
      '\n' +
      '반심에서 샘플링하면 반측정 \\(\\mu\\)에서 스트링을 샘플링할 수 있으며, 이는 빈 문자열 \\(x=\\epsilon\\)으로 시작하는 것이다.\n' +
      '\n' +
      '확률 \\(\\mu(a|x):=\\mu(xa)/\\mu(x)\\)는 \\(Exin\\mathcal{X}\\)에 대해 \\(x\\s xa\\)를 연장한다. 반복하세요.\n' +
      '\n' +
      '확률 \\(1-\\sum_{a\\in\\mathcal{X}}\\mu(a|x)\\)의 수익률은 \\(x\\)이다.\n' +
      '\n' +
      '\\(D:=(x^{1},...,x^{J})\\는 \\(\\mu\\)에서 샘플링된 \\(J\\) 서열이다. 이러한 샘플만 있으면 다음과 같이 \\(\\mu\\)를 추정할 수 있습니다.\n' +
      '\n' +
      '”\\[\\hat{\\}}=\\ \\frac{D}}\\ \\\\ |D|{1}\\ \\\\\\{1}{|_{y\\in D}[[\\uu(x)\\geq\\y\\ y_{1:\\geq\\ y_{1:\\]]\\stackrel{{{ w.\n' +
      '\n' +
      '_Proof:_ Let \\(D_{x}):=(y\\in D:\\geq\\(y)\\ \\wedge\\ y_{1:\\ell(y)}=x)\\)은 \\(x\\)에서 시작하는 요소이다. \\(x^{j}\\)는 \\(\\mu\\)에서 i.d를 샘플링하기 때문에 많은 수의 법칙은 \\(J\\to\\\\)에 대한\\(|D_{x}|/|D|\\to\\mu(x)를 의미한다. (\\Box\\)\n' +
      '\n' +
      '단순 정규화 방식인 정상화가 제한 정규화이다.\n' +
      '\n' +
      '}}}}M_{s,L,}(x_\\)\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n' +
      '\n' +
      '이것은 최대 길이 \\(n\\)에 대한 서열에 대한 적절한 척도이다. 그것으로부터 샘플링은 \\(M_{s,L,n}\\)의 샘플링과 동일하지만 \\(n\\)보다 짧은 모든 서열을 폐기한다. HH(비테테실드{D}:=(x^{j}\\in D^{J}:\\ell(x^{j})\\geq n)\\로 하자. 그러면 그러면 그러면.\n' +
      '\n' +
      '}\\,L,n,\\.{D}}\\ <\\sum_{y\\\\>}\n' +
      '\n' +
      '_Proof:_ 우선, \\(|\\etilde{D}|D|\\)은 길이 \\(n\\)를 갖는 서열의 상대적인 분획이며, \\(\\sum_{x_{1:n}}}M_{s,L,n}(x_{1:n})은 서열이 길이가 \\(n\\)이므로 전자가 \\(J\\to\\ty\\)에 대해 후자로 수렴할 확률이다. 둘째.\n' +
      '\n' +
      '}},\\_\\n}:\\n{)\\.\n' +
      '\n' +
      '셋째, 양측에서 합계 \\(\\sum_{x_{i+1:n}}\\)를 취하고 최종적으로 한계 \\(s,L,n\\to\\ty\\)를 취하고 \\(x=x_{1:x}\\)를 설정한다. (\\Box\\)\n' +
      '\n' +
      '이 정규화 계획의 단점은 서열 \\(x\\)의 확률이 \\(x) <n\\)에 의존하는 반면, \\(M_{s,L,n}(x)\\) 및 \\(M_{\\}^{norm}(x)\\)는 본질적으로 \\(n\\)와 무관하다는 것이다.\n' +
      '\n' +
      '**p위치 4**: _Let \\(D:=(x^{1},...,x^{J})\\)는 반측정 \\(예:\\mu\\)(M\\)에서 샘플링된 \\(J\\) 서열이다. \\(\\hat{\\mu}_{\\)} <\\\\frac{D}> <\\\\frac{D} <\\\\<{y\\<{D}>) <\\geq\\ell(x)\\wedge\\ y_{1:\\wedge\\ y_{1:\\wedge\\ y_{1:\\Ｈ을 추정할 수 있다.\n' +
      '\n' +
      '_Proof:_ Let \\(D_{x}):=(y\\in D:\\geq\\(y)\\ \\wedge\\ y_{1:\\ell(y)}=x)\\)은 \\(x\\)에서 시작하는 요소이다. \\(x^{j}\\)는 \\(\\mu\\)에서 i.d를 샘플링하기 때문에 많은 수의 법칙은 \\(J\\to\\\\)에 대한\\(|D_{x}|/|D|\\to\\mu(x)를 의미한다. (\\Box\\)\n' +
      '\n' +
      '***Prop위치 6**: \\(D^{J}:=(x^{1},...,x^{J})\\)는 측정치 \\(M_{s,L,n}\\)의 샘플이다. 그런 다음\\(\\hat{M}_{D^{J}}[\\hat{D^{J}}[\\hat{D^{J}[\\geq\\ell(x)\\ \\geq\\y_{1:\\geq\\\\ y_{1:\\wedge\\ y_{1:\\ell(x)\\ \\geq\\ell(x)\\ \\geq\\ell(x)\\ \\geq\\y\\)\\y\\y\\)\\y\\i\\uuI}[\\geq\\el(x)\\ \\geq\\y\\y\\)\\ \\geq\\y\\ y_{J}[\\geq\\)\\ y_{J}[\\geq\\y)\\ y_{J}[\\wedge\\ y_{1:\\ \\wedge\\ y_{1:\\)\\ y_{1:\\ \\wedge\\ y_{1:\\ y_{1:\\ y_{1:\\ y_{1:\\ y_{1:\\ y_{1:\\\n' +
      '\n' +
      '_Proof:_ 요약 4에서 직접 따른다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:17]\n' +
      '\n' +
      '\\(x\\in\\mathcal{X}^{*}\\) 이전에 표준(컴퓨팅) 솔로몬오프로 한계에서 수렴되는 신경 모델을 학습할 수 있지만 렘마크 7으로 인해 정규화된 버전에 초점을 맞춘다.\n' +
      '\n' +
      '_훈련 변화: \\(M\\)의 경우, 트랜스퍼러는 \\(x\\(x)<n\\)이면 \\(x\\봇\\)을 예측하도록 훈련된다. \\(x) <n\\)는 \\(U^{s}\\)의 시간 한계(\\) 때문일 경우, \\(x\\) 이후에 \\(\\봇\\)를 예측하기 위해 Transformer를 훈련시키는 것이 바람직하며, 이는 우리가 궁극적으로 관심을 갖는 \\(\\to\\infty\\)에 대해 \\(x\\)의 적절한 심볼로\\(x\\)를 확장할 수 있기 때문이다. 이를 달성하기 위한 한 가지 방법은 이하 \\(M^{norm}\\)와 유사한 \\(t=\\ell(x)\\)에서 이 사건 로그손실(전용)을 절단하여 \\(\\봇\\) 예측을 위한 트랜스포머를 보상하지 않는 것이다.\n' +
      '\n' +
      '증발된 솔로몬오프.\n' +
      '\n' +
      '여기 손실의 도출이 있습니다.\n' +
      '\n' +
      '(x_\\u)}} <\\u_{{} <\\u_{{}>\\.\n' +
      '\n' +
      '마지막 평등이 (3)에서 뒤따르는 경우.\n' +
      '\n' +
      '상급자 C 일반화솔로몬오프\n' +
      '\n' +
      '스트리밍 함수(\\varphi\\)는 성장하는 입력 시퀀스를 취하고 성장하는 출력 시퀀스를 생성한다. 일반적으로 입력 및 출력은 결합되지 않은 상태로 성장하거나 유한하게 유지될 수 있다. 형식적으로, \\(\\varphi:\\mathcal{X}^{\\#}^{\\#}\\to\\mathcal{X}^{\\#}^{\\#}\\) 즉,\\(\\mathcal{X}^{{\\#}:=\\mathcal{X}^{\\ty}^{\\cal{X}^cup\\mathcal{X}^cup\\mathcal{X}^{\\#}^{\\#}^{\\#X}^{\\#}^{\\#}^{\\#}^{\\#}^{\\#}^{\\#}^{\\#}^{\\#}^{\\#}^{\\ty{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^{\\ty}^cup\\mathcal{X}^cup\\mathcal{X} 원칙적으로 입력 및 출력 알파벳이 다를 수 있지만 단순성을 위해 모든 서열이 이진, 즉 \\(\\mathcal{X}=\\{0,1\\}\\)라고 가정한다. I\\(\\varphi\\)가 스트리밍 함수로 적격하기 위해서는 입력을 연장하는 것이 단지 확장되어 출력을 수정하지 않도록 해야 한다. 형식적으로 표현하자면, 우리는 형식적으로 균형 있게 말한다고 말하고 있다.\n' +
      '\n' +
      '\\[\\vPer\\{]은}\\quad\\text{:\\varphi(q):\\varphi(p)]\\이다.\n' +
      '\n' +
      'H\\(q\\sqsubseteq p\\)는\\(q\\)가 \\(p\\)의 프리픽스임을 의미하며, \\(I\\리스트 r\\in X^{\\#}:qr=p\\), \\(\\sqsubseteq\\)는 엄격한 프리픽스 \\(r\\neq\\)를 나타낸다. (p\\)은\\(H:\\ex리스트 r:\\phi(p)=xr\\) 및 \\(\\forall r\\forall q\\sqsubseteq p:\\i(q)\\neq xr\\)인 경우,\\(x\\)에 대해 최소이다. 우리는 이를 \\(\\varphi(p)=x*\\)로 나타낼 것이다. (p\\)은 \\(x\\)로 시작하는 문자열을 출력하는 최단 프로그램이다.\n' +
      '\n' +
      '모노톤 투링머신(MTM)은 좌우 읽기 전용 입력 테이프, 좌우 쓰기 전용 출력 테이프, 일부 양방향 작업 테이프가 있는 튜링 기계입니다. 함수의 \\(\\varphi_{T}\\)는 출력 심볼을 작성한 후, 출력 헤드를 이동시키기 전, 입력 헤드를 이동시킨 후, 새로운 셀 콘텐츠를 판독하기 전에, \\(p\\)가 현재 입력 테이프 헤드의 좌측 내용이고, \\(x\\)가 현재 출력 테이프 헤드로 출력되는 테이프의 내용인 경우, \\(\\varphi_{T}(p):=x\\)의 함량인 경우,\\(\\,\\_{T}(p)를 현재 출력 테이프 헤드가 현재 출력 테이프 헤드에 이르는 출력 테이프의 함량인 경우,\\(p\\_{T}(p)의 함량인 경우,\\(\\_{T}(p)를 현재 출력 테이프 헤드에 이르는 출력 테이프의 함량인 경우, \\(\\,\\_{T}(p)의 함량인 경우,\\(\\,\\_{T}(p)은 \\,\\_{T}(p)의 함량인 경우,\\_{T}(p)의 함량인 경우,\\_{T}(p):=x\\,\\_{T}:=x\\) I\\(\\varphi_{T}\\)는 모노톤인 것을 쉽게 알 수 있다. 우리는 \\(T(p)=\\varphi_{T}(p)\\를 약칭한다. (최적의) 범용 MTM \\(U(i^{\\prime}q)=T_{1}, T_{2})인 T_{i}(q)\\를 통해 다른 MTM을 에뮬레이션할 수 있는 게 있다. 모든 MTM 및 \\(i^{\\prime}\\)의 효과적인 열거는 \\(i\\)(Hutter, 2004; Li et al., 2019)를 인코딩하는 프리픽스이다.\n' +
      '\n' +
      '정룡 9의 프로##.\n' +
      '\n' +
      '\\(M^{Q}_{U}(x)\\(Q\\)는 계산 가능한 측정값이고 \\(Q(q)>0\\)\\(\\for q\\in q\\mathcal{X}^{*}\\) 및 \\(Q_q_{1:n})\\(n\\to\\infty\\) 0\\)은 계산 가능한 측정치이고 \\(Q)\\(Q)\\(Q\\(Q\\)\\(Q\\)\\(Q\\)\\(Q\\)\\(Q\\)\\(Q\\(Q\\)\\(Q\\)\\(Q\\)\\(Q\\)\\(Q)\\)\\(Q)\\(Q)\\(Q)\\(Q)\\(Q)\\(Q)\\(g\\)\\(Q)\\(Q)\\(Q)\\(Q)\\(Q)\\(Q)\\(Q)\\ a\\)\\(Q)\\(Q)\\(Q)\\)\\(Q)\\(Q)\\(Q)\\(Q)\\ a\\)\\(Q)\\ 보다 정확하게는, 위의 특성을 가진 모든 범용 모노톤 TM \\(U\\) 및 모든 \\(Q\\)에 대해 \\(M^{Q}_{U}(x) = M_{V}(x)\\(\\forall x\\)\\(\\forall x\\)s가 존재한다. 부록 C.___ 부록 C.__ 부록의 증명.\n' +
      '\n' +
      '우리는 무한히 많은 공정한 코인 플립을 이용할 수 있다면 계산 가능한 모든 \\(Q\\)에서 효과적으로 샘플링할 수 있다. I\\(Q\\)의 조건은 \\(Q\\)의 엔트로피가 무한하도록 하고, 모든 \\(q\\in\\mathcal{X}^{*}\\)에 조절하더라도 무한 상태를 유지한다. 이는 또한 \\(Q\\)에서 샘플을 무한히 많은 균일한 랜덤 비트로 전환시키는 역효과를 허용한다. 포워드 및 후방 변환은 (객관적) 산술(de) 코딩을 통해 샘플 효율이 높을 수 있다. 이는 아래 입증의 근거를 이루고 있다. (x_{1:\\frac{1}}\\), \\(x_{t}{1}\\), \\(x_{t}{2}\\)\\(x_{t}{.{t}{1}\\)의 경우, a\\(x_{t}{1)\\(x_{t}{1:\\-\\-\\-\\-\\-\\-\\)의 경우, \\(x_{U}(x_{t}{1)\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\)의 경우, \\(x.{U} <\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\)의 경우, a\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\)의 경우, a\\-\\-유사}(x.\n' +
      '\n' +
      '프로파: _(케토)_ Let \\(0.q_{1:\\infty}\\in[0;1]\\)는 이진 팽창 \\(q_{1:\\infty}\\)을 갖는 실수이다. 이러한 식별을 통해 \\(Q\\)는 \\([0;1]\\)에 대한 확률 척도로 볼 수 있다. (F(0.{t:q_{i})=1}}(T_{q_{i}:\\inf) 누적 분포 함수, 즉\\(F_{q_{q_{i}:0.\\)\\(F:{q_{i}:0.\\)\\(F:{q_{i}) 및\\(\\)\\(T_{q_{i}:0.{i})\\(T_{q_{i}:\\:{q_{i}:\\:{i}:\\:{q_{i}:\\:{i}:\\:{i}:{i}:\\:{i}:{i}:\\)\\)\\) <\\<\\:{i}:{i}:\\)\\)\\)]\\(ff:\\. 이제\\(Q(q)>0\\)\\(\\for q\\in\\mathcal{X}^{*}\\)를 가정하면 \\(F\\)가 엄격하게 증가하고 있다는 것을 의미하며,\\(Q(q_{1:n})\\에서 0\\)는 \\(F\\)가 계속적이라는 것을 의미한다. 이는 \\(F(0)=0\\) 및 \\(F(1)=1\\)이므로 \\(F\\)가 생체 주입임을 의미한다. 일부 유한 프리픽스 \\(q\\sqsubset q_{1:\\infty}\\)에 대해 간격(0.p_{1:\\infty})(0.q_{1:\\infty}) 및\\(0.q_{1:\\infty}=F^{-1}(0.p_{1:\\infty})\\)를 분할한다.\n' +
      '\n' +
      'Footnote 3:\\(p_{1:m}\\)가 균일하게 분포되어 있으며(일부\\(m\\))는 본질적으로 \\(q_{1:n}\\)를 하나의 카펫으로 암호화하는 산술이다: 서열로부터의 매핑(0.q10^{\\infty}=0.q01^{\\infty}\\)을 합류한다. 모든 합류 서열의 세트는 확률 \\(0\\), (Q\\) 뿐만 아니라 버누이(\\(\\(\\(\\frac{1}{2}\\))를 갖기 때문에, 이 합류로 인해 도입된 모든 오류는 분포 \\(M^{Q}_{U}(x)에 영향을 미치지 않는다.\n' +
      '\n' +
      'p^{1}_{1:\\infty};\\,0.p^{1}_{1:\\infty})\\ :=\\ [F(0.q0^{{\\infty}:\\ =:\\ \\{{ \\infty}); F(0.q1^{ \\infty}:\\):\\[F(0.q0^{{ \\infty}:\\－0^{{ \\infty}:\\ =:\\ <0^{{{{{{{{{{{{{{{{{<<0^{{{{{{{{{{<<0^{{{{{{{{<<<0^{{{{{{{{<\\}:\\>:\\-<<0^{{{ \\infty}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\}:\\\n' +
      '\n' +
      '최소 이진 간격 \\(0.T_{p}\\) 세트로, 여기서 \\(\\Phi(q)\\는 \\(p\\), \\(p0\\), \\(p1\\) 중 대부분은 \\(\\Phi(q)\\에 있다는 의미에서 최소 프리픽스 자유 집합이다. 명시적 표현은\n' +
      '\n' +
      '>t_{0}\\wot p^{1}_{t}.\n' +
      '\n' +
      'i\\(t_{0}\\)가 \\(p^{0}_{t}\\neq p^{1}_{t}\\)인 최초의 \\(t\\)이다. 이제.\n' +
      '\n' +
      '0.{p}.{p\\(q.{\\)\\＆\\-\\[0.105.\\ a\\ \\:\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ >어, 어! (i\\) \\(T_{i}(q)=T(i^{\\prime}q)\\ \\forall q\\)로 한다. Ex\\(\\dot{\\prime}):=\\ell(i^{\\prime})+1\\) 및 \\(\\dot{\\ell}:=\\dot{\\ell}:=p^{i})+1\\) 및 \\(q_{{i}:=i^{\\prime}=p^{i})\\) \\(p^{\\ing}) \\) \\(p^{\\ell}) \\(p^{\\ell}) \\(p^{\\ell:\\(p^{\\ell(p^{\\ell(p^{\\ell(p^{\\ell(p^{\\ell:p^{\\ell:p^{\\ell:p^{\\ell:p^{\\ell})＋1\\) \\) \\) \\(p^{\\ell}) \\) \\(p^{\\ell}) \\) \\(p^{\\ell}) \\) \\(p^{\\ell}) \\) \\) \\ 이제 \\(V(p_{1:\\infty})=U(q_{1:\\infty})를 의미한다.\n' +
      '\n' +
      '\\ =\\ T_\\prime}(F^{\\q_{\\dot{k})\\ =\\ U_ 느껴진다.\n' +
      '\n' +
      '에이스 \\(V\\)는 보편적인 것으로 증명을 마무리한다.\n' +
      '\n' +
      '실용적인 범용 스트리밍 기능 튜링 기계는 비실용적이며 범용 스트리밍 기능을 위한 프로그램을 작성하는 것은 피하는 것이 가장 좋은 단방향의 또 다른 층이다. 프로그래밍 언어는 이미 보편적인 기계입니다. 우리는 실제 프로그램의 전환을 이진 스트링으로부터/대 바이너리 스트링으로 정의하고 입력 스트림으로 프리텐딩할 수 있다. 입력 스트림(q_{1:\\infty}\\)을 샘플링할 때, 우리는 시작을 원하는 프로그래밍 언어의 프로그램으로 변환하고, 이를 입력 스트림으로 꼬리를 먹인다.\n' +
      '\n' +
      '실험 방법론 세부 내용\n' +
      '\n' +
      '### Architecture details\n' +
      '\n' +
      'Rnn. 바닐라 다층 RNN(1990,Elman, 1990)은 표 1에 설명된 RNN 층 전후에 숨겨진 크기와 다층 퍼셉트론(MLP)을 가지고 있다.\n' +
      '\n' +
      '별다른 스택(Joulin and Mikolov, 2015)에 액세스하여 표 1에 대한 접근과 LSTM으로 표 1에 따라 숨겨진 크기를 가진 스트락-RNN 다중층 RNN 컨트롤러이다. 제어기는 RNN 출력의 선형 판독보다 소프트맥스에 의해 주어진 작용 가중치와 함께 표 1에 따른 크기 스택 상에서 푸시, 팝 및 노톱의 임의의 선형 조합을 수행할 수 있다. 스택의 각 셀은 치수 6의 실제 벡터를 포함하고 스택 크기는 모든 (S, M 및 L) 크기에 대해 64이다.\n' +
      '\n' +
      '베이비-NTM 아키텍처(수즈건 등 2019)에서 영감을 받은 다양한 테이프에 대한 접근으로 표 1에 따라 숨겨진 크기를 가진 테프-RNN 다중층 RNN 컨트롤러가 있다. 제어기는 소프트맥스에 의해 주어진 액션 가중치와 함께 테이프로 쓰기 우, 쓰기 좌, 라이트 스페이, 점프 좌, 점프 우의 임의의 선형 조합을 수행할 수 있다. 행동은 현재 위치에서의 글쓰기와 오른쪽 위치(쓰기-우측)로 이동하며, 현재 위치(쓰기-좌측), 현재 위치(쓰기-좌측)에서 쓰기(쓰기-좌측), 점핑 \\(액션-우측) 단계가 입력 길이인 경우(점프-좌측)로, 점핑 \\(\\\\)는 입력 없이 왼쪽으로 이동한다(점프-좌측)에 대응한다. 스테크-RNN에서와 같이 테이프의 각 셀은 치수 6의 실제 벡터를 포함하고 테이프 크기는 모든 (S, M, L) 크기에 대해 64이다.\n' +
      '\n' +
      'Lstm. 다층 LSTM(Hochreiter and Schmidhuber, 1997)은 표 1에 따라 숨겨진 크기의 다중층 LSTM이다.\n' +
      '\n' +
      '형질전환기 디코더. 바닐라 트랜스포머 디코더(Vaswani et al, 2017) 모델 크기별 임베딩 차원, 헤드 수 및 레이어 수(S, M, L)에 대한 표 1을 참조한다. 각 레이어는 주의 레이어, 2개의 조밀한 레이어 및 레이어 정규화로 구성된다. 우리는 원래 건축(Vaswani et al, 2017)에서와 같이 잔류 연결을 추가한다. 우리는 표준 죄/코스(바사와이 등, 2017) 위치 인코딩을 고려한다.\n' +
      '\n' +
      '### Ctw\n' +
      '\n' +
      '아래는 (샘플링) CTW(문제 등, 1997, 1995)에 대한 초소형 도입이다. 보다 자세한 설명과 토론 및 유도체화를 위해 (Catt et al, 2024, Chp.4)를 확인할 수 있다.\n' +
      '\n' +
      '가변차 마르코프 프로세스(binary) 서열(x_{1},x_{2},x_{3},x_{3})에 대한 확률 분포. 다음과 같은 속성으로서, 편지 \\(S\\subset\\{0,1\\}^{*}\\)는 완벽한 바이너리 트리로 등가하게 볼 수 있는 완전한 질식 없는 스트링 세트(역전구 없는 코드)이다. 그런 다음, \\(x_{t}=0|x_{t};S,\\_{S}): \\(x_{t}\\)의 (독특한) 맥락이 \\(s=x_{t-\\ell(s):t-1}\\in S\\), \\(\\_ta_{s}.=(\\_{t[0;1:\\)인 경우 ai(x_{t} <S,\\_{s})가 \\(s=x_{t})인 경우,\\_{t_{s}\\)가 \\(s=x_{t_{t_{s)인 경우,\\_{t_{s}\\)이고,\\_{t_{s}\\)는 \\(s=x_{t_{s)이고,\\)는 \\(s=x_{t_{t_{s)이고, a)는 \\(s=x_{t_{t_{s}\\)이고, a)는 \\(x_{t_{t- 우리는 \\(t\\leq 0\\)에 대해 임의로 \\(x_{t}=0\\)를 정의한다.\n' +
      '\n' +
      'Variable-order 마르코프 소스VOMS에 대한 교육은 나무 구조에서 생성된 데이터를 고려한다. 예를 들어, 이진 트리를 감안할 때\n' +
      '\n' +
      'Root\n' +
      '\n' +
      '0/ \\(\\backslash\\)1\n' +
      '\n' +
      'Leaf_0 Node\n' +
      '\n' +
      '0/ \\(\\backslash\\)1\n' +
      '\n' +
      'Leaf_10 Leaf_11\n' +
      '\n' +
      '데이터 "011"의 이력을 감안할 때(0이 첫 번째 관측 데이터이고 1이 마지막 것) 다음 샘플이 Leaf\\({}_{11}\\)를 사용하므로) (역사의 마지막 두 데이터 포인트가 11이기 때문에) 매개변수 Leaf\\({}_{11}\\)로 Beta 분포의 샘플을 사용하여 다음 데이터를 그린다. 우리는 0을 샘플링하여 역사를 "0110"으로 형질전환하고 레이프티({}_{10}\\)를 사용하여 다음 데이터(지금 잎에 맞는 마지막 두 데이터포인트가 "10"이기 때문에)를 샘플링할 것이다. 이러한 데이터 생성 방법은 매우 일반적이며 확률적 샘플을 가질 수 있는 01010101 이상의 복잡한 패턴과 같은 간단한 규칙적인 패턴으로부터 많은 흥미로운 패턴을 생성할 수 있다. 더 큰 나무는 실제로 매우 복잡한 패턴을 인코딩할 수 있다.\n' +
      '\n' +
      'CTW에서 샘플링하는 것은 최대 순서 \\(D\\in\\mathbb{N}_{0}\\), 즉 최대 깊이 \\(D\\)의 모든 나무(S\\) 및 모든 \\(\\theta_{s}\\in[0;1]\\)에 대한 최대 순서 \\(D\\in S\\)의 모든 가변차 마르코프 공급원에 대한 베이지안 혼합물이다. CTW 분포는 다음과 같이 얻어졌으며, 우리는 빈(냉동) \\(S=\\{\\epsilon\\}\\)로 시작한다. 유사체{{1}}{{2}}\\) 확률 \\(I\\)를 사용하여 \\(s\\)를 동결하고, 확률 \\(\\sfrac{1}{2}\\)을 사용하여 우리는 모든\\(s\\ S\\)가 동결 또는 \\(s\\(s\\)될 때까지 \\(\\)를 동결한다. 그런 다음 모든\\(s\\in S\\)에 대해 \\(\\text{Beta}(\\sfrac{1}{2},\\sfrac{1}{2})\\)의 \\(\\ta_{s}\\)를 샘플한다. 마지막으로 \\ (t=1,2,3) we 샘플 \\(x_{t}\\) \\(x_{t}|x_{<t};S,\\_{S})의\\(x_{t}\\)이다.\n' +
      '\n' +
      'r\\ \\(x_{t})(t-1}) 즉, ax_{t} < <{t} < <{t}> < <{t}>의 수를 다음과 같이 계산할 수 있다. i\\(x_{1:n}^{s}\\in\\{0,1\\}^{a_{s}+b_{s}}\\)는 맥락 \\(x_{t}\\)을 갖는 \\(x_{t}\\)의 하위 집합체이다. I\\(s\\in S\\)에 대한\\(\\theta_{s}\\)의 경우, \\(x_{1:n}^{s}\\)는 ii.d(Bernoulli\\((1-\\theta_{s}\\)이다. (a_{0}{s}},b_{s}})=P_{{s}} <{{s}} <{{s}} <{{a_{s}}}(1-\\frac{a_{s}})\\(1-\\text{a_{s}}}. I\\(s\\notin S\\)가 되면 \\(x_{1:n}^{s}\\)를 \\(x_{1:n}^{0s}\\) 및 \\(x_{1:n}^{1s}\\)로 분할한다. P_{1}}}(x_{1:{{s}})\\{W}}(x_{{s}})\\(P_{{s}}(x_{{s})\\(P_{{s}})\\(P_{{s}}(x_{{s}:{{s})\\(x_{{s})\\{s}}(x_{{s}:{{s})\\{s}}(x_{{s} <{{s})\\{s})\\{s}}(x_{{s}.{{s})\\{s}})\\{s}}(x_{{{s})\\{s}})\\{s}}(x_{{{s})\\{{s}})\\{s}}(x{{{s})\\{{s}})\\{s}})\\{s}}(x_{{s}})\\{{s}})를 재종종종종종종종종종종 이는 \\(P_{\\text{CTW}}(x_{1:n})\\평등 P_{\\text{CTW}}(x_{1:n}^{c})\\의 정의를 완료한다. 컴퓨팅용 충분한 \\(P_{\\text{CTW}}(x_{1:n}) 알고리즘(x_{1:n}) 및 시간 \\(O(D)\\)) 및 비귀적 정의를 Catt 등(2024, Chp.4)에서 찾을 수 있다.\n' +
      '\n' +
      '트리의 분포는 빈 나무이거나 두 하위 나무 모두 깊이 \\(<d\\)가 있는 경우 깊이 \\(\\leq d\\)를 갖는다. 따라서 깊이 \\(\\leq d\\)의 나무를 샘플링할 확률은 \\(F(d)=\\frac{1}{2}{2+\\frac{1}{2}{2}\\), \\(F(0)=\\frac{1}{2}\\)이다. 따라서 깊이 \\(d\\)의 나무를 샘플링할 확률은 \\(d<D\\) 및 \\(P(D)=1-F(D-1)\\에 대한 \\(P(d)=F(d)-F(d-1)\\이다. 이론 곡선(P(0)=\\frac{1}{2}\\), \\(P(1)=\\frac{1}{8}\\), \\(P(2)=\\frac{9}{128}\\tape cell)은 비음성 정수를 함유할 수 있어 \'알파벳 크기\'만큼 크게 성장할 수 있다. 그 수 이상에서는 0으로 되돌아가며, 종이는 17의 알파벳 크기를 선택한다.\n' +
      '\n' +
      '각 테이프에는 포인터가 있습니다. 단순화를 위해 작업 테이프의 포인터를 WTP라고 하며, WTP에서의 값을 정수인 _datum_이라 한다.\n' +
      '\n' +
      'BF는 8가지 지시 <>+[]를 사용한다. 이거야.\n' +
      '\n' +
      '* < > 감소 및 > 감소, WTP의 증가, 테이프의 길이를 수정한다.\n' +
      '*는 기준인 알파벳 크기를 증가시키고 감소시킵니다.\n' +
      '*[조건부 점프: 기준값이 0이면 명령어 포인터가 해당(매칭) ]로 점핑한다.\n' +
      '해당 [.5**]에 해당하는 [.5**]가 무조건 점프하는 것이 해당 [.5**]에 대한 무조건 점프이다.\n' +
      '*, 판독 테이프 포인터 아래의 번호를 데이터움 셀에 복사하고, 판독 포인터를 증가시킨다.\n' +
      '*. 출력 포인터에서 출력 테이프에 기준들을 복사하고 출력 포인터를 증가시킨다.\n' +
      '\n' +
      '본 논문에서는 입력 테이프를 사용하지 않아, 지시서를 사용하지 않습니다.\n' +
      '\n' +
      '프로그램 평가 시, 명령어 포인터는 처음에 제1 명령어에, 출력 테이프는 비어 있고, 작업 테이프에는 제로스가 채워진다. 그런 다음 명령어 포인터 아래의 명령어를 상기 규칙에 따라 평가하고, 명령어 포인터를 우측으로 이동시킨다. 평가된 지침의 수가 주어진 한계에 도달하거나 출력 심볼의 수가 주어진 한계에 도달하면 평가는 종료된다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l} \\hline \\hline\n' +
      '**Level** & **Name** & **Example Input** & **Example Output** \\\\ \\hline \\multirow{4}{*}{Regular (R)} & Even Pairs & _aabba_ & True \\\\  & Modular Arithmetic (Simple) & 1 + 2 - 4 & 4 \\\\  & Parity Check\\({}^{\\dagger}\\) & _aaabba_ & True \\\\  & Cycle Navigation\\({}^{\\dagger}\\) & 011210 & 2 \\\\ \\multirow{4}{*}{Deterministic context-free (DCF)} & Stack Manipulation & _abba_ pop push \\(a\\) pop _abba_ \\\\  & Reverse String & _aabba_ & _abba_ \\\\  & Modular Arithmetic & \\(-(1-2)\\cdot(4-3\\cdot(-2))\\) & 0 \\\\  & Solve Equation\\({}^{\\circ}\\) & \\(-(x-2)\\cdot(4-3\\cdot(-2))\\) & 1 \\\\ \\multirow{4}{*}{Context-sensitive (CS)} & Duplicate String & _abaab_ & _abaabbaba_ \\\\  & Missing Duplicate & 10011021 & 0 \\\\  & Odds First & _aabba_ & _aaaaba_ \\\\ \\multirow{4}{*}{Context-sensitive (CS)} & Binary Addition & 10010 + 101 & 10111 \\\\  & Binary Multiplication\\({}^{\\times}\\) & 10010 + 101 & 1001000 \\\\ \\multirow{4}{*}{Compute Sqrt} & Compute Sqrt & 100010 & 110 \\\\ \\cline{1-1}  & Bucket Sort\\({}^{\\dagger\\star}\\) & 421302214 & 011222344 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 표 (탈랑 등, 2022)에서 취하였다. 추스키 계층화 및 예제 입출력 쌍에서 그 수준을 갖는 태스크를 수행한다. \\(\\dagger\\)는 순열-불변 태스크를 나타내며, \\(\\star\\)는 카운팅 태스크를 나타내고, \\(\\circ\\)는 비결정론적 컨트롤러를 필요로 하는 태스크를 의미하며, \\(\\toxy\\)는 입력 길이 측면에서 초선형 실행 시간이 필요한 태스크를 나타낸다.\n' +
      '\n' +
      'i\\(A\\), \\(B\\) 및 \\(C\\)가 (웰 균형) 지시의 서열인\\(A[B]C\\)의 명령어 시퀀스에 대해 블록의 _body_ 및 \\(C\\) 블록의 _body_ 계속되고_를\\(B\\)라고 부른다.\n' +
      '\n' +
      '얼룩한 생성 및 평가.\n' +
      '\n' +
      '우리는 임의의 BF 프로그램을 샘플링하고 각각 \\(T\\) 단계에 대해 평가하고 싶습니다. 샘플링 및 실행 과정의 계산 효율을 극대화하기 위해 불균형 괄호들을 포함하는 프로그램은 특히 추가 ]를 스킵함으로써 유효하게 이루어진다.\n' +
      '\n' +
      '우리는 _정상화_솔로몬오프 유도 3에 근사하고 싶기 때문에 몇 가지 단순화를 만들 수 있다. 특히, 프로그램들은 명시적으로 중단될 필요가 없으며, 이는 _all_ 프로그램이 무한하다고 생각하지만, 대부분의 \\(T\\) 지침에서는 평가된다고 생각한다. BF 프로그램의 어려움은 샘플링 프로세스와 큰 블록[......]을 완전히 스킵할 수 있기 때문에 평가된 명령어들이 프로그램 테이프 상의 임의의 위치에 있을 수 있다는 것이다.\n' +
      '\n' +
      '부츠 6: 노팅 행동은 이 서열을 평가할 때 \\(좌측 실세일{} 사방 자실+ 자장골{} 기준 0인지 아닌지를 루프하는)와 같은 특정 무한 루프로 프로그램을 종료하고 평가를 종료(영구 루프의 설치)함으로써 회수될 수 있다.\n' +
      '\n' +
      '이것은 BF 프로그램을 나무로 생성하여 고정할 수 있으며, 여기서 오프닝 브라켓[좌측 분기는 블록의 신체에 해당하고( ]로 종료한다) 오른쪽 가지가 블록의 지속에 해당한다. 평가 중 처음으로 오프닝 브래킷을 접할 때, 다음 지점에서 평가되는 지점은 기반에 따라 다르다. 따라서 두 가지 모두 생성하지 않기 위해 프로그램 _as를 생성해야 하는데, [데이터가 0이면 오른쪽 지점을 따라가고 (지금은) 신체를 샘플링할 필요 없이 지속을 샘플링하기 시작하며, 반대로 기준치가 0이 아닌 경우 왼쪽 지점을 따르고 계속을 평가하고 평가해야 한다. 동일한 개구 브라켓이 나중에 다른 데이터 값으로 다시 평가되면, 다른 가지를 생성하여 평가할 수 있다.\n' +
      '\n' +
      '브레인 푸케에서 프로그램 생성 및 평가에 대한 우리의 구현은 프로그램, 하나의 점프 테이블 및 아직 일치되지 않은 오픈 브래킷에 대한 하나의 성장하는 배열을 사용한다.\n' +
      '\n' +
      '명령어 포인터가 프로그램의 끝에 있는 경우 +-\\(\\prec\\)[] 중 새로운 명령어가 된다. 샘플링하면 [과 0]이면 [로 변경된다. 새로운 지시는 프로그램에 적용되었으며, 그 다음 평가됩니다. 새로운 지시가 [일 경우, 샘플(프로그램에 첨부됨)의 다음 지시가 블록의 신체의 시작이지만, 대신 새로운 지시가 [표집될 다음 지시가 (프로그램에 첨부됨) 몸의 지속이다. 이 시점에서 점프 테이블은 아직 업데이트될 필요가 없다 - 다음 평가를 위한 지시도 위치의 다음 지시이기 때문이다. 점프 테이블은 프로그램 내에 연속체와 몸체가 어디에 위치하는지 추적하도록 업데이트된다. 명령어 포인터가 결국 오프닝 브라켓[[resp. ])의 두 번째 시간 동안 다시 돌아올 경우. 원시들은 이제 0(0이 아닌 0)이다. 계속(몸통). 블록의 경우 이제 샘플링되고 프로그램에 평가되어야 하며, 현재 점프 테이블은 그에 따라 업데이트되어야 한다.\n' +
      '\n' +
      '매칭되지 않은 브라켓의 스택은 블록의 바디가 생성되어야 업데이트된다.\n' +
      '\n' +
      '브린 푸케의 일부 특성은.\n' +
      '\n' +
      '* \\(t+k\\) 단계를 위해 프로그램이 실행되면, \\(k\\)의 모든 값에 대해 첫 번째 \\(t\\) 단계에서 동일하게 행동한다.\n' +
      '* 프로그램 생성(샘플링)은 단일 성장 전용 배열만 필요하다. 트리 구조가 필요하지 않습니다. 이는 {의 추가 지시가 있는 이유로서, 두 번째 시간 - 이미 신체 또는 지속이 생성되었는지 여부를 평가한 적이 있다.\n' +
      '* 명령어 포인터가 세포 \\(n\\)에 있는 경우 \\(n\\)의 왼쪽에 대한 모든 지시는 적어도 한 번 평가되었다. 이것이 세포\\(n\\)의 첫 번째 평가라면, \\(n\\)의 권리에 대한 수업은 아직 평가되지 않았다.\n' +
      '\n' +
      '솔로몬오프 로그 손실 상한과 단축 프로그램.\n' +
      '\n' +
      '그림 4에 대한 솔로몬오프 유도 손실을 위한 의미 있는 상한선을 제공하려고 노력했지만 이것은 쉬운 것과 거리가 멀다. 맥락에 대한 제3절을 참조하세요. 거기에서 언급한 바와 같이, 보다 의미 있는 상부 경계를 계산하기 위해, 우리는 일치되지 않은 불필요한 개방 브래킷과 폐쇄 브래킷을 재귀적으로 제거하고 모든 자체 취소 쌍(+-, +, > >><)을 통해 프로그램을 단축한다. 또한, 인쇄의 마지막 평가 이후 처음으로 평가된 프로그램의 모든 지시를 제거합니다. 명령어(산출물 생산에 참여하지 않음) 이 절차는 종종 프로그램을 세 번째로 줄입니다. 따라서 어떤 것도 출력하지 않는 프로그램은 빈 프로그램(확률 1)으로 환원된다.\n' +
      '\n' +
      'I\\(q\\)가 샘플링된 프로그램이라면 \\(\\tilde{q}\\)는 해당 단축 프로그램이다. 샘플링된 프로그램 세트에 U = 브린 푸케를 사용하여 솔로몬오프 예측기의 손실에 대한 상한을 계산했다.\n' +
      '\n' +
      '그림 6: 몇몇 브레인 푸케 프로그램과 해당 출력(256개의 심볼에서 조정)을 하였다. 가장 작은 막대(빨간색)는 값 0에 해당하며, 가장 큰 막대(회색)는 값 16에 해당하며, 불필요한 지시 세트를 제거하여 평가 후 프로그램이 축소되었다. 생성된 출력은 대부분 규칙적이며, 5000개의 샘플링된 프로그램 중 약 1개만이 비정규직 패턴을 나타낸다. 그러나 이러한 수를 개선하고 보다 흥미롭고 복잡한 서열을 생성하는 방법에 대한 표 3을 본다.\n' +
      '\n' +
      '\\begin{tabular}{|c|c|c|c|c|c|c|c|} \\multicolumn{1}{c}{Markov chain order 0} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} \\\\ \\hline Ctx. & \\(<\\) & \\(>\\) & \\(+\\) & - & \\([\\) & \\(]\\) & \\(-\\) & \\([\\) & \\(]\\) & \\(-\\) & \\([\\) \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **14** & **15** & 0.08 & 0.8 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **14** & **15** & 0.08 & 0.8 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **14** & **15** & 0.08 & 0.8 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **14** & **15** & 0.08 & 0.8 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **14** & **15** & 0.08 & 0.8 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **14** & **15** & 0.08 & 0.8 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **15** & 0.08 & 0.08 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **15** & 0.08 & 0.08 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **15** & 0.08 & 0.08 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **15** & 0.08 & 0.08 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **15** & 0.08 & 0.08 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **14** & **15** & 0.08 & 0.08 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **15** & **14** & **15** & 0.08 & 0.2 & 1.400 \\\\ \\hline \\multicolumn{1}{c}{} & **14** & **15** & **15** & **15** & 0.08 & 0.2 & 1.400 \\\\\\(\\hat{Q}=(q^{1},\\ldots,q^{J})\\) and corresponding outputs (\\(U(q^{1})_{1:256},\\ldots,U(q^{J})_{1:256}\\)),\n' +
      '\n' +
      '}} (p)\\leq\\sum_{hat{Q:} (p)\\log\\hat{Q} (p) siRNA.\n' +
      '\n' +
      '프로그램 알파벳은 바이너리가 아니라 7개의 지시를 가지고 있다. 불행히도, 이 결합을 감소시키는 후에도 여전히 상당히 느슨하지만, 이러한 결합을 의미 있게 개선하는 것은 훨씬 더 많은 양의 계산이 필요할 것이다.\n' +
      '\n' +
      '수요자.\n' +
      '\n' +
      '아래에서는 VOMS(그림 7), 체스키 태스크(그림 8), UTM 소스에 대한 실험의 추가 결과를 보여준다(그림 9와 10). 마지막으로 그림 11에서 길이 일반화 분석에 대한 자세한 내용을 보여준다.\n' +
      '\n' +
      '그림 2에서와 동일한 6k 서열에 대한 그림 7 | D소매 결과는 그림 2에서 평가에 사용하기 위해 나무 깊이(모든 궤적에 대해)에 대한 히스토그램과 현재 컨텍스트 길이(모든 궤적의 모든 기준점 이외의)를 보여주었으며 예상대로 대부분의 생성된 나무는 깊이가 낮고 대부분의 데이터포인트는 짧은 맥락을 가지고 있다. 3개의 하부 패널은 트리 깊이당 평균 누적 후회, 상황 길이당 평균 순간 후회를 나타낸다. 얇은 선은 개별 모델(다른 무작위 초기화 포함)에 해당하며, 과감한 선은 모델 크기당 중앙값을 보여준다. 건축가는 매우 짧은 트리 깊이 또는 매우 짧은 컨텍스트 길이에 대해서만 잘 예측하지만(최대 컨텍스트 길이는 트리 깊이에 의해 상부 결합되지만 많은 맥락은 최대 트리 깊이보다 훨씬 짧다. 맥락 래그츠(\\geq 11\\)는 드물기 때문에 이 정권에 정량적 결과가 덜 신뢰할 수 있다.\n' +
      '\n' +
      '그림 2에서와 동일한 6k 서열에 대한 그림 7 | D소매 결과는 그림 2에서 평가에 사용하기 위해 나무 깊이(모든 궤적에 대해)에 대한 히스토그램과 현재 컨텍스트 길이(모든 궤적의 모든 기준점 이외의)를 보여주었으며 예상대로 대부분의 생성된 나무는 깊이가 낮고 대부분의 데이터포인트는 짧은 맥락을 가지고 있다. 3개의 하부 패널은 트리 깊이당 평균 누적 후회, 상황 길이당 평균 순간 후회를 나타낸다. 얇은 선은 개별 모델(다른 무작위 초기화 포함)에 해당하며, 과감한 선은 모델 크기당 중앙값을 보여준다. 건축가는 매우 짧은 트리 깊이 또는 매우 짧은 컨텍스트 길이에 대해서만 잘 예측하지만(최대 컨텍스트 길이는 트리 깊이에 의해 상부 결합되지만 많은 맥락은 최대 트리 깊이보다 훨씬 짧다. 맥락 래그츠(\\geq 11\\)는 드물기 때문에 이 정권에 정량적 결과가 덜 신뢰할 수 있다.\n' +
      '\n' +
      '그림 8: 체스키 태스크에 대해 학습 및 평가된 네트워크의 소매 성능(과제당 6k 서열, 400개 서열; 그림 3에 표시된 주요 결과) 태인은 모델의 단일 랜덤 초기화에 해당하며 볼트 라인은 각각 중앙값을 나타낸다.\n' +
      '\n' +
      '그림 9 \\(|\\)의 UTM 분포 평가 프로그램 길이당 결과(그림 4와 같은 데이터, 6k 서열, 길이 256)를 나타낸다.\n' +
      '\n' +
      '그림 10 \\(|\\) UTM이 체스키 작업으로 이전된다.\n' +
      '\n' +
      '그림 11 | 전장 일반화 결과의 전체 세부 정보는 그림 1과 같다. 모델은 각각의 태스크에 대한 길이 256의 서열에 대해 훈련되었으며 동일한 데이터 생성기 유형으로부터 길이 1024의 6k 서열에 대해 평가된다. 얇은 선은 개별 모델을 보여주며, 과감한 선은 동일한 모델의 무작위 초기화에 걸친 중앙값이다. 예상대로 모든 모델은 훈련된 서열 길이까지 상당히 잘 수행한 다음 성능이 다소 급격히 악화된다. 특히, 변압기 모델의 예측 성능은 크기에 관계없이 256단계에서 매우 빠르게 분해되며 다른 모델보다 크기가 더 나쁜 경우가 많다. 모든 실험에서 LSTM은 더 긴 서열로 일반화하는 측면에서 가장 잘 수행된다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>