<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '#D-Flow : 제어발전을 위한 흐름을 통한 차별화\n' +
      '\n' +
      'Heli Ben-Hamu\n' +
      '\n' +
      'Omri Puny\n' +
      '\n' +
      'Itai Gat\n' +
      '\n' +
      'Brian Karrer\n' +
      '\n' +
      'Uriel Singer\n' +
      '\n' +
      'Yaron Lipman\n' +
      '\n' +
      '메타에서 인턴을 하면서 한 일. ({}^{1}\\)Meta\\({}^{2}\\)Weizmann Institute of Science. 대응: Heli Ben-Hamu \\(<\\)heli.benhamu@weizmann.ac.il\\(>\\)\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '작업별 모델을 재훈련할 필요 없이 최첨단 확산 및 흐름 매칭(FM) 모델의 생성 결과를 길들이는 것은 일반적으로 역문제, 조건부 생성 및 제어된 생성을 해결하기 위한 강력한 도구의 잠금을 해제한다. 본 연구에서는 소스(잡음) 지점을 최적화하면서 흐름을 통해 미분하여 생성 과정을 제어하기 위한 간단한 프레임워크인 _D-Flow_를 소개한다. 가우시안 확률 경로로 훈련된 확산/FM 모델의 경우 생성 프로세스를 통해 차별화하고 데이터 다양체에 기울기를 투영하여 최적화 프로세스에 이전을 암묵적으로 주입한다는 주요 관찰을 통해 이 프레임워크에 동기를 부여한다. 본 논문에서는 영상 및 음성 역 문제와 조건부 분자 생성 문제를 포함한 선형 및 비선형 제어 생성 문제에 대한 프레임워크를 검증한다.\n' +
      '\n' +
      '머신러닝, ICML\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '생성 전으로부터 제어된 생성은 많은 영역에서 큰 관심을 받고 있다. 조건부 생성, 역문제, 샘플 편집 등과 같은 다양한 문제들은 모두 제어된 생성 문제로 프레이밍될 수 있다. 이 연구에서는 확산/흐름 생성 모델(Song and Ermon, 2019; Ho et al., 2020; Lipman et al., 2023)로부터 제어된 생성에 초점을 맞춘다.\n' +
      '\n' +
      '확산/흐름 모델로부터 제어된 생성을 위한 세 가지 주요 접근법들: (i) 조건부 트레이닝, 여기서 모델은 트레이닝 동안 추가 입력으로서 조건을 수신한다(Song et al., 2020; Dhariwal and Nichol, 2021; Ho and Salimans, 2022). 이 접근법을 매우 잘 수행하려면, 경우에 따라 금지적일 수 있는 생성 모델의 태스크 특정 트레이닝이 필요하지만, (ii) 사전 트레이닝 모델의 생성 프로세스를 수정하고 추가 안내를 추가하는 트레이닝 프리 접근법들(Bar-Tal et al., 2023; Yu et al., 2023). 가이던스는 일반적으로 생성의 오류를 초래할 수 있는 생성 프로세스에 대한 강력한 가정을 기반으로 하며, 대부분 방법을 목표에서 선형인 관찰로 제한한다(Kawar et al., 2022; Chung et al., 2022; Song et al., 2023; Pokle et al., 2023); 마지막으로, (iii) 가변적 관점을 채택하여, 제어된 생성을 최적화 문제로 프레임화한다(Graikos et al., 2023; Mardani et al., 2023; Wallace et al., 2023; Samuel et al., 2023). 제어를 강제하기 위해 미분 가능한 비용만을 요구한다. 이 종이는 이 세 번째 부류의 것이다.\n' +
      '\n' +
      '본 논문의 목적은 ODE sampling process_를 통해 사전 학습된 Diffusion or Flow-Matching(FM) 모델에 제어된 생성을 추가하는 프레임워크를 도입하는 것이다. 우리의 주요 관찰은 표준 가우시안 확률 경로를 사용하여 훈련된 확산/FM 모델의 경우 초기점인 \\(x_{0}\\)에 대한 \\(x\\)의 생성 과정을 통해 임의의 손실 \\(\\mathcal{L}(x)\\)을 미분하고, 기울기 \\(\\nabla_{x}\\mathcal{L}\\)을 "데이터 매니폴드", 즉 \\(x\\)에서 주요 데이터 방향에 투영하고, 값진 선행을 암시적으로 주입하는 것이다. 이러한 관찰을 바탕으로 원하는 제어를 나타내는 임의의 비용 함수 \\(\\mathcal{L}(x)\\)를 생성하는 데 사용되는 소스 잡음점 \\(x_{0}\\)의 함수로 최소화하는 간단한 일반 알고리즘을 제안한다. 즉,\n' +
      '\n' +
      '\\[\\min_{x_{0}}\\\\mathcal{L}(x. \\tag{1}\\]\n' +
      '\n' +
      'GAN 또는 일반의 생성기를 통한 차별화\n' +
      '\n' +
      '그림 1: 잠재 T2I FM 모델을 사용한 자유 형식 인페인팅(Ground truth 이미지는 MS-COCO 유효성 검사 세트에서 취함), 조건부로 생성된 분자 및 D-Flow를 사용한 오디오 인페인팅.\n' +
      '\n' +
      '제어된 생성(Bora et al., 2017; Asim et al., 2020; Whang et al., 2021)에 일반적으로 유용한 것으로 입증되었다(Bora et al., 2017; Asim et al., 2020). 최근, (Wallace et al., 2023; Samuel et al., 2023b)는 분류기 안내를 통합하고 희귀한 개념들을 생성하는 특정 태스크들에 대해 이산 확산 해결기를 통해 차별화할 것을 제안하고 있다. 이 논문에서 우리는 이 개념을 두 가지 방법으로 일반화한다: (i) 확산 및 흐름 매칭 모델을 포함한 가우시안 확률 경로로 훈련된 일반적인 흐름 모델을 고려한다; (ii) 우리는 이론적으로나 실제적으로 흐름을 미분함으로써 주입된 유도성 바이어스가 일반적인 비용 함수에 의해 모델링된 훨씬 더 광범위한 종류의 문제에 적용 가능하다는 것을 입증한다.\n' +
      '\n' +
      '본 논문에서는 조건부 이미지넷과 텍스트-2-이미지(T2I) 생성사전을 이용한 이미지의 역문제, QM9의 무조건 생성사전을 이용한 조건부 분자생성, 그리고 무조건 생성사전을 이용한 오디오 인페인팅과 초해상도 등의 다양한 설정과 응용에 대해 실험을 하였다. 모든 응용 프로그램에서 우리는 도메인과 응용 프로그램에 걸쳐 알고리즘을 주의 깊게 조정하지 않고도 최첨단 성능을 달성할 수 있었다. 이 방법의 한 가지 단점은 NVidia V100 GPU의 ImageNet-128에서 생성 시간이 일부 기준선에 비해 상대적으로 길다는 것이다. 그러나 이 방법의 단순성과 우수한 결과는 많은 사용 사례에서 사용 및 적응을 정당화할 수 있다. 게다가, 우리는 속도 향상을 위한 큰 여지가 있다고 믿는다.\n' +
      '\n' +
      '요약하자면, 우리의 기여는 다음과 같습니다.\n' +
      '\n' +
      '* 일반적인 흐름 생성 모델을 이용하여 제어된 생성 문제를 단순한 소스 포인트 최적화 문제로 공식화한다.\n' +
      '* 우리는 가우시안 확률 경로로 훈련된 흐름의 소스 포인트 최적화가 비용 함수의 기울기에 데이터-다양체 투영 거동을 나타내는 암시적 바이어스를 주입한다는 것을 보여준다.\n' +
      '* 우리는 다양한 도메인에 대해 제안된 접근법의 일반성과 유효성을 경험적으로 보여준다.\n' +
      '\n' +
      '## 2 Preliminaries\n' +
      '\n' +
      '**Flow model.** 연속 정규화 흐름(Continuous Normalizing Flows, CNFs)(Chen et al., 2018; Lipman et al., 2023) 및 (결정론적 샘플링의 확산 모델(Song et al., 2020)을 포함하는 생성 흐름 모델들(Song et al., 2020)은 일부 소스(잡음) 분포 \\(x(0)\\sim p_{0}(x_{0})\\으로부터 첫 번째 샘플링에 의해 샘플 \\(x(1)\\in\\mathbb{R}^{d}\\)을 생성한 후, Ordinary Differential Equation(ODE)을 풀 수 있다.\n' +
      '\n' +
      '\\[\\dot{x}(t)=u_{t}(x(t)), \\tag{2}\\]\n' +
      '\n' +
      '소정의 속도장 \\(u:[0,1]\\times\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{d}\\)을 이용하여 시간 \\(t=0\\)에서 시간 \\(t=1\\)1까지. 우리는 \\(x(0)\\sim p_{0}(x(0))\\이 주어졌을 때 \\(x(1)\\)의 분포와 밀도 함수를 \\(p_{1}\\)으로 나타낸다.\n' +
      '\n' +
      '각주 1: 본 논문에서는 잡음에 해당하는 \\(t=0\\)과 데이터에 해당하는 \\(t=1\\)의 관례를 사용한다.\n' +
      '\n' +
      '##3 소스 포인트 최적화를 통한 제어 생성\n' +
      '\n' +
      '신경회로망과 일부 비용함수(\\(\\mathcal{L}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}_{+}\\)로 표현되는 미리 훈련된(동결된) 흐름 모델인 \\(u_{t}(x)\\)을 고려할 때, 본 연구의 목표는 낮은 비용\\(\\mathcal{L}(x)\\)을 제공하고 흐름 모델의 분포(p_{1}\\) 하에서 가능한 샘플 \\(x\\)을 찾는 것이다. 우리는 이 문제를 다음과 같은 최적화 문제로 공식화하는 일반적인 프레임워크를 옹호한다.\n' +
      '\n' +
      '\\[\\min_{x_{0}}\\quad\\mathcal{L}(x(1)) \\tag{3}\\]\n' +
      '\n' +
      '여기서 일반적으로 \\(\\mathcal{L}\\)은 또한 \\(x_{0}\\) 및 \\(u\\)에 의존할 수 있는 잠재적으로 정규화 항을 포함하는 다중 비용을 통합할 수 있고,\n' +
      '\n' +
      '\\[\\tilde{\\mathcal{L}}(x)=\\mathcal{L}(x)+\\mathcal{R}(x_{0},u). \\tag{4}\\]\n' +
      '\n' +
      '이 공식에서, 샘플 \\(x(1)\\)은 초기 경계 조건 \\(x(0)=x_{0}\\을 갖는 ODE 2의 해로 구속되며, 여기서 \\(x_{0}\\)은 (단지) 최적화된 양이고 \\(\\mathcal{L}\\)은 원하는 비용 함수이다. 최적화 방정식 3은 알고리즘 1에 열거된 바와 같이 손실 w.r.t. 최적 변수 \\(x_{0}\\)의 기울기를 계산함으로써 수행된다. 우리는 이 방법을 _D-Flow_라고 부른다. 이 프레임워크의 일반성을 더 잘 이해하기 위해 우리는 다음으로 방정식 3의 몇 가지 인스턴스화를 고려한다.\n' +
      '\n' +
      '```\n' +
      '0: cost\\(\\mathcal{L}\\), pre-trained flow model \\(u_{t}(x)\\))initialize \\(x_{0}^{(0)}=x_{0}\\) for\\(i=1,\\dots,N\\)do \\(x^{(i)}(1)\\leftarrow\\texttt{solve}(x_{0}^{(i)},u_{t})\\)\\(x_{0}^{optimize\\_step}(x_{0}^{(i)},\\nabla_{x_{0}}}}\\mathcal{L}(x^{(i)}(1)))endfor return\\(x^{N}(1))\n' +
      '```\n' +
      '\n' +
      '**알고리즘 1** D-Flow.\n' +
      '\n' +
      '### Cost functions\n' +
      '\n' +
      '**역 샘플링.** 우선 \\(\\mathcal{L}(x)=\\left\\|x-y\\right\\|^{2}\\)인 간단한 경우를 고려한다. 이 경우, 3의 해는 ODE 궤적이 \\(t=1\\), 즉 \\(x(1)=y\\에서 \\(y\\)에 도달하는 \\(x_{0}\\)이 될 것이다. (u_{t}(x)\\)에 대한 약간의 가정 하에서 방정식 2는 임의의 \\(y\\in\\mathbbb{R}^{d}\\)에 대한 diffeomorphism \\(\\mathbbb{R}^{d}\\)을 정의하므로 방정식 3에는 고유한 해 \\(x_{0}\\in\\mathbb{R}^{d}\\)이 존재한다.\n' +
      '\n' +
      '역문제.이 경우에 우리는 몇몇 알려진 부패함수 \\(H:\\mathbb{R}^{d}\\to\\mathbb{R}^{n}\\)와 부패된 표본에 접근할 수 있다.\n' +
      '\n' +
      '\\[y=H(x_{*})+\\epsilon, \\tag{5}\\]\n' +
      '\n' +
      '여기서 \\(\\epsilon\\sim\\mathcal{N}(\\epsilon)\\)은 선택적인 부가 잡음이고, 비용 함수는 보통\n' +
      '\n' +
      '\\[\\mathcal{L}(x)=\\|H(x)-y\\|^{2} \\tag{6}\\]\n' +
      '\n' +
      '여기서 norm은 임의의 \\(L_{p}\\) norm이거나 \\(H(x)\\)와 \\(y\\)을 비교하는 일반적인 손실 \\(\\ell(H(x),y)\\)일 수 있다. 손상 함수의 특정 선택은 일반적인 응용으로 이어질 수 있다: _Image inpainting_는 전체 픽셀들 중 알려진 \\(n<d\\) 픽셀들에 대한 손상 함수 \\(H\\)를 선택하는 것에 해당하며; _Image deblurring_는 블러링 커널과의 컨볼루션과 같은 블러링 함수로서 \\(H:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}\\)를 취하는 것에 해당하며; _Super-resolution_는 블러링 커널과의 컨볼루션과 같은 차원을 \\(H:\\mathbb{R}^{d}\\to\\mathbb{R}^{d/k}\\)의 계수만큼 낮추는 것에 해당한다.\n' +
      '\n' +
      '조건부 샘플링.또 다른 중요한 응용은 샘플링 프로세스가 일부 조건부(y\\)를 만족하도록 안내하는 것이다. 이 경우, 우리는 분류기 또는 어떤 에너지 함수가 특정 클래스 또는 에너지\\(y\\)에 도달하도록 격려하기 위해 \\(\\mathcal{L}(x)\\)를 취할 수 있다. 예를 들어 \\(\\mathcal{F}:\\mathbb{R}^{d}\\to\\mathbb{R}\\)이 어떤 함수이고 우리는 일정 수준 집합 \\(c\\in\\mathbb{R}\\)으로부터 샘플을 생성하고자 한다면 손실을 사용할 수 있다.\n' +
      '\n' +
      '\\[\\mathcal{L}(x)=\\left(\\mathcal{F}(x)-c\\right)^{2}. \\tag{7}\\]\n' +
      '\n' +
      '### Initialization\n' +
      '\n' +
      '초기화는 방정식 3의 최적화 수렴에 큰 영향을 미칠 수 있다. 자연스러운 선택은 소스 분포 \\(p_{0}(x_{0})\\(p_{0}(x_{0}))에서 샘플로 \\(x_{0}\\)을 초기화하는 것이다. 관찰된 신호\\(y\\)가 원하는 \\(x\\)에 대한 많은 정보를 제공하는 경우 최적화의 수렴속도를 향상시킬 수 있음을 알 수 있었다. 예를 들어, 관찰된 \\(y\\)이 이미지의 구조에 강한 선행을 갖는 이미지 상의 선형 역문제에서, 소스 분포로부터의 샘플과 \\(t=1\\)에서 \\(y\\)의 \\(t=0\\)까지의 ODE의 역방향 용액의 혼합으로 \\(x_{0}\\)을 초기화하는 것이 유익하다:\n' +
      '\n' +
      '\\[x_{0}=\\sqrt{\\alpha}\\cdot y(0)+\\sqrt{1-\\alpha}\\cdot z\\tag{8}\\.\n' +
      '\n' +
      '여기서 \\(z\\sim p_{0}(x_{0})\\) 및 \\(y(0)=y+\\int_{1}^{0}u(t,y(t))dt\\이다.\n' +
      '\n' +
      '### Regularizations\n' +
      '\n' +
      '식 3의 공식은 다음에 논의되는 다른 정규화 \\(\\mathcal{R}\\)(식 4)를 포함할 수 있다. 이러한 정규화 중 가장 흥미로울 수 있으며, 본 논문의 주요 요점은 다음과 같이 마지막으로 논의되는 \\(\\mathcal{R}\\equiv 0\\)에 해당하는 _implicit regularization_이다.\n' +
      '\n' +
      '대상 \\(x(1)\\.아마도 가장 자연스러운 것은 표본 \\(x(1)\\), 즉 \\(\\mathcal{R}=-\\log p_{1}(x(1))\\)의 음의 로그 우도(NLL)를 방정식 4에 포함시키는 것이다. 이 선행은 \\(x(t)\\in\\mathbb{R}^{d}\\)를 추가 좌표 \\(z\\in\\mathbb{R}\\)로 증가시키고 방정식 3을 공식화함으로써 통합될 수 있다.\n' +
      '\n' +
      '(x(1))-z(1)}\\mathcal{L}(\\min_{x}(t)=u_{t}(x(t)), x(0)=x_{0} \\tag{9b}\\] \\[\\dot{z}(t)=-\\mathrm{div}\\,u_{t}(x(t)), z(0)=\\log p_{0}(x_{0}) \\tag{9c}\\]\n' +
      '\n' +
      '실제로, 수 \\(t\\in[0,1]\\)에 대해 방정식 9b 및 9c에 의해 정의된 ODE 시스템을 푸는 것은 \\(z(1)=\\log p_{1}(x(1))\\), 참조(Chen et al., 2018)를 참조한다. 그러나, 식 9c의 ODE에서 발산항에 의해 도입된 여분의 복잡성(예를 들어, (Grathwohl et al., 2018)을 제외하고, 이러한 유형의 ODE를 다루는 방법들에 대해 우도가 높은 차원에서의 깊은 생성 모델들에서 좋은 선행인지 여부는 명확하지 않다(Nalisnick et al., 2019); 도 3에서 이미지넷-128의 테스트 이미지의 비트-차원(BPD)과 이미지넷 트레이닝된 흐름 모델에 따라 더 가능성 있는 이미지를 제공하는 0으로 마스킹된 중간 정사각형을 갖는 이 이미지의 버전을 비교한다.\n' +
      '\n' +
      '소스 \\(x(0)=x_{0}\\을 정규화하는 것. 또 다른 옵션은 소스 포인트 \\(x(0)=x_{0}\\을 정규화하는 것이다. 첫 번째 선택은 잡음 샘플의 NLL, 즉 \\(\\mathcal{R}=-\\log p_{0}(x_{0})\\을 통합하는 것인데, 이는 표준 잡음에 대해 \\(p_{0}(x_{0})=\\mathcal{N}(x_{0}|0,I)\\)이 \\(\\mathcal{R}=c+\\frac{1}{2}\\left\\x_{0}\\right\\\\^{2}\\)으로 감소하며, 여기서 \\(c\\)은 \\(x_{0}\\과 무관한 상수이다. 그러나 이것은 모든 평균이 0일 가능성이 가장 높은 쪽으로 \\(x_{0}\\) 끌어당기지만, 대부분의 확률 질량과는 거리가 멀다.\n' +
      '\n' +
      '그림 3: ImageNet-128 모델에서 두 이미지의 BPD.\n' +
      '\n' +
      '그림 2: 최적화 시 중간체 \\(x(1)\\) 본 논문의 최적화는 왜곡된 영상과 초기(x(1)\\을 정의하는 무작위 초기화된 \\(x_{0}\\)이 주어졌을 때, 얼굴 블러 이미지넷-128 검증 집합에서 GT 샘플로 가는 도중에 분포 내 이미지를 통과하는 자연 이미지 매니폴드에 가깝게 이동한다.\n' +
      '\n' +
      '다음 (Samuel et al., 2023a)은 \\(p_{0}\\)의 대부분의 질량이 집중된 지역에 \\(x_{0}\\)이 머물도록 하는 대신 \\(\\chi^{d}\\) 분포를 사용하며, 이는 \\(x_{0}\\sim\\mathcal{N}(x_{0}|0,I)\\)이 다시 표준 정규 분포인 확률 변수 \\(r=\\left\\|x_{0}\\right\\|\\)의 확률 분포로 정의된다. 이 경우의 \\(r\\)의 NLL은\n' +
      '\n' +
      '\\[\\mathcal{R}=-\\log p(r)=c+(d-1)\\log\\left\\|x_{0}\\right\\|-\\frac{\\left\\|x_{0}\\right\\|^{2}}{2}, \\tag{10}\\\\tag}\\\n' +
      '\n' +
      '여기서 \\(c\\)는 \\(x_{0}\\)에 독립적인 상수이다.\n' +
      '\n' +
      '암시적 정규화.아마도 우리의 공식에서 가장 흥미롭고 잠재적으로 유용한 정규화(방정식 3)는 소스 포인트 \\(x(0)=x_{0}\\의 함수로서 비용 \\(\\mathcal{L}(x(1))\\)을 최적화하는 선택에서 비롯된다. 제로 손실로 트레이닝되는 표준 확산/흐름 모델들에 대해:\n' +
      '\n' +
      '구배 \\(\\nabla_{x(1)}\\mathcal{L}(x(1))\\)을 지역 데이터 공분산 행렬로 투영하여 \\(x_{0}\\)에 대한 비용 \\(\\mathcal{L}(x(1))\\)을 최적화하는 것은 데이터 분포 \\(p_{1}(x_{1})\\)을 따른다.\n' +
      '\n' +
      '이것은 그림 4에 직관적으로 설명되어 있다: 기울기 \\(\\nabla_{x(1)}\\mathcal{L}(x(1))\\)의 방향으로 이동하는 동안 일반적으로 데이터 분포에서 멀어지고(분홍색으로), w.r.t.\\(x(0)\\)를 미분하는 것은 이 기울기를 높은 분산 데이터 방향에 투영하고 결과적으로 데이터 분포에 가깝게 유지한다. 이 현상을 예시하기 위해 그림 2의 최적화 단계 \\(x^{(0)}(1),x^{(2)}(1),x^{(4)}(1),\\ldots\\)의 손실 \\(\\mathcal{L}(x)=\\left\\|H(x)-H(\\bar{x})\\right\\|^{2}\\)에서 보여주는데, 여기서 \\(H\\)은 전체 픽셀 수의 \\(90\\%\\)으로 구성된 이미지의 픽셀의 (랜덤) 서브세트를 서브샘플링하는 선형 행렬이고 \\(\\bar{x}\\)은 목표 이미지이다(초기 \\(x^{(0)}(1)\\과 다르다). 여기서 샘플링 과정은 클래스 조건 \'불불\'과 함께 ImageNet 훈련된 플로우 모델을 사용한다. 이 이미지 순서에서 볼 수 있듯이 최적화의 중간 단계는 분포에 가깝고 전구 새의 다른 하위 종을 통과한다. 다음 섹션에서는 이 주장을 뒷받침하는 정확한 수학적 진술을 제공하지만 지금은 직관적인 설명을 제공할 수 있도록 한다.\n' +
      '\n' +
      '### Practical implementation\n' +
      '\n' +
      '알고리즘 1의 실제 구현에는 세 가지 알고리즘 선택이 필요하다. 먼저, \\(x_{0}\\)을 초기화하는 방법을 결정해야 한다. 모든 실험에서 우리는 소스 분포, 즉 정규 가우시안으로부터 샘플로 \\(x_{0}\\)을 초기화하거나, 가능한 경우 관측된 신호의 \\(t=1\\)에서 \\(t=0\\)까지의 역해와 정규 가우시안 분산 보존 혼합을 사용한다. 둘째, 우리는 \\(x(1)\\)을 매개변수화하는 데 사용되는 솔버를 선택해야 한다. 이를 위해 우리는 토치디프텍 패키지(Chen, 2018)를 활용하여 다양한 종류의 미분 가능한 ODE 솔버를 제공한다. 솔버를 통해 역 전파하는 것은 메모리에서 비용이 많이 들 수 있으므로 런타임의 비용으로 메모리 소비를 줄이기 위해 그래디언트 체크포인팅을 사용한다. 대부분의 실험에서 우리는 6개의 함수 평가와 함께 중간점 방법을 사용한다. 마지막으로 그라데이션 단계를 위한 최적화기를 선택해야 합니다. 우리가 수행하는 최적화는 확률적이지 않기 때문에 모든 실험에서 라인 탐색과 함께 LBFGS 알고리즘을 사용하기로 선택한다. 최적화의 실행 시간은 문제에 따라 다르지만 일반적으로 샘플당 \\(5-15\\)분의 범위이다. 큰 텍스트-2-이미지 및 텍스트-2-오디오 모델의 실행 시간은 더 높고 \\(30-40\\)분에 도달할 수 있다.\n' +
      '\n' +
      '## 4 Theory\n' +
      '\n' +
      '이 절에서는 앞 절에서 이루어진 암묵적 정례화 주장에 대한 이론적 뒷받침을 제공한다. 먼저, 확산/흐름 모델을 감독하기 위해 사용되는 데이터에 노이즈를 취하는 Affine Gaussian Probability Paths(AGPP) 계열을 다시 살펴본다. 확산/흐름 모델이 제로 손실에 도달하면 이러한 확률 경로를 재현하므로 암시적 편향을 분석하는 데 사용할 것이다. 둘째, AGPP 가정 하에서 기울기 \\(\\nabla_{x_{0}}\\mathcal{L}(x(1))\\)에 대한 명시적인 공식을 제공하기 위해 인접 동역학 방법을 사용하여 \\(x(1)\\)에서 점근적 변화(속도 벡터)를 유도한다. 마지막으로, 이 속도벡터를 \\(x(1)\\)로 해석하여 데이터 분포 \\(p_{1}(x)\\)의 방향을 가리키는 이유를 설명한다.\n' +
      '\n' +
      'Affine Gaussian Probability Paths.Diffusion 및 최근 흐름 기반 모델들은 APP( Affine Gaussian Probability Path)를 이용하여 훈련에 대한 감독을 수행한다. 특히, 데노팅 \\(p_{0}=\\mathcal{N}(0,\\sigma_{0}^{2}I)\\) 가우시안 잡음(소스) 분포와 \\(p_{1}\\) 데이터(타겟) 분포에 의해 AGPP가 정의된다.\n' +
      '\n' +
      '\\[p_{t}(x)=\\int p_{t}(x|x_{1})p_{1}(x_{1})dx_{1}, \\tag{11}\\]\n' +
      '\n' +
      '여기서 \\(p_{t}(x|x_{1})=\\mathcal{N}(x|\\alpha_{t}x_{1},\\sigma_{t}^{2}I)\\)는 가우시안 커널이고 \\(\\alpha_{t},\\sigma_{t}:[0,1]\\rightarrow[0,1]\\)은 \\(\\alpha_{0}=0\\), \\(\\sigma_{1}\\approx 0\\), \\(\\alpha_{1}=1=\\sigma_{0}\\)을 만족하는 _scheduler_로 불리며, 결과적으로 \\(p_{t}\\)이 시간 \\(t=0\\) 및 \\(t=1\\)에서 소스 및 타겟 분포를 각각 정확하게 또는 대략적으로 보간하는 것을 보증한다. 이 확률 경로를 생성하고 제로 손실에서 확산/흐름 모델에 의해 트레이닝된 속도장과 일치하는 속도장은 (Lipman et al., 2023; Shaul et al., 2023)이다.\n' +
      '\n' +
      '\\[u_{t}(x)=\\int\\left[a_{t}x+b_{t}x_{1}\\right]p_{t}(x_{1}|x)dx_{1} \\tag{12}\\]\n' +
      '\n' +
      '베이즈의 정리를 중심으로\n' +
      '\n' +
      '\\[p_{t}(x_{1}|x)=\\frac{p_{t}(x|x_{1})p_{1}(x_{1})}{p_{t}(x)}, \\tag{13}\\]\n' +
      '\n' +
      '그림 4: 해결사를 통해 차별화하는 데 있어 암시적 편향.\n' +
      '\n' +
      '\\[a_{t}=\\frac{\\dot{\\sigma}_{t}{\\sigma_{t},\\quad b_{t}=\\dot{\\alpha}_{t}-\\alpha_{t}\\frac{\\dot{\\sigma}_{t}{\\sigma_{t}.\\tag{14}\\t}\n' +
      '\n' +
      '솔버를 통해 미분.확산/흐름 모델이 제로 손실로 최적화되면 AGPP 속도 필드, 즉 방정식 12를 완벽하게 재현한다(Lipman et al., 2023). 이 속도장에 대해 우리는 \\(x_{0}\\)에 대한 비용 구배에 대한 공식을 찾는다:\n' +
      '\n' +
      '**정리 4.1**.: _For AGPP 속도 필드 \\(u_{t}\\)(식 12 참조) 및 \\(x(t)\\)는 \\(x_{0}\\)의 함수로서 \\(x(1)\\)의 미분을 통해 정의된다.\n' +
      '\n' +
      '\\[D_{x_{0}}x(1)=\\sigma_{1}\\exp\\left[\\int_{0}^{1}\\gamma_{t}\\mathrm{Var}(x_{1}|x(t))dt\\right], \\tag{15}\\t]\n' +
      '\n' +
      '\\(\\gamma_{t}=\\frac{1}{2}\\frac{d}{dt}\\mathrm{snr}(t)\\)을 정의하고 \\(\\mathrm{snr}(t)=\\frac{\\alpha_{t}^{2}{\\sigma_{t}^{2}\\)을 정의한다.\n' +
      '\n' +
      '그 증명은 부록 A에서 주어진다. \\(\\sigma_{1}=0\\) 또한 \\(\\int_{0}^{1}\\gamma_{t}dt=\\infty\\)을 갖는 정확한 경우에, 그럼에도 불구하고 우리는 부록 A에서 \\(D_{x_{0}}x(1)\\)이 이 경우에도 잘 정의되어 있음을 보여준다. 이제, 행렬 \\(D_{x_{0}}x(1)\\in\\mathbb{R}^{d\\times d}\\)은 대칭적인 양의 정의이고, 행렬-벡터 곱 \\(D_{x_{0}}x(1)v\\)은 행렬 \\(\\int_{0}^{1}\\gamma_{t}\\mathrm{Var}(x_{1}|x(t))dt\\ 내지 \\(v\\)의 반복적 응용에 해당한다. 이 적분에 대한 닫힌 형태 식은 알려져 있지 않지만 공분산 행렬의 가중 합이며,\n' +
      '\n' +
      '\\mathrm{Var}(x_{1}|x(t))=\\mathbb{E}_{p_{t}(x_{1}|x(t))}\\left[x_{1}-\\hat{x}_{1}\\right]\\left[x_{1}-\\hat{x}_{1}\\right]^{T}, \\tag{16}\\t}\n' +
      '\n' +
      '여기서 \\(\\hat{x}_{1}=\\mathbb{E}_{p_{t}(x_{1}|x(t))}x_{1}\\)는 _denoiser_(Karras et al., 2022)이다. \\(\\mathrm{Var}(x_{1}|x(t))v\\)를 갖는 벡터-행렬 곱셈은 \\(x(t)\\, 즉 \\(x_{1}|x(t))에 조건화된 데이터의 분포의 주축에 \\(v\\)을 투영한다. 우리가 곧 보게 될 것처럼, \\(D_{x_{0}}x(1)\\)는 암시적 편향 주장을 이해하는 열쇠이다.\n' +
      '\n' +
      '\\(x(1)\\).최적화된 변수 \\(x_{0}\\)을 기울기 단계, 즉 \\(x_{0}^{\\star}=x_{0}-\\tau\\nabla_{x_{0}}\\mathcal{L}(x(1))\\으로 갱신하는 최적화 단계를 고려하며, 여기서 기울기 \\(\\nabla_{x_{0}}\\mathcal{L}(x(1))\\)은 이제 체인 규칙과 방정식 18로 계산될 수 있다.\n' +
      '\n' +
      '\\[\\nabla_{x_{0}}\\mathcal{L}(x(1))=D_{x_{0}}x(1)\\nabla_{x(1)}\\mathcal{L}(x(1)), \\tag{17}\\]\n' +
      '\n' +
      '그리고 우리는 \\(D_{x_{0}}x(1)\\)이 대칭 행렬임을 사용했다. 우리는 이제 질문할 수 있다: 이 기울기 단계 하에서 표본 \\(x(1)\\)이 무한히 어떻게 변하고 있는가?_ [\\(\\Phi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{d}\\) 맵에 의한 디노트는 \\(t=1\\), 즉 \\(\\Phi(x_{0})=x(1)\\)에서 방정식 2의 해에 초기 조건 \\(x_{0}\\)을 취한다. \\(x(1)\\)의 _variation_는\n' +
      '\n' +
      '\\frac{d}{d\\tau}\\Big{|}\\Phi\\left(x_{0}-\\tau\\nabla_{x_{0}}\\mathcal{L}(x(1))\\right)\\]=-\\left[D_{x_{0}}x(1)\\right]^{2}\\mathcal{L}(x(1)),\\]\n' +
      '\n' +
      '첫 번째 등식은 변이의 정의이고 두 번째 등식은 체인 규칙, 방정식 18 및 방정식 17을 사용한다. 실제로 \\(x(1)\\)의 역학은 공분산 행렬 \\(\\mathrm{Var}(x_{1}|x(t))\\)에 의한 사영을 다른 시간 \\(t\\)에서 반복적으로 적용하는 연산자 \\(D_{x_{0}}x(1)\\)와 함께 기울기 \\(\\nabla_{x(1)}\\mathcal{L}(x(1))\\)의 사영을 따른다.\n' +
      '\n' +
      '## 5 관련 업무\n' +
      '\n' +
      '역 문제.새로운 작업 라인은 역 문제의 훈련 없는 해법을 위한 확산 생성 프로세스를 변경한다. 대부분의 작업은 확산 모델의 생성 과정에 대한 구축 지침 전략으로 볼 수 있다. (Kawar et al., 2022)는 선형 역문제에 대한 해결자를 도출하는 변분적 접근법을 취한다. 마찬가지로, (Chung et al., 2022; Wang et al., 2022)는 비용 함수 또는 투영을 통해 관측치와의 일관성을 강제함으로써 생성 프로세스를 수정한다(Choi et al., 2021; Wang et al., 2022; Lugmayr et al., 2022). 다른 접근법들은 각각의 잡음 제거 단계에서 확산 모델을 통해 파생물들로 샘플링 프로세스를 안내한다(Ho et al., 2022; Chung et al., 2023; Song et al., 2023; Pokle et al., 2023). (Rout et al., 2023)에 의한 최근 작업은 인코더-디코더의 체인화된 애플리케이션들에 의해 잠재 확산 모델들에 대한 아이디어를 확장한다. 우리의 접근법(Mardani et al., 2023)과 유사하게, 스코어 매칭 정규화를 갖는 재구성 손실의 최적화를 수행한다.\n' +
      '\n' +
      '조건 샘플링.확산 모델로부터의 조건 샘플링은 추가적인 잡음-인식 조건 예측기 모델을 트레이닝함으로써(Song et al., 2020) 또는 조건을 트레이닝 프로세스에 통합함으로써(Dhariwal and Nichol, 2021; Ho and Salimans, 2022) 달성될 수 있다. 그러나 이러한 접근 방식은 작업 특정 교육을 필요로 한다. 반면에 플러그 앤 플레이 접근법은 사전 훈련된 무조건 생성 모델을 사전으로 활용한다. (Graikos et al., 2023)는 확산 손실에 의해 정규화된 재구성 항의 최적화를 통해 제약된 생성을 수행한다. (Liu et al., 2023)는 가이드 컨트롤을 학습하기 위해 생성 과정을 통해 최적의 컨트롤 최적화를 추구한다. 이 방법은 생성 정규화 흐름 모델(Whang et al., 2021; Chavez, 2022)에 대한 이전 작업과 유사한 최적화 문제를 공식화한다. 우리는 이산 확산 모델의 경우에 대한 솔버를 통한 구배를 사용하는 것이 분류기 안내를 위해 (Wallace et al., 2023)에 의해 그리고 희귀 샘플을 생성하기 위해 (Samuel et al., 2023)에 의해 처음 사용되었음을 주목한다.\n' +
      '\n' +
      '## 6 Experiments\n' +
      '\n' +
      'D-Flow는 영상의 선형 역문제, 잠재 흐름 모델의 역문제, 조건부 분자 생성과 같은 태스크에 대해 테스트한다. 관측된 신호가 구조적 정보를 제공하는 모든 역문제 실험에서, 우리는 수렴 속도를 높이고 종종 성능을 향상시키기 위해 혼합 초기화를 사용한다. 또한, 대부분의 실험에서 우리는 최적화에 명시적인 정규화 항을 추가할 필요가 없음을 발견했다. 정규화가 도움이 되는 유일한 경우는 잡음의 경우 선형 역 문제와 분자 생성이었다. 추가 세부 사항은 부록 B에 나와 있습니다.\n' +
      '\n' +
      '### 이미지의 선형 역문제\n' +
      '\n' +
      '우리는 이미지에 대한 알려진 열화 모델을 사용하여 표준 선형 역 문제에 대한 방법을 검증한다. 우리가 고려하는 작업은 소음과 소음이 없는 경우 모두에서 중심 작물 인페인팅, 초해상도 및 가우시안 디블러링이다. 모든 경우에 우리는 태스크 종속 목표 PSNR에서 최적화를 중단한다. 잡음이 있는 경우, 우리는 목표 PSNR을 알려진 추가 잡음에 해당하는 PSNR로 선택한다.\n' +
      '\n' +
      '작업들.우리는 (Pokle et al., 2023)에서와 동일한 설정을 따른다: (i) 중심-작물 인페인팅의 경우, \\(40\\times 40\\) 중심 마스크를 사용한다; (ii) 초해상도의 경우, 우리는 이미지를 \\(\\times 2\\)으로 다운샘플링하기 위해 bicubic 보간을 사용한다; 그리고 마지막으로 (iii) 가우시안 디블러에서 세기 \\(1\\)으로 크기 \\(61\\times 61\\)의 가우시안 블러 커널을 적용한다. 각 태스크에 대해 잡음이 없고 잡음이 있는 경우(\\(\\sigma_{y}=0.05\\)에 대한 결과를 보고하고, 수학식 5를 참조한다. 추가 구현 세부 사항은 부록 B.1에서 확인할 수 있다.\n' +
      '\n' +
      'Metrics.The evaluation protocol of the prior works (Chung et al., 2022; Kawar et al., 2022) we report Frechet Inception Distance (FID)(Heusel et al., 2018), Learned Perceptual Image Patch Similarity (LPIPS)(Zhang et al., 2018), peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM).\n' +
      '\n' +
      'Datasets and Baseline.We used the face-blurred ImageNet-128 dataset and report our results on \\(10k\\) split of the face-blurred ImageNet dataset using (Pokle et al., 2023). 본 논문의 방법을 IIGDM (Song et al., 2023), OT-ODE (Pokle et al., 2023) 및 RED-Diff (Mardani et al., 2023)의 세 가지 최신 기술 방법과 비교한다. 우리는 모든 기준선에 대한 (Pokle et al., 2023)의 구현을 사용한다. 우리의 방법을 포함한 모든 방법은 우리가 생성한 결과가 보고된 결과보다 열등하지 않는 한 얼굴 흐릿한 ImageNet-128에서 훈련된 동일한 Cond-OT 흐름 매칭 클래스 조건화 모델로 평가된다(Pokle et al., 2023). 그 경우, 우리는 (Pokle et al., 2023)로부터 보고된 번호들을 사용한다.\n' +
      '\n' +
      '결과.표 1에 나타낸 바와 같이, 우리의 방법은 모든 작업에 걸쳐 강한 성능을 나타내고, 그림 5는 왜곡의 각 유형에 대한 샘플을 나타낸다. 인페인팅 및 초해상도의 경우 대부분의 메트릭에서 우리의 방법은 최신 기술을 개선한다. 우리는 지상 진실에 대한 더 높은 충실도를 갖는 이미지에 도달하는 우리의 방법의 능력이 소스 포인트 최적화에 기인한다고 믿으며, 이는 (Song et al., 2023; Pokle et al., 2023)과 같은 유도 샘플링 접근법과는 달리, 관측된 신호와 더 잘 일치하도록 샘플링 궤적을 반복적으로 교정한다. 또한 최적화 기법인 RED-Diff와 비교하였을 때, 본 논문에서 제안한 방법은 잡음이 많은 경우에 어려움을 겪지 않고 SOTA 성능을 얻을 수 있음을 확인하였다. 우리는 그림 7,8에서 더 많은 샘플을 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c c c c c} \\hline \\hline  & \\multicolumn{3}{c}{**Inpainting-Center**} & \\multicolumn{3}{c}{**Super-Resolution X2**} & \\multicolumn{3}{c}{**Gaussian deblur**} \\\\ \\cline{2-13} Method & FID \\(\\downarrow\\) & LPIPS \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & SSIM \\(\\uparrow\\) & FID \\(\\downarrow\\) & LPIPS \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & SSIM \\(\\uparrow\\) & FID \\(\\downarrow\\) & LPIPS \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & SSIM \\(\\uparrow\\) \\\\ \\hline \\(\\sigma_{y}=0\\) & 5.73 & 0.096 & 36.89 & 0.908 & 6.01 & 0.104 & 34.31 & 0.911 & 4.27 & 0.066 & 37.61 & 0.961 \\\\ OT-ODE (Pokle et al., 2023) & 5.65 & 0.094 & 37.00 & 0.893 & 4.28 & 0.097 & 33.38 & 0.903 & 2.04 & 0.048 & 37.44 & 0.959 \\\\ RED-Diff (Mardani et al., 2023) & 5.40 & **0.068** & 38.91 & **0.928** & 3.05 & 0.091 & 33.74 & 0.900 & **1.62** & 0.055 & 35.18 & 0.937 \\\\ Ours & **4.14** & 0.072 & 37.67 & 0.922 & **2.50** & **0.069** & **34.88** & **0.924** & 2.37 & **0.015** & **39.47** & **0.976** \\\\ \\hline \\(\\sigma_{y}=0.05\\) & 7.99 & 0.122 & 34.57 & 0.867 & 4.38 & 0.148 & 32.07 & 0.831 & 30.30 & 0.328 & 29.96 & 0.606 \\\\ OT-ODE (Pokle et al., 2023) & 6.25 & 0.119 & **35.01** & 0.882 & 4.61 & 0.149 & **32.59** & **0.862** & **4.94** & 0.175 & 31.94 & **0.821** \\\\ RED-Diff (Mardani et al., 2023) & 14.63 & 0.171 & 32.42 & 0.820 & 10.54 & 0.182 & 31.82 & 0.852 & 21.43 & 0.229 & 31.41 & 0.807 \\\\ Ours & **4.76** & **0.102** & 34.609 & **0.890** & **4.26** & **0.146** & 32.35 & 0.858 & 5.35 & **0.167** & **31.99** & 0.820 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 얼굴 흐릿한 ImageNet-128에 대한 선형 역문제의 정량적 평가.\n' +
      '\n' +
      '그림 5: ImageNet-128의 선형 역 문제에 대한 정성적 비교. ImageNet-128 검증의 GT 샘플.\n' +
      '\n' +
      '### 잠재흐름모형의 역문제\n' +
      '\n' +
      '######6.2.1 이미지 인페인팅\n' +
      '\n' +
      '우리는 잠재 T2I FM 모델을 사용하여 자유 형식 인페인팅 작업에 적용하여 비선형 역 문제에 대한 접근법의 능력을 보여준다.\n' +
      '\n' +
      '**Metrics.** 우리의 결과를 정량적으로 평가하기 위해 T2I 생성에 사용된 표준 메트릭: PSNR, FID(Heusel et al., 2018), Clip score(Ramesh et al., 2022)를 보고한다.\n' +
      '\n' +
      '** 데이터셋 및 기준.** 우리가 사용하는 T2I 모델은 \\(330m\\) 이미지-텍스트 쌍의 독점 데이터 세트에 대해 훈련되었다. 그것은 (Rombach et al., 2022)에서와 같이 오토인코더의 잠재 공간에 대해 훈련되었다. 상기 아키텍처는 GLIDE(Nichol et al., 2022)를 기반으로 하며 T5 텍스트 인코더(Raffel et al., 2023)를 사용한다. 우리는 COCO 데이터 세트의 검증 세트로부터 \\(1k\\) 샘플의 서브세트에 대해 평가한다(Lin et al., 2015). 우리는 이전 절에서 사용한 다른 기준선과 마찬가지로 선형 역 문제에 국한되지 않기 때문에 RED-Diff(Mardani et al., 2023)와 우리의 방법을 비교한다. RED-Diff에 대해 서로 다른 하이퍼 파라미터를 테스트하고 가장 좋은 결과를 보고한다.\n' +
      '\n' +
      '**결과.** 표 3은 기준선과 우리의 방법에 대한 메트릭을 보고한다. 메트릭스는 RED-Diff가 마스킹되지 않은 영역과 더 잘 일치하지만, 구조적 메트릭(PSNR, SSIM)에 대해 우수한 성능을 달성하는 반면, 본 방법은 지각 메트릭에서 더 의미적으로 그럴듯한 이미지 완성 승리를 생성함을 나타낸다. 우리는 RED-Diff가 이 작업을 위해 종종 인공물을 생산한다는 것을 관찰한다. 결과는 그림 9에 시각화되어 있다.\n' +
      '\n' +
      '6.2.2 오디오 인페인팅 및 초해상도\n' +
      '\n' +
      '잠재 흐름 매칭 음악 생성 모델을 활용하여 음악 인페인팅과 초해상도 작업에 대한 방법을 평가한다. 이를 위해 End-Codec representation(Defossez et al., 2022)의 상단에서 동작하는 325m 파라미터의 트랜스포머 구조를 갖는 훈련된 Cond-OT flow-matching text conditioned model을 사용하였다. 이 모델의 성능은 텍스트 조건 음악 생성에서 현재 최신 악보와 일치하여 뮤직캡에 대한 Frechet Audio Distance(FAD) 점수 \\(3.13\\)(Kilgour et al., 2018)와 도메인 내 데이터에 대한 FAD \\(0.72\\)을 달성한다. 모델은 10초 샘플들을 생성하도록 트레이닝된다. 다음으로, 본 논문에서 제안한 방법과 RED-Diff를 베이스라인으로 하여 인페인팅과 초해상도의 성능을 평가하고, FAD와 PSNR 메트릭을 보고한다.\n' +
      '\n' +
      '**Datasets and baselines.**\n' +
      '\n' +
      '평가는 음악(Copet et al., 2023; Ziv et al., 2024)과 유사하게 \\(5.5\\)K 쌍의 음악과 텍스트 기술 및 \\(202\\) 샘플의 내부(도메인 내) 평가 세트로 구성된 MusicCaps 벤치마크를 사용한다. 이전 작업과 유사하게 VGGish를 사용하여 FAD 메트릭을 계산한다. 우리는 우리의 방법을 RED-Diff(Mardani et al., 2023)와 비교한다.\n' +
      '\n' +
      '**결과.** 표 2는 인페인팅 및 초해상도 작업에서 우리의 방법을 연구한다. 이 실험은 비선형 설정에서 동작하기 위한 우리의 방법의 능력을 평가하는데, 여기서 흐름 모델은 신경 표현을 통해 훈련되고 비용 함수는 디코딩 후 신호(디코딩 후 신경 표현)에 대해 평가된다. 인페인팅 작업에서, 우리는 신호를 10초 동안 \\(10\\)%와 \\(20\\)%만큼 중심 크롭하고, 각각 2초와 4초를 마스킹한다. 초해상도 작업에서는 각각 \\(4\\)kHz, \\(8\\)kHz, \\(16\\)kHz에서 \\(32\\)kHz로 2, 4, 8의 인자에 의해 신호를 상향 조정한다. 전반적으로, 우리의 방법은 기준선에서 개선된다. 특히, 모든 실험에서 본 방법은 가장 낮은 FAD 메트릭을 얻는다. 인페인팅 작업에서 우리의 방법은 기준선에서 약간 낮은 PSNR을 얻는다. 오디오 샘플은 보충 재료에 부착됩니다. 추가 구현 세부 정보는 부록 B.2.2에 나와 있습니다.\n' +
      '\n' +
      'QM9에서의 조건분자 생성\n' +
      '\n' +
      '이 실험에서 우리는 물질 및 약물 설계 분야에서 실질적으로 중요한 제어 가능한 분자 생성을 위한 방법의 적용을 설명한다. 조건부 생성의 대상이 되는 성질은 분극성\\(\\alpha\\), 궤도에너지\\(\\varepsilon_{HOMO},\\varepsilon_{LUMO}\\) 및 간극\\(\\Delta\\varepsilon\\, Diople moment\\(\\mu\\), 열용량\\(C_{v}\\)을 포함한다. 생성된 분자의 특성을 평가하기 위해 각 특성에 대해 특성 분류기(식 7의\\(\\mathcal{F}\\)를 사용했다. 이들 분류기는 (Hoogeboom et al., 2022)에 요약된 방법론에 따라 훈련되었다. 자세한 내용은 부록 B.3에 나와 있습니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c c c c} \\hline \\hline \\multirow{2}{*}{Method} & \\multicolumn{4}{c}{**Inpainting (10\\%)**} & \\multicolumn{2}{c}{**Inpainting (20\\%)**} & \\multicolumn{2}{c}{**Super-Resolution X2**} & \\multicolumn{2}{c}{**Super-Resolution X4**} & \\multicolumn{2}{c}{**Super-Resolution X8**} \\\\  & FAD \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & FAD \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & FAD \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & FAD \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & FAD \\(\\downarrow\\) & PSNR \\(\\uparrow\\) \\\\ \\hline In-domain & \\multicolumn{4}{c}{} \\\\ RED-Diff (Mardani et al., 2023) & 0.75 & **31.19** & 0.78 & **29.99** & 0.93 & 35.27 & 1.63 & 33.51 & 1.73 & 29.12 \\\\ Ours & 0.22 & 31.02 & 0.49 & 29.57 & 0.22 & 44.51 & 0.50 & **42.64** & 1.01 & 36.50 \\\\ \\hline MusicCaps & \\multicolumn{4}{c}{} \\\\ RED-Diff (Mardani et al., 2023) & 3.59 & **32.81** & 3.72 & 30.39 & 3.07 & 37.13 & 3.51 & 34.99 & 3.97 & 30.49 \\\\ Ours & 1.19 & 31.78 & **1.31** & **31.08** & 1.25 & 38.93 & 1.42 & 35.83 & 2.09 & 32.20 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 잠재 흐름 모델을 이용한 음악 생성의 정량적 평가.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline \\multicolumn{5}{c}{**Inpainting-Free-Form**} \\\\ \\hline Method & FID \\(\\downarrow\\) & LPIPS \\(\\downarrow\\) & PSNR \\(\\uparrow\\) & SSIM \\(\\uparrow\\) & Clip score \\(\\uparrow\\) \\\\ \\hline RED-Diff (Mardani et al., 2023) & 23.31 & 0.327 & 32.88 & 0.813 & 0.882 \\\\ Ours & 16.92 & **0.327** & 32.34 & 0.759 & **0.922** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: T2I 잠재 모델을 사용한 MS-COCO에 대한 자유 형태 인페인팅의 정량적 평가.\n' +
      '\n' +
      '**Metrics.** 조건부 생성을 평가하기 위해, 속성 분류기에 의해 생성된 분자의 예측된 속성 값과 목표 속성 값 사이의 평균 절대 오차(Mean Absolute Error, MAE)를 계산한다. 또한, 원자 안정성(정확한 원자가를 갖는 원자의 백분율), 분자 안정성(모든 원자가 안정한 분자의 백분율), 타당성(RDKit(Landrum, 2016)에 정의된 바와 같이) 및 생성된 분자의 고유성을 평가하여 생성된 분자의 품질을 평가한다.\n' +
      '\n' +
      '**Dataset and baselines.** 본 실험에 사용된 생성 모델은 최대 \\(29\\) 원자를 갖는 소분자를 포함하는 일반적으로 사용되는 분자 데이터세트인 QM9 데이터세트(Ramakrishnan et al., 2014)를 사용하여 훈련된다. 이 실험에서 앞서 사용한 모델은 분자 생성을 위한 무조건 확산 모델, E(3) Equivariant Diffusion Model (EDM) (Hoogeboom et al., 2022)이다. EDM은 다항식 스케줄로 잡음 예측 모델(\\(\\epsilon\\)-예측이라고도 함)로 훈련되었다. 최적화를 위한 결정적 샘플링을 수행하기 위해, 우리는 잡음 예측을 속도장 예측으로 변환하고(수학식 52 참조), 50 단계의 중간점 ODE 샘플러를 사용한다. 본 논문의 방법을 조건부 모델_: 조건부 EDM, 등가 흐름 매칭(Equivariant Flow-Matching, EQuiFM)(Song et al., 2023b) 및 기하학적 잠재 확산 모델(Geometric Latent Diffusion Model, GoLDM)(Xu et al., 2023)의 등분산 흐름 매칭 모델과 비교한다. 또한, 각 속성 분류기(표 4의 QM9\\({}^{*}\\)로 표기됨)의 테스트 MAE를 보고하며, 이는 경험적 하한으로 작용한다. 조건부 생성의 각 특정 속성에 대해 기준선 방법은 고유한 조건부 모델을 활용했으며, 각각은 단일 무조건 모델을 사용하는 동안 해당 특정 속성을 생성하기 위해 개별적으로 훈련되었다. (Satorras et al., 2022)로부터의 조건부 트레이닝 프로토콜에 따르면, 속성 분류기는 QM9 트레인 세트의 절반(\\(50\\)K)에 걸쳐 트레이닝되고, 조건부 트레이닝은 나머지 절반으로 수행된다. 조건부 컨텍스트 없이 작동하는 무조건 모델의 경우 전체 QM9 데이터 세트에 대해 훈련된 사전 훈련된 모델을 활용했다.\n' +
      '\n' +
      '**결과.** 표 4는 우리의 접근법이 조건부 분자 생성의 품질에서 다른 모든 기준선 방법을 상당히 능가한다는 것을 보여준다. 이러한 우수한 성능은 조건부 생성의 직접 최적화에 기인한다. 표 5는 우리의 방법에 대한 안정성 및 유효성 메트릭을 나타낸다. 다양한 특성에 걸쳐 평균 분자 안정성을 달성하는 조건부 EDM과 비교하여, 본 방법은 생성된 분자의 품질에 차이가 있음을 보여준다. 이러한 품질 감소는 샘플링 경로를 확률에서 결정론으로 변경하고 최적화 과정에서 구조적 귀납적 바이어스가 없는 결과일 가능성이 높다. 부록 B.3의 첫 번째 주장에 대한 추가 증거를 제시한다. 그림 6은 서로 다른 분극성 \\(\\alpha\\) 값에 대해 제어된 생성을 시각화하며, 그림의 모든 분자는 \\(1\\)보다 낮은 분류기 오류로 유효하고 안정적이다.\n' +
      '\n' +
      '##7 토론, 한계 및 향후 작업\n' +
      '\n' +
      '사전 훈련된 확산/흐름 모델에서 제어된 생성을 위한 간단하고 일반적인 프레임워크를 제시했으며 이미지, 오디오에서 분자에 이르기까지 다양한 도메인 및 데이터 유형에서 광범위한 문제에 대한 유효성을 입증했다. 우리 접근법의 주요 한계는 속도장의 여러 구성(동등하게 확산 모델)을 통해 역전파할 필요성에서 비롯된 비교적 긴 런타임(섹션 3.4 및 부록 B 참조)이다. 그러나 우리의 이론적 분석과 경험적 증거는 ODE 솔루션을 통한 계산 기울기가 바람직한 암시적 편향을 가지고 있어 공통 조건부 생성 작업에 대한 최신 결과를 생성한다는 것을 보여준다. 결과적으로, 흥미로운 미래 방향은 암시적 편향을 활용하지만 잠재적으로 더 저렴한 계산 오버헤드를 사용하고 다른 제어된 세대 패러다임에서 사용되는 다른 편향에 대한 연결을 유도하는 것이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c} \\hline \\hline Property & \\(\\alpha\\) & \\(\\Delta\\varepsilon\\) & \\(\\varepsilon_{HOMO}\\) & \\(\\varepsilon_{LUMO}\\) & \\(\\mu\\) & \\(C_{v}\\) \\\\ Units & Bohr\\({}^{2}\\) & meV & meV & meV & D & \\(\\frac{\\text{col}}{\\text{mol}^{2}}\\) K \\\\ \\hline QM9\\({}^{*}\\) & 0.10 & 64 & 39 & 36 & 0.043 & 0.040 \\\\ \\hline EDM & 2.76 & 655 & 356 & 584 & 1.111 & 1.101 \\\\ EQuiFM & 2.41 & 591 & 337 & 530 & 1.106 & 1.033 \\\\ GeoLDM & 2.37 & 587 & 340 & 522 & 1.108 & 1.025 \\\\ \\hline Ours & **1.38** & **340** & **179** & **330** & **0.299** & **0.784** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 조건부 분자 생성의 정량적 평가. 표에 보고된 값은 분자 특성 예측에 대한 MAE(\\(10\\)K 샘플 이상)이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c} \\hline \\hline Property & \\(\\alpha\\) & \\(\\Delta\\varepsilon\\) & \\(\\varepsilon_{HOMO}\\) & \\(\\varepsilon_{LUMO}\\) & \\(\\mu\\) & \\(C_{v}\\) \\\\ \\hline Molecule Stability (\\%) & 52.6 & 54.9 & 55.2 & 54.4 & 57.3 & 55.3 \\\\ Atom Stability (\\%) & 94.7 & 95.0 & 95.1 & 95.0 & 95.3 & 94.8 \\\\ Validity (\\%) & 78.7 & 79.5 & 80.6 & 81.0 & 82.0 & 80.0 \\\\ Validity \\& Uniqueness (\\%) & 77.3 & 77.9 & 80.0 & 79.8 & 80.6 & 78.6 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 조건부 분자 생성(10K 샘플)에 대한 D-흐름의 안정성 및 유효성 평가.\n' +
      '\n' +
      '그림 6: 다양한 편광성(\\(\\알파\\)) 수준에 대한 제어된 생성 분자의 정성적 시각화.\n' +
      '\n' +
      '## Acknowledgments\n' +
      '\n' +
      'OP는 데이터 과학 연구 센터와 미네르바 스티퉁을 위한 이스라엘 CHE 프로그램의 보조금으로 지원된다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Anderson et al. (2019) Anderson, B., Hy, T. - S., and Kondor, R. 가마우지: Covariant molecular neural networks, 2019.\n' +
      '* Asim et al. (2020) Asim, M., Daniels, M., Leong, O., Ahmed, A., and Hand, P. Invertible generative models for inverse problems: mitigating representation error and dataset bias, 2020.\n' +
      '* Bar-Tal et al.(2023) Bar-Tal, O., Yariv, L., Lipman, Y., and Dekel, T. 다중 확산: 제어 영상 생성을 위한 확산 경로 융합. _ arXiv preprint arXiv:2302.08113_, 2023.\n' +
      '* Bora et al. (2017) Bora, A., Jalal, A., Price, E., and Dimakis, A. G. Compressed sensing using generative models, 2017.\n' +
      '* Chen et al. (2018) Chen, R. T., Rubanova, Y., Bettencourt, J., and Duvenaud, D. Neural ordinary differential equations. _ arXiv preprint arXiv:1806.07366_, 2018.\n' +
      '* Chen & torchdiffeq (2018) Chen, R. T. Q. torchdiffeq, 2018. URL[https://github.com/rtqichen/torchdiffeq](https://github.com/rtqichen/torchdiffeq).\n' +
      '*Choi et al. (2021) Choi, J., Kim, S., Jeong, Y., Gwon, Y., and Yoon, S. Ilvr: 디노이징 확산 확률 모델들을 위한 컨디셔닝 방법, 2021.\n' +
      '* Chung et al. (2022) Chung, H., Sim, B., Ryu, D., and Ye, J. C. Improving diffusion models for inverse problems using manifold constraints, 2022.\n' +
      '* Chung et al. (2023) Chung, H., Kim, J., Mccann, M. T., Klasky, M. L., and Ye, J. C. Diffusion posterior sampling for general noisy inverse problems, 2023.\n' +
      '* Chavez(2022) Chavez, J. A. Generative flows as a general purpose solution for inverse problems, 2022.\n' +
      '* Copet et al. (2023) Copet, J., Kreuk, F., Gat, I., Remez, T., Kant, D., Synnaeve, G., Adi, Y., and Defossez, A. Simple and controllable music generation. _NeurIPS_, 2023.\n' +
      '* 피토치에서의 재현성 측정. _ Journal of Open Source Software_, 7(70): 4101, 2022. doi: 10.21105/joss.04101. URL[https://doi.org/10.21105/joss.04101](https://doi.org/10.21105/joss.04101).\n' +
      '* Dhariwal & Nichol (2021) Dhariwal, P. and Nichol, A. Diffusion model beat gans on image synthesis. _ arXiv preprint arXiv:2105.05233_, 2021.\n' +
      '* Defossez et al. (2022) Defossez, A., Copet, J., Synnaeve, G., and Adi, Y. 고충실도 신경 오디오 압축 ARXiv 프리프린트 arXiv:2210.13438_, 2022.\n' +
      '* Evans(2005) Evans, L. C. A introduction to mathematical optimal control theory. _ Lecture Notes, University of California, Department of Mathematics, Berkeley_, 3:15-40, 2005.\n' +
      '* Graikos et al. (2023) Graikos, A., Malkin, N., Jojic, N., and Samaras, D. Diffusion models as plug-and-play priors, 2023.\n' +
      '* Grathwohl et al. (2018) Grathwohl, W., Chen, R. T. Q., Bettencourt, J., Sutskever, I., and Duvenaud, D. Ffjord: Free-form continuous dynamics for scalable reversible generative models, 2018.\n' +
      '* Heusel et al. (2018) Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S. 2개의 시간 척도 업데이트 규칙에 의해 훈련된 간스는 2018년 로컬 내쉬 균형(local nash equilibrium)으로 수렴한다.\n' +
      '* Ho & Salimans(2022) Ho, J. and Salimans, T. 분류자가 없는 확산 안내. _ arXiv preprint arXiv:2207.12598_, 2022a.\n' +
      '* Ho & Salimans(2022) Ho, J. and Salimans, T. 분류기 없는 확산 안내, 2022b.\n' +
      '* Ho et al. (2020) Ho, J., Jain, A., and Abbeel, P. Denoising diffusion probability models. _ arXiv preprint arXiv:2006.11239_, 2020.\n' +
      '* Ho et al. (2022) Ho, J., Salimans, T., Gritsenko, A., Chan, W., Norouzi, M., and Fleet, D. J. Video diffusion models, 2022.\n' +
      '* Hoogeboom et al. (2022) Hoogeboom, E., Satorras, V. G., Vignac, C., and Welling, M. 2022년 3d에서 분자 생성을 위한 균등 확산.\n' +
      '* Karras et al. (2022) Karras, T., Aittala, M., Aila, T., and Laine, S. 확산 기반 생성 모델의 설계 공간을 명시합니다. _ 신경 정보 처리 시스템_, 35: 26565-26577, 2022에서의 발전.\n' +
      '* Kawar et al. (2022) Kawar, B., Elad, M., Ermon, S., and Song, J. Denoising 확산 복원 모델. In _Advances in Neural Information Processing Systems_, 2022.\n' +
      '* Kilgour et al. (2018) Kilgour, K., Zuluaga, M., Roblek, D., and Sharifi, M. 프리쳇 오디오 거리: 음악 향상 알고리즘을 평가하기 위한 메트릭. _ arXiv preprint arXiv:1812.08466_, 2018.\n' +
      '* Landrum (2016) Landrum, G. Rdkit: Open-source cheminformatics software. 2016. URL[https://github.com/rdkit/rdkit/releases/tag/Release_2016_09_4](https://github.com/rdkit/rdkit/releases/tag/Release_2016_09_4)\n' +
      '* Lin et al.(2015) Lin, T. - Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Ramanan, D., Zitnick, C. L., and Dollar, P. Microsoft coco: Common objects in context, 2015.\n' +
      '* Lipman et al. (2023) Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., and Le, M. 생성 모델링을 위한 흐름 일치, 2023.\n' +
      '\n' +
      '*Liu et al. (2023) Liu, X., Wu, L., Zhang, S., Gong, C., Ping, W., and Liu, Q. 흐름: 그라디언트가 있는 생성 오드의 출력을 제어합니다. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pp. 24335-24344, June 2023.\n' +
      '* Lugmayr et al. (2022) Lugmayr, A., Danelljan, M., Romero, A., Yu, F., Timofte, R., and Gool, L. V. Repaint: Inpainting using denoising diffusion probabilistic models, 2022.\n' +
      '* Mardani et al. (2023) Mardani, M., Song, J., Kautz, J., and Vahdat, A. A variational perspective on solve inverse problems with diffusion models, 2023.\n' +
      '* Nalisnick et al. (2019) Nalisnick, E., Matsukawa, A., Teh, Y. W., Gorur, D., and Lakshminarayanan, B. Do deep generative models know what they don\'t know them don\'t know?, 2019.\n' +
      '*Nichol et al. (2022) Nichol, A., Dhariwal, P., Ramesh, A., Shyam, P., Mishkin, P., McGrew, B., Sutskever, I., and Chen, M. 글라이드: 2022년 텍스트 유도 확산 모델을 사용한 사실적 이미지 생성 및 편집을 향한다.\n' +
      '* Pokle et al. (2023) Pokle, A., Muckley, M. J., Chen, R. T. Q., and Karrer, B. Training-free linear image inversion via flows, 2023.\n' +
      '* Raffel et al. (2023) Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J., Exploring the limit of transfer learning with a unified text-to-text transformer, 2023.\n' +
      '* Ramakrishnan et al. (2014) Ramakrishnan, R., Dral, P., Rupp, M., and von Lilienfeld, A. Quantum chemistry structure and properties of 134 kilo molecules. _ Scientific Data_, 1, 08 2014. doi: 10.1038/sdata.2014.22.\n' +
      '* Ramesh et al. (2022) Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M. 2022년, 클립 래턴트를 이용한 계층적 텍스트 조건 이미지 생성\n' +
      '* Rombach et al. (2022) Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. High-resolution image synthesis with latent diffusion models, 2022.\n' +
      '* Rout et al. (2023) Rout, L., Raoof, N., Daras, G., Caramanis, C., Dimakis, A. G., and Shakkottai, S. 잠재 확산 모델을 사용한 사후 샘플링을 통해 선형 역 문제를 분명히 해결한다, 2023.\n' +
      '* Samuel et al. (2023) Samuel, D., Ben-Ari, R., Darshan, N., Maron, H., and Chechik, G. Norm-guided latent space exploration for text-to-image generation, 2023a.\n' +
      '* Samuel et al. (2023) Samuel, D., Ben-Ari, R., Raviv, S., Darshan, N., and Chechik, G. Pre-trained diffusion models, 2023b.\n' +
      '* Satorras et al. (2022) Satorras, V. G., Hoogeboom, E., Fuchs, F. B., Posner, I., and Welling, M. E(n) Equivariant Normalizing Flow, 2022.\n' +
      '* Shaul et al. (2023) Shaul, N., Chen, R. T., Nickel, M., Le, M., and Lipman, Y. 생성 모델의 운동 최적 확률 경로에서. In _International Conference on Machine Learning_, pp. 30883-30907. PMLR, 2023.\n' +
      '* Song et al. (2023a) Song, J., Vahdat, A., Mardani, M., and Kautz, J. Pseudoinverse-guided diffusion models for inverse problems. _International Conference on Learning Representations_, 2023a. URL[https://openreview.net/forum?id=9_gsMABMRKQ](https://openreview.net/forum?id=9_gsMABMRKQ).\n' +
      '*Song & Ermon(2019) Song, Y. 및 Ermon, S. 데이터 분포의 기울기를 추정하여 생성 모델링. _ ArXiv preprint arXiv:1907.05600_, 2019.\n' +
      '* Song et al. (2020) Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. Score-based generative modeling through stochastic differential equations. _ arXiv preprint arXiv:2011.13456_, 2020.\n' +
      '* Song et al. (2023b) Song, Y., Gong, J., Xu, M., Cao, Z., Lan, Y., Ermon, S., Zhou, H., and Ma, W. -Y. 하이브리드 확률 수송과 등가 흐름 매칭, 2023b.\n' +
      '* Wallace et al. (2023) Wallace, B., Gokul, A., Ermon, S., and Naik, N. 엔드 투 엔드 확산 잠재 최적화는 분류기 안내, 2023을 개선한다.\n' +
      '* Wang et al. (2022) Wang, Y., Yu, J., and Zhang, J. Zero-shot image restoration using denoising diffusion null-space model, 2022.\n' +
      '* Whang et al. (2021) Whang, J., Lei, Q., and Dimakis, A. G. Solving inverse problems with a flow-based noise model, 2021.\n' +
      '* Xu et al. (2023) Xu, M., Powers, A., Dror, R., Ermon, S., and Leskovec, J. Geometric latent diffusion models for 3d molecule generation, 2023.\n' +
      '* Yu et al. (2023) Yu, J., Wang, Y., Zhao, C., Ghanem, B., and Zhang, J. Freedom: Training-free energy-guided conditional diffusion model, 2023.\n' +
      '* Zhang et al. (2018) Zhang, R., Isola, P., Efros, A. A., Shechtman, E., and Wang, O. 지각적 척도인 심층 특징의 불합리한 효과, 2018년.\n' +
      '* Ziv et al. (2024) Ziv, A., Gat, I., Lan, G. L., Remez, T., Kreuk, F., Defossez, A., Copet, J., Synnaeve, G., and Adi, Y. 단일 비자동 회귀 변압기를 사용하여 마스킹된 오디오 생성. 2024년\n' +
      '\n' +
      '## 부록 A 증명과 정리\n' +
      '\n' +
      '###정리의 증명 4.1\n' +
      '\n' +
      '정리 4.1을 다시 말씀드리죠\n' +
      '\n' +
      '**정리 A.1**.: _For AGPP 속도 필드 \\(u_{t}\\)(식 12 참조) 및 \\(x(t)\\)는 \\(x_{0}\\)의 함수로서 \\(x(1)\\)의 미분을 통해 정의된다.\n' +
      '\n' +
      '\\[D_{x_{0}}x(1)=\\sigma_{1}\\exp\\left[\\int_{0}^{1}\\gamma_{t}\\mathrm{Var}(x_{1}|x(t))dt\\right], \\tag{18}\\t]\n' +
      '\n' +
      '\\(\\gamma_{t}=\\frac{1}{2}\\frac{d}{dt}\\mathrm{snr}(t)\\)을 정의하고 \\(\\mathrm{snr}(t)=\\frac{\\alpha_{t}^{2}{\\sigma_{t}^{2}\\)을 정의한다.\n' +
      '\n' +
      '증명: \\(x(1)\\) w.r.t 초기점 \\(x_{0}\\)의 미분을 계산하기 위해 우리는 보조 동역학을 이용한다.\n' +
      '\n' +
      '조인트 \\(p(t)=D_{x(t)}x(1)\\을 정의하자. \\(p(t)\\)의 역학은 다음의 ODE(Evans, 2005)에 의해 정의된다:\n' +
      '\n' +
      '\\[\\dot{p}(t)=-D_{x}u_{t}(x(t))^{T}p(t) \\tag{19}\\] \\[p(1)=D_{x(1)}x(1)=I. \\tag{20}\\]\n' +
      '\n' +
      '우리는 \\(D_{x_{0}}x(1)\\)을 계산하기 위해 시간 \\(t=1\\)에서 시간 \\(t=0\\)까지 19를 풀었다. 그러면,\n' +
      '\n' +
      '\\[p(0)=D_{x_{0}}x(1). \\tag{21}\\]\n' +
      '\n' +
      '보조 ODE(19)는 선형 ODE이고 초기 조건 방정식(20)과 함께 그 해는 다음과 같다:\n' +
      '\n' +
      '\\[p(t)=\\exp\\left[\\int_{t}^{1}D_{x}u_{s}(x(s))ds\\right] \\tag{22}\\]\n' +
      '\n' +
      '\\(t=0\\)에서, 우리는 다음과 같다:\n' +
      '\n' +
      '\\[D_{x_{0}}x(1)=\\exp\\left[\\int_{0}^{1}D_{x}u_{s}(x(s))ds\\right] \\tag{23}\\]\n' +
      '\n' +
      '우리는 이제 AGPP의 성질을 이용하여 적분 내부의 속도장 \\(D_{x}u_{t}(x(t))\\의 미분을 더 분석할 것이다.\n' +
      '\n' +
      '우리는 일반적인 아핀 가우시안 경로가 다음과 같이 정의됨을 기억한다.\n' +
      '\n' +
      '\\mathcal{N}(x|\\alpha_{t}x_{1},\\sigma_{t}^{2}I),\\] 조건부 확률 경로(24) \\[p_{t}(x)=\\int p_{t}(x|x_{1})q(x_{1})dx_{1},\\] 한계 확률 경로(25)\n' +
      '\n' +
      '여기서 \\((\\alpha_{t},\\sigma_{t})\\)는 스케줄러를 정의하고 \\(q\\)는 데이터세트 확률 밀도이다. 이러한 경로들을 정의하는 속도 필드들은 (Lipman 등, 2023)이다.\n' +
      '\n' +
      'a_{t}x+b_{t}x_{1},\\qquad a_{t}=\\frac{\\dot{\\sigma}_{t}}{\\sigma}},\\;b_{t}=\\int u_{t}(x_{1})dx_{1},\\qquad p_{t}(x_{1})q(x_{1}}{p_{t}(x_{t})\\text{ 한계속도장}\\tag{27}\\\n' +
      '\n' +
      '26을 27에 연결합니다.\n' +
      '\n' +
      '\\[u_{t}(x)=a_{t}x+b_{t}\\hat{x}_{1} \\tag{28}\\]\n' +
      '\n' +
      '여기서 \\(\\hat{x}_{1}=\\mathbb{E}_{p_{t}(x_{1}|x)}x_{1}=\\hat{x}_{1}(x,t)\\)는 일반적으로 _denoiser_라고도 하며, 고정 \\(x\\)과 \\(t\\)에서 denoiser를 평가하기 때문에 여기서 표기법을 남용한다.\n' +
      '\n' +
      '그 후, 속도장의 미분은:\n' +
      '\n' +
      '\\[D_{x}u_{t}(x)=a_{t}I+b_{t}D_{x}\\hat{x}_{1} \\tag{29}\\]\n' +
      '\n' +
      '우리는 이제 \\(D_{x}\\hat{x}_{1}\\)을 찾아야만 한다.\n' +
      '\n' +
      '[D_{x}\\hat{x}_{1}=D_{x}\\int x_{1}p_{t}(x_{1}|x)dx_{1}=\\int x_{1}\\nabla_{x}p_{t}(x_{1}|x)dx_{1}\\tag{30}\\tag{30}\\int x_{1}\\nabla_{x}p_{t}(x_{1}|x)dx_{1}\\tag{30}\\tabla_{x}p_{t}(x_{1}|x)\n' +
      '\n' +
      '첫째, \\(p_{t}(x|x_{1})\\)가 가우시안이므로:\n' +
      '\n' +
      '\\[\\nabla_{x}p_{t}(x|x_{1})=\\frac{\\alpha_{t}x_{1}-x}{\\sigma_{t}^{2}}p_{t}(x|x_{1}) \\tag{31}\\]\n' +
      '\n' +
      '25번으로 연결하면\n' +
      '\n' +
      '\\[\\nabla_{x}p_{t}(x)=\\int\\frac{\\alpha_{t}x_{1}-x}{\\sigma_{t}^{2}}p_{t}(x|x_{1})q(x_{1})dx_{1}\\tag{32}\\]\n' +
      '\n' +
      '27을 사용하여 우리는 다음과 같다.\n' +
      '\n' +
      '\\[\\nabla_{x}p_{t}(x_{1}|x)=p_{t}(x_{1}|x)\\frac{\\alpha_{t}{\\sigma_{t}^{2}}\\left(x_{1}-\\hat{x}_{1}\\right)\\tag{33}\\frac{\\alpha_{t}{\\sigma_{t}^{2}}\\left(x_{1}-\\hat{x}_{1}\\right)\\tag{33}\\frac{\\alpha_{t}{\\sigma_{t}^{2}}\\left(x_{1}-\\hat{x}_{1}\\right)\n' +
      '\n' +
      '마지막으로, 30은 형태를 취한다:\n' +
      '\n' +
      '{x}\\hat{x}_{1}=\\int\\frac{\\alpha_{t}{\\sigma_{t}^{2}}p_{t}(x_{1}-\\hat{x}_{1}}^{T}dx_{1}=\\int\\frac{\\alpha_{t}{\\sigma_{t}^{2}}p_{t}(x_{1}}|x)(x_{1}-\\hat{x}_{1}}{t}=\\frac{\\alpha_{t}(x_{1}-\\hat{x}_{1}}\\mathrm{Var}(x_{1}|x}}\\mathrm{Var}(x_{1}|x}}{\\sigma_{t}{\\sigma_{t}{\\sigma_{t}{\\sigma_{t}{\\sigma_{t}{\\sigma_{t}{\\sigma_{t}{\\sigma_{t}{34}\\tag{\n' +
      '\n' +
      '여기서 두 번째 등식에서 우리는 적분 \\(\\frac{\\alpha_{t}{\\sigma_{t}^{2}}\\hat{x}_{1}\\int p_{t}(x_{1}|x)(x_{1}-\\hat{x}_{1})^{T}dx_{1}=0\\)을 뺀다.\n' +
      '\n' +
      '23에 다시 삽입하면\n' +
      '\n' +
      '\\exp\\left[\\int_{x_{0}}x(1)=\\exp\\left[\\int_{0}^{1}a_{t}I+b_{t}\\frac{\\alpha_{t}{\\sigma_{t}^{2}\\mathrm{Var}(x_{1}|x(t))dt\\right]. \\tag{35}\\frac{\\alpha_{t}}{\\sigma_{t}^{2}\\mathrm{Var}(x_{1}|x(t))dt\\right].\n' +
      '\n' +
      '만약 \\(a_{t}\\)이 적분이 된다면 우리는 얻을 수 있다.\n' +
      '\n' +
      '[D_{x_{0}}x(1)=\\sigma_{1}\\exp\\left[\\int_{0}^{1}b_{t}\\frac{\\alpha_{t}{\\sigma_{t}^{2}\\mathrm{Var}(x_{1}|x(t))dt\\right], \\tag{36}\\frac{\\alpha_{t}{\\sigma_{t}^{2}\\mathrm{Var}(x_{1}|x(t))dt\\right],\n' +
      '\n' +
      '여기서 \\(\\exp\\left[\\int_{0}^{1}a_{t}dt\\right]=\\sigma_{1}\\), 및\n' +
      '\n' +
      '\\frac{\\alpha_{t}}{\\sigma_{t}\\frac{d}{d}\\frac{d}\\frac{d}\\alpha_{t}\\sigma_{t}\\sigma_{t}\\frac{1}{2}\\frac{d}{t}\\sigma_{t}\\sigma_{t}\\frac{d}\\frac{d}\\sigma_{t}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\sigma_{t}\\frac{d}\\f\n' +
      '\n' +
      '증거를 구성하는 것.\n' +
      '\n' +
      '다음으로 식 18의 적분이 \\(\\sigma_{1}=0\\)에 대해서도 정의됨을 보인다.\n' +
      '\n' +
      'Lemma A.2**.: _For a Lipschitz function \\(f:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}\\) we have the \\(\\int\\mathcal{N}(x|y,\\sigma^{2}I)f(x)dx=f(y)+\\mathcal{O}(\\sigma\\))._\n' +
      '\n' +
      '증명: \\[\\left|\\int\\mathcal{N}(x|y,\\sigma^{2}I)f(x)dx-f(y)\\right|\\leq\\mathcal{N}(x|y,\\sigma^{2}I))\\left|f(x)-f(y)\\right|dx\\]\\[=\\int\\mathcal{N}(z|0,I)\\left|f(\\sigma z+y)-f(y)\\right|dz\\]\\[\\leqK\\sigma\\int\\mathcal{N}(z|0,I)\\left|z\\right|dz\\]\\[=\\mathcal{O}(\\sigma),\\(z=\\frac{x-y}{\\sigma}\\sigma}\\sigma),\\(f\\)는 상수 \\(k>0\\)를 갖는 Lipschitz라는 사실을 사용하였다.\n' +
      '\n' +
      '이 Lemma를 사용하여 우리는 ( \\(p_{1}(x)\\)와 그 파생물이 립시츠라는 가정하에) 증명한다:\n' +
      '\n' +
      '**Proposition A.3**.: _\\(t\\to 1\\)에서의 denoiser asymptotics is_\n' +
      '\n' +
      '\\[\\hat{x}_{1}=\\frac{x}{\\alpha_{t}}+\\mathcal{O}(\\sigma_{t}) \\tag{38}\\]\n' +
      '\n' +
      '증명: 첫째, \\(\\sigma_{t}\\to 0\\)과 \\(\\alpha_{t}\\to 1\\)을 \\(t\\to 1\\)으로 가정하고,\n' +
      '\n' +
      '\\mathcal{N}(x|\\alpha_{t}x_{1},\\sigma_{t}^{2}I)=c_{t}\\mathcal{N}\\left(x_{1}\\bigg{|}\\frac{x}{\\alpha_{t},\\left(\\frac{\\sigma_{t}{\\alpha_{t}}}\\right), \\tag{39}\\frac{n}\\left(x_{1}\\bigg{|}\\frac{x}{\\alpha_{t}}\\right)^{2}I\\right), \\tag{39}\\c{t}\\mathcal{N}\\left(x_{1}\\bigg{x}\\frac{x}{\\alpha_{t}}\\frac{t}{\\alpha_{t}}}{\\alpha_{t}}}}I\\right)\n' +
      '\n' +
      '여기서 \\(c_{t}\\)는 \\(c_{1}=1\\)이 되도록 일부 정규화 상수이다. 이제\n' +
      '\n' +
      '\\int\\mathcal{N}(x|\\alpha_{t}x_{1},\\sigma_{t}^{2}I)p_{1}(x_{1})dx_{1}\\tag{40}\\][=c_{t}\\int\\mathcal{N}\\left(x_{1}\\bigg{x}\\frac{x}{\\alpha_{t}},\\left(\\frac{x}{\\alpha_{t}}\\right)dx_{1}(x_{t}}\\right)+\\mathcal{O}(\\frac{x}{\\alpha_{t}\\right),\\tag{42}\\t}}dx_{1}(x_{t}\\right)+\\mathcal{O}(\\frac{x}{\\alpha_{t}\\right)+\\mathcal{O}(\\frac{x}{\\alpha_{t}\\right)+\\mathcal{O}(\\frac{t}p_{1}(x\n' +
      '\n' +
      '두 번째 등식에서 우리는 방정식 39와 마지막 등식 Lemma A.2를 사용했다.\n' +
      '\n' +
      '∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑∑\n' +
      '\n' +
      '여기서 두 번째 등식에서 우리는 \\(p_{t}(x_{1}|x)\\)의 정의를 사용했고, 세 번째 등식에서 우리는 방정식 39를 사용했고, 네 번째 등식에서 우리는 Lemma A.2를 사용했다.\n' +
      '\n' +
      '이제 \\(D_{x}u_{t}(x(t))\\)가 \\(t\\to 1\\)으로 경계됨을 알 수 있다.\n' +
      '\n' +
      '(x(t)) =a_{t}I+b_{t}D_{x}\\hat{x}_{1}\\tag{48}\\] \\[=a_{t}I+b_{t}\\left(\\frac{1}{a_{t}I+\\mathcal{O}(\\sigma_{t}\\right)\\] (49) \\[=\\frac{\\dot{\\alpha}_{t}I+\\mathcal{O}(1), \\tag{50}\\t}\n' +
      '\n' +
      '여기서 첫 번째 등식에서 우리는 방정식 29, 두 번째 명제 A.3(및 \\(p_{1}\\)의 도함수가 점근 법칙의 도출을 위한 립시츠라는 사실)에서, 그리고 마지막 등식 26에서 \\(D_{x}u_{t}(x(t))\\)는 \\(t\\to 0\\)으로 두 \\(a_{0},b_{0}\\)으로 경계가 잘 정의되어 있다. 이것은 \\(D_{x}u_{t}(x(t))\\)이 \\([0,1]\\)에 걸쳐 적분 가능하다는 것을 의미한다.\n' +
      '\n' +
      '### flow matching, denoisers and noise prediction\n' +
      '\n' +
      '다음의 전송 맵에 의해 정의된 일반적인 아핀 조건부 확률 경로를 고려한다:\n' +
      '\n' +
      '\\[x_{t}=\\sigma_{t}x_{0}+\\alpha_{t}x_{1}\\]\n' +
      '\n' +
      '여기서 \\(x_{0}\\sim p_{0}\\) 및 \\(x_{1}\\sim p_{1}\\).\n' +
      '\n' +
      '\\(\\sigma_{t},\\alpha_{t}\\)의 다양한 선택에 대해 우리는 알려진 확산 경로와 흐름 일치 경로를 매개변수화할 수 있다. \\(x_{1}\\) 상의 대응하는 조건부 벡터 필드는:\n' +
      '\n' +
      '\\frac{\\dot{\\sigma}_{t}(x|x_{1})=\\frac{\\dot{\\sigma}_{t}(x-\\alpha}_{t})+\\dot{\\alpha}_{t}x_{1}=\\frac{\\dot{\\sigma}_{t}{\\sigma}x-\\left(\\frac{\\dot{\\sigma}_{t}\\alpha_{t}-\\dot{\\alpha}_{t}\\right)x_{1}\\frac{\\dot{\\sigma}_{t}{\\sigma}\\left(\\frac{\\dot{\\sigma}_{t}\\alpha}\\right)x_{1}\\frac{\\dot{\\sigma}_{t}{\\sigma}{\\sigma}{t}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}\\t}{\\sigma}{\\sigma}\\t}{\\sigma}\\t}\n' +
      '\n' +
      '및 \\(x_{0}\\) 상의 조건부 벡터 필드는:\n' +
      '\n' +
      '\\dot{\\sigma}_{t}x_{0}+\\frac{\\dot{\\sigma}_{t}{\\alpha_{t}(x-\\sigma_{t}{\\alpha_{t}(x-\\sigma}x_{t}{\\alpha_{t}{\\alpha_{t}}{\\alpha_{t}}x-\\left(\\frac{\\dot{\\alpha}_{t}\\sigma}-\\dot{\\sigma}_{t}\\t}\n' +
      '\n' +
      'where \\(\\dot{f}=\\frac{d}{dt}f\\).\n' +
      '\n' +
      '주변 속도장을 고려하라:\n' +
      '\n' +
      '[u_{t}(x)=\\int u_{t}(x|x_{1})p_{t}(x_{1}|x)dx_{1}=\\int u_{t}(x|x_{0})p_{t}(x_{0}|x)dx_{0}\\]\n' +
      '\n' +
      '최적 _denoiser_ function, \\(\\hat{x}_{1}^{*}(x,t)\\)의 관점에서 표현할 수 있다:\n' +
      '\n' +
      'dx_{1}-\\left(\\frac{\\dot{\\sigma}_{t}{\\sigma}_{t}{\\sigma}_{t}{\\sigma}{t}-\\dot{\\alpha}_{t}-\\dot{\\alpha}_{t}-\\dot{\\sigma}_{t}(x_{1}|x)dx_{1}=\\frac{\\dot{\\sigma}_{t}{\\sigma}_{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}\\hat{x}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}\\hat{x}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma}{t}{\\sigma\n' +
      '\n' +
      'For Cond-OT:\n' +
      '\n' +
      '\\[u_{t}(x)=\\frac{\\hat{x}_{1}^{*}(x,t)-x}{1-t} \\tag{51}\\]\n' +
      '\n' +
      '또는, 최적 잡음 예측기의 관점에서, DDPM에서와 같이 \\(\\epsilon^{*}(x,t)\\)\n' +
      '\n' +
      'dx_{0}-\\frac{\\dot{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}-\\dot{\\sigma_{t}-\\dot{\\sigma_{t}-\\dot{\\sigma_{t}{\\alpha}_{t}(x_{0}|x)dx_{0}=\\frac{\\dot{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}{\\alpha}_{t}\\epsilon^{*}(x,t\\t}\\epsilon^{*}(x,t\\t}{\\alpha}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\sigma}{\\s\n' +
      '\n' +
      '및 Cond-OT를 위해:\n' +
      '\n' +
      '\\[u_{t}(x)=\\frac{x-\\epsilon^{*}(x,t)}{t} \\tag{52}\\]\n' +
      '\n' +
      '## 부록 B 구현 세부사항\n' +
      '\n' +
      '### 이미지의 선형 역문제\n' +
      '\n' +
      '#### Optimization Details.\n' +
      '\n' +
      '이 섹션의 모든 실험에 대해 라인 검색을 사용한 각 최적화 단계에 대해 20개의 내부 반복이 있는 LBFGS 최적화기를 사용했다. 정지 기준은 목표 PSNR 값으로 설정되었으며, 작업에 따라 다르다. 선형 역 문제에 대한 알고리즘의 손실, 정규화, 초기화 및 정지 기준은 표 6에 나열되어 있으며, 표 \\(\\chi^{d}\\) 정규화는 방정식 10에 해당하고 \\(\\lambda\\)은 사용된 계수를 나타낸다.\n' +
      '\n' +
      '**Runtimes.**: Inpainting Center crop은 이미지당 10\\(10\\)분, super resolution는 이미지당 12.5\\(12.5\\)분, Gaussian deblurring은 이미지당 15.5\\(15.5\\)분이었다. 노이즈 작업의 경우, 인페인팅 센터 크롭은 이미지당 4분, 초해상도는 이미지당 2.5분, 가우시안 디블러링은 이미지당 3.5분이 소요되었다. 실험은 32GB NVIDIA V100 GPU에서 실행되었다.\n' +
      '\n' +
      'Metrics는 오픈 소스 TorchMetrics 라이브러리(Detlefsen et al., 2022)를 사용하여 계산된다.\n' +
      '\n' +
      '**RED-Diff Baseline.** FM cond-OT 훈련된 모델을 사용하여 RED-Diff baseline을 사용하기 위해 속도 필드를 52에 따라 엡실론 예측으로 변환한다. 작업 매개변수를 검색하고 엡실론 예측 모델을 사용하여 (Pokle et al., 2023)에서 생성된 결과를 능가하는 결과를 보고했으며, 그렇지 않으면 (Pokle et al., 2023)에서 번호를 유지했다.\n' +
      '\n' +
      '잠재 흐름 모델과 함께### 인페인팅\n' +
      '\n' +
      '####b.2.1 이미지 인페인팅\n' +
      '\n' +
      '**최적화 세부사항.** 이 실험에서 우리는 라인 검색과 함께 각 최적화 단계에 대해 20개의 내부 반복이 있는 LBFGS 최적화기를 사용했다. 정지 기준은 런타임 한계인 \\(30\\)분에 의해 설정되었지만, 최적화는 보통 이전에 수렴한다. 사용된 솔버는 6개의 함수 평가로 중간점이었고 손실은 정규화 없이 음의 PSNR이었다. 우리는 \\(\\alpha=0.25\\)의 백워드 블렌드를 사용하여 알고리즘을 초기화했다. 큰 T2I 모델을 통해 역전파를 용이하게 하기 위해 기울기 체크포인팅을 사용한다.\n' +
      '\n' +
      '평가에 사용된 COCO 데이터 세트의 검증 세트는 [http://images.cocodataset.org/zips/val2017.zip](http://images.cocodataset.org/zips/val2017.zip)에서 다운로드되었다.\n' +
      '\n' +
      '**RED-Diff Baseline.** RED-Diff를 잠재 공간 확산 모델에 적용하기 위해 RED-Diff에 사용된 손실을 상기하도록 한다:\n' +
      '\n' +
      '\\texttt{s}\\texttt{q}\\left[\\epsilon(x(t),t)-\\epsilon\\right])^{T}\\mu\\tag{53}\\texttt(=\\ell(\\mu)=\\|y-f(\\mu)\\texttt{q}+\\lambda_{t}(\\texttt{s}\\texttt{q}\\left[\\epsilon(x(t),t)-\\epsilon\\right])^{T}\\mu\\tag{53}\\texttt{s}\\texttt{q}\\left[\\epsilon(x(t),t)-\\epsilon\\right])\n' +
      '\n' +
      '여기서 \\(f\\)는 임의의 미분 가능한 함수일 수 있다. 역 문제에 대한 잠재확산/흐름 모델에서 우리는 \\(f\\)을 \\(f=H(\\texttt{decode}(\\mu))\\으로 모델링할 수 있는데, 여기서 디코딩은 잠재확산/흐름 모델에서 사용되는 오토인코더의 디코더를 적용하고 \\(H\\)은 부패 연산자이다. 우리는 \\(\\text{lr}=0.25,\\lambda=0.25\\)을 사용한다.\n' +
      '\n' +
      '#### b.2.2 오디오 인페인팅\n' +
      '\n' +
      '**최적화 세부사항** B.2.1에 설명된 것과 동일한 설정을 따른다. 다르게, 우리는 \\(10\\) 내부 반복을 사용하고 \\(100\\) 전역 반복 후에 중단한다. 우리는 \\(\\alpha=0.1\\)의 백워드 블렌드로 알고리즘을 초기화한다.\n' +
      '\n' +
      '**RED-Diff Baseline.** B.2.1에서 전술한 동일한 적응을 따른다. \\(\\text{lr}=0.05,\\lambda=0.5\\)을 사용한다.\n' +
      '\n' +
      'QM9에서의 조건분자 생성\n' +
      '\n' +
      '**최적화 세부사항.** 이 절에서는 알고리즘 1이 QM9 실험에서 실제로 어떻게 적용되었는지 설명한다. 실험을 위해 \\(x_{0}\\in\\mathbb{R}^{n\\times 9}\\)을 초기화하였다. 여기서 \\(n\\)은 분자의 원자수를 나타내고, \\(9\\)은 원자당 속성수를 나타낸다. 최적화 공정 안정성을 향상시키기 위해, 모든 최적화 단계 후에 정규화함으로써 \\(x_{0}\\)의 특징별 평균이 0이고 표준 편차가 1임을 보장하였다. 본 연구에서는 총 100\\(100\\)의 함수평가와 함께 중간점법(midpoint method)을 사용하였다. 사용된 최적화 기법은 LBFGS로, 각 단계에 대한 \\(5\\) 최적화 단계와 \\(5\\) 내부 반복의 한계로 구성되었다. 학습률은 \\(1\\)으로 설정하였다. 평균적으로 단일 분자를 생성하는 데는 단일 NVIDIA Quadro RTX8000 GPU를 사용하여 약 1\\(2.5\\)분이 소요되었다.\n' +
      '\n' +
      '**소음 예측 대 속도장 예측.** 이 절에서는 확률적 샘플러 변경의 영향을 조사합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c} \\hline \\hline  & \\multicolumn{2}{c}{**Inpainting-Center**} & \\multicolumn{2}{c}{**Super-Resolution X2**} & \\multicolumn{2}{c}{**Gaussian Deblur**} \\\\ \\cline{2-5}  & \\(\\sigma_{y}=0\\) & \\(\\sigma_{y}=0.05\\) & \\(\\sigma_{y}=0.05\\) & \\(\\sigma_{y}=0.05\\) & \\(\\sigma_{y}=0.05\\) \\\\ \\hline Loss & \\(-\\mathrm{PSNR}(Hx,y)\\) & \\(-\\mathrm{PSNR}(Hx,y)\\) & \\(-\\mathrm{PSNR}(H^{\\dagger}Hx,H^{\\dagger}y)\\) & \\(-\\mathrm{PSNR}(Hx,y)\\) \\\\ \\cline{3-5} Regularization & None & \\(\\chi^{d}\\), with \\(\\lambda=0.01\\) & None & \\(\\chi^{d}\\), with \\(\\lambda=0.01\\) & None & \\(\\chi^{d}\\), with \\(\\lambda=0.01\\) \\\\ Initialization & \\(0.1\\) blend & \\(0.1\\) blend & \\(0.1\\) blend & \\(0.1\\) blend & \\(0.1\\) blend \\\\ Target PSNR & 45 & 32 & 55 & 32 & 55 & 32 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: ImageNet-128 선형 역문제 태스크에 대한 알고리즘 선택.\n' +
      '\n' +
      '속도장(VF) 결정론적 샘플러로의 \\(\\epsilon\\)-예측 무조건 확산 모델. 특히, 우리의 주요 주장은 샘플러의 이러한 변화가 우리가 생성하는 분자의 품질 저하의 관찰된 원인이라는 것이다. 표 7은 동일한 확산 모델을 사용하지만 다른 샘플러와 생성된 분자의 품질을 비교한 것이다. (Hoogeboom et al., 2022)의 무조건 확산 모델은 \\(1000\\) 단계의 이산 확산으로 훈련되었다. 이전 부분에서 언급했듯이 우리는 \\(100\\) 함수 평가를 사용하여 D-흐름으로 샘플링했다. 표에서 감소된 품질의 주요 원인은 감소된 스텝 카운트 또는 최적화 프로세스 자체보다는 샘플러의 변경임을 알 수 있다. 향후 연구에서는 FM으로 훈련된 모델을 사용하여 접근 방식을 평가하는 데 중점을 둘 것이다.\n' +
      '\n' +
      '**QM9.** 널리 알려진 모음인 QM9 데이터세트(Ramakrishnan et al., 2014)는 각각 \\(9\\)개의 무거운 원자(수소를 포함할 때 최대 \\(29\\)개의 원자)를 포함하는 \\(130\\)K 작은 분자에 대한 분자 특성 및 원자 위치를 포함한다. 사용된 열차/검증/시험 파티션은 (Anderson et al., 2019)에 따르며 파티션당 \\(100\\)K/\\(18\\)K/\\(13\\)개의 샘플로 구성된다. 실험에 사용된 특성에 대한 추가 세부 정보를 제공합니다.\n' +
      '\n' +
      '* 외부 전기장을 받을 때 전기 쌍극자 모멘트를 얻기 위한 분자의 경향성.\n' +
      '* 가장 높은 점유 분자 에너지.\n' +
      '* 가장 낮은 비점유 분자 에너지.\n' +
      '* HOMO와 LUMO의 차이.\n' +
      '* 다이폴 순간.\n' +
      '* \\(298.15\\)K에서의 열용량.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline Sample Method & \\multicolumn{2}{c}{NFE Molecule Stability Atom Stability} & \\multicolumn{2}{c}{Validity Validity \\& Uniqueness} \\\\  & (\\#) & (\\%) & (\\%) & (\\%) & (\\%) \\\\ \\hline EDM (\\(\\epsilon\\)-prediction, stochastic) & 1000 & 81.73 & 98.40 & 91.50 & 90.32 \\\\ EDM (\\(\\epsilon\\)-prediction, stochastic) & 100 & 78.22 & 98.00 & 90.26 & 89.00 \\\\ \\hline EDM (VF-prediction, deterministic) & 1000 & 65.90 & 97.03 & 83.70 & 83.00 \\\\ EDM (VF-prediction, deterministic) & 100 & 66.24 & 96.61 & 84.39 & 83.20 \\\\ \\hline EDM (VF-prediction, deterministic) + optimization & 100 & 54. 83 & 95.00 & 80.3 & 79.03 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: 상이한 샘플링 경로를 사용하여 생성된 분자 품질의 비교.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:17]\n' +
      '\n' +
      '그림 8: 노이즈 사례에 대한 ImageNet-128의 선형 역 문제에 대한 정성적 비교. GT 샘플은 얼굴 흐릿한 이미지넷-128 검증 세트에서 나온다.\n' +
      '\n' +
      '그림 9: T2I 잠재 FM 모델을 사용하여 MS-COCO 데이터 세트에 대한 자유 형식 인페인팅에 대한 질적 비교. GT 샘플은 MS-COCO 검증 세트에서 나온다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>