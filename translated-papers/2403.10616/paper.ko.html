<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# DiPaCo: 분산 경로 구성\n' +
      '\n' +
      'Arthur Douillard*,1\n' +
      '\n' +
      'Qixuan Feng*,1\n' +
      '\n' +
      '안드레이 A 루수*, 1\n' +
      '\n' +
      'Adhiguna Kuncoro1\n' +
      '\n' +
      'Yani Donchev1\n' +
      '\n' +
      'Rachita Chhaparia1\n' +
      '\n' +
      'Ionel Gog1\n' +
      '\n' +
      'MarcAurelio Ranzato,1\n' +
      '\n' +
      'Jiajun Shen,1\n' +
      '\n' +
      'Arthur Szlam,1\n' +
      '\n' +
      '1동일 핵심 기여도, *동일 선도 기여도, *구글 딥마인드\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '기계 학습(ML)의 진전은 신경망 모델을 스케일링함으로써 촉진되었다. 이러한 스케일링은 병렬적으로 작동하는 장치 간의 높은 대역폭 통신을 필요로 하는 ML 접근 방식을 수용하는 데 필요한 엔지니어링의 더욱 영웅적인 업적에 의해 가능하게 되었다. 본 논문에서는 DIstributed Path COmposition (DiPaCo)로 명명된 ML 모델을 위한 모듈러 아키텍처와 훈련 방법을 제안한다. 교육 중에 DiPaCo는 공유 모듈 집합을 통해 경로별로 계산을 분산한다. 로컬-SGD 영감 최적화(DiLoCo)와 함께 모듈을 급격히 감소된 통신과 동기화하도록 유지하면서, 우리의 접근 방식은 작업자 실패 및 선점에 대한 견고성을 보장하는 설계로 잘 연결되지 않고 이질적인 작업자 전반에 걸친 교육을 용이하게 한다. 추론 시간에, 임의의 모델 압축이 필요 없이, 각각의 입력에 대해 단일 경로만이 실행될 필요가 있다. 우리는 이 접근법을 덜 동기적이고 더 모듈적인 대규모 학습의 새로운 패러다임을 향한 첫 번째 프로토타입으로 간주한다.\n' +
      '\n' +
      '널리 사용되는 C4 벤치마크에 대한 실험은 동일한 양의 훈련 단계이지만 벽-시계 시간이 적은 경우 DiPaCo가 각각 1억 5천만 매개 변수의 크기를 갖는 256개의 가능한 경로 중 하나를 선택하여 10억 매개 변수 밀집형 변압기 언어 모델의 성능을 초과한다는 것을 보여준다.\n' +
      '\n' +
      'douillard@google.com\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '머신 러닝과 AI의 발전은 더 큰 데이터 세트에 대해 훈련된 더 큰 신경망 모델에 더 많은 FLOP를 지출함으로써 주도되었다. 이러한 스케일링은 데이터 및 모델 병렬성(Dean et al., 2012) 및 파이프라이닝(Narayanan et al., 2020)을 통해 수행되어 계산을 분배함으로써, 많은 수의 디바이스들의 동시 사용을 가능하게 한다(Anil et al., 2023; OpenAI et al., 2023; Touvron et al., 2023). 모델 아키텍처들(Lepikhin et al., 2021; OpenAI et al., 2023)은 또한 계산 병렬성을 허용하기 위해 사용되었고, 최적화 절차들은 더 큰 배치들을 선호한다(Goyal et al., 2017)(더 많은 데이터 병렬성을 허용함) 하지만, 현재의 트레이닝 패러다임은 분산 트레이닝을 용이하게 하기 위해 모델 아키텍처 또는 최적화 절차를 근본적으로 변경하지 않았다. 최첨단 모델은 여전히 본질적으로 모노리스이며, 이들의 최적화는 학습 프로세스의 모든 단계에서 매개변수, 구배 및 활성화의 교환을 필요로 한다.\n' +
      '\n' +
      '이 접근법은 긴 훈련 프로세스에 필요한 긴밀하게 상호 연결된 많은 수의 장치를 프로비저닝하고 관리하는 것과 관련된 엔지니어링 및 인프라 문제를 발생시킨다. 트레이닝 프로세스 자체는 종종 각각의 새로운 모델 릴리스에 대해 재시작되고, 본질적으로 마지막 모델을 트레이닝하기 위한 계산의 많은 부분을 폐기한다. 더욱이, 훈련 모놀리스는 (데이터 준비를 넘어) 프로세스의 모든 단계에 대한 변화의 최종 모델에 대한 효과를 국소화하기 어렵기 때문에 인간-조직적 도전을 초래한다. 특히 단일 조직(Raffel, 2023b)이 아닌 더 큰 ML 커뮤니티의 잠재력을 활용하기 어렵다. 이러한 어려움 때문에 현재 접근 방식으로 계속 확장하는 것이 더 어려워질 수 있다.\n' +
      '\n' +
      '(Barham et al., 2022; Borzunov et al., 2022; Raffel, 2023; Ryabinin and Gusev, 2020)에서와 같이 그림 1에 묘사된 바와 같이, 우리는 많은 양의 데이터를 섭취하고 훈련하는 능력 및 많은 기여자와의 협업을 가능하게 하는 측면에서 모델이 확장 가능하고 모듈식 설계에 의해 지속적으로 업데이트되고 확장될 수 있는 대안적인 접근법을 구상한다. 모듈형 ML은 많은 다른 이점을 가질 수 있으며, 추가 논의 및 참조를 위해 Pfeiffer 등(2023)을 참조한다.\n' +
      '\n' +
      '본 논문에서는 이러한 확장성 있는 모듈형 ML 패러다임으로 나아가기 위해 아키텍처와 학습 알고리즘인 DIstributed Paths COmposition(DiPaCo)을 제안한다. DiPaCo의 아키텍처와 최적화는 통신을 줄이고 더 나은 스케일링을 가능하게 하기 위해 공동 설계되었다. 높은 수준의 아이디어는 path_에 의해 계산을 분배하는 것이다; 여기서, "path"는 입력-출력 함수를 정의하는 모듈들의 시퀀스를 의미한다. 경로는 전체 모델에 비해 작으므로 훈련 또는 평가를 위해 소수의 밀접하게 연결된 장치만 필요하다. 교육 및 배포 중에 쿼리는 전체 모델의 복제본이 아닌 경로의 복제본으로 라우팅됩니다. 즉, DiPaCo 아키텍처는 희소하게 활성화됩니다. 우리는 섹션 2에서 DiPaCo에 대한 자세한 설명을 제공하고 섹션 3에서 이를 구현하기 위해 사용한 인프라를 제공한다.\n' +
      '\n' +
      '섹션 4에서는 C4 데이터셋(Raffel et al., 2020)에서 언어 모델을 1억 5천만 매개 변수의 경로로 훈련하여 DiPaCo의 타당성을 입증하며, 13억 모델의 검증 복잡성 측면에서 성능과 일치하지만 벽 시계 훈련 시간이 45% 적다. 조밀한 1.3B 시스템은 모든 공동 위치 장치를 사용해야 했지만 DiPaCo는 256개의 계산 섬을 사용하며, 각각은 기준선을 훈련하는 데 사용되는 장치의 수의 8분의 1이다. 열차 또는 평가 시간 중 어느 것도 전체 DiPaCo 모델을 공동 찾을 필요가 없다.\n' +
      '\n' +
      '## 2 Approach\n' +
      '\n' +
      '이 섹션에서는 DiPaCo에 대한 자세한 설명을 제공한다. 우리는 우리가 일할 가정과 설정을 설명하는 것으로 시작한다.\n' +
      '\n' +
      '### Setting\n' +
      '\n' +
      '이 작업의 목표는 밀접하게 연결된 하나의 계산 토지 질량과 달리 더 작은 계산 섬의 환경에서 확장 가능한 ML 모델을 시연하는 것이다. 따라서, 우리는 다음과 같이 가정한다:\n' +
      '\n' +
      '1. 트레이닝 컴퓨트(FLOP)는 상대적으로 저렴하다 2. 통신은 상대적으로 비싸다\n' +
      '\n' +
      '이러한 가정은 현재의 ML 훈련 패러다임에서 _not_ 현실적이다. 위에서 논의된 바와 같이, 디바이스들은 일반적으로 단일 조직에 의해 공동 위치되고 운영되며, FLOP들은 비싸고, 많은 가속기들의 구매 및 설치에 의해 제약되지만, 디바이스들 간의 통신은 공동 위치 때문에 상대적으로 저렴하다.\n' +
      '\n' +
      '그럼에도 불구하고, 우리의 관점에서, 이러한 가정은 우리의 계산 요구 사항(또는 모델 크기)이 합리적으로 공동 위치될 수 있는 것 이상으로 성장하여 통신 비용이 상대적으로 더 비싸진다면 가까운 장래에 현실적일 수 있다. 반대로 ML 모델의 분산 훈련의 진전은 더 간단한 인프라 구축을 가능하게 하여 결국 더 많은 사용 가능한 계산으로 이어질 수 있다. 현재, 인프라는 대형 모놀리스를 훈련하기 위한 표준 접근 방식을 중심으로 설계되며, ML 모델은 현재의 인프라는 물론 훈련 접근 방식을 활용하기 위해 설계된다. 이 피드백 루프는 컴퓨팅이 필요한 것보다 더 제약되는 가짜 로컬 최소값으로 커뮤니티를 유도할 수 있다.\n' +
      '\n' +
      '또한 위의 두 가지 가정과 함께 열차와 평가 모두에서 인스턴스화할 수 없다고 가정한다.\n' +
      '\n' +
      '그림 1: **장기 목표**: 궁극적으로 서로 다른 구성 요소인 _paths_\\(\\pi_{i}\\)가 서로 다른 연구자에 의해 각각 설계된 서로 다른 작업인 \\(\\mathcal{D}_{j}\\)에 최적화되는 모듈식 네트워크를 구상한다. 사용 가능한 하드웨어 유형에 대해 훈련된 경로는 전 세계적으로 드물게 통신하며 유용한 정보를 교환하고 새로운 형태의 구성을 가능하게 한다.\n' +
      '\n' +
      '단일 컴퓨팅 섬에서 원하는 크기만큼 큰 모델입니다.\n' +
      '\n' +
      '우리는 언어 모델링(LM)의 맥락에서 작업할 것이다. 위의 가정을 바탕으로, 우리는 평가 복잡성을 염두에 두고 벽-시계 시간에 대한 평가 복잡성(PPL)으로 모델을 평가할 것이다. 모델 교육을 배포하는 방법을 탐구하도록 장려하기 때문에 이 메트릭을 선택하고, 더 일반적으로 ML에 대한 그럴듯한 새로운 패러다임을 지적한다.\n' +
      '\n' +
      '### 시스템 개요\n' +
      '\n' +
      'DiPaCo의 핵심 아이디어는 모듈들을 통한 경로의 선택에 의해 데이터와 계산이 분산되는 희박하게 작동되는 모듈 시스템을 훈련시키는 것이다. 이 작업을 수행하는 데 두 가지 핵심 아이디어가 있습니다.\n' +
      '\n' +
      'Coarse Routing:Sparsely Routed Mixture of Experts (MoE)는 언어 모델링에서 큰 성과를 보였다 (Lepikhin et al., 2021). 변압기 MoE LM에서 표준 접근법은 각 라우팅 계층에서의 특징에 기초하여 각 토큰에서 라우팅 결정을 내리는 것이다. 대조적으로, 이 작업에서, 훈련 동안 우리는 문서당 한 번 그리고 오프라인으로 라우팅할 것이다(Gross et al., 2017; Gururangan et al., 2023).\n' +
      '\n' +
      '문서당 한 번 라우팅하면 시퀀스가 처리됨에 따라 모듈을 안팎으로 스왑할 필요 없이 시퀀스의 모든 토큰에 걸쳐 계산 배치가 가능합니다. 이를 통해 매개 변수가 먼 작업자에 걸쳐 분산될 수 있습니다. 또한 모델과 함께 라우터를 학습하는 대신 라우팅 결정 _offline_을 계산할 것이다. 이를 통해 훈련 시작 전에 경로별로 데이터를 사전 샤딩할 수 있습니다. 이것은 각 작업자가 자체 매개변수 세트를 사용하여 자체 데이터 조각을 처리하여 경로를 훈련할 수 있기 때문에 경로를 통해 훈련을 분배하는 데 중요하다. 하위 섹션 2.4에서는 거친 라우팅에 어떻게 접근하는지 자세히 설명한다.\n' +
      '\n' +
      '동기 경로에 모듈을 유지하기 위한 DiLoCo는 일부 모듈이 여러 경로에 걸쳐 공유될 수 있기 때문에 완전히 독립적으로 훈련될 수 없다. 경로 간 모듈 공유를 지원하기 위해 DiLoCo(Douillard et al., 2023)를 사용하여 낮은 통신 데이터 병렬성을 위해 하위 섹션 2.5를 참조한다. 모듈을 공유하는 \\(P\\) 경로(P\\(P\\) 작업자에게 할당됨)가 있는 경우, 각 해당 작업자는 자신의 데이터 샤드에 대해 SGD를 수행하고, _few hundred_ 단계마다 작업자는 로컬 SGD 단계 전후에 모듈 \\(i\\)의 파라미터의 차이를 평균화한다. 그런 다음 이러한 평균을 사용하여 글로벌 매개변수 벡터를 업데이트한 다음 작업자에게 재분배하여 동기화하며, 이는 하위 섹션 2.6에 설명된 절차이다.\n' +
      '\n' +
      '이 두 가지 선택으로 훈련 시나 테스트 시간에는 그림 1과 같이 전체 네트워크(경로 집합)가 함께 구체화될 필요가 없다.\n' +
      '\n' +
      '### Notation\n' +
      '\n' +
      '이 절에서는 이 작업 전반에 걸쳐 사용된 기본 표기법을 소개한다. 우리는 매개변수\\(\\theta\\)를 갖는 기본 모델 아키텍처를 가지고 있다고 가정한다. 매개변수 인덱스를 \\(L\\)부분집합 \\(B_{l},l\\in[1,\\dots,L]\\)으로 분할한다. 각 \\(l\\)에 대해 우리는 \\(B_{l}\\)의 매개변수에 대한 가능한 선택 수를 나타내는 수 \\(K_{l}\\)을 선택한다. 우리는 \\(B_{l}\\)에 연관된 파라미터들의 세트를 "모듈" 또는 "전문가"인 (Jacobs et al., 1991; Jordan and Jacobs, 1994)에서와 같이 호출할 것이다. 이 용어에서 \\(K_{l}\\)은 \\(B_{l}\\)과 관련된 별개의 모듈의 수이다.\n' +
      '\n' +
      '간단한 예를 들어, 4-계층 완전 연결 네트워크 \\(A\\)를 생각해 보자. 첫 번째 두 층은 \\(B_{1}\\)이고 세 번째와 네 번째 층은 \\(B_{2}\\)이므로 \\(L=2\\)이 될 수 있다. 우리가 \\(i=1,2\\)에 대해 \\(K_{i}=3\\)을 선택한다면, 우리는 총 6개의 모듈에 대해 \\(B_{1}\\)에 3개의 모듈이 있고, \\(B_{2}\\)에 3개의 모듈이 있다. (B_{1}\\)와 모듈 형태 \\(B_{2}\\)에서 어떤 모듈 선택도 신경망을 정의한다; Dean (2021)에서와 같이, 우리는 이 9개의 가능한 네트워크 각각을 "경로"라고 부르며, 그림 2를 참조한다.\n' +
      '\n' +
      '이 예에서, 그리고 이 논문의 나머지 부분에서 우리가 고려할 대부분의 경우, "블록들" \\(B_{i}\\)은 입력-출력 맵핑으로서 작용할 수 있는 \\(A\\)의 연속적인 서브-네트워크들을 결정하지만, 이것은 필요하지 않다. 우리는 \\(B_{1}\\)을 층 1과 3, \\(B_{2}\\)을 층 2와 4로 쉽게 만들 수 있다; 또는 \\(B_{1}\\)은 네트워크의 모든 편향이고, \\(B_{2}\\)은 모든 선형 매개변수이다. 그럼에도 불구하고 우리는 \\(i\\)을 모듈의 "레벨"이라고 부를 것이다.\n' +
      '\n' +
      '입력\\(x\\)을 출력\\(y\\)으로 변환하기 위해서, 우리는 어떤 파라미터들이 \\(x\\)에서 동작하는데 사용될 것인지를 알아내야 한다. 매개변수 선택에 \\(x\\)을 취하는 함수는 "router"라고 하며, 따라서 \\(r(x)\\)는 \\([j_{1},...,j_{L}]\\)의 형태를 가지며, 여기서 각각의 \\(j_{l}\\)은 \\(B_{l}\\)에 대한 매개변수의 \\(K_{l}\\) 선택 중 하나를 인덱싱하고, \\(r\\)은 입력을 경로 \\(\\pi=\\pi_{j_{1},...,j_{L}}\\)에 매핑한다. 우리는 또한 종종 수열 \\(j_{1},...,j_{L}\\)을 단일 수 \\(j\\)으로 붕괴시킬 것이다. 여기서 \\(j\\in\\{1,\\ldots,P=\\Pi_{i=1}^{L}K_{i}\\}). 트레이닝 데이터 세트를 \\(X\\)로 표시하면, 경로 \\(j\\)으로 라우팅되는 데이터의 서브세트는 \\(j\\)번째 "샤드" \\(\\mathcal{D}_{j}\\)이라고 불릴 것이다.\n' +
      '\n' +
      '라우터가 \\(x\\)을 \\(\\{1,\\ldots,P\\}\\) 이상의 분포에 매핑할 때, 우리는 라우터가 "소프트"라고 말한다. 이 작업에서 우리는 선택이 단일 가치이고 결정론적인 "하드" 라우터를 대신 고려할 것이다.\n' +
      '\n' +
      '마지막으로, 모듈 파라미터를 참조하는 것이 유용하다. [1,K_{l}]\\(e\\in[1,K_{l}]\\), \\(l\\in[1,L]\\)으로 \\(i\\)번째 경로가 \\(l\\) 수준에서 모듈 \\(e\\)을 통과한다고 가정하자. 트레이닝 경로들이 완전히 동기화되지 않기 때문에, 우리는 경로 \\(i\\)에서 모듈 \\(l,e)\\)의 파라미터들의 로컬 복사본을 반복 \\(t\\)과 \\(theta(l,e)_{i}^{t}\\)으로 표시한다. (모든 수준에서) \\(i\\)번째 경로가 사용하는 매개변수 집합은 \\(\\theta_{i}^{t}\\)으로 표시된다. 경로에 따른 모듈이 동기화될 때, 모듈 \\((l,e)\\)의 파라미터 값은 모든 경로에서 동일하므로, 우리는 \\(\\theta(l,e)^{t}\\)에서와 같이 경로 인덱스를 생략하여 반복 \\(t\\)에서 모듈 \\((l,e)\\)의 파라미터의 전역 복사본을 나타낸다. 유사하게, 우리는 각각 \\(\\Delta(l,e)_{i}^{t}\\)와 \\(\\Delta(l,e)^{t}\\)으로 모듈 \\((l,e)\\)의 국소 및 전역 기울기를 나타낸다.\n' +
      '\n' +
      '### Coarse Routing\n' +
      '\n' +
      '이 섹션에서는 시퀀스를 라우팅하는 방법을 설명합니다. 기본적인 직관은 어떤 경로가 주어진 시퀀스를 처리하는데 가장 적합한지를 결정하기 위해 어떤 맥락을 사용하는 것이다. 언어 모델링에 초점을 맞추기 때문에 각 시퀀스의 처음 32개의 토큰을 컨텍스트로 사용한다. 트레이닝 시간에, 우리는 모델 파라미터들을 학습하기 위해 나머지 토큰들을 사용한다. 테스트 시간에는 나머지 토큰을 사용하여 보류된 유효성 검사 세트에서 당혹감을 계산합니다. 조밀한 기준선을 포함한 모든 방법은 모델의 라우팅 결정을 결정하는 데 사용된 각 시퀀스의 처음 32개의 토큰을 제외한 모든 토큰을 사용하여 복잡성을 계산하여 동일한 방식으로 평가된다.\n' +
      '\n' +
      '라우팅의 결과가 네트워크의 특정 경로에 각 시퀀스를 할당하고 있음을 주목하십시오. 종합적으로, 특정 경로에 할당된 모든 시퀀스는 원래 데이터세트의 샤드를 형성한다. 본 연구에서는 경로들과 해당 샤드들 사이에 일대일 연관성이 존재하며, 경로\\(\\pi_{i}\\)는 샤드\\(\\mathcal{D}_{i}\\)과 연관된다.\n' +
      '\n' +
      '다음으로, 라우팅의 다른 변형뿐만 아니라 라우팅에 32개의 토큰의 이 접두사를 사용하는 방법을 설명한다.\n' +
      '\n' +
      '###### 2.4.1 생성 라우팅\n' +
      '\n' +
      '생성 라우팅에서 시퀀스를 할당할 샤드에 대한 결정은 당면한 작업, 즉 언어 모델링에 의해 알려지지 않는다. 대신에, 선택은 특징 재구성 에러를 최소화하는 것에 기초한다. 시퀀스(컨텍스트)의 처음 32개의 토큰에 대한 표현 \\(z\\)이 주어지면 각 시퀀스의 특징 \\(z\\)에 \\(k\\)-Means를 수행한 후 \\(k\\)-means assign을 사용한다.\n' +
      '\n' +
      '그림 2: 섹션 2.3의 첫 번째 예제 그림. 처음 2개 층으로 구성된 블록 \\(B_{1}\\)과 다음 2개 층으로 구성된 \\(B_{2}\\)이 있는 4개 층 신경망. 각 블록은 서로 다른 색상으로 표현되는 모듈(각각 자체 매개변수를 갖는)의 3가지 선택을 갖는다. 왼쪽에서 우리는 9개의 가능한 경로를 모두 보여준다. 오른쪽에 우리는 하나의 길을 보여준다.\n' +
      '\n' +
      '데이터 조각을 \\(k\\) 조각으로 분할하는 알고리즘. \\(\\{c_{1},\\ldots,c_{k}\\}\\)이 \\(k\\)-means에 의해 학습된 \\(k\\) 원형이라면, 접두사 \\(z\\)을 갖는 시퀀스는 샤드 \\(\\mathcal{D}_{r(z)}\\)을 통해 할당된다:\n' +
      '\n' +
      '\\[r(z)=\\arg\\min_{i\\in[1,k]}||z-c_{i}||^{2}. \\tag{1}\\]\n' +
      '\n' +
      '#### Discriminative routing\n' +
      '\n' +
      '생성적 라우팅은 언어 모델링 작업의 불가지론이다. 차별적 라우팅에서 샤딩은 전문가가 각 시퀀스에 대해 얼마나 잘 수행하는지 고려한다. 트레이닝 세트는 두 부분으로 나뉩니다. 첫 번째와 가장 큰 부분은 생성 샤딩 어프로치를 사용하여 샤딩된 데이터의 경로를 훈련하는 데 사용된다. 두 번째와 훨씬 작은 부분은 각 시퀀스의 경로를 평가하는 데 사용된다. (s_{i}\\)을 prefix \\(z\\)와 연관된 시퀀스 상의 경로 \\(\\pi_{i}\\)의 로그 우도 점수로 하자. 가장 큰 우도 점수를 얻는 경로의 인덱스인 \\(i^{*}=\\arg\\max_{j}s_{j}\\)는 \\(z\\)의 레이블로 사용된다. 그리고 이 특징들로부터 \\(z\\)을 직접 예측할 수 있도록 로지스틱 회귀 분류기를 훈련시킨다. 이 훈련된 분류기는 \\(r\\)으로 사용된다. 마지막으로, 이러한 분류기를 사용하여 전체 학습 및 검증 데이터 세트를 다시 공유한다.\n' +
      '\n' +
      '이 프로세스는 모델의 파라미터를 업데이트하는 것(경로들)과 잠재 변수들(경로 할당들) 사이에서 교대하는 좌표 하강 방법인 기대 최대화(Dempster et al., 1977)에 대한 근사치이다. 단순화를 위해 경로 점수에 대한 전체 사후 분포와 달리 최상위 점수 경로를 레이블로 사용하기 때문에 근사치이다. 물론, 이러한 재할당 과정은 원하는 횟수만큼 반복될 수 있다.\n' +
      '\n' +
      '라우팅 메커니즘에서 더 깊이 잠수하는 데 관심이 있는 독자를 추가 세부 정보를 위해 부록의 하위 섹션 7.2를 읽도록 초대한다.\n' +
      '\n' +
      '테스트 시간에서 더 자주#### 라우팅\n' +
      '\n' +
      '시퀀스당 한 번만 라우팅하는 것은 경로 전체에 교육을 배포하는 데 중요합니다. 그러나 테스트 시간에는 더 자주 라우팅할 수 있습니다. 그림 3과 같이, 우리는 테스트 시간에서의 시퀀스를 \\(W>1\\)의 연속적인 토큰들, 예를 들어 \\(W=128\\)의 청크들로 분할할 수 있다. 그런 다음 하위 섹션 2.4.2와 유사한 프로세스를 사용하여 \\((i+1)\\)번째 청크에서 사용할 최상의 경로를 예측하기 위해 \\(i\\)번째 청크를 라우터에 공급할 수 있다. 라우터는 자주 실행되지 않고 자동 회귀 생성 모드와 반대로 채점하기 때문에 경로 전환 비용이 작다. 또한 텍스트만 라우터와 다음 선택한 경로에 전달하면 됩니다.\n' +
      '\n' +
      '#### Overlapping Shards\n' +
      '\n' +
      '위에서 각 시퀀스는 한 조각과 한 조각에만 연관되었으며, 다시 말해 데이터셋을 \\(k\\) 분할 집합으로 미리 공유했다.\n' +
      '\n' +
      '샤드 \\(k\\)의 수가 많은 경우, 혼합\n' +
      '\n' +
      '도 3: **Test-Time**에서 더 자주 라우팅: 훈련 시간(왼쪽 패널)에서 라우터는 prefix \\(z\\)을 사용하여 경로 \\(\\pi_{i}\\)을 선택한다. 우리는 일반적인 언어 모델링 손실을 사용하여 전체 시퀀스에서 선택된 경로를 훈련한다. 테스트 시간(오른쪽 패널)에서 프리픽스가 주어진 라우터에 의해 선택된 경로는 토큰의 다음 청크를 스코어링하는 데 사용된다. 그런 다음 라우터를 다시 사용하여 새 청크가 주어졌을 때 가장 가능성이 높은 경로를 선택합니다. 이 과정은 전체 순서가 점수화될 때까지 반복된다.\n' +
      '\n' +
      '특히 경로가 매개 변수를 거의 공유하지 않을 때 개구부가 과도하게 적합할 수 있습니다. 이 문제를 해결하기 위해 우리는 각 시퀀스를 하나의 조각뿐만 아니라 "가장 가까운" 조각에 할당할 수 있다. 이는 샤드들이 서로 중첩되게 하여 그들 사이의 경계를 평활하게 하며, 이는 샤드들의 수가 상대적으로 많을 때 일반화를 개선할 수 있다. 이것은 열차 시간 및 평가 시간에 _독립적으로_ 수행될 수 있다; 즉, 열차, 평가 또는 둘 다 또는 둘 다 동안에만 파편이 중첩될 수 있다. 열차 시간에서, 샤드들을 중첩하는 것은 각각의 경로의 전문화를 제한하고, 각각의 샤드에 필요한 스토리지를 증가시키지만, 그렇지 않으면 각각의 경로가 여전히 그의 샤드 상에서 독립적으로 트레이닝되기 때문에 계산 비용을 갖지 않는다. 그러나, 평가 시 샤드들이 중첩된다는 것은 모델이 다수의 경로를 통해 포워딩되어야 한다는 것을 의미하며, 이는 평가 계산 비용을 증가시킨다.\n' +
      '\n' +
      '이 작업에서는 훈련에서 파편을 겹칠 때 상위 2개의 선택을 사용하는 반면 평가에서는 파편을 겹치지 않는다. 우리는 파편을 겹치기 위한 다른 접근 방식을 향후 작업으로 남겨둔다.\n' +
      '\n' +
      '### DiLoCo: Review\n' +
      '\n' +
      '본 절에서는 DiLoCo(Douillard et al., 2023)가 우리의 분산 최적화 알고리즘의 기초를 제시함에 따라 요약하며, 이는 다음 절에서 설명될 것이다. 하위 섹션 2.4의 거친 라우팅과 함께 DiLoCo는 DiPaCo의 중요한 구성요소이다.\n' +
      '\n' +
      'DiLoCo는 \\(k\\) 작업자에 걸쳐 조밀한 모델을 최적화합니다. 먼저, 원본 데이터셋은 \\(k\\) 조각으로 샤딩되고, 각 샤드는 작업자와 연관된다. 둘째, 모든 작업자는 모델 매개변수(일반적으로 사전 훈련된 모델)의 동일한 사본에서 시작하여 자체 샤드에 대해 \\(H\\)(내부) 최적화 단계를 독립적으로 수행한다. 셋째, 각 작업자는 새로운 매개변수와 초기 매개변수 사이의 매개변수 공간 차이를 중앙 CPU 서버로 전송한다. 우리는 이러한 차이를 _outer gradients_라고 한다. 중앙 서버는 이러한 외부 기울기를 단일 업데이트 벡터로 평균합니다. 마지막으로, 글로벌 파라미터 벡터는 (외부) 최적화기를 사용하여 업데이트되고, 새로운 글로벌 파라미터 벡터는 로컬 트레이닝의 다른 단계를 위해 모든 작업자에게 재파견된다. 프로세스는 원하는 만큼 많은 라운드 동안 반복된다.\n' +
      '\n' +
      '변압기를 이용한 언어 모델링 응용에서 가장 효과적인 것으로 나타난 내부 최적기와 외부 최적기는 각각 AdamW (Kingma and Ba, 2014)와 Nesterov momentum (Sutskever et al., 2013)이다. 경험적으로 이전 연구에서 \\(k\\)은 64, \\(H\\)은 천까지 설정되었다. FedOpt(Reddi et al., 2021)와 같은 다른 대안들은 이러한 프레임워크와 호환가능하다는 점에 유의한다.\n' +
      '\n' +
      '### DiPaCo\n' +
      '\n' +
      '하위 섹션 2.4에서는 데이터를 미리 공유하는 방법을 설명했으며 하위 섹션 2.5에서는 모델이 드물게 통신하는 여러 작업자에 걸쳐 훈련될 수 있는 방법을 설명했다. 이 섹션에서는 전문가의 혼합물로 수준이 대체되는 네트워크인 구성 가능한 혼합물의 효율적인 교육을 위한 이 두 가지 접근법을 결합한다. 우리는 이러한 아키텍처와 훈련 알고리즘 DiPaCo를 더빙한다. 아래 실험에서, 레벨은 여러 개의 연속적인 변압기 블록으로 구성된다.\n' +
      '\n' +
      '그림 4의 장난감 그림에는 \\(B_{1}\\), \\(B_{2}\\), \\(B_{3}\\)의 세 가지 수준이 있다. \\(B_{1}\\)에는 하나의 모듈(동등하게, 하나의 파라미터 세트)만 있으며 모든 경로에 걸쳐 공유됩니다. (B_{2}\\)에는 두 개의 모듈(그 수준에서 모듈에 대한 두 개의 별개의 매개변수 벡터가 있음을 의미함)이 있으며, 첫 번째 모듈은 경로\\(\\pi_{1}\\) 및 \\(\\pi_{2}\\)에 의해 공유되고 두 번째 모듈은 경로\\(\\pi_{3}\\) 및 \\(\\pi_{4}\\)에 의해 공유된다. 마찬가지로 세 번째 수준에서 \\(\\pi_{1}\\)과 \\(\\pi_{3}\\)은 매개변수를 공유하고 \\(\\pi_{2}\\)과 \\(\\pi_{4}\\)은 매개변수를 공유한다.\n' +
      '\n' +
      '결과적인 \\(2\\times 2\\) DiPaCo는 (도 4의 중간 패널에 도시된 바와 같이) 총 4개의 경로를 갖는다. 그러나 전체 모델은 교육이나 테스트 중에 완전히 인스턴스화될 필요가 없습니다. 경로만이 실현되고(도 4의 우측 패널에 도시된 바와 같이), 이들은 드문 통신과 병행하여 훈련된다.\n' +
      '\n' +
      '훈련 시간에 DiLoCo는 전체 네트워크와 대조적으로 모듈 수준에서 적용된다; 알고리즘 1의 라인 11-16을 참조한다. 외부 최적화기는 특정 모듈을 통과하는 경로를 처리하는 작업자로부터 대응하는 외부 구배를 받은 후 각 모듈의 파라미터를 독립적으로 업데이트한다. 예를 들어, 그림 4를 참조하면, 모듈 3b의 외부 구배는 작업자 처리 \\(\\pi_{2}\\) 및 \\(\\pi_{4}\\)의 모듈 3b의 구배를 평균하여 계산된다. 그런 다음 이러한 외부 구배는 모듈(3b)의 파라미터를 업데이트하는 데 사용된다. 작업자는 전체 모델을 호스트하기 위해 (메모리 및 계산 측면에서) 충분히 강력할 필요가 없으며 단일 경로일 뿐입니다. DiLoCo 작업(Douillard et al., 2023)에서와 같이, 내부 최적화기는 AdamW이고 외부 최적화기는 네스테로프 운동량이다. 유사하게, 테스트 시간에서, 경로는 인스턴스화되고, 라우터를 통해 각 경로로 라우팅되는 텍스트와 함께 독립적으로 서비스된다.\n' +
      '\n' +
      '#### Increasing Capacity\n' +
      '\n' +
      '경로가 모듈을 더 많이 통과할수록 경로에 걸친 전이 학습의 기회가 더 많아지지만, 또한 제한된 학습이 더 많고 전체 혼합이 가진 용량이 더 적다. DiPaCo는 이 절충점을 설정하는 방법에 많은 유연성을 제공한다. 레벨이 모든 경로에 의해 공유되는지 또는 특정 하위 집합에 의해서만 공유되는지 여부는 전체 프레임워크를 변경하지 않는다. 유일한 차이는 알고리즘 1의 13행에서 평균을 계산할 때 경로의 어떤 부분집합이 사용되는지 선택하는 것이다.\n' +
      '\n' +
      '한 가지 극단적인 선택은 그림 5와 같이 경로별 모듈을 할당하는 것이다. 이 경우 세 번째 레벨은 경로가 있는 만큼 많은 모듈과 혼합된다. 이것은 DiPaCo.1에서 파라미터 카운트를 증가시키는 특히 쉬운 방법이다.\n' +
      '\n' +
      '각주 1: 이러한 경로별 모듈에 대해 더 이상 기울기 평균이 없지만, 알고리즘 1의 외부 최적화는 기본 최적화기에 비해 수렴성을 경험적으로 향상시키기 때문에 여전히 적용한다.\n' +
      '\n' +
      '분명히, DiPaCo의 제안된 구조는 단지 첫 번째 단계에 불과하다. 우리는 특별히 그것을 고려한다.\n' +
      '\n' +
      '도 4: **DiPaCo**: (왼쪽) 데이터세트는 \\(k\\) 샤드, \\(\\mathcal{D}_{i}\\) (여기서 \\(k=4\\))로 사전 샤딩된다. (중간) 절대 인스턴스화되지 않는 \\(2\\times 2\\) DiPaCo의 컴팩트 뷰. 이 장난감 일러스트에는 세 가지 레벨이 있습니다. 레벨 2와 3은 각각 두 개의 모듈이 혼합된 형태이다. 레벨 1에는 모든 경로가 공유하는 단일 모듈이 있습니다. (오른쪽) 우리는 각 샤드 \\(\\mathcal{D}_{i}\\)을 _path_\\(\\pi_{i}\\), \\(\\forall i\\in[1,4]\\에 연관시킨다. 이 장난감 그림에서 경로는 세 개의 신경망 블록의 구성이다. 색상은 모듈의 ID를 나타냅니다. 그림은 4개의 경로에 걸쳐 풀린 모듈식 네트워크를 보여줍니다. 이들은 디로코(DiLoCo)를 사용하여 훈련되며, 디로코는 수백 단계마다 통신해야 한다. 이 예에서, 모듈 2a(빨간색)는 경로 \\(\\pi_{1}\\) 및 \\(\\pi_{2}\\)에 의해 공유된다. 경로와 관련된 작업자는 다른 하드웨어 유형(다른 종류의 GPU 또는 TPU)을 사용할 수 있으며 멀리 떨어진 지리적 영역에 배치될 수 있다.\n' +
      '\n' +
      '도 5: 더 많은 용량을 갖는 **DiPaCo: 이 예에서, 레벨 3 모듈은 경로 특이적이며, 즉, 그 레벨에서의 모듈은 경로에 의해 공유되지 않는다.**\n' +
      '\n' +
      '최적화 방법과 아키텍처를 공동 설계합니다. 다음 섹션에서는 설정을 위한 최적화 방법을 적용하기 위한 초기 접근법의 일부를 논의한다.\n' +
      '\n' +
      '모듈형 아키텍처의 스케일링\n' +
      '\n' +
      'DiPaCo는 여러 개의 전문가 모듈이 있는 여러 레벨로 만들어진다. _ e.g. a\\(16\\times 16\\)에는 두 개의 레벨이 있으며, 각 레벨에 16개의 모듈이 포함되어 총 256개의 경로로 생성된다. 레벨의 수와 레벨당 모듈의 수를 증가시켜 아키텍처의 크기를 쉽게 확장할 수 있으며, 32,768개의 경로를 갖는다. 그 수의 경로들에 대한 충분한 디바이스들을 찾는 것은 어렵고, 따라서 경로들의 서브세트만이 언제라도 트레이닝될 수 있다. 잠재적으로 내부 최적화의 각 시작에서 경로의 다른 부분 집합을 샘플링할 수 있다. 그렇게 하면 DiPaCo를 임의의 큰 크기로 확장할 수 있습니다.\n' +
      '\n' +
      '전문가의 평면혼합\n' +
      '\n' +
      '하위 섹션 2.6.1에서와 같은 극단적인 형태의 용량 증가는 각 경로가 완전히 독립적인 네트워크가 되도록 하는 것이다. 우리는 이 모델을 전문가(flat MoE)의 _flat_ 혼합물이라고 부를 것이다. 평평한 MoE 경로에서는 _any_ 파라미터를 공유하지 않는다. 하위 섹션 2.3의 언어에서는 한 단계만 있으며, \\(B=B_{1}\\)은 전체 네트워크이고 \\(K=K_{1}\\)은 전체 네트워크이다.\n' +
      '\n' +
      'Flat MoE는 DiPaCo의 구성 버전에 대한 강력한 기준선이다. 실험 결과, 전체 데이터 양의 크기에 비해 샤드 수가 적을 때 공유 모듈로 아키텍처를 능가할 수 있음을 알 수 있다.\n' +
      '\n' +
      '\\(k\\)-means를 사용한 생성적 라우팅의 경우, 이 접근법은 본질적으로 (Gross et al., 2017; Gururangan et al., 2023)이며, 아래의 실험에서 우리는 생성적 라우팅보다 일관되게 성능이 우수하기 때문에 구성 모델에서와 같은 차별적 라우팅을 사용할 것이다.\n' +
      '\n' +
      '최신 최적화 기술\n' +
      '\n' +
      '**outer Gradient Norm Rescaling:** DiPaCo에서 각 모듈은 서로 다른 개수의 경로에 속할 수 있다. 예를 들어, \\(16\\times 16\\) DiPaCo에서 16개의 경로는 단일 모듈에 기여할 수 있는 반면, 경로별 모듈은 다른 모듈이 공유하지 않는 수준이 있을 수 있다.\n' +
      '\n' +
      '결과적으로 알고리즘1의 평균 외부 구배 \\(\\Delta(l,e)^{t}\\)는 모듈마다 상당한 다른 규범을 가지고 있다. 직관과 경험적 관찰을 사용하여 더 많은 수의 경로에 대한 평균이 더 큰 배치 크기를 사용하는 것과 유사하다는 것을 사용하여 모듈을 통과하는 경로 수의 제곱근으로 외부 구배 규범을 다시 조정했다.\n' +
      '\n' +
      '손실 재평가: 일반적으로 파편에는 다른 양의 데이터가 있을 수 있습니다. DiPaCo의 훈련이 샤드/경로당 한 명의 작업자를 사용하여 분산되면 알고리즘1에서 라인 13의 균일한 평균에 따라 더 작은 샤드가 과도하게 샘플링된다. 기울기의 편향되지 않은 추정치를 계산하기 위해, 따라서 우리는 샤드 크기에 비례하여 외부 기울기의 무게를 잰다:\n' +
      '\n' +
      '\\[\\Delta_{l,e}^{(t)}\\leftarrow\\sum\\alpha_{l,e}(\\theta_{l,e}^{(t-1)}-\\theta_{l,e}^{(t)}), \\tag{2}\\\n' +
      '\n' +
      'with:\n' +
      '\n' +
      '\\[\\alpha_{l,e}=\\frac{|\\mathcal{D}_{l,e}|}{\\sum|\\mathcal{D}_{l^{\\prime},e^{\\prime}|}. \\tag{3}\\}\n' +
      '\n' +
      '**Early Stopping:** 각 샤드에 훈련 예제의 작은 부분 집합을 따로 둠으로써 경로 특정 조기 정지를 수행할 수 있다. 이 경우 각 경로에 대해 해당 샤드 유효성 검사 세트에서 가장 낮은 손실을 산출하는 매개변수를 선택했다. 우리는 조기 정지가 작은 파편, 예를 들어 파편의 수가 많을 때 일반화를 개선한다는 것을 발견했다.\n' +
      '\n' +
      '## 3 Infrastructure\n' +
      '\n' +
      '이제 앞에서 설명한 프레임워크를 구현하기 위해 설계한 인프라를 설명합니다. 인프라는 다음과 같은 목표를 달성해야 한다: 1) 빈번한 동기화를 통해 모듈식 아키텍처를 안정적으로 훈련하고, 2) 여러 포드 또는 데이터 센터에 걸친 훈련을 포함하는 시나리오에 대한 쉬운 확장성을 보장하며, 3) 지속적인 장애 허용을 제공하여 시스템의 모든 구성 요소가 교육을 중단하지 않고 실패한 호스트 및 선점으로부터 신속하게 복구할 수 있다.\n' +
      '\n' +
      '도 6의 상이한 컴포넌트들을 예시한다. 일반적인 트레이닝 워크플로우는 다음과 같다:\n' +
      '\n' +
      '1. 각 훈련 단계의 시작에서, 경로 및 샤드 id의 쌍을 각각 포함하는 훈련 작업의 목록이 (보라색으로) 작업 스케줄러 서버에 의해 유지되는 훈련 작업 큐에 추가된다.\n' +
      '2. 작업자 풀(오렌지색) 내의 트레이닝 작업자가 이용가능해지면, 그것은 열차 작업 스케줄러로부터 다음 트레이닝 작업을 인출하고 가속기들에 대해 내부 최적화(알고리즘1의 L5-9)를 수행한다. 내부 최적화가 완료되면 체크포인트는 구글의 분산 파일 시스템(Ghemawat et al., 2003)에 저장되고 훈련 작업자는 다음 훈련 작업에 사용할 수 있게 된다. 체크포인트에 대한 경로는 체크포인트의 메타데이터(예를 들어, 경로 ID, 외부 단계 ID 등)와 함께 데이터베이스 테이블(파란색으로 표시됨)에 기록된다. 이렇게 하면 다른 구성 요소가 지정된 경로에 대한 체크포인트 파일 경로를 조회할 수 있습니다.\n' +
      '3. 체크포인트가 트레이닝 작업자에 의해 저장되면(청록색으로 표시됨), 그 체크포인트에 대한 평가 태스크들이 평가 태스크 큐에 추가된다(노란색으로 강조됨). 평가 작업 큐는 평가 작업을 수행하기 위해 작업자 풀 내의 평가 작업자에 의해 소비된다.\n' +
      '4. 외부 최적화 태스크 스케줄러(연한 파란색으로 표시됨)는 외부 최적화 태스크들을 샤드된 외부 최적화 실행기들(빨간색으로 강조됨)에 분배하며, 이들 각각은 모듈들의 샤드(예를 들어, 단일 모듈 또는 모듈들의 컬렉션)의 외부 최적화를 담당한다. 각 실행기는 해당 모듈들이 포함된 트레이닝 체크포인트들을 Spanner 데이터베이스 테이블에 나타나자마자 로딩하고(Corbett et al., 2012), 파라미터 평균화 및 외부 최적화를 수행한다(L13-14). 업데이트된 모듈 파라미터의 체크포인트는 분산 파일 시스템에 저장되고, 메타데이터가 있는 경로는 데이터베이스 테이블에 기록된다.\n' +
      '5. 모든 훈련 작업의 완료 후, 현재 훈련 단계가 종료되고, 후속 훈련 단계가 시작되고 그들의 대응하는 모듈들이 외부 최적화 단계를 완료하는 즉시 새로운 단계에서의 훈련 작업이 시작될 수 있다. 자세한 내용은 3.3을 참조하십시오.\n' +
      '6. 트레이닝을 통해 작업 상태 모니터(그린)가 작업자와 작업 대기열 서버의 상태를 주기적으로 체크하고, 응답이 없으면 재시작한다.\n' +
      '\n' +
      '모든 구성 요소는 고장 및 선점에 견고하도록 설계되었습니다. 우리는 다음 하위 섹션에서 각 인프라 구성요소에 대한 자세한 내용을 논의할 것이다.\n' +
      '\n' +
      '### Worker Pool\n' +
      '\n' +
      '교육 작업을 배포하기 위해 생산자-소비자 디자인 패턴을 사용합니다. 각 단계 내에서, 트레이닝 태스크들은 태스크 큐에 추가되며, 이들 각각은 주어진 체크포인트로부터 특정 수의 단계들에 대한 경로를 트레이닝하는 것을 수반한다. 우리는 작업자 풀을 유지하는데, 여기서 각 작업자는 작업 대기열에서 훈련 작업을 반복적으로 검색한다. 각 훈련 작업은 다른 작업과 완전히 독립되어 작업자들 간의 동기화나 의사소통이 필요하지 않다.\n' +
      '\n' +
      '작업자 장애 또는 선점 시, 결함 허용 작업 대기열 서버는 다른 사용 가능한 작업자에게 재할당하기 전에 사용할 수 없는 작업자로부터 작업 대기열로 작업을 다시 반환합니다. 작업 큐 서버는 또한 주기적으로 현재 작업 큐를 체크하여, 서버 고장 또는 선구제로부터 복구하는 것을 가능하게 한다.\n' +
      '\n' +
      '이 설계의 핵심 장점은 근로자 간의 완전한 독립성 덕분에 근로자 풀이 비어 있지 않은 한 일부 근로자를 사용할 수 없게 되더라도 시스템이 계속 발전할 수 있다는 것이다. 워커 풀은 _different regions_에 걸쳐 _heterogeneous_ 타입의 디바이스들을 포함할 수 있어, 더 쉽게 스케일 업할 수 있다는 점에 주목할 필요가 있다. 또한, 작업자는\n' +
      '\n' +
      '도 6: **Infrastructure**. 내부 최적화를 수행하는 것을 담당하는 트레이닝 작업자들(주황색)이 트레이닝 작업 큐(보라색)로부터 트레이닝 작업을 인출한다. 일단 트레이닝 체크포인트들이 GFS에 저장되면, 그들의 경로들 및 메타데이터들(예를 들어, 트레이닝 단계, 경로 ID, 위상 ID)은 메타데이터가 주어진 체크포인트 경로를 쉽게 조회할 수 있도록 (파란색으로) 스패너 테이블에 기록된다. 평가 작업자와 샤드된 외부 최적화 실행자(빨간색) 부하 훈련 체크포인트는 일단 준비되면 스패너 테이블에서 나타나는 것으로 시그널링됩니다. 마지막으로 모니터링 작업자(그린)가 주기적으로 작업자의 건강을 체크하고 필요한 경우 재부팅한다.\n' +
      '\n' +
      '풀은 자원 가용성에 따라 풀 크기를 자동 스케일링하여 탄력적인 자원 활용을 가능하게 한다.\n' +
      '\n' +
      '### 작업 대기열 시스템\n' +
      '\n' +
      '실제로, 전술한 태스크 큐 시스템은 원격 프로시저 호출을 사용하여 작업자 풀 내의 작업자 간에 비동기적인 태스크를 관리 및 분배하도록 설계된다. 작업 큐 스케줄러, 작업 큐 서버, 작업 큐 클라이언트의 세 가지 구성 요소로 구성된다. 트레이닝 태스크들은 태스크 큐 스케줄러에 의해 게시되고 태스크 큐 서버로 전송되는 한편, 각각의 워커는 태스크 큐 클라이언트에게 태스크 큐로부터 태스크들을 요청하도록 인스턴스화한다.\n' +
      '\n' +
      '다중 호스트 훈련 시나리오에서, 다중 호스트 병렬성이 단일 프로그램, 다중 데이터(SPMD)에 의해 달성되는 경우, 각 호스트 상의 태스크 큐 클라이언트를 초기화하는 것은 각 호스트가 태스크 큐로부터 상이한 태스크를 끌어당기는 결과를 초래할 것이다. 우리는 모든 호스트에서 결과를 동기화하는 작업 대기열 클라이언트를 구현하여 이 문제를 해결한다. 이것은 첫 번째 JAX 호스트에서만 실제 작업 대기열 클라이언트를 생성함으로써 달성된다. 다른 모든 호스트는 전체 집합 차단 작업을 수행하여 첫 번째 호스트에서 응답을 가져옵니다.\n' +
      '\n' +
      '우리는 또한 일부 장소에서 메인 파이썬 스레드 외부의 작업 큐 쓰기 작업을 동기화해야 한다. 예를 들어, 주어진 체크포인트에 대한 평가 작업은 모든 호스트에서 체크포인트가 완료된 후에만 종료될 수 있습니다. 이 사용 사례를 위해 호스트에서 실행되는 각 프로그램이 동일한 고유 키로 호출할 때까지 차단하는 장벽을 구현했다.\n' +
      '\n' +
      '#외부 최적화 효율성\n' +
      '\n' +
      '외부 최적화 실행기의 순진한 구현은 우리가 전 세계의 경로 수를 확장함에 따라 상당한 오버헤드를 도입한다. 다음 최적화를 통해 외부 업데이트에 대해 2분(알고리즘 1의 라인 11-16) 이하로 위상당 평균 시간을 갖는 수백 개의 경로로 확장할 수 있다.\n' +
      '\n' +
      '온라인 파라미터 기울기 평균화: 페이즈 내의 트레이닝 태스크들이 동시에 완료되지 않을 수 있기 때문에, 트레이닝 체크포인트를 이용가능하게 되는 즉시 현재의 부분 합으로 로딩 및 누적함으로써 파라미터 평균화 시간을 감소시킬 수 있다. 또한, 외부 업데이트를 수행하기 전에 모든 경로를 기다릴 필요가 없는 비동기 업데이트까지 확장할 수 있다(Liu et al., 2024).\n' +
      '\n' +
      '샤딩된 외부 최적화 실행기: 모델 아키텍처가 모듈식이기 때문에 서로 다른 모듈의 평균 메타 구배를 독립적으로 수행할 수 있다. 파라미터 평균화를 그림 7과 같이 여러 서버에 분산함으로써 각 평균화 작업의 메모리 요구 사항과 체크포인트 로딩 및 평균화의 오버헤드를 줄인다. 또한, 해당 모듈이 외부 업데이트를 완료하는 즉시 훈련 작업을 시작할 수 있으므로 훈련 시간을 단축할 수 있다. 결과적으로 전체 모델은 단일 위치에서 구현되지 않지만 항상 여러 서버에 걸쳐 분할됩니다.\n' +
      '\n' +
      '비동기 검사점 수집: 각 외부 최적화 실행자는 관련 모듈을 공유하는 경로의 수만큼 검사점을 로드합니다. 분산 파일 시스템으로부터 지구상의 어느 곳에서나 체크포인트를 로드할 수 있다(Ghemawat et al., 2003). 그러나, 훈련이 이루어진 서버에 위치한 체크포인트가 외부 최적화 실행기와 일정 거리에 있으면 상당한 지연이 발생할 것이다. 이 경우 우리는 체크포인트를 더 가까운 위치에 가져오기 위해 에핑고 프로세스(구글, 2023)를 백그라운드에서 시작한다.\n' +
      '\n' +
      '도 7: **샤딩된 외부 최적화 실행기**: 모듈에 의해 샤딩된 외부 최적화 실행기의 예시로서, 이는 처리 시간 및 메모리 요구량을 상당히 감소시킨다.\n' +
      '\n' +
      '잡종 개선: 기존의 속도 개선 외에도 a) 외부 최적화기 OuterOpt의 파라미터를 캐시하고, b) Just-in-time 컴파일된 최적화기를 재사용하며, c) 다중 쓰레딩 큐를 통해 여러 경로를 병렬로 로드한다.\n' +
      '\n' +
      '### Backup Pool\n' +
      '\n' +
      '기본적으로 우리는 데이터의 경로/샤드, \\(\\forall i\\in[1,P]\\)만큼 많은 훈련 인력(그림 6의 오렌지 참조)을 생성한다. 그러나 경로 수를 확장하면 하드웨어 요구 사항이 엄청나게 증가할 수 있습니다. 예를 들어, 작업자당 256개의 경로와 16개의 A100 GPU를 사용하면 4개의 096 GPU가 필요합니다. 따라서, 실제로 작업자들의 수는 종종 경로의 수보다 적으며, 대신에 모든 경로가 트레이닝될 때까지 외부 반복 단계 내에서 트레이닝의 다중 _rounds_를 수행한다(알고리즘 1의 L3-10).\n' +
      '\n' +
      '라운드 수를 최소화하고 속도를 최대화하기 위해 훈련 인력 백업 풀을 만듭니다. 즉, 낮은 단계의 우선 순위를 사용하여 여러 가속기 유형에 걸쳐 경로가 있는 만큼 많은 작업자를 낳습니다. 가속기를 사용할 수 있는 즉시 이를 낚아채 내부 최적화 단계에 사용합니다. 계층 우선순위가 낮은 장치가 자주 선점되지만, 각 훈련 작업은 대략 몇 분밖에 걸리지 않기 때문에 백업 풀의 이점을 얻을 수 있다(알고리즘 1의 내부 최적화 L5-9).\n' +
      '\n' +
      '이 백업 풀은 하위 하위 섹션 2.6.2에서 언급한 경로 샘플링 아이디어와 함께 사용할 때 특히 유용합니다.\n' +
      '\n' +
      '## 4 Experiments\n' +
      '\n' +
      '본 논문에서는 Common Crawl(Raffel et al., 2020)에서 파생된 C4 데이터셋에서 어휘 크기가 32,000인 SentencePiece tokenizer(Kudo and Richardson, 2018)로 토큰화된 언어 모델링 작업을 고려한다. 모든 계산이 동일한 가속기 유형에서 수행되는 경우 벽-시계 시간에 대한 가까운 프록시인 훈련 시간에 사용되는 가중치 업데이트 단계 수에 대해 검증 세트에 대한 복잡성을 보고한다. 총 가중치 갱신 단계 수는 88,000개로 설정되었으며, DiPaCo 상의 모든 경로는 12개의 블록, 896차원 은닉 상태 및 16개의 헤드를 갖는 변압기를 사용하여 1억 5,000만 개의 파라미터를 갖는다.\n' +
      '\n' +
      '우리는 다양한 경로 수와 다양한 모듈 재사용 수준의 모듈식 네트워크를 구축한다. 본 논문에서는 24개의 블록, 2048차원 은닉 상태, 동일한 헤드의 수를 갖는 1.3B 크기의 고밀도 트랜스포머 언어 모델과 하나의 DiPaCo 경로의 크기인 고밀도 모델의 성능을 비교한다. 이 모델들은 또한 88,000개의 가중치 업데이트 단계를 위해 훈련된다.\n' +
      '\n' +
      '우리는 DiPaCo에 대한 가중치 업데이트가 더 많은 토큰을 보고 경로 수가 더 많을 때 더 많은 FLOP를 사용하기 때문에 이 비교가 문헌에서 _not_ 표준이라고 독자에게 경고한다. 그럼에도 불구하고, 우리의 모듈식 네트워크는 수백 개의 경로로 만들어지지만, 모두 병렬로 훈련되므로, 우리의 훈련 벽시계 시간은 1.3B 밀집 대응물보다 45% 적으며, 대략 150M 파라미터 단일 경로 대응물과 동등하다.\n' +
      '\n' +
      '실험에서 우리는 주로 학습 속도와 네스테로프 운동량의 값이라는 비교적 적은 하이퍼 매개 변수에 대해 검색했다. 시퀀스 길이 1,024 토큰과 배치 크기 512를 사용하며, 평가 시간에는 2,048 토큰의 시퀀스를 고려한다. 우리는 0.0004의 피크 값을 갖는 코사인 학습률 스케줄링을 사용하며, 부록(하위 섹션 7.1)에 모든 하이퍼-파라미터를 나열한다.\n' +
      '\n' +
      'DiPaCo의 모든 인스턴스는 판별 라우팅의 한 단계(2.4.2 및 7.2.1 참조)를 사용한다. (16\\times 16=256\\) 경로 DiPaCo는 훈련 시간에 top-2 겹침 샤드(2.4.4)를 사용한다(이는 비록 샤드의 크기를 증가시키지만, 벽시계나 FLOP에서 훈련을 느리게 하지 않는다).\n' +
      '\n' +
      '1B 밀집 모델과의### 비교\n' +
      '\n' +
      '그림 8은 1.3B 밀집 언어 모델의 수렴 곡선을 \\(16\\times 16\\) DiPaCo와 비교한다. 150M 크기의 256개의 경로가 부분적으로 파라미터를 공유하고 문서당 하나의 라우팅 결정을 갖는 DiPaCo는 크기 1.3B의 조밀한 모델의 성능과 거의 일치하기에 충분하다. 조밀한 1.3B 모델과의 나머지 성능 격차는 테스트 시간에서 64개의 토큰마다 조기 정지 및 라우팅으로 종료될 수 있다.\n' +
      '\n' +
      '우리는 다시 독자에게 그림 8의 \\(x\\) 축이 다른 모델에 대해 FLOP 등가물이 아니라고 경고한다. 150M 기준선 모델과 DiPaCo의 경우 \\(x\\) 축은 대략 동등한 벽-클록에 해당하며(1.3B 모델은 동일한 업데이트 수에 대해 더 느린 w.r.t. 벽-클록이다). 반면에 DiPaCo는 더 많은 FLOP를 사용하고 조밀한 베이스라인보다 훈련 단계당 더 많은 토큰을 본다. 그러나 조밀한 모델의 훈련을 DiPaCo의 척도로 병렬화하는 것은 사소한 일이 아니며, 하위 섹션 4.3 및 특히 표 1, (Douillard et al., 2023)에서 비교를 참조한다.\n' +
      '\n' +
      '###경로 및 파라미터의 수\n' +
      '\n' +
      '그림 9는 더 많은 경로와 더 많은 전체 매개변수가 혼합물에 추가됨에 따라 일반화가 개선됨을 보여준다. DiLoCo의 오버헤드는 최소이므로 x축은 벽시계 시간으로 대체될 수 있다. 물론, \\(16\\times 16\\) DiPaCo는 \\(2\\times 4\\) DiPaCo보다 32배 더 많은 계산량을 요구하지만, 이러한 추가 경로들은 거의 통신하지 않고 병렬로 훈련될 수 있다. 이 실험에서 내부 최적화는 \\(\\tau=150\\) 단계로 구성된다. _경로-특정 모듈_를 사용한 모든 실험에 대해, 트랜스포머 블록 0, 5, 6 11 및 임베딩 매트릭스는 경로에 걸쳐 통신되지 않는다.\n' +
      '\n' +
      '###경로간 파라미터 공유\n' +
      '\n' +
      '서브섹션 2.6.3에 설명된 바와 같이 스펙트럼의 한쪽 끝에서 매개변수를 공유하지 않고 완전히 독립적으로 훈련될 수 있는 경로를 사용한다. 매개 변수가 추가됨에 따라 검증 성능이 단조로 개선되는 하위 섹션 4.2의 추세를 계속하면 적은 수의 경로에 대해 모든 매개변수를 공유하지 않음으로써 개선 사항을 볼 수 있다. 64개의 공유되지 않은 경로를 사용하여 공유되지 않는 \\(16\\times 16\\) DiPaCo에 접근할 수 있다.\n' +
      '\n' +
      '그러나 이 모델은 표 2와 같이 샤드(및 해당 전문가)의 수를 더 늘리면 과적합이 시작되며, 샤드를 겹쳐서 일부 성능을 복구할 수 있지만 완전히 독립적인 경로의 수를 순진하게 확장할 수 없다는 것을 발견했다. 우리는 파편의 보다 정교한 중첩과 경로 분기를 위한 접근법이 향후 작업에 유망한 방향이라고 생각한다.\n' +
      '\n' +
      '스펙트럼의 다른 끝에서, 경로들은 모든 파라미터들을 공유할 수 있고, 효과적으로 단일 경로로 다시 붕괴되고 원래의 DiLoCo(Douillard et al., 2023)의 성능을 회복할 수 있다. 우리는 DiLoCo로 훈련된 베이스 모델, 또는 많은 단계들에 대해 오버 트레이닝된 베이스 모델을 볼 수 있다,\n' +
      '\n' +
      '도 8: **DiPaCo vs Dense Baseline**의 수렴 곡선들: 우리는 먼저 24k 트레이닝 단계들(보라색)에 대해 150M 파라미터 모델들을 사전 트레이닝한다. 그런 다음 16x16 DiPaCo\\(P=256\\)(적색)을 미세 조정한다. 조밀한 1.3B 매개변수 기준선(주황색)에 대한 나머지 간격은 테스트 시간에 더 자주 게이팅함으로써 도달한다.\n' +
      '\n' +
      '그림 9: DiPaCo**에서 경로의 **스케일링 수: 경로 및 매개변수의 수가 다른 DiPaCo의 검증 복잡성을 보고한다. 경로 수를 8개에서 256개로 변경하고 경로별 모듈을 사용하여 용량을 늘립니다. 경로 크기(배치 중 서빙 비용과 대략 동등함)는 이 그림의 모든 모델에 대해 150M 매개변수이다.\n' +
      '\n' +
      '더 큰 DiPaCo 모델과 동일한 수의 FLOP 및 토큰을 수신하더라도 이러한 추가 FLOP를 사용할 수 있는 용량은 없다. 물론 적절한 크기의 기준선이 훨씬 더 잘 될 것이다; 그리고 실제로 위의 1.3B 모델은 이미 더 나은 당혹감을 가지고 있다. 그러나 DiPaCo는 열차 및 테스트에서 각각 150M 크기의 섬만을 필요로 하는 경로로 구성되며, 분산 학습 알고리즘은 아키텍처에 내장되어 있어, 모든 훈련 또는 배치 작업자에게 150M 매개 변수의 경로만 구현해야 한다. 표 1에서 이러한 모든 변형을 비교한다.\n' +
      '\n' +
      '### 평가 시 라우팅 빈도\n' +
      '\n' +
      '표 3의 테스트 시간에서 라우팅의 결과를 더 자주 보여주며, 1,024개의 토큰 시퀀스당 한 번 라우팅에서 128개의 토큰마다 0.74개의 복잡점이 크게 개선되는 것을 관찰한다. 재라우팅의 세분성을 추가로 증가시키면 결과가 일관되게 개선되지만 약간 더 개선된다. 이를 통해 학습 시간에는 시퀀스 레벨에서 라우팅하여 보다 효율적인 학습을 위해 사전 샤딩을 가능하게 하고, 평가 시간에는 더 자주 라우팅하여 성능을 향상시킬 수 있음을 알 수 있다. 토큰을 잠재적으로 64개의 토큰마다 다른 경로로 라우팅함으로써 DiPaCo는 11.38 퍼플렉시티에 도달하여 1B 밀집 모델(11.41)의 성능과 일치한다. 임의의 시간에서 DiPaCo는 크기 150M 파라미터들의 단일 경로를 사용하기 때문에, 6배 더 적은 파라미터들을 사용하는 1B 모델의 성능과 매칭되며, 따라서 추론 시간에서 덜 계산이 요구된다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c} \\hline \\hline Model & Time & Compute and Data & Total Parameters & Validation PPL \\\\ \\hline Baseline & 1\\(\\times\\) & 1\\(\\times\\) & 150M & 16.23 \\\\ \\hline DiLoCo \\(P=8\\) & 1\\(\\times\\) & 8\\(\\times\\) & 150M & 15.02 \\\\ DiLoCo \\(P=64\\) & 1\\(\\times\\) & 64\\(\\times\\) & 150M & 14.96 \\\\ \\hline Flat MoE \\(P=8\\) & 1\\(\\times\\) & 8\\(\\times\\) & 1.2B & 14.62 \\\\ Flat MoE \\(P=64\\) & 1\\(\\times\\) & 64\\(\\times\\) & 9.6B & 12.76 \\\\ \\hline DiPaCo \\(2\\times 4\\) & 1\\(\\times\\) & 8\\(\\times\\) & 0.5B & 14.86 \\\\ DiPaCo \\(8\\times 8\\) & 1\\(\\times\\) & 64\\(\\times\\) & 1.2B & 13.37 \\\\ DiPaCo \\(8\\times 8\\)+ Path Specific Modules & 1\\(\\times\\) & 64\\(\\times\\) & 5.3B & **12.70** \\\\ \\hline \\hline Baseline, 8\\(\\times\\) steps & 8\\(\\times\\) & 8\\(\\times\\) & 150M & 14.72 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: **DiPaCo vs. Flat MoE vs. DiLoCo:** DiLoCo와 Flat MoE(2.6.3)를 비교한다. 디파코 또한 분산 모델과 동일한 FLOP에 대해 훈련된 기준선과 비교한다. DiLoCo에서는 각 외부 최적화 단계에서 모든 경로가 함께 축소됩니다. 플랫 MoE에서는 모든 경로가 독립적입니다. DiPaCo에서, 파라미터들의 서브세트만이 경로들의 서브세트로부터의 정보를 사용하여 "붕괴"된다. 분산된 프레임워크 때문에 DiPaCo는 기준선의 대략 벽시계인 DiLoCo와 동일한 벽시계 시간으로 훈련된다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c} \\hline \\hline \\# fully independent paths & Validation PPL \\\\ \\hline \\(p=8\\) & 14.6 \\\\ \\(p=16\\) & 13.9 \\\\ \\(p=256\\) & 14.2 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 경로 수에 따른 **플랫 MoE(독립 경로) 오버피트 증가**: 10K 단계의 훈련 후 하위 섹션 2.6.3에 설명된 대로 공유 모듈이 없는 DiPaCo의 검증 복잡성. 하위 섹션 2.4.4에서 설명한 바와 같이 샤드가 겹치고 조기 정지하면 \\(P=256\\) 결과를 13.6으로 개선할 수 있지만 여전히 256개의 경로를 가진 64K 단계에서 모델이 오버핏된다. 이와는 대조적으로, \\(16\\times 16\\) DiPaCo를 갖는 파편이 겹치는 256개의 경로에서는 오버피팅이 없다.\n' +
      '\n' +
      '### DiLoCo 대 DiLoCo와의 파라미터 동기화. 진정한 기울기\n' +
      '\n' +
      '마지막으로 부분 동기 최적화 DiLoCo를 사용하여 훈련 시간에 덜 자주 통신하여 성능을 상실하는지 여부를 이해하는 효과를 완화한다. 모든 디바이스들이 실제로 콜케이팅되고 통신 측면에서 제약이 없는 설정에서, 우리는 DiLoCo를 사용하지 않고 완전 동기 방식으로 DiPaCo 모델을 트레이닝할 수 있다: 모든 단계에서, 각각의 경로는 자신의 데이터 샤드로부터 데이터**의 **its 자신의 배치에 대한 그라디언트들을 계산한다; 모든 경로들에 걸친 그라디언트들은 모듈별로 교환되고 집성되며; 마지막으로, 모델은 집성된 그라디언트로 AdamW 업데이트의 한 단계를 수행한다. 놀랍게도, 우리는 완전 동기 훈련 설정과 부분 동기 훈련 설정 사이의 상당한 성능 격차를 관찰하지 못했다. 보다 구체적으로, DiLoCo로 훈련된 DiPaCo는 \\(2\\times 2\\) 및 \\(4\\times 4\\) 아키텍처를 사용할 때 각각 0.3 및 0.6 퍼플렉시티 포인트만큼 완전 동기화 훈련된 버전을 약간 능가한다. 동시적으로 훈련된 \\(8\\times 8\\) DiPaCo에서 100배 더 많은 통신에도 불구하고 0.1 퍼플렉시티에 의해서만 더 나은 퍼플렉시티에 도달한다. 이는 DiLoCo가 DiPaCo에 효과적인 분산 최적화 알고리즘임을 시사한다.\n' +
      '\n' +
      '## 5 관련 업무\n' +
      '\n' +
      '서론에서 언급한 바와 같이 이 작품은 Pathways(총장, 2021)에 표현된 동기와 직관을 동일하게 공유하고 있다. 일반적인 모듈형 멀티모달 멀티태스크 비동기 시스템의 트레이닝을 지원하는 Pathways 프레임워크(Barham et al., 2022)와 달리, 우리는 이러한 종류의 분산 트레이닝을 지원하는 모듈형 시스템의 특정 인스턴스화를 제안한다. 우리의 접근법은 또한 Borzunov et al.(2022); Ryabinin and Gusev (2020)와 동기 및 직관을 공유한다. 이 작업의 핵심 차이점은 각 작업자가 모듈이 아닌 모듈을 통해 _path_를 훈련한다는 것이다.\n' +
      '\n' +
      '### Modularity\n' +
      '\n' +
      '모듈성에 대한 많은 문헌이 있지만, 이것이 항상 그러한 용어로 구성된 것은 아니다. 스펙트럼의 한쪽 끝에는 매우 많은 수의 매우 작은 모듈을 사용하는 접근법이 있다. 예를 들어, RETRO(Borgeaud et al., 2021)는 하나의 그러한 접근법이며, 이에 의해 큰 검색 데이터세트의 토큰 n-그램당 하나의 모듈이 존재하고, 모듈은 단지 바이어스의 벡터일 뿐이다. 스펙트럼의 다른 쪽 끝에는 매우 적지만(예를 들어, 2개) 매우 큰 모듈을 사용하는 접근법이 있다. 예를 들어, 플라밍고(Alayrac et al., 2022)는 미리 학습된 비주얼 인코더와 미리 학습된 언어 모델의 두 개의 주요 모듈로 구성된 비전 언어 모델이다. 유사하게, Dalmia et al.(2023)은 모듈이 사전 훈련된 언어 모델 및 음성 인식 인코더인 다른 접근법을 제안했다. 저자들은 이러한 모듈이 어떻게 다른 언어로 번역되는 음성 인식기를 생성하는 것과 같은 완전히 새로운 작업의 0-샷 학습을 가능하게 하기 위해 다른 방식으로 플러그될 수 있는지를 보여주었다.\n' +
      '\n' +
      '이러한 작업 라인은 모듈성에 대한 대부분의 문헌을 대표한다. 그러나 모듈의 수와 크기가 중간인 작업도 있다. 예를 들어, Purushwalkam 등(2019)은 구성 작업을 처리하기 위해 시각적 질문 응답에서 얼마나 부드럽게 게이팅된 모듈이 사용될 수 있는지를 보여주었다. 다중-작업 교차-언어 전달에서, Pfeiffer et al.(2020)은 모듈이 매우 작은 어댑터인 네트워크를 대신 사용했으며, 대부분의 모듈은\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c|c} \\hline \\hline Early Stopping & Route Every & Perplexity \\\\ \\hline \\(\\mathcal{X}\\) & Once per sequence & \\(12.39\\) \\\\ ✓ & Once per sequence & \\(12.22\\) \\\\ \\hline \\multirow{4}{*}{✓} & \\(128\\) & \\(11.48\\) \\\\  & \\(\\mathbf{64}\\) & \\(\\mathbf{11.38}\\) \\\\ \\cline{1-1}  & \\(32\\) & \\(11.31\\) \\\\ \\cline{1-1}  & \\(16\\) & \\(11.26\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: **Frequent Routing at Eval-Time**: Validation perplexity with a \\(P=256\\)DiPaCo. 크기 150M(\\(>6\\times\\) 더 적은 파라미터)의 경로를 사용함에도 불구하고, 비록 모델이 이전에 선택한 경로와 정확히 동일한 경로로 경로를 선택할 수 있지만, 잠재적으로 64개의 토큰마다 다른 경로로 경로를 재설정함으로써 조밀한 1B 모델(11.41)의 성능을 일치시킨다.\n' +
      '\n' +
      '매개변수는 경로에 걸쳐 공유됩니다. 우리는 독자를 Pfeiffer et al.(2023)의 추가 포인터에 대한 조사를 참조하고, 다음으로 혼합물 모델을 통한 모듈성에 초점을 맞춘다.\n' +
      '\n' +
      '###전문가들의 혼합\n' +
      '\n' +
      '앙상블링 및 부스팅과 함께, 전문가들(MoE)의 혼합물은 기계 학습 문헌에서 모듈성에 대한 초기 접근법이다(Jacobs et al., 1991; Jordan and Jacobs, 1994). 앙상블링과 달리 몇 명의 전문가만 입력을 처리하는 경우 혼합물 모델이 더 효율적일 수 있다. 부스팅과는 달리, 혼합 모델의 트레이닝은 병렬화될 수 있는 반면, 프로세스를 부스팅하는 데 있어서 본질적으로 순차적이기 때문에 효율적이다.\n' +
      '\n' +
      '초기 작업은 평평한 혼합물(조던과 제이콥스, 1994)의 계층적 게이팅 문제를 고려했지만 여러 수준의 혼합물은 최근에야 나타났다. 예를 들어, 아이겐 등(2014)은 경로가 부드럽게 혼합되고 확률적 경사 하강을 통해 공동으로 훈련되는 2-레벨 혼합물을 제안했다. 그 논문에서 저자들은 비퇴화 라우팅 함수 학습의 어려움을 인식하고 몇 가지 해결 방안을 논의했다. 좋은 라우팅 기능을 어떻게 배울 것인가에 대한 문제는 이후 해당 분야의 주요 연구 주제였다.\n' +
      '\n' +
      '그들의 중요한 작업에서 Shazeer et al.(2017)은 시퀀스 모델링 작업을 위한 전문가 LSTM 모델의 매우 큰 혼합을 제안했다. 후속하는 시퀀스 모델링 작업을 위한 대부분의 작업 MoE(Artetxe et al., 2021; Clark et al., 2022; Fedus et al., 2021; Lepikhin et al., 2021)는 변압기의 FFN 층이 혼합물로 대체되는 레시피를 사용하였다. 이러한 MoE들은 토큰 레벨에서 동작하고, 트레이닝은 조밀한 모델 트레이닝과 유사하게 동작한다: 모든 경로들은 모든 구배 하강 단계에서 동기화된다. 토큰-MoE는 트레이닝 FLOP 효율과 관련하여 현재 최첨단이지만, 트레이닝을 위해 등가-활성화된 밀집 모델보다 훨씬 더 많은 공동-위치 가속기를 필요로 한다.\n' +
      '\n' +
      '이와는 대조적으로, (Gururangan et al., 2023)은 문서 레벨 라우터를 이용하여 전문가들을 독립적으로 훈련시킨다; 이 접근법은 Gross et al.(2017)에 의해 컴퓨터 비전에 사용되었고, 연합 학습 문헌(Reisser et al., 2021)에도 나타났다. 우리의 플랫 MoE 베이스라인은 (Gururangan et al., 2023)의 접근법과 밀접한 관련이 있는데, \\(k\\)-Means와 달리 판별 라우터를 사용했고, tf-idf 벡터의 SVD와 달리 문서의 처음 32개의 토큰(및 베이스 트랜스포머 LM으로부터의 특징)을 라우터에 대한 입력으로 사용했다.\n' +
      '\n' +
      '마지막으로, 모델을 병렬로 훈련시키기 위해 도메인별로 데이터를 반복적으로 샤드하고, 이어서 모델 병합 단계가 뒤따르는 아이디어가 Li 등에 의해 제안되었다(2022). 이 작업에서 우리는 전문가 모델의 혼합물을 학습하고 데이터를 자동으로(그리고 심지어 차별적으로) 공유함으로써 이 접근법을 한 단계 더 취한다.\n' +
      '\n' +
      '## 6 Limitations\n' +
      '\n' +
      'DiPaCo에 대한 가장 두드러진 제한은 FLOP 효율과 관련이 있다. 이 작업에서 우리는 FLOP 효율성을 최적화하려는 노력을 기울이지 않았으며 제시된 결과에서 DiPaCo는 표준 조밀한 계산 최적 모델보다 평가 당 FLOP 효율성이 현저히 낮다.\n' +
      '\n' +
      '이 작업은 또한 DiPaCo의 스케일링 법칙을 연구하지 않는다. 단일 경로 크기 축척과 하나의 데이터 세트에서 작업합니다.\n' +
      '\n' +
      '우리는 또한 DiPaCo의 배치를 최적화하기 위해 이 작업에 노력을 기울이지 않았다. 특히, 섹션 (2.4.3)과 같이 배치 중에 순진하게 더 자주 경로를 지정하려면 각 경로 변경 후 각 쿼리에 대한 \\(K\\)V-캐시를 다시 계산해야 한다.\n' +
      '\n' +
      '이러한 제한의 심각성은 훈련 및 배치 인프라의 제약뿐만 아니라 당면한 작업에 달려 있다. 예를 들어, 컴퓨팅 인프라는 시퀀스가 대부분 하나의(또는 매우 적은) 도메인에 연관될 수 있는 작업을 위해 수백 개의 작고 잘 연결되지 않은 장치 섬으로 구성될 때 덜 중요할 수 있다. 일반적으로 이러한 한계를 해결하는 것은 향후 연구의 길을 구성한다.\n' +
      '\n' +
      '##7 결론 및 향후 작업\n' +
      '\n' +
      '본 연구에서는 모듈들의 결합으로서 ML 모델을 설계하고, 이러한 모듈들을 통한 경로로서 입출력 매핑을 정의한다. 우리는 경로를 (거의) 독립적으로 훈련할 수 있고 (사실상) 이러한 경로를 원하는 큰 모델로 다시 재조합할 수 있음을 보여준다. 특히, 경로별 분산 훈련은 유사한 벽시계 시간 동안 1B 밀집 언어 모델의 성능과 일치할 수 있음을 보였다.\n' +
      '\n' +
      '알고리즘과 아키텍처의 설계는 실질적인 절충에 의해 안내된다. 우리의 작업에서 우리는 통신이 비용이 많이 들지만 계산은 그렇지 않다고 가정한다. 즉, 가장 많이 카운트하는 계산은 경로를 호스트하는 공동 위치 장치 중 하나이다. 이러한 비교적 작은 장치의 섬들 사이의 통신이 제한된 한, 우리는 많은 수의 섬들에 걸쳐 계산을 분배함으로써 규모를 조정할 수 있다.\n' +
      '\n' +
      '이러한 제약 조건 하에서 동작하기 위한 두 가지 핵심 요소를 도입하였다: 1) 시퀀스 레벨에서 거칠게 라우팅하고 경로별로 사전 샤드 데이터를 생성하고, 2) 다중 경로에서 공유되는 모듈의 파라미터를 업데이트하기 위해 DiLoCo를 확장한다. 우리는 이 두 가지 아이디어를 결합함으로써 대형 모델을 훈련시키기 위해 잠재적으로 훨씬 더 확장 가능한 패러다임으로 나아갔다고 믿는다.\n' +
      '\n' +
      '미래의 작업에는 몇 가지 방법이 있다. 우리의 조사에서 우리는 벽 시계 효율에 초점을 맞추어 DiPaCo의 FLOP 효율을 제어하려는 노력을 기울이지 않았다. 당연히 FLOP 효율성을 높일 수 있는 몇 가지 간단한 설계 선택이 있으며, 예를 들어 일부 경로가 공동 위치를 찾을 수 있다. 또한 샤딩에 대한 우리의 접근 방식은 상당히 단순하며 보다 정교한 샤딩에 대한 흥미로운 가능성이 많이 있다. DiPaCo는 지속적인 학습을 염두에 두고 설계되었으며, 우리는 결국 그 설정에 적용하고자 한다. 마지막으로, 확실히 중요한 것은, 스케일업이 가장 흥미롭다는 것이다. 딘(2021); 라펠(2023)과 공유된 우리의 장기적인 꿈은 이 접근법을 더욱 구체화하고 모든 사람이 기존 모듈로부터 새로운 예측 변수를 구성하기 위해 사용할 수 있는 끝없는 커뮤니티 중심의 모듈식 학습 시스템을 생성하여 긍정적인 피드백 루프에서 완전히 새로운 모델과 능력을 효율적으로 개발하는 것이다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Alayrac et al. (2022) J.-B. Alayrac, J. Donahue, P. Luc, A. Miech, I. Barr, Y. 하손기 Lenc, A. Mensch, K 밀리컨, M. 레이놀즈, R 링, E. 러더포드, S. 카비태 한진 공성호 사만귀에 몬테이로, J. 메닉, S. Borgeaud, A. Brock, A. Nematzadeh, S. 샤리프자데 빈코스키, R 바레이라, 오 빈얼스, A. 지서먼, K. 사이먼 플라밍고: 몇 개의 샷 학습을 위한 시각적 언어 모델. 2022년 _NeurIPS_에서.\n' +
      '* Anil et al.(2022) R. 안성일 보르지우 우종범 알라락, J. Yu, R. Soricut, J. Schalkwyk, A. M. Dai, A. Hauth, K. 밀리칸, D. 실버, S. 페트로프 Johnson, I. Antonoglou, J. Schrittwieser, A. Glaese, J. Chen, E. Pitler, T. Lillicrap A. Lazaridou, O. 피라트, J 몰로이, M. 이사드, P. R. 바함, T. Hennigan, B. Lee, F. Viola, M. 레이놀즈 서록 도허티, E 콜린스, C. 마이어, E. 러더포드, E. 모레이라, K. 아엽만 고엘, 지 터커, E. 피케라스, M. 크리쿤인바 사비노프, I. 대니헬카, B. 로엘로프, A. 화이트, A. 안드레아센, T. 본글렌 야가티 카제미 곤잘레스 칼만, J. 시그노우스키, A. 프레체트, C. 스미스, L. 컬프 L. 프롤레프 루안, 엑스 첸진로테스 슈처, F. 르브론, A. 루스테미, N. 클레이, P. Crone, T. Kocisky, J. Zhao, B. Perz, D. Yu, H. Howard, A. Bloniarz, J. W. Rae, H. Lu, L. 시프레 마지오니, F. 알코퍼, D. 개럿, M. 반스 Thakoor, J. Austin, G. Barth-Maron, W. 왕룡 조시 차아부니, D. 파티하, A. 아후자, R. 유영 이성 Cogan, J. Chen, C. Jia, C. Gu, Q. 장장림스타드, A.J. 하트만, M. 채드윅, G. S. 토마르, X. 가르시아, E. 센터, E. 타로파, T. S. 필라이, J. 데블린, M. 라스킨, D. 드 라스 카사스, D. 발터, C. 타오, L. Blanco, A. P. Badia, D. Reitter, M. 첸, J 브레넌, C. 리베라, S. 빈상 Iqbal, G. Surita, J. Labanowski, A. Rao, S. 윙클러, E 파리오토, Y 구경 올체브스카, Y. 장룡 A. Miech, A. Louis, L. E. Shafey, D. Teplyashin, G. Brown, E. Catt, N. Attaluri, J. Balaguer, J. Xiang, P. Wang, Z. 애쉬우드, A. 브리오호프, A. 웹슨, S. 가나파시, S 상하비 A. 칸난 - W. 장성룡 선아배나 Aitchison, P. Pejman, H. Michalewski, T. 유찬왕, 제이러브, 제이안, D.블록스위치, 케이. 한필 험프리, T 셀람, J. 브래드베리, V. 고돌, S. Samangooei, B. Damoc, A. Kaskasoli, S. M. R. Arnold, V. 바수드반 아그라왈, J. 리사, D. 레피킨, R. 탄번 임현수 Hodkinson, P. Shyam, J. Ferret, S. 손, A. Garg, T. L. Paine, J. Li, Y. 이명 장아니츠 압바스 요크만 리드, E. 콜, A. 차우더리, D. 다스, D. 로고진스카, V. 니콜라예프, P. 스프렉만, Z. 나도L 질카, F. 프로스트, L. 그문 Monteiro, G. Mishra, C. Welty, J. Newlan, D. Jia, M. 알라마니스, C. H. Hu, R. 데 리데커케, J. 길머, C. 사로핌, S. 이승환 Hou, D. Shrivastava, A. Badepudi, A. Goldin, A. Ozturel, A. Cassirer, Y. Xu, D. Sachan, R. K. Amplayo, C. Swanson, D. Petrova, S. 나라얀, A. 게즈, S. 브라마, J. 랜던, M. 파텔 조경 빌라, L. 왕욱 지아만 라츠 김메네스 영현린, J. 킬링, P. 조지예프, D. 민쿠, B. 우, S. (주)하이칼 사푸트로 보드라할리, J. 진, Z. 칸카라, A. 샤르마, N. 페르난도 Hawkins, B. Neyshabur, S. Kim, A. Hutter, P. Agrawal, A. Castro-Ros, G. van den Driessche, T. 왕필양 (주)인창 매킬로이 루직장 파한민 샤만, P. Natsev, P. Michel, Y. 청영 반살 차광 조승 Shakeri, C. Butterfield, J. Chung, P. K. Rubenstein, S. 아그라왈, A. 멘쉬, K. 소파카르 렌, T 정아포 Maggiore, J. Kay, P. Jhakra, S. 왕재네즈 풍태 토빈, A. 타케티, M. 트레바츠 로빈슨 카타리야 리델, P 베일리, K 소남 엘헬라니 아로요 A. 슬론 N. 홀스비, 엑스 시온지 양은기리보브스카야 워스 L. 이명 이태환 가고하라, J. 파바가디, S. Bridgers, A. Bortsova, S. Ghemawat, Z 아메드, T 류룡 파월 V. 볼리나 Iinuma, P. Zablotskaia, J. Besley, D.-W. 정태환 도잿, R 엑스 코마네스쿠 시재그리어 폴라첵, R. L. 카우프만, S. 토쿠민, H. Hu, E. 부차츠카야, Y. 마오만 엘하와티, A. 싯단트, N. Tomasev, J. Xing, C. Greer, H. Miller, S. 아슈라프, A 로이, Z 장아마 베스타, R 블레인스, T 클리멘코, C.K. 예승 창피노오 장민 파자르스카스, C. 뮤어, V. 코헨철란 하리다산, A. 마라테, S. 한센 더글러스 사무엘 왕승 오스틴, C. 란, J. 장, J. 치우, J. A. 로렌조, L. L. Sjosund, S. 세비 지 글리셔, T 아브라함, A. 보랄, H. 스리니바산, V. 엘로 메기 아이소포스 Hussenot, L. B. Soares, K. Baumli, M. B. Chang, A. Recasens, B. Caine, A. Pritzel, F. Pavetic, F. Pardo, A. Gergely, J. Frye, V. 라마세시, D. 호건, K. N. 바돌라 카스너 로이, E. 다이어, V. 캠포스, A. 토말라, Y. 탕, D. E. 바도위, E. 화이트, B. 무스타파, O. 랑아진달 비크람, 지 공성호 Caelles, R 헴슬리, G. 손튼, F. 펑, W. 스토코위크, C. 정, P. 태커, 카글라 운루, Z. 장민 살레, J. 스벤슨, M. Bileschi, P. Patil, A. Anand, R. 링기 티즐라스, A. 베저, M. 셀비, T 셰블레인 로드리게스 큐아토우스키 다루키 롱A. 다포, N. 피츠제럴드 구람버그 칸, 엘에이 헨드릭스, 엠 펠랏, V. 파인버그, 제이 코본커, 티 세이나스 Rauh S. H. Hashemi 이브스 하손영 이은놀랜드 조남 버드 L. 허규 왕태 소티아욱 파가니니, J-B 레스파우, A. 무파렉, S. 하산기 Shivakumar, J. van Amersfoort, A. Mandhane, P. Joshi, A. Goyal, M. 퉁 A. Brock, H. Sheahan, V. 미사리남 라키셰비치 데하니, F. 류, S. 미탈오상 Noury E. Sezener, F. Huot, M. Lamm, N. D. Cao, C. Chen, G. Elsayed, E. Chi, M. Mahdieh I. Tenney, N. Hua, I. Petrychenko, P. Kane, D. Scandinaro, R. 제인, J. 우사토, R. 다타, 사도프스키, 오 번얀, D. 라비에즈, S. Wu, J. Zhang, G. Vasudevan, E. Leurent, M. Almahlawi, I. Georgescu, N. Wei, I. Zheng, B. Chan, P. G. Rabinovitch, P. Stanczyk, Y. 장대스티너 나스카 아잠 존슨, A. 패스케, C.-C. Chu, J. S. Elias, A. Mohiuddin, F. Muhammad, J. Miao, A. Lee, N. 비야라드 Potluri, J. Park, E. Davoodi, J. Zhang, J. Stanway, D. Garmon, A. Karmarkar, Z. 동종리 주재영 아이작 첸, J. 지아, A. 레브스카야, Z. 주, C. 고르골레우스키, P. 그라보스키, Y. 마오아목기 야오제이 스나이더 Casagrande, P. Suganthan, E. Palmer, G. Irving, E. Loper, M. 파루키, I. 아카타르, N. 천일현 핑크, A. 카스타노, I. 지안누미스, W. 김민 Rybinski, A. Sreevatsa, J. Prendki, D. Soergel, A. Goedeckemeyer, W. 기어케 자파리 가바, J. 위즈너, D. G. 라이트, Y. 위현배슈트 쿨리즈스카야, J. 후버, M. L 이철완 류경 라미레즈, A. 칼린, A. 추이, T. 린, 엠 조지예프 우룡 아길라 Pallo, A. Chakladar, A. Repina, X. 우태 van der Weide, P. Ponnapalli, C. Kaplan, J. Simsa, S. 이오 두스, F. 양, J. 파이퍼, N. le M. 루이 파수마르티 Lintz, A. Vijayakumar, L. N. Thiet, D. Andor, P. Valenzuela, C. Paduraru, D. Peng, K. 이승환 장승 Greene, D. D. Nguyen, P. Kurylowicz, S. 벨루리 크라우스, C. 하딘, L. 딕슨 L. 잔저 추주영 펑병장 라카 장규 Le, E. A. Abellan, D. Du, D. McKinnon, N. 안트로포바 오볼루크바시 켈러, D. 리드, D. 핀첼스틴, M. A. 라드, R. 크로커, P. 호킨스, R. 다다시, C. 개프니, S. 콜기 프랑코, E. 필로노프, A. 불라노바, R. 레블론드, V 야다브 정현감 Xu, F. Fischer, J. Xu, C. Sorokin, C. Alberti, C.-C. Lin, C. Evans, H. Zhou, A. Dimitriev, H. Forbes, D. Banarse, Z. 퉁정류 오메닉, C. 비숍, C. 쿠마르, R. 스터넥 폴리, R. 제인성 미쉬라, 제이샤, 티 보스, G. 시데론, E. 아미드, F. 피시노, X. 왕, P. 반잘, P. 구리타, H. 노가, P. 샤, D. J. 만코위츠, A. 폴로조프, N. 쿠쉬만, V. 크라코브나 브라운 바테니, D. 듀안, V. 피로우 토타쿠리 나탄, A. 모해너니, M. 가이스트 무갈성 긴호리 Roval, R 토조만 권재섭 위안상 바그리, 시노팔니코프, S. 라모스, J. 멜러, A. 샤르마, A. 세버린, J. 레이, K. 우현택 청덕밀러 소너트, 드누코프, R. Greig, J. Beattie, E. Caveness, L. Bai, J. Eisenschlos, A. Korchemniy, T. 차이만 자사레비치 공평도 정필류 주만 Geller, T. H. Teh, J. Sanmiya, E. Gladchenko, N. Tordin, A. Sozanschi, D. Toyama, E. Rosen, S. 타박콜 슈씨 엘킨드 오 Woodman, J. Carpenter, G. Papamakarios, R. 켐프 카플, T. 루니나 신하, A. Talbert, A. Goyal, D. Wu, D. Owusu-Afriyie, C. Du, C. Thornton, J. Pont-Tuset, P. Narayana, J. Li, S. 파테히, J. 위팅, 오 아즈메리, B. 우리아, T. 주영 고룡 나이트 A. 헬리오 N. 니우석 구철방 이남 Levine, A. Stolovich, N. 칼브 산타마리아-페르난데스 고엔카 유스탈림 Studel, A. Elqursh, B. Lakshminarayanan, C. Deck, S. 우파디야이 주젠베리 리진 왕광 레빈, R. 호프만, D. 홀트만-라이스, 오 박성호 유승 Arora, E. Malmi, D. Mirylenka, Q. 탄철호 S. 포더 정필곤제티 타리크 선락 이오니타 세예드호세이니, P. 타프티, R. 코티칼라푸디, 지 리우, A. 굴라티, J. 류, X. 예병철 왕남 세티 이병현 싱원 Fan, A. Parisi, J. Stanton, C. Guang, V. 코베르카투, C. A. 초케트추, Y. 이태환 Lu, A. Ittycheriah, P. Shroff, P. Sun, M. 바라다라잔 바하르감 윌러비, D. 개디, I. 다스굽타, G. 데자딘스, M. Cornero, B. Robenek, B. Mittal, B. Albrecht, A. Shenoy, F. Moiseev, H. Jacobsson, A. Ghaffarkhah, M. 리비에르, A. 월튼, C. 크레이피, A. 패리쉬, Y. 류종 Zhou, C. Farabet, C. Radebaugh, P. Srinivasan, C. van der Salm, A. Fidjeland, S. Scellato, E. Latorre-Chimoto, H. Klimczak-Plucinska, D. Bridson, D. de Cesare, T. 허드슨, P. 멘돌키오, L. 워커, A. 모리스, I. 펜체프, M. 모거, A. 구세이노프, A. 리드, S. 오둠 러허, 브이 코트루타 Yenugula, D. Grewe, A. Petrushkina, T. 두에리그, A. 산체스, S. 야들로스키, A. 심, A. 글로버슨, A. 커즈록, L. 웹상 두아, D. 리, P. 라호티, S. 부파티라주, D. 허트, H. 쿠레시, A. 아가왈, T. 샤니 에이얼, A. 카레, S. R. 벨, L. 왕씨텍커, 엠에스케일, 제이웨이, 로 상병태 리히티 선영 조승 Lee, P. Nayak, D. Fritz, M. R. Vuyyuru, J. Aslanides, N. 야스만 윅크, 엑스 마태호 빌랄, E. 엘티셰프, D. 발리, N. 마틴, H. 케이트, J. 마니카, K. 아미리영 김진우 시온기 강필루지에 Tripuraneni, D. Madras, M. 곽아수 왕, J. 에인슬리, J. 볼드리지, H. 장, G. 프루스티, J. 바우어, F. 양, R. 만수르, J. 겔만, Y. Xu, G. Polovets, J. Liu, H. Cai, W. 천진 성은수 Ozair, A. Yu, C. Angermueller, X. 이원 왕, J. 위싱어, E. 쿠쿠미디스, Y. 천아이어 구루머시, M. 골든슨, P 샤, M. Blake, H. Yu, A. Urbanowicz, J. Palomaki, C. Fernando, K. 브룩스 더든, H. 메타, N. 모체프, E. 라힘토로기, M. 조가키, A. 라울, S. 루더 M. 레드쇼, J. 리, K Jalan, D. Li, G. Perng, B. Hechtman, P. Schuh, M. 나스르 천경 밀라노, V. 미쿨릭 스트로만, J. 프랑코, T. 그린대하사비스 Kavukcuoglu, J. Dean and O. 빈얼스 쌍둥이자리: 매우 유능한 멀티모달 모델의 가족, 2023년.\n' +
      '\n' +
      'M. 아르테텍세 노호세일 고열태 미하일로프 오트상 Shleifer, X. V. Lin, J. Du, S. 라이어, R Pasunuru, et al. Efficient large scale language modeling with mixtures of experts. _ arXiv preprint arXiv:2112.10684_, 2021.\n' +
      '* Barham et al. (2022) P. Barham, A. Chowdhery, J. Dean, S. 게마왓 손, D. 허트, M. 임현림 방승 로이 B. 새타, P. 슈, R. 세파시, L. E. 샤피, C. A. 테카스, Y. 우 경로: 2022년, ml에 대한 비동기 분산 데이터 흐름.\n' +
      '* Borgeaud et al. (2021) S. Borgeaud, A. Mensch, J. Hoffmann, T. 카이 E. 러더포드, 케이 Millican, G. van den Driessche, J. Lespiau, B. Damoc, A. Clark, D. de Las Casas, A. Guy, J. Menick, R. 반지 헤니건, S. 황룡 Maggiore, C. Jones, A. Cassirer, A. Brock, M. 파가니니, G. 어빙, 오 빈얼스, S 오신데로 Simonyan, J. W. Rae, E. Elsen, and L. 시프 2021년, 수조 개의 토큰에서 검색함으로써 언어 모델을 개선한다. URL[https://arxiv.org/abs/2112.04426](https://arxiv.org/abs/2112.04426)\n' +
      '* Borzunov et al. (2022) A. Borzunov, D. Baranchuk, T. 디트머스 야비닌 벨카다, A. 추마첸코, P. 새미긴, C. 라펠. 페탈: 대규모 모델의 협업 추론 및 미세 조정. _ arXiv preprint arXiv:2209.01188_, 2022. URL[https://arxiv.org/abs/2209.01188](https://arxiv.org/abs/2209.01188).\n' +
      '* Clark et al. (2022) A. Clark, D. D. L. Casas, A. Guy, A. Mensch, M. 파가니니, J. 호프만, B. 다목, B. 헥트만, T. 채승 Borgeaud, G. B. V. D. Driessche, E. Rutherford, T. Hennigan, M. J. Johnson, A. Cassirer, C. Jones, E. Buchatskaya, D. Budden, L. 시프레 오신데로 빈얼스, M 란자토, J. 래, E. 엘슨, K. Kavukcuoglu, K. 사이먼 라우팅된 언어 모델에 대한 통합 스케일링 법칙. _Conference International Conference on Machine Learning_, 2022.\n' +
      '* Corbett et al.(2022) J. C. Corbett, J. Dean, M. 엡스타인, A. 피크스, C. 프로스트, J. 퍼먼, S. Ghemawat, A. Gubarev, C. Heiser, P. Hochschild, W. 허상 칸탁, E. 코간, H. 리, A. 로이드, S. 멜닉, D. 무와라, D. 나글, S. 퀸란 라오 롤릭영 사이토 지마니아크, C. 테일러, R. 왕과 D. 우드포드 스패너: 구글의 전 세계적으로 배포되는 데이터베이스. 2012년 _OSDI_에서\n' +
      '* Dalmia et al. (2023) S. 달미아, 오콘코, M. 루이스 에두노프 와타나베, F. 메츠, L. 제틀모이어와 A. 모하메드 레곤: 건물 모듈식 인코더-디코더 모델, 2023.\n' +
      '* Dean(2021) J. Dean. 경로 소개: 차세대 ai 아키텍처[https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/] (https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/), 2021. Google blog post.\n' +
      '* Dean et al. (2012) J. Dean, G. Corrado, R. 몽가 천민 데빈 Mao, M. a. Ranzato, A. Senior, P. Tucker, K. 양규 Le, A. Ng. 대규모 분산 심층 네트워크입니다. F. Pereira, C. Burges, L. 보투와 K Weinberger, editors, _Advances in Neural Information Processing Systems_, volume 25. Curran Associates, Inc., 2012. URL[https://proceedings.neurips.cc/paper_files/paper/2012/file/6aca97005c68f12023815f66102863-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2012/file/6aca97005c68f12023815f66102863-Paper.pdf].\n' +
      '* Dempster et al. (1977) A. P. Dempster, N. M. Laird, and D. B. Rubin. em 알고리즘을 통한 불완전한 데이터의 최대 가능성. _ 왕실 통계학회지 Series B(methodological)_, pages 1-38, 1977.\n' +
      '* Douillard et al. (2023) A. Douillard, Q. 펑 A. A. 루수, R. 차파리아 도초프, A. 쿤코로, M. Ranzato, A. Szlam, J. Shen. Diloco: 언어 모델의 분산 저-통신 훈련, 2023.\n' +
      '*Eigen et al.(2014) D. Eigen, I. Sutskever, and M. 란자토 전문가들의 깊은 혼합 속에서 팩터화된 표상을 배우는 것. In _Workshop in the International Conference on Learning Representations_, 2014.\n' +
      '* Fedus et al. (2021) W. 페더스, B. 조프, N. 셰이저 변압기: 간단하고 효율적인 희소성으로 1조 파라미터 모델로 스케일링 CoRR_, abs/2101.03961, 2021. URL[https://arxiv.org/abs/2101.03961](https://arxiv.org/abs/2101.03961).\n' +
      '* Ghemawat et al. (2003) S. Ghemawat, H. Gobioff, S. - T. 릉 구글 파일 시스템. 2003년 SOSP_에서\n' +
      '* Gogg(2012) Google. 에핑고: 내부 구글 복사 서비스는 데이터를 스캘런으로 옮긴다.\n' +
      '\n' +
      '[https://cloud.google.com/blog/products/storage-data-transfer/inside-googles-internal-effingo-data-copy-service/](https://cloud.google.com/blog/products/storage-data-transfer/inside-googles-internal-effingo-data-copy-service/), 2023: 2014-02-08.\n' +
      '* Goyal et al.(2017) P. Goyal, P. Dollar, R. 기르식, P. 노르후이스, L. 웨솔로스키, A. 키롤라, A. 툴로치, Y. 지아와 K 그 사람이요 정확하고 큰 미니 배치 sgd: 1시간 안에 이미네를 훈련시켜라 _ ArXiv:1706.02677_, 2017.\n' +
      '* Gross et al.(2017) S. 역겨워, M 란자토와 A. 스슬램 대규모의 약한 감독 시야를 위한 전문가의 단단한 혼합물입니다. 2017년 _CVPR_에서.\n' +
      '* Gururangan et al. (2023) S. 구루랑간 이명 루이스 시태 Althoff, N. A. Smith, and L. 제틀모이어 감독되지 않은 도메인 발견으로 전문가 언어 모델을 확장합니다. _ arXiv preprint arXiv:2303.14177_, 2023.\n' +
      '* Jacobs et al. (1991) R. A. Jacobs, M. I. Jordan, S. 노란과 G. E. 힌튼 지역 전문가의 적응 혼합물. _ Neural Computation_, 3:1---12, 1991\n' +
      '* Jordan and Jacobs (1994) M. I. Jordan and R. A. Jacobs. 전문가와 에밀리 알고리즘의 계층적 혼합물. _ Neural Computation_, 6:181-214, 1994.\n' +
      '* Kingma and Ba(2014) D. P. Kingma and J. Ba. 아담: 확률적 최적화를 위한 방법. _ The Proceedings of the 3rd International Conference on Learning Representations (ICLR)_, 2014.\n' +
      '* Kudo and Richardson (2018) T. 쿠도와 J. 리처드슨 문장: 신경 텍스트 처리를 위한 단순하고 언어 독립적인 서브워드 토큰화기와 디토키나이저. _EMNLP_, 2018.\n' +
      '* Lepikhin et al. (2021) D. Lepikhin, H. Lee, Y. 서덕천 피라트 황민 크라이쿤 Shazeer, Z. 첸 {GS}hard: 조건부 계산과 자동 샤딩으로 거대 모델을 스케일링하는 것. In _International Conference on Learning Representations_, 2021. URL[https://openreview.net/forum?id=qrwe7XHTmYb](https://openreview.net/forum?id=qrwe7XHTmYb).\n' +
      '* Li 등 (2022) M. 이성 구루랑간, T 디트머스 루이스, T Althoff, N. A. Smith, and L. 제틀모이어 Branch-train-merge: 당혹스러울 정도로 전문 언어 모델의 병렬 훈련. In _First Workshop on Interpolation Regularizers and Beyond at NeurIPS 2022_, 2022. URL[https://openreview.net/forum?id=SQgVgE2Sq4](https://openreview.net/forum?id=SQgVgE2Sq4).\n' +
      '* Liu et al.(2024) B. Liu, R. 차파리아, A. 두야르, S. Kale, A. A. Rusu, J. Shen, A. Szlam, M. 란자토 언어 모델링을 위한 비동기 로컬-sgd 트레이닝, 2024.\n' +
      '* Narayanan et al. (2020) D. Narayanan, A. Phanishayee, K. 시선 첸과 M. 자하리아 메모리 효율적인 파이프라인 병렬 DNN 훈련 CoRR_, abs/2006.09503, 2020. URL[https://arxiv.org/abs/2006.09503](https://arxiv.org/abs/2006.09503).\n' +
      '* OpenAI et al. (2020) OpenAI, ; J. Achiam, S. S. 애들러 L. 애거월 Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. 알트만 아나드캣 아빌라 I. 바부슈킨 발라지, V 발콤, P. 발테스쿠, H. 바오, M. Bavarian, J. Belgiumum, I. Bello, J. Berdine, G. Bernadett-Shapiro, C. Berner, L. 보그도노프, 오 보이코 보이드, A-L 브락만, 지 브락만, T. 브룩스 황량기 버튼, T 카이락 캠벨, A. 칸, B. 캐리, C. 칼슨, R. 카마이클, B. Chan, C. Chang, F. Chantzis, D. Chen, S. 천록 천진만 첸, B. 체스, C. Cho, C. Chu, H. W. Chung, D. Cummings, J. Currier, Y. 다이씨 데카로 Degry, N 도이치 D. 드빌 A. 다르 D. 도한 S. 다울링 Dunning A. Ecoffet A. Eleti, T. 엘언두, D. 파리, L. 페더스, N. 펠릭스, S. P. 피쉬먼, J. 포르테, I. 풀포드, L. 가오, E. 조지, C. 깁슨, V. 고태 고기네니 Gontijo-Lopes, J. Gordon, M. Grafstein, S. 회색, R 그린제그로스 S.S.구영 곽씨홀러시 그문 히튼, J. 하이데크, C. 헤세, A. 히키, W. Hickey, P. Hoeschele, B. Houghton, K. 허수 허진 허준화 제인성 제인, 장아장 장현진 조모토 B.존, H.준, T. Kaftan, Lukasz Kaiser, A. Kamali, I. Kanitscheider, N. S. Keskar, T. 칸락 길패트릭, J. W. Kim, C. Kim, Y. 김희철 Knight, D. Kokotajlo, Lukasz Kondraciuk, A. Kondrich, A. Konstantinidis, K. 코직, G. 크루거, V. 곽민 람페, 이랜, 티 이준석 임명 린성호 린민 리트윈, T 로페즈 로페루 아마칸주 말파시니 S. 매닝, T 마르코프 마르코프스키, B 마틴기 Mayer, A. Mayne, B. McGrew, S. M. McKinney, C. McLeavey, P. McMillan, J. McNeil, D. Medina, A. Mehta, J. Menick, L. Metz, A. Mishchenko, P. Mishkin, V. Monaco, E. Morikawa, D. Mossing, T. 무무 오무라티 머크, D. 멜리, A. Nair, R. 나카노 나약, A.닐라칸탄, R 고희노 Ouyang, C. O\'Keefe, J. Pachocki, A. Paino, J. Palermo, A. Pantuliano, G. Parascandolo, J. Parish, E. Parparita, A. Passos, M. Pavlov, A. Peng, A. Perelman, F. de Avila Belbute Peres, M. 페트로프, H. P. de Oliveira Pinto, Michael, Pokorny, M. 포크래스, V 퐁태 파월, A. 파워, B. 파워, E. Proehl, R. Puri, A. Radford, J. Rae, A. Ramesh, C. Raymond, F. Real, K. Rimbach, C. Ross, B. Rotsted, H. Roussez, N. 라이더 솔타렐리 샌더스 Santurkar, G. Sastry, H. Schmit, D. Schnurr, J. Schulman, D. Selsam, K. 세퍼드, T 셰르바코프, J. 쉬, S. 쇼커 P. 샤얌 S. Sidor E. Sigler M. 시멘스, J. 싯킨, 케이 Slama, I. Sohl, B. Sokolowsky, Y. 송남 Staudacher, F. P. Such, N. 서머스 I. Sutskever, J. Tang, N. 테작 톰슨, P. 틸렛, A. 투툰치안, E. Tseng, P. Tuggle, N. Turley, J. Tworek, J. F. C. Uribe, A. Vallone, A. Vijayergiya, C. Voss, C. Wainwright, J. J. Wang, A. Wang, B. Wang, J. Ward, J. Wei, C. Weinmann, A. Welihinda, P. Welinder, J. Weng, L. 왕민 위토프, 디 윌너, C. 윈터, S. 월리히 노동자, S 우진우 우경 샤오태 서승 유광 유규 위안원 자렘바 젤러스, 장창 장승 조태호 정종장 죽과 B. 조프 Gpt-4 기술 보고서, 2023\n' +
      '* Pfeiffer et al. (2020) J. Pfeiffer, I. Vulic, I. Gurevych, and S. 루더 매덱스: 다중 작업 언어 간 전송을 위한 어댑터 기반 프레임워크입니다. 2020년 _EMNLP_에서.\n' +
      '* Pfeiffer et al.(2023) J. Pfeiffer, S. Ruder, I. Vulic, E. M. Ponti. 모듈식 딥러닝, 2023\n' +
      '* Purushwalkam et al. (2019) S. 푸루시워캄 니켈, A. 굽타, M. 란자토 제로 샷 구성 학습을 위한 작업 기반 모듈식 네트워크입니다. 2019년 _ICCV_에서\n' +
      '* 라펠(2023a) C. 라펠. 오픈 소스 소프트웨어와 같은 기계 학습 모델을 구축합니다. _ ACM_, 66(2):38-40, 2023a의 통신.\n' +
      '* 라펠(2023b) C. 라펠. 오픈 소스 소프트웨어와 같은 기계 학습 모델을 구축합니다. _ 커뮤니티 ACM_, 66(2):38-40, jan 2023b. ISSN 0001-0782. doi: 10.1145/3545111. URL[https://doi.org/10.1145/3545111](https://doi.org/10.1145/3545111).\n' +
      '* Raffel et al.(2020) C. Raffel, N. Shazeer, A. Roberts, K. 이승환 나랑만 마테나 주원 리, 그리고 P.J. 류 단일 텍스트-텍스트 변환기를 이용한 전이학습의 한계점 탐색 Journal of Machine Learning Research_, 21(1):5485-5551, 2020.\n' +
      '* Reddi et al.(2021) S. 레드디, 지 찰스 자히어 개럿 Rush, J. Konecny, S. 쿠마르와 H. B. 맥마한 적응형 연합 최적화, 2021년\n' +
      '* Reisser et al.(2021) M. 레이서, C. 루이스, E. 개브스, M. 잘 지내요 전문가 연합 혼합물, 2021. URL[https://openreview.net/forum?id=YgrdmztE40Y](https://openreview.net/forum?id=YgrdmztE40Y)\n' +
      '* Ryabinin and Gusev(2020) M. 리아비닌과 A. 구세프 분산된 혼합 전문가들을 이용한 대규모 신경망의 크라우드소싱 훈련에 대하여. _ 2020년, 신경망 정보 처리 시스템_, 33:3659-3672의 발전.\n' +
      '* Shazeer et al.(2017) N. Shazeer, A. Mirhoseini, K. 마지아즈, A 데이비스, Q Le, G. Hinton, 그리고 J. Dean. 엄청나게 큰 신경망들: 희박하게 게이팅된 전문가 혼합층. _International Conference on Learning Representations_, 2017. URL[https://openreview.net/forum?id=B1ckMDqlg](https://openreview.net/forum?id=B1ckMDqlg).\n' +
      '* Sutskever et al. (2013) I. Sutskever, J. Martens, G. Dahl, and G. Hinton. 딥러닝에서 초기화와 모멘텀의 중요성에 대해. _ ICML(International Conference on Machine Learning)_, 2013.\n' +
      '* Touvron et al. (2018) H. Touvron, L. 마틴기 스톤, P. 알버트, A. 알마하일리, Y. 바배이 바슐리코프 바트라, P. 바가바, S. 보살, D. 비켈, L. 브레처, C. C. 페러, M. 첸, G. 쿠쿠럴, D. 에시오부, J. 페르난데스, J. 푸, W. Fu, B. Fuller, C. Gao, V. 고스와미 고열 A. 하트쇼른, S. 호세이니 허현인 카다스, V 커케즈 Khabsa, I. Kloumann, A. Korenev, P. S. Koura, M. - A. 라초, T. 라브릴, J. 리, D. 리스코비치, Y. 류영 마오진 마티넷 미하일로프, P. 미쉬라, I. 몰리보그, Y. 니, A. 폴튼, J. 라이젠슈타인 룽타 살라디, A. Schelten, R. 실바, E. M. 스미스, R. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. 얀인자로프 장아환 캄바두르 나랑 A. 로드리게스, R. 스톱닉 에두노프와 T 사이알롬 라마 2: 오픈 파운데이션 및 미세 조정된 채팅 모델, 2023.\n' +
      '\n' +
      '## Acknowledgements\n' +
      '\n' +
      '오웬 허, 디에고 데 라스 카사스, 로스 헴슬리, 엘레나 그리보브스카야, 예휘 테, 유티안 첸, 알렉산드레 갈라쇼프, 보그단 다모크, 슈레야 패스탁, 아말 라넨-트리키, 알렉 안드리프, 데이비드 버든, 조그 본슈타인 등 프로젝트 개발 전반에 걸친 소중한 피드백에 감사드린다. 또한 제안, 피드백 및 지원에 대해 제프 딘, 사틴더 바베하, 라이어 해델에게 감사드립니다. 마지막으로 키티 스택풀과 가이 스컬리의 프로그램 운영 지원에 감사드립니다.\n' +
      '\n' +
      '## Supplementary Materials\n' +
      '\n' +
      '### Additional Details\n' +
      '\n' +
      '우리는 내부 최적화에 사용된 하이퍼파라미터를 표 4에 나열한다. _150M 모델_ 하이퍼파라미터는 해당 크기의 조밀한 베이스라인 및 DiPaCo의 경로 최적화 모두에 사용된다. 우리의 모든 실험에서, 우리는 Douillard et al.(2023)에 의해 소개된 동일한 레시피에 따라, 0.7의 외부 학습 속도 및 0.9의 외부 운동량을 갖는 외부 최적화기 Nesterov(Sutskever et al., 2013)로서 사용하였다.\n' +
      '\n' +
      '### Routing Details\n' +
      '\n' +
      '우리는 먼저 훈련에서 사용되는 차별적인 거친 라우팅의 세부 사항에 대해 논의한다. 그런 다음 평가에 선택적으로 사용되는 보다 빈번한 라우팅의 세부 사항에 대해 논의한다.\n' +
      '\n' +
      '######7.2.1 문서 수준 차별적 라우팅\n' +
      '\n' +
      '차별적 라우팅을 위해 우리는 우리가\n' +
      '\n' +
      '* 전문가 미세 조정을 위한 초기화로 사용할 수 있는 초기 언어 모델을 학습하였다.\n' +
      '* 라우터에게 공급할 각 문서에 대한 특징을 얻는 특징 추출기를 설정한다.\n' +
      '\n' +
      '두 단계를 번갈아 가며\n' +
      '\n' +
      '1. 게이터를 훈련시키는 단계, 아마도 상기 PPL에 기초하여\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c} \\hline \\hline Hyperparameter & 150M model & 1B model \\\\ \\hline \\# Layers & 12 & 24 \\\\ Hidden dimension & 896 & 2048 \\\\ \\# Heads & 16 & 16 \\\\ Key/value size & 64 & 128 \\\\ Weight decay & 0.1 & 0.1 \\\\ Max learning rate & \\(4e^{-4}\\) & \\(2e^{-4}\\) \\\\ Batch size & 512 & 512 \\\\ \\# Warmup steps & 1000 & 1000 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: **내부 최적화**에 대한 하이퍼파라미터.\n' +
      '\n' +
      '상기 트레이닝 세트의 미사용 부분에 대한 현재 전문가들,\n' +
      '2. 현재 게이터로부터의 샤딩을 기반으로 하는 훈련 전문가.\n' +
      '\n' +
      '이 연구에서 라우터의 특징은 문서의 처음 32개의 토큰에 걸쳐 초기 LM으로부터 마지막 트랜스포머 블록으로부터의 은닉 상태의 평균이다. 이것을 \\(g(\\text{document})\\으로 표시하자. 또한 라우터 품질에 대한 결정을 내리고 라우터를 교육하기 위해 문서의 작은 부분 집합(여기서는 "라우터 데이터"라고 함)을 예약합니다. 라우터 데이터에 C4의 0.005를 사용합니다.\n' +
      '\n' +
      '우리의 초기 라우터는 항상 k-means를 통해 구성되며, 우리는 그 라우터를 사용하여 첫 번째 경로 집합(argmin에 의한 샤딩)을 클러스터링 중심으로 훈련한다.\n' +
      '\n' +
      '판별 라우터를 학습하기 위해 먼저 각 경로에 의해 인코딩된 경우 라우터 데이터에 있는 각 문서의 합산된 자동 회귀 로그 우도를 계산한다. 즉, 길이\\(L\\)와 경로\\(f_{1},...,f_{K}\\)의 \\(n\\times L\\times K\\) 배열의 점수\\(S_{ijp}\\)를 얻을 수 있다.\n' +
      '\n' +
      '\\[S_{ijp}=\\log p_{f_{i}}(t_{i,j}|t_{i-1,j},...,t_{1,j}),\\]\n' +
      '\n' +
      '그리고 여기서 \\(t_{i,j}\\)는 \\(i\\)번째 문서의 \\(j\\)번째 토큰이다. 라우터는 항상 \\(K\\) 클래스 선형 로지스틱 분류기를 사용하여 학습됩니다.\n' +
      '\n' +
      '\\[\\text{argmax}_{p}\\sum_{j=1}^{L}S_{ijp}\\]\n' +
      '\n' +
      '을 타겟으로 하고 \\(g(\\text{document}_{i})\\)을 특징으로 한다.\n' +
      '\n' +
      '많은 수의 경로에서, \\(\\text{argmax}_{p}\\sum_{j}S_{ijp}\\)를 통해 가장 적은 수의 문서를 할당받은 경로는 훈련된 로지스틱 회귀자의 출력에 의해 훨씬 더 과소 표현되었으며, 회귀자의 출력을 사용할 때 경로가 비어 있는 경우가 종종 발생한다. 이를 개선하기 위해 대상 문서 대 경로 분포와 일치하도록 편향 항을 훈련했다.\n' +
      '\n' +
      '우리가 찾은 건\n' +
      '\n' +
      '* 판별 라우터를 훈련시키는 한 단계는 검증 복잡성의 상당한 개선으로 이어지고, 더 교번하는 단계는 추가적인 사소한 개선으로 이어진다.\n' +
      '* 이득은 더 많은 경로와 함께 더 크다.\n' +
      '\n' +
      '평가 시 더 빈번한 라우팅\n' +
      '\n' +
      '이전과 같이 라우터 데이터 집합에 각 토큰의 점수를 부여하는 배열 \\(S_{ijp}\\)이 있다. 우리는 숫자\\(L\\)을 고정시키고, 입력들이 훈련 문서들의 예약된 부분으로부터 토큰 시퀀스\\(t_{i,j}\\)인 시퀀스 변환 훈련 세트를 구축하고, 출력들\\(T=T_{ij}\\)은 다음과 같이 정의된다.\n' +
      '\n' +
      '\\[T_{ij}=\\text{argmax}_{p}\\sum_{j}^{j^{\\prime}}S_{ijp},\\]\n' +
      '\n' +
      '여기서 \\(j^{\\prime}=\\text{min}(\\text{length of document},j+L-1)\\), \\(L\\)은 윈도우 크기이다. 일단 우리가 \\(T\\)을 갖게 되면, 우리는 \\(t\\)으로부터 \\(T\\)을 변환하도록 변압기를 훈련시킬 수 있다. 우리는 표준 LM 훈련과 동일한 하이퍼파라미터를 사용하여 경로를 훈련하기 위해 포크하는 동일한 모델에서 라우터를 미세 조정하며(준비 없이), 2K 단계 후에 수렴한다. 그런 다음 학습된 라우터는 모든 토큰에서 결정을 내릴 수 있습니다.\n' +
      '\n' +
      '우리는 \\(L\\)을 다시 라우팅하기 전에 토큰의 수와 같은 크기로 선택하는 것이 가장 좋은 결과를 가져왔지만, 창이 항상 문서의 끝까지 갈 만큼 충분히 큰 \\(L\\)을 선택하는 것보다 약간 더 낫다는 것을 발견했다. 표 3의 결과는 \\(L\\)(전체 서열의 길이, 1024)의 이러한 선택을 사용한다. 그런 다음 평가 시간 빈도를 선택할 때 동일한 학습된 라우터를 사용할 수 있습니다.\n' +
      '\n' +
      '표 5에서 우리는 다른 _sharding 방법이 \\(8\\times 8\\) DiPaCo에 미치는 영향을 보여준다. 샤딩은 생성 \\(k\\)-평균 변이체에 비해 0.7 퍼플렉시티 포인트의 절대 이득으로 가장 좋은 일반화를 산출하는 차별 변이체와 함께 상당한 차이를 만든다는 것을 관찰한다. 우리는 더 긴 훈련 실행이 차별적 게이팅에서 훨씬 더 큰 이득을 가져온다는 것을 발견했다.\n' +
      '\n' +
      '더 정교한 생성적 라우팅\n' +
      '\n' +
      'DiPaCo를 위한 생성 라우터로서 Product\\(k\\)-Means를 탐색하였다. \\(k\\)이 크면 일부 클러스터에는 예가 거의 할당되지 않기 때문에 \\(k\\)-평균이 비효율적일 수 있다. 더욱이, 우리의 사용 사례에서, 샤드들의 구조는 모듈들의 구조와 일치하지 않는다. 제품\\(k\\)-평균은 이러한 문제를 완화시키는 방법입니다. 2 레벨 DiPaCo의 경우, 특징 \\(z\\in\\mathcal{R}^{D}\\)은 첫 번째 \\(D/2\\) 차원을 포함하는 \\(z_{1},z_{2}]\\)과 두 번째 \\(D/2\\) 차원으로 구성된 \\(z_{1}\\)의 두 그룹으로 나누어진다. 그리고 각각의 특징 집합에 대해 독립적으로 \\(k\\)-평균을 수행하고, 각 시퀀스 \\(z\\)을 쌍에 할당한다. 첫 번째 인덱스는 방정식 1에 따라 \\(z_{1}\\)을 할당하고 두 번째 인덱스는 \\(z_{2}\\)을 할당한다. 각 할당은 \\(k\\) 가능한 값만 취하지만 가능한 고유 쌍 할당의 수는 \\(k^{2}\\)이다. 또한 할당 비용은 총 쌍 할당 수의 제곱근으로 증가합니다. 수백 개의 경로를 실험할 때 이 방법을 사용했는데, 결과는 단순한 \\(k\\)-평균에 비해 개선되었지만, 판별적 라우팅은 여전히 더 우수했으며, 판별 단계 전에 제품 \\(k\\)-평균을 초기 모듈 트레이닝을 위한 라우터로 사용하면 결과가 크게 개선되지 않았다. 판별적 라우팅은 DiPaCo의 구조에 적응하는데, 그 이유는 경로들이 타겟들을 찾기 위해 문서들을 스코어링하기 위해 사용되기 때문이다. 그럼에도 불구하고 대체 생성 라우팅을 고려한다.\n' +
      '\n' +
      '도 11: 검증 복잡성 대 교번 최소화 단계들의 수, 16 경로 플랫 MoE. 교호 단계가 증가함에 따라 결과는 개선되지만 각 단계는 0, 1, 2, 3 단계에 대해 각각 \\(14.0\\~13.38\\~13.36\\~13.25\\) PPL의 개선이 적다. 모든 차별적 라우팅 결과는 본문에서 하나의 교대 최소화 단계를 사용한다.\n' +
      '\n' +
      '그림 10: 경로 수가 다양한 생성 및 판별 평면 MoE 모델, 3개의 교대 판별 단계를 포함한다. 그림의 "분지" 구조는 모델들의 조상에 기인한다: 맨 왼쪽에서, 모두 초기 조상을 공유한다. 16K 단계에서, 각각의 판별-생성 실험 쌍은 생성 조상을 공유하며, 이는 동일한 라우터("생성")와 함께 또는 새로운 라우터("식별")의 시퀀스와 함께 계속된다(코사인 학습 속도 감쇠를 재시작함).\n' +
      '\n' +
      '모든 경로를 점수화하여 차별적인 스케일링은 많은 수의 경로로 확장할 수 없기 때문에 추가 연구에 중요하다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c} \\hline \\hline Sharding & Validation Perplexity \\\\ \\hline \\(k\\)-Means & 17.2 \\\\ Product \\(k\\)-Means & 16.8 \\\\ Discriminative & 16.5 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: **Sharding Impact on 8x8 DiPaCo**: Validation perplexity after 32 outer optimization steps, 각각 62 inner optimization steps with a 8x8 DiPaCo with \\(P=64\\) 더 긴 훈련은 방법 간의 격차를 더욱 증가시킨다. 판별 방법은 곱 \\(k\\)-평균을 기반으로 한다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>