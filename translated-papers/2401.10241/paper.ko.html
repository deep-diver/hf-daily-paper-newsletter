<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '제로 베블 피폴라인 Paiism Pipeline P Interism Pipeline.\n' +
      '\n' +
      ' 제니완, 제니완, 광화황앤민린.\n' +
      '\n' +
      'AI.\n' +
      '\n' +
      '{qiph,wanxy,huanggx,linmin}@sea.com\n' +
      '\n' +
      'Equal Contributors\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '피라인 병렬주의는 대규모 분산 훈련을 위한 핵심 구성 요소 중 하나이지만 효율성이 불가피한 것으로 간주되는 파이프라인 거품으로 고통받고 있다. 이 작업에서 우리는 우리가 아는 한 동기 훈련 의미하에서 제로 파이프라인 거품을 성공적으로 달성하는 첫 번째 스케줄링 전략을 소개한다. 이 개선의 핵심 아이디어는 백워드 계산을 입력에 대한 기울기를 구성하는 것과 매개변수를 계산하는 다른 부분으로 나누는 것이다. 이 아이디어를 기반으로 기준 방법을 상당히 능가하는 새로운 파이프라인 일정을 핸드크래프트합니다. 특정 모델 구성 및 메모리 한계에 기초하여 최적의 일정을 자동으로 찾는 알고리즘을 더 개발한다. 또한, 진정으로 제로 버블을 달성하기 위해 최적화 단계 동안 동기화를 우회하는 새로운 기술을 소개합니다. 실험 평가는 우리의 방법이 유사한 메모리 한계 하에서 처리량의 최대 23%까지 1F1B 일정을 능가한다는 것을 보여준다. 이 번호는 메모리 제약 조건이 완화되면 31%로 더 밀릴 수 있습니다. 우리는 우리의 결과가 파이프라인 병렬주의의 진정한 잠재력을 활용하는 데 중요한 단계를 달렸다고 믿는다. 우리는 [https://github.com/sail-sg/제로-bubble-pipeline-파라니즘](https://github.com/sail-sg/제로-bubble-pipeline-parism)에 대한 인기 메가트론-LM 저장소를 기반으로 구현을 개방했다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '분산 모델 훈련의 영역은 특히 점점 더 크고 복잡한 모델의 출현과 함께 딥러닝 커뮤니티의 초점이 되었다. 이러한 비헴을 훈련하려면 종종 다양한 토폴로지와 연결된 방대한 양의 GPU가 필요하다. 지난 몇 년 동안 DNN을 훈련시키기 위한 다양한 병렬화 기술이 제안되었다. 데이터 병렬주의(DP)는 간편함으로 인해 작은 크기에서 적당한 크기의 모델에 대한 기본 전략이다. 모델 크기를 넘어 하나의 단일 GPU에서 모델 파라미터에 더 이상 맞출 수 없다. 이는 모델 병렬주의가 구조(Harlap et al., 2018; Huang et al., 2019; Fan et al., 2021; Zss et al., 2022)에 다가올 때이다. 텐서 병렬주의(TP)와 파이프라인 병렬주의(PP)의 두 가지 주요 모델 병렬 방식이 있다. TP는 하나의 레이어에서 매트릭스 곱셈을 여러 디바이스로 분할하는 반면, PP는 전체 모델을 상이한 디바이스들에 걸쳐 처리할 수 있는 상이한 스테이지들로 세그먼트화한다. 특히, ZeRO(Rajjhandari et al., 2020)는 DP의 단순성을 유지하면서 장치 전체에 대한 파라미터를 파쇄하여 모델 병렬성에 대한 강력한 대안을 제공한다.\n' +
      '\n' +
      '최근 연구에 따르면 대규모 훈련 시나리오에서 최적의 성능을 달성하는 것은 DP, TP 및 PP 전략의 비개인적 상호 작용이 필요하다. 상호 연결 자원의 존재비에서 하나의 계산 노드 내에서 GPU 간의 NVLink와 같은 DP, TP 및 ZeRO 전략의 혼성화는 효율적으로 작용한다. 많은 경험적 증거가 있는 반면, Fan 등(2021); 정 등(2022); Narayan et al.(2021)은 PP를 보여주는 것은 특히 수천 개의 GPU의 규모에서 교차 관찰자 연결을 사용하는 데 특히 유리하다. 이것은 우리의 작업의 주요 목표인 PP의 효율성을 높이는 것을 강조한다.\n' +
      '\n' +
      'PP의 복잡한 상태로 더 깊이 들어가게 되면, 그 구현의 효율은 파이프라인 버블이라고 하는 장치 유휴 시간의 양에 크게 의존한다. 층 간 의존성으로 인해 거품이 불가피해 보인다. 이 문제를 해결하기 위한 두드러진 초기 작업은 파이프라인의 동시 배치 수를 증가시켜 버블 비율을 감소시키려는 GPipe(Huang et al., 2019)이다. 그러나 이에 대한 직접적인 결과는 피크 메모리 요구의 증가이다. 이를 완화하기 위해 GPipe는 후방 패스 동안 재입력하면서 중간 활성화의 일부를 폐기한다. 그러나 이 접근법은 약 20%(Fan et al., 2021)의 계산 오버헤드를 도입했다. GPipe보다 개선되는 작업 한 줄은 피페드림(Harlap et al., 2018), 피페맨(양 et al., 2021)을 포함한 비동기 PP에 초점을 맞추고 있다. 동기 PP는 이론적으로 거품성이 없지만 정확한 최적화 의미 희생에서 파이프라인 효율을 크게 향상시킵니다. 반면에 동기 설정으로 개선도 이루어집니다. GPipe의 한계를 해결하기 위한 주목할 만한 스케줄링 전략을 _one-forward-one-backward(1F1B)_이라 한다. 비동기 설정 하에서 피페드림(Harlap et al., 2018)에서 처음 제안되었으며 이후 동기 설정(Fan et al, 2021, 나라야난 et al., 2021)에서 도입되었다. 1F1B는 후방 패스를 조기에 스케줄링하여 더 빠른 메모리 제거를 제공합니다. 동일한 수의 마이크로프로세스로 유사한 버블 비율을 생성하지만 피크 메모리에서 뚜렷한 이점을 제공한다. 1F1B를 기준으로 나라야난 등(2021)은 1F1B _인터리빙_ 전략을 도입했다. 동일한 장치에 여러 단계를 할당함으로써, 더 많은 통신 및 더 높은 피크 메모리의 비용으로 버블 크기를 더욱 감소시킨다.\n' +
      '\n' +
      '다양한 노력에도 불구하고, 현재까지 남아 있는 거품은 여전히 동기 훈련 의미 하에서 PP에 가장 큰 문제를 제기한다. 이 작업에서 우리는 계산 그래프를 더 미세한 입도에서 나타내고 스케줄링함으로써 PP가 더 최적화될 수 있는 기회를 발견했다. 고전적인 딥러닝 프레임워크는 레이어의 입도에서 설계된 반면, 현대 딥러닝 컴파일러는 다양한 레벨에서 최적화를 위해 상이한 중간 표현을 사용한다. (Chen et al., 2018; Roesch et al., 2018; Sabne, 2020; Tillet et al., 2019; Lattner et al., 2020) 더 미세한 과립성은 항상 검색을 위한 더 큰 공간을 의미하지만, 공간을 탐색하기 위한 최적화 도구의 부족으로 인해 종종 방해를 받는다. 따라서 적합한 과립성을 선택하는 것이 중요합니다.\n' +
      '\n' +
      '전통적으로 뉴럴 네트워크는 적층된 층으로 과립화된다. 각 층, 전방 및 후방과 관련된 두 가지 기능이 있다. 전방 패스에서 입력 \\(\\mathbf{x}\\)는 파라미터화된 매핑 \\(f(\\mathbf{x},\\mathbf{W})를 갖는 출력 \\(\\mathbf{y}\\)로 변환된다. 양성(\\nabla_{\\mathbf{x}},\\mathbf{d\\ell}}\\mathbf{d\\ell}\\mathbf{d\\ell}{d\\mathbf{d\\ell}}}\\) 및 \\(\\nabla_{\\mathbf{d\\f{d\\f}\\f{d\\f{d\\f}\\mathbf}\\mathbf}\\mathbf{d\\f{d\\f}\\f{d\\f}\\f{d\\f}\\f{d\\f}\\f{d\\f}\\f{d\\f}\\f{d\\f}\\f{d\\f{d\\f}\\f}\\f{d\\f{d\\f{d\\f}\\f}\\f{d\\f{d\\ell}{d\\f}\\f}{d\\f{d\\ell}{d\\ell}{d\\ell}{d\\ell}{d\\ell}{d\\ell}{d\\ 이에 따라, 그들은 입력 \\(\\mathbf{x}\\) 및 레이어의 파라미터 \\(\\mathbf{W}\\)에 대한 기울기를 계산한다. 편의를 위해 단일 문자 \\(B\\)와 \\(W\\)를 사용하여 각각 이 두 계산을 나타내고, \\(F\\)을 사용하여 전진 패스(그림 1)를 나타낸다. 전통적으로 \\(B\\)와 \\(W\\)를 그룹화하여 하나의 후방 함수로 제공한다. 이 디자인은 사용자에게 개념적으로 친화적이며, DP에 대해 잘 작동하는데, 이는 계층 \\(i\\)에서의 가중치 기울기의 통신이 계층 \\(i-1\\)에서의 후방 계산과 중첩될 수 있기 때문이다. 그러나 PP에서 이 디자인은 불필요하게 순차적으로 의존하는 계산을 증가시키며, 즉 층(i-1\\)의\\(B\\)는 일반적으로 파이프라인의 효율성에 해로운 층(i\\)의\\(W\\)에 의존한다.\n' +
      '\n' +
      '분할 \\(B\\)과 \\(W\\)를 기반으로 파이프라인 효율을 크게 향상시키는 새로운 파이프라인 일정을 제시한다. 이 논문의 나머지 부분은 다음과 같이 정리되어 있는데, 2절에서는 수공예품을 소개합니다.\n' +
      '\n' +
      '그림 1: MLP용 컴퓨터 그래프.\n' +
      '\n' +
      '\\(F,B\\)와 \\(W\\)의 실행 시간이 동일하다는 이상적인 가정을 기반으로 한다. 이어서, 제3절에서는 이러한 가정을 제거하고 보다 현실적인 조건에서 작동하는 자동 스케줄링 알고리즘을 제안한다. 0개의 버블을 달성하기 위해 섹션 4는 최적화 단계 동안 동기화의 필요성을 가려내는 방법을 자세히 설명하지만 동기 훈련 의미론을 보존한다. 5절에서 다양한 환경에서 기준 방법에 대한 방법을 실증 평가하고 제로 버블을 달성하기 위해 메모리 요구 사항을 추가로 줄이기 위해 새로운 스케줄링 메커니즘을 제안하고 6절에서 성능을 평가한다.\n' +
      '\n' +
      '우리는 대규모 분산 교육을 위한 일반적인 혼합 전략을 탐색하는 것을 목표로 하지 않는다는 점에 유의해야 한다. 대신, 우리는 특히 바젤린과의 사과 비교에 사과와 함께 지원되는 파이프라인 스케줄링의 효율성을 개선하기 위해 목표한다. 우리의 방법은 DP, TP 및 ZeRO 전략과 직교하며 대규모 훈련에서 PP 부분의 병렬 교체로 사용될 수 있다.\n' +
      '\n' +
      '2개의 하나로 구성되어 있습니다.\n' +
      '\n' +
      '분획 \\(B\\)과 \\(W\\)가 순차적 의존성을 감소시켜 효율성을 향상시킬 수 있다는 주요 관찰을 바탕으로 일반적으로 사용되는 1F1B 일정에서 시작하여 파이프라인을 재설계한다. 그림 2에 도시된 바와 같이, 1F1B는 평가 단계로 시작된다. 이 단계에서 작업자들은 다양한 수의 전방 통과를 수행하며, 각 단계는 일반적으로 바로 후속 단계보다 하나의 전방 패스를 더 수행한다. 상기 평가 단계에 이어 각 작업자는 1개의 전방 통과와 1개의 후진 통과를 번갈아 실행하는 정상 상태로 이동하여 단계들 간의 작업량 분포까지 보장한다. 최종 단계에서는 각 작업자가 뛰어난 기내 미생물선을 위해 후방 패스를 처리하여 배치를 완료한다.\n' +
      '\n' +
      '개선된 버전에서 우리는 후진 패스를 \\(B\\)와 \\(W\\) 통과로 분할했는데, 동일한 미생물 군집에서 \\(F\\)와 \\(B\\)는 여전히 파이프라인 단계에 걸쳐 순차적으로 의존해야 한다. 그러나 \\(W\\)는 동일한 단계의 해당 \\(B\\) 이후에 어디서나 유연하게 스케줄링될 수 있다. 이를 통해 \\(W\\)의 전략적 배치가 파이프라인 거품을 채울 수 있다. 1F1B 이상을 개선하여 버블 크기와 메모리 발자국에서 다르게 거래할 수 있는 가능한 일정이 많습니다. 이 섹션에서 특히 흥미로운 두 가지 핸드메이드 스케줄을 도입하여 파이프라인 거품을 줄이는 데 있어 더 미세한 과립성의 큰 잠재력을 보여준다(그림 3 참조). 초기 설계에서 명확성을 위해 \\(F,B\\) 및 \\(W\\)에 대한 시간 비용이 동일하다고 가정하며, 이는 이전 연구(나라야난 et al., 2021; 황 et al., 2019)가 공유하는 가정이다. 그러나 3절에서는 실제 시나리오에서 스케줄링 효율성을 최적화하기 위해 이 가정을 재평가한다.\n' +
      '\n' +
      '아래: ZB-H2: 수공예 파이프라인 일정, 상단: ZB-H1: ZB-H1.\n' +
      '\n' +
      '그림 2:1F1B 파이프라인 일정.\n' +
      '\n' +
      '메모리 효율적인 일정.\n' +
      '\n' +
      'ZB-H1로 명명된 첫 번째 수작업 일정은 모든 작업자에 대한 최대 피크 메모리 사용이 1F1B의 사용을 초과하지 않도록 합니다. ZB-H1은 일반적으로 1F1B 일정을 따르지만, 평가 살균 횟수에 따라 \\(W\\)의 출발점을 조절한다. 이를 통해 모든 작업자가 동일한 수의 기내 미생물 공급을 유지할 수 있습니다. 그 결과 그림 3(톱)에서 볼 수 있듯이 버블 크기는 1F1B 크기의 3분의 1로 축소된다. 이러한 감소는 \\(B\\)가 1F1B에 비해 모든 작업자에 걸쳐 더 일찍 시작되고 꼬리 말단 거품이 후행 \\(W\\)에 의해 채워지기 때문이다. V\\(W\\)는 일반적으로 \\(B\\)보다 적은 메모리를 사용하므로, 제1 작업자는 1F1B와 일치하는 최대 피크 메모리 사용을 갖는다.\n' +
      '\n' +
      '제로 버블 스케줄.\n' +
      '\n' +
      '1F1B보다 더 큰 메모리 발자국을 허용하고 충분한 수의 마이크로 워치를 가질 때 ZB-H2로 표시된 제로 버블 스케쥴을 달성할 수 있으며, 그림 3(바닥)에 예시된 바와 같이 초기 \\(B\\) 앞의 버블을 채우기 위해 평가 단계에서 더 많은 \\(F\\) 패스를 소개한다. 또한 꼬리에서 \\(W\\) 통과를 재주문하여 사다리꼴에서 평행그램으로 레이아웃을 변경하여 파이프라인의 모든 거품을 제거했다. 여기서 최적화 단계 간의 동기화가 제거된다는 점을 강조하는 것이 중요하며, 이는 4절에서 어떻게 안전하게 수행되는지 논의한다.\n' +
      '\n' +
      '### Quantitative analyses\n' +
      '\n' +
      '우리는 \\(p\\)를 사용하여 각 미생물군의 크기를 나타내기 위해 스테이지 수와 \\(b\\)를 나타낸다. 변압기 아키텍처의 경우, 우리는 주의 헤드의 수를 \\(a\\), 서열 길이는 \\(s\\)이고 숨겨진 치수 크기는 \\(h\\)로 나타낸다. 우리는 1 _B/W_ 패스 및 \\(T_{B}/M_{W}\\)에 대한 액티베이션을 저장하는 데 필요한 메모리를 나타내기 위해 노션 \\(M_{B}/M_{W}\\)을 사용하고, \\(T_{F}\\)/\\(T_{B}\\)/\\(T_{W}\\)를 사용하여 1 _F/B/W_패스의 실행 시간을 나타낸다. 단순화를 위해 피드포워드 내부의 숨겨진 치수 크기가 \\(4h\\)이고 각 주의 헤드에 대한 치수 크기가 \\(h/a\\)인 GPT-3(브라운 et al., 2020)과 유사한 전형적인 설정을 사용하여 변압기 아키텍처(Vaswani et al., 2017)에 대한 정량적 분석만 수행한다.\n' +
      '\n' +
      '나라야난 등(2021)에서와 같이 변압기 층에서 대부분의 계산을 기여하기 때문에 FLOP를 계산할 때 매트물 작업만 고려한다. 전방 고개의 매트물 연산은 해당 후방 패스(그림 1 참조)에서 동일한 FLOP를 갖는 매트물 연산이 두 개 있는데, 각각은 \\(B\\) 또는 \\(W\\)에 속한다. 변압기 층의 FLOP를 계산하기 위한 대략적인 공식은 표 1에 있으며 \\(T_{W}<T_{F}<T_{B}<\\) 및 \\(T_{B}+T_{W}=2T_{F}\\)임을 알 수 있다. 우리는 \\(B\\)에 필요한 활성화 메모리를 추정하기 위해 쿠키칸 et al.(2023)에서 동일한 방법을 사용한다. I\\(B\\)가 완료된 후, 더 이상 사용되지 않고 일부 활성도를 방출하지만 \\(W\\)에 대해 그림 1에서 일부 추가 구배(\\(\\nabla_{\\texttt{z}}L\\)를 유지한다. <표 1>과 같이 \\(W\\)가 요구하는 총 메모리는 \\(B\\)보다 작다.\n' +
      '\n' +
      '<표 2>에서 노동자 \\(i\\)의 활성화 메모리는 \\(p-i+1)M}(i+1){B}(i-1) M}(i-1){B}(i-1){B}(i-1){W}\\)이며, ZB-H1 및 \\(i-1)에 대한 활성 메모리(i+_{B}(i-1)의 활성화 메모리는 ZB-H1 및 \\(i+_{B}(i+_{B}(i+_{B}(i+_{B}) 및 ZB}(i+_{B}(i+_{B}) 및 ZB}(i-H1) ZB}(i-H1) 및 \\) ZB}(i-H1) 및 \\)에 대한 활성화 메모리(i+(i-M_{B}\'{B}(i+_{B}(i+_{B}) \\) \\) \\) \\) \\) \\(i+(i-1) 따라서 피크 활성 메모리는 ZB-H1 및 ZB-H2에 대해 각각 \\(pM_{B}\\) 및 \\((2p-1)M_{B}\\)이다.\n' +
      '\n' +
      '3개의 스케쥴링 스케줄링.\n' +
      '\n' +
      '수공예 스케줄은 단순하고 더 나은 이해력을 제공하지만 실제 응용 분야에서 몇 가지 문제에 직면한다. 하나는 \\(T_{F}=T_{B}=T_{W}=T_{W}\\)가 도입한다는 가정하에 스케줄링한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c} \\hline Pass & FLOPs & Activations Memory Required \\\\ \\hline \\hline \\(F\\) & \\(sbh(24h+4s)\\) & \\(0\\) \\\\ \\hline \\(B\\) & \\(sbh(24h+8s)\\) & \\(sb(34h+5as)\\) \\\\ \\hline \\(W\\) & \\(sbh(24h)\\) & \\(32sbh\\) \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: FLOP 및 각 패스닝된 버블에 대해 변압기 층당 요구되는 활성 메모리, 특히 이러한 값이 크게 다른 모델에 대해 필요하다. 더욱이, 단계 간의 활성화/중력을 전달하는 데 필요한 통신 시간(T_{\\text{comm}}\\)은 종종 수작업 스케줄에서 무시되어 파이프라인 스트림의 눈에 띄는 경이로 이어진다. 마지막으로 버블 크기를 최소화하고 메모리 한계에 붙이는 사이의 균형을 높이는 것은 버블이 없는 일정에 충분한 마이크로워치를 수용하기에 이용 가능한 메모리가 부족할 때 특히 어려워진다.\n' +
      '\n' +
      '이러한 문제를 해결하고 실제 시나리오에 일반화하기 위해 우리는 파이프라인 단계 \\(p\\), 미생물 분석 횟수 \\(m\\), 활성 메모리 한계 \\(M_{\\{limit}}\\), 실행 시간 추정 \\(T_{F}\\), \\(T_{B}\\), \\(T_{\\{comm}}\\) 및 \\(T_{\\{comm}\\)를 고려할 때 최적 일정을 자동으로 검색하도록 알고리즘을 제안한다. 우리는 특히 \\(m\\)가 충분히 클 때 항상 최적의 또는 가까운 최적 솔루션을 생성하는 휴리스틱 전략을 설계한다. 우리는 또한 문제가 일정 규모일 때 오프샵 ILP 솔버(포레스트 & 루지-헤머, 2005년)가 해결할 수 있는 통합 리바 프로그램(더 자세한 부록 G)으로 문제를 체계적으로 공식화했다. 이 두 가지 접근법은 첫째, 휴리스틱 용액을 초기화로 사용한 다음 ILP로 추가로 최적화할 수 있다.\n' +
      '\n' +
      '중요 알고리즘.\n' +
      '\n' +
      '우리는 다음 단계에서 우리의 휴리스틱 알고리즘을 제시한다.\n' +
      '\n' +
      '* 평가 단계에서 메모리 한계 내에서 가능한 한 많은 \\(F\\)를 통과시켜 첫 번째 \\(B\\) 전에 버블을 최소화한다. 결과 일정은 메모리 한계에 도달하지 않을 경우 제1\\(B\\) 전에 여전히 작은 버블(T_{F}\\))을 가질 수 있으며, 여기서 다른 \\(F\\)를 스케줄링하는 경우 다음 \\(B\\)을 지연시킬 수 있다. 우리는 바이너리 하이퍼파라미터를 사용하여 할 것인지 여부를 제어합니다.\n' +
      '* 평가 단계 이후, 우리는 1개의 \\(F\\)와 1개의 \\(B\\)가 반복적으로 예정된 패턴을 고수한다. 우리는 \\(W\\)를 삽입하여 \\(T_{W}\\)보다 큰 간격이 있을 때 버블을 채운다. 거품이 발생하지만 크기가 \\(T_{W}\\) 미만일 때, 현재 버블이 모든 단계 중에서 가장 큰 누적 버블 크기를 만들면 여전히 \\(W\\)를 삽입한다. 우리는 또한 메모리 제한이 부딪힐 때 일부 메모리를 재활용하기 위해 \\(W\\)를 삽입한다. 일반적으로 우리의 휴리스틱 전략은 \\(1F\\)-\\(1B\\)-\\(1W\\) 패턴을 따르는 정상 상태로 들어간다.\n' +
      '* 이 과정을 통해, 파이프라인 단계 \\(i\\)는 \\(F\\)가 사용되기 전에 언제라도 스테이지 \\(i+1\\)보다 적어도 하나 이상의 \\(F\\)를 스케줄링하도록 항상 보장된다. 이 차이가 하나를 초과할 때, 우리는 다른 이진 하이퍼파라미터를 사용하여 더 많은 거품을 일으키지 않으면 파이프라인 단계에서 1 \\(F\\)를 건너뛰는지 여부를 결정한다. 우리는 하이퍼파라미터의 최상의 조합을 찾기 위해 그리드 검색을 수행한다.\n' +
      '*, 각 단계에서 \\(F\\)와 \\(B\\)가 통과하면 왼쪽 \\(W\\)을 하나씩 지나간다.\n' +
      '\n' +
      '4개의 운동 낙관기 동기입니다.\n' +
      '\n' +
      '대부분의 PP 관행에서 파이프라인 단계에 대한 동기화는 보통 수치 강건성을 위해 최적화 단계에서 수행된다. 예를 들어, 글로벌 구배 규범은 구배 규범 클로핑(Pascanu et al., 2013)에 대해 계산되어야 하며, NAN 및 INF 값에 대한 글로벌 체크는 혼합 정밀 설정(Micikevicius et al., 2017)에서 수행되며, 둘 다 모든 단계에 걸쳐 모두 감소된 통신을 필요로 한다. 그러나 최적화 단계의 동기화는 병렬그램(그림 3)을 파괴하고 제로 버블을 불가능하게 만든다. 이 섹션에서는 이러한 동기화를 우회하는 대체 메커니즘을 제안하지만 여전히 동기 최적화 의미론을 유지한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c} \\hline Schedule & Bubble size & Peak activations memory \\\\ \\hline \\hline\n' +
      '1F1B & \\((p-1)(T_{F}+T_{B}+T_{W})\\) & \\(pM_{B}\\) \\\\ \\hline ZB-H1 & \\((p-1)(T_{F}+T_{B}-T_{W})\\) & \\(pM_{B}\\) \\\\ \\hline ZB-H2 & \\((p-1)(T_{F}+T_{B}-2T_{W})\\) & \\((2p-1)M_{B}\\) \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 1F1B와 핸드메이드 스케줄 사이의 비교.\n' +
      '\n' +
      '기존의 구현들에서, 글로벌 상태들을 수집하기 위해 우선 전면적인 커뮤니케이션이 개시되고, 그 다음이 글로벌 상태들에서 조건화되는 최적화 단계들이 시작된다. 그러나 대부분의 전 세계 상태가 효과가 없는 경우, 예를 들어 NAN 및 INF에 대한 글로벌 검사는 대부분의 반복이 수치적인 문제가 없어야 하기 때문에 거의 촉발되지 않는다는 것을 발견했으며, 구배 클로핑 속도는 반복마다 글로벌 구배 규범의 동기화를 정당화하기 위해 경험적으로 상당히 낮다.\n' +
      '\n' +
      '이러한 관찰을 기반으로 우리는 사전 동기화를 사후 업데이트 검증으로 대체할 것을 제안한다. 이 개념은 최적화 단계 이전 각 단계에서 이전 단계에서 부분적으로 감소된 글로벌 상태를 수신하고 현재 단계의 지역 상태와 결합하여 다음 단계로 넘어간다. 각 단계의 최적화 단계는 NAN이 발견되거나 부분적으로 감소된 구배 규범이 클로핑 임계값을 초과할 때 업데이트를 생략하는 것과 같이 부분적으로 감소된 상태에 의해 제어된다. 다음 반복의 평가 단계에서 완전히 감소된 글로벌 상태는 마지막 단계에서 첫 단계로 다시 전파된다. 글로벌 상태를 수신하면 각 단계는 이전 최적화 단계가 정당한지 여부를 결정하기 위해 검증을 수행한다. 구배에 대한 수정이 필요한 경우 롤백(더 자세한 내용은 부록 C를 보고)을 발행하고 완전히 감소된 글로벌 상태를 기반으로 최적화 단계를 재추진한다.\n' +
      '\n' +
      '## 5 Experiments\n' +
      '\n' +
      '### Setup\n' +
      '\n' +
      'T_{\\(T_{W}\\), \\(T_{W}\\), \\(T_{\\{comm}\\) 및\\(T_{\\text{comm}\\)를 대상으로 "표 3"에 자세히 설명된 바와 같이 GPT-3(브라운 et al., 2020)과 유사한 모델을 사용하여 성능을 평가하고, 우리는 먼저 프로파일링을 위한 특정 반복, \\(T_{F}\\), \\(T_{\\)에 대한 경험적 측정, \\(T_{\\-source Megatron-3(브라운 등 3)에 대한 경험적 측정을 수집하여 프로파일링을 위한 특정 수의 반복을 수행하여 표 3과 유사한 모델을 사용하여 성능을 평가한다. 이러한 값을 얻은 후 최적의 일정을 결정하기 위해 자동 파이프라인 스케줄링 알고리즘에 먹였다. 초기 및 최종 파이프라인 단계 모두 중간 단계에 비해 1개의 더 적은 변압기 층을 가지고 있다는 점에 주목할 필요가 있다. 이 디자인은 초기 및 최종 단계에서 추가 임베딩 룩업 및 손실 계산을 보상하여 병목 상태가 되지 않고 다른 단계로 거품을 일으키는 것이다.\n' +
      '\n' +
      'Compared methods:\n' +
      '\n' +
      '* ZB-1p: 활성 메모리가 1F1B와 이론적으로 동일한 피크 메모리를 갖는 \\(pM_{B}\\)로 제한된 자동 검색 스케줄이다.\n' +
      '* ZB-2p: \\(2pM_{B}\\)로 제한된 활성화 메모리로 자동 검색 스케줄, 즉 0 버블에 가깝게 실증적으로 달성하기 위한 가장 적은 양의 메모리(그림 7 참조)이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c|c|c} \\hline Model & Layers & Attention & Hidden & Sequence & Pipelines & Microbatch & Number of \\\\  & & Heads & Size & Length & (GPUs) & Size & Microbatches \\\\ \\hline \\hline\n' +
      '1.5B & 22 & 24 & 2304 & 1024 & 8 & 6 & 24 / 32 / 64 \\\\ \\hline\n' +
      '6.2B & 30 & 32 & 4096 & 1024 & 8 & 3 & 24 / 32 / 64 \\\\ \\hline\n' +
      '14.6B & 46 & 40 & 5120 & 1024 & 16 & 1 & 48 / 64 / 128 \\\\ \\hline\n' +
      '28.3B & 62 & 48 & 6144 & 1024 & 32 & 1 & 96 / 128 / 256 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '실험에 사용된 표 3:모델 및 고정 설정은 실험에 사용된 표 3:모델 및 고정 설정\n' +
      '\n' +
      '그림 4: 최적화기 동기화를 대체하기 위한 사후 검증 전략은 다음과 같다.\n' +
      '\n' +
      '* 1F1B 및 1F1B-I:1F1B 및 Hlap et al.(2018) 및 나라야난 et al.(2021)에 의해 도입된 인터리빙된 1F1B 방법. 메가트론-LM에서 구현된다. 인터리빙된 1F1B의 경우, 전체 모델을 각 단계에 의해 순환적으로 취해진 청크의 시퀀스로 나누어 인터리빙된 파이프라인을 형성한다. 인터리빙된 실험에서 우리는 항상 최대 양의 청크를 사용하여 최소 버블, 즉 각 변압기 층이 청크 역할을 한다.\n' +
      '\n' +
      '우리의 실험은 RoCE RDMA 네트워크에 의해 상호 연결된 4개의 노드에 분포하는 최대 32개의 NVIDIA A100 SXM 80G GPU를 사용한다. 각 반복의 실행 시간은 여러 번 평가 반복 후에 기록된다. 메가트론-LM 구현에 의해 제공되는 재현성 덕분에 융합될 때까지 모델을 실행하지 않고 ZB-1p 및 ZB-2p의 올바른 여부를 확인할 수 있다. 우리는 고정된 무작위 종자를 사용하여 모델을 초기화하고 ZB-1p, ZB-2p 및 1F1B에 대해 반복 후 손실을 기록한 다음 비트 대 비트임을 확인한다.\n' +
      '\n' +
      '### Main results\n' +
      '\n' +
      '그림 5의 모든 방법의 처리량을 제시하고 표 4의 각 설정에 대한 추가 세부 사항을 남겨두며, 우리의 실험은 ZB-2p가 다양한 설정에 걸쳐 다른 모든 방법을 일관되게 능가한다는 것을 보여준다. 특히, 1F1B, 1F1B-I 및 ZB-1p의 처리량은 미생물 용량 수와 강한 양의 상관관계를 보여준다. 대조적으로, ZB-2p는 마이크로시치가 적더라도 효율성을 유지한다. ZB-2p의 버블 속도가 거의 0(표 5), 거의 0에 도달했기 때문이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c c c|c c c|c c c|c c} \\hline \\multirow{3}{*}{Setup} & \\multicolumn{2}{c|}{Model} & \\multicolumn{2}{c|}{1.5B} & \\multicolumn{2}{c|}{6.2B} & \\multicolumn{2}{c|}{14.6B} & \\multicolumn{2}{c}{28.3B} \\\\ \\cline{2-13}  & \\multicolumn{2}{c|}{\\#GPU} & \\multicolumn{2}{c|}{8} & \\multicolumn{2}{c|}{8} & \\multicolumn{2}{c|}{16} & \\multicolumn{2}{c}{32} \\\\ \\cline{2-13}  & \\multicolumn{2}{c|}{\\#Microbatch} & 24 & 32 & 64 & 24 & 32 & 64 & 48 & 64 & 128 & 96 & 128 & 256 \\\\ \\hline \\hline Samples & ZB-2p & **14.5** & **14.8** & **14.9** & **4.32** & **4.35** & **4.39** & **1.81** & **1.83** & **1.85** & **0.99** & **1.00** & **1.00** \\\\ per GPU & ZB-1p & 12.9 & 13.4 & 14.2 & 3.88 & 4.00 & 4.20 & 1.61 & 1.67 & 1.76 & 0.87 & 0.90 & 0.96 \\\\ per second & 1F1B & 11.8 & 12.5 & 13.6 & 3.50 & 3.70 & 4.03 & 1.40 & 1.49 & 1.64 & 0.76 & 0.80 & 0.88 \\\\  & 1F1B-I & 13.1 & 13.4 & 13.9 & 4.01 & 4.08 & 4.19 & 1.54 & 1.59 & 1.66 & 0.82 & 0.85 & 0.90 \\\\ \\hline \\multirow{3}{*}{Memory (GB)} & ZB-2p & 59 & 59 & 59 & 70 & 70 & 70 & 51 & 51 & 51 & 74 & 74 & 74 \\\\  & ZB-1p & 32 & 32 & 32 & 42 & 42 & 42 & 33 & 33 & 33 & 44 & 44 & 44 \\\\ \\cline{1-1}  & 1F1B & **30** & **30** & **30** & **39** & **39** & **39** & **32** & **32** & **32** & **43** & **43** & **43** \\\\ \\cline{1-1}  & 1F1B-I & 40 & 40 & 40 & 48 & 48 & 48 & 39 & 39 & 39 & 58 & 58 & 58 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4:실험 결과 내표 4:실험 결과 세부표 4:실험 결과 내용표 4: <표 4>: <표 4:실험 결과표 4:\n' +
      '\n' +
      '그림 5: 다른 파이프라인 일정에 걸친 처리량의 비교.\n' +
      '\n' +
      '처리량과 처리량은 이미 상부 결합체에 가깝습니다. 여기에서 상부 결합체는 1F1B 및 \\(\\frac{1}{1-\\text{bubble rate 1F1B}}\\)의 처리량에 대략적으로 곱하여 추정한다(더 자세한 내용 제5.3절). 앞서 언급한 바와 같이 ZB-2p의 향상된 효율성은 1F1B 기준선과 비교하여 더 높은 메모리 소비 비용으로 나온다. 또한 부록 F에서 동일한 기억 소비 하에서 ZB-2p와 1F1B를 비교하고 실험 결과는 ZB-2p가 1F1B에 비해 반 마이크로볼링 크기에서도 더 높은 처리량을 달성한다는 것을 보여준다.\n' +
      '\n' +
      '대조적으로, ZB-1p는 1F1B 기준선과 유사한 피크 메모리 비용을 갖도록 설계되었다. 8개의 GPU 세트에서 1F1B-I와 유사한 처리량을 보여준다. 통신 대역폭이 병목보다 더 많은 다중 모드 세트에서 ZB-1p는 1F1B-I를 명확하게 능가하여 추가 통신 비용을 일으키지 않고 파이프라인 거품을 줄이는 데 이점이 있음을 강조한다.\n' +
      '\n' +
      '대부분의 환경에서 우리는 파이프라인 병렬성의 더 일반적인 사용 사례이기 때문에 단계 \\(p\\)보다 더 많은 수의 미생물 측정 수를 설정했다. 그러나 유사한 메모리 소비로 20%에서 30%의 개선을 나타내는 \\(m\\leq p\\) 사례에 대해 부록 H에 나열된 실험을 수행했다.\n' +
      '\n' +
      '자동 스케줄링의 효율\n' +
      '\n' +
      '자동 스케줄링 알고리즘에서 생성된 스케줄의 효율성을 연구합니다. 그러나 우리의 주요 실험과 동일한 세트를 사용하지만, 우리의 목적은 자동 스케줄링 알고리즘의 효율성을 연구하는 것이기 때문에 여기의 숫자는 실제 실험 대신 이론적 계산을 기반으로 한다. 관제 일정의 효율성을 정량화하기 위해 \\(T_{F}-m(T_{F}+T_{B}+T_{W}))/\\텍스트{비용}\\)로 계산된 버블 속도의 개념을 소개한다. 여기서의 비용은 프로파일링된 \\(T_{F}\\), \\(T_{B}\\), \\(T_{W}\\) 및 \\(T_{\\text{comm}}\\) 값을 사용하여 각 일정에 대해 계산된 모든 단계의 가장 큰 실행 시간으로 정의된다. i\\(m(T_{F}+T_{B}+T_{B}+T_{W})\\)는 모든 통신이 계산과 중복되어 파이프라인에 거품이 없는 최적의 실행 시간이다.\n' +
      '\n' +
      '서로 다른 일정의 버블 비율은 표 5에 나와 있다. 자동으로 검색된 일정의 기저부로 수작업 스케줄 ZB-H1 및 ZB-H2를 포함한다. 대부분의 환경에서 ZB-2p는 모든 일정 중에서 가장 좋은 1% 미만의 버블 속도를 생성한다. 대조적으로, ZB-H2는 ZB-2p보다 일관되게 더 나쁜 성능을 보인다. 이것은 우리의 자동 스케줄링 알고리즘이 \\(T_{F}\\), \\(T_{B}\\), \\(T_{W}\\) 및 \\(T_{\\text{comm}}\\)의 보다 정확한 추정치를 사용하여 현실적인 시나리오에 더 잘 적응한다는 강력한 증거를 제공한다. 반대로, 이러한 개선은 ZB-1p 대 ZB-H1에서 관찰되지 않으며, 메모리 제한이 지배 요인이 되기 때문에 저혈압적으로 관찰된다. 특히, 모든 방법은 1F1B를 상당히 능가한다.\n' +
      '\n' +
      '우리는 또한 ZB-2p와 그 프로파일링된 실제 실행을 16개의 GPU에 도표하여 그것이 진정으로 제로 버블 스케줄이라는 직접적인 시각적 증거를 제공한다. 그림 6과 같이 자동으로 생성된 ZB-2p 일정은 버블이 거의 없다. 프로파일된 실행은 약간 더 많은 거품을 가지고 있지만 전반적인 정렬을 잘 유지한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c|c|c|c} \\hline Model & \\#Stage (\\(p\\)) & \\#Microbatch (\\(m\\)) & 1F1B & 1F1B-I & ZB-H1 & ZB-H2 & ZB-1p & ZB-2p \\\\ \\hline \\hline \\multirow{3}{*}{1.5B} & \\multirow{3}{*}{8} & 24 & 0.2431 & 0.1055 & 0.1585 & 0.1083 & 0.1585 & **0.0433** \\\\  & & 32 & 0.1985 & 0.0818 & 0.1242 & 0.0837 & 0.1242 & **0.0039** \\\\  & & 64 & 0.1240 & 0.0443 & 0.0674 & 0.0444 & 0.0674 & **0.0026** \\\\ \\hline \\multirow{3}{*}{6.2B} & \\multirow{3}{*}{8} & 24 & 0.2347 & 0.0808 & 0.1323 & 0.0698 & 0.1323 & **0.0029** \\\\  & & 32 & 0.1898 & 0.0628 & 0.1045 & 0.0559 & 0.1045 & **0.0022** \\\\  & & 64 & 0.1091 & 0.0320 & 0.0554 & 0.0294 & 0.0554 & **0.0010** \\\\ \\hline \\multirow{3}{*}{14.6B} & \\multirow{3}{*}{16} & 48 & 0.2552 & 0.1104 & 0.1397 & 0.0672 & 0.1397 & **0.0066** \\\\  & & 64 & 0.2082 & 0.0852 & 0.1088 & 0.0516 & 0.1088 & **0.0054** \\\\  & & 128 & 0.1251 & 0.0445 & 0.0576 & 0.0266 & 0.0576 & **0.0028** \\\\ \\hline \\multirow{3}{*}{28.3B} & \\multirow{3}{*}{32} & 96 & 0.2646 & 0.1493 & 0.1421 & 0.0641 & 0.1421 & **0.0038** \\\\  & & 128 & 0.2168 & 0.1164 & 0.1106 & 0.0490 & 0.1106 & **0.0029** \\\\  & & 256 & 0.1352 & 0.0624 & 0.0594 & 0.0257 & 0.0594 & **0.0018** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 다른 환경에서 1F1B, 1F1B-I, ZB-H1, ZB-H2, ZB-1p, ZB-2p의 부블 비율은 표 5이다.\n' +
      '\n' +
      '### Memory limit\n' +
      '\n' +
      '기억 극한의 효과를 더 잘 이해하기 위해 \\(M_{\\text{limit}}\\)에 대한 버블 속도의 관계를 연구한다. 우리는 일련의 \\(M_{\\text{limit}}\\)로 휴리스틱 알고리즘을 실행하여 그림 7에서 플롯하고 있으며, 기포율은 \\(M_{\\text{limit}}\\)의 값을 높여 선형적으로 가까운 감소 추세를 보인다. 이론적으로 곡선은 \\(p-1)(T_{B}+2T_{\\text{comm}})+pT_{F}}{T_{F}}M_{B}\\) 주위에 안정되어야 한다. 실증적으로 \\(2pM_{B}\\)는 \\(T_{F}\\ 엔트렉스 T_{B}\\) 및 \\(T_{\\text{comm}}\\)가 상대적으로 작을 때 제로 버블 속도에 가깝게 달성하기에 좋은 임계값을 찾는다. 변곡점을 넘어 충분히 큰 메모리 제한이 이론적으로 제로 버블 속도를 초래하지만 일반적으로 비용은 이득을 능가한다. 자세한 내용은 부록 B를 참조하세요.\n' +
      '\n' +
      '6개의 버블 스케줄이 효율적입니다.\n' +
      '\n' +
      '그림 8: ZB-V 일정. 각 장치는 정확히 2개의 청크에 할당되며, 여기서 흰색 텍스트 색상은 제1 청크 및 블랙 텍스트 색상은 제2 청크를 나타낸다. 모델 청크들 간의 종속성의 시퀀스는 전후방 통과 모두에 대해 "V" 형상 패턴을 따른다.\n' +
      '\n' +
      '그림 6: ZB-2p(톱)와 그 프로파일링된 실행 과정(바닥)이 제작한 A 스케줄이다.\n' +
      '\n' +
      '그림 7: 우리의 휴리스틱 알고리즘을 사용하여 메모리 한계와 버블 레이트 사이의 관계를 보여준다.\n' +
      '\n' +
      'ZB-2p는 거의 0개의 버블을 효과적으로 달성할 수 있지만, 1F1B에 비해 메모리 소비를 두 배로 증가시키는 비용에서 나온다. 이러한 증가된 기억 요구 사항은 실제 시나리오에서 실용적인 적용 가능성에 한계가 있다. 이 문제를 해결하기 위해 1F1B와 동일한 메모리 제약 내에서 최소한의 유휴 시간을 달성하는 스케줄링 접근 방식인 ZB-V를 설계한다. 나라야난 등(2021)이 제안한 인터리빙된 1F1B 전략에 의해 영감을 받아, 우리의 방법은 전체 모델을 정확히 \\(2p\\) 청크로 고르게 분할하여 각 작업자에게 2개의 청크를 할당한다. 인터리빙된 방식과 대조적으로, 우리의 방법은 첫 번째 작업자로부터 시작하여 마지막으로 진행되는 작업자에게 모델 청크를 순차적으로 할당한 다음 마지막 작업자로부터 첫 번째 작업자로 순서를 역전시켜 독특한 "V" 형상을 생성(그림 8의 첫 번째 미생물 배치의 전방 통과 참조)하는 것을 포함한다. 예를 들어, 4단 파이프라인에 대한 16층 변압기 모델을 분할함에 있어서, 1-2층 및 15-16층, 3-4층 및 13-14층을 근로자 2에 할당한다.\n' +
      '\n' +
      '이 접근법은 각 미생물 배치에 대한 정방향 패스 및 후방 패스 모두 동일한 작업자로부터 유래함을 보장하고, 이는 1F1B 및 인터리빙된 1F1B와 같은 이전 방법과 구별되며, 여기서 정방향 패스는 마지막 작업자로부터 시작되고 후방 패스는 최초 작업자로부터 시작된다. 이러한 구별은 첫째, 첫 번째 작업자가 마지막 작업자로부터 복귀하기 위해 후진 통과를 기다리지 않고 빠르게 후방 패스를 개시할 수 있으므로 최소한의 유휴 시간을 달성하기 위해 더 빠른 메모리 제거 및 감소된 메모리 요구 사항을 달성할 수 있다는 두 가지 주목할 만한 이점을 제공한다. 조건(T_{F}=T_{B}=T_{B}=T_{W}\\)에서 ZB-V는 \\(pM_{B}\\)의 피크 활성 메모리로 제로 버블을 달성하여 1F1B의 최대 피크 메모리 사용과 일치한다. 특히, 이는 \\((2p-1)M_{B}\\)를 활용하는 ZB-H2에 비해 메모리 요구량의 거의 절반이다. 둘째, 피크 메모리 사용은 본질적으로 모든 작업자에 걸쳐 균형을 이루고 있다. 이 평형은 모든 모델 청크에 걸쳐 균일한 계산 작업량과 일관된 메모리 소비로 인해 발생한다.\n' +
      '\n' +
      '그림 8에서 ZB-V의 스케줄링 전략은 세 가지 뚜렷한 단계로 전개된다. 초기 평가 단계에서 각 작업자(i\\(i\\))는 제1 청크의 경우 \\(2p-i\\) 패스 및 제2 청크의 경우 \\(i-1\\)를 포함하는 총 \\(2p-1\\) 전방 통과를 수행한다. 선별 후, 모든 작업자는 반복적인 1_F-1B-1W_ 패턴을 특징으로 하는 정상 단계로 전환된다. 정상 단계에서 작업자는 특정 청크에 해당하는 각 그룹을 갖는 계산 그룹, 특히 _F-B-W_를 실행한다. 주어진 근로자 \\(i\\)의 경우, 이 과정은 제2 청크에 대한 \\(p-i\\) 그룹의 실행으로 시작된다. 이어서, 작업자는 제2 청크용 하나의 그룹과 제1 청크용 하나의 그룹 간의 처리 사이를 이동시킨다. 이 패턴은 전방 통과가 모두 처리될 때까지 계속된다. 최종 단계에서 각 작업자는 나머지 \\(B\\) 및 \\(W\\) 계산을 처리하는 데 초점을 맞추고 \\(B\\)가 우선적이고 \\(W\\)가 거품을 채우는 데 중점을 둔다.\n' +
      '\n' +
      '제3.1절에서 설명한 유사한 휴리스틱 알고리즘을 사용하여 파이프라인 단계 \\(p\\), 미생물들의 수 \\(m\\), 활성 메모리 한계 \\(M_{\\{limit}}\\), 프로파일링된 러닝 시간 \\(T_{F}\\), \\(T_{B}\\), \\(T_{\\{W}\\), \\(T_{\\{comm}\\)와 같은 매개변수를 고려하여 최적의 일정을 자동으로 검색한다. 메모리 분포는 평가 단계 및 정상 단계 동안 모든 작업자에게 본질적으로 균형을 이루므로 메모리 제약 범위 내에서 모든 \\(W\\)를 우측으로 간단하게 이동시킬 수 있다. 이 수정은 주로 \\(F\\) 및 \\(B\\)에 비해 상대적으로 짧은 기간의 \\(W\\)에서 발생하는 일정의 꼬리에 거품을 채울 수 있도록 하는 추가 \\(W\\)의 효과적인 활용을 가능하게 한다(B\\).\n' +
      '\n' +
      '### Evaluation\n' +
      '\n' +
      '표 6에서 1F1B, ZB-1p, ZB-2p 및 ZB-V 간의 포괄적인 성능 비교를 수행한다. 공정한 기억 소비 평가를 보장하기 위해 마이크로볼링 크기를 반감시키고 마이크로팩트 수(ZB-2p*로 표시됨)를 두 배로 증가시켜 ZB-2p 구성을 조정하여 모든 방법에 걸쳐 일관된 글로벌 배치 크기를 유지한다.\n' +
      '\n' +
      '실험 결과는 ZB-V가 다양한 환경에서 일관되게 1F1B 및 ZB-1p를 능가함을 나타내며, 이는 ZB-2p*와 유사한 성능을 보여준다. ZB-2p*와 ZB-V의 비교에 더 깊이 정착하기 위해 표 7의 미생물 배치 크기를 증가시켜 처리량이 어떻게 변하는지를 조사하는 절제 연구를 수행하며, 더 큰 배치 크기는 GPU 활용도와 전반적인 효율성을 실증적으로 향상시킨다. 결과는 마이크로볼링 크기를 1에서 2로 증가시킬 때 14.6B 및 28.3B 모델에 대해 주목할 만한 8% 개선을 보여주지만 마이크로볼링 크기가 이미 충분히 크기 때문에 6.2B 모델에 대해 개선이 더 완만(3% 미만)하다. 이 시나리오에서 ZB-2p*가 ZB-V를 능가하는 이유를 설명한다. 결론적으로, 더 큰 마이크로볼링 크기와 감소된 버블 속도 사이에 트레이드오프가 존재한다. 더 작은 버블 레이트의 이점이 더 큰 마이크로볼링 크기의 편익보다 크면 후자를 희생시키는 것이 전략적 선택일 수 있다.\n' +
      '\n' +
      '### Schedule efficiency\n' +
      '\n' +
      '표 8에서 1F1B, 1F1B-I, ZB-H1, ZB-H2 및 ZB-V에 대해 섹션 5.3에 도입된 버블 속도를 계산한다. 계산은 ZB-V에 대한 실험에서 얻은 \\(T_{F},T_{B},T_{W}\\) 및 \\(T_{\\text{comm}}\\)의 프로파일링 값을 기반으로 한다. 결과는 ZB-V의 버블 속도가 ZB-H2와 비슷하지만 1F1B, 1F1B-I 및 ZB-H1보다 절반만 현저히 작다는 것을 나타낸다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c c c|c c c|c c c} \\hline \\multirow{3}{*}{Setup} & Model & \\multicolumn{2}{c|}{6.2B} & \\multicolumn{3}{c|}{14.6B} & \\multicolumn{3}{c}{28.3B} \\\\ \\cline{2-11}  & \\multicolumn{2}{c|}{\\#GPU} & \\multicolumn{2}{c|}{16} & \\multicolumn{3}{c|}{24} & \\multicolumn{3}{c}{32} \\\\ \\cline{2-11}  & \\multicolumn{2}{c|}{\\(b\\)} & \\multicolumn{2}{c|}{6} & \\multicolumn{3}{c|}{2} & \\multicolumn{3}{c}{2} \\\\ \\cline{2-11}  & \\multicolumn{2}{c|}{\\(m\\)} & 48 & 64 & 128 & 72 & 96 & 192 & 96 & 128 & 256 \\\\ \\hline \\hline Samples & ZB-V & 4.15 & 4.21 & 4.35 & **1.85** & **1.88** & **1.93** & **1.01** & **1.02** & **1.06** \\\\ per GPU & ZB-2p* & **4.36** & **4.37** & **4.45** & 1.84 & 1.84 & 1.85 & 1.00 & 1.00 & 1.01 \\\\ per & ZB-1p & 3.87 & 4.00 & 4.29 & 1.72 & 1.78 & 1.89 & 0.94 & 0.97 & 1.03 \\\\ second & 1F1B & 3.38 & 3.57 & 3.91 & 1.52 & 1.61 & 1.76 & 0.82 & 0.87 & 0.95 \\\\ \\hline \\multirow{3}{*}{Memory (GB)} & ZB-V & 64 & 64 & 64 & 45 & 45 & 45 & 71 & 71 & 71 \\\\  & ZB-2p* & 63 & 64 & 65 & 46 & 46 & 46 & 72 & 72 & 72 \\\\ \\cline{1-1}  & ZB-1p & 62 & 62 & 62 & 46 & 46 & 46 & 73 & 73 & 73 \\\\ \\cline{1-1}  & 1F1B & 61 & 61 & 61 & 44 & 44 & 44 & 69 & 69 & 69 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6은 동일한 메모리 소비하에서 1F1B, ZB-1p, ZB-2p 및 ZB-V 사이의 비교이다. 우리는 ZB-2p에 대한 뚜렷한 구성을 채택하는 것이 중요하며, 여기서 마이크로볼링 크기를 \\(b/2\\)로 설정하고 마이크로팩트 수를 \\(2m\\)로 설정했다. 이러한 변이를 강조하기 위해 우리는 이 특정 설정을 ZB-2p*로 나타낸다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c c|c c|c c|c c} \\hline \\multirow{3}{*}{Setup} & Model & \\multicolumn{2}{c|}{6.2B} & \\multicolumn{3}{c|}{14.6B} & \\multicolumn{3}{c}{28.3B} \\\\ \\cline{2-11}  & \\multicolumn{2}{c|}{\\#GPU} & \\multicolumn{3}{c|}{16} & \\multicolumn{3}{c|}{24} & \\multicolumn{3}{c}{32} \\\\ \\cline{2-11}  & \\multicolumn{2}{c|}{\\(m\\)} & 64 & \\multicolumn{3}{c|}{96} & \\multicolumn{3}{c}{128} \\\\ \\cline{2-11}  & \\multicolumn{2}{c|}{\\(b\\)} & 3 & 6 & \\(\\Delta\\) & 1 & 2 & \\(\\Delta\\) & 1 & 2 & \\(\\Delta\\) \\\\ \\hline \\hline Samples per & ZB-V & 4.13 & 4.21 & 1.94\\% & 1.75 & 1.88 & 7.43\\% & 0.95 & 1.02 & 6.32\\% \\\\ GPU per & ZB-1p & 3.91 & 4.00 & 2.30\\% & 1.65 & 1.78 & 7.88\\% & 0.90 & 0.97 & 5.56\\% \\\\ second & 1F1B & 3.48 & 3.57 & 2.59\\% & 1.47 & 1.61 & 9.52\\% & 0.80 & 0.87 & 8.75\\% \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: 각 마이크로볼링의 두 배 크기일 때 개선합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c|c|c|c} \\hline Model & \\#Stage (\\(p\\)) & \\#Microbatch (\\(m\\)) & 1F1B & 1F1B-I & ZB-H1 & ZB-H2 & ZB-V \\\\ \\hline \\hline \\multirow{3}{*}{6.2B} & \\multirow{3}{*}{16} & 48 & 0.2668 & 0.1499 & 0.1536 & 0.0823 & **0.0697** \\\\  & & 64 & 0.2206 & 0.1169 & 0.1198 & 0.0630 & **0.0533** \\\\  & & 128 & 0.1390 & 0.0621 & 0.0637 & 0.0325 & **0.0274** \\\\ \\hline \\multirow{3}{*}{14.6B} & \\multirow{3}{*}{24} & 72 & 0.2699 & 0.1519 & 0.1439 & **0.0628** & 0.0638 \\\\  & & 96 & 0.2229 & 0.1184 & 0.1121 & **0.0480** & 0.0483 \\\\  & & 192 & 0.1403 & 0.0630 & 0.0595 & **0.0247** & 0.0250 \\\\ \\hline \\multirow{3}{*}{28.3B} & \\multirow{3}{*}{32} & 96 & 0.2676 & 0.1509 & 0.1429 & 0.0629 & **0.0593** \\\\  & & 128 & 0.2204 & 0.1177 & 0.1111 & 0.0478 & **0.0451** \\\\ \\cline{1-1}  & & 256 & 0.1362 & 0.0626 & 0.0593 & 0.0251 & **0.0236** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: 1F1B, 1F1B-I, ZB-H1, ZB-H2 및 ZB-V의 Bubble 비율은 다른 환경에서 표시된다.\n' +
      '\n' +
      '메모리 소모. 특히, 이 비교에서 1F1B, ZB-H1 및 ZB-V는 유사한 메모리 소비를 갖는 반면, 1F1B-I 및 ZB-H2는 다른 방법에 비해 더 많은 메모리를 필요로 한다.\n' +
      '\n' +
      '그림 9에서 버블 속도와 메모리 한계 사이의 관계를 탐구한다. 우리의 관찰은 5.4절에서 제시된 경향과 일치하며, 버블 속도는 \\(M_{\\text{limit}}\\)의 값이 증가함에 따라 밀접하게 선형적으로 감소하여 결국 특정 임계값을 넘어 제로 버블 속도에 가까운 고원에 도달한다. 특히, 메모리 제한이 \\(2pM_{B}\\) 미만인 경우 ZB-V는 ZB-V(그림 9의 ZB로 표시됨)를 레버리지 않는 휴리스틱 알고리즘과 비교하여 상당한 이점을 보여준다.\n' +
      '\n' +
      '7개의 타악과.\n' +
      '\n' +
      '본 연구에서는 후방 계산에서 활성화 구배와 파라미터 구배를 분할하여 파이프라인 병렬성의 효율성을 향상시키기 위한 새로운 전략을 소개하고, 다양한 메모리 예산 하에서 파이프라인 버블 속도를 최소화할 수 있는 자동 파이프라인 스케줄링 알고리즘을 설계한다. 이 알고리즘에 의해 생성된 스케줄은 일관되게 1F1B를 능가하고 심지어 제로 버블 속도에 가깝게 달성된다. 메모리 소비를 더욱 줄이기 위해 \\(T_{F}=T_{B}=T_{W}\\)일 때 제로 버블을 달성할 수 있는 ZB-V라는 새로운 스케줄링 메커니즘을 제안했고, 1F1B와 동일한 메모리 한계를 고수했다. 우리의 방법의 또 다른 장점은 더 적은 수의 미생물 분석(사이언티컬 \\(3p\\)으로 최적의 효율성을 달성할 수 있다는 것이며, 이는 데이터 병렬 차원보다 더 많은 마이크로 웨이브를 분할할 수 있음을 의미한다. 이것은 대형 모델 학습에 더 나은 확장성을 제공합니다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* 브라운 등 (2020) 톰 브라운, 벤자민 맨, 니크 리더, 멜라노이 Subbiah, 자르드 디 카플란, 프라풀라 다하리왈, 아빈드 네나칸탄, 프랜나브 시흐만탄, 기러시 스스티, 아미다 아사셀, 언어 모델은 몇 가지 샷 학습자들이다. 신경 정보 처리 시스템_, 2020년 33:1877-1901의 발전이다.\n' +
      '* 브리티만 등 (2018)\n' +
      '\n' +
      '그림 9: ZB-V의 메모리 한계와 버블 속도 사이의 관계는 섹션 3.1의 휴리스틱 방법과 비교된다.\n' +
      '\n' +
      'Tianqi Chen, 티에리 모레우, 지청 장, 리안민 정, 에드디옌, 하이첸 선, 메건 코완, 르위안 왕, 유웨이 후, 루이스 세제, 등{TVM}: 안 자동화 {End-to-End}는 딥러닝을 위한 컴파일러 최적화를 수행한다. 2018년 제13차 USENIX 운영 시스템 설계 및 구현(OSDI 18)_, pp 578-594에 대한 심포지엄에서.\n' +
      '* 판 등은 (2021) 시칭 판, 이롱, 첸멍, 자룽옌카오, 시유왕, 조언정, 추안우, 구오핑 롱, 준양, 리슈샤 등 대형 모델 교육을 위한 파이프라인 데이터 병렬 접근 방식. 2021년 제26차 ACM SIGPLAN 심포지엄에서 병렬 프로그램_, pp. 431-445의 원칙 및 실무에 관한 것이다.\n' +
      '* 포레스트와 루게-헤머(2005) 존 포레스트와 로빈 루게-헤머이다. Cbc 사용자 가이드입니다. _메르싱 이론, 방법 및 애플리케이션_에서 pp. 257-277. INFORMS 2005.\n' +
      '* 고달 등은 (2017) 프리야 고열, 프리오야 게라, 로스 기릭, 피에터 노로드히이스, 루카즈 위솔로스키, 아포 키롤라, 앤드루 풀로치, 양칭 지아, 키임킹 하이. 1시간 만에 정확하게, 큰 미니부치 sgd: 훈련 상상력. arXiv 프리프린트 arXiv:1706.02677_ 2017.\n' +
      '* 하라프 등은 (2018) 아론 하릴랩, 딥크 나라야난, 아마르 파하야예, 비브크 세샤드리, 니힐 데바누르, 그레강어, 필 기브본 등이 있다. 피테드림: 패스트 및 효율적인 파이프라인 병렬 dnn 훈련. __pipedream: Fast 및 효율적인 파이프라인 평행 디n 훈련. arXiv 프리프린트 arXiv:1806.03377_ 2018.\n' +
      '*황 등은 (2019) 옌핑황, 야울롱청, 안쿠롱갑나, 오한비라, 오르한피라트, 데하오첸, 미아첸, 효크조롱 리, 지칸나기암, 퀘칸나기암, 쿼크비어, 용휘우 등 파이프라인병행을 이용한 거대신경망의 효율적인 훈련. 신경 정보 처리 시스템_, 2019년 32.\n' +
      '* 쿠키칸티 등 (2023) 비자야 안드 쿠키칸티, 자르드 카스퍼, 상쿠그 리마, 로렌스 맥아피, 마이클 안데르치, 모하마드 시이비, 브라이언 카탄자로 등이다. 대형 변압기 모델에서 감소 활성화 재입원은 __ 감소하는 활성화 재출력은 큰 변압기 모델에서 반복된다. 기계학습 및 시스템_, 5, 2023의 진행.\n' +
      '* 라트너 등은 (2020) 크리스 라트너, 메흐디 아미니, 우데이 본드후룰라, 알버트 코헨, 앤디 데이비스, 자크 피엔야르, 강 리들, 타티아나 시페만, 니콜라스 바실리카, 오클랑드르 자이너코 등이 있다. Mlir: 모어의 법칙의 종료를 위한 컴파일러 인프라. __Mlir: A 컴파일러 인프라. arXiv 프리프린트 arXiv:2002.11054_, 2020.\n' +
      '* Li et al. (2020) 선리, 옌리 자오, 로한 바마, 오므카 살페카, 피에터 노르트히우스, 텔리 리, 아담 파스케, 제프 스미스, 브라이언 비노만, 피타암 다마니아 등은 데이터 병렬 훈련을 가속화하는 것에 대한 전문가 : Pytorch를 배포하였다. arXiv 프리프린트 arXiv:2006.15704_ 2020.\n' +
      '* 로쉬칠로프와 후터(2017) 아이리카 로쉬칠로프와 프랑크 홉터. 감소된 체중 붕괴 규칙화 __ 감소 체중 붕괴 규칙화. __ 감소 체중 붕괴 규칙화. arXiv 프리프린트 arXiv:1711.05101_ 2017.\n' +
      '* 미키니비우스 등 (2017) 폴리우스 미키비우스, 샤이니 노랑, 조나 알벤, 그레고리 디아모스, 에리치 엘센, 다비드 가르시아, 보리스 진스부르크, 마이클 휴스턴, 오클릭시 쿠차예프, 가네히 베네키츠 등 고정 정밀 훈련. arXiv 프리프린트 arXiv:1710.03740_ 2017.\n' +
      '크나라야안, 모하마드 샤이비, 자르드 카스퍼, 패트릭 르그레스리, 모스토파 파커리, 비제이 쿠키칸티, 디미트리 바이니브랜드, 프레디 카슈클런티, 줄리 버나우어, 브라이언 카타네로 등을 사용하여 gpu 군집에 대한 대규모 언어 모델 교육을 효율적으로 수행했습니다. 2021년 고성능 컴퓨팅, 네트워크링, 저장 및 분석_, pp. 1-15 국제 컨퍼런스의 _검토에서.\n' +
      '* 파스칸루 등은 (2013) 라즈반 파스칸루, 토마스 미콜로프, 요슈아 벤지오 등이 있다. 재발성 신경망을 훈련시키는 데 어려움이 있다. 머신 러닝_, pp. 1310-1318. PMLr, 2013. _국제회의에서.\n' +
      '* 라자베나리 등은 (2020) 사미암 라자베나리, 제프 라슬리, 올라툰지 루위즈, 유시온가 등이 있다. 제로: 메모리 최적화는 트레이닝조 파라미터 모델을 인코딩한다. _SC20: 고성능 컴퓨팅, 네트워크링, 저장 및 분석_, pp. 1-16. IEEE. 2020.\n' +
      '* 로슈 등은 (2018) 자르드 로슈, 스티븐 리보마스키, 로건 위버, 조쉬 파록, 마리사 키리사메, 톈치첸, 자차 타터록 등이다. 관련: 기계 학습 프레임워크를 위한 새로운 아이입니다. 2018년 제2차 ACM SIGPLAN 국제 워크숍에서 기계학습 및 프로그래밍 언어_, pp. 58-68에 관한 프로그램입니다.\n' +
      '* 라그나반 등 (2019)* 사벤(2020) 아미트 사브네. Xla : 2020년 피크 성능을 위한 컴파일링 머신 러닝입니다.\n' +
      '* 타일렛 등은 (2019) 필리필레 타일렛, Hsiang-Tsung Kung, 데이비드 콕스 등이다. 트리톤: 타일링된 신경망 계산을 위한 중간 언어 및 컴파일러이다. 2019년 제3회 ACM SIGPLAN 국제 워크숍에서 기계학습 및 프로그램 릴레이지_, pp. 10-19에 관한 _프로그래밍입니다.\n' +
      '* 바스완이 등은 (2017) 아샤시 바소와이, 노암 샤제리, 니키 파마르, 작노 우즈코레이트, 리온 존스, 디단 노 고메즈, 루카즈 카이저, 일리아 폴로숙신 등이 있다. 필요한 것이 전부입니다. __ 주의가 필요합니다. __ 주목된다. 신경 정보 처리 시스템_, 30, 2017의 발전.\n' +
      '* 양 등은 (2021) 보웬 양, 지안 장, 조나단 리, 크리스토퍼 리, 크리스토퍼 애버거, 크리스토퍼 데사 등이 있다. 피페미어: 시동기 파이프라인은 dnn 훈련을 병행한다. __ 기계학습 및 시스템_, 2021년 3:269-296의 진행.\n' +
      '*정(2022) 르안민정(2022) 루안민정, 주한리, 하오장, 용하오장, 용하오쩌, 지펑첸, 옌핑황, 요다왕, 요안중추, 단양주후, 에릭피싱, 유통 딥 러닝을 위한 오토닝 인터 앤 {Intra-작동자} 평행성. 제16차 USENIX 심포지엄에서 운영 시스템 설계 및 구현(OSDI 22)_, 2022년 pp. 559-578.\n' +
      '\n' +
      '데이터 친화주의 커뮤니케이션\n' +
      '\n' +
      '데이터 병렬성을 고려할 때, 최적화 단계 이전에 구배를 수집하기 위해 전면적인 커뮤니케이션이 개시된다. 일반적으로 이러한 통신은 계산 패스와 잘 겹치지 않아 특히 통신 대역폭이 제한적일 때 대기 시간이 발생한다. 그림 3과 같이 일반적으로 반복의 꼬리에 다수의 \\(W\\) 통과가 예정되어 있다. 각 \\(W\\) 통과에 대해 서로 다른 매개변수에 대한 구배를 계산하는 여러 독립적인 계산으로 구성된다. 그림 10과 같이, 우리는 동일한 매개변수에 대한 구배를 계산하는 계산을 군집링하기 위해 이러한 모든 계산을 재주문할 수 있으므로 계산과 통신 사이의 최적 중첩을 달성할 수 있다.\n' +
      '\n' +
      '자동 스케쥴링 알고리즘\n' +
      '\n' +
      '메모리 한계와 버블 속도의 관계는 초기 단계에서 첫 번째 \\(B\\) 앞의 거품의 영향을 크게 받는다. 첫 번째 마이크로볼링은 정방향 패스가 초기 단계에서 최종 단계로 나아가야 하며, 후방 패스는 결국 초기 단계로 돌아갈 때까지 이 과정을 역전시킨다. 처음 미생물화가 시작부터 완료되는 총 시간은 적어도 \\(p(T_{F}+T_{B})+2(p-1)T_{\\text{comm}}\\)를 취하며 의존성 사슬로 인해 짜낼 수 없다. 우리는 \\(F\\)의 수를 \\(k(\\geq 1)\\로, 버블 크기는 \\(\\beta(\\geq 0)\\로 표시하며, 초기 단계에서 첫 번째 \\(B\\)를 통과한다. 그럼 저희가 가지고 있습니다.\n' +
      '\n' +
      '\\}}\\geq kM_{B}\\tag{1}\\\\.\n' +
      '\n' +
      '\\[\\beta\\geq p(T_{F}+T_{B})+2(p-1)(T_{F}-T_{B})+(p-1)(T_{B}+2T_{{F}})+(p-k)\n' +
      '\n' +
      'i\\(M_{\\text{limit}}\\)의 하측은 \\(k\\)에 비례하고( 화학식 1 참조), \\(\\beta\\)는 \\(k\\)에 반비례한다( 화학식 2 참조). H\\(k\\)을 증가시키고 \\(k<\\lfloor\\frac{(p-1)(T_{B}+2T_{\\text{comm}}})+pT_{F}}{T_{F}}\\rative\\)을 유지할 때,\\(\\beta\\)는 선형적으로 감소하며, 이는 \\(M_{\\{limit}}})의 낮은 결합으로 선형적으로 증가한다. \\(\\beta\\)은 \\(B\\_{F}}{F})+pH_{frac{(B\\)+pT_{F}}를 지연시키지 않고 최소값에 도달하며, \\(T_{F}}) 값은 \\(T_{F})에 도달한다. 이 점을 넘어 파이프라인 거품을 0으로 더 줄이는 것은 쉽지 않다. 각 단계(그림 6 참조)에는 \\(T_{F}\\)보다 작은 버블이 있고, 다른 \\(F\\)를 스케줄링하면 \\(B\\)의 시작 시간이 지연되어 이전 단계에서 \\(F\\)에 더 많은 요구 사항이 발생하기 때문이다. 이론적으로, 모든 단계에 대한 첫 번째 \\(B\\) 이전 버블(그림 11 참조)을 완전히 제거하기 위해 초기 단계에서 또 다른 \\(p-1\\) F 통과가 필요하며, 이는 또한 적어도 \\(\\lfloor\\frac{(p-1)(T_{B}+2T_{\\text{comm}})+(2p-1)({F}}{T_{F}}\\rfloor M_{B}\\)의 총 활성화 메모리 사용량(p-1)(p-1)(p-1)(p-1)(p-1)(p-1)(p-1)(T_{F}}{F}}{T_{F}}{T_{F} <그림 11 참조)+(p-1)+(p-1)+(p-1)({F}}{F}}{T_{B}}\\rfloor M_{B}<그림 11 참조)을 의미한다.\n' +
      '\n' +
      '그림 11: 32 마이크로워치가 있는 1.5B 모델에 대한 제로 버블 스케쥴입니다.\n' +
      '\n' +
      '그림 10: 중복(톱)이 좋지 않은 \\(W\\)로 그룹화된 원래 일정과 최적의 중복(바닥)을 갖는 매개변수로 그룹화된 재순수 일정 간의 비교이다. 숫자 \\(i\\)는 계산은 \\(i\\)-th \\(W\\)에 속하며, 상이한 색상들은 서로 다른 파머들에 대한 계산을 나타낸다.\n' +
      '\n' +
      '위치 최적화기 롤백입니다.\n' +
      '\n' +
      '최적화 단계를 롤백해야 할 때, 일반적인 방법은 역사적인 버전의 파라미터와 최적화기 상태를 저장하고 필요할 때 이 역사적 버전으로 복귀하는 것이다. 그러나 이 방법은 기억력 비효율적이며 많은 복사 작업이 필요하며, 이는 확실히 훈련 성능을 손상시킨다. 대부분의 최적화에 대해 단계 기능이 아르메트로 가역적이라는 것을 알 수 있다. 이 관찰에서 우리는 추가 메모리를 할당하는 것을 피하고 롤백을 수행할 때만 추가 계산을 필요로 하는 위치 내 최적화기 롤백을 수행하는 새로운 기술을 제안한다. 알고리즘 1에서와 같이 아담와 최적화기(Loshchilov and Hutter, 2017)의 단계 기능을 롤링하는 방법을 보여준다.\n' +
      '\n' +
      '```\n' +
      '1:Optimizer States:\n' +
      '2:\\(\\gamma\\)(에피실론), \\(\\beta_{2}\\)(히브리다\\)(체중 붕괴), \\(\\beta_{2}\\)(betas): \\(\\bamma\\)(letas), \\(\\b intraperda\\)(letas), \\(\\beta_{2}\\)(비타스), \\(\\beta_{2}\\)(비타스), \\(\\beta_{2}\\)(비타스), \\(\\betas), \\) \\(\\) \\(\\) \\(\\) \\(\\) \\(알람다.\n' +
      '원자격(모수), (첫 번째 순간), (모수), (첫 번째 순간), \\(v\\), \\(\\), \\(m\\), \\(m\\): \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\)(1차(2차), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\), \\(m\\) 3:3:1차(1차)(1차(1차(1차(1차)(1차(1차(1차)(1차(1차(1차)(2차(2차\n' +
      '4:\\(t\\)(time stamp).\n' +
      '위치 단계 5: 기능 단계(\\(g\\)\n' +
      '6:\\(t=t+1\\)\n' +
      '7:\\(m=\\beta_{1}m+(1-\\beta_{1})g\\)\n' +
      '8:\\(v=\\beta_{2}v+(1-\\beta_{2})g^{2}\\)\n' +
      '9:\\(m^{\\prime}=m/(1-\\beta_{1}^{t})\\)\n' +
      '10:\\(v^{\\prime}=v/(1-\\beta_{2}^{t})\\)\n' +
      '11:\\(\\theta=\\theta-\\gamma\\lambda\\theta-\\gamma m^{\\prime}/(\\sqrt{v^{\\prime}}+\\epsilon)\\)\n' +
      '12:endfunction\n' +
      '기능성 롤백(\\ (g\\))\\(TPtriangleright\\)13.\n' +
      '14:\\(m^{\\prime}=m/(1-\\beta_{1}^{t})\\)\n' +
      '15:\\(v^{\\prime}=v/(1-\\beta_{1}^{t})\\)\n' +
      '16:\\(\\theta=(\\theta+\\gamma m^{\\prime}/(\\sqrt{v^{\\prime}}+\\epsilon))/(1-\\gamma\\lambda)\\)\n' +
      '17:\\(m=(m-(1-\\beta_{1})g)/\\beta_{1}\\)\n' +
      '18:\\(v=(v-(1-\\beta_{2})g^{2})/\\beta_{2}\\)\n' +
      '19:\\(t=t-1\\)\n' +
      '20:endfunction\n' +
      '```\n' +
      '\n' +
      '아담미용 롤백****\n' +
      '\n' +
      '실험 시간.\n' +
      '\n' +
      '5절에서의 실험을 위해 우리는 다양한 설정에 걸쳐 ZB-2p에서 \\(T_{F},T_{B},T_{W}\\) 및 \\(T_{\\text{comm}}\\)의 프로파일링 시간을 기록한다. 그런 다음 이러한 값은 섹션 5.3 및 5.4에서 고려되는 모든 방법에 대한 버블 속도를 계산하는 데 사용되며 이 값은 표 9에서 찾을 수 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c|c} \\hline Model & \\#Stage (\\(p\\)) & \\#Microbatch (\\(m\\)) & \\(T_{F}\\) & \\(T_{B}\\) & \\(T_{W}\\) & \\(T_{\\text{comm}}\\) \\\\ \\hline \\hline \\multirow{3}{*}{1.5B} & \\multirow{3}{*}{8} & 24 & 18.522 & 18.086 & 9.337 & 0.601 \\\\  & & 32 & 18.513 & 18.086 & 9.331 & 0.626 \\\\  & & 64 & 18.546 & 18.097 & 9.321 & 0.762 \\\\ \\hline \\multirow{3}{*}{6.2B} & \\multirow{3}{*}{8} & 24 & 29.718 & 29.444 & 19.927 & 0.527 \\\\  & & 32 & 29.802 & 29.428 & 19.530 & 0.577 \\\\  & & 64 & 29.935 & 29.621 & 19.388 & 0.535 \\\\ \\hline \\multirow{3}{*}{14.6B} & \\multirow{3}{*}{16} & 48 & 11.347 & 11.248 & 8.132 & 0.377 \\\\  & & 64 & 11.307 & 11.254 & 8.101 & 0.379 \\\\  & & 128 & 11.325 & 11.308 & 8.109 & 0.378 \\\\ \\hline \\multirow{3}{*}{28.3B} & \\multirow{3}{*}{32} & 96 & 10.419 & 10.207 & 7.715 & 0.408 \\\\  & & 128 & 10.408 & 10.204 & 7.703 & 0.408 \\\\ \\cline{1-1}  & & 256 & 10.402 & 10.248 & 7.698 & 0.460 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 9: \\(T_{F}, T_{B}, T_{W}\\) 및 \\(T_{\\text{comm}}\\)의 식별 시간.\n' +
      '\n' +
      '출발 후 전략 최적화 연구에 대한\n' +
      '\n' +
      '이 절에서는 최적화 후 검증 전략의 효과에 대한 절제 연구를 제공한다. 이 연구는 두 가지 조건에서 ZB-2p의 처리량을 사후 검증과 모두 감소된 동기화와 비교한다. 표 7의 실험 결과에 따르면 ZB-2p의 동기화된 버전은 최적화 후 검증과 함께 ZB-2p에 비해 약 8%의 성능 감소를 보여준다.\n' +
      '\n' +
      '동일한 메모리 소비 아래 1F1B를 갖는 1F1B를 가진 동일한 메모리 소비량에서## 부록 F 컴퍼스 ZB-2p.\n' +
      '\n' +
      '동일한 기억 소비하에서 1F1B 및 ZB-1p에 대한 각 미생물군의 크기를 두 배로 늘리고 표 11의 ZB-2p와 처리량을 비교했으며 실험 결과는 ZB-2p가 1F1B에 비해 반 마이크로볼링 크기에서도 더 나은 성능을 가지고 있음을 보여준다. 실증적으로, 더 큰 배치 크기는 GPU의 이용률을 증가시켜 효율성을 향상시킨다. 그러나 숨겨진 차원이 장치 활용을 포화시킬 만큼 크기 때문에 큰 모델에 대한 우려는 적다. 이 고려 사항과 실험 결과에 기초하여, 우리는 ZB-2p가 1F1B에 대한 배치 크기를 증가시키는 것보다 더 선호된다고 믿는다. 디바이스 활용이 덜 포화되고 \\(m/p\\)가 상대적으로 큰 일부 실험에서 미생물 배치 크기가 2배인 ZB-1p는 ZB-2p보다 약간 더 이상 증가할 수 있다.\n' +
      '\n' +
      '애플리케이션믹스 G ILP 공식입니다.\n' +
      '\n' +
      '파이프의 모든 통과는 \\(i,j,c)\\에 의해 고유하게 인덱싱될 수 있으며, 여기서 \\(i\\in\\{1,2,...p\\}\\)는 단계를 지수하고, \\(j\\in\\{1,2,.,\\}\\)은 마이크로매치를 지수하고, \\(c\\in\\{F,B,W\\}\\)은 미생물부치의 특정 패스를 나타낸다. 우리는 가변 \\(T_{(i,j,c)}\\)를 시간 비용으로 정의하고 \\(E_{(i,j,c)}\\)를 패스 종료 시간으로 정의한다. 우리는 패스 \\(i,j,c)에 의해 발생하는 기억 증가를 나타내기 위해 \\(\\Delta M_{(i,j,c)}\\)를 소개한다. 예를 들어, 정방향 패스가 백워드 패스에 저장된 활성화의 \\(M_{B}\\)의 순 증가로 이어지기 때문에 \\(\\Delta M_{(\\cdot,\\cdot,F)}=M_{B}\\)이다. (\\Delta M_{(\\cdot,\\cdot,B)}=M_{W}-M_{B}-M_{B}\\)은 \\(W\\)에서 요구하는 메모리를 추가하면서 \\(B\\)에 저장된 메모리를 제거한다. 마지막으로, 우리가 탐색하고자 하는 변수는 변수\\(O_{(i,j,j,c)의 패트릭(i,j{\\prime},c^{\\prime},c^{\\prime})}\\in\\{0,1\\}\\)을 소개하는 스케줄의 패스 순서이며, 이는 \\(i,j,j,c)의 패스 지수가\\(i,j{\\prime},c^{\\prime}) 전에 예정된지 여부를 나타내는 지표이다.\n' +
      '\n' +
      'E(i,j,B)\\{{(i,{{{(i,{{)}(i)\\{{(i,{{)}}(i, ai)\\{f}}(i,j)\\{f}}}<\\\\{]]\\\\[t].\n' +
      '\n' +
      '전반적으로 최적화 대상(3)은 가장 긴 단계가 지출한 시간을 최소화하는 것이다. 제약 (4) 및 (5)는 인접 단계에서 동일한 미생물군의 \\(F\\) 및 \\(B\\) 통과에 대한 순차적 종속 요구 사항을 추가한다. 또한, (6)은 스케줄링 주문의 결정에 의해 부과된 종속성 제약을 추가한다. 마지막으로, (7)은 피크 활성 메모리를 \\(M_{\\text{limit}}\\) 이하로 제한한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c} \\hline Model & \\#Stage (\\(p\\)) & \\#Microbatch (\\(m\\)) & Post-validation & All-reduce synchronization \\\\ \\hline \\hline\n' +
      '1.5B & 8 & 24 & **14.5** & 13.11 \\\\ \\hline\n' +
      '6.2B & 8 & 24 & **4.32** & 4.00 \\\\ \\hline\n' +
      '14.6B & 16 & 48 & **1.81** & 1.68 \\\\ \\hline\n' +
      '28.3B & 32 & 96 & **0.99** & 0.91 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 10: ZB-2p와 동기화된 ZB-2p 비교를 ZB-2p와 동기화된 ZB-2p(초당 GPU당 샘플)의 비교는 표 10: "표 10: ZB-2p와 동기화된 ZB-2p(초당 GPU당 샘플) 비교이다.\n' +
      '\n' +
      '소수에 1F1B를 사용하여 소량의 살균법에 대해 1F1B를 지정했다.\n' +
      '\n' +
      '미생물원 수(m\\)가 적으면 PP의 성질에 의해 (p\\) 단계의 수가 적으면 거품이 많이 생길 것이다. 그러나 모기 방법은 이러한 희귀 환경에서 여전히 성능을 약 20%에서 30% 증가시킬 수 있다. 통신을 무시하고 \\(m<=p\\) 및 \\(T_{W}<T_{B}\\)를 가정한 대략적인 분석에서 1F1B 반복은 \\((m+p-1)*(T_{F}+T_{B}+T_{W}\\)를 취하며, ZB 반복은 \\((m+p-1)*(T_{B} <T_{B}<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B>)*(T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B<T_{B>)*)*(T_{B<T_{B<T_{B> 실험 결과는 표 12에 나와 있으며 \\(m<=p\\) ZB-1p 및 ZB-2p가 본질적으로 동일하고 1F1B와 유사한 메모리를 소비할 때 알 수 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c|c} \\hline Model & \\(p\\) & \\(m\\) & \\(b\\) & Samples per GPU per second & Memory(GB) & Schedule \\\\ \\hline \\hline \\multirow{8}{*}{1.5B} & \\multirow{8}{*}{8} & 12 & 12.0 & 57 & 1F1B \\\\  & & & 12 & 13.0 & 61 & ZB-1p \\\\  & & & 6 & **14.5** & 59 & ZB-2p \\\\ \\cline{2-6}  & \\multirow{8}{*}{8} & 12 & 12.6 & 57 & 1F1B \\\\  & & & 12 & 13.6 & 61 & ZB-1p \\\\  & & & 6 & **14.8** & 59 & ZB-2p \\\\ \\cline{2-6}  & \\multirow{8}{*}{64} & 12 & 13.8 & 57 & 1F1B \\\\  & & & 12 & 14.4 & 61 & ZB-1p \\\\  & & & 6 & **14.9** & 59 & ZB-2p \\\\ \\hline \\multirow{8}{*}{6.2B} & \\multirow{8}{*}{8} & 6 & 3.56 & 66 & 1F1B \\\\  & & & 6 & 3.95 & 71 & ZB-1p \\\\  & & & 3 & **4.32** & 70 & ZB-2p \\\\ \\cline{2-6}  & \\multirow{8}{*}{64} & 6 & 3.76 & 66 & 1F1B \\\\  & & & 6 & 4.05 & 71 & ZB-1p \\\\  & & & 3 & **4.35** & 70 & ZB-2p \\\\ \\cline{2-6}  & \\multirow{8}{*}{64} & 6 & 4.09 & 66 & 1F1B \\\\  & & & 6 & 4.24 & 71 & ZB-1p \\\\  & & & 3 & **4.39** & 70 & ZB-2p \\\\ \\hline \\multirow{8}{*}{14.6B} & \\multirow{8}{*}{16} & 2 & 1.53 & 50 & 1F1B \\\\  & & & 2 & 1.73 & 51 & ZB-1p \\\\  & & & 1 & **1.81** & 51 & ZB-2p \\\\ \\cline{2-6}  & \\multirow{8}{*}{128} & 2 & 1.62 & 50 & 1F1B \\\\  & & & 1 & **1.83** & 51 & ZB-2p \\\\ \\cline{2-6}  & \\multirow{8}{*}{128} & 2 & 1.78 & 50 & 1F1B \\\\  & & & 2 & **1.89** & 51 & ZB-1p \\\\  & & & 1 & 1.85 & 51 & ZB-2p \\\\ \\hline \\multirow{8}{*}{28.3B} & \\multirow{8}{*}{32} & 2 & 0.81 & 72 & 1F1B \\\\  & & & 2 & 0.93 & 74 & ZB-1p \\\\ \\cline{1-1}  & & & **0.99** & 74 & ZB-2p \\\\ \\cline{1-1} \\cline{2-6}  & \\multirow{8}{*}{32} & 2 & 0.85 & 72 & 1F1B \\\\  & & & 2 & 0.96 & 74 & ZB-1p \\\\ \\cline{1-1}  & & & **1.00** & 74 & ZB-2p \\\\ \\cline{1-1} \\cline{2-6}  & \\multirow{8}{*}{256} & 2 & 0.94 & 72 & 1F1B \\\\  & & & 2 & **1.02** & 74 & ZB-1p \\\\ \\cline{1-1}  & & & 1 & 1.00 & 74 & ZB-2p \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 11: 동일한 메모리 소비하에서 1F1B, ZB-1p 및 ZB-2p 간의 비교이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c|c} \\hline Model & \\(p\\) & \\(m\\) & \\(b\\) & Samples per GPU per second & Memory(GB) & Schedule \\\\ \\hline \\hline \\multirow{4}{*}{1.5B} & \\multirow{4}{*}{8} & 2 & 6 & 3.56 & 11 & 1F1B \\\\  & & 6 & **4.25** & 12 & ZB-2p \\\\ \\cline{3-6}  & & 4 & 6 & 5.74 & 18 & 1F1B \\\\  & & 6 & **6.92** & 19 & ZB-2p \\\\ \\cline{3-6}  & & 8 & 6 & 8.26 & 29 & 1F1B \\\\  & & 6 & **9.90** & 34 & ZB-2p \\\\ \\hline \\multirow{4}{*}{6.2B} & \\multirow{4}{*}{8} & 2 & 3 & 1.04 & 21 & 1F1B \\\\  & & 3 & **1.33** & 21 & ZB-2p \\\\ \\cline{3-6}  & & 4 & 3 & 1.69 & 28 & 1F1B \\\\  & & 3 & **2.16** & 29 & ZB-2p \\\\ \\cline{3-6}  & & 8 & 3 & 2.45 & 39 & 1F1B \\\\  & & 3 & **3.07** & 44 & ZB-2p \\\\ \\hline \\multirow{4}{*}{14.6B} & \\multirow{4}{*}{16} & 4 & 1 & 0.39 & 19 & 1F1B \\\\  & & 1 & **0.52** & 20 & ZB-2p \\\\ \\cline{3-6}  & & 8 & 1 & 0.65 & 24 & 1F1B \\\\  & & 1 & **0.85** & 24 & ZB-2p \\\\ \\cline{3-6}  & & 16 & 1 & 0.95 & 32 & 1F1B \\\\  & & 1 & **1.25** & 33 & ZB-2p \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 12: 작은 수의 미생물에서 1F1B와 ZB-2p 사이의 비교이다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>