<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 옴니Pred: 유니버설 레지스터로서의 언어 모델\n' +
      '\n' +
      'Xingyou Song\\({}^{1}\\)1\n' +
      '\n' +
      'Oscar Li\\({}^{2*}\\)2\n' +
      '\n' +
      'Changoo Lee\\({}^{1}\\)\n' +
      '\n' +
      'Bangding (Jeffrey) Yang\\({}^{3}\\)\n' +
      '\n' +
      'Daiyi Peng\\({}^{1}\\)\n' +
      '\n' +
      'Sagi Perel\\({}^{1}\\)\n' +
      '\n' +
      'Yutian Chen\\({}^{1}\\)\n' +
      '\n' +
      '({}^{1}\\)Google DeepMind, \\({}^{2}\\)Carnegie Mellon University, \\({}^{3}\\)Google\n' +
      '\n' +
      '각주 1: 균등 기여. 구글 딥마인드에서 학생 연구원으로 수행한 작품{Work performed for student research in Google DeepMind}\n' +
      '\n' +
      'Code: [https://github.com/google-research/optformer/tree/main/optformer/omnipred](https://github.com/google-research/optformer/tree/main/optformer/omnipred)\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '실험 설계의 광범위한 환경에서 회귀는 일련의 매개변수가 주어진 시스템 또는 모델의 결과 메트릭을 정확하게 예측하는 강력한 도구였지만 전통적으로 특정 작업에만 적용되는 방법으로 제한되었다. 본 논문에서는 다양한 실세계 실험으로부터 \\((x,y)\\) 평가 데이터에 대한 범용 종단간 회귀자로 언어 모델을 훈련하기 위한 프레임워크인 OmniPred를 제안한다. 세계에서 가장 큰 블랙박스 최적화 데이터베이스 중 하나인 구글 비지에에서 가져온 데이터를 사용하여, 우리의 광범위한 실험은 수학적 매개변수와 값의 텍스트 표현만을 통해 언어 모델이 매우 정확한 수치 회귀가 가능하고 여러 작업에 대해 훈련할 기회가 주어지면 전통적인 회귀 모델을 크게 능가할 수 있음을 보여준다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '회귀는 하이퍼파라미터 튜닝, 컴퓨터 소프트웨어, 산업 공학 및 화학 발견과 같은 많은 영역에서 실험 설계의 기본 과제이다. 회귀의 목표는 입력 특징 집합이 주어졌을 때 일반적인 시스템의 메트릭 \\(y\\)을 예측하는 것이다. 이러한 회귀자들은 추후 오프라인 최적화(Kumar et al., 2022; Traubacco et al., 2022), 온라인 최적화(Cai et al., 2020), 저비용 벤치마킹(Zela et al., 2022; Eggensperger et al., 2015) 및 시뮬레이션(Mendis et al., 2019; Hashemi et al., 2018; Kaufman et al., 2021)과 같은 다양한 애플리케이션에 사용될 수 있다.\n' +
      '\n' +
      '최근 대규모 언어 모델(LLM)은 입력 피쳐와 출력 레이블 간의 복잡한 관계를 나타내기 위해 대규모 이종 데이터 세트에 걸쳐 텍스트 표현을 대규모로 처리하는 강력한 도구로 등장했다. LLM이 코딩(Li 등, 2022)과 같은 자연어 처리를 넘어 다양한 작업에 효과적인 것으로 나타났다는 점을 감안할 때 상징적 매테\n' +
      '\n' +
      '그림 1: 우리 방법의 개요. Google Vizier를 사용하여 최적화된 시스템에서 수집된 이질적인 오프라인 블랙박스 기능 평가를 사용하여 LM 기반 회귀자를 훈련한다.\n' +
      '\n' +
      '2022), 및 과학적 추론(Singhal et al., 2022), 의구심이 드는 것은 합리적이다: _언어 모델들이 회귀를 위해 사용될 수 있는가?_\n' +
      '\n' +
      '이 질문에 답하는 것은 전통적인 실험 설계 분야뿐만 아니라 LLM 연구의 끊임없이 변화하는 분야에서도 매우 중요하며, 특히 강화 학습 미세 조정에서 복잡한 시스템의 결과를 예측하는 능력(Gruver et al., 2023)과 보상 모델링에 대한 최근 관심으로 인해 중요하다(Ziegler et al., 2019). LLM의 텍스트 처리 능력은 입력(즉, \\(x\\))을 원시 수치 텐서로 지루하게 재구성할 필요성을 잠재적으로 우회할 수 있기 때문에 특히 매력적이다. 작업 전에 대규모 이질적인 오프라인 데이터 세트에 대해 "보편적" 메트릭 예측 변수를 훈련하는 것의 실현 가능성과 유용성을 구체적으로 다루는 그러한 연구는 없었다.\n' +
      '\n' +
      '요약하면 우리의 핵심 기여는 다음과 같다:\n' +
      '\n' +
      '* 우리가 아는 한, 우리는 일반적인 입력 공간에 적용 가능한 제약 독립적 텍스트 표현에 기초한 최초의 확장 가능하면서도 간단한 메트릭 예측 프레임워크인 OmniPred를 제안한다.\n' +
      '* 이러한 텍스트 및 토큰 기반 표현만을 통해 OmniPred는 실험 설계 데이터에 대해 매우 정확한 메트릭 예측이 가능하다.\n' +
      '* 매우 다른 입력 공간과 목표에 걸쳐 동시에 다중 작업 학습을 수행함으로써, 많은 경우에 옴니프레드는 MLP 및 부스트 트리와 같은 전통적인 회귀 모델을 능가할 수 있다.\n' +
      '* 이러한 전이 학습 혜택은 소량의 새로운 평가 데이터에 대해 OmniPred를 국부적으로 미세화한 후 보이지 않는 작업에서도 지속된다.\n' +
      '\n' +
      '##2 관련 업무 및 동기부여\n' +
      '\n' +
      '전통적인 회귀 방법은 표 데이터 설정에서 흔히 볼 수 있는 고정 길이 특징 벡터가 주어진 스칼라 목표를 예측하기 위해 가우스 프로세스(GP), 트리 기반 방법 및 다층 퍼셉트론(MLP)과 같은 통계 기술을 널리 사용했다. 멀티태스크(Bonilla et al., 2007) 및 컨텍스트(Krause and Ong, 2011) 변형은 전이 학습 목적을 위해 추가로 제안되었지만, 여전히 \\(x\\)의 고정 길이 텐서 표현을 필요로 하고, 따라서 동일한 입력 공간으로부터의 이전 \\(x\\)만을 사용할 수 있다. 딥 러닝 기반 회귀자들을 활용하는 추가적인 최근 작업들은 트랜스포머들(Hollmann et al., 2023; Huang et al., 2020), 순환 신경망들(Hashemi et al., 2018), 그래프 신경망들(Lukasik et al., 2020; Gao et al., 2023), 및 길이-독립성을 허용하는 딥-계층적 GP들(Fan et al., 2024)을 포함한다. 그럼에도 불구하고, 빈번한 이슈는 여전히 \\((x,y)\\의 _tensor representation_에 의존하는 것이다.\n' +
      '\n' +
      '텐서 표현은 각 텐서 요소가 모델에 대한 입력으로서 합리적인 수치 범위(예: \\([-1,1]\\))에 있어야 하기 때문에 본질적으로 _constraint-dependent_이다. 따라서 \\(x\\)을 표현하려면 모든 스칼라 피쳐는 사용자 제공 경계에 대해 정규화되어야 하며 모든 범주 피쳐는 사용자 제공 선택에 대해 하나의 핫이 임베딩되어야 한다. 새로운 경계 또는 추가 범주와 같은 동적이지만 작은 입력 공간 변경이 이 정적 표현과 호환되지 않습니다. \\(y\\)을 표현하려면 \\(\\mathbb{R}\\)의 원시 목적도 정규화되어야 하며, 이는 특이치 \\(y\\) 값을 만날 때 테스트 시간에 문제가 될 수 있다. 이 문제를 처리하면 복잡한 비선형 워핑(다이몬, 2011; 여 및 존슨, 2000)이 구현되며, 이들 중 다수는 또한 데이터 종속적이다(예를 들어, 트레이닝 데이터로부터 최소/최대 값을 저장해야 함).\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{|c|c|c|c|c|} \\hline Regressor & Dynamic Input Spaces? & Can Multitask? & Normalize \\(x\\)? & Normalize \\(y\\)? \\\\ \\hline MLP & No & Only fixed spaces & Yes & Yes \\\\ \\hline Tree-based & No & Only fixed spaces & Yes & **No** \\\\ \\hline Gaussian Process (GP) & No & Only fixed spaces & Yes & Yes \\\\ \\hline GNN / Transformer / RNN & No & Only fixed domains & Yes & Yes \\\\ \\hline OmniPred (Ours) & **Yes** & **Yes** & **No** & **No** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 다른 전형적인 회귀 변수의 유연성 간의 비교.\n' +
      '\n' +
      '원칙적으로 이상적인 회귀자는 외부 통계 또는 검색 제약 조건의 변경과 무관하게 절대 용어로 \\(x\\) 및 출력 \\(y\\)을 모두 처리해야 한다. 예를 들어, 목적식이 \\(f(x)=\\exp(x)\\이라면, \\(f(2)\\)에 대한 회귀자의 예측은 제약식이 \\(x\\in[1,5]\\) 또는 \\(x\\in[0,100]\\이더라도 불변해야 한다. 이를 달성하기 위한 한 가지 방법은 데이터의 _token 기반 representation_를 통해 이루어지며, 이는 대신 토큰들 또는 심볼들에 의해 이산적으로 파싱된다(Zhou et al., 2023). 이는 가변 길이 입력 및 추가 컨텍스트 메타데이터를 다룰 때 많은 양의 전송성을 즉시 잠금 해제한다.\n' +
      '\n' +
      '이 토큰 기반 패러다임은 인간 피드백(Ziegler et al., 2019)으로부터 강화 학습의 경우 큰 성공을 보여주었으며, 여기서 텍스트 응답에 대한 회귀(_reward modelling_)는 ChatGPT(OpenAI, 2022) 및 Bard(Thoppilan et al., 2022)와 같은 최근 대화형 LLM의 성공에 결정적이었다. 여기서, LLM은 쌍별 순위("\\(y\\)") 또는 확률적 점수(\\(y\\in[0,1]\\)(브래들리와 테리, 1952)의 형태로 인간의 등급을 모방할 수 있다.\n' +
      '\n' +
      '현재의 압도적인 초점은 창의성, 안전성, 인성과 같은 측면을 결정하는 데 필요한 주관적인_인간 기반_ 피드백에 있었지만, 실험 설계에 공통되는 복잡하고 자연스러운 시스템을 평가하기 위한 언어 모델에 대해서는 훨씬 더 많은 관심을 기울이지 않았으며, 이는 \\(y\\in\\mathbb{R}\\)의 보다 객관적이고 숫자 기반 데이터로 구성된다. 언어 모델들(Hendrycks et al., 2021; Nogueira et al., 2021)에서 수치 처리의 브리튼성과 불신뢰성을 보여준 다수의 작업들을 고려할 때, 언어 모델들이 토큰 기반 표현들에 비해 고정밀 수치 예측이 가능하다는 것은 즉시 명백하지 않다. 이것은 우리의 논문이 범용 예측자를 찾기 위해 해결하는 중요한 기술적 과제이다.\n' +
      '\n' +
      '## 3 Methodology\n' +
      '\n' +
      '### 예비 및 문제 정의\n' +
      '\n' +
      '표준 블랙박스 최적화 용어(Golovin et al., 2017; Liaw et al., 2018)를 기반으로 주어진 과제 \\(\\mathcal{T}=(\\mathcal{X},f,\\mathcal{D},m)\\)에 대해, 우리는 (잠재적인) 입력 공간 \\(\\mathcal{X}\\)에서 선택된 제안 \\(x\\)의 평가로부터 _trials_\\(x,y)\\을 얻는 고유한 목적 함수 \\(f:\\mathcal{X}\\rightarrow\\mathbbb{R}\\)이 있다고 가정한다. 우리는 _study_를 시행(\\(\\mathcal{D}=\\{(x_{1},y_{1}),...,(x_{T},y_{T})\\}\\)의 오프라인 집합으로 정의한다. 서로 다른 태스크들을 구별하기 위해, 추가적으로 태스크를 특성화할 수 있고 잠재적으로 대응하는 목적 \\(f(x)\\)의 행동을 기술할 수 있는 관찰가능한 태스크-레벨 메타데이터 \\(m\\)이 존재할 수 있다.\n' +
      '\n' +
      '표준 메트릭 예측의 목표는 \\(s:\\mathcal{X}\\rightarrow\\mathcal{P}(\\mathbb{R})\\)의 분포함수 \\(s:\\mathcal{X}\\rightarrow\\mathcal{P}(\\mathbb{R})\\)를 구하는 것이다. 특히, 다중 작업 학습 데이터\\(\\cup\\{\\mathcal{D}^{train}_{1},\\mathcal{D}^{train}_{2},...\\}\\)를 사용하여 언어 모델을 제공한다. (\\{\\mathcal{T}_{1},\\mathcal{T}_{2},...\\}\\). 이러한 외부 작업은 당면한 \\(f\\)에 대한 정확한 평가를 포함하지 않고 심지어 다른 입력 공간을 가질 수 있지만, 이러한 추가 외부 데이터에 대한 훈련은 특히 유사한 작업에 대한 전달성을 여전히 초래할 수 있다.\n' +
      '\n' +
      '예측 변수(결정론적 또는 확률론적)의 정확도를 측정하는 공통적이고 통일적인 방법은 회귀자 종속 집계자 \\(\\alpha:\\mathcal{P}(\\mathbb{R})\\rightarrow\\mathbb{R}\\)를 사용하여 최종 점별 예측 간의 차이를 실제 객관적 값에 대해 계산하는 것이다. 그러나 연구마다 객관적인 척도(예: CIFAR10 정확도는 \\([0,1]\\) 이내, 합성목적은 \\([10^{2},10^{9}]\\) 이내)가 크게 다를 수 있기 때문에 연구당 통계량(예: 특정 과제에 대한 통계량)에 따라 차이를 정규화해야 하므로 연구 오차를 정규화된 평균 절대 오차(MAE: Normalized Mean Absolute Error)로 정의한다.\n' +
      '\n' +
      '\\frac{1}{y_{\\max}-y_{\\min}\\frac{1}{|\\mathcal{D}^{test}|}\\sum_{(x,y)\\in\\mathcal{D}^{test}|\\alpha(s(x)-y|\\tag{1}\\\n' +
      '\n' +
      '이상치 예측이 평균 오차에 크게 변동하는 것을 방지하기 위해, 회귀자가 단순히 \\(\\{y_{\\min},y_{\\max}\\})의 경계값을 출력할 때와 동등한 \\(1.0\\)의 클리핑 오차를 추가한다.\n' +
      '\n' +
      '### Language Model\n' +
      '\n' +
      '본 논문에서는 표준 다중 태스크 회귀 설정(standard multi-task regression setting, \\((x,y)\\) 및 태스크 레벨 메타데이터 \\(m\\)에 대해 프롬프트는 \\((x,m)\\)이고 응답은 \\(y\\)으로 인코더-디코더 및 디코더 전용 설정과 호환된다. 단순화를 위해, 우리는 표준 200M 파라미터 T5 인코더-디코더(Raffel et al., 2020) **from scratch**를 트레이닝한다. 우리는 임의의 과제\\(\\mathcal{T}\\)이 주어졌을 때 예측인자\\(s_{\\theta}(\\cdot)\\)을 형성하는데 사용될 수 있는 가중치\\(\\theta\\)의 단일 집합을 학습하고자 한다. (1) 각 태스크에 대해 별도의 모델\\(\\theta_{t}\\)을 학습해야 하는 전통적인 회귀(\\mathcal{D}_{t}\\) 또는 (2) 상황 내 학습을 위한 전문화된 시험 토큰화에 걸쳐 완전히 평가된 궤적을 필요로 하는 설정(Chen et al., 2022; Hollmann et al., 2023)과 달리, 우리의 설정은 훈련 데이터의 사용을 최대화하며, 그 중 많은 부분이 미완성 궤적 또는 비표준 \\(x\\) 형식을 포함할 수 있다.\n' +
      '\n' +
      '** 표현:** 여러 이종 연구에 대한 단일 모델의 훈련을 용이하게 하기 위해 앞서 언급한 바와 같이 중요한 지침 원칙은 입력 공간과 특정 연구의 숫자 스케일링과 무관하게 \\(x\\) 및 \\(y\\)을 _absolute_ 방식으로 표현하는 것이다. 따라서, 우리는 \\(x\\)을 _key-value_ 형식으로 표현하고, 파라미터 이름을 값에 직접 매핑하지만, **not**는 입력 공간 \\(\\mathcal{X}\\)을 표현하여 조건부 파라미터와 동적 제약조건을 일반화 할 수 있다. 우리는 부호, 지수 및 유효 자릿수를 표현하기 위해 특정 토큰을 사용하여 토큰 로짓 제한을 통해 적절한 디코딩을 보장하기 위해 **고정 길이 맞춤 토큰**으로 \\(y\\)을 나타낸다. 다른 토큰화에 대한 삭제는 부록 A.1에서 수행됩니다.\n' +
      '\n' +
      '각주 1: 코드 검색과 같은 응용 프로그램에서는 가능한 모든 프로그램의 공간을 표현하는 것조차 불가능하다.\n' +
      '\n' +
      '**Training:** 단순성과 정규화-독립성을 유지하기 위해, 우리는 일반적인 언어 모델 훈련과 일치하는 \\(y\\)-값 토큰에 대한 표준 교차 엔트로피 손실을 최소화한다. 따라서 모델은 학습 데이터로부터 암묵적으로 숫자 거리를 학습할 것이다.\n' +
      '\n' +
      '** 샘플링 및 디코딩:** 정규 온도 디코딩을 통해 \\(\\hat{y}\\sim s_{\\theta}(x)\\)을 반복적으로 샘플링하여 \\(\\mathbb{R}\\)에 정의된 기본 분포를 근사화할 수 있다. 강한 특이치에 강건하게 유지하기 위해, 부록 A.2의 서로 다른 집계 방법에 대한 삭제와 함께 경험적 중앙값을 사용하여 샘플을 집계한다. 모델은 입력 공간의 보이지 않는 영역에 대해 예측해야 할 수 있으므로, 샘플링된 \\(\\hat{y}\\)의 농도와 디코딩된 모든 토큰에 대한 특정 로그 확률을 관찰함으로써 모델의 불확실성을 평가할 수 있다.\n' +
      '\n' +
      '로컬 Finetuning:** 보이지 않는 태스크\\(\\mathcal{T}_{u}\\)에 적응하기 위해, 모델은 태스크들의 대응하는 트레이닝 데이터\\(\\mathcal{D}_{u}^{train}\\)에 걸쳐 더 빠르게 Finetuning될 수 있다. 이것은 회귀자 유도 검색 동안 일반적인 요구 사항이며, 온라인 기능 평가가 예를 들어 위스투바 및 그라보카(2021)에서 고려되어야 한다. Finetuning은 또한 모델이 특정 연구에 대해 완전히 최적화되지 않은 경우, 예를 들어 사전 훈련 데이터 세트가 너무 큰 경우, 보이는 데이터에 다시 초점을 맞추는 데 도움이 될 수 있다.\n' +
      '\n' +
      '## 4 Data\n' +
      '\n' +
      '### Vizier Format\n' +
      '\n' +
      '위의 3.1절의 추상화는 블랙박스와 하이퍼파라미터 최적화를 위한 연구 인터페이스인 Open Source Vizier(Song et al., 2022)에서 구체적으로 구현된다. 모든 공간\\(\\mathcal{X}\\)은 연관된 값을 갖는 _parameters_, 타입 DOUBLE, INTEGER, DISCRETE, 또는 CATEGORICAL의 리스트에 의해 정의된다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c} \\hline \\hline  & Language Model Textual Representation \\\\ \\hline \\(x\\) & batch\\_size:128,kernel:’rbf’,learning\\_rate:0.5,model:’svm’,optimizer:’sgd’ \\\\ \\hline \\(m\\) & title:’classification’,user:’some-person’,description:’spam detection’, objective:’accuracy’ \\\\ \\hline \\(y\\) & \\(<\\)+\\(>\\)\\(<\\)1\\(>\\)\\(<\\)2\\(>\\)\\(<\\)3\\(>\\)\\(<\\)E-2\\(>\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: OmniPred. \\ (<\\)*\\(>\\)은 단일 커스텀 토큰을 나타낸다. 입력 공간과 \\(x\\)는 그림 2와 같다. 실시예 \\(y\\) 토큰화는 1.23의 값을 나타낸다.\n' +
      '\n' +
      'set. 모든 파라미터는 또한 잠재적으로 _child 파라미터_일 수 있으며, 대응하는 부모 파라미터가 특정 값일 때만 활성이다(예를 들어, 부모 범주형 파라미터가 "Adam"을 선택하는 경우에만 "베타"가 활성이지만, "SGD"는 아니다). 한 예가 도 2에 도시되어 있다.\n' +
      '\n' +
      '작업 수준 메타데이터 \\(m\\)는 제목, 소유자 사용자 이름, 설명, 목적 이름 및 선택적 자유 형식 텍스트로 구성됩니다. Vizier API는 사용자를 위한 최적화 서비스를 제공하는 것을 의미하기 때문에, 사용자별 설정으로 인해 많은 전송의 원천이 있을 수 있다. 이들은,\n' +
      '\n' +
      '* 단일 사용자 또는 팀이 정기적으로 유사한 실험을 튜닝합니다.\n' +
      '* 다수의 상이한 사용자가 유사한 실험(예를 들어, CIFAR10 상의 트레이닝 ResNets)을 튜닝한다.\n' +
      '* 상이한 실험들(예를 들어, "학습 속도")에 걸쳐 사용되는 유사한 파라미터들.\n' +
      '* 목적함수의 성질을 설명하는 메타데이터 \\(m\\)\n' +
      '\n' +
      '### Datasets\n' +
      '\n' +
      '**BBOB(Shifted):** 합성 데이터 세트를 생성하고 온라인 평가를 수행할 수 있는 정밀한 제어 실험을 위해, 우리는 바닐라\\(f(x)\\)을 \\(f(x-c)\\)으로 변환하기 위해 랜덤 도메인 시프트 \\(c\\)을 적용하고 \\([2,6]\\)에 걸쳐 차원을 범위로 하여 BBOB 벤치마크의 다중 작업 버전을 생성한다(ElHara et al., 2019). 따라서 각 과제\\(\\mathcal{T}\\)는 제어 가능한 \\(m=\\)(함수 클래스, 차원, 시프트)에 의해 매개변수화되며, 해당 목표는 \\(f(x,m)\\)으로 볼 수 있어 보이지 않는 \\(m\\)에 대한 평가가 가능하다. 특정 과제\\(\\mathcal{T}_{i}\\)에 대해, 우리는 학습 내 학습 데이터_크기\\(\\mathcal{D}_{i}^{train}\\)을 최소화하지만, 학습 간 학습 데이터\\(\\{\\mathcal{D}_{j}^{train}\\{j\\neqi}\\)은 다른 과제\\(\\{\\mathcal{T}_{j}\\}_{\\neqi}\\)에서 자유롭게 가변한다. 따라서 단일(\\mathcal{D}_{i}^{train}\\)에서만 훈련할 수 있는 전통적인 회귀자(예: MLP)는 이러한 제한된 데이터 조건에서 해당 \\(f_{i}\\)를 회귀하는 데 어려움을 겪을 것이다. 대조적으로, LM은 기능이 \\(f_{i}\\)과 유사성을 공유하는 다른 작업의 시도를 볼 수 있기 때문에 더 잘 수행할 수 있다.\n' +
      '\n' +
      '**Real World Data:** 풍부한 다양한 태스크를 포함하는 실제 세계 데이터에 대한 메트릭 예측을 조사하기 위해, 우리는 자연스럽게 Google Vizier(Golovin et al., 2017)의 데이터베이스를 사용할 것이다. 평평한 입력 공간에서 완전히 완료된 궤적에 대한 훈련에만 국한되지 않기 때문에 데이터 사용은 표 3에서 볼 수 있듯이 OptFormer(Chen et al., 2022) 훈련을 위한 750K 연구보다 훨씬 크다.\n' +
      '\n' +
      'Vizier는 블랙박스 최적화를 위한 경량 서비스 역할만 하기 때문에 대부분의 경우 실제 목적 \\(f(x)\\)에 대한 온라인 액세스가 없다.\n' +
      '\n' +
      '그림 2: Google Vizier에서 (아마도 내포된) 공간과 제안 \\(x\\)의 일반적인 예.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c} Property & Statistic \\\\ \\hline \\# Studies & \\(\\mathcal{O}\\)(70M+) \\\\ \\# Trials & \\(\\mathcal{O}\\)(120B+) \\\\ \\# Distinct Users & \\(\\mathcal{O}\\)(14K) \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 구글 비지에 데이터베이스에 대한 관련 통계. 우리는 예를 들어 "합법적인" 연구 또는 시험을 정의하는 다양한 방법이 있을 수 있으므로 주문 추정치를 제공한다. 자세한 내용은 부록 D를 참조하십시오.\n' +
      '\n' +
      '우리는 데이터 샘플들만을 \\(\\mathcal{D}\\)을 사용하여 예측자의 정확도를 평가해야 한다. 따라서 우리는 작업에서 높은 정확도를 달성하기 어려운 공간\\(\\mathcal{D}_{train}\\)을 얼마나 충분히 커버하는지 고려해야 한다. 영향 인자는 다음을 포함한다:\n' +
      '\n' +
      '* 시험 횟수: 사용자가 튜닝을 중단할 시기를 결정할 수 있고, 따라서 연구의 크기는 \\(10^{0}\\)에서 \\(10^{5}\\) 정도일 수 있다.\n' +
      '* 시행의 다양성: 기본적으로 연구의 시행 \\(\\{(x_{1},y_{1}),...,(x_{T},y_{T})\\}\\)은 최적화 루프의 궤적을 형성하며, 따라서 이후 시행은 단일 국소 최적으로 수렴할 수 있다.\n' +
      '* 공간 크기: 공간의 근사 카디널리티 \\(\\mathcal{X}\\)는 \\(\\exp(\\text{parameter count})\\)이므로, 큰 입력 공간은 자연스럽게 덜 탐색될 것이다.\n' +
      '\n' +
      '우리는 (1) 연구당 최대 초기 시험 한도를 설정하고 (2) 시험을 무작위로 섞은 다음 (3) 고정된 열차/검증/시험 분할 비율(기본값 0.8/0.1/0.1)을 결정하는 것과 같은 실용적인 처리 단계를 적용하지만, 각 \\(\\mathcal{D}\\)이 공간을 포화하는지 또는 본질적으로 작업이 얼마나 "쉬운"지를 완전히 제어할 수 없다. 대신에, 우리는 과제 난이도의 프록시 메트릭으로 \\(\\mathcal{D}^{train}\\)에만 훈련된 기초선 회귀자를 사용하고 해당 \\(\\mathcal{D}^{test}\\)에 대해 평가한다.\n' +
      '\n' +
      '## 5 Experiments\n' +
      '\n' +
      '우리는 다음과 같은 핵심 질문에 답한다.\n' +
      '\n' +
      '1. 서로 다른 입력 공간과 객관적인 스케일의 여러 작업에서 동시에 퇴행할 수 있는가?\n' +
      '2. 다중 작업 훈련에 대한 이점이 있고 텍스트 신호가 전이 학습에 유용한가?\n' +
      '3. 미세 조정은 사전 훈련 세트 외부에서 보이지 않는 연구보다 정확도를 향상시킬 수 있는가?\n' +
      '\n' +
      '부록 A는 옴니프레드의 기능에 대한 추가 삭제를 포함한다. 부록 B와 C는 각각 언어 모델 및 베이스라인 구현에 대한 세부 사항을 포함한다.\n' +
      '\n' +
      '### Simultaneous Regression\n' +
      '\n' +
      '그림 3에서 BBOB 훈련 모델이 매우 다른 객관적인 척도의 분석 기능의 전체 모양을 높은 정밀도로 캡처하는 방법을 시각적으로 제시한다. 또한, 모델은 ID 예측 샘플을 통해 불확실성 추정치를 표현할 수 있다.\n' +
      '\n' +
      '그림 3: 선택된 4D 시프트된 BBOB 함수들 위의 모델 예측 샘플들. 경험적 모드(볼드) 및 min/max는 10개의 샘플에서 표시된다. 모든 BBOB 함수에서 우리는 좌표값 \\(x_{i}\\)을 변화시키면서 다른 \\(x_{j\\neq i}\\)을 고정시킨다.\n' +
      '\n' +
      '그림 4에서 실제 데이터를 통해 훈련된 모델에 대해 구글에서 내부적으로 조정된 목표를 대표하는 크게 다른 입력 공간을 가진 손으로 선택한 연구보다 유사한 시각화를 제시한다. 여기에는 표준 기계 학습(예: 이미지 분류 및 언어 모델링), 생산 시스템(예: 구글 입찰 시뮬레이션, LLM 추론 지연), 과학적 연구(예: 단백질 및 하드웨어 설계)가 포함된다.\n' +
      '\n' +
      '### Multi-task Transferrability\n' +
      '\n' +
      '이 하위 섹션에서는 평가되는 작업에서 훈련 데이터만 관찰하는 "단일 작업" 회귀자(부록 C에 설명됨)와 달리 다른 유사하지만 비등가 작업에서 얻은 지식을 사용하여 특정 작업에 대한 학습 전달 능력, 즉 정확도를 향상시키는 모델의 능력을 보여준다.\n' +
      '\n' +
      '그림 5에서 우리는 훈련에서 볼 수 있는 더 많은 작업으로 모델의 정확도가 향상되고 결국 모든 전통적인 기준선을 능가한다는 것을 분명히 알 수 있다. 구글에서 발견된 AutoML 연구의 경우 오류가 발견된 연구의 고정된 하위 집합에서 평균화된다. BBOB의 경우, 훈련 중에 발생하지 않는 새로운 변화가 있는 보이지 않는 작업에 대해 평가함으로써 메타데이터 \\(m\\)(x\\)에 비해 모델의 연구 간 일반화 기능을 추가로 입증할 수 있다.\n' +
      '\n' +
      '도 4: **Left:** Diagonal fit(_l_)이 더 좋다. 모델의 예측 대. 다양한 연구에 대한 배경 진리 목표 목표. 기업별 객관적인 이름이 수정되었습니다. **Right:** 대응 입력 공간. "#-H, $-T"는 # 루트 파라미터 및 $ 가능한 총 파라미터를 갖는 조건부 입력 공간에 대해 속기된다.\n' +
      '\n' +
      '그림 5: 아래(\\(\\downarrow\\))가 더 좋다. 훈련에 사용된 다양한 연구의 양(로그 척도)을 변경할 때 모델의 평균 연구 예측 오류. 색상 수평 선에는 단일 작업 기준선 오류가 표시됩니다.\n' +
      '\n' +
      '모델이 텍스트 단서를 읽어 전이 학습을 수행하고 있는지 확인하기 위해 표 4에서 연구 종속 해시 함수를 사용하여 데이터를 "익명화"한 경우와 결과를 비교한다. BBOB의 경우 원래 표시된(함수 클래스, 차원, 시프트) 메타데이터\\(m\\)을 해시합니다. AutoML의 경우 매개 변수 이름과 문자열 값을 해시합니다. 각 연구는 여전히 고유하게 식별되고 훈련될 수 있지만 모델은 더 이상 일반적인 텍스트 단서로부터 유용한 상관 관계를 관찰할 수 없다. 흥미롭게도 모델은 데이터가 너무 크고 이질적인 경우인 전체 익명화된 BBOB 데이터 세트에 대해 훈련하지 못한다.\n' +
      '\n' +
      '그림 6에서 우리는 모델의 경우 다중 작업 훈련이 단일 작업 훈련에 비해 일관되게 개선되고 훈련 데이터에서 입력 공간 포화도가 상대적으로 낮은 체제에서 다중 작업 모델이 여러 다른 도메인에서 전통적인 기준선을 능가한다는 것을 추가로 볼 수 있다. 흥미롭게도 처음부터 훈련된 단일 작업 모델은 경쟁적인 선택으로 남아 있으며 특정 도메인에 대해서는 다른 모든 단일 작업 기준선을 능가할 수도 있다.\n' +
      '\n' +
      '### Finetuning Analysis\n' +
      '\n' +
      '우리는 먼저 미세조정이 유익할 수 있는 조건을 조사한다. 표 5에서 우리는 AutoML 연구를 통해 다양한 사전 훈련된 모델을 세분화한다. 데이터에서 AutoML 모델을 다시 미세 조정하는 데 이점이 없지만, 전체 Vizier 데이터 세트에 대해 사전 훈련된 모델은 사전 훈련된 AutoML 모델과 동일한 수준의 정확도로 미세 조정할 수 있는 반면 BBOB 사전 훈련된 모델은 단일 작업 모델보다 훨씬 더 나쁜 결과를 초래한다는 것을 알 수 있다. 이는 사전 훈련에서 얻은 지식이 AutoML과 같은 특정 도메인에 대한 전이성에 큰(긍정적 또는 부정적) 영향을 미칠 수 있음을 시사한다.\n' +
      '\n' +
      '또한, 본 연구에서는 보이지 않는 태스크, 즉 원래 트레이닝 세트가 스크래핑된 후 새로 생성된 태스크에 대한 평가를 통해 이러한 효과를 살펴보고, 새로운 사용자 및 목표의 연구를 포함할 수 있다. 도\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c} \\hline  & \\multicolumn{2}{c}{Mean Study Error (\\(\\downarrow\\))} \\\\ Datasets (\\# Training Studies) & Original & Anonymized \\\\ \\hline BBOB (50K) & **0.03** & 0.46 \\\\ BBOB (Full 1M) & **0.01** & FAIL \\\\ AutoML (26.3K) & **0.19** & 0.44 \\\\ AutoML (Full 540K) & **0.15** & 0.43 \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 하부((\\(\\downarrow\\))가 더 좋다. BBOB-Shifted 및 AutoML 테스트 시행 전반에 걸쳐 원본 데이터와 익명화된 데이터에 대해 훈련된 모델 간의 비교. “FAIL”은 모델이 훈련조차 하지 못했다는 것을 의미한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c} \\hline  & \\multicolumn{2}{c|}{Mean Study Error (\\(\\downarrow\\)) on AutoML} \\\\ Pretraining Dataset & Before Finetuning & After Finetuning \\\\ \\hline None (Single-Task) & 0.98 & 0.20 \\\\ BBOB & 0.98 & 0.45 \\\\ AutoML & **0.15** & **0.15** \\\\ Entire Vizier & 0.31 & **0.15** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 하한(\\(\\downarrow\\))이 더 좋다. 사전 훈련된 모델과 해당 미세 조정 버전의 평균 연구 오류.\n' +
      '\n' +
      '도 6: **Left:** Lower(\\(\\downarrow\\))이 더 좋다. 다른 도메인에 걸쳐 오류를 집계합니다. ** 오른쪽:** 도메인에 대한 통계. 속기 표기법: "TpS" = 연구당 트라이얼, "SS" = 공간 크기, 괄호(\\(\\#\\), \\(\\$\\))를 사용하여 조건부 공간을 \\(\\#\\) 루트 매개변수와 \\(\\$\\) 가능한 총 매개변수로 나타냅니다.\n' +
      '\n' +
      '도 7을 참조하면, 이전 비지어 데이터에 대한 사전 훈련된 모델과 처음부터 초기화를 비교한다(단일 작업 훈련으로 이어짐). 사전 훈련에서 얻은 지식이 새로운 작업에 대해 크게 이전하고 예측을 도울 수 있음을 알 수 있지만, 세 가지 연구에서 왼쪽에서 볼 수 있듯이 부정적인 이전 사례는 거의 없다.\n' +
      '\n' +
      '## 6 Conclusion\n' +
      '\n' +
      '우리의 옴니프레드 프레임워크는 매우 다른 입력 공간과 응용 프로그램에서 모든 규모의 목표에 대해 고정밀 예측을 수행할 수 있는 범용 회귀자를 향한 첫 번째 단계이다. 간단하고 확장 가능한 설계는 많은 양의 오프라인 다양한 평가에서 전이 학습을 허용하는 반면, 단일 작업 변형은 여전히 다양한 금 표준 기준선에 대해 경쟁적으로 수행할 수 있다. 또한, 이전 데이터에서 지식을 전달하면서 미세 조정을 통해 보이지 않는 데이터에 적응할 수 있다. 이 연구는 실험 설계 분야에서 새로운 잠재적 확장을 흥미롭게 하기 위한 토대를 제시한다.\n' +
      '\n' +
      '도 7: **Left:** Lower(\\(\\downarrow\\))이 더 좋다. 보이지 않는 스터디에 대한 예제 LM 스터디 오류는 랜덤한 별개의 사용자에 대해 필터링되었습니다. **오른쪽:** 보이지 않는 연구 1000개 이상의 다른 방법에 대한 비교를 집계합니다.\n' +
      '\n' +
      '##7 한계와 향후 작업\n' +
      '\n' +
      '**환각:** 모델에 대략 모든 \\(\\mathbb{R}\\)에 걸쳐 \\(y\\)-값을 샘플링할 수 있는 자유도를 부여함으로써, 엄청나게 부정확한 이상치 예측이 이제 가능하다. 이는 상당한 플로트 토큰(예를 들어, 리딩 디지트 또는 지수)에 대한 잘못된 예측에 의해 악화될 수 있다. 편의를 위해 모든 부동 토큰이 동일한 중요도를 갖는 비가중 교차 엔트로피 손실을 사용했지만, 더 중요한 토큰에 가중치를 부여함으로써 예측 정확도를 향상시킬 수 있어 학습 손실이 \\(\\mathbb{R}\\) 이상의 수치 거리를 더 잘 인식하게 한다.\n' +
      '\n' +
      '즉시-측면 숫자 토큰화:** 이 작업에서 우리는 LLM 문헌과 일치하도록 \\(x\\)에서 기본 인간 판독 가능한 형식으로 숫자 매개변수 값을 직접 표현했다. 이것은 차선책일 수 있는데, 이는 대응하는 토큰들이 정확히 디지트 단위로 디지트되지 않을 수 있기 때문이다(예를 들어, SentencePiece 토큰화는 토큰 {\'12\', 3\', 4.5\'}로 이어진다). 대신에 \\(y\\)-값(예: \\(<\\)+\\(>\\)\\(<\\)1\\(>\\)\\(<\\)2\\(>\\)\\(<\\)3\\(<\\)3\\(<\\)4\\(>\\)E0\\(>\\) 또는 텍스트 공간에서 \'[1 10e2 2 10e1 3 10e0 4 10e-1 ]\'과 같이 원자적으로 숫자를 강조하는 다른 직렬화를 사용하여 사용자 지정 토큰화를 잠재적으로 재사용할 수 있다.\n' +
      '\n' +
      '**Pretrained English Encoder:** \\(x\\)는 영어 단어를 포함하는 파라미터 이름 및 메타데이터를 포함하기 때문에, 영어 텍스트에 미리 훈련된 모델로부터 웜 스타트하는 것은 정확도를 향상시킬 수 있다. 그러나 T5-small 및 T5-medium과 같은 모델의 크기(\\(<\\)1B 파라미터)와 유사한 대부분의 체크포인트는 실험 데이터에 대해 사전 훈련되지 않으며 \'learning_rate\'와 같은 수치적 의미를 이해하지 못할 것이다. 또한, 사전 훈련된 영어 모델을 사용할 때 고려해야 할 수많은 혼란스러운 기술적 선택(예: 인코더를 동결할지, 학습 속도를 조정할지, 추가 맞춤형 플로트 토큰을 내장할지, \\(x\\) 및 \\(m\\)의 더 많은 영어 기반 표현을 사용할지)이 있지만, 이 주제는 향후 추구할 가치가 있다. 이 작업에서 우리는 비교적 작은 모델을 처음부터 훈련하는 것이 여전히 회귀를 달성할 수 있다는 것을 이미 발견했으며, 따라서 영어 이해 없이도 우리의 기술의 광범위한 적용 가능성을 시사한다.\n' +
      '\n' +
      '**계산 비용:** 전통적인 기준선과 비교하여, 언어 모델은 가속기 사용을 필요로 하며, 더 높은 추론 시간 외에도 훈련 및 미세 조정 모두에 대해 상대적으로 더 높은 계산 비용을 갖는다. 본 연구에서는 학습용 GPU가 최대 8개, 추론용 GPU가 1개인 \\(\\approx\\)220M 파라메터를 사용하여 비용을 최소화하도록 모형을 설계하였다.\n' +
      '\n' +
      '**기타 입력 공간:** Vizier API는 주로 하이퍼파라미터 튜닝 공간에 중점을 둡니다. 전통적으로 조합론이나 그래프와 같은 더 복잡한 공간은 회귀자를 형성하기 위해 정교한 모델링 기술이 필요하며, 주로 \\(x\\)을 텐서로 표현하는 데 어려움이 있다. 또한, 이러한 프로그램 합성과 같은 표현 불가능한 공간을 가진 많은 응용 프로그램은 전통적으로 퇴보하는 것이 불가능하다. 우리는 텍스트와 토큰 기반 표현이 매우 유망하며 이전에 실험 설계 분야에서 탐구되지 않은 도메인에 널리 적용 가능하다고 믿는다.\n' +
      '\n' +
      '**기타 메타데이터:** \\(m\\) 및 매개변수 이름을 익명화한 삭제를 수행했지만 예측에 특히 유용한 메타데이터 유형에 대해 더 많은 조사가 이루어질 수 있다. 이러한 메타데이터는 neural architecture search를 위한 Jacobian Covariance(Mellor et al., 2021) 및 neural-network norms(Jiang et al., 2020)과 같은 이전의 도메인-특정 작업들에 의해 소개된 _proxy metrics_를 포함할 수 있다. 기계 학습 또는 프로그래밍 작업을 구현하는 관련 _code_는 특히 중요할 수 있다.\n' +
      '\n' +
      '## Acknowledgements\n' +
      '\n' +
      '올리브에 바켐, 하도 반 하셀트, 존 점퍼, 에이비럴 쿠마르, 잉지 마오, 세바스티안 노오진, 망포 포틸림타나, 지왕, 스콧 야크, 아미르 야즈단바흐쉬 등 유익한 토론과 지속적인 지원에 감사드립니다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Bonilla et al. (2007) Edwin V Bonilla, Kian Chai, and Christopher Williams. 다중 작업 가우시안 프로세스 예측. In _Advances in Neural Information Processing Systems_, Volume 20, 2007.\n' +
      '* Bradley and Terry (1952) Ralph Allan Bradley and Milton E. Terry. 불완전 블록 설계의 순위 분석: I. 쌍을 이루는 비교 방법. _ Biometrika_, 39(3/4):324-345, 1952. ISSN 00063444. URL[http://www.jstor.org/stable/2334029](http://www.jstor.org/stable/2334029).\n' +
      '* Cai et al. (2020) Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, and Song Han. 모든 경우: 하나의 네트워크를 훈련하고 효율적인 배치를 위해 특수화합니다. _8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020_. OpenReview.net, 2020. URL[https://openreview.net/forum?id=HylxE1HKwS](https://openreview.net/forum?id=HylxE1HKwS)이다.\n' +
      '* 차튼(2022) 프랑수아 차튼. 변압기가 있는 선형 대수학 트랜스 마흐 배워 Res._ , 2022, 2022. URL[https://openreview.net/forum?id=Hp4g7FAXXG](https://openreview.net/forum?id=Hp4g7FAXXG).\n' +
      '* Chen et al. (2022) Yutian Chen, Xingyou Song, Chansu Lee, Zi Wang, Richard Zhang, David Dohan, Kazuya Kawakami, Greg Kochanski, Arnaud Doucet, Marc\'Aurelio Ranzato, Sagi Perel, and Nando de Freitas. 변압기를 사용하여 범용 하이퍼파라미터 최적화기를 학습합니다. _NeurIPS_, 2022. URL[http://papers.nips.cc/paper_files/paper/2022/hash/cf6501108fced72ee5c47e2151c4e153-Abstract-Conference.html](http://papers.nips.cc/paper_files/paper/2022/hash/cf6501108fced72ee5c47e2151c4e153-Abstract-Conference.html)에서,\n' +
      '* 다이몬(2011) 다카시 다이몬. 복스 콕스 변신 _Miodrag Lovric(ed.), International Encyclopedia of Statistical Science_, pp. 176-178. Springer, 2011. doi: 10.1007/978-3-642-04898-2_152. URL[https://doi.org/10.1007/978-3-642-04898-2_152](https://doi.org/10.1007/978-3-642-04898-2_152)\n' +
      '* d\'Ascoli et al. (2022) Stephane d\'Ascoli, Pierre-Alexandre Kamienny, Guillaume Lample, and Francois Charton. 반복 시퀀스에 대한 깊은 기호 회귀입니다. _ CoRR_, abs/2201.04600, 2022. URL[https://arxiv.org/abs/2201.04600](https://arxiv.org/abs/2201.04600).\n' +
      '* Eggensperger et al. (2015) Katharina Eggensperger, Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. 대리인을 통한 하이퍼파라미터 최적화기의 효율적인 벤치마킹 Blai Bonet and Sven Koenig(eds.), _Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30, 2015, Austin, Texas, USA_, pp. 1114-1120. AAAI Press, 2015. doi: 10.1609/AAAI.V29I1.9375. URL[https://doi.org/10.1609/aaai.v29i1.9375](https://doi.org/10.1609/aaai.v29i1.9375)\n' +
      '*EilHara et al. (2019) Ouassim Ait ElHara, Konstantinos Varelas, Duc Manh Nguyen, Tea Tusar, Dimo Brockhoff, Nikolaus Hansen, and Anne Auger. COCO: 대규모 블랙박스 최적화 벤치마킹(bbob-largescale) 테스트 제품군. _ ArXiv_, abs/1903.06396, 2019.\n' +
      '* Fan et al.(2024) Zhou Fan, Xinran Han, Zi Wang. 이종 검색 공간에서 베이지안 최적화를 위한 전이 학습 Transactions on Machine Learning Research_, 2024. ISSN 2835-8856. URL[https://openreview.net/forum?id=emXh4M7YH](https://openreview.net/forum?id=emXh4M7YH).\n' +
      '* Gao et al. (2023) Yanjie Gao, Xianyu Gu, Hongyu Zhang, Haoxiang Lin, and Mao Yang. 그래프 신경망을 이용한 딥러닝 모델의 실행시간 성능 예측 _45th IEEE/ACM International Conference on Software Engineering: Software Engineering in Practice, SEIP@ICSE 2023, Melbourne, Australia, May 14-20, 2023_, pp. 368-380. IEEE, 2023. doi: 10.1109/ICSE-SEIP58684.2023.00039. URL[https://doi.org/10.1109/ICSE-SEIP58684.2023.00039](https://doi.org/10.1109/ICSE-SEIP58684.2023.00039](https://doi.org/10.1109/ICSE-SEIP58684.2023.00039)\n' +
      '* Ghahramani et al. (2019) Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John Karro, and D. Sculley. 구글 비지에: 블랙박스 최적화를 위한 서비스. In _Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, NS, Canada, August 13 - 17, 2017_, pp. 1487-1495. ACM, 2017. doi: 10.1145/3097983.3098043. URL[https://doi.org/10.1145/3097983.3098043](https://doi.org/10.1145/3097983.3098043)\n' +
      '* Gruver et al. (2023) Nate Gruver, Marc Finzi, Shikai Qiu, and Andrew Gordon Wilson. 대형 언어 모델은 제로샷 시계열 예측 변수입니다. _ CoRR_, abs/2310.07820, 2023. doi: 10.48550/ARXIV.2310.07820. URL[https://doi.org/10.48550/arXiv.2310.07820](https://doi.org/10.48550/arXiv.2310.07820).\n' +
      '* Hashemi et al. (2018) Milad Hashemi, Kevin Swersky, Jamie A. Smith, Grant Ayers, Heiner Litz, Jichuan Chang, Christos Kozyrakis, and Parthasarathy Ranganathan. 메모리 액세스 패턴을 학습합니다. Jennifer G. Dy and Andreas Krause(eds.), _Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmassan, Stockholm, Sweden, July 10-15, 2018_, volume 80 of _Proceedings of Machine Learning Research_, pp. 1924-1933. PMLR, 2018. URL[http://proceedings.mlr.press/v80/hashemi18a.html](http://proceedings.mlr.press/v80/hashemi18a.html).\n' +
      '* Havasi et al. (2021) Marton Havasi, Rodolphe Jenatton, Stanislav Fort, Jeremiah Zhe Liu, Jasper Snoek, Balaji Lakshminarayanan, Andrew Mingbo Dai, and Dustin Tran. 강력한 예측을 위해 독립적인 서브네트워크를 훈련합니다. _9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021_. OpenReview.net, 2021. URL[https://openreview.net/forum?id=0Gg9XnKxFAH](https://openreview.net/forum?id=0Gg9XnKxFAH)이다.\n' +
      '* Hendrycks et al. (2021) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. MATH 데이터 세트를 사용하여 수학적 문제 해결을 측정하는 중입니다. Joaquin Vanschoren and Sai-Kit Yeung (eds.), _Proceedings of Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual_, 2021. URL[https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db77\n' +
      '* Hollmann et al. (2023) Noah Hollmann, Samuel Muller, Katharina Eggensperger, and Frank Hutter. Tabpfn: 작은 표 분류 문제를 1초 만에 해결하는 변압기. _The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net, 2023. URL[https://openreview.net/pdf?id=cp5Pvc16w8_](https://openreview.net/pdf?id=cp5Pvc16w8_)\n' +
      '* Huang et al. (2020) Xin Huang, Ashish Khetan, Milan Cvitkovic, and Zohar S. 카르닌 Tabtransformer: 문맥 임베딩을 이용한 Tabular 데이터 모델링_ CoRR_, abs/2012.06678, 2020. URL[https://arxiv.org/abs/2012.06678](https://arxiv.org/abs/2012.06678).\n' +
      '* Jiang et al. (2020) Yiding Jiang, Behnam Neyshabur, Hossein Mobahi, Dilip Krishnan, and Samy Bengio. 환상적인 일반화 방안과 그것들을 어디서 찾을 수 있을까. _8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020_. OpenReview.net, 2020. URL[https://openreview.net/forum?id=SJgIPJBFvH](https://openreview.net/forum?id=SJgIPJBFvH)이다.\n' +
      '* Kaufman et al. (2021) Samuel J. Kaufman, Phitchaya Mangpo Phothilimthana, Yanqi Zhou, Charith Mendis, Sudip Roy, Amit Sabne, and Mike Burrows. 텐서 프로세싱 유닛들에 대한 학습된 성능 모델. Alex Smola, Alex Dimakis, and Ion Stoica(eds.), _Proceedings of Machine Learning and Systems 2021, MLSys 2021, virtual, April 5-9, 2021_. mlsys.org, 2021. URL[https://proceedings.mlsys.org/paper/2021/hash/85d8ce590ad8981ca2c8286f79f59954-Abstract.html](https://proceedings.mlsys.org/paper/2021/hash/85d8ce590ad8981ca2c8286f79f59954-Abstract.html).\n' +
      '* 크라우스와 옹(2011) 안드레아스 크라우스와 쳉 옹. 맥락적 가우시안 프로세스 대역 최적화. In _Advances in Neural Information Processing Systems_, 2011.\n' +
      '* Krause et al. (2018)Taku Kudo and John Richardson. 문장: 신경 텍스트 처리를 위한 단순하고 언어 독립적인 서브워드 토큰화기와 디토키나이저. In _Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations_, pp. 66-71, 2018.\n' +
      '* Kumar et al. (2022) Aviral Kumar, Amir Yazdanbakhsh, Milad Hashemi, Kevin Swersky, and Sergey Levine. 하드웨어 가속기를 설계하기 위한 데이터 기반 오프라인 최적화 10차 국제학술대회에서는 ICLR 2022, Virtual Event, April 25-29, 2022_. OpenReview.net, 2022. URL[https://openreview.net/forum?id=GsH-K1VYyY](https://openreview.net/forum?id=GsH-K1VYyY).\n' +
      '* 2022년 12월 9일_, 2022년.\n' +
      '* Li et al. (2022) Yujia Li, David H. Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Remi Leblond, Tom Eccles, James Keeling, Felix Kimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d\'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. 알파벳 코드와 경쟁 레벨 코드 생성. _ CoRR_, abs/2203.07814, 2022. doi: 10.48550/ARXIV.2203.07814. URL[https://doi.org/10.48550/arXiv.2203.07814](https://doi.org/10.48550/arXiv.2203.07814)\n' +
      '* Liaw et al. (2018) Richard Liaw, Eric Liang, Robert Nishihara, Philipp Moritz, Joseph E. Gonzalez, and Ion Stoica. Tune: 분산 모델 선택 및 교육을 위한 연구 플랫폼_ CoRR_, abs/1807.05118, 2018. URL[http://arxiv.org/abs/1807.05118](http://arxiv.org/abs/1807.05118).\n' +
      '* 42nd DAGM German Conference, DAGM GCPR 2020, Tubingen, Germany, 9월 28일\n' +
      '- October 1, 2020, Proceedings_, volume 12544 of _Lecture Notes in Computer Science_, pp. 188-201. Springer, 2020.\n' +
      '* Mellor et al.(2021) Joe Mellor, Jack Turner, Amos J. Storkey, and Elliot J. Crowley. 훈련 없이 신경망 아키텍처를 검색합니다. Marina Meila and Tong Zhang(eds.), _Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event_, volume 139 of _Proceedings of Machine Learning Research_, pp. 7588-7598. PMLR, 2021. URL[http://proceedings.mlr.press/v139/mellor21a.html](http://proceedings.mlr.press/v139/mellor21a.html).\n' +
      '* Mendis et al. (2019) Charith Mendis, Alex Renda, Saman P. Amarasinghe, and Michael Carbin. Ithemal: 심층 신경망을 이용한 정확하고, 휴대가능하며, 빠른 기본 블록 처리량 추정. Kamalika Chaudhuri and Ruslan Salakhutdinov(eds.), _Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA_, volume 97 of _Proceedings of Machine Learning Research_, pp. 4505-4515. PMLR, 2019. URL[http://proceedings.mlr.press/v97/mendis19a.html](http://proceedings.mlr.press/v97/mendis19a.html).\n' +
      '* Nogueira et al. (2021) Rodrigo Frassetto Nogueira, Zhiying Jiang, and Jimmy Lin. 간단한 연산 작업을 통해 변압기의 한계를 조사합니다. _ CoRR_, abs/2102.13019, 2021. URL[https://arxiv.org/abs/2102.13019](https://arxiv.org/abs/2102.13019).\n' +
      '* Nogueira et al. (2021)OpenAI. 채팅팅을 소개합니다. 2022년\n' +
      '* Raffel et al. [2020] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. _J. Mach. Learn. Res._, 21:140:1-140:67, 2020. URL [http://jmlr.org/papers/v21/20-074.html](http://jmlr.org/papers/v21/20-074.html).\n' +
      '* Singhal et al. [2022] Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Kumar Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Nathaneal Scharli, Aakanksha Chowdhery, Philip Andrew Mansfield, Blaise Aguera y Arcas, Dale R. Webster, Gregory S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun Liu, Alvin Rajkomar, Joelle K. Barral, Christopher Semturs, Alan Karthikesalingam, and Vivek Natarajan. Large language models encode clinical knowledge. _CoRR_, abs/2212.13138, 2022. doi: 10.48550/ARXIV.2212.13138. URL [https://doi.org/10.48550/arXiv.2212.13138](https://doi.org/10.48550/arXiv.2212.13138).\n' +
      '* Song et al. [2022] Xingyou Song, Sagi Perel, Chansoo Lee, Greg Kochanski, and Daniel Golovin. Open source vizier: Distributed infrastructure and API for reliable and flexible blackbox optimization. In Isabelle Guyon, Marius Lindauer, Mihaela van der Schaar, Frank Hutter, and Roman Garnett (eds.), _International Conference on Automated Machine Learning, AutoML 2022, 25-27 July 2022, Johns Hopkins University, Baltimore, MD, USA_, volume 188 of _Proceedings of Machine Learning Research_, pp. 8/1-17. PMLR, 2022. URL [https://proceedings.mlr.press/v188/song22a.html](https://proceedings.mlr.press/v188/song22a.html).\n' +
      '* Thoppilan et al. [2022] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera y Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. Lamda: Language models for dialog applications. _CoRR_, abs/2201.08239, 2022. URL [https://arxiv.org/abs/2201.08239](https://arxiv.org/abs/2201.08239).\n' +
      '* Trabucco et al. [2022] Brandon Trabucco, Xinyang Geng, Aviral Kumar, and Sergey Levine. Design-bench: Benchmarks for data-driven offline model-based optimization. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), _International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA_, volume 162 of _Proceedings of Machine Learning Research_, pp. 21658-21676. PMLR, 2022. URL [https://proceedings.mlr.press/v162/tabucco22a.html](https://proceedings.mlr.press/v162/tabucco22a.html).\n' +
      '* 위스투바와 그라보카[2021] 마틴 위스투바와 요시프 그라보카. 심층 커널 대용치를 이용한 소수 샷 베이지안 최적화 arXiv preprint arXiv:2101.07667_, 2021.\n' +
      '* Yeo and Johnson[2000] In-Kwon Yeo and Richard A. Johnson. 정규성 또는 대칭성을 개선하기 위한 새로운 거듭제곱 변환군 _ Biometrika_, 87(4):954-959, 2000. ISSN 00063444. URL[http://www.jstor.org/stable/2673623](http://www.jstor.org/stable/2673623)\n' +
      '* Zela et al. [2019] Arber Zela, Julien Niklas Siems, Lucas Zimmer, Jovita Lukasik, Margret Keuper, and Frank Hutter. Surrogate NAS benchmarks: Going beyond the limited search spaces of tabular NAS benchmarks. In _TheTenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022._ OpenReview.net, 2022. URL [https://openreview.net/forum?id=OnpFa95RVqs](https://openreview.net/forum?id=OnpFa95RVqs).\n' +
      '* Zhou et al. [2023] Qi-Le Zhou, Han-Jia Ye, Le-Ye Wang, and De-Chuan Zhan. Unlocking the transferability of tokens in deep models for tabular data. _CoRR_, abs/2310.15149, 2023. doi: 10.48550/ARXIV.2310.15149. URL [https://doi.org/10.48550/arXiv.2310.15149](https://doi.org/10.48550/arXiv.2310.15149).\n' +
      '* Ziegler et al. [2019] Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul F. Christiano, and Geoffrey Irving. Fine-tuning language models from human preferences. _CoRR_, abs/1909.08593, 2019. URL [http://arxiv.org/abs/1909.08593](http://arxiv.org/abs/1909.08593).\n' +
      '\n' +
      '## 부록 A 모델 어블레이션\n' +
      '\n' +
      '우리는 모델의 예측 정확도에 영향을 미치는 특정 설정과 시나리오를 축소한다.\n' +
      '\n' +
      '### \\(y\\)-Tokenization\n' +
      '\n' +
      '사용자 지정 토큰을 사용하여 플로트(예를 들어, 123.4)를 나타내는 여러 가능한 방법이 있다. (Charton, 2022; Nogueira et al., 2021; d\'Ascoli et al., 2022)로부터의 예들을 사용하여, 다음의 것들은 모두 가능한 표현들이다:\n' +
      '\n' +
      '*(Default) Separate Sign and Digit-by-Digit: \\(<\\)\\(+\\)\\(>\\)\\(1\\)\\(>\\)\\(<\\)\\(2\\)\\(>\\)\\(<\\)\\(2\\)\\(<\\)\\(3\\)\\(<\\)\\(3\\)\\(<\\)\\(4\\)\\(>\\)\\(<\\)E-\\(2\\)\\(>\\)\\(2\\)\\(>\\)\n' +
      '* Merged Mantissa: \\(<\\)\\(+\\)\\(234\\)\\(>\\)\\(<\\)E-\\(2\\)\\(>\\)\n' +
      '* 가수전 지수: \\(<\\)\\(+\\)\\(>\\)\\(<\\)E-\\(2\\)\\(>\\)\\(<\\)\\(1\\)\\(>\\)\\(<\\)\\(2\\)\\(<\\)\\(2\\)\\(<\\)\\(3\\)\\(>\\)\\(<\\)\\(4\\)\\(>\\)\n' +
      '\n' +
      '표 6에서 이러한 토큰화 차이는 큰 학습 데이터(예: 다중 작업)에서는 중요하지 않지만, 낮은 데이터 체제(예: 단일 작업)에서는 매우 중요하다는 것을 알 수 있다. "Merged Mantissa"를 사용한 부정확한 정확도는 18K 가능한 가수 토큰 간의 차이를 학습하기 위해 많은 양의 데이터를 필요로 하기 때문에 특히 명백하다.\n' +
      '\n' +
      '샘플링의### 효과\n' +
      '\n' +
      'LM은 지수 토큰 또는 유효 자릿수에 대한 부정확한 예측으로 인해 \\(y\\)-예측에서 극단적인 이상치를 출력할 수 있다. 이러한 문제는 모델이 태스크(예: BBOB)에서 거의 완벽하게 퇴보한 후에는 발생하지 않지만, 사소한 오류가 있는 사실적인 태스크(예: AutoML)에서 자주 발생하므로 수정을 위한 기술이 필요하다.\n' +
      '\n' +
      '오차를 줄이는 한 가지 분명한 방법은 샘플 카운트를 증가시키는 것이다:\n' +
      '\n' +
      '집계 방법을 추가로 비교하여 중앙값을 사용하는 것이 최대값보다 상당히 우수하다는 것을 확인합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c|c c} \\hline \\hline  & \\multicolumn{2}{c}{AutoML} & \\multicolumn{2}{c}{BBOB} \\\\ Tokenization Method & Single-Task & Multi-Task & Single-Task & Multi-Task \\\\ \\hline Default & 0.21 & 0.15 & 0.17 & 0.01 \\\\ Merged Mantissa & 0.73 & 0.15 & 0.41 & 0.01 \\\\ Exponent Before Mantissa & 0.24 & 0.15 & 0.17 & 0.01 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 상이한 토큰화 방법들 간의 평균 연구 오차(\\(\\downarrow\\)) 비교.\n' +
      '\n' +
      '그림 8: 아래(\\(\\downarrow\\))가 더 좋다. 추론 중 사용된 표본을 변경할 때 평균 연구 오류(로그 척도)입니다.\n' +
      '\n' +
      '가능성 및 평균. 우리는 이것이 상대적으로 높은 확률로 발생할 수 있고 평균을 왜곡할 수 있는 환각 이상치 샘플에 대한 중위수의 견고성 때문이라고 가정한다.\n' +
      '\n' +
      '### Uncertainty\n' +
      '\n' +
      '우리 작업 전반에 걸쳐 사용되는 주요 메트릭은 점별 예측을 기반으로 하지만 회귀자에 대한 중요한 능력은 정확한 예측을 제공할 수 없을 때 불확실성을 표현하는 것이다. 이는 불확실성을 탐사 프록시로 사용할 수 있는 베이지안 최적화와 같은 응용 분야에서 특히 유용하다. 이 섹션에서는 이러한 목적으로 모델을 보정하거나 조정하지 않더라도 모델이 불확실성을 정량화할 수 있는지 여부를 조사한다.\n' +
      '\n' +
      '우리는 무작위로 부호가 뒤집힌 BBOB 목표에 대해 모델을 훈련할 때 그림 9에서 다중 모드 분포를 비모수적으로 표현하는 LM의 능력을 입증하는 것으로 시작한다. 대조적으로, 앙상블된 MLP(Havasi et al., 2021) 및 가우시안 프로세스 혼합물(Bonilla et al., 2007)과 같은 전통적인 방법은 혼합물 카운트를 선험적으로 지정해야 한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c} \\hline \\hline  & \\multicolumn{2}{c}{Mean Study Error (\\(\\downarrow\\))} \\\\ Empirical Aggregation Method & AutoML (Full 540K) & BBOB (Full 1M) \\\\ \\hline Median (default) & **0.15** & 0.01 \\\\ Max-likelihood & 0.22 & 0.01 \\\\ Mean & 0.23 & 0.01 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: 하한(\\(\\downarrow\\))이 더 좋다. 64개의 샘플을 사용할 때 다른 샘플 집계 방법을 비교합니다.\n' +
      '\n' +
      '그림 9: 논문의 주요 섹션에서 그림 3과 유사하지만 이중성을 갖는 설정.\n' +
      '\n' +
      '또한 각 연구에서 불확실성과 오차의 상관관계를 측정하였다. 표 8에서 우리는 연구 전반에 걸친 평균 상관 관계를 보고한다. 흥미롭게도 표 7은 LM 샘플에 대한 평균 집계가 중위수 집성보다 예측에 더 나쁘다는 것을 보여주었지만 오류는 샘플의 표준 편차와 잘 상관되어 있다.\n' +
      '\n' +
      '### 순위 및 상관 메트릭\n' +
      '\n' +
      '비록 본 논문은 가장 유익한 점적 예측에 초점을 맞추고 있지만, 우리는 우리의 예측을 순위 기반 메트릭으로 사소하게 부트스트랩할 수 있으며, 이는 \\(y\\)-스케일에 불가지론적인 진화 알고리즘에 대한 다운스트림 사용일 수 있다. 우리는 일반적으로 다중 작업 LM이 일반적으로 경쟁 순위 메트릭을 유지한다는 것을 안다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c|c c} \\hline \\hline  & & Pearson, Kendall-Tau, Spearman Correlation (\\(\\uparrow\\)) \\\\ Regressor & Uncertainty Metric & AutoML & BBOB \\\\ \\hline Gaussian Process & Predicted SD & 0.254, 0.230, 0.307 & 0.018, 0.068, 0.048 \\\\ LM w/ mean aggregation & Sample SD & 0.560, 0.487, 0.625 & 0.360, 0.366, 0.454 \\\\ LM w/ median aggregation & Harrell-Davis SE & 0.525, 0.412, 0.539 & 0.360, 0.293, 0.380 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: (\\(\\uparrow\\))이 높을수록 좋다. 정량화된 불확실성(SD = 표준 편차, SE = 표준 오차)과 10회 이상의 시험 시행(모든 BBOB 연구 및 641 AutoML 연구)에 대한 실제 오차 사이의 순위 상관 관계\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c c c c c c c} \\hline \\hline  & & & \\multicolumn{4}{c}{Kendall-Tau, Spearman Correlation (\\(\\uparrow\\))} \\\\ Regressor & BBOB & Bid Simulation & Google-AML & IniT2Winit & Protein Design & V-AML (Tab) & V-AML (Text) \\\\ \\hline Gaussian Process & 0.69, 0.80 & 0.80, 0.91 & 0.04, 0.06 & 0.15, **0.81** & 0.35, 0.43 & -0.03, -0.05 & 0.30, 0.39 \\\\ Random Forest & 0.59, 0.75 & 0.71, 0.84 & 0.45, 0.57 & 0.55, 0.67 & 0.40, 0.52 & 0.56, 0.71 & 0.29, 0.38 \\\\ Tree & 0.60, 0.74 & **0.82, 0.93** & 0.37, 0.48 & 0.59, 0.71 & 0.44, 0.57 & 0.55, 0.70 & 0.28, 0.36 \\\\ MLP & 0.63, 0.76 & 0.73, 0.85 & 0.37, 0.49 & 0.53, 0.63 & 0.47, 0.60 & 0.50, 0.64 & 0.25, 0.34 \\\\ Single-task LM & 0.01, 0.01 & 0.19, 0.28 & 0.21, 0.28 & 0.05, 0.08 & 0.15, 0.20 & 0.18, 0.24 & 0.11, 0.16 \\\\ Multi-task LM & **0.92, 0.96** & 0.70, 0.84 & **0.61, 0.73** & **0.65, 0.74** & **0.72, 0.81** & **0.57, 0.72** & **0.49, 0.58** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 9: (\\(\\uparrow\\))이 높을수록 좋다. 서로 다른 회귀 변수와 작업에 걸쳐 메트릭 순위를 매깁니다.\n' +
      '\n' +
      '#스터디 사이즈 대. 다중 작업 이득\n' +
      '\n' +
      '직관적으로, 태스크의 공간이 시도로 더 포화됨에 따라, 단일 태스크 트레이닝은 정확한 예측을 위해 더 충분해진다. 그림 10에서 이 가설을 검증하기 위해 단일 작업 MLP 기준선에 대한 다중 작업 LM 훈련의 이득을 표시한다. 이득은 대략 \\(\\approx 50\\) 훈련 시행에서 최대가 되며 훈련 시행 횟수가 증가함에 따라 감소한다. 작업의 구조를 식별하기 위해서는 아마도 _some_ 훈련 시험이 여전히 필요하기 때문에 최대 이득은 \\(\\approx 0\\) 시험에서 발생하지 않는다.\n' +
      '\n' +
      '도 10: 더 높게(\\(\\uparrow\\))가 더 좋다. 개별 AutoML 작업에 비해 MLP와 다중 작업 LM 간의 오류 차이를 연구합니다. 백분위수는 x축을 적절하게 비닝한 후 계산됩니다.\n' +
      '\n' +
      'Model Details\n' +
      '\n' +
      '### Pretraining\n' +
      '\n' +
      '우리는 오픈소스 코드베이스[https://github.com/google-research/t5x](https://github.com/google-research/t5x)에서 찾을 수 있는 T5X(Raffel et al., 2020)를 사용하여 모델을 사전 훈련시켰다. 대부분 디폴트된 중요한 하이퍼파라미터는 다음과 같다:\n' +
      '\n' +
      '* Architecture size: 12 encoder layer, 12 decoder layer, 12 head, 64 head dimension, 768 embedding dimension, 2048 MLP dimension.\n' +
      '* Optimizer: 기초 학습률 0.01 및 제곱근 감쇠를 갖는 Adafactor. 배치 크기 256\n' +
      '* 어휘 및 토큰화기: \\(y\\)-객관들을 나타내기 위한 커스텀 토큰들 이외에 32000개의 서브워드 토큰들의 어휘를 갖는 SentencePiece 토큰화기(Kudo and Richardson, 2018).\n' +
      '* 조기 정지: 최대 100만 단계 동안 훈련하지만, 과적합이 검출되면 유효성 검사 손실에 기초하여 조기 정지한다.\n' +
      '\n' +
      '모델(\\(\\approx\\) 200M 매개변수)은 4x4 TPU V2를 사용하여 사전 훈련되었다.\n' +
      '\n' +
      '### Local Training\n' +
      '\n' +
      '지역 교육 동안 데이터는 단일 연구의 제한된 시험(최대 1000개)에서만 조달된다. 학습 세트 크기는 배치 크기(256)보다 낮을 수 있으므로, 우리는 하나의 에포크를 학습 데이터를 한 번 보는 것으로 정의해야 한다. 즉, 학습 크기\\(\\leq\\) 배치 크기인 경우 하나의 그래디언트 단계만 보고 그렇지 않은 경우 여러 그래디언트 단계를 정의해야 한다.\n' +
      '\n' +
      '일관성을 위해 사전 훈련에서 동일한 설정을 사용하지만 최대 30시대를 허용합니다. 조기 중단을 위해 이제 샘플링된 배치가 아닌 전체 유효성 검사 세트에 대해 유효성 검사 손실을 측정합니다. 추가적인 구체적인 변경들은:\n' +
      '\n' +
      '* ** 단일 작업 훈련:** 모델은 무작위로 초기화되기 때문에 사전 훈련 중에 발생하는 초기 학습 속도와 일치하는 \\(10^{3}\\)의 더 큰 일정한 학습 속도를 사용한다.\n' +
      '* **Finetuning:** 체크포인트로부터 최적기 상태(예를 들어, 운동량 파라미터를 포함함)에 추가하여 가중치를 다시 로드한다. 우리는 훈련 후기에 일반적으로 접하는 \\(\\mathcal{O}(10^{-4})\\보다 10배 낮은 \\(10^{-5}\\)의 작은 고정 학습률을 사용한다.\n' +
      '\n' +
      '작은 훈련 세트와 상대적으로 낮은 미세 조정 단계로 인해 단일 1x1 TPU V2를 사용했다.\n' +
      '\n' +
      '### Inference\n' +
      '\n' +
      '추론 시간에는 1.0의 온도로 온도 샘플링을 수행하고, 로짓은 \\(y\\)-값을 표현하기 위한 사용자 지정 부동 소수점 토큰만 디코딩하도록 제한한다. 1x1 TPU V2에 대한 배치 크기를 최대화하기 위해 64개의 샘플을 생성하고 컴퓨팅 오류 시 이러한 부동 소수점 샘플의 경험적 중앙값을 최종 예측으로 선택한다.\n' +
      '\n' +
      'ABLE]\n' +
      '\n' +
      '## 부록 C 기준 상세\n' +
      '\n' +
      '###izier 입력공간\n' +
      '\n' +
      '상기 공간은 ParameterConfig들의 리스트로서 정의되며, 이들 각각은 네 개의 프리미티브들 중 하나이다:\n' +
      '\n' +
      '* DOUBLE: 탐색 범위 \\([l,u]\\)을 지정한다.\n' +
      '* DISCRETE: \\(\\mathbb{R}\\)의 유한 서브세트를 지정한다.\n' +
      '* INTEGER: 정수 범위 \\([l,u]\\)을 지정한다.\n' +
      '* CATEGORICAL: 문자열 집합을 지정합니다.\n' +
      '\n' +
      '숫자(DOUBLE, DISCRETE 및 INTEGER) 파라미터들은 선택적인 로그 또는 역-로그 스케일링을 특정할 수 있다. 로그 스케일링은 학습 속도를 조정하기 위해 가장 일반적으로 사용된다.\n' +
      '\n' +
      'Flat Space를 위한### 데이터 처리\n' +
      '\n' +
      '_flat space_는 연구의 모든 시도에서 공간에 구성된 모든 매개변수를 지정하는 것이다. 이 경우, 우리는 파라미터를 단위 하이퍼큐브 \\([0,1]^{d}\\)로 변환한다. 숫자 매개변수의 경우 (역)-로그 스케일링이 구성되지 않는 한 기본적으로 선형 스케일링을 사용하여 모든 값을 \\([0,1]\\) 범위로 스케일링한다. CATEGORICAL 파라미터의 경우, 우리는 원-핫 인코딩을 사용한다.\n' +
      '\n' +
      '조건부 공간을 위한### 데이터 처리\n' +
      '\n' +
      '_conditional space_는 한 파라미터의 값에 따라 다른 파라미터가 블랙박스 함수에 의해 사용되지 않을 수 있는 경우이다. 조건 공간은 일반적으로 오토ML 설정에서 나타나는데, 여기서 다른 모델 클래스는 튜닝할 다른 매개변수 세트를 필요로 한다. 또 다른 일반적인 사용 사례는 로그 척도에서 숫자 하이퍼파라미터를 최적화하고 싶지만 검색에 0(예: 탈락률, 정규화 계수), 즉 \\(\\texttt{UNUSED}\\}\\cup[l,u]\\)을 포함하는 경우이다.\n' +
      '\n' +
      '범주형 매개변수의 경우, 우리는 하나의 핫 인코딩에 대해 어휘 외 차원을 추가하기만 하면 된다.\n' +
      '\n' +
      '숫자 매개변수의 경우, 먼저 평평한 공간에서와 동일한 스케일링을 사용하여 매개변수 값을 NaN(\\cup[0,1]\\)으로 변환하지만 모든 UNUSED를 NaN으로 매핑한다. 그런 다음 다음과 같이 정의된 사용자 정의 계층(매개 변수당 하나씩)을 추가합니다.\n' +
      '\n' +
      'cases}v_{p}&\\text{if $x$ is NaN},\\\\x&\\text{otherwise}\\end{cases}\\\n' +
      '\n' +
      '여기서 \\(v_{p}\\)는 나머지 모델과 함께 훈련되는 파라미터이다.\n' +
      '\n' +
      '### Regressor Baselines\n' +
      '\n' +
      '**Gaussian Process:** GP Regressor 모델은 [https://github.com/google/vizier](https://github.com/google/vizier)에서 Open Source Vizier를 찾은 GP-Bandit 구현에서 나온 것으로 다음과 같이 구성된다.\n' +
      '\n' +
      '*\\(\\alpha\\sim\\text{TruncatedLogNormal}\\)은 Matern5/2 커널의 진폭을 제어한다.\n' +
      '*\\(\\lambda_{i}\\sim\\text{TruncatedLogNormal}\\)(i.i.d. for each dimension \\(i\\))는 \\(i\\)번째 차원에 대한 길이 척도를 제어한다.\n' +
      '*\\(\\sigma\\sim\\text{TruncatedLogNormal}\\)는 가우시안 잡음을 제어한다.\n' +
      '*\\(z\\sim\\text{Normal}(0,\\sigma)\\)는 관측 잡음이다.\n' +
      '*\\(f\\sim\\text{GP}(\\lambda,\\alpha)\\)는 함수이다.\n' +
      '*\\(y\\sim f(x)+z\\)는 잡음 함수이다.\n' +
      '\n' +
      '이 알고리즘은 L-BFGS를 이용하여 \\(\\alpha,\\lambda\\)와 \\(\\sigma\\)의 MAP 추정치를 구한다.\n' +
      '\n' +
      '여기서 한 가지 주의사항은 이 모델은 관측치에 대한 비선형 전처리가 필요하며 따라서 전처리된 공간에서 \\(y\\)을 예측한다는 것이다. 이 전처리는 다양한 가치 범위를 가진 비지어 연구에 걸쳐 안정적인 회귀를 달성하는 데 중요한 것으로 확인되었다. 전처리는 비선형이기 때문에 닫힌 형태로 원시 관측치에 대한 예측 분포를 얻을 수 없다. 대신 GP에서 1000개의 샘플을 채취하고 전처리기의 역수를 적용한 후 평균을 취한다.\n' +
      '\n' +
      '**Tree and Random Forest:** XGBoost([https://github.com/dmlc/xgboost](https://github.com/dmlc/xgboost])에서 발견되는 표준 API(XGBRegressor, XGBRFRegressor)를 사용한다.\n' +
      '\n' +
      '**다층 퍼셉트론:**베이스 아키텍처는 최종 스칼라 출력을 갖는 은닉 크기 256의 2-레이어 ReLU 밀집 네트워크로 구성된다. \\ (y\\)-값은 tf.keras.layers.Normalization을 사용하여 정규화되고, 훈련 데이터에서 경험적으로 계산된 표준 편차로 평균과 나눈다. 학습률\\(10^{-2}\\), 100 에폭 이상의 전체 배치 학습 및 평균 제곱 오차를 사용하여 Adam 최적화기를 사용하여 훈련을 수행했다.\n' +
      '\n' +
      '구글비즈어 데이터\n' +
      '\n' +
      '### Study Preprocessing\n' +
      '\n' +
      '구글 비지에(Google Vizier)는 사용자가 평가를 제어하는 서비스이기 때문에 원시 연구 데이터의 상당 부분이 상당히 혼란스러울 수 있다. 우리는 데이터를 훈련 및 평가에 더 도움이 되도록 특정 전처리 기술을 적용한다.\n' +
      '\n' +
      '**잘못된 시도 제거:** 사용자는 제안된 \\(x\\)을 무시하거나 평가하지 못할 수 있습니다. 또한, 일부 시도 동안, \\(y\\)-객관성은 특별한 "불가능" 값으로 표시될 수 있다(예를 들어, 높은 배치 크기가 GPU 아웃-메모리 또는 학습과 마주친 NaN으로 이어지는 경우). 이러한 시도는 추후 작업에서 불가능함을 지원하기 위해 \\(y\\)-토큰화를 확장할 수 있지만 작업에서 고려 대상에서 제외한다.\n' +
      '\n' +
      '**시험 횟수 하드 한계:** 일부 원시 연구는 데이터 분포를 지배할 수 있는 \\(10^{5}\\) 시험 이상의 시험을 포함할 수 있다. 따라서 우리는 하드한계를 적용하고 연구당 첫 번째 \\(10^{3}\\) 시험만을 고려한다.\n' +
      '\n' +
      '**특정 사용자를 필터링:**특정 인간 및 자동화된 "파워 사용자"가 있으며, 이는 평균 사용자보다 수십 배 더 많은 연구를 생성한다. 특히 일부 자동 사용자는 Vizier의 사용과 관련된 자동 단위 테스트일 뿐이다. 이러한 사용자가 데이터 배포를 지배하는 것을 방지하기 위해 이러한 사용자의 연구를 무시한다.\n' +
      '\n' +
      '### 실제 세계 데이터 기술\n' +
      '\n' +
      '**(전체) 전체 데이터베이스:** 필터가 적용되지 않았습니다. 데이터베이스의 모든 연구는 2023년 3월 31일에 수출되었으며, 보이지 않는 연구를 포함하는 파인튜닝 실험은 이 날짜 이후에 생성된 연구로 구성된다.\n' +
      '\n' +
      '**입찰 시뮬레이션:** 구글의 입찰 시뮬레이터 중 하나에 대한 하이퍼파라미터를 포함한다. 시뮬레이터는 비용, 노출, 클릭 및 변환 볼륨과 같은 주요 측정 기준 측면에서 광고가 어떻게 수행되었을 수 있는지 추정합니다.\n' +
      '\n' +
      '**구글 오토ML(내부):** Vertex AI 오토ML의 구글 내부 버전. Vertex AI AutoML과 다른 입력 공간과 다른 ML 파이프라인 구현을 사용합니다.\n' +
      '\n' +
      '**Init2Winit:** 최적화 및 튜닝 실험(예: CIFAR10 상의 ResNets, LM1B 상의 Transformers)에 특히 중점을 둔 결정론적, 확장성 및 잘 문서화된 딥 러닝 실험을 실행하기 위한 구글 연구 프로젝트. 공개 코드베이스는 [https://github.com/google/init2winit](https://github.com/google/init2winit)에서 찾을 수 있다.\n' +
      '\n' +
      '**단백질 디자인:** 각 공간은 50개 이상의 매개변수로 구성되며, 각각은 범주형 단백질 빌딩 블록을 나타낸다.\n' +
      '\n' +
      '**정점 AI AutoML(Tabular and Text):**표 또는 텍스트 데이터에 대한 자동화된 ML 모델 선택 및 트레이닝을 위한 정점 AI 플랫폼. 테이블형 데이터의 경우 AutoML은 모델 및 최적화기 유형 트리, 하이퍼매개변수, 데이터 변환 및 ML 파이프라인의 기타 구성요소를 검색합니다. 텍스트에 대해 AutoML은 텍스트 데이터를 분류하거나 정보를 추출하거나 저자의 감정을 이해하기 위해 ML 모델을 훈련한다. [https://cloud.google.com/vertex-ai?#train-models-with-minimal-ml-expertise](https://cloud.google.com/vertex-ai?#train-models-with-minimal-ml-expertise)를 참조하라.\n' +
      '\n' +
      '### Serialization Examples\n' +
      '\n' +
      '투명성을 위해 모델에서 볼 수 있는 텍스트 표현의 예를 제공한다. **거부:** 기업의 개인 정보 보호 정책으로 인해 일부 매개 변수 이름과 값을 수정(빨간색으로)했습니다.\n' +
      '\n' +
      '\\begin{tabular}{c|l|l} \\hline Dataset & Example \\(x\\) & Example \\(m\\) \\\\ \\hline Google AutoML & batch_size: 128 & title: "n-w597ng9917130-q40zcb001ea71" \\\\  & model_type: REDACTED & user: REDACTED \\\\  & activation_fn: "tanh" & description: "" \\\\  & batch_norm: "True" & objective: "val_categorical_cross_entropy" \\\\  & dropout: 0.143 & amc_model_version: REDACTED \\\\  & embedding_combiner: "mean" & task_type: "multi_class_classification" \\\\  & gradient_clip_norm: 1.63e+03 & task_type: "multi_class_classification" \\\\  & num_hidden_layers: 1 & \\\\  & hidden_units[0]: 359 & \\\\  & optimizer_type: "AdamOptimizer" & \\\\  & beta1: 0.9 & beta2: 0.999 \\\\  & learning_rate: 0.926 & \\\\  & nlpvocabulary_strategy: & \\\\  & "adjusted_mutual_info" & \\\\  & vocabulary_strategy: & \\\\  & "adjusted_mutual_info" & \\\\ \\hline Init2Winit & dropout_rate: 0.6 & title: "d_spl-lmlb_trfmr-b1024-2021aug20* \\\\  & decay_factor: 0.0379 & user: REDACTED \\\\  & label_smoothing: 0.378 & description: "" \\\\  & lr_bparams.baselr: 0.00285 & objective: "valid/ce_loss" \\\\  & lr_params.decay_steps_factor: 0.854 & \\\\  & lr_params.power: 1.94 & \\\\ \\hline Protein Design & p00000000:"9" & title: "871cac3095671leab5ber371aelbb25a" \\\\  & p00000001:"16" & user: REDACTED \\\\  & p00000002:"1" & description:"" \\\\  & p00000003:"11" & objective:"" \\\\  & p00000004:"16" & \\\\  & p00000006:"9" & \\\\  & p00000006:"0" & \\\\  & p00000007:"14" & \\\\  & \\\\  & p00000047:"13" & \\\\ \\hline Vertex AI Text & universalmodeltype: & title: "2022028-621c9aea-0000-2c94" \\\\  & single_dense_feature" & user: REDACTED \\\\  & token_model_type: "cnn" & description: REDACTED \\\\  & token_bow_combiner: "sqrtn" & objective:"micro-auc-pr-label0_label" \\\\  & token_model_type: "bow" & act_study_dataset_tag:"" \\\\  & rand:0 & act_study_notes:"" \\\\  & batchsize: 4 & convnet: "2:3:4*100pa" \\\\  & dropout_keep_prob: 1 & hidden_layer_dims: 50 \\\\  & max_length: 1.54e+03 & max_num_classes_for_per_class_metric: 0 \\\\  & max_token_vocab_size: 1e+05 \\\\  & merge_word_embeddings_vocab_size: 1e+05 \\\\  & token_freq_cutoff: 1 \\\\  & tokenizer_spec: "delimiter" \\\\  & word_embedding: REDACTED \\\\  & word_embedding_dim: 100 & \\\\ \\hline \\end{tabular}\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>