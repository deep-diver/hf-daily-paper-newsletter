<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '<# DITTO> : 음악세대용 직장근무 시간\\(T\\)-최적화\n' +
      '\n' +
      'Zachary Novack\n' +
      '\n' +
      'Julian McAuley\n' +
      '\n' +
      'Taylor Berg-Kirkpatrick\n' +
      '\n' +
      '브라이언노콜라스 J. 브라이언안니콜라스 J. 브란안니콜라스 J.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '우리는 초기 소음 래치 최적화를 통해 추론 시간에 미리 학습된 텍스트 간 확산 모델을 제어하기 위한 범용 프레임워크인 **D***D**I**nference-**T***ime \\(\\mathbf{T}\\)-**O**ptimization(***DITTO******)를 제안한다. 우리의 방법은 목표(실화) 출력 및 메모리 효율에 대한 기울기 체크포인트를 달성하기 위해 상이한 특징 매칭 손실을 통해 최적화하는 데 사용될 수 있다. 우리는 기본 모델을 미세 조정하지 않고 강도, 멜로디, 음악 구조 제어뿐만 아니라 인포팅, 아웃포팅, 루프링을 포함한 음악 세대의 놀라울 정도로 광범위한 응용 프로그램을 보여준다. 관련 훈련, 지도 및 최적화 기반 방법에 대한 접근법을 비교할 때 DITTO는 제어 가능성, 오디오 품질 및 계산 효율성에 대한 유사한 접근 방식을 능가하는 것을 포함하여 거의 모든 작업에 대한 최첨단 성능을 달성하여 고품질, 유연하고 훈련 없는 확산 모델의 제어를 위한 문을 열 수 있다. 소리 예는 [https://DITTO-음악 지투비오/web/] (https://DITTO-음악 지투비오/web/)에서 찾을 수 있다.\n' +
      '\n' +
      '기계 학습, ICML 기계 학습, ICML 기계 학습, ICML 기계 학습, ICML 머신 학습, ICML 기계 학습, ICML 기계 학습, ICML 컴퓨터 학습, ICML 기계 학습, ICML 기계 학습, ICML 기계 학습\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '대규모 확산 모델(호 et al., 2020)은 텍스트 대 이미지(TTI) 세대(Rombach et al, 2022, Karras et al, 2022, Chen, 2023), 비디오 생성(호 et al, 2022, Gupta et al, 2023), 3D 객체 생성(Watson et al, 2022, Poole et al, 2022)과 같은 다양한 양식으로 강력한 결과로 생성 매체의 선도적 패러다임으로 부상했다. 최근 오디오의 주파수 도메인 분광법(TTA) 생성(Liu et al., 2023a,b; Huang et al., Huang et al., 2023b) 및 텍스트 대 음악(TTM) 생성(Hawthorne et al, 2022; Forsgren 및 마르티로스, 2022; Chen et al., Huang et al., 2023a; Schneider et al., 2023) 생성, Schneider et al., 2023) 생성(Hawgren 및 마르티로스, 2023) 생성, 2023) 생성(Hawgren 및 마르티로스, 2023) 생성, 2023) 생성(Hawgren 및 마르티로스, 2023; Hugren 및 마르티로스, 2023) 생성, 2023; Hun et al, 2023, Schn et al, 2023) 생성, Schn et al, 2023) 생성, Schn et al., Schneider 등 2023) 생성, 2023, Schneider) 생성, 2023, Schneider et al., Schneider et al, 2023) 생성, 2023)에서 유망 결과를 이미지로 처리하여 오디오에 이미지 도메인 방법을 오디오에 적용하여 이미지 도메인 결과를 오디오에 적용하여 이미지 이러한 방법은 텍스트 프롬프트를 통해 관절된 장르, 기분 및/또는 키워드 제어가 있는 스펙트로그램보다 픽셀 또는 잠재 확산(Rombach et al., 2022)을 통해 동작한다.\n' +
      '\n' +
      '그러나 이러한 접근법은 일반적으로 고수준의 제어만을 제공하여 추가 작업을 동기를 부여한다. TTM 확산 모델에 대한 보다 정확한 제어를 추가하려는 현재 시도는 아직 자체 트레이드오프를 제시할 가능성이 있다. 제어넷(Wu et al., 2023a; Saharia et al., 2022a; Zhang et al., 2023)과 같은 피네잉 기반 방법은 쌍을 이루는 예시와 함께 값비싼 대규모 훈련을 필요로 하며 훈련 시간에 제어 신호를 고정하는 반면, 샘플링 중 모델 출력의 근사치에 의존하여 미세 변경 표현성에 대한 확산 샘플링 프로세스 투쟁을 안내하는 추론 시간 방법(Levy et al., 2023; 유 et al., 유 et al., 2023)을 안내한다.\n' +
      '\n' +
      'TTM 확산 모델에 대한 범용적이고 훈련 없는 제어 패러다임의 목표로 **DITTO**: **D**확산 ***I**nference-**T***ime \\(\\mathbf{T}\\)-**O*ptimization을 제안한다. DITTO는 원하는(일시적) 출력을 달성하기 위해 다른 확산 샘플링 프로세스에 걸쳐 _arbitrary_ 특징 매칭 손실에 대한 초기 소음 래치(\\mathbf{x}_{T}\\)를 최적화하고 기울기 체크포인트링(Chen et al. 2016)을 통해 효율적인 메모리 사용을 보장한다. 일반적으로 고의로 간주되고 작은 정보(송 등 2020, 프레차콜 등, 2022)를 인코딩하기 위해 음악 창작에서 광범위한 응용 분야에 대한 확산 과정을 제어해야 하는 힘과 정밀 초기 소음 래치들을 보여줌으로써 음악 창작에 있어 음악적으로 불안정한 특징 제어와 고품질 오디오 편집이 가능하다. 오디오 도메인 외부에서 이전 최적화 기반 작업(Wallace et al., 2023a)과 비교하여 DITTO는 SOTA 제어를 달성하며 또한 시간과 기억 효율성으로 2배이다.\n' +
      '\n' +
      '전반적으로, 우리의 기여는 그렇습니다.\n' +
      '\n' +
      '* A 사전 훈련된 확산 모델을 제어하기 위한 범용, 훈련 없는 프레임워크는 메모리 효율에 대한 기울기 체크포인트를 받아들이는 원하는(일시적) 출력을 달성하기 위해 달성된다.\n' +
      '* 오디오 도메인 음악 인포팅, 아웃포팅, 멜로디 제어, 강도 제어, 그리고 새로 제안된 루프링 및 음악적 구조 제어를 포함하여 많은 수의 미세화된 시간 의존적 작업에 우리의 틀을 적용한다.\n' +
      '\n' +
      '* 평가는 우리의 접근법을 통해 멀티-디퓨전(Bar-Tal et al., 2023), 프리도M(유 et al., 2023), 지침 조사 조사(Levy et al., 2023), 음악 제어넷(Wu et al., 2023), 비교 가능한 추론 시간 최적화 방법 DOODL(Wallace et al., 2023)을 능가하는 반면 DOODL보다 2배 이상 빠르고 기억의 절반을 사용하는 것으로 나타났다.\n' +
      '\n' +
      '2개는 회사 관련.\n' +
      '\n' +
      '음악 세대는.\n' +
      '\n' +
      '생성 음악은 컴퓨터 음악 연구자들(매헤럴 등 1969)의 오랜 목표였다. 초기 작품은 _symbolic_세대(동 et al., 2018; Chen et al., 2020; Dai et al., 2021)에 초점을 맞췄다. 최근 _audio_-domain 음악 생성은 음악LM(Agostinelli et al., 2023)과 같은 언어 모델(LM)과 오디오LDM(Liu et al., 2023;b)과 같은 확산 모델의 발전으로 대중화되고 있다.\n' +
      '\n' +
      'LM 기반 접근법은 보통 별개의 압축 오디오 토큰(Zghidour et al, 2022; Defossez et al, 2022; 감마 등 2023), 시간이 지남에 따라 자동 억제 방식으로 오디오를 생성하고(Borsos et al., 2023; 돈아에 등, 2023; Agostinelli et al, 2023; Carcia et al., 2023; Carcia et al., 2023; Borsos et al., Borsos et al., 2023) 또는 샘플 반복(Garcia et al., Borsos et al., 2023)을 자동 억제 방식으로 오디오를 생성하고, 생성된 토큰을 직접 오디오로 변환한다. 반면, 확산 기반 접근법은 일반적으로 이미지 대 가이드 변환기 또는 보코더(Forsgren and 마르티로스, 2022; Liu et al., 2023;b Schneider et al., 2023)를 통해 오디오로 디코딩되는 오디오 또는 _스펙트로그램_의 2D 주파수 도메인 표현을 생성함으로써 작동한다.\n' +
      '\n' +
      '텍스트 제어 기능이 있습니다.\n' +
      '\n' +
      '텍스트는 현재 확산 모델에 가장 인기 있는 제어 매체입니다. 이 경우 텍스트 캡션은 임베딩에 인코딩되어 교차 주의, 부가적 변조 또는 Stable Diffusion(Rombach et al, 2022) 또는 Imagen(Saharia et al, 2022)와 같은 모델에서 발견되는 것과 유사한 훈련 동안 생성 모델에 주입된다. 인기에도 불구하고 글로벌 캡션 기반 텍스트 컨디셔닝에는 미세한 제어(장 등, 2023년)가 부족하여 대안을 동기부여합니다.\n' +
      '\n' +
      '대체 예방 방법.\n' +
      '\n' +
      '확산 모델에 고급 제어를 추가할 때 추가 입력으로 기존 텍스트 제어 가능한 모델을 미세 조정하는 것이 일반적이다. 제어넷(Zhang et al, 2023)과 단위 제어넷(Zhao et al., 2023)은 에지 검출 또는 포즈 추정과 같은 특정 사전 정의된 대조군에 대한 추가 제어 어댑터를 추가하여 미세-선 텍스트-영상 확산 모델에 큰 쌍을 이루는 데이터 세트를 사용한다. 교육 요구를 더욱 줄이기 위해 소수의 사례(Ruiz et al., 2023; 최 등, 2023; Gal et al., 2022; Kawar et al., 2023)에서 미세 훈련된 다수의 작품들을 사전 훈련했다. 다른 사람들은 직접 미세 조정(Clark et al., 2023; Prabhudesai et al., 2023) 또는 강화 학습 유사 목표(블랙 et al., 2023)를 통해 미세 조정에 대한 외부 보상 모델을 사용하여 탐구했다. 그러나 이러한 접근법은 여전히 고가의 훈련 과정이 필요하며 훈련 후 제어 메커니즘을 수정할 수 없다. 음악은 제어넷식 접근(Wu et al., 2023)만을 취하였다.\n' +
      '\n' +
      '시간 안내서 기반 관리\n' +
      '\n' +
      '대규모 모델 미세 조정 작업을 수행해야 하는 것을 피하기 위해 확산 모델의 추론 시간 제어 방법이 점점 더 대중화되었다. 이 범주 내의 초기 접근법에는 신속한 촉진 이미지 편집(Hertz et al., 2022), 멀티디확산(Bar-Tal et al., 2023)이 포함되며, 이는 여러 개의 마스킹 확산 경로를 함께 융합하여 국소화된 객체 대체, 인포팅, 아웃포팅 및 공간-지도 제어를 가능하게 한다. 이러한 방법은 이미지의 특정 픽셀 영역에 국한될 수 있고 주파수 및 여러 중첩 소스에 걸쳐 간접적인 픽셀 대응성을 갖는 오디오 스펙트로그램에 대해 한꺼번에 덜 적용될 수 있는 제어 표적에 의존한다.\n' +
      '\n' +
      '그림 1: We는 추론 시간에 사전 훈련된 확산 모델을 제어하기 위한 범용 프레임워크인 ***DITTO*** 또는 **D**확산 ***I*****************timization을 제안한다. 1) 초기 잡음 잠재 \\(\\mathbf{x}_{T}\\; 2)를 샘플링하여 음악 스펙트로그램 \\(\\mathbf{x}_{0}\\)을 생성했으며, 3) 생성된 콘텐츠로부터 특징을 추출하고, 4) 입력 대상(stylized) 출력을 입력하고, 5)은 초기 노이즈를 최적화하여 다른 생존 가능한 손실에 맞게 최적화한다.\n' +
      '\n' +
      '우리는 또한 사전 훈련된 분류기 \\(\\nabla_{x_{t}}\\mathcal{L}_{\\phi}_{\\phi})의 구배를 통해 생성 과정을 제거하기 위해 각 샘플링 단계에서 업데이트를 도입하는 안내 기반 방법(Dharibwal and Nichol, 2021, 정 등은 2023, Levy et al, 2023)의 클래스를 참조한다. 이러한 접근법은 샘플링 동안 모델 출력의 근사치를 필요로 하며, 이는 미세-곡물 표현성을 제한하거나 노이즈 수준당 사전 훈련된 분류기를 제한하므로 추론-시간 효율성의 목적을 상실한다. 음악을 위해 안내 기반 방법은 레비(Levy et al.(2023)에서만 탐색되었다.\n' +
      '\n' +
      '시간 최적화 기반 제어\n' +
      '\n' +
      '최근 연구는 GPU 메모리를 적절하게 관리하면 확산 샘플링을 통한 최적화가 가능하다. 확산 래치들(DOODL)(Wallace et al., 2023a)의 직접 최적화는 최근 제안된 EDICT 샘플링 알고리즘(Wallace et al., 2023b), 아핀 결합층(ACLs)(Dinh et al., 2014, 2016)을 사용하여 완전히 가역적인 샘플링 프로세스를 형성하고 CLIP 안내, 어휘 확장 및 심미적 개선을 위한 초기 확산 노이즈 래치들을 최적화하기 위해 EDICT를 통해 역전파한다. 그러나DOODL은 미세 변경 제어 신호(Wallace et al., 2023a)에 대한 투쟁(Wallace et al., 2023a)와 EDICT에 의존하기 때문에 다중 저하가 있으며, 1을 포함한 EDICT에 의존하기 때문에 잠복기 및 메모리 사용을 증가시키는 정방향 및 역방향 샘플링 모두에 대한 모델 평가가 2배 필요하며, 3)은 ACL 확산 사슬 간의 분기로 인한 안정성 문제와 보상 해킹으로 인해 발생할 수 있다.\n' +
      '\n' +
      '확산 잡음 최적화(DNO)(Karunratanakul et al., 2023) 방법은 제한된 관절 위치의 짧은 서열에 걸쳐 작동하는 인간 움직임 생성을 위한 샘플링 과정을 통해 역프로파고를 제안했다. 이 작업은 작은(즉, \\(<18\\)M 매개변수) 변환기 인코더 전용 아키텍처, 샘플링 단계, 긴 최적화 시간 및 순수하게 무조건적인 생성과 같은 메모리 사용을 줄이기 위해 수많은 도메인 특이적 변형을 강조한다. 따라서 이 접근법은 텍스트 대 이미지, 텍스트 대 스토리 및 텍스트 대 음악과 같은 더 높은 기억 요구를 가진 보다 표준적인 생성 작업에 적용할 수 없다.\n' +
      '\n' +
      '3 Diffusion Inference-시간\\(T\\)-최적화].\n' +
      '\n' +
      '### Diffusion Background\n' +
      '\n' +
      '덴노징 확산 확률 모델(DDPM)(Sohl-Dickstein et al., 2015; Ho et al., 2020) 또는 확산 모델은 정방향 및 역방향 무작위 마르코프 공정에 의해 정의된다. 정방향 과정은 청정 데이터를 취하고 노이즈로 반복적으로 방해하여 신경망 \\(\\mathbf{\\epsilon}_{\\theta}\\)를 훈련시킨다. 네트워크 \\(\\mathbf{\\epsilon}_{\\theta}\\)는 전형적으로 (noisy) 데이터 \\(\\mathbf{x}_{t}\\), 확산 단계 \\(t\\), (텍스트) 컨디셔닝 정보 \\(\\mathbf{c}_{\\text{c}}\\)를 입력한다. 역가공은 샘플링 과정을 통해 무작위 노이즈 \\(\\mathbf{x}_{T}\\ason\\mathcal{N}(0,I)를 취하고 이를 학습된 네트워크와 반복적으로 처리하여\\(T\\)에 걸쳐 새로운 데이터 \\(\\mathbf{x}_{0}\\)를 생성한다.\n' +
      '\n' +
      '}}\\math{t}}\\math{f{f}}\\math{{t}}\\math{{t}.\n' +
      '\n' +
      '\\(\\mathbf{\\epsilon}\\심\\mathcal{N}(0,I)\\), \\(\\alpha_{0}:=1\\), \\(\\alpha_{t}\\) 및 \\(\\bar{\\pha}_{t}\\)가 노이즈 일정을 정의하는 경우,\\(\\sigma_{t}}\\)는 샘플링 표준 편차이다. 샘플링 시간을 줄이기 위해 덴오잉 디퓨전 이미지 모델(DDIM) 샘플링(송 등 2020)은 결정론적일 수 있는 더 빠른 샘플링 프로세스(예: \\(20-50\\) 단계를 생성하는 대체 최적화 목적을 사용한다.\n' +
      '\n' +
      '텍스트 컨디셔닝을 개선하기 위해 분류기가 없는 안내(CFG)를 사용하여 조건부 및 무조건 생성 출력(호, 살리만, 2021)을 혼합할 수 있다. CFG로 트레이닝할 때 컨디셔닝은 시간의 일부분인 널 값으로 무작위로 설정된다. 추론 동안, 확산 모델(\\mathbf{f{t}_{\\bf{t}_{\\bf{f}_{\\text}},t,\\mathbf{c}})은 \\(\\mathbf{\\on}_{\\theta}_{\\theta}_{\\theta})와 선형적으로 결합되며(\\mathbf{\\bf{\\s}_{\\bf{\\:{\\bf{\\bf{\\bf{\\)은 \\(\\mathbf{\\bf{\\ingsilon}_{\\bf{\\:{\\bf{\\bf{\\FA}_{\\bf{\\:{\\bf{\\) CFG 스케일 힌지}_{\\bf{\\) CFG 스케일(\\mathbf{\\vf{\\p{\\f}_{\\f}_{\\bf{\\or}_{\\ml}_{\\f}_{\\f}_{\\f}_{\\f}}_{\\ 추론 중 CFG는 \\(\\mathbf{\\epsilon}_{\\theta}\\)의 전방 패스를 배가시킨다. 확산 모델 검토를 위해 최종 출력에서 부록 A. Though(\\mathbf{x}_{T}\\)의 역할이 일반적으로 무작위 종자로서만 생각되며, 다음 섹션에서는 실제로 생성 과정에 대한 미세 변경 제어를 위해 \\(\\mathbf{x}_{T}\\)가 어떻게 레버리지될 수 있는지 보여준다.\n' +
      '\n' +
      '### Problem Formulation\n' +
      '\n' +
      '우리는 제어 신호를 감안할 때 원하는 출력을 생성하기 위해 확산 샘플링 프로세스의 초기 상태 또는 래치들에 맞는 최적화 문제로 사전 훈련된 확산 모델을 제어하는 작업을 공식화한다. 형식적으로.\n' +
      '\n' +
      '<\\mathbf{x}> <\\mathbf{c}> <\\mathbf{x>} <\\math{f}> <\\math{f}> <\\math{x>}.\n' +
      '\n' +
      'r\\(\\math{x}_{T}\\)는 초기 노이즈 래치(\\math{c}}I)로 알려져 있는 Gaussian 무작위 벡터(\\math{N}(\\math{f})의 최종 출력으로서,\\math{N}(\\math{c}d\\)은 임의의 다른 특징(\\math{c}}}\\)으로 알려져 있는 Gaussian)의 샘플이며,\\(\\math{c}}<\\b\\(\\math{c}}/\\)은 임의의 다른 특징(\\b\\)은 오디오의 최종 출력이고,\\(\\math{c}}<\\)은 임의의 다른 특징(\\b\\:\\(\\b\\)은 오디오의 최종 출력이고,\\(\\math{c}}}<\\)은 임의의 다른 특징(\\b\\(\\b\\)은 오디오의 최종 출력이고,\\-math{c}}}<\\)은 임의의 다른 특징(\\b\\(\\b\\)은 오디오의 최종 출력이고,\\ \\(\\b\\:\\:\\:\\:\\:\\) 제어 작업을 초기 소음 래치들에 임의의 특징-매칭 최적화 문제로 프레이밍함으로써, 다양한 범위의 제어 작업을 통합할 수 있다.\n' +
      '\n' +
      '그러나 백프로파고를 사용하여 (2)를 해결하면 일반적으로 극단적인 기억 요구 사항으로 인해 견딜 수 없다. 즉, 확산 샘플링 과정은 설계 및 표준 자동 분화 패키지에 의해 재귀화되어 있으며, 동시적으로는 CFG가 사용될 때 단계당 활성 세트(\\(\\mathbf{\\epsilon}_{\\theta}\\)에 대한 \\(\\mathbf{\\epsilon}_{\\theta}\\)에 대한 모든 중간 결과를 샘플러(\\(2T\\) 내에 저장해야 한다. 따라서 2-3개의 샘플링 단계라도 표준 U-Net 확산 아키텍처로 메모리 오류를 유발할 수 있다.\n' +
      '\n' +
      '비지트 체크아웃.\n' +
      '\n' +
      '최적화 중 대형 메모리 사용을 우회하기 위해 기울기 재물질화 또는 체크포인트링(Chen et al, 2016)을 사용한다. 계산 시간 동안 메모리 비용을 거래함으로써 매우 깊거나 재귀 신경망을 트레이닝할 때 메모리를 절약하기 위해 방사선 체크포인트를 도입하였다. 핵심 아이디어는 높은 메모리 사용을 가하는 역프로파싱의 전방 패스 동안 저장된 중간 활성화 값을 폐기하고/하거나 캐싱된 입력에서 필요할 때 후진 패스 동안 이를 재검증하기 위해 낮은 비용인 것이다.\n' +
      '\n' +
      '우리는 샘플링 동안 각 확산 모델 콜에 대한 구배 체크포인트를 사용하여 중간 시끄러운 확산 텐서와 컨디셔닝 정보를 저장하는 데 필요한 메모리가 전형적인 확산 모델(예: 대형 UNet 내의 교차 의도 활성화 맵)의 중간 활성화와 비교하여 분이기 때문에 샘플링 동안 각 확산 모델 콜에 대한 기울기 체크포인트를 사용한다. 샘플러-단계 체크포인트 1)으로 (2) 역프로파킹을 실행하려면 (2) 메모리가 \\(\\mathbf{\\epsilon}_{\\theta}\\) 중간 시끄러운 확산 텐서 \\(\\mathbf{x}_{t}_{t}<0, a\\) 및 컨디셔닝 \\(\\mathbf{c}\\)를 저장하기 위한 비용 \\(T\\) 중간 시끄러운 확산 텐서 \\(\\mathbf{t <0, a\\:T\\)를 저장하기 위한 비용 \\ (T\\) 중간 시끄러운 확산 텐서 \\(\\mathbf{t}_{t}_{t> t=0, T\\:T\\) 및 컨디셔닝 \\)를 저장하기 위해 비용 \\)를 저장하기 위해 비용(T\\)을 저장하는 데 필요한 메모리 비용 \\(\\mathbf{t=0, T\\:T\\) 및 컨디셔닝 \\(T\\:T\\:T\\:T\\:T\\) 및 컨디셔닝 \\)을 저장하는데 필요한 한 가지 확산 텐서 \\ 우리의 기억 감소는 그림 2와 같이 샘플링 프로세스 또는 \\(T\\) 확산 모델 호출의 추가 전진 패스에 의해 지불된다.\n' +
      '\n' +
      '우리의 접근법과 대조적으로 DOODL은 또한 MemCNN 라이브러리(Leemput et al., 2019)를 통한 구배 체크포인트를 차지한다. 그러나DOODL은 샘플링 과정을 샘플링 단계당 2개의 비병렬 업데이트 방정식으로 분할하는 EDICT 샘플링 알고리즘을 사용해야 한다. 결과적으로 DOODL은 메모리 _and_ 런타임 비용을 두 배 이상 필요로 하며, 또한 상관된 업데이트를 정렬하기 위해 EDICT의 "고정" 계층으로 인해 샘플링 프로세스(특히 낮은 샘플링 단계) 동안 전반적인 불안정성에 시달린다(제6.3절 참조). DOODL에 대한 메모리 다이어그램과 약간 더 메모리 효율적이지만 부록 B에서 표준 백프로파보다 6배 느린 DOODL에 대한 대체 메모리 절차를 보여준다.\n' +
      '\n' +
      '### Complete Algorithm\n' +
      '\n' +
      '우리의 DITTO 알고리즘에 대한 푸도-코드는 알고리즘 1에 표시되며, 체크포인트는 1이 입력 및 저장 가능한 다른 식별 가능한 네트워크(즉, 샘플러) 및 네트워크에 대한 임의의 입력 주장은 후방 패스에서 필요할 때 활성화 캐싱을 꺼내기 위해 네트워크의 디폴트 활성화 캐싱 거동을 오버랩하는 기울기 체크포인트로서 정의한다. 실제로, 우리는 보통 \\(\\mathbf{x}_{T}\\)에서 \\(\\mathbf{x}_{0}\\)에 걸쳐 있는 샘플링 단계(예: 20)의 작은 하위 집합을 사용한다.\n' +
      '\n' +
      '## 4 Applications\n' +
      '\n' +
      '우리는 TTM 확산 모델에 대해 음악적 구조와 루프링이 모두 설명되지 않은 아웃포팅, 인포팅, 루프링, 강도 제어, 멜로디 제어 및 음악적 구조 제어를 포함한 다양한 애플리케이션1에 유연한 프레임워크를 적용한다. 이는 둘 다 참조를 구성한다.\n' +
      '\n' +
      '그림 2: 샘플링을 통한 역전달을 위한 다른 메모리 설정입니다. 일반적으로 모든 중간 활성도는 메모리에 저장되며, 이는 현대 확산 모델에 적합한다. DITTO에서 구배 체크포인팅은 빠른 런타임 보존을 위해 모델 호출의 수 2배만으로 효율적인 메모리 사용을 달성할 수 있게 한다.\n' +
      '\n' +
      '그림 3과 같이 기반(즉, 기존 오디오를 사용하는 것) 및 기준 없는(스크래치로부터의 세대) 제어 동작들을 사용하여) 우리 목표는 초기 소음 래치들이 확산 과정에 걸쳐 가지고 있는 표현 제어 가능성을 표시하는 것이다.\n' +
      '\n' +
      '**아웃필팅**-아웃포팅은 실제 또는 이전에 생성된 콘텐츠의 길이를 연장하는 작업이며, 영상 및 오디오 편집은 물론 확산 모델을 이용하여 장기 음악 콘텐츠를 생성하는 데 중요하다. 과거의 실화 방법에는 다중 융합 Bar-Tal et al.(2023) 및 지침 조사 결과 Levy et al.(2023)가 있으며, 이는 긴 형태의 정합성과 국소 평활화를 유지하기 위해 고군분투한다. 우리는 기존 기준 오디오 신호 \\(\\mathbf{x}_{\\text{ref}}\\)를 취하여 1) 참조 종료 시 중첩 영역 \\(o\\)을 정의하며, 2)는 DITTO를 사용하여 중첩 영역과 일치하지만 이를 확장한 다음, 참조 및 새로 생성된 콘텐츠를 함께 스티칭한다. MS(\\mathbf{f}}{math{M}}{math{f}}{math{f}}{math{f}}{\\math{f}}{\\math{f}}}{\\math{f}}} <\\math{f}}{f}}{f}}{f}}\\math{f}} <\\math{f}}{f}}{f}}{f}{f}}{f}}{f}{f}}{f}}{f}{f}}{f}{f}{f}{f}}{f}{f}{f}{f}{f}{f}{f}{f}}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}{f}\n' +
      '\n' +
      '** 인필팅**-인포팅은 실제 또는 이전에 생성된 콘텐츠의 내부 영역을 대체하는 작업이며 오디오 편집 및 음악 리메이크링에 필수적이다. 정씨(2023년)와 레비 등(2023년)가 다양한 성공을 거두기 위해 이미지 및 오디오 도메인에서 인포팅에 대한 과거 작업이 탐구됐다. 우리는 DITTO를 사용하여 외념과 유사한 인포화를 수행하는데, 유일한 변형은 \\(\\mathbf{M}_{\\text{ref}}=\\mathbf{M}_{\\text{gen}}\\)로, _2_ 중첩 영역(스펙트로그램의 각 측면)을 나타내며, 간 공백을 돌리기 위한 맥락에서 사용된다.\n' +
      '\n' +
      '** 루프핑** - 로핑은 원형 패턴으로 반복되는 콘텐츠를 생성하여 반복 가능한 음악 조각을 생성하여 더 큰 구성의 기초를 형성하는 작업이다. 루프링을 위해 DITTO를 도식과 유사하게 사용하지만 \\(\\mathbf{M}_{\\text{ref}}\\) 및 \\(\\mathbf{M}_{\\text{gen}}\\)를 정의할 때 출력의 2개의 중첩 에지 영역을 지정하지만 출력의 _opposite_ 측면에 해당하지만(인화와의 유사) 확장 영역이 참조 클립의 시작으로 원활하게 전환되도록 한다. 알고 있는 범위 내에서는, 우리는 루프링 제어를 가진 최초의 모방 TTM 확산 모델이다.\n' +
      '\n' +
      '** 밀도 조절***-뮤지컬 강도 제어는 생성된 음악의 동적 대비를 시간에 걸쳐 조정하는 과제이다. 우리는 음미, 데시벨(dB) 볼륨 곡선을 따르는 음악을 생성하기 위해 훈련 시간 방법을 사용하는 음악 제어넷(우 et al.(2023 참조)의 강도 제어 프로토콜을 따른다. 음악 제어넷,\\bf}\\(\\math{f}\\)은 주어진 dB-스케일 곡선,\\math{L}\\(\\math{f})의 스무딩 계수,\\math{f}}(\\math{f}/\\math{f} <\\math{f} <\\math{f}{2>를 설정함으로써,\\math{f}{f}. 여기요, 보컬도 통해 역전파해 주세요.\n' +
      '\n' +
      '***멜로디 제어** - 뮤지컬 멜로디 제어는 시간이 지남에 따라 두드러진 음악적 톤을 제어하는 작업이며 창작자가 기존 멜로디에 반주 음악을 생성할 수 있도록 한다. 최근 작업 코펫 등(2023년)에 이어 우 등(2023년)이 승인된다. 녹음의 멜리는 하이패스 크롬그램 함수 \\(\\mathbf{C}(\\cdot)\\)Muller(2015)를 통해 시간이 지남에 따라 12-pitch 클래스의 평활화된 에너지 레벨을 계산함으로써 추출할 수 있다. 타겟 멜로디 \\(\\mathbf{y},\\mathbf{V}},\\mathbf{x}_{0})\\(\\mathbf{V}}\\bf{V}(\\mathbf{x}/\\dots,12\\}^{N\\i}}})\\)=\\mathbf{V}(\\math{V}\\bf{x}\\bf{V}\\bf{x}\\bf{x}\\bf{V}\\bf{x}\\bf{C}\\bf{x}\\dots,\\dots, 12\\dots,\\dots, 12\\{N\\{N\\}}}}}}}}}} <\\bf{x}}}} <\\bf{x}}} <\\dots,\\dots, 12\\{N\\{N\\{N\\{N\\{N\\}}}}}}} <{N\\.{N\\}}}} <{N\\.{N\\} 추가 구현 세부 정보를 위해 우 등(2023)을 참조하세요.\n' +
      '\n' +
      '** 음악 구조 제어** - 음악 구조 제어를 시간 경과에 따라 생성된 음악의 상위 음악 형태를 제어하는 과제로 정의한다. 뮤지컬 형태를 모델링하기 위해, 우리는 음악적 구조 분석 작업 McFee와 Ellis(2014)를 따라 가장 간단한 경우 타임브레인이 "시끄러운 소리도 피치도 아니다" 에릭슨(1975)인 지역 타임브레스의 자기 유사성(SS) 행렬을 계산함으로써 구조를 측정한다. 따라서\\(\\mathbf{x}_{0})는\\(\\mathbf{T}) 내지\\mathbf{T}(\\mathbf{x}_{0}),\\(\\mathbf{T}_{0})를 설정하여 음악적 구조 제어를 위해 DITTO를 사용한다.\n' +
      '\n' +
      '그림 3: 세기(왼쪽), 멜로디(중간), 구조(오른쪽)를 포함한 창조적 제어를 위해 DITTO의 사용 실시예와 대상 제어 및 최종 특징이 각 스펙트로그램 아래에 표시된다.\n' +
      '\n' +
      '타임브레 추출 기능 및 \\(\\mathcal{L}\\propto|f}\\mathbf{x}_{0})-\\mathbf{y}||_{2}^{2}\\)를 포함한다. 구체적으로 멜-빈도 Cepstrum Co 비효율성(MFCCs)(McFee et al., 2010)을 사용하여 첫 번째 계수를 생략하고 시간 축을 가로질러 정규화한 다음 시간 내 추출 기능으로 2D 사비츠키-골레이 필터를 통해 SS 매트릭스를 매끄럽게 하여 프레이즈 내 유사성의 약간의 변화를 처벌하지 않는다. 이러한 목표 SS 매트릭스는 "ABBA"(그림 3) 패턴의 형태를 취할 수 있다. 예를 들어. 알고 있는 범위 내에서는, 우리는 구조 제어를 가진 최초의 모방 TTM 확산 모델이다.\n' +
      '\n' +
      '위에서 설명한*** 기타 적용** - 응용 프로그램을 개시하면 DITTO는 상관 기반 강도 조절(C), 실제 클라우디오 반전(D), 기준 무첨가 루프링(E), 음악적 구조 전달(F), 기타 샘플링 방법(G), 다중 성능 최적화(H) 및 빠른 추론을 위해 최적화된 래치 재사용과 같은 부록에서 설명하는 TTM 생성에서 이전에 설명되지 않은 수많은 새로운 확장에 사용할 수 있다.\n' +
      '\n' +
      '5개의 디자인.\n' +
      '\n' +
      '### DITTO Setup\n' +
      '\n' +
      '우리는 아담(킹마, Ba, 2014)을 DITTO의 최적지로 사용하고, 학습율은 \\(5\\t 10^{-3}\\)로(더 높은 경우 안정성 문제로 이어진다. 우리는 모든 실험에 \\(20\\) 단계와 동적 보유(Saharia et al., 2022b)를 사용한 DDIM(송 et al., 2020) 샘플링을 사용한다. 선율 및 구조 작업에 대해 70에서 150으로 두 배로 증가한 최대 최적화 단계의 수 외에 적용 전반에 걸쳐 최적기 하이퍼파라미터가 변경되지 않았다.\n' +
      '\n' +
      '### Datasets\n' +
      '\n' +
      '장르, 기분, 템포 태그로 허가된 기악 음악 \\(\\touchx\\)\\(1800\\) 시간의 데이터셋에서 모델을 훈련합니다. 우리의 데이터 세트는 자유형 텍스트 설명이 없기 때문에 주케박스(Dariwal et al., 2020)에서 수행한 것처럼 글로벌 뮤지컬 스타일의 클래스조건 텍스트 제어를 사용한다. 선율 제어 참조를 위해 **Nikifonia Lead-Sheet Dataset***(Simonetta et al., 2018)의 380표본 공개 도메인 하위 집합의 녹음을 합성한다. 우 등(2023a)에서와 같이 강도 및 구조 제어를 위한 작은 세트의 수공예 강도 곡선 및 음악적 구조 매트릭스(예: 매끄러운 크레센도 및 "ABA" 형태)를 구성(더 많은 예들에 대한 부록 H 참조)한다. 평가를 위해 우리는 또한 텍스트 설명이 있는 약 5K 10초 클립과 함께 **음악캡 다타세트**(아조스티넬리 등 2023)를 사용한다.\n' +
      '\n' +
      '### Evaluation Metrics\n' +
      '\n' +
      '우리는 VGGish(Hershey et al, 2017) 백본과 함께 프라이트 오디오 거리(FAD)를 사용하여 기준 기록 세트의 임베딩 분포와 생성된 기록(Kilgour et al., 2018) 사이의 거리를 측정한다. FAD 메트릭은 모든 실험에 대해 2.5K 모델 세대에 대한 참조 분포로 뮤직캡을 사용하여 계산된다. 참조 없는 표적의 경우 텍스트 캡션과 출력 오디오 사이의 전반적인 정렬을 측정하는 CLAP 점수(Wu et al, 2023b)를 사용하는데, 우리의 모델이 _tag_-조건일 뿐이므로 주형 _"\\(A\\)[genre] [mood] 곡을 사용하여 각 태그를 분당 [BPM] 비트에서 캡션으로 변환한다. 또한 강도 및 음악적 구조 제어를 위해 생성된 출력(즉, 최종 특징 매칭 거리)에 걸쳐 평균 손실(\\mathcal{L}\\)을 보고하고, 분류 과제로 프레임화되어 있기 때문에 멜로디 제어를 위한 전반적인 정확도를 보고한다.\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      '우리는 포함하는 광범위한 방법에 대해 벤치마킹한다.\n' +
      '\n' +
      'DDIM}(\\sqrt{\\bf{t}}}\\srt{\\bf{t}}} <\\bar{\\f{t}}} <\\bar{\\al{t}}}:\\bar{\\bf{t}})\\mathbf{t}}.\n' +
      '* 멀티디퓨전(Bar-Tal et al., 2023): 이 경우는 순진한 접근 방식과 유사하지만 대신 하드 마스크를 사용하는 대신 중첩된 영역에서 시끄러운 출력을 사용한다. 우리는 또한 샘플링 프로세스의 특정 지점(반쪽으로 등)에서 이러한 평균 작업을 중단하고 프로세스를 안내하지 않고 모델 샘플을 할 수 있으며, 이전 접근법을 MD로, 후자는 양조을 위한 MD-50으로 나타낸다.\n' +
      'f(\\hat{\\mathbf{t}){t}}(\\hat{\\mathbf{t}}}}} <\\hat{\\mathbf{x}}}}_{t})\\mathbf{x}(\\mathbf{x})\\mathbf{x}(\\mathbf{t}:\\mathbf{t}:\\mathbf{t}}/\\mathbf{t}} <\\mathbf{t}}} <\\mathbf{t}}} <\\mathbf{t}} <\\mathbf{t}}} <\\mathbf{t}}}} <\\mathbf{t}})\\math{math{t}}}}}}}}}}}}}}}}.{t}}} <\\math{f{t}}}}}}}}}}}}}}}}}}}}} <{t}} <{t}} 12. \\(\\eta_{t}\\)는 전체 구배 규범의 함수인 시간 의존적 학습률이다.\n' +
      '* 지침 조사(GG)(Levy et al., 2023): GG는 FreeDoM에서 업데이트 방정식을 취하고 두 가지 작은 수정을 한다. 즉, \\(\\eta_{t}\\)는 샘플링 전체에 걸쳐 고정되어 있으며, GG는 특징 추출기 \\(f(\\cdot)\\가 완전히 선형인 경우 추가적인 데이터 일관성 단계를 포함한다.\n' +
      '* 뮤직 컨트롤넷(Wu et al., 2023a): 음악 제어넷은 제어 신호 \\(\\mathbf{y}\\)에 대한 대규모 훈련 동안 우리의 작업과 동일한 기본 기반 모델을 공유하지만 추가 핀셋 어댑터 모듈을 컨디셔닝으로 공유하는 트레이닝 기반 접근법이다.\n' +
      '* DOODL(Wallace et al., 2023a): DOODL2는 EDICT(Wallace et al., 2023b) 샘플러를 사용하는 최적화 기반 접근 방식이며, 노이즈를 주입하고 \\(\\mathbf{x}_{T}\\) 재정규화하는 등의 최적화 과정에 다중 ad-hocqes를 사용한다. 우리는 유사한 안정성 문제로 인해 DITTO와 동일한 학습률을 사용한다.\n' +
      '\n' +
      '우리는 모두 선율과 강도 실험을 위한 선형 특징 매칭 목적, 음악 제어넷, 모든 실험에 대한 자유DoM 및 DOODL을 가지고 있기 때문에 인포팅, 아웃포팅 및 루프링 실험에 대한 Naive Masking, 멀티디확산 및 지침 조사자와 비교된다.\n' +
      '\n' +
      '## 6 Results\n' +
      '\n' +
      '측정 결과, 그림 그림, 그림 그림, 그림 그림 및 높은 결과.\n' +
      '\n' +
      '표 1과 그림 2에서 외화 및 루프링에 대한 객관적인 평가 결과를 보여주는데, 중복 영역에 대한 낮은 손실이 _overall_ 오디오가 응집력이 필요하다는 것을 요구하지 않기 때문에 FAD를 보고한다. DITTO는 중복 크기가 1~3초이고 그림 간격이 2~4초인 모든 기저부에 대해 가장 낮은 FAD를 달성한다는 것을 발견했다. DOODL은 DITTO 뒤에, 추론 시간 지도 방법은 특히 투쟁한다.\n' +
      '\n' +
      '질적으로, 우리는 모든 기저부(평판 DOODL)가 그림과 같이 중첩 지역 외부의 출력 음악에서 가청적인 "삼"을 생성하는 경향이 있음을 발견했다. 4, 최종 출력은 순전히 중첩 영역(즉, 특징 매칭 타겟에 대한 최적화를 초과)과 일치하고 중첩 생성과 나머지 세대 사이의 전반적인 일관성을 무시하는 경향이 있다. 중복 영역에 걸쳐 재구성하기 위해 \\(\\mathbf{x}_{T}\\)를 최적화하여 DITTO는 이 과정이 의미적인 콘텐츠를 원활하게 보존하기 위해 묵시적으로 비오버랩 생성 섹션을 장려하기 때문에 이러한 문제를 효과적으로 회피한다.\n' +
      '\n' +
      '측정, 멜디, 구조 측정 결과.\n' +
      '\n' +
      '표 3에서 강도, 선율 및 구조 제어에 대한 객관적인 메트릭을 보여준다. 우리는 1) 다양한 방법이 FAD 및 3)을 통해 MSE 또는 Accuracy 2) 전체 오디오 품질을 통해 생성 모델에 표적 제어를 어떻게 부과하는지 이해하고자 한다. 우리는 DITTO가 _제로_감독 훈련을 통해 음악 제어Net을 제치고 SOTA 강도와 멜로디 제어를 달성한다는 것을 알게 된다. 우리는 더 깊이 있는 음악 제어Net의 열악한 강도 제어를 부록 C. 신라에서 탐구하지만, 구조 제어에서 자유도M이 DITTO를 약간 꺾지만 강도 및 특히 멜로디 제어에 대한 성능이 좋지 않아 복잡한 특징 추출기에 대한 안내 기반 방법의 한계를 보여준다.\n' +
      '\n' +
      '최적화 기반 제어에 대한 주목할만한 관심사는 보상 해킹의 가능성(Skalse et al., 2022; Prabhudesai et al., 2023)으로, 통제 대상이 모델 품질 및 염기 행동의 저하로 과대 최적화된다. 우리는 DOODL이 일반적으로 DITTO보다 통제 시 더 나쁘다는 것 외에도 지속적으로 이러한 보상 해킹 행동을 나타내어 통제 대상과 일치시키는 데 유리한 전반적인 품질과 중요한 텍스트 관련성을 희생한다는 것을 발견했다. 반면 DITTO는 과최적화 및 품질 및 텍스트 관련성 유지 없이 목표 제어의 균형을 맞출 수 있다.\n' +
      '\n' +
      '그림에서. 3, 우리는 정성적 강도, 선율, 그리고 struc를 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c} \\hline \\hline FAD (\\(\\downarrow\\)) & \\(o=1\\) & \\(o=2\\) & \\(o=3\\) & Looping \\\\ \\hline DOODL & 9.4525 & 9.0397 & 9.0210 & 8.9239 \\\\ Naïve & 9.5281 & 9.4074 & 9.4053 & 9.4954 \\\\ MD & 9.8201 & 9.4784 & 9.3108 & 9.5815 \\\\ MD-50 & 9.4387 & 9.2521 & 9.1156 & 9.4053 \\\\ GG & 10.3076 & 9.8281 & 9.3881 & 9.5524 \\\\ FreeDoM & 9.7073 & 9.7708 & 9.6027 & 9.4535 \\\\ DITTO (ours) & **9.1859** & **8.9178** & **8.6897** & **8.8431** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 기준 픽셀, 안내 및 최적화 기반 방법에 대한 DITTO에 대한 아웃필링 및 루프링 결과는 표 1:이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c} \\hline \\hline FAD (\\(\\downarrow\\)) & gap = 2 & gap = 3 & gap = 4 \\\\ \\hline DOODL & 8.8018 & 9.0050 & 9.5049 \\\\ Naïve & 9.4871 & 9.5524 & 9.6067 \\\\ MD & 9.3279 & 9.7251 & 10.0740 \\\\ MD-50 & 9.0677 & 9.4161 & 9.8342 \\\\ GG & 9.7049 & 10.1605 & 10.9959 \\\\ FreeDoM & 9.4770 & 9.5516 & 10.3422 \\\\ DITTO (ours) & **8.3470** & **8.3229** & **8.5733** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 기준 픽셀, 안내 및 최적화 기반 방법에 대한 DITTO에 대한 그림 결과이다.\n' +
      '\n' +
      '그림 4: 기준 도장 방법의 실패 사례. 기준법들은 생성된 출력의 오버랩 영역과 비오버랩 영역 사이의 오디오에서 가청적인 "삼"을 생성하는 경향이 있어 의미 내용에서 부자연스러운 점프를 유발한다. DITTO는 이 문제를 피하고 전체 세대 전체에 무심코 도장을 제공합니다.\n' +
      '\n' +
      '순수한 제어 결과. 왼쪽에는 상승된 다음 하강 강도 곡선으로 생성된 스펙트로그램을 보여준다. 중간에 입력 타겟으로 생성된 스펙트로그램을 보여주고 멜로디 시각화(크로마토그램)을 생성했다. 오른쪽에는 타겟이 있는 생성된 스펙트로그램을 보여주고 ABBA 구조 패턴이 있는 자기 유사 행렬을 생성했다.\n' +
      '\n' +
      '### Efficiency Comparison\n' +
      '\n' +
      'DITTO와 세대 품질 및 제어 측면에서 DOODL을 비교하는 것 외에도 빠른 융합에 의해 느린 반복 런타임이 상쇄될 수 있고 샘플링 단계 수가 증가함에 따라 그러한 행동이 어떻게 변화하는지 실제 효율성과 수렴 속도 모두에서 어떻게 다른지 파악하고자 한다. 단순 선형화 방법과 보다 복잡한 선율 제어 사이의 중간 지면을 나타내기 때문에 강도 제어에 중점을 둔다. MSE, FAD 및 CLAP 외에도 융합(MS2C), 즉 일부 임계값(\\tau\\), 평균 최적화 속도(MOS), 최적화 단계당 평균 초수, 즉 확산 모델에 의한 최적화 동안 사용되는 평균 GPU 메모리(in GB)를 측정하는 데 필요한 평균 최적화 단계 수를 보고한다. 우리는 \\(K=70\\) 최대 최적화 단계 및 \\(\\tau=2\\) dB를 사용하여 단일 40GB A100에서 테스트를 실행한다. DOODL의 경우 20단계에서 더 높은\\(p\\)와의 심각한 발산으로 인해 월레이스(2023) 및 \\(p=0.83\\) 후 50단계에서 \\(p=0.93\\)의 혼합 계수를 사용한다.\n' +
      '\n' +
      '표 4에서 DOODL은 DITTO보다 \\(\\ 엔트렉스 2\\)x 더 느리고 \\(\\ 엔트렉스 2\\)x를 더 많이 차지한다는 것을 실증적으로 확인하는데, DOODL은 전방 및 체크포인트 백워드 패스 모두에서 모델 호출 수를 두 배로 늘리고 두 입력 사슬을 메모리에 저장하기 때문이다. 가장 두드러진 것은 DOODL이 DITTO와 실질적으로 동일한 수렴 속도를 나타냄을 발견하여 DOODL의 추가 복잡성이 최적화에 속도를 높이는 데 도움이 되지 않는다는 것을 보여준다. 샘플링 단계의 수를 증가시키는 것이 대조군 부착을 분해하는 경향이 있다는 점에 주목하며, 이는 샘플링 사슬이 길수록 역전달을 더 어렵게 만들기 때문일 수 있다. 흥미로운 사실은 샘플링 시간이 전체 FAD가 DOODL에 대해 크게 향상됨에 따라 EDICT가 샘플링 단계가 거의 없는 특히 투쟁한다는 증거를 제공하며 따라서 DOODL은 눈에 띄는 보상 해킹 없이 더 적은 단계를 사용하여 유출될 수 없다.\n' +
      '\n' +
      '### 두확산 휴면 공간 억제력.\n' +
      '\n' +
      '일반적으로 확산 잠재 공간은 이전에 GAN 잠재 공간(송 et al, 2020; Preechakul et al., 2022)에 비해 의미론적 의미를 거의 인코딩하지 않는 것으로 생각되었기 때문에 확산 모델에서 초기 잠재 \\(\\mathbf{x}_{T}\\)를 무시한다. 그러나 DITTO의 강력한 성능은 사전 훈련된 확산 기반 모델을 편집하지 않고 확산 잠재 공간 탐색을 통해 의미 있게 의미 있는 미세 구성 특징을 순전히 조작할 수 있다는 놀라운 사실을 제시한다. 우리는 이 아이디어를 더 탐구하며, 우리의 발견은 이론적으로 부록 J에서 Si et al.(2023)에 의해 언급된 저주파 구조의 인코딩에 어떻게 묶여 있는지이다.\n' +
      '\n' +
      '## 7 Conclusion\n' +
      '\n' +
      'DITTO: **D**확산**I**nference-***T**ime \\(\\mathbf{T}\\)-***O*ptimization, 음악 생성에 대한 창의적인 편집과 제어 과제를 폭넓게 가능하게 하기 위해 사전 훈련된 확산 모델을 제어하기 위한 통일된 훈련 없는 프레임워크를 제안한다. DITTO는 SOTA 편집 능력을 달성하고 완전 훈련 기반 방법의 제어 가능성과 일치하며, 시간과 기억 효율성으로 2배인 동시에 선도 최적화 기반 접근법을 능가하고 모델링 아키텍처나 샘플링 과정에 제한을 두지 않는다. 향후 연구에서는 실시간 상호 작용과 보다 표현적인 제어를 달성하기 위해 최적화 절차를 가속화할 수 있기를 기대한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c|c c} \\hline \\hline Method & DITTO & DOODL & DITTO & DOODL \\\\ Sampling Steps & 20 & 20 & 50 & 50 \\\\ \\hline MSE (\\(\\downarrow\\)) & **4.7576** & 4.7847 & **7.6404** & 8.8939 \\\\ FAD (\\(\\downarrow\\)) & **10.5294** & 12.3362 & 10.3652 & **9.9090** \\\\ CLAP (\\(\\uparrow\\)) & **0.4326** & 0.3418 & **0.3977** & 0.3114 \\\\ MS2C (\\(\\downarrow\\)) & **44.4661** & 49.2031 & **46.8550** & 47.8341 \\\\ MOS(\\(\\downarrow\\)) & **1.8594** & 4.1773 & **4.4720** & 10.0362 \\\\ MAM (\\(\\downarrow\\)) & **5.0020** & 8.2740 & **5.0941** & 8.3112 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '강도 제어에 대한 DITTO와 DOODL 간의 성과는 표 4:이다. DITTO 및 DOODL은 유사한 수의 단계에서 융합에 도달하지만 DOODL은 DITTO보다 더 덜 효율적이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c|c c c|c c c} \\hline \\hline Control & \\multicolumn{3}{c|}{**Intensity**} & \\multicolumn{3}{c|}{**Melody**} & \\multicolumn{3}{c}{**Structure**} \\\\ Metric & MSE (\\(\\downarrow\\)) & FAD (\\(\\downarrow\\)) & CLAP (\\(\\uparrow\\)) & Acc (\\(\\uparrow\\)) & FAD (\\(\\downarrow\\)) & CLAP (\\(\\uparrow\\)) & MSE (\\(\\downarrow\\)) & FAD (\\(\\downarrow\\)) & CLAP (\\(\\uparrow\\)) \\\\ \\hline Default TTM & 40.8430 & **8.6958** & 0.3732 & 0.10527 & 8.6958 & 0.3732 & 0.3091 & 8.6958 & 0.3732 \\\\ ControlNet & 38.4108 & 11.1315 & 0.3084 & 0.8135 & **7.8574** & **0.4784** & – & – & – \\\\ FreeDoM & 23.2920 & 9.5056 & **0.4823** & 0.3154 & 9.2858 & 0.4766 & **0.0177** & **6.6774** & 0.4152 \\\\ DOODL & 4.7847 & 12.3362 & 0.3418 & 0.8159 & 9.5114 & 0.3361 & 0.0742 & 9.3642 & 0.3856 \\\\ DITTO (ours) & **4.7576** & 10.5294 & 0.4326 & **0.8262** & 8.2431 & 0.4321 & 0.0237 & 7.0904 & **0.4181** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '<표 3>은성향, 선율, 구조 조절 결과이다. DITTO는 SOTA 강도와 멜로디 제어를 달성합니다. 뮤직 컨트롤넷은 강도 제어 MSE에 대한 투쟁을 합니다. 자유DoM은 구조에 대해 잘 수행되지만 보다 복잡한 선율과 강도 제어에 대한 투쟁을 수행한다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:9]\n' +
      '\n' +
      '*동 등은 (2018) 동, 호와, 호시아오, W. 양, 양, L. -C와 양, Y. H. MuseGAN: 상징적 음악 생성 및 반주를 위한 멀티 트랙 순차적 생성 적대 네트워크입니다. 인공지능_AAAI 컨퍼런스에서 2018년 1위입니다.\n' +
      '* 디보세즈(2022) 디보세즈, A, 코펫, J, 시나내브, G 및 아디, Y. 고충도 신경 오디오 압축 __고충도 신경 오디오 압축 __고충도 신경 오디오 압축. __고충도 신경 오디오 압축. arXiv 프리프린트 arXiv:2210.13438_, 2022.\n' +
      'R. __* 에릭슨 (1975) 에릭슨, R. _* 에릭슨 (1975) 에릭슨이다. 음악_의 소리 구조. 1975년 캘리포니아 언론 언비브.\n' +
      '* Forsgren & 마르티로스(2022) Forsgren, S. 이와 마티로스, H. 리퓨전: 실시간 음악 생성을 위한 안정 확산, 2022년 URL[https://riffusion.com/ 황폐] (https://riffusion.com/약)을 포함한다.\n' +
      '* Gal et al(2022) Gal, R, Alaluf, Y, Atzmon, Y, Patashnik, O, Bermano, A, Chechik, G 및 Cohen-또는 D. An 이미지는 2022년 텍스트 반전법을 사용하여 텍스트 대 이미지 생성을 개인화하는 한 마디 가치가 있다.\n' +
      '* 가르시아 등은 (2023) 가르시아, H. F., 세타르만, P. 쿠마르, R. 및 파도, B. 버프넷: 마스킹 음향 토큰 모델링을 통한 음악 세대이다. 국제 음악 정보 재평가학회(ISMIR)_ 2023년.\n' +
      '* 구파 등은 A(2023) 구타, A, 유, L, 손, K, 구, X, 한, M, 리, F-F, 에사, I, 장, L, 레자마, J. 포토레틱 비디오 생성이 확산 모델을 가지고 있다. 2023.\n' +
      '* 호로른(2022) 하노른(C), 시몬(I), 로버츠, A, 제지두르, N, 가드너, J, 마닐로우, E 및 엔젤, J. 멀티 생리 음악 합성이 스펙트로그램 확산에 따라 이루어졌다. 국제 음악 정보 재평가학회(ISMIR)_ 2022년에.\n' +
      '* He et al.(2016) He, K, 장, X, 르, S, 태양, J.딥 잔차 학습 영상 인식을 위한 학습. 컴퓨터 비전 및 패턴 인식(CVPR)_ 2016년 _IEEE 콘퍼런스에서.\n' +
      '* Hershey et al.(2017) Hershey, S., 차우드히리, S., Ellis, D. P., Gemmeke, J F., J. F., Jansen, A., 무어, R. C, Plakal, M., Platt, D., Saurous, R. A.의 대규모 오디오 분류를 위한 CNN 아키텍처입니다. 2017년 오디오, 스피치 및 신호 처리(ICASSP)_IEEE 국제 회의에서.\n' +
      '* 헤르츠 등은 A(2022) 헤르츠, A, 목다디, R, 테네바움, J, 아버만, K, 프리치, Y 및 코헨-또는 D. 프롭토 촉진 이미지 편집을 교차 주의 제어로 한다. arXiv 프리프린트 arXiv:2208.01626_, 2022.\n' +
      '*호앤살리만스(2021) 호, J, 살리만스, T. 고전기가 없는 확산 안내입니다. 딥젠에 있는 _NeurIPS 워크숍에서. 모델과 다운스트림 앱_ 2021.\n' +
      '*호 등은 (2020)호, J, J, Jain, A 및 Abbeel, P. 덴오징 확산 확률 모델. __. 신경정보처리시스템(NeurIPS)_, 2020.\n' +
      '*호 등은 (2022)호, J, 살리만스, T, 그레센코, A, 찬, W, 노루지, M 및 플렛, D. J 비디오 확산 모델. __비디오 확산 모델. arXiv:2204.03458_, 2022.\n' +
      '*황 등(2023a) 황, Q, 박, 왕, T, 덴크, T, 리, A, 체, N, 장, Z, 유, J, 프랑크, C, 확산 모델이 있는 텍스트 조건 음악 세대. arXiv:2302.03917_, 2023a.\n' +
      '*황 등은 황(2023b) 황, R, 황, J, 양, D, Ren, Y, 류, L, 리, M, 예, Z, 류, J, Yin, X 및 Zhao, Z. 신속한 강화 확산 모델이 있는 __메이크-안-오디오: 텍스트-대-오디오 생성. arXiv 프리프린트 arXiv:2301.12661_, 2023b.\n' +
      '* 카라스 등은 (2022) 카라스, T, 아칸타, M, 아릴라, T 및 메인, S. 확산 기반 생성 모델의 설계 공간을 설명합니다. 2022년 _NeurIPS_에서.\n' +
      '* 카르루나타나쿨 등은 (2023) 카루나타나울, K, 프루차콜, K, 아산, E, 베이어, T, 수와자나콘, S 및 당, S. 확산 잡음을 최적화하는 것은 보편적 운동 제사 역할을 할 수 있다. __ 만능 운동 잡음이 될 수 있다. arXiv 프리프린트 arXiv:2312.11994_, 2023.\n' +
      '* 가와르 등은 (2023) 가와르, B, 자다, S, 랑, O, 토프, O, 창, H, 데켈, T, 모세리, I 및 이란, M. 임식: 확산 모델이 있는 텍스트 기반 실제 이미지 편집입니다. 컴퓨터 비전 및 패턴 인식(CVPR)_, 2023년에 _IEEE/CVF 콘퍼런스에서.\n' +
      '* 킬고르 등은 (2018) 킬고르, K, 갈루가, M, 로블리크, D 및 샤리피, M. 페체트 오디오 거리: 음악 강화 알고리즘을 평가하기 위한 메트릭. __Frechet 오디오 거리: 음악 향상 알고리즘을 평가하기 위한 메트릭. arXiv:1812.08466_ 2018.\n' +
      '확률 최적화를 위한 방법 ___킹마 & Ba(2014) 킹마, D. P. 및 Ba, J. 아담: 확률 최적화를 위한 방법. arXiv 프리프린트 arXiv:1412.6980_ 2014.\n' +
      '* 킹마 & 웰링(2013) 킹마, D. P. 및 웰링, M. 자동 인코딩 가변 만입니다. 2013년 _국제 학습 발표 컨퍼런스(ICLR)_.\n' +
      '* 구마르 등은 (2023) 구마르, R, 세스타만, P, 루미스, A, 쿠마르, I 및 쿠마르, K. RVQGAN이 개선된 고 충실도 오디오 압축입니다. 1998년 _Neural 정보 처리 시스템(NeurIPS)_에서.\n' +
      '이씨(2022) 이씨, S.S. 핑, W, 진스부르크, B, 카탄자로, B, 윤, S. 큰 규모의 훈련을 가진 __Bigvgan: A 보편적 신경 보컬레이터. __ 대규모의 훈련을 가진 보편적 신경 보컬이다. arXiv 프리프린트 arXiv:2206.04658_, 2022.\n' +
      '* 레멘트, S. C.(2019) 레멘트, Teuwen, J, Ginneken, B v 및 만니싱, R. Memcnn: 메모리 효율적인 인버블 뉴럴 네트워크를 생성하기 위한 A python/pytorch 패키지. __Memcnn: A python/pytorch 패키지. 오픈 소스 소프트웨어_, 2019 ISSN 2475-9066. 도이: 10.21105/손실.01576.\n' +
      '* 레비 등은 (2023) 레비, M., 게리오기, B D, 위즈, F, 카타오폴로스, A 및 니손, T. 확산 모델 및 안내 구배로 제어 가능한 음악 생산. __ 확산 모델 및 지침 구배를 사용하여 제어 가능한 음악 생산. _. ArXiv_, 절대/2311.00613, 2023.\n' +
      '\n' +
      '* 류(2023a) 류, H, Chen, Z, Y, Y, Mei, X, Liu, X, 만디치, D, 왕, W 및 Plumbley, M. 오디시오LDM: 잠복 확산 모델이 있는 텍스트-대-오디오 생성. _국제기계학습회의(ICML)_, 2023a.\n' +
      '* 류 등은 (2023b) 류, H, 톈, Q, 요안, Y, 류, X, Mei, X, 콩, Q, 왕, Y, 왕, 왕, Y, 플라블리, M. 오디시오LDM 2: 자기 지도 전술을 가진 학습 전체 오디오 생성이다. arXiv 프리프린트 arXiv:2308.05734_, 2023b.\n' +
      '* 루 등 (2022) 루, C, 저우, Y, 바오, F, 첸, J, Li, C 및 주, J. Dpm 솔버++: 확산 확률 모델의 가이드 샘플링을 위한 패스트 솔버이다. ArXiv_, 절대/2211.01095, 2022.\n' +
      '1969년(1969) 마테카스, MV, 밀러, JE, 무어, F. R, 피어스, J R 및 리세트, J-C. _ Mathews et al. 컴퓨터 음악_의 기술. 1969.\n' +
      '* McFee & Ellis(2014) McFee, B. 및 Ellis, D. Analyzing 곡 구조는 스펙트럼 군집링이다. E_국제음악정보귀국회(ISMIR)_. 2014년 시저.\n' +
      '* McFee et al. (2010) McFee, B, 바링턴, L 및 Lanckriet, G. R. 학습 유사성은 협업 필터에서 유사성을 나타낸다. 2010년 _국제 음악 정보 환수학회(ISMIR)_.\n' +
      '* 목다디 등 (2023) 목다디, R, Hertz, A, Aberman, K, Pritch, Y 및 Cohen-Or, D. Null-텍스트 반전은 유도 확산 모델을 사용하여 실제 이미지를 편집하기 위한 것이다. 컴퓨터 비전 및 패턴 인식(CVPR)_, 2023년에 _IEEE/CVF 콘퍼런스에서.\n' +
      'M. __* 뮐러 (2015) 뮐러, M. __* 뮐러 (2015) 뮐러. 음악 처리의 한 가지: 오디오, 분석, 알고리즘, 애플리케이션_ 2015년 생강.\n' +
      '* 판 등은 (2023년) 판, Z, Gherardi, R, Xie, X 및 S. Huang, S. 반복 확산 반전 속도가 가속화된 효과적인 실제 이미지 편집입니다. 1998년 컴퓨터 비전(CVPR)__IEEE/CVF 국제 회의.\n' +
      '* 포올 등 (2022) 포올, B, Jain, A, Barron, J T 및 Mildenhall, B 드림퓨전: 2d 확산을 사용하여 텍스트 대 3d이다. arXiv_, 2022.\n' +
      '* 프라부데사이는 (2023) 파브라후데사이, M, 고달, A, 파탁, D 및 크라기아다키, K. 보상 역프로파고를 갖는 텍스트 대 이미지 확산 모델. _ 정렬 텍스트- 화상 확산 모델. ArXiv_, 절대/2310.03739, 2023.\n' +
      '* 페리차콜 등은 (2022) 프리차콜, K, 차테, N, 위자드왈사, S, 스와자나카콘 등이 있다. 확산 자동 암호화기: 의미 있고 해독 가능한 표상입니다. 컴퓨터 비전 및 패턴 인식(CVPR)_ 2022년에 _IEEE/CVF 콘퍼런스에서.\n' +
      '* 람바흐(2022) 루바흐, R, 블라트만, A, 로렌츠, D, 에서, P 및 Ommer, B. 고해상도 이미지 합성은 잠재 확산 모델을 가지고 있다. 컴퓨터 비전 및 패턴 인식(CVPR)_, 2022년 _IEEE 콘퍼런스에서.\n' +
      '* Ronneberger et al. (2015) Ronneberger, O, Fischer, P 및 Brox, T. 의학적 이미지 분할을 위한 U-Net:컨볼루션 네트워크. 2015년 _ 의료 이미지 컴퓨팅 및 컴퓨터 보조 협정(MICCAI)_에서.\n' +
      '* Ruiz et al. (2023) Ruiz, N, Li, Y, Jampani, V, Pritch, Y, Rubinstein, M 및 Aberman K. 드림보스: 주제 중심 생성을 위한 텍스트 대 이미지 확산 모델입니다. 컴퓨터 비전 및 패턴 인식(CVPR)_, 2023년에 _IEEE/CVF 콘퍼런스에서.\n' +
      '* 사하라리아 등은 (2022a) 사하라리아, C, 찬, W, 창, H, 이, C, 호, J, 살리만스, T, 플렛, D 및 노루지, M. 팔렛: 이미지 대 이미지 확산 모델. _ACM SIGGRAPH 회의 결과_, 2022a.\n' +
      '* 사아리아 et al.(2022b) 사아리아, C., 찬, W., Saxena, S., Li, L., Whang, J., Denton, E. L., Ghasemipour, K, Gonti조 로프, R., 카라골 아얀, B, Salimans, T. 등 언어 이해가 깊은 사진론적 텍스트 대 이미지 확산 모델. 신경정보처리시스템(NeurIPS)_, 35, 2022b.\n' +
      '* 슈나이더 et al.(2023) 슈나이더, F., 진, Z. arXiv 프리프린트 arXiv:2301.11757_, 2023.\n' +
      '* Si 등은 (2023) 시, C, 황, Z, 장, Y, Z, Liu. 확산 u-net의 자유: 확산 u-net의 무료 점심. __ 자유: 확산 u-net의 무료 점심. ArXiv_, 절대/2309.11497, 2023.\n' +
      '* 시몬타 등 (2018) 시노네타, F, 카노발리니, F, 오리오, N, 로다, A. 심볼릭 음악 유사성은 그래프 기반 표현을 통해 나타난다. E_Audio Mostly 2018에서는 면역과 Emotion_의 Sound에 관한 것이다. 2018.\n' +
      '* 스칼세 등 (2022) 스칼세, J, 하예, N, 크라스펜니코프, D 및 쿠에거, D. 디바이징 및 특성화 보상 게임. 신경정보처리시스템(NeuralPS)_, 2022년 35.\n' +
      '* 소릴-디키슈타인 등은 (2015) 소울-디케스타인, J, 웨이스, E, 매서워라노사탄, N 및 강리, S. 비평형 열역학을 이용한 심층 비지도 학습. 2015년 _국제기계학습회의(ICML)_.\n' +
      '* 송 등은 (2020) 송, J, 멍, C, 에르몬, S. 덴노징 확산 암묵적인 모델입니다. 2020년 _국제 학습 발표 컨퍼런스(ICLR)_.\n' +
      '심리적 크기 피치의 측정을 위해 E. B.(1937) 스테벤스 등 (1937) 스테벤스, S. S., 볼크만, J. 및 뉴먼, E. B. A 척도. 1937년 미국 음향학회(JASA)_ 저널.\n' +
      '* 월레이스 등 (2023a) 월레이스, B, 곡물, A, 에르몬, S 및 N백, N. End-to-말단 확산 잠재 최적화는 분류기 지침을 향상시킨다. IEEE/CVF 국제 컴퓨터 비전(ICCV)_, 절대/2303.13703, 2023a.\n' +
      '\n' +
      '* 월레이스 등은 (2023b) 월레이스, B, 곡물, A, N N. EDICT: 결합 변환을 통한 엑택트 확산 반전. 컴퓨터 비전 및 패턴 인식(CVPR)_, 2023b에 대한 _IEEE/CVF 콘퍼런스에서.\n' +
      '* 왓슨 등은 (2022) 왓슨, D, 찬, W, 마르틴-브루갈라, R, 호, J, 타글리아스코치, A 및 노루지, M. 확산 모델을 사용한 새로운 뷰 합성 __ 노벨 뷰 합성은 확산 모델이다. ArXiv_, abs/2210.04628, 2022.\n' +
      '* 우(2023a) 우, S. 음악 생성을 위한 멀티플렉스 타임바링 컨트롤: __L, 돈아에, C, 와타나베, S 및 브라이언, N. J 뮤직 컨트롤넷. ArXiv_, 절대/2311.07069, 2023a.\n' +
      '* 우 등은 우(2023b) 우, Y, 첸, K, 장, T, 후이, Y, 베르그-커크패트릭, T 및 두보노프, S. 특징 융합 및 키워드 대 소비 증강으로 대규모 대비 언어-오디오 척을 한다. E_IEEE 국제 오디오 컨퍼런스에서 스피치 및 신호 처리(ICASSP)_, 2023b.\n' +
      '*샤 등은 (2021) 샤, W, 장, Y, 양, Y, 주, 주, B, 양, M. H. 간 반전: A 조사. __Gan 반전: A 조사. __Gan 반전: A 조사. _Gan 반전: A 조사. IEEE 전환은 2021년 패턴 분석 및 기계 지능_, 45에 관한 것이다.\n' +
      '*유 등은 무훈련 에너지 유도 조건부 확산 모델 __자유: 무훈련 조건부 확산 모델. (2023) 유, J, 왕, Y, 자오, C, 가템, B 및 장, J. 자유. IEEE/CVF 국제 컴퓨터 비전(ICCV)_, 2023.\n' +
      '* 제지두르 등은 (2021) 제지도르, N, 루이스, A, 오므란, A, 스콜로문트, J 및 타글리아카치, M. 소리스트림: 안 종단 간 신경 오디오 코덱. __ 말단은 신경 오디오 코덱. IEEE/ACM 거래는 2021년 오디오, 스피치 및 언어 처리(TASLP)_, 30에 관한 것이다.\n' +
      '* 장 등은 (2023) 장, 라오, A, 아크로팔라, M. 텍스트 대 이미지 확산 모델에 조건부 제어를 추가하세요. 1998년 컴퓨터 비전(ICCV)__IEEE/CVF 국제 회의.\n' +
      '* 자오 등은 (2023) 자오, S, 첸, D, 첸, Y. -C, Bao, J, 하오, S, 원, L 및 원, K. 텍스트 대 이미지 확산 모델에 대한 __. 유니 컨트롤넷: 올인원 제어: 텍스트 대 이미지 확산 모델에 대한 제어. _Y. K. 유니 컨트롤넷: 올인원 제어. arXiv:2305.16322_, 2023.\n' +
      '\n' +
      '확인서 A.\n' +
      '\n' +
      '덴노징 확산 확률 모델(DDPM)(Sohl-Dickstein et al., 2015; Ho et al., 2020) 또는 확산 모델은 생성 잠재 변수 모델 부류이다. 그들은 정방향 및 역방향 랜덤 마코프 공정에 의해 정의된다. 직관적으로 정방향 과정은 청정 데이터를 취하고 노이즈로 반복적으로 방해하여 (노징) 신경망을 훈련시키고 역과정은 랜덤 노이즈를 취하고 학습된 네트워크로 반복 리필하여 새로운 데이터를 생성한다.\n' +
      '\n' +
      '순방향 과정은 마코프 체인으로 정의된다.\n' +
      '\n' +
      '(\\mathbf{x}_{t}) \\tag{d_{t}(\\mathbf{x} <\\math{t}_{t}} <\\math{f}_{t}) <\\math{f} <\\math{x} <\\math{x}> <\\math{f} <{t}> <\\math{t}> <\\math{f} <{t}> <\\math{t} <{math{t} <{t} <{math{t} <{t} <{f} <{t} <{t} <{f} <{t} <{f} <{t} <{t} <{f} <{t} <{f}> <{t} <{t} <{f} <{t} <{f} <{t} <{t} <{f} <{t}> < <{t}>>> < <\\math{t}>> < <\\math{t}> < <\\math{t}\n' +
      '\n' +
      'HH(q(\\mathbf{x}_{0})\\는 진정한 데이터 분포, \\(q(\\mathbf{x}_{T})\\는 표준 정규 가우시안 분포, \\(0<\\beta_{1}<\\beta_{2}<\\cdots<\\beta_{T})는 노이즈 일정 변수이고,\\(T\\)는 노이즈 단계의 총 수이다. 고정 정방향 데이터 부패 과정의 효율성을 높이기 위해 (5)를 단순화하여 정방향 데이터 부패 과정의 효율성을 향상시킬 수 있다.\n' +
      '\n' +
      '>\\mathbf{x}(\\math{f}_\\math{f})\\math{f}.\n' +
      '\n' +
      'I\\(알파_{t}=1-\\beta_{t}), \\(\\t{\\alpha}_{t}==\\prod_{i =1}^{t}\\alpha_{t}}\\) 및 \\(\\mathbf{\\on}\\)는 표준 정상 가우시안 노이즈로서 깨끗한 데이터 \\(\\mathbf{x}_{t}_{t}_{t}_{t}_{t}_{t}_{t}_{t}_{t}_{t}_{t}_{t}:\\)를 제공하는 모든 단계에 대한 전방 샘플링을 가능하게 하여,\\_\\_\\bf{t}.\n' +
      '\n' +
      '전방 과정을 감안할 때, 우리는 모델 분포 \\(p_{\\theta}(\\mathbf{x}_{0})\\(q_{\\theta}(\\mathbf{x}_{0})\\)를 지정할 수 있다. \\(p_{\\theta}(\\mathbf{x}_{0})를 쉽게 샘플링하기 위해 데이터 생성 과정을 지정한다.\n' +
      '\n' +
      '<p_{theta}>=p_{theta}(\\mathbf{T}) <\\math{T} <{{t}> = <\\math{T}} <\\math{x}> <\\math{f}} <\\math{x} <{f}> <\\math{x}.\n' +
      '\n' +
      'HH(\\mathbf{x}_{0}), 즉,\\mathbf{x}_{T}\\)는 모두 동일한 데이터 공간에서 잠재 변수이다.\n' +
      '\n' +
      '진정한 데이터 생성 과정(4)과 모델(9)을 감안할 때, 우리는 신경망을 트레이닝하여 \\(\\mathbf{x}_{t-1}\\)를 통해 중간 시끄러운 데이터 \\(\\mathbf{x}_{t}\\)를 복구할 수 있다. 데이터 가능성에 대한 가변적 하위 결합(킹마 및 웰링, 2013)을 최적화하여 노이즈 \\(\\mathbf{\\epsilon}\\)를 예측하면(\\mathbf{\\epsilta}_{\\theta}(\\mathbf{x}_{t},t) 매개변수를 사용하여 적절한 신경망을 학습할 수 있음을 보여주었다.\n' +
      '\n' +
      '{f{x}}\\mathbf{\\epsilon}}\\mathbf{}\\mathbf{{x}(\\mathbf{x}_{t})\n' +
      '\n' +
      'I\\(t\\)가 확산 시간 단계인 경우.\n' +
      '\n' +
      '학습된 \\(\\mathbf{\\epsilon}_{\\theta}(\\mathbf{x}_{t},t)를 감안할 때 우리는 역방향 확산 과정인k.a를 통해 새로운 데이터를 생성할 수 있다. 그러기 위해 우리는 가우시안 노이즈 \\(\\mathbf{x}_{T}\\sim\\mathcal{N}(0,I)를 무작위로 샘플링한다.\n' +
      '\n' +
      '}}\\mathbf{x}}\\mathbf{f} <\\math{{t>}}{\\math{1-\\tpha}}\\mathbf{\\epf}_{\\t}.\n' +
      '\n' +
      '분틸 \\(t=0\\)은 \\(T\\) 변성 반복 후 생성된 데이터 \\(\\mathbf{x}_{0}\\)를 생성한다. 고품질의 세대를 얻기 위해 \\(T\\)는 일반적으로 큰(예: \\(1000\\)이며, 이는 느린 생성 과정을 초래한다.\n' +
      '\n' +
      '샘플링(기준)의 계산 비용을 줄이기 위해 송 등은 데노징 확산 암묵 모델(DDIM)을 제안했다. DDIM은 스스로 대체 샘플링 제형을 생성하는 대체 변이 최적화 목표를 사용한다.\n' +
      '\n' +
      '}\\mathbf{t}}\\math{t}} <\\math{t}} <\\math{t}} <\\math{t} <\\math{t}> <\\math{t}} <\\math{t}>와 <\\math{t}} <\\math{t>}} <\\math{t} <\\math{t} <\\math{t{t>}} <\\math{t{t{t{t{t{t{f{t{t}}{t{t{f{t{t}}{t{t{t{f{t{t{t}}{t{t{t{t{t{t}} <\\f{t{t{t{t}} <\\f{t{t}} <\\s{t{t>}} <\\f{t{t>}} <\\d{t>}} <\\f{t} <\\f{t>}} <\\f{t} <\\f{t>}} <\\f{t 이 제형은 생성 품질에 최소한의 영향을 미치는 추론(예: \\(50\\심 100\\)) 동안 필요한 샘플링 단계의 수를 최소화한다. 또한, DDIM의 특수 사례는 \\(\\sigma_{t}=1-\\alpha_{t-1})/(1-\\alpha_{t-1})}\\sqrt{1-\\alpha_{t}/\\alpha_{t}/\\alpha_{t-1}}}), DDIM 샘플링이 \\(\\sigma_{t}=0\\)이 완전히 결정적이 되면 2배 1) 2배이다.\n' +
      '\n' +
      '텍스트 컨디셔닝을 개선하기 위해 분류기가 없는 안내(CFG)를 사용하여 조건부 및 무조건적인 생성 출력과 트레이드 오프 컨디셔닝 강도, 모드 커버리지 및 샘플 품질(호 및 살리만, 2021)을 혼합할 수 있다. CFG로 모델을 트레이닝하는 경우, 컨디셔닝은 시간의 일부분의 널 값으로 랜덤하게 설정된다. 추론하는 동안 확산 모델 출력 \\(\\mathbf{\\epsilon}_{\\theta}(\\mathbf{x}_{t}_{t},t,\\mathbf{c}_{\\text{text}})로 대체된다.\n' +
      '\n' +
      '(\\mathbf{t},\\mathbf{f},\\mathbf{f},\\mathbf{f})\n' +
      '\n' +
      '\\(\\mathbf{c}_{\\text{text}}\\)가 텍스트 임베딩이고, \\(w\\)는 CFG 스케일링 팩터이고, \\(\\mathbf{c}_{\\ financingyset}\\)는 널 임베딩이다.\n' +
      '\n' +
      '정정하지 않은 레이어가 있는## 부록 B EDICT 및 DOODL과\n' +
      '\n' +
      '커플링된 트랜스폼 또는 EDICT를 통한 커플링 디확산 반전은 _exact_ 확산 반전 가능하도록 월레이스 등(2023b)에 도입된 샘플링 방법이다. EDICT는 두 개의 상관 확산 사슬인 \\(\\mathbf{x}^{\\prime}_{t}\\)와 \\(\\mathbf{x}^{\\prime\\prime}_{t}\\)에 의해 다음과 같은 업데이트를 통해 이를 달성한다.\n' +
      '\n' +
      '}}.\n' +
      '\n' +
      '제1 두 선이 아핀 결합층을 나타내고 마지막 두 선이 고정된 혼합 계수 \\(p\\)와 층을 혼합하는 경우이다. 이 샘플링 절차는 정확히 상쇄될 수 있는 이점이 있다.\n' +
      '\n' +
      '}}{{.\n' +
      '\n' +
      '이중 사슬 샘플링 접근법의 한 가지 결과는 두 사슬이 분기되지 않도록(특히 낮은 샘플링 단계에서) 충분히 낮을 필요가 있고 사슬을 반전시킬 때 수치 정밀 오차를 방지하기 위해 충분히 높으므로 \\(p\\) 혼합 매개변수를 설정하는 데 고유한 절충이다.\n' +
      '\n' +
      'DOODL에 대한 공식 구현에서는 EDICT의 인버시티를 사용하지 않으며 대신 EDICT 샘플러에 정상적인 체크포인트를 사용하여 4x의 모델 호출 수를 표준 역프로파이션으로 사용한다. 그러나 EDICT의 가역적 특성을 감안할 때 DOODL은 _all_ 기능 입력을 메모리에 저장하기보다는 역 동작을 직접 사용하기 위해 대안적으로 공식화될 수 있다. 이 설정에서 최종 \\(\\mathbf{x}_{0}\\)만을 GPU 메모리에 저장한 다음 역 샘플링 작업을 사용하여 기능 입력을 재계산한 다음 모델을 통해 다시 통과시켜 구배 계산을 위한 중간 액티베이션을 재조정한다. 이 절차는 DOODL과 DITTO의 공식 구현보다 기억 효율이 높지만 _sextuples_ 모델 호출 및 런타임 수는 추론 시간 잠재 최적화를 위한 가장 느린 절차이다. 그림 5는 두 세트를 더 자세히 설명한다.\n' +
      '\n' +
      '도보.\n' +
      '\n' +
      '이러한 입력들에 대해 완전히 훈련되었음에도 불구하고 강도 제어 작업에 대한 음악 제어넷(Wu et al., 2023)의 놀라운 통제 성능을 감안할 때, 우리는 제어 순응을 이해하기 위한 대체 메트릭들을 조사했다. 특히, 우리는 음악 제어넷이 세기 _상관_를 암묵적으로 모델링하고, 곡선 자체의 절대 dB 값보다 시간에 따른 강도 곡선의 전체 형태에 더 주목한다는 것을 발견했다. 우리는 UNet 백본 컨볼루션(상관) 계층이 규모와 위치 불변임을 감안할 때 이것이 의미가 있다고 믿는다. 이 결과를 감안할 때, 우리는 \\(\\mathcal{L}\\propto-\\rho(f(\\mathbf{x}_{0}),\\mathbf{y})\\을 설정하거나 표적 및 출력 강도 곡선 간의 상관 관계를 최대화하여 상관성을 직접 최적화하기 위해 강도 제어를 대안적으로 매개할 수 있다.\n' +
      '\n' +
      '표 5에서 우리는 음악제어넷, DITTO, DITTO에 대한 절대 MSE와 상관성 \\(\\rho\\) 값을 상관관계 기반 손실 함수와 모두 보여준다. 음악 제어넷은 강도 상관에 대한 탁월한 성능을 갖는 반면, 기준 DITTO는 최적화 목적을 감안할 때 상관 관계에 비해 절대 강도를 우선한다. DITTO는 상관 목표로 전환함으로써 음질 품질 및 텍스트 관련성에서 절대 강도 DITTO의 성능을 일부 유지하면서 모두 음악 제어Net의 상관 성능에 거의 부합할 수 있다. 이 실험은 신속한 실험을 위해 의도된 행동을 변경하기 위해 DITTO의 유연한 설정에서 단일 타겟 특징이 어떻게 파라미터화될 수 있는지 보여준다.\n' +
      '\n' +
      '실시간 반전 D D DITTO.\n' +
      '\n' +
      '실제 참조 매체 \\(\\mathbf{x}_{\\text{ref}}}\\)를 생성 모델의 잠재 공간으로 인코딩하는 작업 또는 작업은 이미지 및 오디오 편집 작업(송 et al, 2020, Dhariwal and Nichol, 2021, 샤, 2021, 목다디 등, 2023)에 중요하다. 과거의 음성 도메인 반전 작업은 매우 제한적이지만 과거 이미지 도메인 방법에는 입력(송 et al, 2020), DDIM 샘플링 프로세스(Dhariwal and Nichol, 2021)를 반전시키고 반전 정확도를 향상시키기 위해 추가 _null-텍스트_ 파라미터(Mokady et al, 2023)를 배우는 것이 포함된다. (\\mathbf{x}_{0})=\\mathbf{x}_{0}\\), \\(\\mathbf{y}=\\mathbf{x}_{\\text{ref}_{\\f}) 및 손실(\\mathcal{L}\\math{L}\\mathbf{x}_{f}:\\)을 설정하여 반전 작업을 위해 DITTO를 사용한다. 그런 다음 (2)를 해결해 \\(\\mathbf{x}_{T}\\)를 찾아 (3)가 목표 기준 매체 \\(\\mathbf{x}_{0}\\)를 재구성하는 \\(\\mathbf{x}_{0}\\)를 생성할 수 있다. 고품질 재건축은 완전히 쉽게 가능합니다.\n' +
      '\n' +
      '그림 5: DOODL에 대한 포워드 및 백워드 패스, 공식 구현 및 대안적으로 EDICT 인버블 레이어를 사용하여 DOODL에 대한 포워드 패스이다. 표준 DOODL 백프로프는 EDICT 샘플링으로 인한 모델 호출의 수를 두 배로 증가시켰지만 체크포인팅을 사용하여 각 타임스팟에 대한 기능 입력을 저장한다. EDICT의 인버시티를 사용할 때 최종 출력만 메모리에 저장되지만 반전 과정은 뒷면 패스 동안 타임스팟당 2개의 _모어_ 모델이 통과해야 한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c} \\hline \\hline Method & MSE (\\(\\downarrow\\)) & \\(\\rho\\) (\\(\\uparrow\\)) & FAD (\\(\\downarrow\\)) & CLAP (\\(\\uparrow\\)) \\\\ \\hline Music ControlNet & 38.4108 & **0.9413** & 11.1315 & 0.3084 \\\\ DITTO (\\(\\mathcal{L}\\propto||f(\\mathbf{x}_{0})-\\mathbf{y}||_{2}^{2}\\)) & **4.7576** & 0.6166 & **10.5294** & **0.4326** \\\\ DITTO (\\(\\mathcal{L}\\propto-\\rho(f(\\mathbf{x}_{0}),\\mathbf{y})\\)) & 60.8952 & 0.9040 & 11.0858 & 0.3503 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '<표 5>는 음악제어넷과 DITTO에 대한 강도 상관도 결과와 표준 및 상관성 기반 손실함수가 모두 나타났다. 절대 집약도 대신 상관관계를 최적화하여 오디오 품질과 텍스트 관련성을 향상시키면서 음악제어넷의 상관관계를 일치시킬 수 있다.\n' +
      '\n' +
      '수직 가능한 EDICT 샘플러(Wallace et al., 2023b)는 이중 사슬 완전 결정론적 샘플링(Pan et al., 2023)에 의해 역 콘텐츠로 추가 편집이 복잡하다.\n' +
      '\n' +
      '생성 텍스트 조건 모델의 경우 역전 방정식의 핵심 요소는 텍스트(호 및 살미만, 2021)를 통한 제어 가능성 향상에 도움이 되는 _분류자 무함유 안내_ 파라미터의 척도이지만 분류자가 없는 안내 결과를 사용하여 단순 DDIM 기반 반전(모카디 등, 2023)과 분기함에 따라 반전 과정을 더욱 어렵게 만든다. DDIM 샘플링 과정을 모델을 통해 역전된 참조 스펙트로그램, DDIM 샘플링 과정을 실행하는 DDIM 기반 반전, DDIM 반전(모카디 et al, 2023) 방법에 가우시안 노이즈를 추가하는 Naive 역전 방법과 비교하여 DDIM 반전에서 시작하여 시간 의존적 무조건 텍스트 임베딩 \\(\\mathbf{c}_{\\mathbf{0},t}\\)을 학습하여 높은 유도 척도의 존재를 개선한다. 우리는 널 텍스트와 마찬가지로 DDIM 역전을 DITTO의 초기 추측으로 사용한다.\n' +
      '\n' +
      '목표가 참조 오디오의 직접적인 레크리에이션이기 때문에 전체 5K-샘플 음악 캡 데이터 세트에 걸쳐 MSE 재구성을 보고한다. 우리는 4가지 다른 지침 척도(순수한 무조건 0에서 7.5로 변경)에 걸쳐 이 평가를 실행하며, 또한 기준 6차 모델뿐만 아니라 _24_2차 음악 생성 모델 모두에서 이를 실행하며, 이는 기본 모델로서 동일한 훈련 하이퍼파라미터와 모델 크기를 모두 유지하고 출력 치수가 \\(2048\\t 160\\ 1\\)라는 점에서 차이가 있다. 표 6에서 DITTO가 null-텍스트 반전보다 약간 더 나쁜 6개의 2차 기본 모델에서 가장 높은 안내 척도를 제외하고 모든 지침 척도 및 모델 크기에 걸쳐 다른 모든 반전 방법을 박멸한다는 것을 보여준다. 특히, 24개의 두 번째 모델에 대한 DITTO의 우수한 성능은 이미지 크기(as \\(\\mathbf{x}_{T}\\)로 자유 파라미터의 수를 스케일링하는 것이 높은 안내가 있는 상태에서 재구성 품질을 유지하는 데 도움이 되는 반면, 이미지 크기(유사 null-텍스트 반전)로 스케일링하는 방법은 이러한 이점이 없음을 보여준다.\n' +
      '\n' +
      '질적으로, 우리는 널-텍스트 역전이 부르던 보컬을 트럼펫 또는 타버린으로 교체하는 것과 같은 재구성된 오디오에서 독특한 의미론적 아티팩트를 나타내는 반면 DITTO는 이러한 실패 사례를 회피한다는 것을 발견했다. 기본 모델에 대한 모든 학습 데이터가 순수하게 기악음악에 있었기 때문에, 이것은 DITTO가 TTM 확산 모델이 그들의 학습 데이터의 분포 외부의 실제 오디오와 상호작용할 수 있게 한다는 것을 보여준다. 추가 작업에서 반전 입력(이미지 도메인에서 흔히 볼 수 있는)이 필요한 더 복잡한 편집을 탐색하여 EDICT 기반 접근법과 비교하기를 바란다.\n' +
      '\n' +
      '표백.\n' +
      '\n' +
      '우리는 일반적으로 기존의 오디오를 원활하게 취하여 스스로 혼합하는 긴 형태의 참조 기반 루프 생성에 초점을 맞추고 있지만, DITTO는 무조건 짧은 음악적 루프를 생성하려고 하는 짧은 형태의 참조-_free_ 루프 생성에도 사용될 수 있다는 점에 주목한다. 이 프레임워크는 기준 기반 루프링과 유사하지만 대신 생성된 오디오를 일부 고정된 참조 오디오로 정의하기보다는 _itself_로 다시 루프로 정의한다. r\\(\\math{f},2}\\math{f}}.{math{math{f}}.{math{f}) 및\\(\\math{f}}{math{f} <\\math{f}:{f}<\\math{f}.{f}.{f}<\\math{f}.{f}.{math{f}.{math{math{math{f}.{math{math{math{math{math{math{math{math{math{math{math{math{f}}}.{f}}.{math{math{math{f}}.{math{math{f}>}}.{f}}.{f}.{f}}.{f}.{f}.{f}.{f}.{f}.{f}.{f}.{f}.{f}.{f}.{f}.{f}.{f}}.{f} 우리는 \\(\\mathbf{M}_{\\text{gen}_{\\text{gen},2}\\)를 스펙트로그램(가장자 중 하나 미만)에서 더 일찍 발생시킴으로써, 우리는 전체 컨텍스트 창(우리 경우, 6초)보다 작거나 동일한 길이의 루프를 생성할 수 있다는 점에 주목한다. 그림 6에서 우리는 \\(o=0.5\\) 두 번째 중첩과 총 두 번의 반복을 갖는 기준 없는 루프링의 스펙트로그램과 고리 경계가 빨간색으로 표시된다.\n' +
      '\n' +
      '부록.\n' +
      '\n' +
      '본고에서 단순 음악 구도(\'ABA\' 같다)를 통해 고차원 음악 형태를 제어하는 것으로 우리 세대에게 기존 곡의 구조를 집중시키고 있지만, 우리는 또한 직접적으로 _transfer__transfer_가 직접 음악적 구조 조절 과제를 집중시킬 수 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c c|c c c c} \\multirow{2}{*}{MSE \\((\\downarrow)\\)} & \\multicolumn{4}{c|}{6 seconds} & \\multicolumn{4}{c}{24 seconds} \\\\  & \\(w=0\\) & \\(w=1\\) & \\(w=4\\) & \\(w=7.5\\) & \\(w=0\\) & \\(w=1\\) & \\(w=4\\) & \\(w=7.5\\) \\\\ \\hline Naïve & 0.0678 & 0.0668 & 0.0714 & 0.0787 & 0.1044 & 0.1042 & 0.1071 & 0.1122 \\\\ DDIM & 0.0115 & 0.0072 & 0.0192 & 0.0334 & 0.0089 & 0.0072 & 0.0115 & 0.0179 \\\\ NT & 0.0043 & 0.0072 & 0.0055 & **0.0072** & 0.0057 & 0.0072 & 0.0057 & 0.0060 \\\\ DITTO (ours) & **0.0011** & **0.0010** & **0.0025** & 0.0075 & **0.0011** & **0.0011** & **0.0015** & **0.0023** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 상황 크기 및 지침 강도에 걸친 반전 결과는 표 6이다. DITTO는 대부분의 경우 SOTA 재구성을 수행하고 컨텍스트 크기로 눈에 띄게 스케일을 수행한다.\n' +
      '\n' +
      '유사한 과정을 거쳐 DITTO. 주어진 구도를 기반으로 한 목표 자기 유사 행렬을 생성하는 대신 \\(\\mathbf{y}=\\mathbf{T}(y)\\mathbf{T}(y)^{\\top}\\)를 설정할 수 있으며, 여기서\\(y\\)는 _real_ 곡의 멜-전망이며 \\(\\mathbf{T}(\\cdot)는 MFCC 기반 타임브러브-추출 기능이다. 이와 같이 \\(\\mathcal{L}\\propto\\|f(\\mathbf{x}_{0})-\\mathbf{y}\\|_{2}^{2}\\)를 사용하여 DITTO를 사용하여 기존 음악적 단편의 미세한 자기 유사 행렬과 일치하는 음악을 생성할 수 있다. 여기서 우리는 2D 사비츠키-골레이 단계를 출력 자기 유사 행렬에 걸쳐 생략하고, 여기서 우리는 광범위한 음악적 형태를 포착하려는 것보다(광범위한 음악적 형태를 포착하려는 것보다) 인트라-프레이 유사성 구조와 직접 일치하기를 원한다. 우리는 표적을 가진 스펙트로그램의 예를 보여주고 그림에서 자기 유사 행렬을 생성했다. 프리뮤직 아카이브 데이터셋(Defferrard et al, 2017)의 노래에서 목표 자기 유사 행렬을 추출한 7개이다.\n' +
      '\n' +
      '응답자 G.\n' +
      '\n' +
      '확산 잠재 최적화(Wallace et al., 2023a)에 대한 이전 작업과 달리 DITTO는 최적화 절차를 수행하는 데 사용되는 샘플링 과정에 제한을 두지 않으므로 수행제 확산 모델 샘플링 알고리즘을 선택할 수 없다. 즉, 조건부 확산 환경에서 샘플 품질을 개선하기 위한 SOTA 확산 샘플러인 DPM-솔버++(Lu et al., 2022)를 사용하여 탐구한다. 외화 및 강도 조절을 테스트 사례로 사용하여 표 7에서 MSE 및 FAD 결과를 보여준다. DDIM이 강도 조절 과제에 대해 DPM++보다 _better_이지만 DPM++가 도장 작업에 약간 더 좋다고 흥미롭다. 우리는 다른 확산 샘플링 알고리즘이 노이즈 잠재 최적화 과정에 어떻게 영향을 미치는지 이론적으로 그리고 실증적으로 발견하는 미래 작업을 초대한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c} \\hline \\hline Target & Sampler & MSE & FAD \\\\ \\hline Intensity & DDIM & 4.77 & 10.53 \\\\ Intensity & DPM++ & 6.30 & 11.04 \\\\ Outpainting & DDIM & – & 9.19 \\\\ Outpainting & DPM++ & – & 9.12 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: DITTO에 대한 다른 샘플러의 비교. DDIM은 강도 작업에 대해 DPM++보다 견고하게 더 잘 작동하며 DPM++는 실화에 대해 약간 더 잘 형성된다.\n' +
      '\n' +
      '그림 6: \\(o=0.5\\) 초과의 중첩을 갖는 참조 없는 루프 생성이다. 루프 경계는 빨간색으로 표시된다.\n' +
      '\n' +
      'H 멀티믹스.\n' +
      '\n' +
      '(Wu et al., 2023a)에 의해 영감을 받아 다객관적 최적화 설정에 대한 _multiple_ 특징 매칭 기준을 통합하기 위해 DITTO의 유연성을 활용할 수 있다.\n' +
      '\n' +
      '}}(f_{i},\\mathbf{x}_{i}),\\mathbf{x}_{i}}.\n' +
      '\n' +
      '우리는 각각의 손실 함수의 다른 스케일을 균형을 맞추기 위해 추가로 \\(\\lambda_{i}\\) 가중치를 포함하는 곳. DITTO의 일반성을 감안할 때, 이것은 편집 _and_ 제어 신호를 동시에 조합할 수 있게 하여, 긴 형식의 음악을 미세 작곡된 시간 제어와 반복적으로 구성하는 능력을 효과적으로 잠금 해제한다. 여기에서 우리는 여러 기준 없는 대조군의 조합을 보여주는 두 가지 강도+구조와 참조 기반 편집 방법으로 참조가 없는 대조군이 어떻게 구성될 수 있는지 보여주는 인테르펜스+아웃그림을 모두 실험한다. 두 실험 모두에서 원시 dB 공간에서 강도가 계산됨에 따라 \\(\\lambda_{\\text{ 세기}}=1/40\\) 및 기타 모든 \\(\\lambda_{i}=1\\)를 설정했다. 인플루언스+좌표 제어의 경우 \\(o=2\\) 초과의 중첩을 사용하고 _논오버핑_ 구간에 대한 강도 곡선만을 최적화하여 우 등(2023a)의 "안티케어" 영역과 유사한 효과를 갖는다. 그림 8과 9에서 두 실험에 대한 스펙트로그램과 출력 특징을 보여준다.\n' +
      '\n' +
      '표## 부록 I은 최적화된 항균제를 무증식했다.\n' +
      '\n' +
      'DITTO와 같은 추론-시간 최적화 방법의 핵심 병목화는 최적화 절차가 주어진 특징과 일치하는 단일 출력을 생성하여 확장성을 제한하기 위한 명백한 필요성이다. 이러한 효과를 완화하고 사용자를 위한 창의적인 작업 흐름을 가속화하기 위해 우리는 초기 최적화된 특징 신호를 따르는 다양한 출력을 생성하기 위해 _reuse_ 최적화된 래치 \\(\\mathbf{x}_{T}^{*}\\)를 탐색한다.\n' +
      '\n' +
      '일부 초매개체 \\(\\mathbf{x}_{T}{T}^{*}},\\sigma^{2}}\\) 모델에 대한 잠재 공간 내에 있는 일부 정규 분포(\\mathbf{x}(\\math{x}_{T}^{*},\\sigma^{*})의 평균으로서(\\mathbf{x}<\\sigma^{2}}}.{T}.{T}.{T}}.{T}.{T}}.{T}.{T}.{T}}.{T}}.{T}}.{T}.{{{*}}.{T}.{T}.{{*},\\)의 평균으로\\)를 처리한 다음 최적화된 래트에 재사용가능성)를 샘플링하는 것은 각\\(\\mathbf{x}}.{T}}.{T}}.{T}.{{*}}.{T}}.{{*}}.{T}}.{{*},\\)의 평균으로 처리하고,\\ 우리는 이 과정이 실무에서 최적화된 특징으로부터 상당한 분산을 초래하고, 이를 남기게 된다는 것을 발견하게 된다.\n' +
      '\n' +
      '그림 7: 실제 음악 오디오에서 추출한 자기 유사성 MFCC 행렬을 대상으로 하는 뮤지컬 구조 전송이다.\n' +
      '\n' +
      '그림 8: 특징 추출기로 설정된 강도와 구조를 갖는 다중 주관적 DITTO에 대한 출력 스펙트로그램, 강도 곡선 및 MFCC 자기 유사 행렬이다.\n' +
      '\n' +
      '그림 9: 특징 추출기로 설정된 그림과 강도를 갖는 다중 요소 DITTO에 대한 출력 스펙트로그램 및 강도 곡선을 보여준다. 중첩은 \\(o=2\\) 초로 설정되며, 강도 조절은 비오버핑 구간에 대해서만 적용된다.\n' +
      '\n' +
      '향후 작업을 통해 더 나아가 탐구할 수 있습니다. 대신, 우리는 실제로 (12)의 DDPM(DITTO 동안 여전히 _결정적_샘플러를 확률적 샘플러로서 사용하는 것)과 같은 추론 시간에 확률적 샘플링 알고리즘으로 전환하는 것만큼 간단한 \\(\\mathbf{x}_{T}^{*}\\)에서 시작하는 확률적 _객체_를 샘플링하는 경우가 최적화 과정을 상당히 더 어렵게 만드는 경향이 있다고 생각한다. 또한 DITTO 동안 사용된 초기 프롬프트 \\(\\mathbf{c}_{\\text{text}}\\)가 다양하여 확률성의 또 다른 출처를 추가하는 경우를 탐구한다.\n' +
      '\n' +
      '이 실험에서 DITTO를 DDIM으로 수행한 후 확률 궤적을 샘플링하기 위해 최적화된 래치(1)를 재사용하기 위한 두 가지 가능한 방법을 비교하고 추론 시간에 DDPM을 사용하여 샘플과 추론 시 DDPM을 사용하고 추론을 위해 DDPM을 사용한 다음 각 DDPM 단계에서 자유DoM(유 et al, 2023) 안내 업데이트를 포함한다. 선택의 시작 잠복 및 확률적 샘플링 알고리즘으로\\(\\frac{B}{B}{i}}{B}^{i}}\\)를 측정하고 \\(\\f{B}^{i}}\\)를 사용하여\\(\\frac{B}{i}1}\\b}{B}\\)를 테스트하고(\\math{B}{i}}<\\math{B}{i}}<\\.{B}<\\.{B}<\\.{i}.{B}<\\.{B}<\\.{B}<\\.{B}<\\.{B}<\\.{B}<\\.{B}<\\.{B}<\\.{B}<\\.{i>}<\\.{B}<\\.{B}<\\.{B}<\\.{B}<\\.{B}<\\.{i>}<\\.{B}<\\.{i>}<\\.{B}<\\.{i>}<\\.{i>}<\\.{i>}<\\ 우리는 각 \\(\\mathbf{x}_{0}{0}^{{(i)}\\)가 무작위 프롬프트(\\mathbf{c}_{i}\\)로 생성되며, 각각의 프롬프트가 초기 프롬프트(\\mathbf{c}_{i}=\\mathbf{c}_{i}=\\mathbf{c}_{i}=\\mathbf{c}_{i})에 고정되어 컨디셔닝에서 추가 확률성의 효과를 측정하는 이 실험을 수행한다.\n' +
      '\n' +
      '표 8에서 배치 크기 \\(B=10\\)로 강도, 선율, 음악적 구조 제어에 대한 결과를 보여준다. 특히, 샘플링 동안 기준선 DDPM으로 전환하는 것은 예측 가능하게 기능 부착을 악화시키는 반면, DDPM을 사용한 FreeDoM을 사용하고 \\(\\mathbf{x}_{T}^{*}\\)에서 시작하여 최적화된 표적에 대한 특징 부착을 크게 향상시켰다. 이는 DITTO 래치들이 강력한 출발점에서 궤적을 안내하기 위해 자유DoM을 활용하여 합리적인 특징 사제 역할을 할 수 있기 때문에 안내 기반 및 최적화 기반 접근법의 유용한 혼인을 제시한다.\n' +
      '\n' +
      '## 적용서 J 두확산 라테스 및 저주파수 콘텐츠\n' +
      '\n' +
      'Si et al.(2023)에서 저자는 TTI 모델 세대의 저주파(2D 픽셀 도메인 내) 함량 중 상당 부분이 샘플링 과정에서 훨씬 일찍 결정된다는 것을 발견했으며, 여기서 추가 샘플링 단계는 고주파 정보만 생성하고 품질을 향상시킨다. 이는 DITTO가 세기와 선율 및 음악적 구조와 같은 TTM 생성에 대한 많은 표적 제어가 스펙트로그램 도메인(즉, 스펙트로그램 어드레스 오디오 품질 요소에서 가장 고주파 2D 함량)에서 저주파 특징이기 때문에 이러한 특징을 표적으로 하기 위해 최적화하는(\\mathbf{x}_{T}\\)은 이미 1위에서 저주파 정보를 인코딩하는 확산 모델의 잠재 공간 내에서 잘 나타난다. 이는 음악 태그와 캡션이 일반적으로 높은 수준의 양식 정보만을 다루며, 텍스트 캡션(시간-변조 강도, 멜로디, 구조 등)에 의해 캡처되지 않는 모든 것을 초기화에 통합하도록 남기고 있다는 사실에 의해 합성된다.\n' +
      '\n' +
      '이 제안된 정당성을 검증하기 위해 기본 확산 모델에서 샘플의 5K 배치(B=10\\))를 생성하는데, 여기서 배치의 절반은 무작위 초기화 및 무작위 프롬프트가 있는 반면 나머지 절반은 동일한 초기화 \\(\\mathbf{x}_{T}\\)를 가지고 있다. 각 그룹에 대해 배치 출력에서 추출한 강도, 선율 및 음악적 구조 특징의 각 배치 내에서 분산을 측정한다. 그림에 표시된다. 10, 초기화를 고정하는 모든 특징에 걸쳐 통계적으로 유의한 효과를 발견하여 배치 내 특징 분산을 크게 감소시킨다. 이는 모델 산출물의 두드러진 음악적 특징이 이미 _at 초기화_로 결정되는 실증적 정당화 역할을 한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l|c c} \\hline \\hline Optimization & Inference & Feature & \\(\\mathcal{L}\\) & \\(\\mathcal{L}\\) \\\\ Sampler & Sampler & Feature & & (Fixed Prompt) \\\\ \\hline DDIM & DDPM & Intensity & 24.5120 & 13.8316 \\\\ DDIM & DDPM+FreeDoM & Intensity & 16.9780 & 11.2481 \\\\ DDIM & DDPM & Melody & 2.7973 & 2.7441 \\\\ DDIM & DDPM+FreeDoM & Melody & 1.8482 & 1.8710 \\\\ DDIM & DDPM & Musical Structure & 0.2952 & 0.2643 \\\\ DDIM & DDPM+FreeDoM & Musical Structure & 0.0251 & 0.0235 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8:\\(\\mathbf{x}_{T}^{*}\\)의 확률적 샘플링으로 생성된 샘플의 손실은 표 8:였다. 우리는 DITTO 래치들이 최적화된 래치들에 자유DoM을 사용하여 특징 순응도를 크게 개선하여 최적화 기반 및 안내 기반 방법이 고품질 및 효율적인 제어를 위해 콘주프트에 사용될 수 있는 방법을 보여주는 일반화된 특징 제사 역할을 할 수 있음을 관찰한다.\n' +
      '\n' +
      'K 모델 사전 훈련.\n' +
      '\n' +
      '우리 스펙트로그램 생성 모델의 경우, 우리는 음악 제어넷(Wu et al., 2023)과 같이 디폴트 TTM으로 처리된 동일한 훈련을 따른다. 우리는 다운샘플링 블록 사이에 2개의 스트라이드가 있는 블록당 5개의 2D-컨볼루션 ResNet(He et al., 2016) 블록이 있는 컨볼루션 UNet(론버거 et al., 2015)을 사용한다. UNet는 160dB의 동적 범위로 클로닝되고 2048의 창 크기인 256(즉, 프레임 비율 \\(\\mathrm{f_{k}}\\ 승인된x 86\\) Hz로 22.05kHz 오디오에서 계산된 \\([-1,1]\\)로 스케일링되었으며, 2048의 창 크기인 멜빈 160개를 입력한다. 장르, 무드 및 템포 글로벌 스타일 제어 \\(\\mathbf{c}_{\\text{test}}\\)의 경우 교차 의사를 통해 U-Net의 내부 2개의 ResNet 블록에 주입되는 256차원의 학습 가능한 수업조건 임베딩을 사용한다. 각 블록에 U-Net 기능이 직접 합산된 학습 가능한 선형 변환이 있는 정현파 임베딩을 통해 주입되는 1000개의 확산 단계가 있는 코사인 노이즈 일정을 사용한다. 출력 시간 차원을 512 또는 \\(\\touchx\\)6초로 설정하여 512\\(\\tcer\\)160\\(\\times\\)1 출력 차원을 생성한다. 우리는 선형 평가 및 코사인 붕괴와 함께 \\(10^{-5}\\)에 대한 학습률을 가진 애덤 최적화기인 예측 노이즈와 실제 추가된 노이즈 사이의 L1 훈련 목표를 사용한다. 제한된 데이터와 효율성 고려로 인해 GPU당 배치 크기가 24인 32 A100 GPU에서 5일 동안 평행하게 분포된 데이터로 41M 파라미터와 전뇌의 비교적 작은 모델을 인스턴싱한다. 마지막으로, 우리는 또한 5일 동안 8 A100 GPU에서 훈련된 초기 업샘플링 레이어에 대해 학습률 0.0001, 판별기 및 발전기 최적화기, 배치 크기 48 및 1536 채널에 대해 학습율 최적기로 훈련된 DAC 판별기(Kumar et al., 2023)로 수정된 BigVGAN 보더(이 등은 2022)를 사용한다.\n' +
      '\n' +
      '그림 10: 초기 잠재성을 고정하지 않고 모델 세대에 대한 Intra-batch 분산이다. 우리는 잠재량을 고정하는 통계적으로 유의한 효과를 발견하여 \\(\\mathbf{x}_{T}\\)가 이미 많은 특징 정보를 인코딩한다는 것을 보여준다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>