<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '[MISSING_PAGE_FAIL:1]\n' +
      '\n' +
      '전문가 성인과 마찬가지로 (예 등, 2023; 헨드류 병사 알, 2020; 중 등은 2023, 장 등은 2023)에서 주장하는 바와 같다. 또한, 벤치마크가 공백으로 이중언어 LMM의 발달은 방향감이 없다. 대규모 다과제에 대한 LMM을 평가하기 위해 고안된 새로운 중국 종합 벤치마크인 CMMMU를 제안하여 이중언어 LMM의 개발을 전문가 수준의 인공 지능으로 향하는 경로를 안내함으로써 격차를 채운다.\n' +
      '\n' +
      'MMMMU는 대학시험과 퀴즈, 교과서에서 수작업으로 수집된 12k의 중국 복합문항을 비롯해 아트&디자인, 비즈니스, 과학, 건강의학, 인문사회과학, 테크&엔지니어링 등 6개 핵심학문을 다루는 \'MOSM\' 복합추론과 인식능력을 평가하는 가장 포괄적인 벤치마크 중 하나다.\n' +
      '\n' +
      'CMMMU의 각 질문은 LMM에 대해 어떤 유형의 질문이 어려운지를 조사하기 위해 상세한 하위 필드 및 이미지 유형으로 더 주석이 달렸다.\n' +
      '\n' +
      'GPT-4V(TV)가 잘못 답하는 300개 샘플에 대한 포괄적인 오류 분석을 제공하고 30개 피험자 중 고르게 분포하며 가장 발전된 LMM을 천식으로 이끄는 대부분의 사례를 다룬다. CMMMU에서 최고 성능 LMM, _e.g._, Qwen-VL-Plus 및 GPT-4V를 평가함으로써, 우리는 여전히 전문가 수준의 이중언어 LMM을 향해 가는 길이 멀다고 주장한다. 가장 발전된 폐쇄 소스 LMM, GPT-4V 및 Qwen-VL-Plus조차도 각각 42%와 36%의 정확성만을 달성하여 개선의 중요한 여지가 있음을 나타낸다. 우리는 또한 MMMU에서 입증된 바와 같이 중국 맥락에서 오픈 소스 커뮤니티와 가장 강력한 폐쇄 소스 LMM 사이의 격차가 영어보다 훨씬 작다는 것을 보여준다. 예를 들어, 가장 강력한 오픈소스 LMM, _i._e._Qwen-VL-Chat는 GPT-4V에 비해 14% 격차가 있는 28%의 정확도를 달성하고, 영어 격차는 21%이다. CMMMU를 개발하고 기존 오픈소스 LMM을 벤치마킹하면서 얻은 통찰력에 비추어, 우리는 이-VL-6B1, 이-VL-34B2 및 Qwen-VL-Chat만이 무작위 선택 설정에 비해 훨씬 더 잘 수행되고 GPT-4V에 가까운 반면, 다른 오픈소스 LMM은 CMMMU에 대한 무작위 선택 설정과 유사하게 수행됨을 관찰했다. 놀랍게도, 이-VL-34B는 CMMMU에서 오픈 소스 LMM과 GPT-4V의 격차를 7%까지 좁혔다.\n' +
      '\n' +
      '폐지 1: [국경 구조 표면][국경 안정 표면.코/01-ai/Yi-VL-6B](국경 구조 표면.co/01-ai/Yi-VL-6B)\n' +
      '\n' +
      '주류 2: [국경 구조 표면][국경 구조 표면.코/01-ai/Yi-VL-34B](국경 구조 표면.co/01-ai/Yi-VL-34B)\n' +
      '\n' +
      '우리는 CMMMU가 지속적인 LMM 연구 개발 노력에 혜택을 주고 LMM의 민주화를 촉진할 수 있다고 믿는다.\n' +
      '\n' +
      '우리의 기여는 다음과 같이 요약된다.\n' +
      '\n' +
      '** 우리는 첫 번째 중국 매생 멀티-수능 멀티모달 이해 기준인 CMMMU를 소개한다.\n' +
      '* 우리는 GPT-4V를 포함하여 기존 LMM이 중국 맥락에서 복잡한 추론과 이해에 대해 제대로 수행되지 않음을 보여준다.\n' +
      '* 우리는 중국 맥락에서 오픈소스 이중언어 LMM과 폐쇄소스 LMM 간의 차이를 분석하고 영어 맥락에 비해 현저히 작다는 점을 지적하고 있다.\n' +
      '\n' +
      '그림 1: CMMMU의 징계.\n' +
      '\n' +
      ' \n' +
      '\n' +
      '2개는 회사 관련.\n' +
      '\n' +
      '### Multimodal Benchmark\n' +
      '\n' +
      '전통적으로 복합 벤치마크들은 과제 중심이므로 LMM을 평가하도록 설계되지 않았다. 이러한 다중 모드 모델을 베이크킹하는 것은 시각적 질문 응답(VQA)(안톨 et al, 2015), 이미지 캡션(Vinyals et al, 2014), 정보 검색(Wei et al, 2023, 우 et al, 2024)과 같은 다양한 양식의 표현을 정렬하고 활용하는 일련의 작업에 의존한다. 이러한 복합 작업과 벤치마크를 구축하는 성공은 MSCOCO(Lin et al., 2014), Flickr30k(Plummer et al., 2015)와 같은 대규모 주석이 달린 데이터셋에 크게 의존한다. 일부 작업은 또한 일반적인 지식 염기(Marino et al., 2019; Schwenk et al., 2022)에서 파생된 VQA 데이터와 교차 모달 정렬 능력을 평가한다.\n' +
      '\n' +
      '최근의 연구 라인은 LMM 평가에 맞춘 벤치마크를 설계하려고 시도한다. 예를 들어, 과학 영역(Lu et al, 2022, 우 et al, 2024)에서 주어진 데이터 분포 _e._에서 복잡한 지식을 인식하고 학습하도록 요구함으로써 모델을 조사할 수 있다. 생성 LMM과 호환되는 벤치마크를 구성하기 위해 MME(Fu et al., 2023)는 예노 문제를 사용하고 MMBench(Liu et al., 2023)는 다중 선택 형식을 기반으로 한다. 일부 최근 연구에서는 모델이 수학 추론(Lu et al., 2023), 웹사이트 상호작용 Deng et al.(2023), 또는 종합 대학 수준 지식 추론(Yue et al, 2023)과 같은 더 도전적인 시나리오에서 생성된 정보를 인식하고 해석할 수 있는지 여부를 조사하는 것을 제안한다. 이러한 복합 벤치마킹 분야의 유망한 진전이 이루어졌지만, 데이터셋의 지배적인 비율은 영어로 되어 있어 중국처럼 자주 사용되는 다른 언어로 포괄적이고 도전적인 벤치마크를 구축하는 것이 시급한 격차이다.\n' +
      '\n' +
      '대용량 멀티메달 모델.\n' +
      '\n' +
      '기준점의 발달 흔적과는 다른 기존의 복합 모델들 중 다수는 통합 이중언어 대형 언어 모델로 인해 영어와 중국어를 모두 지원한다. 이러한 진술은 서로 다른 모델에서 설정되지만, 사례들은 누드된 특징들에 따라 달라질 수 있다. 다중 모드 모델은 언어 모델을 교차 수정 정렬 방법으로 적응시켜 텍스트 데이터를 넘어서는 것을 목표로 하는 반면, 중국 영어 이중언어 코퍼스와 미리 훈련된 일부 언어 모델은 텍스트 모델링의 구성 요소(Hu et al., 2023; Bai et al., 2023; Ding et al., 2022; Du et al., LinkSoul-AI, 2023)로 선택된다. 일부 흥미로운 통찰력은 탐구되지만, 일부 모델만이 중국 복합 작업에 대해 평가된다. 예를 들어, 0샷 설정에서도 영어 명령 튜닝 데이터만으로 훈련된 멀티모달 모델이 중국어로 잘 작동한다는 것은 후(2023) 등에 의해 드러난다. 또 다른 모델 세트는 효율적인 튜닝(Cld et al., 2023)으로 중국어에 적응된 언어 모델을 선택한다. 적절한 정렬 아키텍처 설계 및 훈련 데이터 선택을 감안할 때, 이러한 모델은 여전히 이중언어 다중 모드 태스크(예 et al., 2023; 선 et al., 2023; Chen et al., 2023; 왕 et al., 2023; 홍 et al., 2023; LinkSoul-AI, 2023)에 대한 강력한 성능을 보여준다. 더욱이 폐쇄 소스 GPT-4(아치암 등 2023)는 아키텍처 관련 세부 사항을 제공하지 않지만 인간 수준과 가까운 영어로 시각적 이해 작업을 달성한다는 점에서 중국 복합 벤치마크에서 평가된 기준선을 언급할 가치가 있다.\n' +
      '\n' +
      '언어 모델의 선택과 학습 데이터에 관계없이 많은 복합 모델은 실제 사용 시 일정 수준에서 중국 과제에 대한 능력을 보여준다. 이 작품에서 우리는 대부분 영어 과제와만 평가되었기 때문에 종합적이고 도전적인 중국 복합 과제를 가진 모델의 능력 경계를 정량적으로 측정하는 것을 목표로 한다.\n' +
      '\n' +
      '3개의 CMMMU 벤치마크.\n' +
      '\n' +
      '우리는 광범위한 과제에 걸쳐 LMM의 전문가 수준 다중 모드 이해 능력을 평가하기 위해 대학 수준 지식을 덮는 수동으로 큐레이팅된 벤치마크인 중국 매스티브 멀티 이론 이해(_CMMMU_) 벤치마크를 도입하는데, CMMMU는 중국 맥락에서 처음으로 다중 모드 질문-매핑 벤치마크이자 LMM의 복잡한 이해와 추론 능력을 조사하는 몇 안 되는 다중 모드 벤치마크 중 하나이다.\n' +
      '\n' +
      '공정.\n' +
      '\n' +
      '** 데이터 수집:** 저희는 3단계 데이터 수집 절차를 신중하게 설계합니다. 로드레이터 주최자는 **Stage 1***에서 감독 기관(주로 저자)은 **Stage 1***에서 라이센스 요구 사항을 만족하는 소스를 수집한다.\n' +
      '\n' +
      '그림 3: CMMMU에서 6개 학문과 30개 과목의 비율. 30명의 피험자의 다중 모드 샘플은 관련 전문가 수준 도메인 지식을 균일하게 포괄한다.\n' +
      '\n' +
      '그림 2: CMMMU 예는 각 규율에서 샘플링되었다. 그림에는 음악 점수, 표, 화학 구조, 곡선, 회로 도표 및 기타 유형의 그림이 포함되며, 질문의 어려움은 전문가 수준의 지식이 이해하고 이성을 요구합니다.\n' +
      '\n' +
      '웹사이트 링크 또는 북 타이틀의 포맷입니다. 주석 주최 측은 복제 및 재분배를 금지하는 사이트의 자료를 피하면서 저작권 및 면허 규정을 준수하도록 잘 지시받고 있다. 각 규율에서 각 주제에 대해 최소 20개의 주석 소스, _i.e._, 웹사이트 또는 책을 수집합니다. **스테이지 2***에서 주석 주최자는 추가 주석을 위해 주석 출처를 인파소싱 주석으로 전달한다. 모든 주석은 학부생이거나 학위가 높아 주석이 달린 질문과 관련 설명을 확인할 수 있다. 주석 과정에서 주석으로 하여금 이미지의 무자격 질문을 걸러낼 수 있는 몇 가지 핵심 원칙을 엄격하게 준수해 줄 것을 요청한다.\n' +
      '\n' +
      '이미지가 없으면 대답할 수 있는* 쿼션을 걸러내야 한다.\n' +
      '동일한 이미지를 사용하는* 쿼티브는 가능한 한 걸러져야 한다.\n' +
      '전문가 지식이 답변할 것을 요구하지 않는*문항들은 가능한 한 걸러져야 한다.\n' +
      '* 동일한 특정 지식점에 대한 문항 수와 유사한 질문각을 가지는 문항 수는 10개를 초과하지 않아야 한다.\n' +
      '\n' +
      '우리는 또한 주석에게 부록G(Yue et al., 2023)의 데이터 주석 프로토콜을 따르도록 요청한다. **Stage 3**에서 주석 주최자는 데이터셋의 균형을 맞추기 위해 질문 부족, _e._g._, 예술, 진단 및 이코노미스트에 대한 질문을 추가로 보충한다.\n' +
      '\n' +
      '** 데이터 품질 제어:** CMMMU의 데이터 품질을 더욱 향상시키기 위해 엄격한 데이터 품질 관리 프로토콜을 따른다. *** 첫**, 각 질문은 종이 저자 중 적어도 하나에 의해 수동으로 검증된다. LMM에 의해 생성된 응답에서 추출하기 어려운 답변으로 질문을 조심스럽게 걸러냅니다. 이 과정에서 대학 수준의 검사가 아닌 모든 질문을 꼼꼼히 걸러줍니다. ***2***는 데이터 오염의 우려를 감안할 때 OCR의 도움 없이 GPT-4, Qwen-7B, 딥세크-7B 및 이순-7B로 올바르게 해결할 수 있는 모든 질문을 동시에 필터링한다.\n' +
      '\n' +
      '멀티모달 벤치마크 지정.\n' +
      '\n' +
      '입력 이미지 유형으로부터 벤치마크의 공통 이미지 포맷은 대략 VQA, GQA, VisWiz와 같은 (1) 시각 입력이라는 3개의 단순 카테고리로 나눌 수 있다. (2) 광학적 문자는 TextVQA와 같은 것이다. (3) 시각 입력 + 광학적 문자는 OKVQA, SEED, MMBench, MM-Vet과 같은 것이다. 또한 사이언스QA 벤치마크에는 5가지 형태의 이미지 폼이 있습니다. CMMMU 벤치마크에는 차트, 테이블, 다이어그램, 화학 구조, 사진, 그림, 기하학적 형태, 음악적 점수 및 의료 이미지가 포함된 39가지 유형이 있다.\n' +
      '\n' +
      '질문 유형 측면에서, 대부분의 공통 벤치마크들은 VQA, GQA, VisWiz, OKVQA와 같은 (1) Open QA이다. TextVQA, SEED, MMBench, MMBench,와 같은 (2) 다중 선택 질문은 TextVQA, SEED, MMBench,와 같은 선택 질문이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline Dataset & Size & Images & Format & Source & Answer \\\\ \\hline VQA (Agrawal et al., 2015) & \\(>\\) 1M & V & I+T & Annotated & Open \\\\ GQA (Hutson and Manning, 2019) & \\(>\\) 1M & V & I+T & Synthesized & Open \\\\ Vi2Wiz (Gurari et al., 2018) & 32K & V & I+T & Annotated & Open \\\\ TextVQA (Ganz et al., 2023) & 45K & OC & I+T & Annotated & MC \\\\ OKVQA (Marino et al., 2019) & 14K & V+OC & I+T & Annotated & Open \\\\ SEED (Li et al., 2023) & 19K & V+OC & I+T & Annotated & MC \\\\ MMBench (Liu et al., 2023) & 3K & V+OC & I+T & Repurposed & MC \\\\ MM-Vet (Yu et al., 2023) & 0.2K & V+OC & I+T & Repurposed & MC \\\\ ScienceQA (Lu et al., 2022) & 6K & 5 Types & I+T & Textbooks & MC \\\\ MathVista (Lu et al., 2023) & 6K & V+OC & I+T & Synthesized & MC/Open \\\\ \\hline MMMU (Yue et al., 2023) & 11.5K & 30 Types & Interleaved & \\begin{tabular}{c} Textbooks \\\\ Internet \\\\ Annotated \\\\ \\end{tabular} & Open \\\\ \\hline CMMMU & 12K & 39 Types & Interleaved &\n' +
      '\\begin{tabular}{c} Textbooks \\\\ Internet \\\\ Annotated \\\\ \\end{tabular} & Open \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 다른 멀티모달 벤치마크MM-Vet, 사이언스QA와의 비교. CMMMU에는 개방형 질문과 여러 가지 선택 문항이 포함되어 있을 뿐만 아니라 판단 문항을 추가하여 질문 유형을 풍부하게 한다.\n' +
      '\n' +
      '지식 깊이의 측면에서 이전의 벤치마크들은 보통 상식이나 단순한 신체적 혹은 시간적 추론을 필요로 한다. 대조적으로, 제안된 CMMMU 벤치마크는 대학 수준의 교과 지식에 대한 사려 깊은 추론을 필요로 한다.\n' +
      '\n' +
      '또한, 우리는 최근 AGI를 평가하는 데 다른 벤치마크들이 사용되었음을 발견했으며, 예를 들어 Mind2Web는 모든 웹사이트에서 복잡한 작업을 완료하기 위해 언어 지침을 따를 수 있는 웹에 대한 일반 에이전트를 개발하고 평가하는 데 사용된다. 우리의 CMMMU는 평가제와 달리 LMM 전문가 AGL의 능력을 평가하는 것을 목표로 한다. MathVista 벤치마크는 시각적 배경에서 수학적 추론 능력을 평가하기 위해 고안된 반면, 우리의 CMMMU는 수학적 추론 능력에 대한 평가를 포함할 뿐만 아니라 화학 구조 및 회로 도표와 같은 30개의 하위 분야에서 전문가 지식의 평가를 포함한다. MMMU는 도메인 특정 지식을 가진 고급 인식과 추론, 전문가들이 직면한 모델과 유사한 작업을 수행하기 어려운 모델에 중점을 둔다. MMMU의 파트너로서, 우리의 CMMMU 벤치마크는 평가 전문가 AGI를 이중 언어 영역으로 확장하여 전문가 AGI 진행에 대한 이해도를 충족한다.\n' +
      '\n' +
      'CMMMU.\n' +
      '\n' +
      '본 논문은 중국 내 광범위한 과제에 걸쳐 기반 모델의 전문성 수준 복합적 이해 능력을 평가하기 위해 신중하게 설계된 새로운 벤치마크인 대규모 중국 다학제 다학제 이해 및 근거(CMMMU) 벤치마크를 소개한다. 30여 개 과목에 걸쳐 예술, 사업, 보건, 의학, 과학, 인문 사회 과학, 기술, 공학 등 6개 학문을 다루고 있다. CMMMU는 12K 문항으로 구성되어 있으며, 몇 샷 개발 세트, 검증 세트 및 테스트 세트로 나뉜다. 몇 번의 샷 개발 세트는 각 주제에 대해 5개의 질문을 포함하고, 검증 세트는 900개의 문항으로 하이퍼파라미터 선택을 보조하며, 테스트 세트는 11K 질문을 포함한다.\n' +
      '\n' +
      '그림은 병리학적 다이어그램, 음악적 점수, 회로도, 화학 구조도 등 39가지 유형을 포함한다. 우리는 지적인 어려움보다는 논리적 어려움으로 데이터를 이지(30%), 중형(58%), 하드(12%)로 분류했다. 질문 유형에 따르면 7738개의 선택 문항, 2998개의 필인-블랭크 문항, 1276개의 판단 문항이 있다. 이들 예들 중, 11,760은 문제의 이미지이고, 2169개는 옵션 내의 이미지이고, 597개는 다수의 이미지를 갖는 이미지들이다. 분석 결과.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c} \\hline \\hline Statistics & Number \\\\ \\hline Total Questions & 12012 \\\\ Total Disciplines/Subjects/Subfields & 6/30/4165 \\\\ Image Types & 39 \\\\ \\hline Dev:Validation:Test & 112:900:11000 \\\\ Difficulties (Easy: Medium: Hard) & 30\\%:58\\%:12\\% \\\\ \\hline Multiple-choice Questions & 7738 (64.41\\%) \\\\ Fill in the blank Questions & 2998 (24.95\\%) \\\\ True or false Questions & 1276 (10.62\\%) \\\\ \\hline Questions with an Explanation & 247 (2.05\\%) \\\\ Image in the Question & 11760 (84.42\\%) \\\\ Image in Options & 2169 (15.57\\%) \\\\ Example with Multiple Images & 597 (4.97\\%) \\\\ \\hline Average question length & 51.12 \\\\ Average option length & 8.76 \\\\ Average explanation length & 78.29 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: CMMMU 통계: CMMMU 통계: CMMMU 통계:표 2:: CMMMU 통계: 통계:표 2:: CMMMU 통계: 통계: <표 2: <표 2:: CMMMU <표 2::: CMMMU: 통계: 통계:: CMMMU <표 2: <표 2::: CMMMU <표 2: 통계:: CMMMU <표 2: 통계:: CMMMU <표 2: <표 2::: CMMMU <표 2: 통계:: CMMMU <표 2: <표 2:: CMMMU>의 통계: 통계: 통계: 통계:: CMMMU <표 2:\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:7]\n' +
      '\n' +
      '* CogAgent(홍 et al., 2023)는 GUI 이해 및 내비게이션을 위해 설계된 1,800억 매개변수 비전 언어 모델이다.\n' +
      '* Qwen-VL(Bai et al., 2023b)은 Qwen-7B를 LLM의 초기화, 오픈클립 ViT-빅G를 시각적 인코더의 초기화로 사용한다. 그리고 무작위로 초기화된 교차 의도 계층과 연결합니다. 우리는 Qwen-VL 시리즈에서 QWen-VL-Chat 및 QWen-VL-plus를 기준 모델로 선택한다.\n' +
      '* 내측VL(Chen et al., 2023)은 비전 트랜스포머(ViT)를 6B 매개변수로 스케일링하고 LLM과 정렬한다. 내부 VL-Chat-Chit-6B-Vicuna-7B, 내부VL-Chat-vit-6B-Vicuna-13B, 내부VL-Chat-vit-6B-Vicuna-13B, 내부VL-Chat-6B-Llama2-13B 등 내부VL 시리즈 내에서 다양한 크기의 언어 모델이 있다.\n' +
      '* GPT-4V 3은 이미지 및 텍스트 입력을 수용하고 텍스트 출력을 방출하는 OpenAI의 폐쇄 소스 대형 멀티모달 모델로 다양한 전문 및 학술 벤치마크에서 인간 수준 성능을 보여준다. 폐지 3: [임대용 신경공개닷컴/연구/자료-4](임대용 신경공개닷컴/연구/연구/자료-4)\n' +
      '* 이-VL-6B 및 이-VL-3B는 복합 모델로서 대형 언어 모델에 이미지 이해 능력을 제공한다. 이러한 모델에서 Vit는 Openclip 224이고 언어 모델은 이순-6B-Chat 또는 이순-34B-Chat이다.\n' +
      '\n' +
      '***Text 전용 LLM*** 우리는 일반 텍스트를 다룰 때 LLM(_e._,GPT4, Owen-7B(Bai et al., 2023a), 딥세크-7B(딥슨크-Al et al, 2024), 이-6B5) 및 베이촨-7B의 성능을 다중 모드 데이터에서 평가한다. 또한 외부 이미지 도구가 다중 모드 데이터에 대한 LLM의 성능을 향상시킬 수 있는지 확인하기 위해 매십닉스 6 처리 이미지에 의해 OCR을 배치하여 특정 이미지 정보를 텍스트 형태로 변환한다.\n' +
      '\n' +
      '유도 4: [임대용 신경공개닷컴/연구/자료-4](임대용 신경공개닷컴/연구/연구/자료-4)\n' +
      '\n' +
      '부타주 5: [부주행 요추면.코/01-ai/Yi-6B-Chat] (부주행 요추면.코/01-ai/Yi-6B-Chat)\n' +
      '\n' +
      '발주 6: [주행://math 픽셀.com/] (https://math픽셀.com/)\n' +
      '\n' +
      '*** 평가** 우리는 체계적이고 규칙적인 평가 파이프라인을 구축한다. 모델 응답으로부터 답변을 추출하기 위해 적절한 정기적인 표현을 구축한다. 구체적으로, 다중 선택형 문항을 위해 옵션을 키워드로 직접 사용하여 모델 응답을 추출하고, 모델 응답에서 옵션 수가 가장 많은 것을 답으로 취한다. 모델의 응답에 유효한 답이 없는 경우, 다중 선택형 질문에 대해 랜덤 선택을 수행한다. 판결과 공개형 질문 답변은 구체적인 규칙을 활용하여 답이 발생할 수 있는 일부 부분을 추출한 후 그 안에서 답이 발생하는지 여부를 감지한다. 우리는 기저부로 무작위 선택과 빈번한 선택을 추가하는데, 전자는 무작위로 옵션을 선택하고 후자는 해당 주제에 발생 빈도를 기반으로 검증 세트에서 특정 주제별로 가장 빈번한 옵션을 선택한다. 마지막으로, 우리는 평가 메트릭으로 미세 평균 정확도를 채택한다.\n' +
      '\n' +
      '우리가 사용하는 신속성과 그에 상응하는 질문 유형은 다음과 같다.\n' +
      '\n' +
      '*** 다중선택형 질문 :**(다음의 선택형 문항 및 선택형 다선택형 질문)를 모두 포함시켜 주시기 바랍니다. 이 질문에는 단일선택형 및 다중선택형 서식이 모두 포함되며, 제공된 정보가 명확한 답변을 결정하기에 충분하지 않은 경우 사용 가능한 자료 및 판단에 따라 가장 정확한 옵션을 선택하십시오. 7.\n' +
      '\n' +
      '부츠 7: 영어 버전은 모델에 대한 입력의 일부가 아니다.\n' +
      '\n' +
      '***True/False 질문:**(다음의 진정한/허위 질문)에 답하여 질문 설명 및 제공된 정보에 기초하여 진술의 올바른 여부를 결정하여 주시기 바랍니다. 절대 판단에 대한 정보가 불완전하거나 불충분하다면 논리적 추론과 사용 가능한 정보를 사용하여 가장 가능성 있는 판단을 내릴 수 있도록 해주시기 바랍니다.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:9]\n' +
      '\n' +
      '부록에는 정확한 응답과 잘못된 응답의 141개의 예가 자세히 설명되어 있으며, 다음에는 각 오류 유형의 특성을 설명한다.\n' +
      '\n' +
      '**개념 오류(26%):**개념 오류는 GPT-4V에 의한 잘못된 예제의 생성의 주요 이유 중 하나이다. 한편, 모델은 이미지에서 화살표와 기호를 이해하지 못할 때, 그 순서를 위에서 아래로, 좌우로 잘못 해석하면 이미지에 대한 기본적인 인식의 편차를 도입하여 잘못된 반응을 이끌어낸다. 반면, 모델은 영역별 지식, 숨겨진 의미 또는 불명확한 공식에서 모호성을 마주할 때 해당 도메인에 특정한 지각적 오류를 나타내는 경향이 있다. 이러한 경우 GPT-4V는 텍스트 정보(_i.e._문항 및 옵션)에 기초하여 답하는 것에 더 의존하는 경향이 있으며, 시각적 입력에 비해 텍스트 정보를 우선하여 다중 모드 데이터를 이해하는 데 편향을 일으킨다.\n' +
      '\n' +
      '** 잔류 에르미러(26%):** 이유 에로어는 GPT-4V에 의한 잘못된 예 생성에 기여하는 또 다른 주요 요소이다. 한편으로는 모형에서는 기호의 숨겨진 의미를 인지하지 못해 잘못된 추론과 산출으로 이어지는 그림 5의 일러스트와 같이 앞서 언급한 지각적 오류로부터 비롯된 잘못된 정보를 받으면 추론 오류가 발생한다. 반면에, 다른 한편에서도, 심지어 심지어, 심지어 심지어, 심지어, 심지어 심지어, 심지어, 심지어, 심지어, 심지어, 심지어, 이는 다른 한편에서도 그렇다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c} \\hline \\hline  & **Validation** & **Test** & **Art \\& **B** & **Business** & **Science** & **Health \\&**Human. \\&** **Tech \\&** \\\\  & **Overall** & **Overall** & **Design** & & **Medicine** & **Social Sci.** & **Eng.** \\\\  & (900) & (11,000) & (1,091) & (1,538) & (2,494) & (1,086) & (1,038) & (2,974) \\\\ \\hline Random Choice & 21.6 & 21.6 & 32.9 & 9.1 & 18.8 & 23.8 & 23.9 \\\\ Frequent Choice & 24.1 & 26.0 & 36.2 & 11.8 & 23.9 & 30.2 & 28.5 & 27.7 \\\\ \\hline \\multicolumn{8}{c}{**Large Multimodal Models (MMs: Text + image as Input)**} \\\\ \\hline mPLUG-Owl2 & 20.8 & 22.2 & 30.4 & 13.3 & 19.6 & 25.2 & 24.7 & 23.4 \\\\ VisCPM & 25.2 & 22.7 & 37.7 & 11.3 & 19.1 & 26.1 & 24.0 & 23.7 \\\\ Chinese-LIAVA & 25.5 & 23.4 & 34.4 & 11.7 & 21.6 & 25.5 & 26.3 & 24.7 \\\\ Ennn2-Chat & 23.8 & 24.5 & 35.3 & 11.7 & 22.1 & 25.5 & 28.0 & 27.1 \\\\ CogAgent-Chat & 24.6 & 23.6 & 33.8 & 14.1 & 20.6 & 26.3 & 24.8 & 25.3 \\\\ Owen-VL-Chat & 30.7 & 31.3 & 52.6 & 18.5 & 26.9 & 33.4 & 34.1 & 31.4 \\\\ InternVL-Chat-ViT-6B-Vicuna-7B & 26.4 & 26.7 & 39.7 & 13.8 & 23.0 & 31.7 & 26.5 & 28.5 \\\\ InternalVL-Chat-ViT-6B-Vicuna-13B & 27.4 & 26.1 & 38.5 & 13.9 & 22.1 & 30.2 & 29.8 & 27.5 \\\\ Yi-VL-6B-Vicuna-13B & 35.8 & 35.0 & 58.0 & 19.9 & 32.8 & 39.3 & 40.6 & 32.1 \\\\ Yi-VL-34B & 36.2 & 36.5 & 62.9 & 19.1 & 31.5 & 42.1 & 42.5 & 34.5 \\\\ \\hline Owen-VL-Plus & 39.5 & 36.8 & 61.5 & 23.2 & 32.8 & 40.5 & 43.4 & 33.3 \\\\ GPT-4V & **42.5** & **43.7** & 61.0 & **36.3** & **40.9** & **46.8** & **44.2** & **41.5** \\\\ \\hline \\multicolumn{8}{c}{**Large Language Models (LIMs: Only Text as Input)**} \\\\ \\hline DeepSeek-7B & 22.3 & 21.9 & 41.3 & 11.2 & 18.3 & 23.5 & 24.7 & 21.3 \\\\ Batchman-7B & 26.0 & 24.3 & 42.7 & 12.6 & 19.6 & 28.0 & 27.8 & 23.9 \\\\ Queue-7B & 24.7 & 25.1 & 43.8 & 12.6 & 20.7 & 30.5 & 26.9 & 24.5 \\\\ Yi-6B & 25.6 & 24.2 & 26.3 & 15.0 & 23.4 & 29.1 & 27.0 & 24.7 \\\\ \\hline DeepSeek-7B + OCR & 25.2 & 23.2 & 41.2 & 13.2 & 19.4 & 26.1 & 26.5 & 21.8 \\\\ Batchman-7B + OCR & 25.3 & 24.7 & 40.2 & 15.2 & 21.0 & 27.9 & 30.7 & 22.8 \\\\ Queen-7B + OCR & 27.0 & 26.1 & 44.6 & 14.3 & 22.1 & 29.3 & 29.8 & 25.4 \\\\ Yi-6B + OCR & 28.4 & 26.8 & 33.4 & 16.9 & 24.8 & 32.3 & 33.2 & 25.5 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: CMMMU 검증 및 테스트 세트에 대한 오픈 소스 및 폐쇄 소스 모델의 모든 결과를 보여준다. LMM의***bold 결과***는 모든 모델에 대해 최상의 결과를 나타내고 **blue 결과***는 오픈 소스 모델 중에서 가장 좋은 결과를 나타낸다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c} \\hline \\hline Models & Multiple-choice & Fill in the blank & True or false & Overall \\\\  & (7076) & (2753) & (1171) & (11000) \\\\ \\hline mPLUG-Owl2 & 22.9 & 7.0 & 53.8 & 22.2 \\\\ VisCPM & 24.5 & 5.4 & 52.8 & 22.7 \\\\ Chinese-LIaVA & 25.6 & 5.4 & 52.7 & 23.4 \\\\ Emu2 & 28.4 & 2.9 & 51.4 & 24.5 \\\\ CogAgent & 25.9 & 5.9 & 51.9 & 23.6 \\\\ InternVL-Chat-ViT-6B-Vicuna-7B & 28.5 & 7.3 & 61.6 & 26.7 \\\\ Yi-VL-6B & 40.8 & 11.7 & 54.9 & 35.0 \\\\ Yi-VL-34B & 42.5 & 10.4 & 61.6 & 36.5 \\\\ \\hline Owen-VL-Plus & 42.9 & 15.7 & 49.4 & 36.8 \\\\ GPT-4V & **46.4** & **27.4** & **66.0** & **43.7** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 질문 유형 전반에 걸친 샘플 분해이다.\n' +
      '\n' +
      '모델이 이미지와 텍스트가 전달하는 의미를 올바르게 지각하면 복잡한 논리적, 수학적 추론이 필요한 문제를 해결할 때 추론 과정의 오류가 발생할 수 있다. 일반적으로 이러한 오류는 모델의 논리적 및 수학적 추론 능력이 약하기 때문에 발생한다.\n' +
      '\n' +
      '** 지식 부족(22%):** 전문성의 결여 역시 GPT-4V가 잘못된 반응을 일으키는 이유 중 하나이다. 그림 6의 예는 해당 물리학 지식 부족으로 인해 잘못된 답을 생성하는 GPT-4V를 보여준다. CMMMU는 LMM의 전문가 AGI를 평가하기 위한 벤치마크이기 때문에 다양한 학문 및 하위 분야에 대한 전문가 수준의 지식이 필요하다. 따라서 LMM에 전문가 수준의 지식을 주입하는 것도 AGI로 작동할 수 있는 방향 중 하나이다.\n' +
      '\n' +
      '** 리젝션(12%):**의 모델이 답을 거부하여 잘못된 반응을 초래하는 현상도 흔한 현상이다. 분석을 통해 모형의 답변 거부 이유를 여러 가지 확인하였는데, _(i)_ 모형에서는 이미지로부터 정보를 인식하지 못하고, 문제의 텍스트 정보가 미흡하여 모델을 더 많은 정보를 대기하게 한다.\n' +
      '\n' +
      '종교적 사항이나 개인적 실생활 정보를 포함하는__(ii)_문항들은 모델이 인간 가치에 부합하여 대답을 자제하도록 이끈다. _(ii)_문항으로 이어진다. (iii)_ 문항이 성별과 주관적 문제를 포함할 때 모델은 정확한 응답을 제공하는 것을 회피한다.\n' +
      '\n' +
      '** 다른 어러러:** 나머지 오류는 텍스트 이해 오류(7%), 주석 오류(2%), 추출 오류(5%)이다. 이러한 오류는 능력에 따른 복잡한 지도, 복잡한 텍스트 논리 이해, 대응 생성의 한계, 데이터 주석 오류, 답변 매칭 추출에서 직면하는 문제 등 다양한 요인에 기인한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c} \\hline \\hline Models & Easy & Medium & Hard & Overall \\\\  & (3369) & (6328) & (1303) & (11000) \\\\ \\hline mPLUG-Owl2 & 25.5 & 20.8 & 20.7 & 22.2 \\\\ VisCPM & 26.8 & 21.1 & 20.1 & 22.7 \\\\ Chinese-LLaVA & 25.5 & 26.3 & 24.7 & 23.4 \\\\ Emu2 & 28.0 & 22.4 & 25.1 & 24.5 \\\\ CogAgent & 27.7 & 21.7 & 22.7 & 23.6 \\\\ InterVL-Chat-ViT-6B-Vicuna-7B & 30.3 & 25.6 & 22.6 & 26.7 \\\\ Yi-VL-6B & 43.3 & 31.6 & 30.3 & 35.0 \\\\ Yi-VL-34B & 45.6 & 32.6 & 31.9 & 36.5 \\\\ \\hline Qwen-VL-Plus & 46.7 & 32.9 & 29.9 & 36.8 \\\\ GPT-4V & **51.5** & **40.7** & **38.3** & **43.7** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 질문 난이도에 걸친 샘플 분해. LMM의**bold 결과***는 모든 모델에 대해 최상의 결과를 나타내며 파란색 결과는 오픈 소스 모델 중에서 가장 좋은 결과를 나타낸다.\n' +
      '\n' +
      '그림 4: GPT-4V 오류 반응 분포.\n' +
      '\n' +
      '## 5 Conclusion\n' +
      '\n' +
      'CMMMU 벤치마크는 첨단 일반 정보 개발(AGI)에서 상당한 보석을 나타낸다. CMMMMU의 설계는 최신 대형 멀티모달 모델(LMM)을 엄격하게 평가하고 초등 지각 기술, 복잡한 논리적 추론 및 특정 영역의 심오한 전문성을 테스트하는 데 맞춰진다. 우리는 CMMMU와 MMMU에 대한 LMM의 성능을 비교하여 중국 맥락에서 가장 발전된 이중언어 LMM의 추론 능력과 영어 맥락 간의 차이를 보여준다. 이러한 철저한 평가는 다양한 분야의 노련한 전문가의 숙련도와 평행한 AGI 달성을 위한 궤적을 묘사하는 데 중추적이다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* 아치암 등은 (2023) 조쉬 아치암, 스티븐 아들러, 샌드히니 아가왈, 라마 아흐마드, 일게 아카야, 플로렌시아 레니 아맨, 디아고 알미다, 조코 알텐슈미트, 샘 알트만, 세타말 아나드카트 등 4가지 기술보고. arXiv 프리프린트 arXiv:2303.08774_, 2023.\n' +
      '* 아가랄 등은 (2015) 아슈와리아 아크로갈, 지아센 루, 스탠리스시안톨, 마가레트 미첼, C. 로렌스 지트니크, 디루 바트라 및 데비 파라이크이다. Vqa: Visual 질문 답변. __Vqa: Visual 질문 답변. __Vqa: Visual 질문 답변. arXiv 프리프린트 arXiv: 2015. 1505.00468_입니다.\n' +
      '* 안톨 등은 (2015) 스탠리스시안톨, 아슈와리아 아크로랄, 지아센 루, 마가레트 미첼, 다루브 바트라, 코로렌스 지트닉, 데비 파라크 등이다. Vqa: 비주얼 질문 답변. 컴퓨터 비전_, pp. 2425-2433에 대한 IEEE 국제 회의의 _검토에서 2015.\n' +
      '*바이 등은 (2023a) 진제바이, 샤이바이, 윤페이 추, 제유 코이, 카이당, 샤오동 덩, 양판, 원빈게, 유한, 필황 등의 기술보고를 하고 있다. arXiv 프리프린트 arXiv:2309.16609_, 2023a.\n' +
      '*바이 등은 진제바이, 샤이바이, 슈청양, 샤이왕, 신안탄, 펑왕, 준양린, 창주, 진렌주 등이 있다. Qwen-vl: 이해, 현지화, 텍스트 판독 및 그 이상의 다양한 비전-언어 모델. __지역화, 텍스트 판독을 위한 다용도 비전-언어 모델. arXiv 프리프린트 arXiv:2308.12966_, 2023b.\n' +
      '*코언 등은 (2023) 짐첸, 지안난우, 원하이왕, 위지수, 위지첸, 센시밍, 무옌중, 청롱장, 시즈우주, 레이웨이 루, 빈 리, 핑 루오, 퉁루, 유샤오, 지펑 다이 등이 있다. 인턴블: 비전 기반 모델을 편집하고 일반 시각 친화적 작업을 정렬합니다. __ 비전 기반 모델을 수정합니다. arXiv 프리프린트 arXiv:2312.14238_, 2023.\n' +
      '*의 등은 (2023) 예밍쿠이, 지칭양, 신야오 등이 있다. 중국 일마 및 알파카에 대한 효율적이고 효과적인 텍스트 인코딩 __ 중국 일마 및 알파카에 대한 효율적이고 효과적인 텍스트 인코딩이다. arXiv 프리프린트 arXiv:2304.08177_, 2023. URL[https://arxiv.org/abs/2304.08177](https://arxiv.org/abs/2304.08177).\n' +
      '후후, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후이, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후오, 후 유, 야중수, 샹키유, 보우위장, 하우위장, 명화장, 명화장, 월화장, 위차오장, 선게앙장, 야오자오, 야오쩌오, 샤오쩌우, 샹옌쩌주, 꽝샤우, 셰이옌쩌후, 유정주, 장. 딥시크 llm: 장기주의가 있는 오픈소스 언어 모델 스칼링. arXiv 프리프린트 arXiv: 2401.02954_, 2024.\n' +
      '*뜰 등은 (2023) 샤앙 덩, 유구, 보부안 정, 시지 첸, 사미엘 스티븐스, 보시 왕, 후안 선, 유수 등이다. Mind2web: 웹용 일반요원. __Toward: 웹용 일반요원. arXiv 프리프린트 arXiv:2306.06070_, 2023.\n' +
      '(2021)* 드링 등 알(2021)* 다이닝 등은 명딩, 주요이 양, 원이 홍, 위니 정, 창주, 다진, 준양 린, XuZou, 저우 샤오, 홍시아 양 등 변압기를 통한 마스터 텍스트 대 이미지 생성. 2021년 신경 정보 처리 시스템_, 34:19822-19835의 발전입니다.\n' +
      '* 듀 등은 (2022) 정시아오 두, 유지 Qian, 샤오 류, 명딩, 지중 Qiu, 지린 양, 지탕 등이다. 이미: 자기회귀 블랭크를 주입하는 척하는 일반 언어 모델입니다. 컴퓨터통계학회 제60회 연례회의 _검토[1: 롱 파이어스]_, pp. 320-335.\n' +
      '* P.(2023) 차오우푸, 페릭스안 첸, 윤항 선, 야렐리 진, 멍단 장, 잔린, 진루린, 샤우 정, 케이 리, 시잉 선 등 복합 대형 언어 모델에 대한 종합 평가 벤치마크. Mme: 다중 모드 대형 언어 모델에 대한 종합 평가 벤치마크. arXiv 프리프린트 arXiv:2306.13394_, 2023.\n' +
      '* 간즈 등은 로이 간즈(2023)와 오렌 누릴, 아비드 애버담, Yair Kittenplon, Shai Mazor, Ron Litman 등이 있다. 보고 읽을 수 있는 토우드 모델 __Towards 모델을 보고 읽을 수 있다. 컴퓨터 비전_, 2023. 도이: 10.1109/ICCV51070.2023.01985에 대한 IEEE 국제 회의.\n' +
      '* 구라리 등은 (2018) 다나 구라리, 청리, 압게일 J 스트랑플, 안홍 구오, 치린, 크리스텐 그레이만, 지보 루오, 제프리 파 비삼 등이 있다. 비즈위즈 대도전: 시각장애인들의 시각적 질문을 해결하십시오. 컴퓨터 비전 및 패턴 인식_, pp. 3608-3617에 대한 IEEE 회의의 _검토에서 2018.\n' +
      '* 펜드랙 등은 (2020) 단 헨드롭스, 콜린 번스, 스티븐 바카르트, 앤디 주, 만타스 미지카, 전당곡, 제이콥 슈타인하르트 등이다. 대규모 멀티태스킹 언어 이해를 측정하는 __ 대규모 멀티태스킹 언어 이해를 측정할 수 있다. arXiv 프리프린트 arXiv:2009.03300_ 2020.\n' +
      '*홍 등은 (2023) 위이홍, 웨한왕, 진송레프, 자선청주, 원멍유, 준희지, 옌왕, 자한왕, 유시아오동, 명딩, 지당 등이 있다. 코가젠트: 2023년 구이 에이전트에 대한 시각적 언어 모델.\n' +
      '* Hu 등은 (2023) 진이후, 유안야오, 충이왕, 샤니왕, 윤수판, 진유, 진유, 진유, 천유, 항하오우, 유에조우, 하예장, 주한, 유카이린, 자오위, 다하이 리, 지히유안 류, 마송순이다. 큰 다국어 모델은 언어를 가로질러 제로샷 멀티모달 학습을 피한다. 2023.\n' +
      '* 허드슨, 매니닝(2019) 드류 아 허드슨, 크리스토퍼 디 매니닝. Gqa: 현실 세계 시각 추론 및 구성 질문 대답을 위한 새로운 데이터셋입니다. 컴퓨터 비전 및 패턴 인식_, pp 6700-6709에 대한 IEEE/CVF 회의의 _검토에서 2019.\n' +
      '*리 등은 알(2023) 보하오 리, 리의왕, 광지왕, 유잉게, 요시아오게, 예잉샹 등이 있다. Seed-bench: 벤클마크 다중 모드 램은 생성적 이해를 가진 __Seed-bench: 벤클마크 다중 모드 llms이다. arXiv 프리프린트 arXiv:2307.16125_, 2023.\n' +
      '* 린 등은 (2014) 타성이린, 마이클 마이어, 세르게 벨롱기, 제임스 하이이스, 피에트로 페로나, 데바 라만, 프리오르 딜, 코렌스 지트닉 등이 있다. 마이크로소프트 코모: 맥락상 공통 객체. "컴퓨터 비전-ECCV 2014: 제13차 유럽 회의, 스위스 취리히, 2014년 9월 6-12일, 제작, 파트 V 13_, pp 740-755. 스프링거 2014.\n' +
      '* 류 등은 (2023)링크솔-AI입니다. 중국 라라바[국경://github.com/LinkSoul-AI/중국-LLaVA]]]. 1955년(https://github.com/LinkSoul-AI/중국-LLaVA)\n' +
      '(2023) 원 류, 하동 단안, 원한 장, 보 리, 송양 장, 왕보 자오, 야이크 유안, 지아치 왕, 콩휘 하이, 지웨이 류, 등 다모달 모델이 만능 선수인가? arXiv 프리프린트 arXiv:2307.06281_, 2023.\n' +
      '* 루 등 (2022) 판루, 세와로프 미슈라, 탕린샤, 리앙큐, 카이위 창, 송춘주, 오이빈드 타프조드, 피터 클락, 아슈윈 칼라이언. 과학 질문 답변에 대한 사고 사슬을 통한 멀티모달 추론: 과학 질문 답변에 대한 사고 사슬을 통한 멀티모달 추론: 설명하도록 학습한다. 신경 정보 처리 시스템_, 2022년 35:2507-2521의 발전입니다.\n' +
      '* 루 등은 (2023) 판 루, 히트릭 반살, 토니 샤, 지아청 류, 춘유안 리, 한나네 하지시르지, 하오 청, 카이위 창, 미셸 갈리, 지안펑 가오 등이다. Mathvista: 시각적 맥락에서 기반 모델의 수학적 추론을 평가하는 _athvista: 시각적 맥락에서 기초 모델의 수학적 추론을 평가한다. arXiv 프리프린트 arXiv:2310.02255_, 2023.\n' +
      '* 루 등은 알(2022)* 마미노 등은 알(2019) 케네스 마노, 모하마드 라스티가리, 알리 파하디, 루 우즈벡 모타게이 등이 있다. 옥바: 외부 지식이 필요한 벤치마크에 답하는 시각적 질문. 컴퓨터 비전 및 패턴 인식(CVPR)_ 2019년에 _Conference.\n' +
      '* 플래머 등은 (2015) 브라이언 아 플래머, 리웨이 왕, 크리스 메르반테스, 후안 카메고, 줄리아 호켄마이어, 스베를라나 라즈비니크 등이 있다. Flickr30k 엔티티: 영역 대 프레이즈를 수집하는 것은 더 풍부한 이미지 대 좌표 모델에 대응한다. 컴퓨터 비전_, pp. 2641-2649에 대한 IEEE 국제 회의의 _검토에서 2015.\n' +
      '* 슈웬크 등은 (2022) 더스틴 슈웬크, 아틀레브 케델왈, 크리스토퍼 클라크, 케네스 마리노, 루 우즈베크 모타게이 등이 있다. A-okvqa: 세계 지식을 사용하여 답하는 시각적 질문에 대한 벤치마킹입니다. 컴퓨터 비전_, pp. 146-162, 2022년 스프링거에 관한 _유럽 회의에서.\n' +
      '*선(2023) 추안선, 유펑의, 샤오송장, 판장, 기잉유, 정시온고루오, 유에제왕, 용밍로오, 징징류우, 티준황, 신장왕 등이 있다. 생산적 멀티 모달 모델은 인텍스트 학습자입니다. 2023.\n' +
      '* 비넬 등은 (2014) 오리올 비네스, 알렉산더 토스허프, 삼이 벤지오, 두릿루 에르한 등이 있다. A 신경 영상 캡션 생성기를 보여주세요. 2014년 __corr abs/1411.4555 (2014) __corr abs/1411.4555 (2014) arXiv 프리프린트 arXiv:1411.4555_ 2014.\n' +
      '*왕 등은 (2023) 위한왕, 진송레프, 원멍유, 원멍유, 원이홍, 지귀, 옌왕, 준희지, 주오이양, 레이 자오, 시수안송, 조조청주, 빈Xu, 주안지리, 유시아오동, 명딩, 지에당 등을 알 수 있다. 코그블m: 사전 절제된 언어 모델을 위한 비주얼 전문가 2023.\n' +
      '* Wei et al. (2023) Cong Wei, 양 첸, 해난 첸, 히시앙 후, 거장, 지푸, 알란 리터, 원후 첸을 들 수 있다. 유니어는 __Uniir: 보편적 다중 모드 정보 검색기를 훈련하고 벤치마킹하는 보편적 다중 모드 정보 검색자이다. arXiv 프리프린트 arXiv:2311.17136_, 2023.\n' +
      '*우 등은 우(2024) 시웨이 우, Yizhi LI, 강주, 거장, 예밍 리강, 기징 마, 카누가오 샤오, 하로안 장, 보하오 양, 원후 코헨, 원하오 황, 원하오 황, 누우 알 무바예드, 지후, 첸구아 린. SciMMIR: 벤키마크 과학 멀티-모달 정보 리베리발, 2024년 1월 URL[https://doi.org/10.5281/젠도10521030](https://doi/10.5281/젠도10521030).\n' +
      '*예(2023) 칭하오예, 하이양수, 지바오예, 명옌, 하와이 류, 기안, 지장, 필황, 진렌주 등이 있다. 무플러그-볼2: 모달리티 협업으로 다중모달 대형 언어 모델을 혁명화하는 _mplug-owl2: 모달리티 협업으로 통합한다. arXiv 프리프린트 arXiv:2311.04257_ 2023.\n' +
      '*유 등은 알(2023) 위하오 유, 지니규안 양, 린지 리, 지안펑 왕, 케빈 린, 지청 류, 시치오 왕, 리주안 왕이다. Mm-vet: 통합 역량을 위한 대형 멀티모달 모델을 평가하는 __Mm-vet: 통합 역량을 위한 대형 멀티모달 모델을 평가한다. arXiv 프리프린트 arXiv: 2308.02490_, 2023.\n' +
      '*유에 등은 (2023) 샤앙유, 유산정니, 카이장, 톈유장, 톈유위정, 루치우, 거장, 사무엘 슈벤스, 동푸장, 위밍 르, 유수안 선 등 전문가 아이에 대한 대규모 다범 복합 이해와 추론 벤치마크이다. arXiv 프리프린트 arXiv:2311.16502_, 2023.\n' +
      '*장 등은 샤오티안 장(2023)과 춘양 리, 이동, 선규잉, 리앙허, 시펑귀 등이 있다. 거대 언어 모델의 성능을 토포카오 벤치마크에 평가하는 __. arXiv 프리프린트 arXiv:2305.12474_, 2023.\n' +
      '*중 등은 (2023)완준중, 루닉시앙쿠이, 요이오구오, 야보리앙, 샤이 루, 옌린왕, 아민 사이드, 웨이슈첸, 난두안 등이다. 기초 모델을 평가하기 위한 인간 중심 벤치마크 __Agieval: 기반 모델을 평가하기 위한 인간 중심 벤치마크이다. arXiv 프리프린트 arXiv:2304.06364_, 2023.\n' +
      '\n' +
      '부록 A.\n' +
      '\n' +
      '부록은 141개의 오류 예 및 65개의 정확한 예들에 대한 분석을 포함하여 GPT-4V의 샘플 분석이다.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:15]\n' +
      '\n' +
      '(B) * **Front-*****G 그라운드 진실: (B) ****G 그라운드 진실: (B) * ****G 그라운드 진실: (B) * * * ***G 그라운드 진실: (B) * * * ***G 그라운드 진실: (B) * * * * * * * * * * **G 그라운드 진실: (B) * * * * * * * * * * * * * * * * * * * **G 그라운드 진실: (B)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:17]\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Error Reason:** GPT-4V는 이미지를 정확하게 분석한 결과, 다리 운동을 위해 뒷면에 누워 있는 사람이 (A)와 (D) 모두에서 가능한 정답을 추론했다. 그러나 요추 디스크 탈진 등으로 환자가 입원했다는 점을 간과하고, 요추 디스크 해석 수술 후 (D)신경근 접착을 방지하기 위한 운동으로 추론 오차로 이어졌다.\n' +
      '\n' +
      '**G 그라운드 진실:** (D)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:19]\n' +
      '\n' +
      '***\n' +
      '\n' +
      '**Error Reason:** GPT-4V는 이미지를 올바르게 해석하여 정확한 판단을 하였다. 그러나 후속 분석에서 "EL"과 같은 키워드의 포함은 추출 및 배치 과정에 오류가 발생하여 답변(A)과 (C)의 추출이 이루어졌다.\n' +
      '\n' +
      '**Ground Truth:** **(A)****\n' +
      '\n' +
      '**Option:**\n' +
      '\n' +
      '(A) 40cm\\(\\sim\\)50cm\\(\\#\\)30cm\n' +
      '\n' +
      '(B) 50cm\\(\\sim\\)60cm\\(\\#\\)40cm\n' +
      '\n' +
      '(C) 60cm\\(\\sim\\)70cm\\(\\#\\)50cm\n' +
      '\n' +
      '(D) 70cm\\(\\sim\\)80cm\\(\\#\\)60cm\n' +
      '\n' +
      '<지식**>의 부족.\n' +
      '\n' +
      '**Error Reason:** GPT-4V는 이미지를 올바르게 해석하여 1과 2를 모두 식별하였으나 실제 지식이 부족하여 1과 2의 높이를 결정할 수 없었다.\n' +
      '\n' +
      '(C) 60cm 합계 70cm, 50cm*****G 그라운드 진실: (C)\n' +
      '\n' +
      '**Error Category: 지식오차소포의 개념오차 :** GPT-4V는 전류의 방향, 코일의 권취, 관련 자기장 효과 등 이미지의 정보를 정확하게 이해하거나 분석하지 못했다. 이러한 오차는 GPT-4V가 회로 도표나 심볼과 같은 이미지에서 세부 사항을 직접 파싱할 수 없기 때문에 발생하여 전기 키가 닫힌 후 부드러운 철 조각 A, B 및 C의 자기 극 변화를 정확하게 결정할 수 없었다. 이 경우 GPT-4V는 확정적인 답을 제공하지 않고 전자석의 일반적인 원리에 근거하여 설명하였으며, 이는 이미지 내의 특정 시각 정보를 처리할 수 없음을 나타낸다.\n' +
      '\n' +
      '****************************************************************************************************************************************************************************************************************************************************************\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:23]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:24]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:25]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:26]\n' +
      '\n' +
      '**Error C 카테고리: 정답 추출 에러 어러 레슨:** 코드에 의해 추출된 답은 GPT-4V에 대한 정답이 아니다. 문항은 이미지에 나타난 연결 유형을 식별하도록 요청하였고, GPT-4V는 (D)키드 커넥션을 잘못 선택한 반면, 이미지에 표시된 실제 연결은 키리스 커넥션이다. 이는 GPT-4V가 텍스트와 이미지로부터 정답을 추출하는 오류를 만들어 부적절한 답을 선택했음을 나타낸다.\n' +
      '\n' +
      '(B) 키 키드드 오일 : (B) 키더드***G 그라운드 진서: (B)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:28]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:29]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:30]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:31]\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Error Reason:** GPT-4V는 질문과 이미지를 올바르게 이해하여 이미지가 현미경 아래의 혈액 도말임을 추론한다. 그러나, 그것은 일반적으로 혈액 성분이 아닌 청색 세포(흡연 세포)를 기반으로 하는 옵션을 배제했다. 평소 상황에서 도말 세포는 혈액 도말을 하는 과정에서 손상된 백혈구를 의미한다.\n' +
      '\n' +
      '(A)TT)(A)TTTT(A)TTT)T 그라운드 진서 : (A)***G 그라운드 진서: (**G 그라운드 진서: (A)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:33]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:34]\n' +
      '\n' +
      '지식***Error Category\n' +
      '\n' +
      '**Error Reason:\\(\\mathrm{GPT}\\)-4V는 일부 지식을 간과하거나 결여했다. 사실, 림프구는 실제로 GPT-4V에서 언급한 특성을 가지고 있다. 그러나 이미지 내의 세포는 청색 세포질뿐만 아니라 반응성 림프구의 특징인 매우 불규칙한 형태를 가지고 있다. 유사하게, 반응성 림프구는 또한 앞서 언급한 특성***도 가지고 있다.\n' +
      '\n' +
      '**G 그라운드 진실: (D)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:36]\n' +
      '\n' +
      '<지식**>의 부족.\n' +
      '\n' +
      '문제의 텍스트**Error Reason:**는 실제로 이미지 DNF의 역보완 서열이므로 전자가 DNA 중합효소를 통해 후자에 의해 생성되는 것이 옳다. GPT-4V는 역보완 서열에 대한 지식이 부족하여 잘못된 판단을 초래했다.\n' +
      '\n' +
      '**Ground Truth: (LE.)**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:38]\n' +
      '\n' +
      '**Error C 카테고리: 이유기 에르러 리워즈:** 전사는 실제로 오른쪽에서 왼쪽으로 진행되므로 템플릿의 3\' 내지 5\' 방향을 따라 발생한다(음성). 위에서 언급한 가닥(음성 가닥)은 전사 템플릿이다. GPT-4V는 공제액을 과대평가하여 잘못된 결론을 내렸다.\n' +
      '\n' +
      '**Ground Truth:**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:40]\n' +
      '\n' +
      '**Error Category:Perceptual Error**\n' +
      '\n' +
      '옵션 C의 분자**Error Reason:**는 아미노(-NH-) 그룹과 에테르(-O-) 구조를 포함한다. 이 두 작용기는 에틸 카바메이트의 성분과 혼동될 수 있다. 이 두 부분에는 각각 질소 및 산소 원자가 포함되어 있지만 에틸 카바메이트 구조가 형성되지 않는다. 더욱이, 옵션 C의 화합물은 페닐 링과 에톡시 그룹 사이에 위치한 에테르 산소(-O-)를 포함하며, 이는 GPT-4에 의한 잘못된 선택을 초래했다.\n' +
      '\n' +
      '**Ground Truth: (D):**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:42]\n' +
      '\n' +
      '***그림 1:** 영상은 난류 노즐을 명확하게 나타내지만 GPT-4V는 인식하지 못했을 수 있다. 이미지 판독 능력이 부족하거나 인식 능력이 약하기 때문에 이미지로부터 모든 실제 정보를 올바르게 획득하지 못했으며, 이는 더 나아가 잘못된 선택으로 이어졌다.\n' +
      '\n' +
      '**Error C 카테고리:개념 에러 에르러 리워즈:**분명히 GPT-4V는 그림의 하이드록실 그룹의 수를 잘못 계수했다. 현실적으로 옵션 C는 D와 동일한 수의 하이드록실기를 가지며, 수산기와 동일한 고리에 2개의 메톡시기가 있어 화합물의 산도를 크게 향상시킬 수 있다. 따라서, 이것은 다이어그램을 오독하는 경우이다.\n' +
      '\n' +
      '(성각\\)H\\(성각\\)C\\(성각\\)\\(성각\\)H\\(성각\\)\\(C) 3***G 그라운드 진실: (C) \\(표각) H\\(\\) \\(八) －**G 그라운드 확인) \\(C) \\((직각도) \\(직각도) \\(직각도) \\) \\(직각도(직각도) \\) \\(직각도(직각도) \\) \\(직각도(직각도) \\) \\(직각도) \\) \\(직각도(직각도) \\) \\) \\(직각도)***H\\) \\(직각도(직각도(직각도) ) \\) ) \\(직각도(직각도(직각도) ) ) ) ) \\(직각도(직각도(직각도(직각도) ) ) )\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:45]\n' +
      '\n' +
      '**Error Category:Perceptual Error**\n' +
      '\n' +
      '**Error Reason:\\(\\mathrm{GPT}\\)-\\(4\\mathrm{V}\\)은 시스템이 뜨거운 물을 저장하기 위한 적어도 두 개의 용기를 포함하고 있으며, 프로세스는 강제 순환 간접 가열 모드임을 관찰했다. 그러나 그림에는 물탱크가 1개, 물주그 1개가 있고 GPT-4는 물주그 둘 다 잘못 식별하여 잘못된 선택을 하게 된다.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:47]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:48]\n' +
      '\n' +
      '**Error Category: 지식 연관 규범의 부족:** 그림의 장치는 석탄 채굴기의 모델이다. GPT-4V는 이를 인식하지 못했으며, 이는 이러한 지식이 부족할 수 있음을 나타낸다. 따라서 이러한 오류는 지식 결여로 분류된다.\n' +
      '\n' +
      '**G 그라운드 진실:** (A)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:50]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:51]\n' +
      '\n' +
      '**Error Category:Reasoning Error**\n' +
      '\n' +
      '**Error Reason:**GPT-4V는 이 영역에 지식을 가지고 있으며 이미 "중수 반응기는 농축되지 않은 천연 우라늄을 연료로 사용할 수 있다"고 답했다. 그러나 최종 답에서는 (A) 중수로 반응했는데, 이는 이유 있는 어로이다.\n' +
      '\n' +
      '**Error Category:Textual Understanding**\n' +
      '\n' +
      '**Error Reason:GPT-4V는 이미지를 올바르게 이해하고 \'제조 링크가 중간 골짜기 위치에 위치하고 있다\'는 핵심점을 파악했지만, 질문 옵션에서 \'가장 낮음\'과 \'비교적 낮음\'을 정확하게 구분하지 못했다. 비교적 낮은 것으로 전 세계적으로 가장 낮은 위치를 착각하고 있어 GPT-4V가 이 질문에 잘못 답하는 것으로 나타났다.**.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:54]\n' +
      '\n' +
      '에러 에러러***Eror.\n' +
      '\n' +
      '**Error Reason: A 선수가 \'다운\'을 선택하고 B 선수가 \'오른쪽\'을 선택할 때 GPT-4V는 이러한 Nash 평형을 고려한다. 그러나 이런 상황에서 B 선수가 \'좌석\'으로 선택을 바꾸면 더 높은 보수를 얻게 된다. 따라서 \'다운, 우\'의 조합은 나시 균형이 아니다. GPT-4V는 이 사건에서 리슈팅 에러를 만들었다.***.\n' +
      '\n' +
      '**G 그라운드 트러티: (C)\\(\\overline{\\mathbf{\\mathf{\\math{\\math{{\\mathf{\\mathf{}}})\n' +
      '\n' +
      '**Error C 카테고리: 적합성 에르오러 리워즈:**GPT-4V는 다른 전략을 선택할 때 이미 각 회사에 대해 최상의 반응을 나열했으며, 어떤 당사자가 일방적으로 전략을 변경할 유인이 없을 때 나시 균형이 발생한다는 것을 알고 있다. 이 시점까지는 문제가 없습니다. 다만 어떤 상황이 "일방적으로 전략을 바꿀 유인이 없는 정당"에 속할 때 오류가 발생했는데, 기업 1과 2가 모두 가격을 인하하면 기업 2의 전략 변화는 실제로 더 큰 이익으로 이어진다. 따라서 나이시 균형은 옵션 A에서는 발생하지 않고 옵션 C에서는 발생한다.\n' +
      '\n' +
      '**Error C 카테고리: Answer Error Reason에 대한 범위: 경제학에서 기업은 2단계에서 생산하는데, 이는 도표에서 L=5~L=8을 지칭하기 때문에 정답이 D이기 때문에 GPT-4V가 잘못된 주된 이유는 지식 부족 때문이다.\n' +
      '\n' +
      '(D)5<L<8<L<8<L<8<L<8<***G 그라운드 진서: (D)5<L<8<L<8<L<8<L <8<L****G 그라운드 진서: (D)5<L<8<L <8<L <8<L****G 그라운드 진서: (D)****G 그라운드 진서: (D)5<L <8<L<L <8<L <8<L <8<L<L <8<L <8<L <8<L***********************************************************************************************************************\n' +
      '\n' +
      '**Error C 카테고리:지식 에르러 리슨:GPT-4V의 부족은 초기에 약간의 공제를 하였지만 최종 결론은 정답을 산출하지 못했다. 이는 GPT-4V의 구체적인 문제 해결 지식 부족으로 인한 것이다. 따라서 여기서 GPT-4V의 오류 이유는 \'지식 부족\'이다.\n' +
      '\n' +
      '**Ground Truth: (C)70**\n' +
      '\n' +
      '**Error C 카테고리: 지식 간섭의 부족:** GPT-4V에서 제공하는 반응은 정확하지 않다. 금융 분야에서는 자산 i에 대한 요구수익률(Ri)과 그 베타(\\(\\beta\\))의 관계에 의해 형성된 선을 통상적으로 자본시장선이 아닌 보안시장선(SML)이라 한다. GPT-4V의 오류는 관련 영역에 대한 지식이 부족한 것에서 비롯된다.\n' +
      '\n' +
      '**Ground Truth:**\n' +
      '\n' +
      'dot w_{C}\\cot w_{C}\\cot w_{C}\\cot w_{C}\\cot w_{C}\\cot w.\n' +
      '\n' +
      '또한 포트폴리오의 분산을 계산하는 데 이 공식을 성공적으로 사용했다.\n' +
      '\n' +
      '그러나 후속 추론 동안 GPT-4V는 표준 편차를 정확하게 계산하지 않았다. 대신 분산에 가장 가까운 답을 선택하여 추론 오류를 초래하였다.\n' +
      '\n' +
      '앞의 진실 : (C) 6.2******* (C) 지상 진증: (C) 6.2******G 그라운드 진증.\n' +
      '\n' +
      '**Error C 카테고리: 텍스트 이해 Eror Reason:**GPT-4V는 질문 프롬프트를 잘못 해석했다. 그 프롬프트는 A주와 B주가 완전히 음(-)의 상관관계가 있는 두 종목을 명시적으로 명시하여 상관 계수에 대한 정보를 제공한다. 그러나 GPT-4V는 이러한 중요한 정보를 간과하여 후속 추론 계산의 다른 오류를 초래하고 AB를 포함한 여러 답변을 초래한다.\n' +
      '\n' +
      '일정한 진실 : (A) 0.0225***** (A) 0.0225****G 그라운드 진실:\n' +
      '\n' +
      '**Error C 카테고리: Answer Error Reason의 범위:**GPT-4V는 이미지가 \'증권 시장에서 조달\'에 대한 데이터를 직접 표시하지 않는 것으로 보고 있으며, 이는 비금융 기업 부문에서 증권 시장에서 직접적으로 자금조달의 특정 비중을 계산할 수 없다고 본다. 현실적으로 이미지 내 \'증권시장으로부터의 네트워킹 차입\'은 답을 위해 필요한 핵심 정보이다. GPT-4V는 특정 데이터의 부족이 응답을 제공하는 것을 방지하는 것으로 간주한다.\n' +
      '\n' +
      '**Ground Truth: 0.48**\n' +
      '\n' +
      '이 경우 GPT-4V는**Error C 카테고리: 주석 에르러 에러 리워슨:**에서 질문의 의미를 정확히 파악하고 엄격한 제형과 계산을 제공했다. 계산된 결과는 완전히 정확했습니다. 그러나 표준 답변을 주석하는 문제로 인해 정확한 반응은 D 0.16이 되어 주석 에러로 이어져야 한다.\n' +
      '\n' +
      '앞의 진실: (C) 0.15*******G 그라운드 진실: (C) 0.15*****G 그라운드 진실: (C)\n' +
      '\n' +
      '이 경우 GPT-4V는 프로젝트 A와 C에 대한 상황을 정확하게 계산했지만 프로젝트 B를 계산할 때 잘못된 추론을 하였다. 3년차에 3000개의 현금흐름이 5000보다 작은 상황에서 프로젝트 B는 초기 투자 회수 요건을 충족하지 못한다. 정답은 A와 C여야 합니다.\n' +
      '\n' +
      '**G 그라운드 진실: (B) A\\ (경쟁자{\\mu}\\)C****G 그라운드 진실\n' +
      '\n' +
      '실용적인 에러러***Eror.\n' +
      '\n' +
      '**Error Reason:**GPT-4V는 총 비용을 계산하는 공식을 제공하지만 차트 내의 정보를 잘못 해석한다. 제품 A를 예로 들자면, 기준 기간을 단위 비용으로 잘못 고려하여 제품 B의 출력을 자체로 귀속시켜 계산 데이터의 오정렬을 초래하고 결과적으로 계산의 오류로 이어진다.\n' +
      '\n' +
      '(D) 2.51; 820***G 그라운드 진실:(D) 2.51; 820***G 그라운드 진실:(D) 2.51; 820***G 그라운드 진실:(D) 2.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:66]\n' +
      '\n' +
      '**Error C 카테고리: 지식 오류 이유 부족:**GPT-4V는 이자 및 과세 전(EBIT) 대 총자산 비율을 계산하기 위한 잘못된 공식을 잘못 제공했다. 올바른 공식은 이자 및 과세 전(EBIT)을 고용된 평균 총자산으로 나눈 것이다. 또한 GPT-4V는 이미지 데이터 처리에서 편차를 나타내어 이자 및 과세 전(EBIT) 및 총 자산 값을 부정확하게 판독했다.\n' +
      '\n' +
      '**Ground Truth: 22.86**\n' +
      '\n' +
      '<지식**>의 부족.\n' +
      '\n' +
      '**Error Reason:GPT-4V는 이익 마이너스(자본비용률 \\(CS) 자본투자)와 같다며 잔차 소득에 대한 잘못된 계산 방법을 제공했다. A 센터의 경우 수익 285,000, 평균 영업 자산 1,350,000, 자본 비용 비율 18%인 A 센터의 경우 정확한 결과는 285,000 -(1,350,000 \\) 18%) = 42,000~18%이어야 한다.\n' +
      '\n' +
      '**Ground Truth: 4.27**\n' +
      '\n' +
      '실용적 이해**오차 범주:\n' +
      '\n' +
      '**Error Reason:**GPT-4V는 과제의 의미를 오해하였다. 추론 과정에서 제2 디바이스로 이동하기 전에 제1 디바이스 상에서 처리가 먼저 발생해야 한다는 전제 조건을 간과하였다. 이 감독으로 인해 추론 과정의 오류가 발생했습니다.\n' +
      '\n' +
      '(D) D-A-C-B*****G 그라운드 진실: (D) D-A-C-B****G 그라운드 진실: (D) D-A-C-B***G 그라운드 진실: (D) D-A-B****G 그라운드 진실: (D) D-A-C-B****G 그라운드 진실: (D) D-A-C-B****G 그라운드 진실: (D) D-A-C-B*****G 그라운드 진실: D-A-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C********G 그라운드 진실: D-A-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-C-\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:70]\n' +
      '\n' +
      '**Error C 카테고리: 지식 오류 이유 부족:**CPT-4V는 비교 순위 동안 잘못된 처리를 유도하는 \'일대일 비교 방법\'에 대한 관련 지식이 부족하다. 더 높은 비교를 더 낮은 것으로 착각하여 잘못된 추론을 초래한다.\n' +
      '\n' +
      '(D) XXX*****G 그라운드 진: (D) XXX****G 그라운드 진: (D) XXX****G 그라운드 진서: (D)\n' +
      '\n' +
      '실용적인 에러러***Eror.\n' +
      '\n' +
      '**Error Reason:**GPT-4V는 이미지 내의 데이터의 의미를 오해하였다. 제2 행의 데이터는 연간 유지 비용을 나타내고, 제3 행의 데이터는 각각의 확률에 대응한다. 각 컬럼은 다른 공급자를 나타내며 서로 다른 연도 간의 변화를 포함하지 않는다. 그러나 GPT는 서로 다른 열의 데이터를 서로 다른 연도의 변화로 잘못 해석했다.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:73]\n' +
      '\n' +
      '[B] 0.994343;[B] 0.994343; 8****G 그라운드 진실:[B] 0.994343; 8****G 그라운드 진실\n' +
      '\n' +
      '**Error Category: 지식오차 요구의 결여:**GPT-4V는 단순한 선형 회귀 모형을 설정하기 위한 구체적인 단계에 대한 자세한 설명을 제공하며, 정보에 오류가 없다. 그러나 GPT-4V는 계산을 위한 전문 통계 소프트웨어나 도구가 필요하기 때문에 단순 선형 회귀 모델을 직접 계산하거나 설정할 수 없다.\n' +
      '\n' +
      '지상 진실: (B) 466.06***.54~485.06*********G 그라운드 진실: (B) 466.06***.54~485.06******G 그라운드 진실: (B) 466.54~485.06******G 그라운드 진실: (B)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:76]\n' +
      '\n' +
      '적절한 접근 방식은 총 모금액에 대한 각 모금액의 비율을 계산하고 이러한 비율을 가중치로 사용하여 자본의 한계 비용을 산출하고 "자본***의 한계 비용을 계산, 즉 자본 비용의 가장 높은 비율"으로 잘못 해석해야 한다.\n' +
      '\n' +
      '**Error C 카테고리: 지식 오류 이유 부족:**GPT-4V는 한계 비용을 계산하는 데 관련 지식이 부족하고 도표에서 가변 비용을 한계 비용으로 잘못 해석한다. 그러나 한계 비용의 진정한 의미는 생산량의 1단위 변화에 대한 총 비용의 변화가 되어야 한다. 따라서 4단위를 생산할 때 한계비용은 19-10=9로 한계비용이 시장균형가격과 같을 것이다.\n' +
      '\n' +
      '(B) 41 400*******G 그라운드 진서: (B)\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:79]\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Reason:** GPT-4V 모델은 질문을 분석하는 데 추론 오류를 나타냈다. 이 문제에서 공기로 둘러싸인 유리 슬래브가 수직 발생률을 갖는 단색 평행광 아래 수직으로 변위될 때 간섭무늬가 어떻게 변하는지를 이해하는 것이 관건이다. 모델의 반응은 상부 유리 슬래브가 위쪽으로 이동됨에 따라 에지 근처의 쐐기 두께가 증가하여 광학 경로 차이가 증가하여 간섭 프린지가 가장자리에서 멀어지게 된다는 것을 잘못 제안했다. 이것은 잘못된 추론입니다.\n' +
      '\n' +
      '**(C) *******G 지상진표:********G 지상진표:**************G 그라운드진표:***********************************************************************************����������������������������������������������������������������������������������������������������������������������������\n' +
      '제한.\n' +
      '\n' +
      '**Error Reason:** GPT-4V 모델은 이 물리학 문제를 분석할 때 추론 오류를 만들었다. 문제는 주어진 힘 시스템의 결과 순간을 점 I에 대해 계산해야 하며, 모델은 레버 팔에 대한 AB 길이에 OA의 길이를 추가하여 포인트 I에 대한 힘 F의 순간을 잘못 계산했다.\n' +
      '\n' +
      '()(D) M1=500N cm(()***G 그라운드 진서: (D) M1=500N cm ( ()***G 그라운드 진서: (D) M1=500N cm ( (****G 그라운드 진서) : (D) M1=500N cm ( (****G 그라운드 진서: - - - - - ( ()*****G 그라운드 진서: (D) - - (D) *******         )\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Error Reason:**GPT-4V는 순간 다이어그램을 사용하여 전단력 다이어그램을 결정할 수 있으며 최대 전단은 보통 순간도의 최대점 또는 최소점 근처에서 발생한다고 올바르게 지적했다. 다만, 순간 변동률의 구체적인 변화를 분석할 때 모형의 추론에 편차가 있었다.\n' +
      '\n' +
      '(D) 2F*****G 그라운드 진: (D) 2F****G 그라운드 진: (D) 2F****G 그라운드 진: (D)\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:83]\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Reason:** GPT-4V는 가능한 옵션에 대해 추론할 때 특정 수준의 도메인 지식을 보여주었지만 이 지식을 특정 질문에 정확하게 적용하지는 못했다. 이 모델은 여러 구조 시스템의 일반적인 특성을 올바르게 기술했지만 이미지 정보를 기반으로 특정 옵션을 효과적으로 판단할 수 없었다. 이 이해와 적용 사이의 단절은 충분한 상황 정보가 부족하거나 지식 기반이 이 영역에 광범위한 전문성이 없기 때문일 수 있다.\n' +
      '\n' +
      '**G 그라운드 진실:** (B)\n' +
      '\n' +
      '**Error C 카테고리: 인식 오류, 개념 오류/정답 수정:** 첫째, 인식 오차와 관련하여 GPT-4V는 실제로 이미지 인식 능력을 가지고 있지만, 이 응답에서는 이미지 내용을 보고 이해할 수 없다고 잘못 진술하였다. 이는 모델이 해당 이미지의 내용을 파싱하기 위해 이미지 처리 능력을 올바르게 사용하지 않아 질문에 대한 이해가 불완전함을 나타낸다. 둘째, 답변 거부와 관련하여 이미지 내용을 이해할 수 없음을 확인한 후 모델이 특정 답변을 제공하지 않는 경로를 선택했다. 질문을 완전히 이해할 수 없는 상황에서 주의를 행사하는 것이 합리적이지만, 그러한 경우 모델은 해당 지식 기반에서 정보를 사용하여 질문의 요청과 밀접하게 일치하는 답을 제공하거나 적어도 텍스트 설명에 기초하여 합리적인 추측을 제공하려고 시도했어야 했다.\n' +
      '\n' +
      '**G 그라운드 진실:** (A)\n' +
      '\n' +
      '**Error Category: Answer Error Reason에 대한 객체:** While GPT-4V는 이미지 인식의 능력을 가지고 있으며, 이러한 특정 맥락에서 이미지 콘텐츠를 분석하고 답을 제공하는 이러한 능력을 완전히 활용하지 못했다. 모델은 질문에 직접 답하지 않도록 선택했고 대신 더 많은 배경 정보의 필요성을 강조했다. 이는 이미지 기반의 다중 선택형 문항을 다룰 때 지나치게 신중하다는 모델의 전략이 이미지 내용에 대한 직접적인 판단을 회피하기 때문일 수 있다.\n' +
      '\n' +
      '**G 그라운드 진실:** (B)\n' +
      '\n' +
      '**Error Category: Answer Error Reason의 대상:**GPT-4V는 이 질문에 대답하지 않기로 선택했다. 이 모델은 일반적으로 기계적 시스템의 운동학 및 역학에 대한 깊은 이해와 일러스트레이션에 묘사된 구조의 제약 및 자유도에 대한 분석이 필요하기 때문에 기계적 시스템의 특정 기하학적 구성 유형을 직접 제공할 수 없음을 나타낸다. 그러나 이 응답 접근법은 이미지 기반 질문을 다룰 때 모델의 한계를 보여준다.\n' +
      '\n' +
      '**G 그라운드 진실:** (D)\n' +
      '\n' +
      '**Error C 카테고리:개념 에르러 에러 리러 실록:**의 응답에서 GPT-4V는 낮은 이미지 해상도로 인해 노드, 멤버 및 제약의 수를 명확하게 식별할 수 없다고 언급했다. 이는 모델이 시각적 정보를 바탕으로 질문에 답하려고 시도했음을 나타내지만, 그 시각적 인식 능력의 한계로 인해 이미지 내 내용을 정확하게 해석할 수 없었다. 이는 시각적 정보에 대한 모델의 해석이 부정확하거나 불충분한 전형적인 인식 오류이다.\n' +
      '\n' +
      '**Ground Truth:-2**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:89]\n' +
      '\n' +
      '**Error C 카테고리: 지식 에러 실론의 부족:** GPT-4V는 특정 음악 이론에서 지식의 부족을 보여준다. 피아노 키보드에서는 검은 키 각각이 실제로 두 개의 흰색 키의 상행 또는 하행 톤이지만, 특정한 톤 이름이 있다. 이 경우 모델은 블랙 키에 대한 정확한 톤명을 정확하게 제공하지 못했지만 대신 일반적인 설명을 해 음악 이론에서 지식 부족을 보여준다. 모델은 피아노 키보드의 각 키를 정확하게 식별하고 이름화할 수 있는 충분한 지식을 가져야 한다.\n' +
      '\n' +
      '(A)[R]*****G 그라운드 진실: (A)[R]****G 그라운드 진실: (A)[R]****G 그라운드 진실: (A)[R]****G 그라운드 진실: (A)[R]****G 그라운드 진실: (A)[R]] (R]*****G 그라운드 진실: (R][R]] (R][R]****�����������������������������������������������������������������������������������������������������������������������������������������������������\n' +
      '\n' +
      '실용적인 에러러***Eror.\n' +
      '\n' +
      '**Error Reason:** GPT-4V는 이미지 내의 정보를 올바르게 인식하고 해석하여 질문에 답할 수 없었다. 이는 이미지 입력을 처리하는 모델의 능력에 지각적 한계를 시사한다. 모델은 이미지(예: 배우의 의상과 메이크업 스타일)에서 일부 기본 요소를 인식할 수 있었지만, 이러한 요소들을 특정 유형의 연극과 정확하게 연관시키지 못했다. 이는 다양한 유형의 중국 연극에 대한 시각적 특징과 양식적 세부 사항에 대한 모델이 충분히 심도 있는 이해가 부족하기 때문일 수 있다.\n' +
      '\n' +
      '**Error Category: 지식 오류 실수의 결여:** 이 응답에서 이미지 콘텐츠는 노래 노래 공간에 대한 선율 요소의 출처를 결정할 수 있는 충분한 정보를 제공하고 이 정보를 인식하고 활용하지 못하는 모델이 도메인 특이적 지식의 부족을 보여준다.\n' +
      '\n' +
      '**G 그라운드 진실:** (A)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:93]\n' +
      '\n' +
      '표기.\n' +
      '\n' +
      '**Error Reason:** GPT-4는 각 옵션에 의해 제공되는 라인 드로잉의 종류를 특성화하여 가능한 답변을 추측하고자 한다. 그러나 이 방법은 그림에 대한 직접적인 관찰과 분석이 없는 상태에서 정확성과 타당성에 매우 제한적이다. 그림의 특정에 접근할 수 없는 GPT-4는 효과적으로 분석하거나 정확한 답변을 제공할 수 없다. 또한 GPT-4는 실제 라인을 "맞힐 수 없다"는 반응을 분명히 했다.\n' +
      '\n' +
      '실용적인 에러러***Eror.\n' +
      '\n' +
      '**Error Reason:** GPT-4V는 이미지를 처리할 때 캘리그라피 브러시의 각도를 잘못 해석하였다. 이 경우, 정답은 종이의 표면에 대한 서예 브러시의 끝 각도에 기초할 필요가 있다. 올바른 경우 브러시의 끝이 종이의 표면, 즉 "중앙-변" 스트로크에 수직이어야 하지만 모델은 브러시의 끝이 수직적이지 않다는 것을 잘못 인식하고 따라서 "측-변" 스트로크를 정답으로 잘못 선택한다.\n' +
      '\n' +
      '** 그룹디 진실:** (B)\n' +
      '\n' +
      '**Error C 카테고리: 지식오차 실연의 부족:** GPT-4V는 이미지의 내용을 직접 인식할 수 없으며, 어떤 예술품인지 판단할 수 없다. 더욱이 답변에서 모델은 "황추안이 남송시대 화가였다"고 언급하는데, 이는 훈련 자료에서 역사적 정보에 의존한다는 것을 나타낸다. 다만, 모델의 학습 데이터는 황추안의 라이어 버드 드링스가 생성된 특정 시대에 대한 정확한 정보를 포함하지 않거나, 이 정보가 모델에 의해 올바르게 학습 및 리콜되지 않을 수 있다. 이로 인해 모델은 응답에서 지식 결핍을 나타낸다.\n' +
      '\n' +
      '**G 그라운드 진실: (D)\\ (\\mathbf{\\mathbb{R}}\\)****G 그라운드 트러시.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:97]\n' +
      '\n' +
      '<지식**>의 부족.\n' +
      '\n' +
      '**Error Reason:** GPT-4V는 이러한 전문화 용어를 정확하게 식별하거나 이해하지 못했다. 모델의 (A)패딩밴드 채핑 선택은 중국화 용어와 기법에 대한 이해가 제한적이며 서로 다른 청핑 기법을 정확하게 구별할 수 없음을 시사한다. 또한, 모델의 응답은 특정 용어에 대한 정확한 이해보다는 회화 양식에 대한 일반적인 설명을 기반으로 하는 것으로 보인다.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:99]\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Error Reason:** GPT-4V에서 만든 오류는 Gradient Editor에서 컬러 바의 작은 제곱의 기능에 대한 오해에서 비롯될 수 있다. 그래픽 편집 소프트웨어에서, 기울기 편집기의 설계 및 기능은 소프트웨어마다 다를 수 있다. 모델은 그 학습 데이터로부터 일반적인 지식 또는 문제의 특정 상황에 대한 세부 사항을 정확하게 파악하지 않고 특정 소프트웨어의 기능성에 기초하여 답변을 추론할 수 있다.\n' +
      '\n' +
      '(C)[XMM] *[DE]***G 그라운드 진실: (C) [XMM] *[DE]***G 그라운드 진실: (C) <***G 그라운드 진실: (C) < <XMM]] * [DE]****G 그라운드 진실: (C) <����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n' +
      '\n' +
      '**Error C 카테고리: 지식 오류 이유의 결여:** 에러의 출처는 GPT-4V의 전문성의 부족, 즉 이미지 내의 특정 텍스트 스타일에 대한 적절한 인식과 이해의 부재이다. 이미지의 텍스트는 아크 같은 시각적 효과를 나타내지만 정답은 "(D) 판"이어야 한다. 이는 서로 다른 텍스트 형태화 스타일을 이해하고 구별하는 모델의 능력에 대한 지식 한계를 시사한다. 모델은 이러한 질문에 답할 때 학습 데이터의 정보에 의존한다. 학습 데이터에 특정 텍스트 스타일(예: 팬, 하향 아크 등)에 대한 정보가 부족한 경우, 모델은 이러한 스타일 및 애플리케이션 시나리오의 특성을 정확하게 인식하고 이해할 수 없다.\n' +
      '\n' +
      '**G 그라운드 진실: (D)\n' +
      '\n' +
      '제한.\n' +
      '\n' +
      '**Error Reason:** 이 응답에서 GPT-4V는 질문에 답하기 위해 거부한다. 이러한 선택은 이미지 처리 능력에 대한 오해 때문일 수 있다. 실제로 GPT-4V는 일부 이미지 분석 능력을 가지고 있으며, 객체 식별, 색상, 레이아웃 등 공급되는 이미지에 대한 기본적인 시각적 콘텐츠 분석을 수행할 수 있다. 이 질문에서 사용자는 GPT-4V의 영상 처리 능력에 대해 질문하였다. 이 질문에서 사용자는 이미지의 시각적 특성을 분석하여 GPT-4V가 이론적으로 답변할 수 있는 이미지 편집 기법("faux 스탬프 도구)"의 영향을 묻고 있다. 또한, 모델은 질문의 맥락을 제대로 이해하지 못하였고, 그것이 영상 콘텐츠의 직접 수정 또는 생성과 관련된 요청이라고 오인하게 가정했을 수 있으며, 이는 GPT-4V가 현재 가지고 있지 않은 특징이다. 그러나 현실적으로, 질문은 이미지 내용을 분석할 뿐 이미지를 수정하지 말라는 질문일 뿐이다.\n' +
      '\n' +
      '**G 그라운드 진실:** (B)\n' +
      '\n' +
      '**Error C 카테고리:개념 에르러 에러 레슨:** GPT-4V는 이미지를 볼 수 없기 때문에 질문에 답하기 위해 직접 콘텐츠를 분석할 수 없음을 명시적으로 보여준다. 이는 일부 정도의 영상 처리 능력을 보유하더라도 영상 관련 정보를 처리하는 데 있어 모형의 한계를 보여준다. 모델은 각 옵션에 대한 일반적인 설명을 제공함으로써 이미지 콘텐츠에 대한 인식 부족을 보상하려고 시도하지만, 이 접근법은 이미지 콘텐츠에 특정한 질문에 정확하게 답할 수 없다. 모델의 설명은 기술적으로 정확하지만, 이는 이미지 콘텐츠에 대한 직접적인 분석이 필요하기 때문에 특정 이미지에 직접 적용할 수 없다.\n' +
      '\n' +
      '**G 그라운드 진실:** (A)\n' +
      '\n' +
      '**Error C 카테고리: Answer Error Reason에 대한 대상:** GPT-4V는 거부 태도를 반영하여 질문에서 주어진 옵션에 기초하여 논리적으로 이성을 시도하거나 역사적 지식을 제공하기보다는 직접 답을 거절하는 것을 선택한다. 이 경우, 직접 사진을 분석할 수 없음에도 불구하고 모델은 여전히 광범위한 지식 기반을 사용하여 옵션에 대한 컨텍스트 정보를 제공할 수 있으므로 사용자가 가능한 정답을 추론하는 데 도움을 줄 수 있다. 예를 들어, 각 옵션에서 언급된 역사 장소 또는 침식물을 설명하거나 이러한 사이트의 공통 특징 및 역사적 맥락 중 일부를 제공한다.\n' +
      '\n' +
      '**G 그라운드 진실:** (D)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:105]\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Error Reason:** While을 설명하는 GPT-4V는 핵 생성 이론으로부터 일반적인 원리를 올바르게 참조했지만 추론에 이 원리를 적용하는 데 오류를 냈다. 문제의 경우, 이미지는 핵형성 반경 \'r\'과 자유 에너지 \'\\(\\Delta\\)G\'의 변화 사이의 관계를 묘사하였으며, 서로 다른 온도를 나타내는 3개의 곡선을 포함하였다. 이론적으로 자유 에너지 변화 곡선의 높이는 온도에 반비례하며, 이는 낮은 곡선이 더 높은 온도를 나타낸다는 것을 의미한다.\n' +
      '\n' +
      '그러나 이 이미지를 분석할 때 GPT-4V는 가장 높은 피크가 가장 낮은 온도를 나타내는 곡선을 잘못 가정하여 "G1>G2>G3, T1>T2>T3"에서 언급된 중요한 정보를 소홀히 하였는데, 이는 r이 같을 때 동일한 핵형성 반경에 대해 자유에너지 \'\\(\\Delta\\)_G__\'의 더 큰 변화가 더 낮은 온도에 해당한다는 것을 의미한다.\n' +
      '\n' +
      '진실: (C) T3*****G 그라운드 진실: (C) T3****G 그라운드 진실: (C) T3*****G 그라운드 진실:\n' +
      '\n' +
      '**Error C 카테고리:정답의 수정:** GPT-4V 모델은 질문에 직접 답변하지 않기로 선택했으며(정답의 대상) 대신 다양한 유형의 사각 지대에 대한 설명 정보를 제공했다. 모델은 어떤 종류의 격자가 표시되고 있는지를 결정하기 위해 이미지로부터 중요한 정보를 추출하고 이해하는 능력이 부족하기 때문이다. 모델은 잘못된 응답을 주지 않기 위해 직접적인 답보다는 관련 정보를 제공하는 신중한 전략을 채택하였다.\n' +
      '\n' +
      '**G 그라운드 진실:** (C)\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Error Reason:** GPT-4V 모델은 에지 탈구의 전형적인 특징인 "결정부에 삽입된 추가 반감기"를 언급했다. 다만, 질문 설명과 정답에 기초하여, 이미지는 나사 탈구를 묘사해야 한다. 이는 모델이 이미지의 내용에 대한 논리적 추론에서 벗어났음을 나타내며, 아마도 이미지 특징을 엣지 탈구와 잘못 연관시키기 때문일 수 있다.\n' +
      '\n' +
      '**G 그라운드 진실:** (B)\n' +
      '\n' +
      '표기.\n' +
      '\n' +
      '**Error Reason:**의 질문 설명에 따르면, 문제는 열 분석 방법을 통해 얻은 위상도의 해석에 관한 것이다. 그러나 GPT-4V의 반응은 이미지에서 중요한 정보를 정확하게 식별하고 해석할 수 없음을 보여준다. 모델은 이미지의 특징을 공정 또는 공정 차단 반응을 나타낼 수 있는 것으로 잘못 해석한 반면 정답은 "과학적"이다.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:110]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:111]\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Error Reason:** GPT-4V는 질문에 답함에 있어서 직접 노동 단위 비용을 질적으로 추정했을 뿐, 이를 인건비가 증가했다는 결론을 내리는 근거로 사용하였다. 그러나 실제로는 기업의 노동비 증가는 주로 시간당 임금율의 상승으로 인한 것이며, 기업의 생산효율성은 감소하지 않았다. 효율성 향상은 단위 제품당 인건비를 2위안으로 줄였습니다. 여기에서 모델은 정량적 추론에 관여하지 않았으므로 그것이 이유 있는 에로어를 구성한다.\n' +
      '\n' +
      '***G 그라운드 진실:(C)\\(\\mathcal{L}\\)**G 그라운드 진실:**(C) \\(\\mathcal{L}\\)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:113]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:114]\n' +
      '\n' +
      '**Error C 카테고리: 지식 에러 레슨의 부족:** GPT-4V는 이미지를 올바르게 이해하고 이미지를 기반으로 해답이 (A), (B), (C)의 대략적인 범위 내에 있다고 추론했다. 그러나 영역별 지식이 부족하여 구체적인 답변을 제공할 수 없었다.\n' +
      '\n' +
      '앞선 진찰: (A) #4.1******* (A) #4.1*****G 그라운드 진실: (A) #4.1*****G 그라운드 진실:\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:116]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:117]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:118]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:119]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:120]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:121]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:122]\n' +
      '\n' +
      '**Error C 카테고리: 이론적으로 Error Error Reason:** GPT-4V는 질문의 요구 사항과 회로의 구성을 올바르게 이해했지만 추론 과정에 실수를 했다. 실행 다이오드가 더 높은 전위 \\(U_{B}\\)에 연결된 것으로 잘못 가정하였으며, 다이오드를 통한 전류의 방향이 잠재량의 절대값만이 아니라 전위차에 의해 결정된다고 무시하였다. 이 회로에서 \\(U_{A}\\)와 \\(U_{B}\\) 모두 양성과 다이오드가 모두 전방 편향되었을 때만 수행되기 때문에, 하부 전위 \\(U_{A}\\)에 연결된 다이오드가 수행되어 \\(U_{B}\\)에 연결된 다이오드가 차단된다. 따라서 잠재적 \\(u_{F}\\)는 \\(1\\)V인 \\(U_{A}\\)의 잠재력과 같아야 한다. 따라서 정답은 (A) \\(1\\)V이다.\n' +
      '\n' +
      '진실: (A) 1V*****G 그라운드 진실: (A) 1V****G 그라운드 진실: (A) 1V*****G 그라운드 진실:\n' +
      '\n' +
      '이 솔루션은 현재 \\(I_{1}\\)를 찾기 위해 Kirchhoff의 현행법(KCL)을 사용할 필요성을 올바르게 식별하지만 노드 C에 법률을 적용할 때 추론 오류를 만들었으며, 주어진 전류가 제대로 설명되지 않아(I_{1}\\) 노드의 잘못된 계산으로 이어지며, 정확한 접근법은 10A 및 5A 전류만이 아니라 노드에 진입하고 떠나는 모든 전류를 고려하여 KCL 방정식을 작성하고 해결하는 것을 포함한다.\n' +
      '\n' +
      '**Ground Truth: 9**\n' +
      '\n' +
      '**Eror Category: Reasoning Error Error Reason:**오차는 GPT-4V가 이미지에서 회로의 구성 요소와 구조를 올바르게 이해했지만 B 지점에서 전압을 결정하기 위해 올바른 추론 과정을 적용하지 못했기 때문에 발생하였고, 오엠의 법칙 및 키르치호프의 전압 법칙과 같은 전기 회로의 원리를 사용하여 내성 및 전압의 주어진 값에 기초하여 방정식을 설정했어야 했다. 이러한 방정식을 해결함으로써, B 지점의 전압을 결정할 수 있었다. 대신 GPT-4V는 추가 정보 없이 B 지점에서의 전압을 결정할 수 없다고 주장했는데, 이는 회로도에 필요한 정보가 존재했기 때문에 추론 오류였다.\n' +
      '\n' +
      '**Ground Truth: -14.286**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:126]\n' +
      '\n' +
      '(C) 2,4**** 그룹산 진: (C) 2,4**** 그룹화 진실: (C)\n' +
      '\n' +
      '**Error C 카테고리: 지식 오류 이유 부족:** (A) 컴퓨팅 사실 (n)은 n+1 재귀 수행이 필요하며, 이는 원래 호출과 n 감소 요청 외에도 n이 0에 도달할 때 기본 사례 호출도 있기 때문이다.\n' +
      '\n' +
      '(7) = 5040*****(B)의 사실:*****(B)****** (7)\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:129]\n' +
      '\n' +
      '<지식**>의 부족.\n' +
      '\n' +
      '다중 작물: 다중 작물: 1년 동안 동일한 땅에서 두 개 이상의 작물을 재배하는 연습** 동일 땅에서 두 개 이상의 작물을 재배하는 관행.\n' +
      '\n' +
      '그림에서****에서는 건지에서 두 가지 작물을 동시에 재배하므로 정답은 A.**입니다.\n' +
      '\n' +
      '**G 지상 진실 : (A)\n' +
      '\n' +
      '**Error C 카테고리:개념오차 오류 이유:** 현대 농업은 식량 생산과 품질을 향상시키기 위한 생산 효율성과 기술 적용에 더 많은 관심을 기울이고 관광 농업은 농업 경험과 교육을 제공하는 데 더 중점을 두고 농업에 경제적 가치를 추가한다. 사진에는 분명히 관광객들이 많아서 C 대신 D를 선택하세요.\n' +
      '\n' +
      '**G 그라운드 진실:** (D)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:132]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:133]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:134]\n' +
      '\n' +
      '**Error C 카테고리: 지식 부족, 왜곡 이유 범위:** GPT-4V는 전문 고생물학적 지식과 특정 화석 연구에 대한 이해 부족으로 인해 질문에 답을 거부한다.\n' +
      '\n' +
      '**Ground Truth:**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:136]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:137]\n' +
      '\n' +
      '**GPT-4V:** GPT-4V는 박테리아에서 박테리오파지 감염 과정에 대한 지식을 가지고 있으며, 감염 서열이 박테리아 세포벽에 자신을 부착하고 유전 물질을 주입하고 세포 내에서 박테리오파지 성분을 합성하고 성숙한 박테리오파지를 조립하고 세포를 용해하여 파지를 방출한다는 것을 이해한다. 그러나 각 단계를 묘사하는 이미지를 정확하게 식별하지 못하여 이미지와 해당 이름 사이의 잘못된 일치로 이어진다.\n' +
      '\n' +
      '(A) BDADAEC******G 그라운드 진실: (A) BDAEC****G 그라운드 진실: (A) BDAEC****G 그라운드 진실:\n' +
      '\n' +
      '(B) 2******G 그라운드 진서 : (B) 2****G 그라운드 진: (B)****G 그라운드 진서: (B)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:140]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:141]\n' +
      '\n' +
      '**GPT-4V:**: **B.B.**\n' +
      '\n' +
      '**Error C 카테고리:**: **GPT-4V는 이미지와 텍스트를 성공적으로 이해하고 홍수 상황에서 더 높은 수위가 더 큰 유량에 해당한다는 지식을 올바르게 리콜한다. 다만, 모형은 변수를 고정하지 않고 직접 답을 선택한다. 사실, 모델은 하나의 변수를 고정하고 다른 변수의 값을 비교해야 한다.**.\n' +
      '\n' +
      '**Ground Truth: C**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:143]\n' +
      '\n' +
      '**Error C 카테고리: 인식적 오류, 지식 간섭의 부족:** GPT-4V는 "절대 높이" 개념에 대한 특정 지식이 부족하여 해수면에 대한 높이를 의미한다는 것을 이해하지 못했다. 나아가 GPT-4V는 해수면을 나타내는 이미지에서 점선을 잘못 해석하여 \'\\(\\not\\subseteq\\)\'로 표기한 점 및 \'\\(\\not\\subseteq\\)\'와 \'\\(\\)\\\'의 높이 차이를 잘못 계산한다.\n' +
      '\n' +
      '**Ground Truth: 2500**\n' +
      '\n' +
      '실용적 이해**오차 범주:\n' +
      '\n' +
      '**Error Reason:** 영역은 M 및 N 영역의 강수 특성에 대해 문의했지만 GPT-4V의 반응은 P 영역의 강우 패턴에 해당하여 결과적으로 잘못된 답변을 초래했다.\n' +
      '\n' +
      '**G 지상 진실 : (A)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:146]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:147]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:148]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:149]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:150]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:151]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:152]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:153]\n' +
      '\n' +
      '**Error C 카테고리: 지식 오류 이유의 결여:** 옵션에서의 결론은 이미지에서 표현된 물리적 과정으로부터 추론되고 입증될 수 있지만 모델은 특정 지식을 사용하여 답변하지 않았다.\n' +
      '\n' +
      '**G 그라운드 진실: (D)\n' +
      '\n' +
      '**Error C 카테고리: 퍼셉트 에러 에르러 레슨:** 모델은 이미지를 완전히 이해하지 못했으며, 특히 이미지에서 수치 정보를 인식하지 못했다. 따라서 잘못된 답변을 만들었습니다.\n' +
      '\n' +
      '**Ground Truth: 2.60**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:156]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:157]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:158]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:159]\n' +
      '\n' +
      '***그림 1:** 모형은 문제의 지식과 요구 사항을 올바르게 이해하였으나 추론에서 실수를 하였다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:161]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:162]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:163]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:164]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:166]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:169]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:170]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:176]\n' +
      '\n' +
      '[MISSING_PAGE_POST]\n' +
      '\n' +
      '\\begin{tabular}{|l|l|l|l|l|l|l|} \\hline \\(r\\) (h) & 1.0 & 2.0 & 3.0 & 4.0 & 5.0 & 6.0 \\\\ \\hline \\(C\\) (\\(\\mu\\)g/mL ) & 8.40 & 5.94 & 4.20 & 2.\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:180]\n' +
      '\n' +
      '**Ground Truth: (\\(\\mathbf{\\mathbb{X}}\\))**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:185]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:188]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:191]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:194]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:195]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:196]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:197]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:199]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:200]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:201]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:202]\n' +
      '\n' +
      '**Ground Truth: (B)**\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:204]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:205]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:206]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:207]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:209]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:211]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:213]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:214]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:216]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:218]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:219]\n' +
      '\n' +
      '**G\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:222]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:223]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:225]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:226]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:227]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:228]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:230]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:233]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:235]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:236]\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:237]\n' +
      '\n' +
      '그림 5: 퍼셉터널 에러의 경우.\n' +
      '\n' +
      '부록 A.\n' +
      '\n' +
      '그림 6: 지식 부족의 경우.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>