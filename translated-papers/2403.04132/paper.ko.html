<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 챗봇 아레나: 인간 선호도에 의한 LLM 평가를 위한 개방형 플랫폼\n' +
      '\n' +
      ' 웨이린치앙\n' +
      '\n' +
      '1**리안민정**\n' +
      '\n' +
      '1 *Ying Sheng**\n' +
      '\n' +
      '2 **아나스타시오 N. Angelopoulos**\n' +
      '\n' +
      '1**티넬 리**\n' +
      '\n' +
      '1**다청 리**\n' +
      '\n' +
      '**Banghua Zhu**\n' +
      '\n' +
      '**Hao Zhang**\n' +
      '\n' +
      '**Michael I. Jordan**\n' +
      '\n' +
      '**Joseph E. Gonzalez**\n' +
      '\n' +
      '**Ion Stoica**\n' +
      '\n' +
      '동일한 기여도 \\({}^{1}\\)UC Berkeley \\({}^{2}\\)Stanford \\({}^{3}\\)UCSD. 대응: Wei-Lin Chiang <weichiang@berkeley.edu>.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '대규모 언어 모델(LLM)은 새로운 기능과 응용 프로그램을 잠금 해제했지만, 인간의 선호도와의 정렬을 평가하는 것은 여전히 중요한 문제를 제기한다. 이 문제를 해결하기 위해 우리는 인간의 선호도를 기반으로 LLM을 평가하는 개방형 플랫폼인 챗봇 아레나(Chatbot Arena)를 소개한다. 우리의 방법론은 쌍대 비교 접근법을 사용하고 크라우드소싱을 통해 다양한 사용자 기반에서 입력을 활용한다. 플랫폼은 몇 달 동안 운영되어 240K 표 이상을 모았다. 본 논문은 플랫폼에 대해 설명하고, 지금까지 수집된 데이터를 분석하고, 모델의 효율적이고 정확한 평가 및 순위를 위해 우리가 사용하고 있는 검증된 통계 방법을 설명한다. 우리는 크라우드소싱된 질문이 충분히 다양하고 차별적이며 크라우드소싱된 인간 표가 전문가 평가자의 표와 잘 일치함을 확인한다. 이러한 분석은 집합적으로 챗봇 아레나의 신뢰성을 위한 강력한 기반을 구축한다. 챗봇 아레나는 독특한 가치와 개방성 때문에 대표적인 LLM 개발자와 기업이 널리 인용하는 LLM 리더보드 중 하나로 부상했다. 우리의 데모는 [https://chat.lmsys.org](https://chat.lmsys.org)에서 공개적으로 사용할 수 있다.\n' +
      '\n' +
      '머신러닝, ICML, ICML\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '최근 대형 언어 모델(LLM)의 발전은 전통적인 자연 언어 처리 경계를 넘어 광범위한 일반 작업(OpenAI, 2023; Gemini et al., 2023; Touvron et al., 2023)을 다루는 그들의 능력을 상당히 확장시켰다. 이러한 발전은 LLM의 잠재력을 강조하지만 성능 평가와 관련하여 우려를 불러일으켰다. 현재의 벤치마크는 종종 이러한 모델의 미묘하고 다양한 측면을 포착하지 못하며, 특히 실제 개방형 작업에서 인간의 선호도와의 정렬을 평가하는 데 실패한다.\n' +
      '\n' +
      'LLM의 성능을 평가하기 위해 연구 커뮤니티에서는 다양한 벤치마크를 도입했다. 이러한 벤치마크는 질문의 출처(정적 또는 라이브)와 평가 척도(지상 진실 또는 인간 선호도)의 두 가지 요소를 기반으로 분류할 수 있다. 이러한 요인에 따라 벤치마크는 그림 1과 같이 네 가지 범주로 분류될 수 있다. 벤치마크 범위가 유익하지만 LLM을 평가하는 가장 널리 사용되는 현재 방법은 부분적으로 이러한 평가가 저렴하고 재현 가능하기 때문에 정적, 지상 진실 기반 평가로 남아 있다.\n' +
      '\n' +
      '그러나 이러한 정적, 지상 진실 기반 벤치마크는 몇 가지 한계를 나타낸다. 첫째로, 이러한 벤치마크들 내의 질문들은 개방형(open-ended)이 아니며, 실세계 설정들에서 발견되는 유연하고 상호작용적인 사용을 캡처하는 능력을 방해한다(Zheng et al., 2023). 둘째, 이러한 벤치마크에서 테스트 세트는 정적이어서 시간이 지남에 따라 오염될 수 있으며, 이는 평가 결과의 신뢰성을 저해한다(Yang et al., 2023). 더욱이, 많은 복잡한 작업들에 있어서, 확실한 지상 진리를 확립하는 것은 어려울 뿐만 아니라 때때로 성취할 수 없다. 결과적으로 현재 벤치마크는 특히 사용자 선호도를 평가할 때 최첨단 LLM의 요구를 적절하게 해결하지 못한다. 따라서, 현실 세계의 사용을 보다 정확하게 반영할 수 있는 인간 선호에 기초한 개방형 라이브 평가 플랫폼에 대한 긴급한 필요성이 있다.\n' +
      '\n' +
      '이러한 벤치마크 플랫폼을 만드는 것은 중요한 과제를 수반한다. 실세계 시나리오를 정확하게 나타내기 위해서는 라이브, 신선하고 다양한 사용자 질문의 수집이 필요하다.\n' +
      '\n' +
      '그림 1: LLM 벤치마크의 분류: 질문이 정적 데이터 세트인지 또는 살아있는 새로운 소스인지, 평가 메트릭이 지상 진실 또는 (근사화된) 인간 선호도에 의존하는지의 두 가지 차원을 따라 분류한다. MMLU(Hendrycks et al., 2020), HellaSwag(Zellers et al., 2019), GSM-8K(Cobbe et al., 2021), MT-Bench(Zheng et al., 2023), AlpacaEval(Li et al., 2023) 등이 정적 벤치마크의 일반적인 예이다. 챗봇 아레나는 본 논문에서 소개한 플랫폼이다.\n' +
      '\n' +
      '또한, 많은 수의 모델을 평가하기 위해서는 확장성, 증분성 및 효율적인 순위 시스템을 개발하는 것이 필수적이다. 더욱이, 인간 선호의 시끄러운 특성을 고려할 때 인간 평가의 품질을 보장하는 것이 중요하다.\n' +
      '\n' +
      '이를 위해 크라우드소싱 환경에서 익명의 무작위 전투를 특징으로 하는 LLM의 벤치마킹 플랫폼인 챗봇 아레나를 소개한다. 챗봇 아레나는 모든 사용자에게 무료로 제공되는 웹사이트이다.1 이 웹사이트에서 사용자는 두 명의 익명 LLM으로부터 질문을 하고 답변을 얻을 수 있다. 이후, 사용자는 선호하는 응답을 전달하는 모델에 대해 투표를 하고, 모델들의 신원은 투표 후에만 드러난다. 이 크라우드소싱 방법은 실제 LLM 응용 프로그램을 정확하게 반영하여 다양한 새로운 사용자 프롬프트를 효과적으로 수집한다. 이 데이터로 무장한 우리는 브래들리와 테리의 통계 모델(1952)에서 Vovk와 Wang의 E-값(2021)에 이르기까지 강력한 통계 기법 세트를 사용하여 모델에 대한 순위를 가능한 한 신뢰성 있고 표본 효율적으로 추정한다. 이러한 도구를 사용하여 통계적 타당성을 유지하면서 순위의 수렴을 가속화하는 방식으로 모델 쌍을 선택하기 위해 효율적인 샘플링 알고리즘을 특별히 설계했다.\n' +
      '\n' +
      '각주 1: [https://chat.lmsys.org](https://chat.lmsys.org)\n' +
      '\n' +
      '우리는 플랫폼의 신뢰성을 보장하기 위해 수집된 데이터에 대한 철저한 분석을 수행합니다. 우리는 사용자가 생성한 질문이 광범위한 LLM 사용 사례를 포괄하기에 충분히 다양하고 모델 간의 구별에 충분히 도전적이라는 것을 보여준다. 또한, 우리는 크라우드소싱 투표가 전문가 평가와 매우 일치함을 확인한다.\n' +
      '\n' +
      '우리는 2023년 4월부터 시스템을 운영해 왔으며 2024년 1월 현재 100개 이상의 언어로 약 90K 사용자로부터 240K 이상의 표를 얻었으며, 사용자 참여를 장려하기 위해 50개 이상의 최신 모델을 무료로 사용할 수 있도록 했다. 또한 오픈AI, 구글, 인류학, 미스트랄, 포옹 페이스, 다양한 대학교와 같은 선도적인 모델 개발자와 협력하여 최신 모델을 플랫폼에 통합합니다. 우리는 정기적으로 리더보드를 업데이트하고 분석 블로그를 게시하며 데이터 세트를 공개하고 트윗을 통해 정보를 공유함으로써 커뮤니티를 계속 참여시킵니다. 독특하고 중요한 가치 때문에 당사의 리더보드는 LLM 분야에서 가장 많이 참조되는 분야 중 하나로 부상했으며 업계의 벤치마크가 되었습니다. 우리는 이 플랫폼이 오픈 소스 및 오픈 액세스가 가능하도록 데이터와 코드를 사용할 수 있도록 약속합니다.\n' +
      '\n' +
      '우리는 다음과 같은 공헌을 한다.\n' +
      '\n' +
      '* 우리는 1M 이상의 사용자가 방문하는 최초의 대규모 크라우드소싱 라이브 LLM 평가 플랫폼을 구축합니다.2 각주 2: 2024년 3월 현재 Google Analytics에 의해 그 수를 추정했습니다. 우리 웹사이트도 "직접 채팅" 모드를 제공하므로 사용자 방문이 투표로 전환되지 않을 수 있음을 유의하십시오.\n' +
      '* 수집된 데이터에 대한 신속한 다양성, 품질, 투표 품질 및 인간 피드백에 대한 통찰력을 포함하여 심층 분석을 수행한다.\n' +
      '* 챗봇 아레나에서 수집한 100K 이상의 쌍별 투표로 인간 선호 데이터셋을 공개한다.\n' +
      '* 우리는 샘플 효율이 때때로 크게 향상되도록 어떤 모델 쌍을 보여줄지를 능동적으로 선택하는 효율적인 샘플링 알고리즘을 설계한다.\n' +
      '\n' +
      '##2 관련 업무\n' +
      '\n' +
      '**LLM 벤치마크.** 우리는 그림 1에 제시된 분류에 따라 일반적인 LLM 벤치마크를 간략하게 검토한다. 가장 널리 사용되는 벤치마크는 정적, 지상 진실 기반 벤치마크이며 일반적으로 사전 정의된 답변 및 테스트 사례가 있는 객관식 질문 또는 질문 응답 작업의 형태이다. 이러한 벤치마크는 언어 이해, 수학, 코딩 및 논리적 추론을 포함한 다양한 주제를 포함한다. 이러한 카테고리에서 두드러진 예는 MMLU(Hendrycks et al., 2020), HellaSwag(Zellers et al., 2019), GSM-8K(Cobbe et al., 2021), BigBench(Srivastava et al., 2023), AGIEval(Zhong et al., 2023), 및 HumanEval(Chen et al., 2021)이다. ToxicChat(Lin et al., 2023), HELM(Liang et al., 2022)과 같은 포괄적 스위트와 같이 안전에 중점을 둔 벤치마크도 존재한다. 벤치마크는 폐쇄형 질문 외에도 인간 판단에 의해 평가되는 개방형 질문을 포함할 수 있으며, 이는 아마존 메커니컬 투르크(Karpinska et al., 2021; Geng et al., 2023; Wang et al., 2023)와 같은 전문가 또는 크라우드 작업자에 의해 평가될 수 있다. 최근 추세는 인간의 판단을 근사화하기 위해 GPT-4를 활용하는 것(Chiang and Lee, 2023)을 포함하며, 주목할 만한 사례는 MT-Bench(Zheng et al., 2023b) 및 AlpacaEval(Li et al., 2023)이다. 정적 벤치마크 외에도 새로운 질문을 포함하는 라이브 벤치마크도 사용할 수 있다. 이러한 질문은 Codeforces(Li et al., 2022; Huang et al., 2023)와 같은 연례 시험 또는 주간 온라인 콘테스트로부터 얻어질 수 있다. 또한 인간의 상호 작용에서 얻을 수 있습니다. 일부 연구는 인간 선호도로부터 강화 학습을 위해 살아있는 인간 상호작용을 사용하는 것을 탐구했다(Bai et al., 2022; Ouyang et al., 2022; Touvron et al., 2023). 그러나 이러한 연구는 일반적으로 특정 조직에 국한된다. 본 논문에서는 라이브 휴먼 인터랙션을 활용한 오픈, 대규모, 크라우드소싱 벤치마크 플랫폼인 챗봇 아레나(Chatbot Arena)를 소개한다.\n' +
      '\n' +
      '**Static Benchmarks.** Static 벤치마크들은 오염, 포화, 과적합, 및 인간 정렬의 결여를 포함하는 특정 문제들을 갖는다(Yang et al., 2023; Oren et al., 2023). DynaBench(Kiela et al., 2021)는 이러한 과제를 식별하고 고전적인 NLP 벤치마크에 대한 인간-인-루프 접근법을 통합하는 라이브 벤치마크의 사용을 권장한다. 우리 시스템은 비슷한 정신을 채택한다. 그러나 LLM과 채팅하는 데 중점을 두고 있으며 훨씬 더 큰 사용자 규모로 구현합니다.\n' +
      '\n' +
      '** 랭킹 시스템** 랭킹 시스템은 통계학에서 잘 연구된 주제이다. 관련 토픽으로는 확률 모델(Hunter, 2004; Rao and Kupper, 1967), 순위 도출(Szorenyi et al., 2015; Busa-Fekete et al., 2014a;b), 온라인 실험 설계(Chernoff, 1992; Karimi et al., 2021) 등이 있다. 엘로 등급 시스템은 또한 LLMs(Bai et al., 2022; Boubdir et al., 2023)에 사용되었다. 이 문헌에 기여하여, 우리는 LLM의 대규모 실제 설정에 특히 적용되는 순위 수렴을 가속화하고 이상을 감지하는 기술을 소개한다.\n' +
      '\n' +
      '**인간 선호도 데이터 세트.** 인간 선호도의 중요성 때문에 인간 선호도를 통합하는 여러 데이터 세트 및 분석이 존재한다. 여기에는 OpenAssistant(Kopf et al., 2023), HH-RLHF(Bai et al., 2022), LMSYS-Chat-1M(Zheng et al., 2023a), UltraFeedback(Cui et al., 2023) 및 Nectar(Zhu et al., 2023)와 같은 인간 선호도의 합성 근사치가 포함된다. 우리의 이전 데이터 릴리스인 LMSYS-Chat-1M(Zheng et al., 2023a)은 크라우드소싱을 통해 유사하게 수집된다. 그러나 LMSYS-Chat-1M은 대화만으로 구성되며 인간 선호도 데이터가 부족하여 순위 연구에서 직접 사용하기에 적합하지 않다. 본 논문은 순위화 목적의 선호도 데이터 분석에 초점을 맞추고 있다.\n' +
      '\n' +
      '##3 인체 선호 데이터 수집\n' +
      '\n' +
      '이 섹션에서는 인간의 선호도를 수집하고 요약 통계를 제시하기 위한 인터페이스 설계에 대해 논의한다.\n' +
      '\n' +
      '### Interface\n' +
      '\n' +
      '챗봇 아레나 군중은 모델 평가를 위해 사용자의 피드백을 제공한다. 우리의 목표는 사용자가 데이터에 기여할 수 있도록 마찰을 줄이기 위해 사용하기 쉬운 인터페이스를 설계하는 것입니다. 많은 사용자의 피드백을 수집하기 때문에 다양한 사람들에게 일관된 등급 루브릭을 설정하는 것은 어렵다. 따라서 우리는 사용자가 절대 점수를 제공해야 하는 대신 두 가지 모델 응답을 비교하고 더 나은 응답을 투표하기만 하면 되는 쌍별 비교 메커니즘을 채택한다.\n' +
      '\n' +
      '각 전투에서 두 개의 익명 모델이 샘플링된다. 데이터 다양성을 장려하기 위해 웹 사이트에서 입력 프롬프트를 미리 설정하지 않습니다. 사용자는 두 모델에 대한 프롬프트를 자유롭게 입력할 수 있습니다. 우리는 이것이 특히 무료 서비스를 제공한다는 점을 감안할 때 사용자 참여에 대한 인센티브를 창출한다고 믿습니다. 또한 실제 사용을 나타내는 다양한 입력 세트를 수집하는 데 도움이 됩니다. 모델들이 그들의 답변을 제공한 후, 사용자는 그것들을 나란히 비교하고 선호하는 답변에 투표한다. 사용자가 첫 번째 턴에서 선택할 수 없는 경우, 사용자는 승자를 식별할 때까지 채팅을 계속할 수 있다. 확실하지 않은 사람들을 위해, 우리는 또한 "타이" 또는 "둘 다 나쁘다"라는 두 개의 버튼을 제시한다. 도 8은 우리 인터페이스의 스크린샷을 보여준다. 서비스를 사용하기 전에 사용자는 사용 조건을 수락해야 하며, 이를 통해 데이터를 공개적으로 공개할 수 있습니다.\n' +
      '\n' +
      '### Data Statistics\n' +
      '\n' +
      '2023년 4월부터 데이터를 수집하기 시작했으며 2024년 1월 현재 90K 이상의 사용자로부터 약 240K표를 받았습니다. 우리의 데이터는 GPT-4, 클로드 및 제미니와 같은 독점 모델과 LLaMA 및 미스트랄과 같은 개방형 모델을 모두 포함하여 50개 이상의 모델을 포함한다. 이 대화는 100개 이상의 언어를 다루고 있으며, 77%는 영어로, 5%는 중국어로, 나머지 언어인 러시아어, 독일어, 스페인어, 프랑스어, 일본어는 각각 전체의 2% 미만을 차지한다. 각 데이터 포인트는 사용자와 두 LLM 사이의 멀티턴 대화, 및 사용자가 어떤 모델을 선호하는지 나타내는 투표를 포함한다. 우리는 기존의 다른 인간 선호 데이터 세트와 함께 표 1의 통계를 요약한다.\n' +
      '\n' +
      '부록의 그림 10은 모형별 득표수를 나타낸 것이다. 모델별로 평균 8K 표가 모인다. 그림 2에서 우리는 대표적인 모델 집합을 선택하여 그들의 승률과 전투 횟수를 제시한다. 더 높은 불확실성으로 인해 유사한 성능을 갖는 모델 쌍에 투표를 집중하기 위해 불균일한 샘플링을 사용한다는 점에 유의해야 한다. 이는 안정적인 결과에 도달하기 위해 필요한 투표 수를 줄이는 데 도움이 됩니다. 이후 적응형 샘플링 방법을 개발하고 무작위 샘플링에 대한 효과를 입증한다. 자세한 내용은 섹션 5를 참조하십시오.\n' +
      '\n' +
      '익명을 보장하기 위해 키워드를 사용하여 모델 이름(예: GPT, Claude) 또는 회사(예: OpenAI, Anthropic)와 같은 모델 ID를 포함하는 대화를 필터링합니다. 오용을 방지하기 위해, 우리는 안전하지 않은 콘텐츠를 포함하는 대화를 플래그하기 위해 오픈AI 조정 API를 채택한다. 플래그가 표시된 사용자 요청은 전체 요청의 3%를 차지한다. 부록의 그림 9는 시간이 지남에 따라 유효한 사용자 투표의 수를 보여주는데, 여기서 우리는 최근 몇 달 동안 하루에 1-2K 표를 얻고 새로운 모델이나 리더보드 업데이트를 소개하면서 급증한다.\n' +
      '\n' +
      '##4 쌍별 비교에서 순위별\n' +
      '\n' +
      '우리의 데이터는 쌍별 비교로 구성되어 있지만, 어떻게 이러한 비교를 사용하여 모든 \\(M\\) 모델에 대한 순위를 복구할 수 있습니까? 이것은 순위 매기기 학습에 관한 문헌에서 잘 연구된 주제이며(Liu et al., 2009), 여기에 우리의 관점을 제시한다. 우리는 \\(\\mathcal{A}=\\{(m,m^{\\prime}):m<m^{\\prime}\\text{ and }m,m^{\\prime}\\in[M]\\}\\)을 비교 데이터 셋으로 나타내도록 한다.\n' +
      '\n' +
      '우리는 시간\\(t\\in\\mathbb{N}\\)에서 한 쌍의 모델\\(A_{t}\\in\\mathcal{A}\\)을 인간에게 제공하고, 차례로 인간의 반응\\(H_{t}\\in[0,1]\\)을 관찰한다. 예를 들어, 우리는 모델 1보다 인간이 모델 2를 더 선호한다는 것을 나타내는 \\(A_{t}=(1,2)\\)과 \\(H_{t}=1\\)을 가질 수 있다. 후속 텍스트에서 우리는 주로 이진 사례에 초점을 맞출 것이지만, 우리의 접근법은 인간이 다른 선호 정도를 표현하거나 모델이 묶여 있다고 말할 가능성을 포함하여 모든 형태의 피드백으로 일반화할 것이다.\n' +
      '\n' +
      '한 가지 중요한 목표는 모든 \\(a\\in\\mathcal{A}\\)에 대해 _win 행렬_: \\(\\theta^{*}(a)=\\mathbb{E}[H_{t}\\mid A_{t}=a]\\)을 추정하는 것이다. 이항행렬에서 승행렬의 \\(a\\) 엔트리는 쌍으로 나타낼 때 인간이 모델 \\(a_{2}\\)에서 \\(a_{1}\\)을 선호할 확률에 해당한다. 승리 행렬을 찾는 것은 비교적 간단한 평균 추정 문제이다; 우리는 섹션 5에서 세부 사항을 제공할 것이다.\n' +
      '\n' +
      '형식적으로, _score_\\(s(\\mathbb{P})\\in\\mathbb{R}^{M}\\)을 고려하며, 여기서 \\(\\mathbb{P}\\)은 \\(A\\)과 \\(H\\)에 걸친 결합 분포이다. (기본적으로, 우리는 \\(\\mathcal{A}\\)에 걸친 균일한 분포를 목표로 할 것이다.) 각 모델은 참점수\\(s(\\mathbb{P})_{m}\\)를 가지며, 더 나은 모델은 더 높은 점수를 가질 것이다. 특히, 우리는 모델 \\(m\\)의 순위를 갖는다:\n' +
      '\n' +
      '\\[\\mathrm{rank}(\\mathbb{P})_{m}=1+\\sum_{m^{\\prime}\\in[M]}\\mathds{1}\\left\\{s(\\mathbb{P})_{m^{\\prime}}>s(\\mathbb{P})_{m}\\right\\}. \\tag{1}\\\n' +
      '\n' +
      '가장 좋은 모델은 순위\\(1\\)입니다. 만약 가장 잘 어울리는 다른 모델이 있다면, 그들은 둘 다 순위 \\(1\\)을 받게 될 것이다.\n' +
      '\n' +
      '**점수 선택.** 이 설정에서의 표준 점수 함수는 브래들리-테리(BT) 계수들의 벡터이다(브래들리 및 테리, 1952). Bradley-Terry 모형에서는 \\(H_{t}\\in\\{0,1\\}\\)과 확률모형 \\(m\\)비트 모형 \\(m^{\\prime}\\)을 로지스틱 관계를 통해 모형화하였다.\n' +
      '\n' +
      '\\[\\mathbb{P}(H_{t}=1)=\\frac{1}{1+e^{\\xi_{m^{\\prime}}-\\xi_{m}}}, \\tag{2}\\]\n' +
      '\n' +
      '여기서 \\(\\xi\\)는 소위 BT 계수의 \\(M\\)-길이 벡터이다. 일반성의 손실 없이, 우리는 \\(\\xi_{1}=0\\)을 취한다. (모델은 \\(\\xi\\)의 덧셈에 불변하므로) 우리의 목표는 모집단 브래들리-테리 계수, 즉 이진 교차 엔트로피를 최소화하는 계수를 추정하는 것이다:\n' +
      '\n' +
      '\\\\[s(\\mathbb{P})=\\operatorname*{argmin}_{\\xi}\\mathbb{E}_{(A,H)\\sim\\mathbb{P}} \\left[\\ell\\left(H,\\frac{1}{1+e^{\\xi_{A_{2}}-\\xi_{A_{1}}}}\\right], \\tag{3}\\w}\n' +
      '\n' +
      '여기서 \\(\\ell\\)은 이진 교차 엔트로피 손실, \\(\\ell(h,p)=-(h\\log(p)+(1-h)\\log(1-p))이다.\n' +
      '\n' +
      'BT 모델은 모델 승률에 대한 모수적 형태를 기술적으로 가정하지만, Huber et al.(1967)의 중요한 결과; White (1982)는 소위 "샌드위치" 공분산 행렬이 사용되는 한, 이러한 가정이 _do not_ 홀드된 경우에도 최대 우도 추정기가 여전히 점근적으로 정상임을 보여준다; 세부 사항은 섹션 5를 참조하고, 브래들리-테리 모델의 비모수적 확장에 대해서는 부록 B를 참조하다. 마지막으로, 우리는 우리의 온라인 인터페이스의 이전 진화가 BT 계수 대신 Elo 점수(Elo, 1967)와 같은 다른 순위 점수를 보고했다고 언급한다. BT 계수가 통계적 추정의 목적에 더 적합하기 때문에 우리는 이러한 변화를 만들었다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c} \\hline \\hline Dataset & \\# Convs & \\# Models & \\# Users & \\# Langs & Avg. \\# Turns per Sample & Avg. \\# Tokens per Prompt & Avg. \\# Tokens per Response \\\\ \\hline Anthropic HH & 338,704 & - & 143 & 1 & 2.3 & 18.9 & 78.9 \\\\ OpenAssistant & 66,497 & - & 13,500 & 35 & - & 36.9 & 214.2 \\\\ \\hline Chatbot Arena (20240121) & 243,329 & 50 & 90,051 & 149 & 1.3 & 94.9 & 269.0 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: Anthropic HH(Bai et al., 2022), OpenAssistant Conversations(Köpf et al., 2023), 및 Chatbot Arena(2024/1/21 기준)를 포함하는 인간 선호 데이터 세트의 통계. 토큰은 Llam2의 토큰화기에 의해 계산된다. “Conv” = 대화. “Lang” = 언어.\n' +
      '\n' +
      '그림 2: 챗봇 아레나에서 모델의 하위 집합 간의 승률(왼쪽) 및 전투 횟수(오른쪽)입니다.\n' +
      '\n' +
      '## 5 효율적인 근사 순위\n' +
      '\n' +
      '섹션 4에서 우리는 승률 행렬, 점수 및 순위를 계산하는 방법을 설명했다. 이제 우리는 우리의 추정 절차에 대해 설명한다.\n' +
      '\n' +
      '**승 행렬 추정.**승 행렬의 추정은 비교적 간단하다. 정의 \\(X_{t}(a)=\\frac{1}{P_{t}(a)}H_{t}\\mathds{1}\\left\\{A_{t}=a\\right\\\\), 여기서 \\(P_{t}(a)\\)은 시간 \\(t\\)에서 샘플링 쌍 \\(a\\)의 확률이고, \\(X_{t}\\)은 벡터에 따라 결정된다. 그러면 추정기는\n' +
      '\n' +
      '\\[\\hat{\\theta}_{T}=\\frac{1}{T}\\sum_{t=1}^{T}X_{t}. \\tag{4}\\]\n' +
      '\n' +
      '모든 \\(t\\)에 대해 \\(\\mathbb{E}[X_{t}(a)]=\\theta^{*}(a)\\)이므로 \\(\\hat{\\theta}_{T}\\)는 \\(\\theta^{*}\\)의 편향되지 않은 추정량이라는 점에 유의한다. 우리는 더 나아가 공분산 행렬을 다음과 같이 추정할 것이다.\n' +
      '\n' +
      '\\[\\widehat{\\sigma}_{T}=\\frac{1}{T}\\sum_{t=1}^{T}(X_{t}-\\hat{\\theta}_{T})(X_{t}-\\hat{\\theta}_{T}^{\\top}. \\tag{5}\\t}\\t}\n' +
      '\n' +
      '적절한 규칙성 조건에서 우리는\n' +
      '\n' +
      '\\[\\sqrt{T}\\widehat{\\Sigma}^{-1/2}(\\hat{\\theta}-\\theta^{*})\\rightarrow\\mathcal{N}(0,I_{d}), \\tag{6}\\\n' +
      '\n' +
      '그리고 그에 따라 신뢰 구간을 구성합니다. 적절한 규칙성 조건에 대한 이해는 Durrett(2019), 정리 8.2.8을 참조하며, 조건(ii)은 \\(P_{t}(a)>\\epsilon>0\\), 조건(i)은 \\(P_{t}(a)\\)의 극한 분포 \\(P(a)\\)에 대한 거의 확실한 수렴에 의해 함축된다.\n' +
      '\n' +
      '**BT 스코어 추정.** BT 계수를 추정하기 위해, 미러링(3), 우리는 우리의 데이터 포인트들에 대해 (재8) 최대 우도 추정을 수행한다:\n' +
      '\n' +
      '\\[s(\\hat{\\mathbb{P}})=\\operatorname*{argmin}_{\\xi}\\sum_{t=1}^{T}\\frac{1}{P(A_{t}}\\ell\\left(H_{t},\\frac{1}{1+e^{\\xi_{A_{t},2}-\\xi_{A_{t,1}}}}\\right), \\tag{7}\\t}\\t}\\t}\\t}\\t}\\t}\\t}\\t}\\t}\\t}\\t}\\t}\n' +
      '\n' +
      '여기서 \\(A_{t}\\sim P\\). 우리는 \\(A_{t})\\에 대한 역가중치를 수행한다. 이는 우리가 \\(A\\)에 걸쳐 균일한 분포를 갖는 점수를 목표로 할 수 있기 때문이다.\n' +
      '\n' +
      'BT 계수에 대한 신뢰 구간을 계산하기 위해 (1) 피벗 부트스트랩(DiCiccio and Efron, 1996)과 (2) Huber et al.(1967)에 요약된 "샌드위치" 강력한 표준 오차(또한 필요한 기술적 가정의 개요에 대해 Freedman(2006) 참조)의 두 가지 전략을 사용한다. 궁극적으로 부록 A에 설명된 시뮬레이션 연구 결과를 기반으로 큰 샘플에 더 작은 크기로 인해 샌드위치 간격을 배치하기로 선택한다.\n' +
      '\n' +
      '**근사 순위.** 마지막으로 점수 추정의 불확실성을 설명하는 각 모델에 대한 근사 순위를 보고한다. 주어진 \\(M\\)차원 신뢰집합 \\(\\mathcal{C}\\) 만족\n' +
      '\n' +
      '\\[\\mathbb{P}(s(\\mathbb{P})\\in\\mathcal{C})\\geq 1-\\alpha, \\tag{8}\\)\n' +
      '\n' +
      '우리는 근사 순위 \\(R_{m}=1+\\sum_{m^{\\prime}\\in[M]}\\mathds{1}\\left\\{\\inf\\mathcal{C}_{m^{\\prime} >\\sup\\mathcal{C}_{m}\\right\\}을 추출한다. \\(\\mathcal{C}\\)의 균일타당도는 \\(\\mathbb{P}(\\exists m:R_{m}>\\operatorname{rank}(\\mathbb{P})_{m})\\leq\\alpha\\)-- 즉, 높은 확률로 모델의 성능이 과소 평가되지 않음을 직접적으로 의미한다. 다른 한편으로는 어떤 모델의 성능도 과장되지 않는다는 보증은 \\(\\inf\\)과 \\(\\sup\\)을 상호 변경함으로써 가능하다. 균일한 신뢰 집합을 얻기 위해 분산의 샌드위치 추정치를 사용하여 중심 극한 정리가 내포하는 카이 제곱 구간을 구성한다. 즉, 구간 \\(\\xi:T\\left\\|\\hat{V}^{-1/2}(\\hat{\\xi}-\\xi)\\right\\|\\leq\\chi_{1-\\alpha,M-1}^{2}\\)을 구성하고, 여기서 \\(\\hat{\\xi}\\)은 BT 계수의 MLE이고 \\(\\hat{V}{\\xi}\\)은 로지스틱 회귀의 샌드위치 분산이다.\n' +
      '\n' +
      '**활성 샘플링 규칙.** 우리의 샘플링 규칙은 해당 쌍을 샘플링하여 신뢰 구간 크기의 감소에 비례하여 모델 쌍 \\(a\\in\\mathcal{A}\\)을 선택하는 것이었다.\n' +
      '\n' +
      '\\propto\\sqrt{\\frac{\\hat{\\Sigma}_{t,a,a}}{|\\{t:A_{t}=a\\}|}-\\sqrt{\\frac{\\hat{\\Sigma}_{t,a,a}}{|\\{t:A_{t}=a\\}|+1}}. \\tag{9}\\\n' +
      '\n' +
      '비정상적인 사용자 탐지\n' +
      '\n' +
      '다른 측면에서, 우리는 데이터 세트에서 비정상적인 IP 주소를 식별하는 첫 번째 단계를 취한다. 우리는 \\(U\\) 고유 IP 집합에서 \\(\\text{IP}=\\{1,\\dots,U\\}\\)을 모든 IP 주소의 집합으로 한다. 이 데이터베이스 밖에 있는 "테스트" 사용자를 고려해보자. 이 사용자는 행동(A_{1}^{\\prime},\\dots,H_{n}^{\\prime}\\)을 제시하면 평점(H_{1}^{\\prime},\\dots,A_{n}^{\\prime}\\)을 부여한다. 우리의 절차의 아이디어는 새로운 사용자에 대한 등급의 분포를 주어진 동작에 대한 등급의 역사적 분포와 비교하는 것이다. 우리는 \\(\\mathcal{H}_{a}=\\{H_{t}:A_{t}=a\\}\\)을 두고, 사용자가 투표를 제출할 때마다 다음과 같은 수를 계산한다:\n' +
      '\n' +
      '[p_{i}=\\frac{1}{|\\mathcal{H}_{A_{i}^{\\prime}}|+1}\\left(1+\\sum_{h\\in\\mathcal{H}_{A_{i}^{\\prime}}\\mathds{1}\\left\\h\\geq H_{i}^{\\prime}\\right}}\\tag{10}\\t}\n' +
      '\n' +
      '(\\mathcal{H}_{A}_{i}^{\\prime}\\)이 \\(H_{i}^{\\prime}\\)과 교환가능하다는 귀무가설 하에서, \\(p_{i}\\)은 유효한 p-값이다(증명을 위해 부록 C 참조). 또한 이러한 p-값의 의존성은 점근적으로 무시할 수 있다.\n' +
      '\n' +
      '이 p-값을 손에 넣으면 본페로니 보정 변형과 함께 피셔의 조합 검정(피셔, 1928)을 사용하여 이 귀무 가설에 대해 순차적으로 검정할 수 있다. 특히, 각 사용자의 \\(j\\)번째 투표 후, \\(M_{j}=-2\\sum\\limits_{i=1}^{j}\\log(p_{i})\\을 계산한다. 1에서 100 사이의 5개의 임의로 선택된 \\(j\\) 값에서, 우리는 \\(M_{j}\\geq\\chi_{2j,1-\\alpha/5}^{2}\\)일 때 사용자를 변칙으로 식별한다. (이 p-값을 해킹하기 위해 전략화하는 변칙적인 사용자를 피하기 위해 시간을 무작위로 선택한다.) 이 절차의 휴리스틱 적용에도 불구하고 표 5에 보고된 소규모 테스트에서 잘 작동하는 것으로 판단된다.\n' +
      '\n' +
      '## 6 데이터 분석\n' +
      '\n' +
      '아레나의 크라우드소싱 데이터가 실제 사용 사례를 반영하는지 여부를 조사하기 위해 사용자 프롬프트에 대한 토픽 모델링을 수행한다. 이러한 프롬프트가 모델을 구별하는 데 얼마나 효과적인지 보여줍니다. 마지막으로 전문가와 데이터를 다시 레이블링하여 투표 품질을 검증한다.\n' +
      '\n' +
      '### 사용자 프롬프트에 대한 토픽 모델링\n' +
      '\n' +
      '신속한 다양성을 연구하기 위해 BERTopic3(Grootendorst, 2022)을 사용하여 토픽 모델링 파이프라인을 구축한다. 우리는 OpenAI의 텍스트 임베딩 모델(텍스트 임베딩-3-small)을 사용하여 사용자 프롬프트를 표현 벡터로 변환하는 것부터 시작한다. 데이터 클러스터링을 위한 차원의 저주를 완화하기 위해 UMAP(Uniform Manifold Approximation and Projection)(McInnes et al., 2020)을 사용하여 임베딩 차원을 1,536에서 5로 줄이고 계층적 밀도 기반 클러스터링 알고리즘인 HDBSCAN을 사용하여 최소 클러스터 크기 32의 토픽 클러스터를 식별하고 토픽 레이블을 얻기 위해 각 토픽 클러스터에서 10개의 프롬프트를 샘플링하고 토픽 요약에 GPT-4-Turbo로 공급한다.\n' +
      '\n' +
      '각주 3: [https://github.com/MaartenGr/BERTopic](https://github.com/MaartenGr/BERTopic)\n' +
      '\n' +
      '파이프라인은 시 쓰기, 코딩, 수학 및 의학 질의를 포함한 광범위한 주제를 포함하는 600개의 클러스터를 식별한다. 그림 3에서 상위 16개의 토픽 클러스터를 제시하였는데, 가장 큰 클러스터는 전체 집합의 1%만을 차지하고 나머지는 빠르게 <0.5%로 떨어지며, 클러스터 간의 유사성이 작아 롱테일(long-tail)과 다양한 분포를 보인다. 공간 한계로 인해 그림 11과 12의 상위 64개 클러스터의 유사성 행렬과 클러스터 계층을 부록에 제시한다.\n' +
      '\n' +
      '아레나가 모델을 구별할 수 있을까?\n' +
      '\n' +
      '다음으로 이러한 주제 군집이 모델 강점을 구별하는 데 얼마나 효과적인지 연구한다. LLM의 빠른 능력 증가로 인해 도전적인 프롬프트를 구성하는 것이 점점 더 어려워졌습니다. 예를 들어, Llama-2-70b-chat과 같은 개방형 모델은 GPT-4만큼 좋은 영화 또는 여행 추천에 대한 문의에 응답할 수 있지만 추론 또는 코딩과 같은 다른 도메인에서는 그렇지 않다. 이를 위해 7개의 토픽 클러스터에서 30개의 프롬프트를 샘플링하여 Llama-2-70b-chat과 GPT-4의 성능을 비교하였으며, 변수를 통제하기 위해 사용자 투표를 추출하고 LLM-as-judge(Zheng et al., 2023b)를 고려하여 모델 응답을 평가하였다. 결과는 표 2에 나와 있으며, 여기서 GPT-4는 코딩 및 추론 기술이 필요한 군집에서 상당히 높은 윈레이트(최대 97%)를 가지고 있다. 반면, 문제 해결 과제가 적은 클러스터의 경우 GPT-4 승률이 60% 이하로 하락한다. 본 논문에서는 부록 D.1의 사례를 통해 모델들이 다양한 영역에서 다양한 강점을 보일 수 있음을 보여주며, 챗봇 아레나에서 토픽 클러스터 중 일부가 모델 차별화에 효과적임을 보여준다.\n' +
      '\n' +
      '**챌린지 벤치마크를 구축.** 프롬프트 품질을 추가로 입증하기 위해 크라우드소싱 사용자 프롬프트로 도전적인 벤치마크를 구성하는 것이 가능함을 보여준다. 토픽 커버리지와 품질을 모두 보장하기 위해 먼저 토픽 모델링 파이프라인을 실행하고 Zheng et al.(2023a)에서 유사한 절차를 따라 각 토픽 클러스터에서 샘플링된 도전 질문을 선택한다. 예시 프롬프트 및 평가 절차는 각각 부록 D.2 및 부록 D.3에서 찾을 수 있다. 우리는 선택된 프롬프트가 모델을 구별하는 데 매우 효과적임을 관찰한다. 도 4에서, 우리는 널리 사용되는 LLM 벤치마크인 MTBench(Zheng et al., 2023b)와 Arena 벤치를 비교한다. 우리는 아레나 벤치가 독점 모델과 가장 강력한 개방형 모델 간의 상당한 성능 격차를 효과적으로 드러낸다는 것을 알 수 있다.\n' +
      '\n' +
      '투표의 질 검증\n' +
      '\n' +
      '군중투표의 질을 평가하기 위해 GPT-4-Turbo와 Llama-2-13B, GPT-4-Turbo와 GPT-3.5-Turbo-0613 사이의 160개의 전투를 무작위로 선택하고 전문가4에게 비교당 선호도에 라벨을 붙이도록 요청했다. 전문가들에게 프롬프트와 답변을 맹목적으로 제공하고, 검색 엔진과 같은 외부 자원으로 모델의 답변을 주의 깊게 사실 확인하도록 요청했다. 각각 수동으로 레이블을 지정함\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline Topic Cluster & Win-rate & Size \\\\ \\hline Python Game Programming Challenge & 96.7\\% & 0.2\\% \\\\ C/C++ Process Multi-Threading & 86.7\\% & 0.3\\% \\\\ SQL Query Database Assistance & 73.3\\% & 0.2\\% \\\\ Poetry Writing Prompts & 66.7\\% & 1.1\\% \\\\ Python Coding Basics & 65.0\\% & 0.2\\% \\\\ Linguistic Analysis \\& Wordplay & 58.3\\% & 0.7\\% \\\\ Travel Itinerary Planning & 58.3\\% & 0.4\\% \\\\ Movie Recommendations \\& Ratings & 53.3\\% & 0.2\\% \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 다양한 주제 클러스터에서 30개의 샘플 프롬프트에 대한 Llama-2-70b-채팅에 대한 GPT-4-0613의 승률. 우리는 GPT-4-터보를 판사로 사용하여 쌍별 비교에서 모델 반응을 평가한다.\n' +
      '\n' +
      '그림 3: 상위 16개 주제 클러스터의 유사성 행렬. 항목 레이블이 뒤따르는 숫자는 클러스터 크기를 백분율로 나타냅니다. 유사성은 클러스터의 중심 임베딩에 의해 계산되므로 대각선은 항상 하나이다.\n' +
      '\n' +
      '데이터 포인트는 평균 3-5분이 소요되었습니다. 참고로, 우리는 쌍별 비교를 위한 판사로 GPT-4도 사용한다. 군중-이용자, 전문가, GPT-4 판사의 일치율은 <표 3>에 제시되어 있고, 이에 상응하는 승률은 <표 4>에 제시되어 있다.\n' +
      '\n' +
      '요약하자면, 우리는 두 설정 모두에서 아레나 크라우드 사용자와 전문가 사이의 높은 일치율(72%에서 83%)을 관찰한다. 두 전문가 간의 합의율은 비슷한 수준(79.4%와 89.8%)에 달한다는 점에 유의한다. 전문가 간의 10%-20% 불일치는 대부분 일부 사용자 프롬프트에 근거 진실 답변이 없기 때문이다. 평가자의 선호도에 따라 D.4의 사례와 같이 두 답변 모두 다른 답변보다 나은 것으로 주장될 수 있다. 크라우드-vs-전문가 합의율과 전문가-vs-전문가 합의율(5%-10%) 사이의 격차는 대부분 크라우드 사용자가 실수하거나 모델의 응답에서 사실적 오류를 간과하기 때문이다. 전반적으로 표 3에 제시된 합의율은 챗봇 아레나에서 크라우드소싱 투표의 적절한 품질을 검증한다.\n' +
      '\n' +
      '## 7 Experiments\n' +
      '\n' +
      '### Ranking system\n' +
      '\n' +
      '**실제 데이터에 대한 순위를 계산.** 이 섹션에서는 대략적인 순위에 대한 실험 결과를 보고한다. 이 실험을 위해 온라인 플랫폼에서 \\(T=213,576\\)의 과거 표를 다시 재생하고 앞서 설명한 추정 알고리즘을 신뢰 구간으로 사용하여 BT 계수를 계산했으며, 이러한 구간에 대해 그림 5를 참조하십시오. 다중도 보정이 있거나 없는 경우, 근사 순위의 공식 개념은 기술적으로 다중도 보정이 필요하지만 구간을 느슨하게 만든다.\n' +
      '\n' +
      '**구간들의 커버리지를 평가하는.** 자연스런 후속 질문은 구간들이 그들의 일을 올바르게 하고 있는지 여부이다: 그들이 적어도 (그리고 거의 정확히) \\(1-\\알파\\)의 확률로 진정한 BT 계수를 커버하는지 여부이다. 물론\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r r r} \\hline \\hline Baseline & Arena User & Expert 1 & Expert 2 & GPT-4 \\\\ \\hline \\hline Llama-2-13b & 81.2\\% & 89.4\\% & 86.9\\% & 78.8\\% \\\\ GPT-3.5-Turbo & 76.3\\% & 82.5\\% & 89.4\\% & 79.4\\% \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: Llama-2-13b와 GPT-3.5-Turbo-0613과의 쌍대 싸움에 대한 군중-사용자, gpt-4 판사 및 전문가 전반에 걸친 GPT-4-Turbo의 승률.\n' +
      '\n' +
      '그림 4: 아레나 벤치와 MT-벤치 간의 모델의 성능으로 개방 모델과 독점 모델 간의 격차가 증가하는 것을 보여준다. 둘 다 GPT-4를 판사로 사용한다.\n' +
      '\n' +
      '그림 5: 다중도 보정 유무에 따른 BT 계수의 간격. 다중도 보정은, 이 경우, 카이-제곱 CLT 인터벌은, _all_ 스코어들이 그들의 인터벌들에 동시에 포함되도록 보장하기 때문에, 랭킹의 계산 목적을 위해 기술적으로 요구된다(그리고 랭킹은 모든 스코어들의 함수이다). 그러나 추가 보수주의를 유발하므로 두 간격 모두 보고한다.\n' +
      '\n' +
      '실제 데이터에서는 이를 평가할 수 없으므로 시뮬레이션을 실행합니다. BT 계수의 벡터는 분포\\(\\text{beta}(1/\\gamma,1/\\gamma)\\)에서 각 좌표가 i.i.d로 샘플링되어 그려지며, 그림 6의 \\(\\gamma=2\\)을 취하고 부록 A의 \\(\\gamma\\)을 변경한다. 이러한 계수가 주어지면 데이터 세트가 합성되고 20개의 시도 각각에 대해 적용 범위와 평균 너비가 계산된다. 보정되지 않은 구간에 대한 결과는 그림 6에서 볼 수 있다. 구간의 커버리지는 모델 수에 관계없이 \\(1-\\알파\\)를 중심으로 예상대로 행동한다. 한편, 모형이 많이 포함될수록 구간이 커지게 된다.\n' +
      '\n' +
      '** 활성 샘플링 규칙을 평가한다.** 다음으로, 우리는 윈 매트릭스 추정을 위한 식 (9)와 같은 우리의 활성 샘플링 규칙의 평가에 대해 논의한다. 우리는 213,576 포인트 크기의 홀드아웃 세트에 가장 적합한 BT 계수를 취한 다음 활성 샘플링 알고리즘을 사용하여 해당 분포에서 샘플링하여 이 샘플링 규칙을 평가한다. 그 결과는 그림 7에 표시되어 있다. 그림을 보면 알 수 없지만, 개선은 상당하다: \\(\\theta^{*}\\)을 0.2의 정밀도로 추정하려면 랜덤 니즈 6,800개 샘플, 적응 니즈 4,400개 샘플을 추정하고, 반면에 점수를 0.3의 정밀도로 추정하려면 랜덤 니즈 17,200개 샘플, 적응 니즈 16,400개 샘플을 추정한다. 따라서 무작위 기준선은 동일한 수준의 정밀도를 달성하기 위해 각각 54% 및 5% 더 많은 데이터를 필요로 한다. 그림 7의 도표에서 이러한 결과가 체리 선택되지 않음을 알 수 있으며, 이 방법의 샘플 효율성은 수평축의 모든 값에서 더 우수하다.\n' +
      '\n' +
      '비정상적인 사용자 탐지\n' +
      '\n' +
      '섹션 5.1에서 이상치 탐지 방법을 평가한다. 우리는 입력이 매우 반복적이거나 무의미한 25명의 이상 사용자를 수동으로 식별하여 평가 세트를 구성한다. 우리는 최소 50표 이상의 정상 사용자 25명을 무작위로 샘플링하고 비정상적인 행동이 없도록 입력 프롬프트를 검사한다. 섹션 5.1에서 언급한 바와 같이, 사용자당 5 \\(M_{j}\\)을 계산하고 \\(M_{j}\\geq\\chi^{2}_{2j,1-\\alpha/5}\\)인 경우 사용자를 변칙으로 식별한다. 우리는 표 5에서 두 가지 다른 \\(\\alpha\\)(즉, 유의 수준)의 결과를 제시하며, 검출 방법이 유효(예: 90% true positive 및 60-70% true negative rate)하다는 것을 발견했다. 우리는 잘못된 부정 오류를 검사하고 사용자가 항상 비정상적으로 행동하지 않아 탐지하기가 더 어렵다는 것을 발견한다.\n' +
      '\n' +
      '## 8 Discussion\n' +
      '\n' +
      '**제한.** 사용자 기반이 광범위하지만, 우리는 그것이 주로 LLM 애호가와 최신 LLM을 실험하고 평가하기를 열망하는 연구원으로 구성될 것으로 예상한다. 이러한 성향은 사용자의 편중된 분포를 초래할 수 있다. 또한 이전 섹션에서 논의된 프롬프트에 포함된 광범위한 주제에도 불구하고 데이터는 주로 온라인 채팅 인터페이스에서 나온다. 이 소스는 생산 환경 또는 특수 도메인에서 LLM의 실제 사용을 정확하게 반영하지 못하여 잠재적으로 왜곡된 신속한 배포로 이어질 수 있다. 또한, 우리의 연구는 LLM의 유용성을 평가하는 데 집중하지만 안전 측면을 간과한다. 우리는 평행선의 가능성과 필요성을 인식한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r} \\hline \\hline \\(\\alpha=0.1\\) & Pred. Positive & Pred. Negative \\\\ \\hline Actual Positive & 13/14 & 12/36 \\\\ Actual Negative & 1/14 & 24/36 \\\\ \\hline \\(\\alpha=0.3\\) & Pred. Positive & Pred. Negative \\\\ \\hline Actual Positive & 21/29 & 4/21 \\\\ Actual Negative & 8/29 & 17/21 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 서로 다른 \\(\\alpha\\)의 혼돈행렬. “Pred.”는 예측된 것을 의미한다. 양수는 변칙, 음수는 정상을 의미한다.\n' +
      '\n' +
      '그림 6: 샘플 수와 모델 수\\(M\\)의 함수로서 BT 계수에 대한 간격.\n' +
      '\n' +
      '그림 7: 랜덤 샘플링 및 적응형 샘플링을 위해 샘플 수의 함수로서 윈 매트릭스(상단 그림) 및 BT 계수(하단 그림) 상의 간격 폭. 적응 샘플링의 개선은 점수의 척도에서 더 미묘하지만 두 경우 모두에서 볼 수 있다.\n' +
      '\n' +
      '이러한 모델의 안전성을 평가하는 메커니즘입니다.\n' +
      '\n' +
      '**Future Direction.** 향후 작업에서 포괄적인 주제 리더보드를 개발하고 보다 역동적이고 게이미피케이션한 환경에서 멀티모달 및 에이전트 기반 LLM을 위한 전용 섹션을 구축하여 보다 복잡한 작업을 처리할 계획입니다. 우리는 또한 유해한 사용자를 탐지하는 우리의 접근법이 비음성 슈퍼마티게일 및 E-값(하워드 외, 2020; Wudby-Smith and Ramdas, 2020; Vovk and Wang, 2021; Ramdas 외, 2023) 이론을 사용하여 개선되고 더 형식적으로 엄격해질 수 있다고 믿는다.\n' +
      '\n' +
      '## 9 Conclusion\n' +
      '\n' +
      '본 논문에서는 크라우드소싱을 통해 LLM을 평가하는 개방형 플랫폼인 챗봇 아레나(Chatbot Arena)를 제안한다. 우리는 다양성과 품질을 검증하기 위해 크라우드소싱된 사용자 프롬프트 및 선호도 투표에 대한 심층 분석을 수행한다. 효율적인 모델 샘플링 및 랭킹 알고리즘을 개발한다. 향후 연구를 위해 100K pairwise preference votes를 포함한 데이터셋이 공개될 예정이다.\n' +
      '\n' +
      '## Acknowledgments\n' +
      '\n' +
      '이 프로젝트는 Kaggle, MBZUAI, a16z, Together AI, Anyscale, HuggingFace의 후원으로 지원됩니다. 이 프로젝트는 액센츄어, AMD, 구글, IBM, 인텔, 마이크로소프트, 삼성 SDS, SAP, 우버, VM웨어 등도 부분적으로 지원한다. 저자들은 통찰력 있는 토론에 대한 시위안 장과 원고에 대한 유용한 피드백에 대한 티자나 Zrnic에 감사하고 싶다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Bai et al. (2022) Bai, Y., Jones, A., Ndousse, K., Askell, A., Chen, A., Das-Sarma, N., Drain, D., Fort, S., Ganguli, D., Henighan, T., et al. training helpful and harmless assistant with reinforcement learning from human feedback. _ ArXiv:2204.05862_, 2022.\n' +
      '* Boubdir et al. (2023) Boubdir, M., Kim, E., Ermis, B., Hooker, S., and Fadaee, M. Elo는 2023년 언어 모델 평가에서 강인성과 모범 사례를 발견했다.\n' +
      '* Bradley and Terry (1952) Bradley, R. A. and Terry, M. E. Rank analysis of incomplete block designs: I. the method of paired comparison. _ Biometrika_, 39(3/4):324-345, 1952.\n' +
      '* Busa-Fekete et al. (2014) Busa-Fekete, R., Huellermeier, E., and Szorenyi, B. Preference-based rank elicitation using statistical models: The case of mallows. 싱, E. P. and Jebara, T. (eds.), _Proceedings of the 31st International Conference on Machine Learning_, volume 32 of _Proceedings of Machine Learning Research_, pp. 1071-1079, Bejing, China, 22-24 Jun 2014a. PMLR URL[https://proceedings.mlr.press/v32/busa-fekete14.html](https://proceedings.mlr.press/v32/busa-fekete14.html)\n' +
      '* Busa-Fekete et al. (2014) Busa-Fekete, R., Huellermeier, E., and Szorenyi, B. Preference-based rank elicitation using statistical models: The case of mallows. 싱, E. P. and Jebara, T. (eds.), _Proceedings of the 31st International Conference on Machine Learning_, volume 32 of _Proceedings of Machine Learning Research_, pp. 1071-1079, Bejing, China, 22-24 Jun 2014a. PMLR URL[https://proceedings.mlr.press/v32/busa-fekete14.html](https://proceedings.mlr.press/v32/busa-fekete14.html)\n' +
      '* Busa-Fekete et al. (2014) Busa-Fekete, R., Huellermeier, E., and Szorenyi, B. Preference-based rank elicitation using statistical models: The case of mallows. 싱, E. P. and Jebara, T. (eds.), _Proceedings of the 31st International Conference on Machine Learning Research_, pp. 1071-1079, Bejing, China, 22-24 Jun 2014b. PMLR URL[https://proceedings.mlr.press/v32/busa-fekete14.html](https://proceedings.mlr.press/v32/busa-fekete14.html)\n' +
      '* Chen et al. (2021) Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et al. 코드에서 훈련된 대형 언어 모델들을 평가한다. _ arXiv preprint arXiv:2107.03374_, 2021.\n' +
      '* Chernoff(1992) Chernoff, H. _Sequential Design of Experiments_, pp. 345-360. Springer New York, New York, NY, 1992. ISBN 978-1-4612-4380-9. doi: 10.1007/978-1-4612-4380-9.27. URL[https://doi.org/10.1007/978-1-4612-4380-9_27](https://doi.org/10.1007/978-1-4612-4380-9_27](https://doi.org/10.1007/978-1-4612-4380-9_27)\n' +
      '* Chiang and Lee (2023) Chiang, C.-H. 그리고 이현예 대용량 언어 모델이 인간의 평가에 대한 대안이 될 수 있을까? 로저스, A., Boyd-Graber, J., and Okazaki, N. (eds.), _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp. 15607-15631, Toronto, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.870. URL[https://aclanthology.org/2023.acl-long.870](https://aclanthology.org/2023.acl-long.870).\n' +
      '* Cobbe et al. (2021) Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. 수학 단어 문제를 해결하기 위한 훈련 검증자. _ arXiv preprint arXiv:2110.14168_, 2021.\n' +
      '* Cui 등 (2023) Cui, G., Yuan, L., Ding, N., Yao, G., Zhu, W., Ni, Y., Xie, G., Liu, Z., and Sun, M. 울트라패스트백: 고품질 피드백으로 언어 모델을 부스팅, 2023.\n' +
      '* DiCiccio and Efron(1996) DiCiccio, T. J. and Efron, B. Bootstrap confidence intervals. _ Statistical science_, 11(3):189-228, 1996.\n' +
      '* Durrett(2019) Durrett, R. _ 확률: 이론 및 예제_, 권 49. 케임브리지 대학 언론, 2019.\n' +
      '* Elo(1967) Elo, A. E. The proposed uscf rating system, its development, theory and applications. _ Chess Life_, 22(8):242-247, 1967.\n' +
      '* Fisher(1928) Fisher, R. A. _Statistical methods for research workers_. 5번, 올리버와 보이드 1928년\n' +
      '* Freedman(2006) Freedman, D. A. on the 소위 "huber sandwich estimator" and "robust standard error". _ The American Statistician_, 60(4):299-302, 2006.\n' +
      '\n' +
      '* Gemini et al. (2023) Gemini, T., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., et al. Gemini: 고능력 멀티모달 모델의 패밀리. _ arXiv preprint arXiv:2312.11805_, 2023.\n' +
      '* Geng et al. (2023) Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., and Song, D. Koala: A dialogue model for academic research. 블로그 포스트, 4월 2023. URL[https://bair.berkeley.edu/blog/2023/04/03/koala/](https://bair.berkeley.edu/blog/2023/04/03/koala/].\n' +
      '* 그루텐도르스트(2022) 그루텐도르스트, M. 버토픽: 클래스 기반 tf-idf 절차를 이용한 신경망 토픽 모델링. _ arXiv preprint arXiv:2203.05794_, 2022.\n' +
      '* Hendrycks et al. (2020) Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. Measuring massive multitask language understanding. _International Conference on Learning Representations_, 2020.\n' +
      '* Howard et al. (2020) Howard, S. R., Ramdas, A., McAuliffe, J., and Sekhon, J. Time-uniform chernoff bounds via nonnegative supermartingales. 2020년\n' +
      '* Huang et al. (2023) Huang, Y., Lin, Z., Liu, X., Gong, Y., Lu, S., Lei, F., Liang, Y., Shen, Y., Lin, C., Duan, N., et al. Competition-level problems are effective llm evaluators. _ arXiv preprint arXiv:2312.02143_, 2023.\n' +
      '* Huber et al. (1967) Huber, P. J. et al. The behavior of maximum likelihood estimate under nonstandard conditions. In _Proceedings of the fifth Berkeley symposium on mathematical statistics and probability_, volume 1, pp. 221-233. Berkeley, CA: University of California Press, 1967.\n' +
      '* 406, 2004. doi: 10.1214/aos/1079120141. URL[https://doi.org/10.1214/aos/1079120141](https://doi.org/10.1214/aos/1079120141)\n' +
      '* Karimi et al. (2021) Karimi, M. R., Gurel, N. M., Karlas, B., Rausch, J., Zhang, C., and Krause, A. Online active model selection for pre-trained classifier. In _International Conference on Artificial Intelligence and Statistics_, pp. 307-315. PMLR, 2021.\n' +
      '* Karpinska et al. (2021) Karpinska, M., Akoury, N., and Iyyer, M. 개방형 텍스트 생성을 평가하기 위해 기계식 투르크 사용의 위험 모엔스 - F., Huang, X., Specia, L., and Yih, S. W.-t. (eds.), _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pp. 1265-1285, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main. 97. URL[https://aclanthology.org/2021.emnlp-main.97](https://aclanthology.org/2021.emnlp-main.97)\n' +
      '* Kiela et al. (2021) Kiela, D., Bartolo, M., Nie, Y., Kaushik, D., Geiger, A., Wu, Z., Vidgen, B., Prasad, G., Singh, A., Ringshia, P., et al. Dynabench: Rethinking benchmarking in nlp. In _Proceedings of the 2021 Conference of the North American chapter of the Computational Linguistics: Human Language Technologies_, pp. 4110-4124, 2021.\n' +
      '* Kopf et al. (2023) Kopf, A., Kilcher, Y., von Rutte, D., Anagnostidis, S., Tam, Z. -R., Stevens, K., Barhoum, A., Duc, N. M., Stanley, O., Nagyfi, R., et al. Openassistant conversation-democratizing large language model alignment. _ arXiv preprint arXiv:2304.07327_, 2023.\n' +
      '* Langley(2000) Langley, P. Crafting paper on machine learning. In Langley, P. (ed.), _Proceedings of the 17th International Conference on Machine Learning (ICML 2000)_, pp. 1207-1216, Stanford, CA, 2000. Morgan Kaufmann.\n' +
      '* Li et al. (2023) Li, X., Zhang, T., Dubois, Y., Taori, R., Gulrajani, I., Guestrin, C., Liang, P., and Hashimoto, T. B. Alpacaeval: a automatic evaluator of instruction-following models. [https://github.com/tatsu-lab/alpaca_eval] (https://github.com/tatsu-lab/alpaca_eval), 2023.\n' +
      '* Li et al. (2022) Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., Eccles, T., Keeling, J., Kimeno, F., Dal Lago, A., et al. 경쟁 레벨 코드 생성은 알파-코드를 가지고 있다. _ Science_, 378(6624):1092-1097, 2022.\n' +
      '* Liang et al. (2022) Liang, P., Bommasani, R., Lee, T., Tsipras, D., Soylu, D., Yasunaga, M., Zhang, Y., Narayanan, D., Wu, Y., Kumar, A., et al. arXiv preprint arXiv:2211.09110_, 2022.\n' +
      '* Lin et al. (2023) Lin, Z., Wang, Z., Tong, Y., Wang, Y., Guo, Y., Wang, Y., and Shang, J. ToxicChat: Unveiling hidden challenges of toxicity detection in real-world user-AI conversation. Bouamor, H., Pino, J., and Bali, K. (eds.), _Findings of the Association for Computational Linguistics: EMNLP 2023_, pp. 4694-4702, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-emnlp. 311. URL[https://aclanthology.org/2023.findings-emnlp.311](https://aclanthology.org/2023.findings-emnlp.311)\n' +
      '* Liu et al. (2009) Liu, T. -Y. et al. Learning to rank for information retrieval. _ 2009년 Information Retrieval_, 3(3):225-331의 기초 및 동향(r).\n' +
      '* McInnes et al. (2020) McInnes, L., Healy, J., and Melville, J. Umap: Uniform manifold approximation and projection for dimension reduction, 2020.\n' +
      '* OpenAI(2023) OpenAI. Gpt-4 기술 보고서입니다 arXiv preprint arXiv:2303.08774_, 2023.\n' +
      '* O\'Hagan et al.(2020)\n' +
      '* Oren et al. (2023) Oren, Y., Meister, N., Chatterji, N., Ladhak, F., and Hashimoto, T. B. Proving test set contamination in black box language models. _ arXiv preprint arXiv:2310.17623_, 2023.\n' +
      '* Ouyang et al. (2022) Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., and Lowe, R. 2022년, 언어 모델을 인간 피드백으로 지침을 따르도록 훈련한다.\n' +
      '* Ramdas et al. (2023) Ramdas, A., Grunwald, P., Vovk, V., and Shafer, G. Game-theoretic statistics and safe anytime-valid inference. _ Statistical Science_, 38(4):576-601, 2023.\n' +
      '* Rao & Kupper (1967) Rao, P. V. and Kupper, L. L. Ties in paired-comparison experiment: generalization of the bradley-terry model. _ Journal of the American Statistical Association_, 62(317):194-204, 1967. doi: 10.1080/01621459.1967.10482901.\n' +
      '* Srivastava et al. (2023) Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A., Garriga-Alonso, A., et al. Beyond the imitation game: Quantifying and extrapating the capabilities of language models. _ 기계 학습 연구 관련 거래, 2023년\n' +
      '* Szorenyi et al. (2015) Szorenyi, B., Busa-Fekete, R., Paul, A., and Hullermeier, E. Online rank elicitation for blackettluce: A dueling bandits approach. Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., and Garnett, R. (eds.), _Advances in Neural Information Processing Systems_, volume 28. Curran Associates, Inc., 2015. URL[https://proceedings.neurips.cc/paper_files/paper/2015/file/7eacb532570ff6858afd27758ff790-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2015/file/7eacb532570ff6858afd790-Paper.pdf].\n' +
      '* Touvron et al. (2023) Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al. Llama 2: Open foundation and fine-tuned chat models. _ arXiv preprint arXiv:2307.09288_, 2023.\n' +
      '* Vovk & Wang(2021) Vovk, V. 및 Wang, R E-값: 보정, 조합 및 응용 프로그램 _ The Annals of Statistics_, 49(3):1736-1754, 2021.\n' +
      '* Wang et al. (2023) Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N. A., Khashabi, D., and Hajishirzi, H. Self-instruct: Aligning language models with self-generated instructions. 로저스, A., Boyd-Graber, J., and Okazaki, N. (eds.), _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp. 13484-13508, Toronto, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.754. URL[https://aclanthology.org/2023.acl-long.754](https://aclanthology.org/2023.acl-long.754).\n' +
      '* Waudby-Smith & Ramdas (2020) Waudby-Smith, I. and Ramdas, A. Estimating means of bounded random variables by betting. _ arXiv preprint arXiv:2010.09686_, 2020.\n' +
      '* White(1982) White, H. Maximum likelihood estimation of misspecified models. _ Econometrica: Journal of the econometric society_, pp. 1-25, 1982.\n' +
      '* Yang et al. (2023) Yang, S., Chiang, W. - L., Zheng, L., Gonzalez, J. E., and Stoica, I. Rethinking benchmark and contamination for language models with rephrased samples. _ arXiv preprint arXiv:2311.04850_, 2023.\n' +
      '* Zellers et al. (2019) Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y. 헬라스바그: 기계가 정말로 당신의 문장을 끝낼 수 있을까요? In _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_, pp. 4791-4800, 2019.\n' +
      '* Zheng et al. (2023a) Zheng, L., Chiang, W. -L., Sheng, Y., Li, T., Zhu, Z., Zang, Y., Li, Z., Lin, Z., Xing, E. P., Gonzalez, J. E., Stoica, I., and Zhang, H. Lmsys-chat-1m: 대규모 실세계 llm 대화 데이터세트, 2023a.\n' +
      '* Zheng et al. (2023b) Zheng, L., Chiang, W. -L., Sheng, Y., Zang, S., Wu, Z., Zang, Y., Lin, Z., Li, Z., Li, D., Xing, E., Zhang, H., Gonzalez, J. E., and Stoica, I. LLM-as-a-판정을 MT-벤치와 챗봇 아레나로 한다. IMT-2000 3GPP-신경정보처리시스템에 관한 제37차 컨퍼런스에서 데이터세트 및 벤치마크 Track_, 2023b. URL[https://openreview.net/forum?id=uccHPGDlao](https://openreview.net/forum?id=uccHPGDlao)\n' +
      '* Zhong et al. (2023) Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., and Duan, N. 농업: 기초 모델 평가를 위한 인간 중심 벤치마크. _ arXiv preprint arXiv:2304.06364_, 2023.\n' +
      '* Zhu et al. (2023) Zhu, B., Frick, E., Wu, T., Zhu, H., and Jiao, J. 스탈링-7b: Improving llm helpfulness & harmlessness with traif, November 2023.\n' +
      '\n' +
      '도 8: 챗봇 아레나의 스크린샷.\n' +
      '\n' +
      '도 9: 시간 경과에 따른 득표수\n' +
      '\n' +
      '그림 11: 상위 64개 토픽 클러스터의 유사도 행렬.\n' +
      '\n' +
      '그림 10: 모델당 투표 수.\n' +
      '\n' +
      '그림 12: 상위 64개의 클러스터가 계층 구조로 시각화되었습니다. x축은 코사인 유사도 거리를 나타낸다. y축은 gpt-4-터보로 요약된 군집당 주제 제목을 보여준다.\n' +
      '\n' +
      '## 부록 신뢰구간 시뮬레이션 연구\n' +
      '\n' +
      '샌드위치 추정기에 대한 부트스트랩 신뢰 구간을 평가하기 위해 시뮬레이션 연구를 수행한다. 대체로, 두 간격은 동일합니다--사실, 그들의 간격은 종종 육안으로 동일합니다. 그럼에도 불구하고, 우리의 실험에는 약간의 차이가 있다. 먼저 그림 13에서는 본문에서 언급한 동일한 213576개의 데이터 포인트를 활용하여 리플레이 연구를 진행한다.\n' +
      '\n' +
      '또한 본문과 동일한 베타 생성 과정을 사용하여 시뮬레이션에서 \\(\\gamma=2\\)의 실험을 수행한다. 결과는 그림 14에 나와 있다. 결과는 매개변수 \\(\\gamma\\)와 모델 강도의 많은 선택에 걸쳐 유사하며, 이는 두 간격 모두 우리가 노출할 실제 조건에서 좋은 커버리지와 폭을 가질 것임을 나타낸다.\n' +
      '\n' +
      '## 부록 B : 비모수 브래들리-테리 모형\n' +
      '\n' +
      '**비모수적 브래들리-테리.** 다음으로 브래들리-테리(BT) 모델(브래들리 및 테리, 1952)의 비모수적 확장을 고려하여 순위가 반드시 과도적이지 않은 경우로 한다. \\(\\mathcal{G}(m)\\)는 모델에 대한 모든 _paths_의 집합을 나타낸다 \\(m\\), 즉,\n' +
      '\n' +
      '\\[\\mathcal{G}(m)=\\left\\{g\\in\\mathcal{B}^{M-1}:g_{i,1}\\neq g_{j,1},\\\\forall i\\neq j,\\\\text{ and}\\g_{M-1,2}=m\\right\\}, \\tag{11}\\}\n' +
      '\n' +
      '여기서 \\(\\mathcal{B}=\\mathcal{A}\\cup\\{(a_{2},a_{1}):a\\in\\mathcal{A}\\}\\). \\(\\mathcal{G}(m)\\)의 각 원소는 \\(m\\)으로 이어지는 모델 쌍의 사슬이며, 예를 들어 \\(m=5\\)과 \\(M=6\\)이면 \\(\\mathcal{G}(m)\\)의 한 원소는 \\(((1,2),(2,4),(4,3),(3,6),(6,5))이다. 우리의 점수 함수는 평균으로 주어진다.\n' +
      '\n' +
      '도 14: 합성 실험. 계수는 왼쪽의 BT 계수 분포 \\(x\\)에서 도출된다. 보정되지 않은 구간의 범위가 중간에 표시됩니다. 세트 폭의 선 도표는 오른쪽에 표시되며 거의 완벽하게 일치합니다.\n' +
      '\n' +
      '도 13: 부트스트랩 및 샌드위치 간격의 간격, 커버리지 및 평균 간격 크기를 보여주는 재생 실험. 샌드위치 간격은 작은 샘플에서 더 크지만 더 안정적이며 큰 샘플에서는 실제로 더 작아진다. 우리는 두 구간의 다중도 수정 버전을 사용하므로 둘 다 커버리지가 1이다. (여기서는 전체 데이터 세트의 BT 계수 솔루션과 관련하여 계산되므로 아래 시뮬레이션 도표에서와 같이 의미가 없다.)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:16]\n' +
      '\n' +
      '## 부록 C Valid P-값\n' +
      '\n' +
      'p-값을 고려\n' +
      '\n' +
      '[p_{i}=\\frac{1}{|\\mathcal{A}_{i}^{\\prime}|+1}\\left(1+\\sum_{h\\in\\mathcal{H}_{i}^{\\prime}\\mathds{1}\\left\\h\\geq H_{i}^{\\prime}\\right}}\\tag{25}\\left(1+\\sum_{h\\in\\mathcal{H}_{i}^{\\prime}\\right)\n' +
      '\n' +
      '우리는 벡터\\(\\mathcal{H}^{\\prime}=(H_{t}:A_{t}=A_{i}^{\\prime})\\|(H_{i}^{\\prime})\\)이 교환가능하다는 귀무 가설 하에서 이 p-값이 유효하다는 것을 증명할 것이다. 여기서 \\(\\|\\)은 연결 연산자를 나타낸다. 첫째, 우리가 동등하게 쓸 수 있다는 것에 주목하라\n' +
      '\n' +
      '[p_{i}=\\frac{1}{|\\mathcal{H}^{\\prime}|}\\sum_{h\\in\\mathcal{H}^{\\prime}}\\mathds{1}\\left\\{h\\geq H_{i}^{\\prime}\\right\\}. \\tag{26}\\times}\n' +
      '\n' +
      '또한 \\(\\mathbb{P}(p_{i}\\leq t)\\leq\\mathbb{P}(p_{i}\\leq\\frac{k}{|\\mathcal{H}^{\\prime}|})\\(k=\\lfloor t|\\mathcal{H}^{\\prime}|\\rfloor/|\\mathcal{H}^{\\prime}|\\)을 갖는다. 그리고 데이터 포인트가 교환 가능하기 때문에 \\(H_{i}^{\\prime}\\)이 \\(\\mathcal{H}^{\\prime}\\)의 순위 사이에 균일하게 분포하므로 \\(\\mathbb{P}(p_{i}\\leq\\frac{k}{|\\mathcal{H}^{\\prime}|})\\leq\\frac{k}{|\\mathcal{H}^{\\prime}\\leq t\\)의 증명을 완료한다.\n' +
      '\n' +
      '## 부록 D 샘플 프롬프트\n' +
      '\n' +
      '### 다른 클러스터로부터의 프롬프트 예제\n' +
      '\n' +
      '**예 1:** 클러스터 "파이썬 게임 프로그래밍 챌린지"로부터의 예시적인 사용자 프롬프트. 이것은 GPT-4-0613 성능을 라마-2-70b-채팅과 뚜렷하게 분리한다. 사용자는 각 어시스턴트로부터 "고품질 코드"를 요청한다. GPT-4-터보는 유용한 설명과 함께 올바른 구현을 제공하는 반면, 라마-2-70b-채팅은 프로그램을 제공하지 못하고 전반적으로 덜 도움이 되는 응답을 제공했다.\n' +
      '\n' +
      'forwordinenglish_wordsif7<=wordforwordinenglish_wordsiflen(word)<=9] hard_words=[wordforwordinenglish_wordscom/dwyl/english-words/master/words.txt](https://raw.githubusercontent.com/dwyl/master/words.txt]"step4:Createfunctiontrandomlyselectaword basedonthedhedary=\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:19]\n' +
      '\n' +
      '<|Llama-2-70b-chat\'s Answer|> 물론! 3단계 난이도에 대한 완전한 영어사전을 활용하여 항만과 유사한 눈사람 게임 개발에 대한 단계별 안내를 드립니다. 제1단계 : 프로젝트 설정\n' +
      '* 새로운 파이썬 프로젝트 디렉토리를 만들고 Git으로 초기화한다.\n' +
      '* 필요한 라이브러리 설치 : 난수 생성을 위한 + \'너피\' + 영어사전에 접속하기 위한 \'nltk\' + 게임 그래픽 생성을 위한 \'pygame\' + 효과음을 재생하기 위한 \'pydub\' (선택사항)\n' +
      '* 영어 사전 데이터셋(예: Kaggle에서)을 다운로드하여 \'dictionary.txt\'라는 이름의 파일에 저장한다. 제2단계 : 사전을 로딩하여 단어를 생성하는 단계\n' +
      '* \'nltk\' 라이브러리를 이용하여 사전 파일을 읽고 단어들을 리스트에 저장한다.\n' +
      '* 사용 길이와 빈도에 따라 쉬운 단어, 중간 단어, 어려운 단어의 세 부분으로 목록을 나눕니다.\n' +
      '* 단어 순서를 무작위화하기 위해 목록을 섞는다. 제3단계: 게임 그래픽 생성\n' +
      '* \'피게임\'을 이용하여 게임을 위한 창을 만들고, 흰 바탕이 눈을 나타내도록 한다.\n' +
      '*몸, 모자, 스카프 등에 검은 사각형을 사용하여 배경에 눈사람 형상을 그린다.\n' +
      '* 플레이어가 자신의 추측을 제출할 수 있도록 버튼을 추가한다. 제4단계: 게임 로직 구현\n' +
      '* 적절한 난이도에서 임의의 단어를 생성하여 누락된 글자(예: \'___________\')로 화면에 표시하는 함수를 생성한다.\n' +
      '*어절에 추측된 글자가 나타나는지 확인할 수 있는 기능을 생성하고, 그에 따라 표시를 갱신한다(예: ____X___)\'\n' +
      '* 경고 메시지를 표시하거나 효과음을 재생하는 등의 잘못된 추측을 처리할 수 있는 기능을 생성한다.\n' +
      '* 축하 메시지를 표시하거나 승리 효과음을 연주하는 등 게임에서 승리할 수 있는 기능을 생성한다. 단계 5: 효과음 추가(선택사항)\n' +
      '* \'pydub\'를 이용하여 글자를 바르게 또는 잘못 추측하는 등 게임 내 다양한 액션에 대한 효과음을 연주한다.\n' +
      '* \'pygame_mixer\'와 같은 라이브러리를 사용하여 pygame에서 음향 효과를 재생하는 과정을 단순화하는 것을 고려한다.\n' +
      '\n' +
      '제6단계: 게임의 테스트 및 정제\n' +
      '\n' +
      '* 게임을 철저히 테스트하여 예상대로 작동하는지, 버그나 오류가 없는지 확인합니다.\n' +
      '* 플레이어 피드백 또는 개인 선호도에 따라 필요에 따라 게임 메카닉 및 그래픽을 정제한다.\n' +
      '* 플레이어의 점수를 추적하거나 각 추측을 위한 시간 제한을 구현하는 것과 같은 추가 기능을 추가하는 것을 고려한다.\n' +
      '\n' +
      '제7단계: 게임의 포장 및 유통\n' +
      '\n' +
      '* PyInstaller와 같은 도구를 사용하여 독립 실행형 실행 파일로 게임을 포장합니다.\n' +
      '* 게임을 친구, 가족 또는 온라인 커뮤니티에 배포하고 향후 개선을 위한 피드백을 수집합니다.\n' +
      '\n' +
      '이것은 항만과 유사한 눈사람 게임을 만드는 데 관련된 단계에 대한 높은 수준의 개요입니다. 물론 세부 사항은 특정 구현과 사용하기로 선택한 도구에 따라 달라집니다. 프로젝트에 행운을 빌어요!\n' +
      '\n' +
      ' <|GPT-4-Turbo\'s judgment Verdict|> GPT-4-0613 Wins\n' +
      '\n' +
      '**프로그램 출력:** 아래는 GPT-4-0613에 의해 프로그래밍된 스노우맨 게임의 단말 출력으로서, 그 정확성을 입증한다. GPT-4-0613의 응답이 사용자의 요청에 더 도움이 되고 관련이 있다는 것은 분명하다.\n' +
      '\n' +
      '>> python snowman.py Choose 난이도(easy, medium, hard): easy 단어가 6글자를 포함하고 있다. 잘했어! 그 단어에는 그 글자가 들어 있다. _ A_______ 편지를 받아라: e 잘했어! 그 단어에는 그 글자가 들어 있다. _ A______ E Guess a letter: d\n' +
      '\n' +
      ' ( ) 미안하지만, 그 단어는 그 문자를 포함하지 않는다. _ A______ E Guess a letter: g\n' +
      '\n' +
      '**예 2:** 클러스터 "파이썬 게임 프로그래밍 챌린지"로부터의 예시적인 사용자 프롬프트. 이것은 GPT-4-0613 성능을 라마-2-70b-채팅과 뚜렷하게 분리한다. 제한된 공간으로 인해, 각 어시스턴트의 응답으로부터의 코드는 생략된다.\n' +
      '\n' +
      '```\n' +
      '<!UserPrompt|> Writeapythonfunctionthatprintsachristmastreeintheformofa triangleofasterisks,wheretheonlyinputize. <!GPT-4-0613\'sCodeOutput|>>>print_christmas_tree(5) ***************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n' +
      '```\n' +
      '\n' +
      '**<!GPT-4-TurboVerdict|>**GPT-4-0613Wins```\n' +
      '**예 3:** 클러스터 "영화 추천 및 평가"로부터의 예시적인 사용자 프롬프트. 두 비서 모두 정확한 영화 정보를 검색하고 거의 동일한 설명을 했다. 따라서 이 프롬프트는 GPT-4-0613의 성능을 라마-2-70b-채팅과 구별할 수 없다.\n' +
      '"<!UserPrompt|> Whichfilmcameoutfirst,BlindShaftorTheMaskOfFuManchu?" <!GPT-4-0613\'sAnswer|> TheMaskofFuManchuwasreleasedin1932,andBlindShaftwasreleasedin2003.Therefore,TheMaskofFuManchucameoutfirst. <!Llama-2-70b-chat\'sAnswer|> TheMaskOfFuManchucameoutfirst.Itwasreasedin1932,whileBlindShaftwasreasedin2003. <!GPT-4-TurboVerdict|> Tie\n' +
      '\n' +
      '**예 4**: 클러스터 "여행 일정 계획"으로부터의 예시적인 사용자 프롬프트. 두 비서 모두 똑같이 도움이 되는 여행 일정을 제공했다. 따라서 이 프롬프트는 GPT-4-0613의 성능을 라마-2-70b-채팅과 구별할 수 없다.\n' +
      '\n' +
      '프랑스, CanyoumakealistofthingsIcoulddowithmygirlfriendinLille? <|GPT-4-0613\'sAnswer> Absolute,herearesomesuggestions foractivitiesYouandyourgirlfriend canenjoyinLille,France: 1.VisitthePalaisdesBeaux-Arts:ThisisoneofFrance\'s largestmuseums andit\'srightintheheheofLille.IthousescollectionsofEuropean paintings,amedievalandRenaissancecollection,ceramics,French sculpturesandmore. 2.ExploretheVieuxLille:Strollthroughthecharmingoldtownwithits Flemishinfluenced architecture,chicboutiques,anddelightfuleateries. 3.VisittheLilleCathedral(Basilique-catedraletNotre-Dame-de-la-Treille):Thisbeautifulcathedralisamixofmodernandtraditional architecture. 4.EnjoyapicnatheCitadelPark:Thisisagreatplacetorelax,haveapicnic,andenjoytheoutdoor. 5.VisittheLAM(LilleMetropoleMuseedd\'artmoderne,d\'contemporainet d\'artbrut):Thismuseumishometoauniquecollectionofmodernandcontemporaryart. 6. TakeaboattourontheDeuleRiver:Thisisaromaticwaytoseethecityanditssuroundings. 7.Maison NataledeCharlesdeGauille:ThisisthebirthplaceofCharlesdeGauilleandit\'snowamuseumded tohis life andwork. 8.ExploretheMarchedeWazemmes:ThisisoneofthelargestmarketsinFranceandit\'safereplacetobuylocalproducts. 9.Enjoyamalataclocalrestaurant:Lilleisknownforitsdeliciouscusinsine,somakesuretotrysomelocaldishes. 10.TheLilleZoo 방문:Thisisasmallbutwell-keptzoothhathouses 약 70개의 다른 종. 11.TakeapromanticwalkthroughtheJardindesPlantesdeLille:This botanicalgardenisapeacefulplacetoenjoynature. 12.VisittheMuseedeld\'HospiceComtesse:Thismuseumislocatedinadormerhospitalandit\'shometoacollectionofartandartifacts from theMiddleAges. 13.EnjoyapperformanceattheLilleOpera:Checktheschedule andbookticketsforaromaticnightout. 14. TakeadaytriptothenearbycityofBruges:Thischarming Belgiancityisjustashortrainrideaway. 15.LePalaisRihour 방문:ThispalacehousestheLilleTouristOfficeandit\'salshometotheSalleduConclave, whosehasabeautifulGothicfireplace. 방문하기 전에 코로나19 예방 조치를 기억하세요. 즐거운 여행 되세요! <|Llama-2-70b-chat\'sAnswer> Sure!LilleisabeautifulcityinnorthernFrancethatoffersavarietyofactivitiesforcouplestoenjoy. Herearesomeideasforthingsyou can do your girlfriend in Lille:\n' +
      '\n' +
      '1. 그랑 플레이스, 비유 코스, 릴 대성당 등 도시의 매력적인 거리와 역사적인 명소를 탐험해 보세요.\n' +
      '\n' +
      '2. Palais des Beaux-Arts de Lille, Museed\'Art Moderne, d\'Art Contemporain et d\'Art Brut, 또는 Musee de l\'Hospice Comtesse와 같은 많은 박물관들 중 하나를 방문한다.\n' +
      '\n' +
      '3. 운하를 따라 산책을 하고 해안가에서 도시의 경치를 감상한다.\n' +
      '\n' +
      '4. 매년 12월에 열리는 유명한 릴 크리스마스 마켓에 방문해 축제 노점, 음식, 음료가 있다.\n' +
      '\n' +
      '5. 도시의 많은 부티크 및 갤러리, 또는 유랄릴 또는 릴 유럽과 같은 대형 쇼핑 센터에서 쇼핑하세요.\n' +
      '\n' +
      '6. 미슐랭 스타 르 콤푸투아르 뒤 릴레이나 아늑한 르비스트로 드알사체 같은 릴의 훌륭한 레스토랑 중 한 곳에서 로맨틱한 시너를 즐겨보세요.\n' +
      '\n' +
      '7. 그림 같은 운하와 중세 건축물로 유명한 벨기에의 인근 도시 브루기로 하루 여행하세요.\n' +
      '\n' +
      '8. 릴 오페라나 르 제니스 공연장에서 열리는 쇼나 콘서트에 가보세요.\n' +
      '\n' +
      '9. 섬유 산업과 아름다운 아르데코 건축물로 유명한 루바익스 인근 마을을 방문하세요.\n' +
      '\n' +
      '10. 도시에서 평화롭게 탈출할 수 있는 아름다운 파르 드 라 시타델을 산책하고 연못, 식물원, 동물원이 특징입니다.\n' +
      '\n' +
      '11. 자전거 타기 또는 파크 네이즐 지역 노르드파 드 칼레와 같은 주변 카운슬에서 하이킹을 하세요.\n' +
      '\n' +
      '12. 매주 일요일에 열리는 유명한 릴 벼룩시장을 방문하여 다양한 골동품, 빈티지 아이템, 중고품을 제공한다.\n' +
      '\n' +
      '13. 요리교실을 함께 수강하고 카보네이드 플라만데(쇠고기 스튜)나 타르테 오마로유(치즈 타르트) 등 지역의 맛있는 특산물을 만드는 방법을 익힌다.\n' +
      '\n' +
      '14. 와인 시음 투어를 가서 샤블리나 샴페인과 같은 지역의 훌륭한 와인을 발견하세요.\n' +
      '\n' +
      '15. 열기구를 타고 도시를 가로질러 릴의 아름다운 건축물과 주변 환경을 조감할 수 있는 전망을 즐기세요.\n' +
      '\n' +
      '이것은 당신을 시작하기 위한 몇 가지 아이디어일 뿐입니다. 릴은 활기차고 낭만적인 도시로서 커플들이 함께 즐거운 시간을 보낼 수 있는 많은 기회를 제공합니다. 즐거운 여행 되세요!\n' +
      '\n' +
      '<!GPT-4-Turbo Verdict|>\n' +
      '\n' +
      'Tie\n' +
      '\n' +
      '아레나 벤치 프롬프트\n' +
      '\n' +
      '**실시예 1**: 아레나 벤치로부터의 프롬프트는 현실 세계 애플리케이션을 고수하면서 매우 높은 레벨의 복잡한 문제 해결 기술 및 추론을 요구한다.\n' +
      '\n' +
      '사용자의 일상 습관을 추적하는 습관 추적을 위한 플러터 앱을 만듭니다. 사용자는 추적하려는 여러 일일 작업을 생성할 수 있어야 합니다. 그리고 그는 그 습관들을 한 무리의 그룹으로 분류할 수 있어야 한다. 사용자가 작업을 완료하면 작업당 다수의 포인트를 보상받는다. 앱에는 그룹당 총점을 요약하는 페이지가 있어야 합니다. 그리고 모든 습관 그룹의 종합 점수. 이 플루터 앱은 안드로이드와 iOS 모두에 대해 컴파일할 수 있어야 합니다.\n' +
      '\n' +
      '**예 2**: 아레나 벤치로부터의 프롬프트는 현실 세계 애플리케이션을 고수하면서 매우 높은 레벨의 복잡한 문제 해결 기술 및 추론을 요구한다.\n' +
      '\n' +
      '간단한 배선이 있는 태양 전지판으로 구동되는 원격 라즈베리 파이 0을 설정하고 싶습니다. 작은 2W 펌프, 간단한 전자 마이크, 마이크에서 감지된 오디오를 분류하는 데 사용되는 라즈베리 파이에서 실행되는 맞춤형 파이썬 스크립트에 전원을 공급하고 싶습니다. 비용을 최적화하고 전기 작업(예: 납땜)을 최소화하려면 어떤 구성 요소가 필요합니까? 이 전체 시스템에 전원을 공급하려면 어떤 크기의 태양 전지판이 필요합니까?\n' +
      '\n' +
      '### 아레나 벤치 시스템 프롬프트\n' +
      '\n' +
      '새로운 평가 절차는 다음과 같다. GPT-4-터보에는 사용자 프롬프트, 참조 답변 및 보조자 2인의 답변과 함께 시스템 프롬프트가 아래에 표시된다. 참고답변을 위해 GPT-4-Turbo, GPT-4-0314, Claude-1 등 3명의 어시스턴트들의 답변이 포함된 사용자 프롬프트를 GPT-4-Turbo에게 제시하고, GPT-4-Turbo에게 프롬프트에 대한 답변을 생성하도록 요청한다. 일관된 쌍별 판단을 보장하기 위해 GPT-3.5-Turbo-0301을 비교 대상 모든 모델에 대한 기준 해답으로 설정했다. 위치 편향을 피하기 위해 프롬프트당 두 가지 판단을 수행하는데, 첫 번째 판단은 베이스라인 답변을 어시스턴트 A로 제시하고 두 번째 판단은 베이스라인 답변을 어시스턴트 B로 제시한다. 총 350개의 사용자 프롬프트에 걸쳐 GPT-3.5-터보-0301에 대해 각 모델 간에 700쌍별 비교를 수행하여 베이스라인에 대한 승률을 계산한다. 그리고 승률 10점, 승률 5점, 승률 0점, 승률 3점, 승률 3점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 3점, 승률 3점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 승률 1점, 마지막으로 승패와 동점을 평균하여 최종 점수를 계산한다.\n' +
      '\n' +
      '```\n' +
      '<|SystemPrompt|>Pleaseactsanimpartialjudgeandevaluatethequalityoftheresponses providedbytwoAIassistantstotheuserpromptdisplayedbelow.Yourjob istecvaluatewhichassant\'sanswerisbetter.\n' +
      '"Whenevaluationtheassistants\'answ,comparebothassistants\'answ. Youmustidentifyandcorrectanymistakesorinaccurateinformation."\n' +
      '그런 다음 보조자의 도움이 되고 관련이 있으며 협의할 수 있습니다. Helpfulmeanstheorrectrespondpromptorfollowsthe instructions.Notewhenuserprompthasanyambiguityormorethanone interpretation,itismorehelpfulandappropriatetoaskforclarifications ormoreinformation from theuserthanprovidingananswerbased assumptions.Relevantmeansallpartsoftheresponsecloselyconnectorareappropriatettohatisbeingasked.Concisemeanstheresponseisclearandnotverboseorexcessive\n' +
      'picialtoincludewhenrespondingtotheuser.Finally,identifyanymissingimantinformation\n' +
      'Afterprovidingyourexplanation,youmustoutputonlyoneofthefollowingchoicesasyourfinalverdictwithalabel:\n' +
      '```\n' +
      '1.AssistantAisignificantlybetter:[[A>>B]]\n' +
      '2.AssistantAislightlybetter:[[A>B]]\n' +
      '3.Tie,relativelythesame:[[A=B]]\n' +
      '4.AssistantBislightlybetter:[[B>A]]\n' +
      '5.AssistantBisignificantlybetter:[[B>>A]]\n' +
      '6 예출력: "Myfinalverdictistie:[[A=B]]" ""\n' +
      '\n' +
      '지상 진실이 없는 아레나 전투\n' +
      '\n' +
      '**예 1**: GPT-4-터보와 라마-2-13B-채팅 사이의 아레나 배틀의 예이며, 여기서 상이한 선호도에 따라, 어느 쪽 대답이 다른 쪽보다 더 나은 것으로 주장될 수 있다. 두 대답 모두 맞지만 GPT-4-터보의 답은 객관식 질문의 형식에 간결하고 적절하다. 반면 Llama-2-13B-chat은 객관식 답변에 유용한 설명을 제공한다.\n' +
      '\n' +
      '```\n' +
      '<|UserPrompt|>  MultipleChoiceQuestion  Allplantshavebothahaploidandadiploidform.Astheplantchanges  fromoneformtoanother,thisiscalled:  Multiplechoicequestion. alternativelifecycle  succession  alternationofgenerations <!GPT-4-Turbo\'sAnswer|>  alternationofgenerations <!Llama-2-13B-chat\'sAnswer|> Thecorrectansweris:analternationofgenerations. 식물, 유사체, 하베드ifferentlifecyclestages, 그리고 그들은 canexistinwodifferentforms:haploidanddiploid.thehaploidform  isasingalestofchromosome,whilethediploidform istwosetsof chromosome.Astheplantchangesfromoneformtoanother,Thisiscalled of alternationofgenerations.Thisprocessinvolvesthealternation  haploidanddiploidphases,anditisafundamentalaspectofthelifecycle ofplantants. Alternativelifecycle andsuccessionreferstotheprocessofone  speciesreplacinganotherinaparticularenvironmentorniche,astheyrefertodifferentconcepts.Alternativelifecycleers  tothedifferentstages oflifeanorganismmaygothrough,suchaslarva,  pupa,andadultininsects,whilesuccessionreferstotheprocessofone  speciesreplacinganotherinaparticularenvironmentorniche.\n' +
      '```\n' +
      '\n' +
      '**예 2**: GPT-4-터보와 라마-2-13B-채팅 사이의 아레나 배틀의 예이며, 여기서 상이한 선호도에 따라, 어느 쪽 대답이 다른 쪽보다 더 나은 것으로 주장될 수 있다.\n' +
      '\n' +
      '```\n' +
      '<!UserPrompt|> WhatarecriticalelementsofaProductMindsetforstartupfounders? <!GPT-4-Turbo\'sAnswer|>  AdoptingaProductMindsetiscrucialforstartupfoundersasithelpsthem  focusoncreatingproductsthatdelivervaluetocustomerswhileachieving  businessobjectives.HerearessomecriticalelementsofaProductMindset forstartupounders:\n' +
      '``1.CustomerCentricity: -Understandandempathizewith yourcustomers\'sneeds,problem and  motivation.` "* 지속적으로 고객 피드백을 수집하여 제품 개발 프로세스에 통합합니다.\n' +
      '* 고객의 통증 지점을 직접 해결하고 경험을 향상시키는 기능 및 개선 사항 우선 순위 지정\n' +
      '\n' +
      '2. 가치 명제:\n' +
      '* 제품이 시장에 제공하는 고유한 가치를 명확하게 정의합니다.\n' +
      '* 제품의 기능과 기능을 가치 제안과 일치시켜 목표 고객의 기대에 부응할 수 있도록 합니다.\n' +
      '\n' +
      '3. 문제 해결 초점:\n' +
      '* 혁신을 위한 기능만 만드는 것이 아니라 사용자를 위한 실제 문제를 식별하고 해결하는 데 집중합니다.\n' +
      '* 실험 및 사용자 테스트를 통해 가정 및 가설을 검증한다.\n' +
      '\n' +
      '4. 반복적 개발:\n' +
      '* 반복적인 주기로 구축, 측정 및 학습하는 민첩한 개발 접근 방식을 수용합니다.\n' +
      '* 피드백 및 시장 반응을 기반으로 피벗팅하거나 중요한 변화를 만드는 데 열려 있습니다.\n' +
      '\n' +
      '5. 데이터 구동 의사결정:\n' +
      '* 데이터를 사용하여 제품 개발, 마케팅 및 성장 전략에 대한 결정을 알려줍니다.\n' +
      '* 제품의 성공을 측정하고 시간이 지남에 따라 진행 상황을 추적하기 위한 핵심 성능 지표(KPI)를 구축한다.\n' +
      '\n' +
      '...\n' +
      '\n' +
      '이러한 요소를 내면화함으로써 창업자는 자신의 결정과 전략을 안내하는 강력한 제품 마인드셋을 개발하여 궁극적으로 고객이 사랑하고 창업의 성공에 기여하는 제품으로 이어질 수 있다.\n' +
      '\n' +
      '<!Llama-2-13B-chat\'s Answer|>\n' +
      '\n' +
      '제품 마인드셋은 스타트업 창업자들에게 중요한 제품 개발을 사고하고 접근하는 방식이다. 다음은 스타트업 창업자를 위한 제품 마인드의 몇 가지 필수 요소입니다.\n' +
      '\n' +
      '1. 고객 중심성: 제품 마인드셋은 고객의 욕구, 욕구, 통증점 등을 이해하는 것에서 출발한다. 창업자는 고객에게 집착해야 하며, 고객의 요구를 이해하기 위해 기꺼이 노력을 기울여야 합니다.\n' +
      '\n' +
      '2. 반복과 실험: 제품 사고방식은 모두 실험과 반복에 관한 것이다. 창업자는 고객의 피드백을 바탕으로 새로운 것을 시도하고 가설을 테스트하며 제품에 대해 반복할 의향이 있어야 합니다.\n' +
      '\n' +
      '3. 가치 중심: 제품 마인드 셋은 고객에게 가치를 전달하는 데 중점을 둔다. 창업자는 고객에게 가장 큰 가치를 전달하는 가장 중요한 기능과 기능을 식별하고 우선순위를 정할 수 있어야 한다.\n' +
      '\n' +
      '4. 협업: 제품 마인드 셋은 엔지니어링, 디자인, 제품 관리를 포함한 교차 기능 팀 간의 협업이 필요합니다. 창업자는 이러한 팀과 효과적으로 협력하여 고객의 요구에 맞는 제품을 개발할 수 있어야 합니다.\n' +
      '\n' +
      '5. 데이터 기반 의사 결정: 제품 사고방식은 데이터 기반이며, 창업자는 자신의 제품에 대한 정보에 입각한 의사 결정을 하기 위해 데이터를 사용하는 것이 편안해야 한다. 여기에는 제품 개발을 알리기 위해 고객 피드백, 사용 데이터 및 기타 메트릭을 분석하는 것이 포함됩니다.\n' +
      '\n' +
      '...\n' +
      '\n' +
      '이러한 제품 마인드 셋의 요소를 수용함으로써 스타트업 창업자는 고객의 요구에 맞는 제품을 개발하고 가치를 전달하며 장기적인 성공을 위해 회사를 설립할 수 있습니다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>