<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '확산 기반 3D 주문형 이미지 합성\n' +
      '\n' +
      '종현 이\\({}^{1,2,}\\), 한삼초\\({}^{1,2}\\), 영준유\\({}^{2}\\), 서영범김\\({}^{1}\\), 용현정\\({}^{2}\\)\n' +
      '\n' +
      '한국대학교는\\({}^{1}\\,{}^{2}\\)\n' +
      '\n' +
      '카.krtomtomll103, 보삼95, shkim1}@korea.ac.krtomtomll103, chosam95, shkim1}@korea}@korea.\n' +
      '\n' +
      '{youngjoon.yoo,yonghyun.jeong}@navercorp.com\n' +
      '\n' +
      '1등. NAVER 클라우드 인턴십 기간 동안 수행된 작업. 응답 권한.\n' +
      '\n' +
      '카.krtomtomll103, 보삼95, shkim1}@korea.ac.krtomtomll103, chosam95, shkim1}@korea}@korea.\n' +
      '\n' +
      '{youngjoon.yoo,yonghyun.jeong}@navercorp.com\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '텍스트-조건 확산 모델에서 정확한 레이아웃 표현의 원천으로서 텍스트의 한계를 추가하는데, 많은 작품은 생성된 이미지 내에서 특정 속성을 조건하기 위해 추가적인 신호를 통합한다. 성공적이기는 하지만 이전 작품은 3차원 평면으로 확장된 해당 속성의 구체적인 위치를 설명하지 않는다. 이러한 맥락에서 우리는 3차원 객체 배치에 대한 제어를 여러 예시 이미지로부터 글로벌 양식적 의미론의 단절된 표현과 통합하는 조건부 확산 모델을 제시한다. 구체적으로, 우리는 먼저 _깊이 이젠트 학습_을 도입하여 객체들의 상대적 깊이를 추정기로 활용함으로써, 모델이 합성 이미지 트리플트의 사용을 통해 비세그먼트 오브젝트의 절대 위치를 식별할 수 있도록 한다. 또한 추가 국소화 신호를 사용하지 않고 글로벌 의미학을 표적 영역에 부과하는 방법인 _soft 안내_를 소개합니다. 우리의 통합 프레임워크인 목적 및 정복(CnC)은 이러한 기술을 통일하여 여러 조건을 불쾌하게 국소화한다. 우리는 우리의 접근법이 다양한 깊이에서 객체에 대한 인식을 허용하면서 다양한 글로벌 의미론으로 국소화된 객체를 구성하기 위한 다재다능한 프레임워크를 제공한다는 것을 보여준다.\n' +
      '\n' +
      '그림 1: 목적 및 정복은 3D 깊이 인식 방식으로 지역 조건과 글로벌 조건을 모두 현지화할 수 있다. 그림에 대한 자세한 내용은 1절에서 확인할 수 있다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '최근 텍스트-조건 확산 모델(Rombach et al., 2022; Ramesh et al., 2022; Saharia et al., 2022; Nichol et al., 2021)의 진행에 따라 생성된 이미지의 글로벌 레이아웃을 정확하게 나타내는 고유한 한계를 해결하기 위한 많은 후속 연구가 등장했다. 이러한 후속 작업은 세분화 맵(Zeng et al, 2023; Goel et al., 2023), 깊이 맵(Zhang and Agrawala, 2023; Mou et al, 2023), 바운딩 박스(Li et al, 2023), 인포팅 마스크(양 et al, 2023)와 같은 추가 조건을 통합하여 확산 모델의 텍스트 기반 컨디셔닝 능력을 풍부하게 한다. 이러한 변형은 전처리된 사제들에게 캡슐화된 광범위한 지식을 효과적으로 유지한다.\n' +
      '\n' +
      '이러한 발전에도 불구하고 현재 문헌에서 두 가지 주요 과제가 지속된다. 첫째, 기존 모델은 본질적으로 구조적 속성을 포착하는 깊이 맵 및 바운딩 박스처럼 국소적으로 제약된 조건에서 객체를 생성하는 데 효율적이지만 생성 공간을 2차원 평면에 혼란스럽게 만든다. 이러한 한계는 3차원(3D) 또는 z축(깊이) 관점 내에서 객체 배치를 처리하는 데 덜 의존하지 않으며, 따라서 다수의 객체의 깊이 인식 배치를 제대로 반영하지 않고 이미지를 생성하는 데 취약해진다. 둘째, 제어 방식으로 타겟 이미지의 여러 이미지 소스로부터 특정 영역에 이르기까지 스타일, 의미 등 글로벌 조건을 적용하는 문제는 아직 해결되지 않았다.\n' +
      '\n' +
      '현존하는 지역 및 글로벌 조건에 대한 한계를 해결하고 이미지 생성 모델의 역량 제고를 위해 구성 및 커밍(CnC)을 소개합니다. 우리의 제안된 CnC는 각 문제를 해결하기 위해 설계된 로컬 퓨저 및 글로벌 퓨저의 두 개의 빌딩 블록으로 구성된다. 먼저, 로컬 퓨저는 _깊이 디멘탕트 학습_(DDT)이라는 새로운 훈련 패러다임을 가지고 작동하여 3D 공간에서 여러 오브젝트가 서로 어떻게 관계되게 배치되어야 하는지 모델을 이해하도록 한다. DDT는 원래 이미지 구성 분야에서 도입된 합성 이미지 트리플트의 깊이 맵을 추출하여 로컬 퓨저에 대한 염기성 객체의 상대적 배치에 대한 정보를 증류한다. 둘째, 글로벌 퓨저는 명시적인 구조적 신호 없이 글로벌 조건을 현지화하는 데 우리의 모델을 보조하는 _soft 안내_라고 하는 방법을 사용한다. 부드러운 지침은 각 염기성 객체의 특정 영역에 참석하는 교차 의도 계층의 유사성 매트릭스의 영역을 선택적으로 마스크한다.\n' +
      '\n' +
      '그림 1은 DDT와 소프트 안내에 대해 훈련된 모델의 주요 능력을 보여준다. 그림 1(a)에서 DDT는 우리의 모델이 하나의 이미지 내에서 다수의 객체들의 상대적 깊이 연관성을 추론하고, z축의 서로 다른 깊이에 놓인 객체들을 전경 객체들과 효과적으로 다른 객체들을 폐색시키는 것을 생성한다. 그림 1(b)에서 부드러운 지침을 적용하여 우리의 모델이 전 지구적 의미론을 불쾌하게 현지화할 수 있음을 보여준다. Fig. 1(c)에서 입증된 바와 같이 지역 및 글로벌 퓨서를 동시에 활용하여 우리 모델은 사용자에게 각 국소 영역에 주입된 다양한 글로벌 의미론을 가진 여러 지역화된 객체를 구성할 수 있는 능력을 제공하여 방대한 수준의 창의적인 자유를 제공한다.\n' +
      '\n' +
      '다른 기준선 모델에 대해 모델을 정량적으로 평가하고 여러 입력 조건에 대한 샘플의 충실도와 견고성을 측정하고 우리의 모델이 다양한 메트릭에서 다른 모델을 실질적으로 능가한다는 것을 보여준다. 우리는 또한 재구성 능력, 그리고 _order_ 객체가 서로 다른 상대 깊이로 작용하는 능력 측면에서 우리의 모델을 평가한다. DDT가 DDT의 사용에 대해 조명했으며, 여기서 DDT가 물체의 상대적 깊이 배치를 추론하기 위해 장면의 추가 관점을 제공해야 한다는 것을 보여준다. 또한, 부드러운 지도가 우리의 모델이 지역화된 영역에 글로벌 의미학을 주입할 수 있을 뿐만 아니라 다른 지역으로의 출혈과 다른 의미도 방지한다는 것을 보여준다.\n' +
      '\n' +
      '우리의 기여는 다음과 같이 요약된다.\n' +
      '\n' +
      '* We는 여러 물체의 3D 상대 포지셔닝에 대한 모델의 이해를 용이하게 하는 새로운 훈련 패러다임인 _깊이 디멘탕트 훈련_(DDT)을 제안한다.\n' +
      '* We는 명시적인 구조적 신호를 필요로 하지 않고 글로벌 조건의 위치를 가능하게 하는 기술인 _soft 안내_를 도입하여 특정 이미지 영역에 글로벌 의미학을 부과하기 위한 고유한 메커니즘을 제공한다.\n' +
      '*는 이 두 가지 명제를 결합하여 3차원 객체 배치 및 글로벌 의미학의 국소 영역에 대한 주입에 대한 강화된 제어로 텍스트 조건 확산 모델을 확대하는 프레임워크인 구성 및 커밍(CnC)을 제시한다.\n' +
      '\n' +
      '2개는 회사 관련.\n' +
      '\n' +
      '조건부 융합 모델(DM) (Sohl-Dickstein et al., 2015; Ho et al., 2020)은 목표 데이터 분포를 점진적으로 공지된 이전으로 전환하는 순방향 프로세스를 역전시키기 위해 훈련된 생성 잠재 변수 모델이다. 다라리왈과 니콜, 2021년, 호 et al, 2022년, 니콜 et al, 2021년, 람바흐 et al, 2022년, Ramesh et al., 2022년 등 여러 작업에 이어 무조건적으로 샘플을 생성하는 능력에 매우 효과적인 것을 증명하여 특정 조건을 취하여 해당 이미지를 생성하는 확산 과정을 공식화했다. 이 모델들 중 롬바흐 등(2022)은 자동인코더를 활용한 잠재 텍스트조건 DM인 LDM을 제안하고, 고 충실도 결과를 달성하면서 생성의 계산 복잡도를 효과적으로 감소시킨다. 더 일반적으로 스테이블 디퓨전이라고 알려져 있는 LDM은 연구 공동체에 개방되는 가장 강력한 확산 모델 중 하나이다. LDM은 인코더가 \\(\\mathbf{x}\\)를 잠재 표현(\\mathbf{z}\\)에 매핑하고 훨씬 더 낮은 메모리 친화적인 차원에서 데노징 \\(\\mathbf{z}\\)을 진행하는 2배 접근법을 사용한다. 일단 완전히 변성되면 디코더는 \\(\\mathbf{z}\\)를 원래 이미지 차원에 매핑하여 샘플을 효과적으로 생성한다.\n' +
      '\n' +
      '텍스트 조건 외에도 텍스트 조건 DM은 생물이 자유 형태의 프롬프트를 사용할 수 있게 하지만 유일한 조건으로서 텍스트는 한계가 있다. 즉, 텍스트-조건 DM은 해당 모델을 훈련시키는 데 사용되는 대규모 웹 규모 데이터 세트의 텍스트 프롬프트(Schuhmann et al, 2021)가 명시적인 로컬화된 설명 및 의미 정보를 제공하지 않기 때문에 객체 및 특정 의미 개념을 텍스트 단독으로 국소화하는 것에 투쟁한다. 이러한 한계를 추가하기 위해 많은 작품은 추가 모듈을 훈련하면서 강력한 사전, _e.g._ 동결 모델을 보존하면서 모델에 추가적인 조건부 신호를 통합하는 방법을 도입했다. 이 모델 중 제어넷(장 및 아크로알라라, 2023)과 T2I-Ad캡터(Mou et al., 2023)는 깊이 맵 및 캐니 에지 이미지와 같은 모달리티가 결합된 추가 모듈을 훈련시켜 로컬 객체 생성을 돕는다. 그러나 이러한 모델은 여러 신호나 물체를 조건화하는 능력이 부족한 단일 조건만을 지원한다. 제어넷에서 영감을 얻은 유니 컨트롤넷(Zhao et al., 2023)은 여러 지역 조건과 단일 글로벌 조건을 한꺼번에 수용하기 위한 프레임워크를 확장한다. 모든 레버리지 스테이플 디퓨젼을 제사의 원천으로 자세히 설명한 반면, 코포저(황 등, 2023)는 픽셀 공간에서 작동한다. 여러 조건을 한 번에 처리할 수 있지만, 컴포저와 유니-제어넷 모두 호환 불가능한 조건을 처리하거나 서로 겹치는 조건에서 투쟁한다. 그들은 또한 지역화된 지역에 글로벌 의미론을 국소화하는 방법을 제공하지 않는다. 대조적으로, 우리의 접근법은 두 가지 새로운 방법, 깊이 무력화 훈련 및 부드러운 지침을 제안함으로써 이러한 문제를 직접 해결하며, 이는 지역 지역으로의 여러 지역/세계 조건의 구성을 가능하게 한다.\n' +
      '\n' +
      '3가지 방법론.\n' +
      '\n' +
      '그림 2에 예시된 아키텍처는 제안된 방법의 전반적인 틀을 보여준다. CnC는 전처리된 텍스트-조건 DM의 로컬 퓨저, 글로벌 퓨저 및 구성 요소로 구성된다. 당사의 로컬 퓨저는 깊이 맵을 통해 이미지의 상대적 z축 위치를 캡처하고, 우리의 글로벌 퓨저는 지정된 영역에 CLIP 이미지 임베딩(라드포드 등 2021)으로부터 글로벌 의미학을 부과한다. 지역 및 글로벌 퓨저의 설명은 아래에 자세히 설명되어 있습니다.\n' +
      '\n' +
      '정확하게.\n' +
      '\n' +
      '추가 조건 신호(Li et al, 2023; Mou et al., 2023; Zhang 및 Agrawala, 2023; Zhao et al., 2023; Zhao et al., 2023)를 포함하는 이전 연구에 따르면 우리는 이전 출처로 Stable Diffusion(SD)로 알려져 있는 LDM 변이체를 사용한다. 구체적으로 SD는 시끄러운 잠재 기능이 12개의 공간 다운샘플링 블록, 1개의 센터 블록(C\\), 12개의 공간 업샘플링 블록을 연속적으로 통과하는 구조와 같은 UNet(론네버거 등 2015)을 사용한다. 각 블록은 ResNet(He et al, 2016) 블록 또는 트랜스포머(Vaswani et al, 2017) 블록으로 구성되며, 양조성은 각각 12개 블록의 각 그룹을 인코더 \\(E\\) 및 디코더 \\(D\\)로 지칭한다. 제어넷 장과 아크로알라라(2023) 및 유니 컨트롤넷 자오 등(2023)에 의해 영감을 받은 Stable Diffusion 아키텍처는 먼저 전체 모델을 동결하고 인코더 및 센터 블록의 훈련 가능한 사본을 복제하는 모델에서 2배 활용되며, 이는 \\(E^{\\prime}\\) 및 \\(C^{\\prime}\\)로 표시된다. 우리는 SD에서 전체 모델의 가중치와 Uni-대조군Net에서 \\(E^{\\prime}\\) 및 \\(C^{\\prime}\\)의 가중치를 초기화한다. 복제된 인코더 \\(E^{\\prime}\\) 및 센터 블록 \\(C^{\\prime}\\)은 우리 모델의 시작점으로 작용하는 로컬 퓨저로부터 국부적인 신호를 수신한다. 아래 섹션에서 모델 아키텍처, 두 건물 블록의 방법론 및 대응하는 훈련 패러다임을 자세히 설명합니다.\n' +
      '\n' +
      '### Local Fuser\n' +
      '\n' +
      '먼저 추출된 깊이 맵을 포함하는 로컬 퓨저에 대한 세부 정보를 제공하며, 이는 지역 조건으로 전처리된 단안 깊이 추정 네트워크(란프틀 등 2020)를 형성한다. 구체적으로, 우리의 로컬 퓨저는 냉동 SD 블록에 통합된 국부적 특징의 원천 역할을 한다. 우리는 또한 _깊이 반점 훈련_에 대한 세부 사항과 합성 이미지 삼중선이 물체의 상대적 깊이 배치의 공급원으로 어떻게 레버링되는지 제공한다.\n' +
      '\n' +
      '합성 이미지 트리플렛은 추론 동안 다양한 깊이 스코프가 있는 중복되는 객체를 나타낼 수 있기 때문에 모델은 훈련 중에 오브젝트에 의해 가려진 다른 요소를 인식하도록 학습할 필요가 있다. 3D 세계에서 간단하지만, 2D 영상에서 다른 사람에게 폐색된 객체에 대한 모델을 알려주는 것은 비개인적인 것이지만, 일단 이미지가 캡처되면 그 뒤에 있는 객체에 대한 공간적 정보는 영원히 손실된다는 사실 때문이다. 이러한 한계를 극복하기 위해 먼저 영상 구성에 사용되는 과정(Fang et al., 2019)을 채택하여 종합 이미지 삼중체를 생성하는데, 이는 다음 섹션에서 자세히 설명하는 깊이 무능 훈련(DDT)을 위한 훈련 샘플 역할을 한다. 전경 이미지 \\(I_{f}\\in\\mathbb{R}\\in\\mathb{R} W\\times W\\tcer 3}\\)는 단일 소스 이미지 \\(I_{b}\\in\\mathb{HCI} W\\tome 3}\\), 배경 이미지 \\(I_{b}\\I_{f} W\\i} W\\i,I_{H\\in\\mathb{H} W\\i}\\in\\in\\in\\mathb} W\\i} W\\i} W\\i} W\\i} W\\I_{H\\I_{H\\I_{H\\i} W\\I_{H\\i} W\\I_{H\\i} W\\I_{H\\i} W\\I_{H\\i} W\\I_{H\\i} W\\i} W\\I_{H\\i} W\\i} W\\i} W\\i} W\\I_{H\\i} W\\i} W\\i} W\\i} W\\i} W\\ 전경 이미지 \\(I_{f}\\)는 \\(I_{f}=I_{s}\\)의 하다마드 제품을 사용하여 도출되며, 이는 \\(I_{s}\\)의 두드러진 객체만을 남겼다. i\\(I_{b}\\)를 생성하기 위해, 우리는 Stable Diffusion의 인포팅 모듈(Rombach et al, 2022)을 사용한다. 이는 \\(I_{s}\\otep(1-\\tilde{M})\\의 결과를 치환함으로써 달성되며, 여기서 \\(\\tilde{M}\\)는 이진 확장형 \\(M\\)이다. 개념적으로, 이 과정은 염기성 객체가 없는 \\(I_{s}\\)의 묘사와 마찬가지로 생각할 수 있으며, 이는 우리의 모델 _see_를 효과적으로 뒤처진다. 이 선택에 대한 세부 사항은 부록 A.2를 참조하십시오.\n' +
      '\n' +
      '합성 이미지 트리플츠(\\{I_{f}, I_{b}, M\\})가 준비되면, 우리는 깊이 무력화 훈련(DDT)이라고 하는 지역 퓨저를 훈련시키기 위해 \\(I_{f}\\)와 \\(I_{b}\\)의 깊이 맵을 추출하도록 진행한다. 당사의 로컬 퓨저는 ResNet 블록으로 구성된 자체 개별 스트림을 통과하는 이 두 깊이 맵을 통합하고 채널 차원을 따라 연결됩니다. 네트워크 진입 전 서로 다른 지역 조건을 직접 융합한 이전 작품과는 별도로 DDT는 자체 독립 계층에서 \\(I_{f}\\)와 \\(I_{b}\\)의 깊이 맵 각각을 먼저 처리한다. 쾌락한 객체 검출(주 등 2021)의 초기 및 후기 융합 방법론을 제거하면, 우리는 DDT를 후기 융합의 변이체로 간주하며, 여기서 네트워크는 먼저 각 표현을 불쾌하게 구별한다. 일단 연결되면 오브젝트에 대한 공간 정보가 포함된 특징이 있다.\n' +
      '\n' +
      '그림 2: ** 모델 건축***입니다. 우리의 모델은 로컬 퓨저, 글로벌 퓨저 및 복제된 인코더/중앙 블록 \\(\\{E^{\\prime},C^{\\prime}\\}\\)로 구성된다. 입력 깊이 맵들은 로컬 퓨저에 공급되어 \\(E^{\\prime}\\)에 통합된 다양한 공간 해상도의 4개의 잠재 표현을 생성한다. CLIP 이미지 임베딩은 글로벌 퓨저에 공급되어 텍스트 토큰 임베딩과 연결되도록 2개의 추가 토큰을 생성한다. 과제 \\(M\\)는 평평하고 반복되어 \\(M^{\\prime}=\\operatoral{concat}(J,\\varphi(M), 1-\\varphi(M))를 생성하며, 이는 교차 의도 계층의 부드러운 지침의 원천 역할을 한다.\n' +
      '\n' +
      '추출층에 의해 서로 다른 해상도를 따라 다양한 깊이가 추출된다. 그런 다음 이러한 특징을 복제된 SD 블록과 냉동 SD 블록에 통합하여 부록 A.2에 추가 세부 정보를 제공하고 추론 동안 다양한 깊이로 중첩된 물체를 나타내기 위해 모델이 불량한 오브젝트에 의해 가려진 요소를 인식해야 하기 때문에 모델을 훈련시키기 위해 DDT를 공식화한다. 우리의 모델을 두드러진 객체, 즉 합성-배열 합성-그 뒤에 있는 것에 대한 명시적인 깊이 표현을 제공함으로써 우리의 모델은 여러 물체의 상대적 깊이를 효과적으로 구별할 수 있다. 그림 3은 이전 작업에서 수행한 바와 같이 \\(I_{s}\\) 깊이 지도에 대한 모델을 훈련하는 것과 비교하여 DDT로 우리의 모델을 훈련하는 효과를 보여준다. 우리 지역 퓨서가 전경 염도 객체와 배경 깊이 맵 사이의 상대적 깊이 연관만을 전달하는 깊이 맵에 대해 훈련되었음에도 불구하고, 우리의 모델이 서로 다른 염도 객체를 국소화하는 데 확장된다는 것을 발견했다.\n' +
      '\n' +
      '### Global Fuser\n' +
      '\n' +
      '우리의 로컬 퓨저는 상대 객체 장소의 공급원으로 깊이 맵을 통합하지만, 우리의 글로벌 퓨저는 세계 의미학을 특정 지역에 지역화하기 위해 _소프트 안내_를 침출한다. CLIP 이미지 인코더(라드포드 등, 2021)에서 도출된 이미지 임베딩을 글로벌 시맨틱 조건으로 사용한다. 이 선택은 대조적으로 훈련된 상대방인 CLIP 텍스트 인코더로부터 텍스트 임베딩을 통합하도록 설계된 SD의 훈련 방법론에 의해 안내된다. 텍스트 임베딩(\\mathbf{y}_{\\text{text}}\\)은 교차 의도 메커니즘을 통해 중간 SD 블록에 통합된다. 이 설정에서 텍스트 임베딩은 키와 값에 대한 컨텍스트 역할을 하는 반면 중간 비지도 래치들은 쿼리로서 작용한다. 이전 작품(Nichol et al, 2021; Ramesh et al., 2022; Huang et al., 2023)은 DM의 교차 의도 계층 내에서 텍스트 임베딩과 CLIP 이미지 임베딩을 병합했지만, 이 접근법은 공간 접지 정보의 제공이 부족하다. 결과적으로, 글로벌 의미학은 정확한 국소화 능력이 결여되어 생성된 전체 이미지 상에서 조건화된다. 이러한 한계를 극복하기 위해 우리의 방법은 합성 이미지 삼중수에서 \\(I_{f}\\)를 추출하는 데 사용된 이진 전경 마스크 \\(M\\)를 인용한다.\n' +
      '\n' +
      '구체적으로, 우리는 먼저 적층된 피드포워드 층으로 구성된 글로벌 퓨저를 사용하여 \\(I_{s}\\) 및 \\(I_{b}\\)의 이미지 임베딩을 투사한다. 글로벌 퓨저는 별도의 전경/배경 하천으로 구성되며, 각각의 이미지 임베딩이 각각 \\(N\\) 글로벌 토큰에 투사되고 재결합되어 \\(\\mathbf{y}_{\\text{fg}}\\) 및 \\(\\mathbf{y}_{\\text{bg}}\\)를 생성한다. 우리 글로벌 퓨저는 로컬 퓨즈 모듈과 달리 피드포워드 레이어 내에서 각 스트림을 융합하지 않습니다. 확장된 컨텍스트(\\mathbf{y}},\\math{f{illcat},\\math{f}}}, \\mathda_{\\text{fg}}}},\\math{fg}}}{\\f}}})는 서로 연결된 \\(\\math{fg}:\\math{fg}},\\math{fg}},\\math{f}_{\\f{fg}},\\math{f}}}{\\bf{\\d{f}}}}{\\bf}{\\f}}{\\-{\\f}}{\\f}}}{\\bg}}}{\\bg}}{\\f}}{\\f}}{\\f}}{\\f}}{\\f}}{\\f}}}{\\f}}}{\\f}}{\\f}}}{\\f}}}{\\f}}}{\\f}}}}{\\f}}}{\\f}}}}{\\f} (\\lambda_{\\text{fg}}\\) 및 \\(\\lambda_{\\text{bg}}}\\)는 훈련 중 \\(1\\)로 설정된 각 토큰의 무게를 제어하는 스칼라 하이퍼파라미터를 나타낸다. 유사성 기질(Q=W_{Q}\\cdot\\mathbf{z}_{t}\\) 및 \\(K=W_{K}\\cdot\\mathbf{t}}}}\\)에 의해 제공되며(K=W_{K}\\cdot\\mathbf{t}}}}} <\\) 유사 기질은 \\(K=W_{K}\\cdot\\mathbf{dot\\crtbf}{t}{t}.{K}\\(K ={K}\\cdot\\cdot\\crtbf}{t}{dot\\dot\\crtbf}{dot\\dot\\crtbf}{dot\\dot\\crtbf}{t}}{dot\\dot\\dot\\crtbf}{t}{t}{dot\\dot\\bf}{t}}{dot\\dot\\sf}{t}}}{t}}}{t}}}}}}\n' +
      '\n' +
      '일단 \\(S\\)가 계산되면, 우리는 먼저 \\(S\\)의 동일한 차원을 갖는 Boolean 매트릭스 \\(M^{\\prime}\\)를 생성하여 부드러운 지침을 적용한다. \\(J\\in\\math j-2N}\\)는 모든 매트릭스(J,\\vath{i)를 나타내는 모든 매트릭스(J,\\vati{i)\\(M,\\vath{b(M)\\in\\mathi{B}\\i)를 의미하고, 여기서\\(M,\\vath{B(M)\\in\\math{b\\i첨부(M)\\i{b\\i{i\\i{b\\i{b\\i{i\\i{b\\i{b\\i{i\\i{b\\i{B(M)\\vati{b\\i{b\\i{b\\i{b\\i{b\\i\\i{b\\i\\i{b\\i{b\\i\\i{b\\i{b\\i\\i{b\\i\\i{b\\i{b\\i\\i\\i{b\\i\\i<\\i <\\i{B})는\\(M)\\i{B(M)\\i{B(M)\\i{B(M)\\i:\\i\\i Hadamard 제품 \\(S^{\\prime}=S\\otome M^{\\prime}\\)으로 \\(S\\)를 과잉 공급함으로써, 주의 운영 \\(\\operatorRep{softmax}(S^{\\prime})\\cdot V\\)을 완성한다. 직관적으로 부드러운 지도는 마스킹하는 것으로 생각할 수 있다.\n' +
      '\n' +
      '그림 3: ** 불가항력 훈련. DDT(Left)에서 학습된 우리의 모델은 전경 깊이 맵(좌측 상단 왼쪽)에 의해 묘사된 객체가 배경 깊이 맵(Bottom 왼쪽)에 가깝게 배치되어야 하며 더 큰 물체를 완전히 덮고 있음을 성공적으로 인식한다. 한편, \\(I_{s}\\)의 깊이 맵만으로 훈련했을 때, 우리의 모델은 깊이 맵을 무시하기 위해 투쟁하여 객체들이 융합(샘플(a), (c))되거나 전경 객체(샘플(b)를 완전히 무시하는 결과를 낳는다.\n' +
      '\n' +
      '\\(\\mathbf{y}_{t}}\\)의 교차 선택 계산은 \\(\\mathbf{y}_{\\{fg}}\\)에 참석하지 않아야 하며, \\(\\mathbf{fg}}}\\) 및 \\(\\mathbf{y}_{\\}_{t}}}\\)의 교차 의도 계산은 \\(\\mathbf{y}_{\\)의 해당 평탄한 값에서만 수행되어야 한다. 우리는 \\(\\mathbf{y}_{\\text{텍스트}}\\)의 토큰을 전체 잠재된 토큰에 참석시키고 추가 토큰을 제한함으로써 생성된 샘플이 \\(M\\)의 공간 정보가 몰라도 조건화된 글로벌 의미학을 지역화된 영역에 반영하면서 텍스트 조건에 유지될 수 있음을 발견했다.\n' +
      '\n' +
      '### Training\n' +
      '\n' +
      'LDM은 호 등은 먼저 제안한 \\(q(\\mathbf{x}_{0})\\에 결합된 재가중 가변 하부 변이체를 사용하여 노이즈 예측 방식으로 최적화되어 있다. 우리는 이 제형을 확장하고 모델을 Eq로 최적화한다. 1은 \\(p(\\mathbf{z}|y)\\의 조건부 분포를 학습하는데, 여기서 \\(y\\)는 CLIP 텍스트 임베딩과 함께 볼펜mm 및 이미지 임베딩 조건의 세트를 나타낸다. 위에서 언급한 바와 같이 복제된 인코더 \\(E^{\\prime}\\), 중심 블록 \\(C^{\\prime}\\) 및 지역/글로벌 퓨저 모듈의 가중치를 공동 최적화하는 동안 초기 SD 모델을 동결한다(\\theta^{\\prime}\\).\n' +
      '\n' +
      '}\\math{{}\\math{{}\\math{{.\n' +
      '\n' +
      '## 4 Experiments\n' +
      '\n' +
      '### Experimental Setup\n' +
      '\n' +
      '우리의 합성 이미지 트리플츠(I_{f},I_{b}, M\\)는 COCO-Stuff(Caesar et al., 2018), Pick-a-Pic(Kirstain et al., 2023)의 두 가지 별개의 데이터세트로부터 생성된다. 우리는 독자를 이 선택 뒤에 있는 우리의 추론에 대해 4.3절에게 참조한다. 164K 이미지가 적용된 COCO-Stuff 데이터셋은 픽셀별 주석을 가지고 있는 객체들을 "다운"(웰 정의 형상)과 "스택(배경 영역)"으로 분류한다. 우리는 사물의 범주에 있는 사물을 소수 대상으로 볼 수 있다는 사실을 레버리지하고, 80개의 사물의 집합 중 어느 하나에 속하면 색인 마스크의 각 화소를 1로 설정하여 \\(M\\)를 만들고, 그렇지 않으면 0을 생성한다. 텍스트 프롬프트는 각 이미지에 대해 사용할 수 있는 5개의 이미지로부터 무작위로 선택된다. Pick-a-Pic 데이터 세트는 SD 및 그 변이체에 의해 생성된 584K 합성 이미지 텍스트 쌍을 포함하고 선호도 점수 모델을 훈련시키기 위한 노력으로 수집되었다. 각각의 텍스트 프롬프트는 2개의 생성된 이미지와 페어링되고, 주어진 프롬프트에 대한 충실도 및 의미 정렬 측면에서 선호 이미지를 나타내는 라벨을 보유한다. 선호 이미지를 유지하고 부적절한 콘텐츠를 필터링하기만 하면 138K 이미지-텍스트 쌍으로 마무리됩니다. Pick-a-Pic은 COCO-Stuff과 달리 염기성 객체에 대한 그라운드 진리 라벨을 보유하지 않기 때문에, 우리는 \\(M\\)를 생성하기 위해 두드러진 객체 검출 모듈(Qin et al, 2020)을 사용한다. 이 두 데이터 세트를 결합하여 섹션 3.2에 자세히 설명된 과정을 통해 302K 합성 이미지 트리플츠(\\{I_{f}, I_{b}, M\\}\\)를 생성한다.\n' +
      '\n' +
      '깊이 맵 표현을 위해 단일 깊이 추정 네트워크(Ranftl et al., 2020), 그리고 글로벌 의미 조건에 CLIP 이미지 인코더(Radford et al., 2021)를 사용한다. 단일 모델로 공식화되었지만, 우리는 지역 및 글로벌 퓨서를 독립적으로 훈련하고 결합된 가중치를 가속화하는 것이 더 빠른 수렴으로 이어진다는 것을 경험적으로 발견했다. 훈련하는 동안 이미지는 재구성되고 중앙은 \\의 해상도로 크롭된다(512\\tenn 512\\). 우리는 복제된 \\(E^{\\prime}\\) 및 \\(C^{\\prime}\\)를 사용하여 로컬 퓨저를 훈련시키고, 28epochs에 대한 글로벌 퓨저, 24epochs에 대한 글로벌 퓨저, 8 NVIDIA V100s에 걸쳐 32의 배치 크기로 9epoch에 대한 전체 모델을 구했다. 훈련 동안 우리는 모델이 다양한 조합을 일반화하기 위해 학습하도록 각 조건에 대한 독립적인 중도 탈락 확률을 설정했다. 우리의 평가를 위해 50단계로 DDIM(송 et al., 2020), CFG(호 및 살미만, 2021) 척도를 사용하여 \\(768\\·768\\)의 이미지를 생성한다.\n' +
      '\n' +
      '### Evaluation\n' +
      '\n' +
      '질적 평가를 통해 깊이 맵을 국소 조건으로 포함하는 다른 기준선 모델, 전 지구적 조건으로 CLIP 이미지 임베딩 또는 둘 다에 비해 이 방법의 결과를 보여준다. 기준선 모델은 표 1. GLIGEN(Li et al., 2023), 제어넷(장 및 아크로알라라, 2023)에 나열되어 있으며 단일 깊이 맵을 국소 조건으로 수용하도록 훈련된다. 유니 컨트롤넷(Zhao et al., 2023), T2I-Ad캡터(Mou et al., 2023)는 CLIP 이미지 임베딩의 소스로서 깊이 맵과 예시 이미지를 수용하도록 훈련된다. 그림 4에서 깊이 맵과 예시 이미지를 모두 글로벌 의미론의 공급원으로 수용하는 모델과 비교하여 모델의 질적 결과를 보여준다. 우리의 모델은 두 개의 깊이 맵과 두 개의 예시 이미지를 수용하기 때문에 그림 4의 각 모달리티에 대해 동일한 이미지를 조건한다는 점에 주목하며, 다른 모델들은 각 조건의 아이디어를 파악하는데, 예를 들어 이미지와 텍스트 프롬프트가 제공하는 깊이 맵과 의미 정보 사이의 균형을 찾는 데 우리의 모델이 초과함을 알 수 있다. 첫 번째 열을 예로 들자면 유니-제어넷은 종종 글로벌 의미론을 통합하지 못하는 반면, T2I-캡터는 종종 "가짜" 또는 "보츠"와 같은 텍스트 신호를 무시하고 예시 영상에서 의미론을 과도하게 조절한다. 우리의 접근법은 글로벌 의미론을 정확하게 반영하는 동시에 깊이 맵에 의해 제공되는 텍스트 기반 세부 정보와 구조적 정보를 강조하는 이러한 측면을 능가한다. 추가적인 질적 결과를 위해 독자를 그림 5에 참조한다.\n' +
      '\n' +
      '정량적 평가는 기준 메트릭으로 생성된 이미지의 품질을 평가하기 위해 FID(Heusel et al, 2017) 및 인셉션 스코어(살리만 et al, 2016)와 생성된 이미지의 의미 정렬을 텍스트 프롬프트에 평가하기 위해 CLIPS코어(Hessel et al, 2021)를 사용한다. 표 1은 COCO-Stuff 검증 세트의 5K 이미지에 대해 평가한 결과를 보고한다. 추론(CnC, 양조에 대해) 동안 독립적으로 훈련되고 결합된 지역 및 글로벌 퓨저를 사용한 모델은 적절한 성능을 보여주지만 깊이 전용 실험의 FID 및 IS를 제외하고 대부분의 메트릭에서 핀셋된 모델이 탁월함을 알 수 있다. 이는 기준 모델이 검증 이미지로부터 추출된 단일 깊이 맵에서만 취하지만, 우리의 모델은 데이터 세트의 사전 분포를 반영하지 못할 수 있는 침입된 영역을 갖는 추가 깊이 맵에서 취하기 때문일 수 있다. 우리의 모델이 상충되는 현지화 정보의 깊이 지도를 처리해야 한다는 사실은 또 다른 가능한 설명이다. 모든 모델은 SD 이전에 공유 생성 모델을 고려할 때 유사한 CLIPS코어를 보고하지만 부드러운 지도의 통합 덕분에 예시 이미지에서만 생성할 때 핀셋 모델이 탁월하다. 우리는 우리의 안정 모델이 실질적인 성능을 달성한다고 결론지었다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c c|c c c|c c c} Model/Condition & \\multicolumn{3}{c}{Depth} & \\multicolumn{3}{c|}{Semantics} & \\multicolumn{3}{c}{Depth+Semantics} \\\\  & FID (\\(\\downarrow\\)) & IS (\\(\\uparrow\\)) & CLIP Score (\\(\\uparrow\\)) & FID (\\(\\downarrow\\)) & IS (\\(\\uparrow\\)) & CLIP Score (\\(\\uparrow\\)) & FID (\\(\\downarrow\\)) & IS(\\(\\uparrow\\)) & CLIP Score (\\(\\uparrow\\)) \\\\ \\hline GLIGEN & 18.887 & 29.602 & 25.815 & - & - & - & - & - & - \\\\ ControlNet & **17.303** & **31.652** & 25.741 & - & - & - & - & - & - \\\\ Uni-ControlNet & 19.277 & 31.287 & 25.620 & 23.632 & 28.364 & 24.096 & 18.945 & 28.218 & 24.839 \\\\ T2I-Adapter & 20.949 & 31.485 & 26.736 & 35.812 & 23.254 & 23.666 & 30.611 & 23.938 & 24.579 \\\\ \\hline\n' +
      '24.659&25.421 & 24.659\\\\ & 25.305 & 24.659 & 25.211 & 21.555 & 27.555 & 25.9932 & 21.9932 & 21.9932 & 21.9932 & 19.804 & 21.9932 & 21.9932 & 21.9932 & 21.9932 & 21.985 & 21.9932 & 21.9932 & 21.38 및 21.9932 & 21.9932 & 21.38 및 21.38 및 21.38 및 21.9932 & 21.985 & 21.985 & 21.38 및 21.9932 & 21.985 & 21.985 & 21.38 및 21.9932 & 21.985 & 21.9932 & 21.38 및 21.38 및 21.9932 & 21.09.930 및 21.985 & 21.985 & 21.38 및 21.9932 & 21.9932 & 21.38 및 21.9932 및 21.09.59 및 21.9932 & 21.38 및 21.9932 & 21.38 및 21.\n' +
      '**CnC Finetuned** & 22.257 & 27.981 & **26.870** & **17.254** & **32.131** & **25.940** & **18.191** & **29.304** & **25.880** \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: COCO-Stuff 밸브 세트에 대한 평가 메트릭. 우리는 이러한 조건을 지원하지 않는 모델로 인해 GLIGEN과 ControlNet에서 의미론적 및 깊이+제학 결과를 생략한다. 가장 큰 결과는 **bold***입니다.\n' +
      '\n' +
      '그림 4: ** 샘플은 다른 기준선 모델과 비교하여 a***에 비해 CnC는 주어진 깊이 맵, 예시 이미지 및 텍스트 프롬프트 사이의 균형을 맞췄다.\n' +
      '\n' +
      '추가적인 핀셋링 단계로 인해 푸더가 서로의 컨디셔닝 프로세스를 더 잘 적응하고 이해할 수 있습니다. Pick-a-Pic 검증 세트에 대한 결과에 대한 A.3절을 참조한다.\n' +
      '\n' +
      '또한 "표 2"에 나열된 COCO-Stuff 및 Pick-a-Pic 검증 세트에 대해 평가된 정량적 재구성 메트릭을 보고하며, 우리의 모델은 지상 진리 검증 이미지의 이미지 삼중선에서 추출된 깊이 맵 및 CLIP 이미지 임베딩을 사용하고 기준 모델은 모달리티당 하나 이상의 조건을 지원하지 않기 때문에 지상 진리 이미지로부터 추출된 깊이 맵 및 CLIP 이미지 임베딩을 사용한다. 우리는 LPIPS(Zhang et al., 2018)를 지각적 유사성의 메트릭으로, SSIM(왕 등은 2004)을 구조적 유사성의 메트릭으로 채택한다. 우리는 또한 z축으로 확장된 구조적 유사성의 추가 척도로서 생성된 상대방으로부터 추출한 지상 진리 깊이 맵과 깊이 맵의 MAE를 보고한다. COCO-Stuff의 SSIM 값과 별도로 우리는 모델이 다른 모델을 큰 폭으로 능가한다는 것을 발견했다. 그림 6에서 볼 수 있듯이, 우리는 우리의 모델이 현장 깊이를 보존하면서 다양한 지역 내 객체들을 충실히 재현할 수 있다는 것을 발견했다. 다른 기준선 모델은 객체 지역화에 성공하지만 깊이 관점을 합성하는 데 어려움을 겪으며 상대적으로 평평하게 보이는 이미지를 낳는다.\n' +
      '\n' +
      '개념 출혈(Podell et al., 2023)으로 알려져 있는 현상은 서로 다른 의미론으로 이어져 의도하지 않은 결과를 초래한다. 소프트 지도가 가능합니다\n' +
      '\n' +
      '그림 5: ** 정성적 결과** 포그라운드/배경 조건은 각 샘플의 왼쪽에 있다.\n' +
      '\n' +
      '그림 6: ** 정성적 재구성 비교** 삼그룹은 COCO-Stuff(Left) 및 Pick-a-Pic(그렇죠)의 검증 샘플에서 추출한 조건을 사용하여 생성된다.\n' +
      '\n' +
      '글로벌 의미학은 이러한 바람직하지 않은 효과를 방지하면서 국부적 영역에 조절된다. 그림 7은 두 가지 상반된 의미론이 국한되어 있는 이 능력을 보여준다. Hi(\\lambda_{\\text{fg}}\\)를 1로 고정하고 \\(\\lambda_{\\text{bg}}\\)를 꾸준히 증가시킴으로써 배경 의미론의 효과가 증폭된다. 그러나 부드러운 지도로 인해 배경 의미론이 심해지면서 전경 물체의 모순된 의미성은 그대로 유지된다. 부드러운 안내 동안 \\(M\\)의 공간 정보가 손실되지만 출혈로 인한 모든 의미학에 대한 장벽을 충실히 생성한다는 것을 발견했다. 추가 회수를 위해 A.4절을 볼 수 있습니다.\n' +
      '\n' +
      '### Discussions\n' +
      '\n' +
      '4.1절에서 언급한 바와 같이, 우리가 모델을 훈련시키기 위해 사용하는 두 데이터 세트는 다른 데이터 세트와 매우 다르다. 즉, COCO-Stuff의 이미지는 일상적인 장면을 포함하는 반면 Pick-a-Pic의 이미지는 근본적으로 합성되어 실제 생활 시나리오에 대한 모든 설명을 초월하는 프롬프트로부터 SD의 변이체에 의해 생성된다. 이 설계 선택은 의도적인 것이지만, 우리는 대부분의 기준 모델이 MS-COCO(Lin et al., 2014)의 변이체에 대해 훈련된다는 사실을 먼저 지적한다. 이러한 모델은 새로운 조건을 도입하는 방법으로서 실제 이미지에서만 훈련하는 것이 적절하다는 것을 보여주지만, Kirstain et al.(2023) 및 Podell et al.(2023)는 COCO 제로 샷 FID가 생성된 이미지의 인간 선호도와 시각적 미학과 _음성 상관 관계가 있다고 보고한다. COCO와 그 변이체의 이미지는 새로운 조건을 도입하는 데 목적을 제공하지만 전처리된 DM의 이전에 학습된 것과 일치하는 또 다른 데이터 세트를 활용하여 사전 표류로부터 안전망을 제공한다고 주장한다. COCO-Stuff의 상세한 근거 진실 픽셀별 주석들을 활용하고 우리의 모델을 Pick-a-Pic에 의해 제공되기 전에 원래 표상으로부터 추가적인 표현을 배우게 함으로써, 우리는 두 세계 중 최고를 활용하며 DM 이전에 사용자에게 선호되는 동안 조건의 강력한 후방을 제공한다.\n' +
      '\n' +
      '5 콘퓨전.\n' +
      '\n' +
      '우리는 현장에서 두 가지 주요 과제를 다루는 새로운 텍스트-조건 확산 모델인 목적 및 정복(CnC)을 제시했는데, 이는 여러 물체의 3차원 배치와 여러 출처에서 글로벌 의미학의 지역별 국소화이다. CnC는 지역 및 글로벌 퓨저의 두 가지 주요 구성 요소를 사용하는데, 이는 각각 새로운 제6차 장애훈련(DDT)과 소프트 안내 기법을 사용한다. DDT가 물체의 절대 깊이 배치를 추론하고 부드러운 지도가 국소 지역에 의미론을 통합할 수 있음을 보여준다. COCO-stuff 및 Pick-a-Pic 데이터 세트에 대한 평가는 광범위한 실험 결과를 통해 입증된 바와 같이 이러한 문제를 해결하는 CnC의 능력을 보여준다. 현재 프레임워크는 이용 가능한 조건의 수와 비참한 공간 근거를 전경 및 배경으로 제한하기 때문에 이미지를 더 깊이 분해하여 원시물과 중간 지면을 묘사하여 향후 작업을 위해 레버리지한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c c|c c c} Model/Condition & \\multicolumn{3}{c|}{COCO-Stuff} & \\multicolumn{3}{c}{Pick-a-Pic} \\\\  & SSIM(\\(\\uparrow\\)) & LPIPS(\\(\\downarrow\\)) & MAE(\\(\\downarrow\\)) & SSIM(\\(\\uparrow\\)) & LPIPS(\\(\\downarrow\\)) & MAE(\\(\\downarrow\\)) \\\\ \\hline Uni-ControlNet & **0.2362** & 0.6539 & 0.1061 & 0.2506 & 0.6504 & 0.1111 \\\\ T2I-Adapter & 0.1907 & 0.6806 & 0.1201 & 0.2238 & 0.6724 & 0.1270 \\\\ \\hline\n' +
      '0.6636 & 0.6431 & 0.1080 \\\\ 0.6421 & 0.1061 & 0.1080 \\\\ < 0.2345 및 0.2345 및 0.2336 & 0.1080 \\\\****CnC** & 0.2345 및 0.\n' +
      '**CnC Finetuned** & 0.2248 & **0.6509** & **0.0990** & **0.2690** & **0.6216** & **0.1027** \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: COCO-Stuff 및 Pick-a-Pic 밸브-sets에서 평가된 정량적 재구성 메트릭이다.\n' +
      '\n' +
      '그림 7: ** 상충되는 의미와의 소프트 가이드의 효과** 로컬 퓨저 내의 스트림별 동일한 깊이 맵을 조건하고, 프롬프트 "An Igloo"로 각 샘플을 생성한다. r\\(\\lambda_{\\text{fg}}\\)를 고정하고 \\(\\lambda_{\\text{bg}}\\)를 증가시켜 배경 글로벌 정자의 효과가 실질적으로 증가한다. 부드러운 지침은 두 가지 글로벌 정자가 서로 출혈되는 것을 방지하고 _e.g._개념 출혈을 방지하여 igloo의 의미성을 효과적으로 유지한다.\n' +
      '\n' +
      '## Acknowledgements\n' +
      '\n' +
      '사려 깊은 조언과 토론에 NAVER 클라우드의 이미지비전 팀에 감사드립니다. 네이버 스마트 기계학습(NSML) 플랫폼(김 et al., 2018)에서 훈련 및 실험을 수행하였다. 이 연구는 BK21 FOUR에 의해 뒷받침되었다.\n' +
      '\n' +
      '## Ethics statement\n' +
      '\n' +
      '확산 모델은 생성 모델의 한 종류로서 유익하고 잠재적으로 유해한 방법 모두에서 사용될 수 있는 합성 함량을 생성할 가능성이 있다. 우리의 작업은 이러한 모델의 이해와 역량을 발전시키는 것을 목표로 하지만 책임 있는 사용의 중요성을 인정한다. 우리는 실무자들이 그러한 모델을 배치할 때 보다 광범위한 사회적 의미를 고려하고 악성 애플리케이션에 대한 안전장치를 구현하도록 권장한다. 구체적으로, 우리 작업에서 이전의 공급원으로 사용하는 확산 모델은 웹스트랩 컬렉션인 LAION(Schuhmann et al., 2021) 데이터셋에서 훈련된다. 데이터셋의 크리에이터가 부적절한 데이터를 걸러내는 최선의 의도에도 불구하고 LAION에는 인종 고정관념, 폭력, 음란물 등 모델들이 내면화하는 데 부적절할 수 있는 콘텐츠가 포함되어 있다. 이러한 문제를 인식하여 유해한 편향과 잘못된 정보의 영구화를 방지하기 위해 그러한 모델을 사용하는 데 엄격한 조사의 필요성을 강조한다.\n' +
      '\n' +
      '## Reproducibility statement\n' +
      '\n' +
      '소스 코드 및 전처리 모델은 [https://github.com/tomtom1103/목적 및 수정](https://github.com/tomtom1103/목적 및 목적 정복)에서 찾을 수 있다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* 카사르 등 (2018) 홀거 카사르, 자스퍼 의자르, 비토리오 페라리 등이 있다. 코코스타프: 트싱과 아이템 클래스는 맥락입니다. 컴퓨터 비전 및 패턴 인식_, pp. 1209-1218에 대한 IEEE 회의의 _검토에서 2018.\n' +
      '* 다라리왈과 니콜(2021) 프라풀라 다라리왈과 알렉산더 니콜이 있다. 확산 모델은 이미지 합성에서 게이스를 이겼다. __확산 모델이 이미지 합성에서 게이스를 꺾었다. 2021년 신경망 정보 처리 시스템_, 34:8780-8794의 발전이다.\n' +
      '*판 등은 하오샹, 지안화순, 루홍왕, 명하오고우, 용루리, 쿠후루루 등이 있다. 인타보스트: 확률 맵을 통한 부스트 인스턴스 분할은 카피 포스팅을 안내했다. 컴퓨터 비전_, pp. 682-691에 대한 IEEE/CVF 국제 회의의 _검토에서 2019.\n' +
      '* 고엘 등은 (2023) 비디트 고엘, 엘리아 페루조, 예판 장, 데지아 주, 니쿠 세베, 트레보 다렐, 장양 왕, 후미프리 시이를 밝혔다. 페어 확산: 구조 및 응용 쌍 확산 모델이 있는 대상 수준 이미지 편집: __ 구조 및 활용 쌍 확산 모델이 있다. arXiv 프리프린트 arXiv:2303.17546_, 2023.\n' +
      '* 굿펠로우 등 (2014) 이안 굿펠로우, 장푸겟-아아디, 메흐디 미자, 빙쉬, 다비드 워드-팔리, 셔질 오제르, 아론포빌, 요슈화 벤지오 등이 있다. Al_ 생성적 역관망 __ 생성적 역관망. _2. 신경 정보 처리 시스템_, 2014년 27.\n' +
      '* He et al. (2016) 키밍 하이, 샹유 장, 샤오킹 르, 지안 선. 이미지 인식을 위한 심잔차학습. 컴퓨터 비전 및 패턴 인식_, pp. 770-778에 대한 IEEE 회의의 _발표 2016.\n' +
      '* 헤셀 등은 (2021) 잭 헤셀, 아리 홀츠만, 맥스웰 포브스, 로난 르 브루스, 예진 최씨 등이다. 클립스코어: 영상 자막을 위한 기준 없는 평가 메트릭. __영상 자막을 위한 기준 없는 평가 메트릭. arXiv 프리프린트 arXiv:2104.08718_ 2021.\n' +
      '* Heusel et al.(2017) 마르틴 Heusel, Hubert Ramsauer, 토머스 유니터타이너, 베르나르 네슬러, 세파 호흐레이터. 2개의 시간 규모의 업데이트 규칙에 의해 훈련된 팬은 로컬 nash 평형으로 수렴한다. _ 시간 규모의 업데이트 규칙에 의해 수렴된다. 신경 정보 처리 시스템_, 30, 2017의 발전.\n' +
      '*호앤살리만스(2021) 조나단 호와 팀 살리만스. 고전기가 없는 확산 안내입니다. 2021년 딥 유전체 모델 및 다운스트림 애플리케이션_의 _NeurIPS 2021 워크숍에서입니다.\n' +
      '* 헤셀 등은 (2018)*호 등 (2020) 조나단호, 아약 자인, 피에터 압벨 등이 있다. 덴노징 확산 확률적 모델 __데노징 확산 확률적 모델. _<덴도징 확산 확률적 모델. 신경 정보 처리 시스템_, 2020:6840-6851의 발전.\n' +
      '*호 등은 (2022) 조나단호, 치토완 사하라리아, 윌리엄 찬, 데이비드 J 플렛, 모하마드 노루지, 팀 살미만 등이 있다. 고충도 이미지 생성을 위한 __고충도 이미지 생성을 위한 카스캅드 확산 모델. __고충도 이미지 생성을 위한 카스캔 확산 모델. 기계 학습 연구 저널 23(1):2249-2281, 2022.\n' +
      '*황 등은 (2023) 리앙화황, 디첸, 유류, 유준 선, 델리 자오, 진렌 주 등이 있다. 컴퓨터: 합성 가능한 조건을 가진 창의 및 제어 가능한 이미지 합성. __ 구성 요소: 합성 가능한 조건을 갖는 창의 및 제어 가능한 이미지 합성. arXiv 프리프린트 arXiv:2302.09778_, 2023.\n' +
      '* 김씨(2018) 한주킴, 민규김, 동주서, 진웅김, 흥석공원, 소은공원, 현우조, 경현김, 원길양, 영관김 등 실세계 사례연구와 함께 mlaas 플랫폼 알. Nsml. arXiv 프리프린트 arXiv:1810.09957_ 2018.\n' +
      '*케터인 등은 유발 케스테인, 아담 폴리크, 우리엘 싱어, 샤불랜드 마티아나, 조 펜나, 오머 레비 등이 있다. 픽-아-픽: 텍스트-이미지 생성을 위한 사용자 선호도의 공개 데이터셋. __ 텍스트-이미지 생성을 위한 사용자 선호도의 오픈 데이터셋. arXiv 프리프린트 arXiv:2305.01569_, 2023.\n' +
      '*리 등은 유정리, 하오티 류, 칭양우, 포저우 무, 지안웨이 양, 지안펑 가오, 춘유안 리, 용재 이씨 등이다. 리펜: 오픈셋 접지 텍스트 대 이미지 생성입니다. 컴퓨터 비전 및 패턴 인식_, pp 22511-22521, 2023에 대한 IEEE/CVF 회의의 _발표에서.\n' +
      '* 린 등은 (2014) 타성이린, 마이클 마이어, 세르게 벨롱기, 제임스 하이이스, 피에트로 페로나, 데바 라만, 프리오르 딜, 코렌스 지트닉 등이 있다. 마이크로소프트 코모: 맥락상 공통 객체. "컴퓨터 비전-ECCV 2014: 제13차 유럽 회의, 스위스 취리히, 2014년 9월 6-12일, 제작, 파트 V 13_, pp 740-755. 스프링거 2014.\n' +
      '* 마우 등은 (2023) 총무, 신타오 왕, 리앙빈 시, 지안 장, 중앙기, 예잉 샹, 샤오후 키이다. T2i 어댑터: 텍스트 대 이미지 확산 모델에 대한 더 통제 가능한 능력을 파내기 위한 학습 어댑터. __이미지 확산 모델을 위한 학습 어댑터. arXiv 프리프린트 arXiv:2302.08453_, 2023.\n' +
      '* 니콜 등은 (2021) 알렉스 니콜, 프라풀라 다라리왈, 아디아 레즈, 프란나브 시섀, 파멜라 미슈킨, 밥 맥그루, 아이라이아 세이츠케버, 마크 첸 등을 들 수 있다. 글라이드: 광자론적 이미지 생성 및 텍스트 유도 확산 모델 편집. __안드로드 광자론적 이미지 생성. arXiv 프리프린트 arXiv:2112.10741_ 2021.\n' +
      '*니우 등은 (2021) 리니누, 원옌 콩, 류 류, 옌홍, 보장, 징량, 리칭 장 등이 있다. 이미지를 다시 현실로 만드는 __ 딥 이미지 구성에 대한 종합조사: 심층 이미지 구성에 대한 종합조사. arXiv 프리프린트 arXiv:2106.14490_ 2021.\n' +
      '* 박씨 등은 (2019) 태성공원, 명유류, 투잉춘왕, 준야후 등이 있다. 공간적으로 적응적인 정상화를 가진 로맨틱 이미지 합성입니다. 컴퓨터 비전 및 패턴 인식_, pp. 2337-2346에 대한 IEEE/CVF 회의의 _검토에서 2019.\n' +
      '* 포델 등은 (2023) 더스틴 포델, 지온 영어, 카일 레이시, 안드레아스 블라트만, 팀 도코렌, 조 뮬러, 조펜나, 로빈 람바흐 등을 들 수 있다. 고해상도 이미지 합성을 위한 잠재 확산 모델 개선: __고해상도 이미지 합성을 위한 잠재 확산 모델 개선. arXiv 프리프린트 arXiv:2307.01952_, 2023.\n' +
      '* Qin et al.(2020) Xue빈 Qin, Zichen Zhang, Chenyang Huang, 마사드 드하건, 오스마르 R Zaiane, 마르틴 자이르랜드. U2-net: 유리체 객체 검출을 위해 중첩된 u-구조로 더 깊이 계발한다. 패턴 인식_, 106:107404, 2020.\n' +
      '* Radford et al.(2021) 알레크 라드포드, 종욱 김, 크리스 홀리스, 아디아 레즈, 가브리엘 고, 샌히니 아가왈, 기리시 사스트리, 아미다 아셀, 파멜라 미슈킨, 잭 클라크 등 자연 언어 감독으로부터 시각적 모델을 전수할 수 있다. 머신러닝_, pp. 8748-8763에 관한 _국제회의에서 2021년 PMLR.\n' +
      '* 라즈(2022) 아디야 레즈, 프라풀라 다라리왈, 알렉스 니콜, 케이시 추, 마크 첸 등이 있다. 클립 래치들을 가진 __ 계층적 텍스트-조건 이미지 생성  _ 클립 래치들을 갖는 계층적 텍스트-조건 이미지 생성이다. arXiv 프리프린트 arXiv:2204.06125_, 1(2):3, 2022.\n' +
      '* 러프트릴 et al. (2020) Rene Ranftl, Katrin Lasinger, 데이비드 하프너, 콘래드 슈딘들러, 블라디미르 칼튼 등이 있다. 우수한 단안 깊이 추정: 0-샷 교차-다타세트 전달을 위한 고정 데이터 세트: 0-샷 교차-다타세트 전달을 위한 고정 데이터셋이다. 패턴 분석 및 기계 지능_, 44(3):1623-1637, 2020에 대한 IEEE 거래.\n' +
      '* 라메쉬 등은 (2020)* 롬바흐 등 (2022) 로빈 라이바흐, 안드레아스 블라트만, 도미니크 로렌츠, 패트릭 에저, 보쯔 오머 등이다. 잠재 확산 모델을 사용한 고해상도 이미지 합성입니다. 컴퓨터 비전 및 패턴 인식_ pp 10684-10695에 대한 IEEE/CVF 회의의 _발표에서 2022년 pp. 10684-10695.\n' +
      '* Ronneberger et al. (2015) Olaf Ronneberger, 필리필 피셔 및 토머스 Brox. U-net: 생물의학적 이미지 분할을 위한 콘볼루션 네트워크. E_ 의료 이미지 컴퓨팅 및 컴퓨터 보조 개입-MICCAI 2015: 제18차 국제 회의, 뮌헨, 독일, 2015년 10월 5-9일, 합의, 부분 III 18_ pp. 234-241. 스프링거.\n' +
      '* 사하라리아 등은 윌리엄 샤아리아, 윌리엄 찬, 소라바 시세나, 라라 리, 자 휘앙, 에밀릴 리, 카마르 게르미포, 라파엘 게티조 로프, 버쿠 카가골 아얀, 팀 살림산 등 언어 이해가 깊은 포토어리스틱 텍스트 대 이미지 확산 모델. 신경정보처리시스템_, 2022년 35:36479-36494의 효과.\n' +
      '* 살리만스 등 (2016) 팀 살리만스, 이안 굿펠로우, 우제키 자레마바, 비키 체웅, 알레크 라드포드, 시 첸 등이 있다. 간을 훈련시키기 위한 개선된 기술 __ ＆개선된 기술. 신경 정보 처리 시스템_, 29, 2016의 발전이다.\n' +
      '* 슈하만 등은 (2021) 크리스토프 슈하만, 리처드 베르누, 로메인 베아룸트, 로베르트 카카마키크, 클레이튼 갈리스, 아루시 카타, 테오 코바스, 제니아 지트세프, 아란 코마쓰자키 등이다. 라온-400m: 클립 필터링된 4억 이미지-텍스트 쌍의 오픈 데이터셋. __ 클립 필터링된 4억 이미지-텍스트 쌍. arXiv 프리프린트 arXiv:2111.02114_ 2021.\n' +
      '* 소울-디케스타인 등은 (2015) 자스차 소힐-디키슈타인, 에릭 웨이스, 니루 마세사야탄, 사리아 강리 등이 있다. 비평형 열역학을 이용한 심층 비지도 학습. 머신러닝_, pp. 2256-2265에 관한 _국제회의에서 2015. PMLR.\n' +
      '* 송 등은 송(2020)의 지밍 송, 첸린 멍, 스테파노 에르몬 등이 있다. 덴노징 확산 암묵적인 모델입니다. 2020학년도 _국제학습설명회 회의.\n' +
      '* 송 등은 (2022) 요시송, 지페리 장, 저장린, 스콧 코헨, 브라이언 가격, 지밍 장, 수예 김, 다니엘 알리가 등이다. 객체: 유전자 합성 __유전적 객체: 유전적 객체 합성. arXiv 프리프린트 arXiv:2212.00932_, 2022.\n' +
      '* 수보로프 등은 (2022) 로마 수보로프, 엘리자베타 로바바, 안톤 마시크신, 아나스타시아 레미자바, 아르세니 아슈카, 알레세 실레트로프, 내진 콩, 하셜 곡가, 기웅 공원, 빅토르 레미츠키 등을 들 수 있다. 진화-로버는 대형 마스크를 푸리에 컨볼로 담백합니다. 컴퓨터 비전_, pp 2149-2159의 적용에 대한 IEEE/CVF 겨울 회의의 _발표에서 2022년.\n' +
      '* Szegedy et al. (2016) 크리스티안 Szegedy, 빈센트 반우케, 세르게이 이오프, 조온 샤넨스, 지비뷰 우자나. 컴퓨터 비전을 위해 인셉션 아키텍처를 생각하십시오. 컴퓨터 비전 및 패턴 인식_, pp. 2818-2826에 대한 IEEE 회의의 _검토에서 2016.\n' +
      '* 바스완이 등은 (2017) 아샤시 바소와이, 노암 샤제리, 니키 파마르, 작노 우즈코레이트, 리온 존스, 디단 노 고메즈, 루카즈 카이저, 일리아 폴로숙신 등이 있다. 필요한 것이 전부입니다. __ 주의가 필요합니다. __ 주목된다. 신경 정보 처리 시스템_, 30, 2017의 발전.\n' +
      '* 왕 등은 (2004) 저우왕, 알란 C 보비크, 하미드 리시크, 에로 피시몬셀리 등이 있다. 이미지 품질 평가: 오류 가시성부터 구조적 유사성까지. _이미지 품질 평가: 오류 가시성부터 구조적 유사성까지이다. 이미지 처리_, 13(4):600-612, 2004에 대한 IEEE 트랜잭션이다.\n' +
      '* 양 등은 알(2023)빈신 양, 슈양구, 보장, 투링장, 주진첸, 샤오안 선, 동텐, 포앙 위넨 등이 있다. 예를 들어, 확산 모델을 사용한 예시적인 기반 이미지 편집입니다. 컴퓨터 비전 및 패턴 인식_ pp 18381-18391, 2023에 대한 IEEE/CVF 회의의 _발표에서.\n' +
      '*Zeng et al.(2023) 유쩡, 저장린, 지안밍 장, 청 류, 존 콜로모세, 제이슨 쿠엔, 비슈알 마텔. Scenecomposer: Any 수준의 의미 이미지 합성입니다. 컴퓨터 비전 및 패턴 인식_, pp 22468-22478, 2023에 대한 IEEE/CVF 회의의 _검토에서.\n' +
      '* 장&아크로라(2023) Lvmin Zhang과 메네쉬 아크로라라. 텍스트 대 이미지 확산 모델에 조건부 제어를 추가하는 _ 이미지 확산 모델. _ 영상 확산 모델에 추가한다. arXiv 프리프린트 arXiv:2302.05543_, 2023.\n' +
      '\n' +
      '*장 등은 (2018) 리처드 장, 필립 아이솔라, 알렉세이 아 에프로스, 에리 셰흐트만, 오리버 왕 등이 있다. 심층적 특징의 불합리한 효과는 지각적 메트릭으로 작용한다. 컴퓨터 비전 및 패턴 인식_, pp 586-595에 대한 IEEE 회의의 _검토에서 2018.\n' +
      '* 자오 등은 (2023) 시하오 자오, 동동 첸, 예운 첸, 지안민바오, 샤오허 하오, 루위안, 관예 K 원 등이 있다. 이미지 확산 모델 __Uni-대조군net: All-in-one 제어가 텍스트 대 이미지 확산 모델에 대한 제어이다. 신경 정보 처리 시스템_, 2023의 발전은 있다.\n' +
      '* 저우 등은 (2021) 도주, 덩필판, 명밍정, 지빙선, 링샤오 등이 있다. Rgb-d 살리믹 객체 검출: A 조사: __Rgb-d 살리믹 객체 검출: A 조사. 컴퓨터 컴퓨터 미디어_, 2021년 7:37-69입니다.\n' +
      '\n' +
      'Appendix\n' +
      '\n' +
      '일단은.\n' +
      '\n' +
      '이미지 구성(Niu et al, 2021)은 단일화된 합성 이미지를 생성하기 위해 주어진 전경을 배경으로 혼합하는 작업을 포함한다. 전통적인 방법은 전형적으로 객체 배치, 이미지 블렌딩/하모니화 및 그림자 생성으로 구성된 순차적 파이프라인을 따른다. 이러한 단계는 두 이미지 컴포넌트 간의 시각적 불일치를 최소화하는 것을 목표로 한다. 최근 생성 모델, 특히 GAN 굿펠로우 등(2014년), DMs 호 등(2020년)의 발전으로 이미지 구성 도전은 생성 과제로 반박되었다. GAN 기반 모델은 연구 기여 수, 확산 기반 모델 측면에서 주도해 온 반면, 오바마스트티 송(2022)과 피인트 바예 양(2023) 같은 작품에서 예시한 바와 같이 이미지 구성을 위한 원샷 솔루션으로서 DM의 가능성을 보여줌으로써 다단계 전통적인 방법으로부터 이탈을 제공한다. 그러나 우리의 접근법은 전형적인 이미지 구성에서 분기된다는 점에 유의해야 한다. 우리의 모델은 전경 및 배경의 뚜렷한 정체성을 보존하기 위한 것이 아니라, 이를 메우기 위한 텍스트 및 글로벌 의미학에 대한 국부적 표현으로 활용한다. 우리의 작업은 본질적으로 다른 과제를 해결하는 것을 목표로 하지만, 우리는 합성 이미지 트리플트를 레버리지하고 생성하고자 하는 타겟 이미지를 처리하는 방식으로 이미지 구성과 평행선을 도출한다.\n' +
      '\n' +
      'CnC에는 결정 사항이 있습니다.\n' +
      '\n' +
      '지방 Fuser.Depth 이젠탕스 트레이닝(DDT)에 대한 자세한 내용은 로컬 퓨저를 훈련시키기 위해 합성 이미지 트리플츠(\\{I_{f},I_{b},M\\}\\)를 침출한다. DDT는 먼저 그림 2와 같이 자체 전경/배경 하천에 \\(I_{f}\\) 및 \\(I_{b}\\)의 깊이 맵을 통합하며 스트림의 특징은 채널 차원을 따라 연결되며 4개의 공간 해상도로 \\(I_{f}\\) 및 \\(I_{b}\\)에 대한 공간적 특징을 모두 통합하는 특징이 추출된다. 추출된 각각의 특징은 이후에 0 컨볼루션 레이어를 통과하며, Zhao et al(2023)에서 수행된 바와 같이 특징 변성 레이어(박 등 2019)를 통해 최종적으로 \\(E^{\\prime}\\)에 통합된다. 냉동 SD는 잔류 스킵 연결에 의해 통합된 디코더 \\(D\\)에서 \\(E^{\\prime}\\) 및 \\(C^{\\prime}\\)로부터 국부적인 신호를 수신한다. \\(E\\),\\(E\\),\\bf}}\\(D\\) 및\\(C^{\\f}\\)는 각각\\(\\mathbf}}}\\), \\(\\mathbf{d}\\), \\(\\mathbf{d}\\) 및 \\(\\mathbf{f}\\)의 해당 출력으로 캡처된다.\n' +
      '\n' +
      '종종{d}\\mathrm{d}_{i-1}\\mathbf{d}}\\mathbf{e}}\\mathbf{e}}\\mathbf{e}}{j}}\\mathbf{e}}<\\math{e}}{j}}{math{c}}{math{e}}{math{e}}{mathbf{e}}{math{e}}}{mathbf{e}}{math{e}}{mathbf{e}}{d{e}}{d{e}}{d{e}}{d{e}}{d{e}}{d{e}}{math{d{e}}}{d{e}}}{d{e}}}}{d{d{e}}}{d{d{e}}}}}{d{d{e}}}}{d{d{e}}}}}{d{d{e}}}}}}\n' +
      '\n' +
      '글로벌 퓨저에 대한 자세한 내용은 아래의 글로벌 퓨저를 훈련시키기 위해 교차 의도 계층에 소프트 가이드를 통합하는 과정을 요약하는 알고리즘을 제공한다.\n' +
      '\n' +
      '```\n' +
      '\\(I_{s}}}\\),\\(I_{s}\\), \\(I_{s}}=1\\), \\(I_{f{g}), \\(I_{{t}=1\\), \\(\\mathda_{text{g}), \\(\\mathda_{text{g}) \\(I_{ff} <\\), \\(I_{t}=1\\), \\) \\(I_{t}=1\\), \\(I_{t}) \\(I_\\) \\) \\(I_\\) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(I) \\(\n' +
      '1:\\(E_{s},E_{b}) 사다리꼴 상징체{CLIP 이미지 인코더}(I_{s},I_{b})\n' +
      '2:\\((\\mathbf{y}_{\\text{fg}},\\mathbf{y}_{\\text{bg}})\\leftarrow\\textsc{Global Fuser}(E_{s},E_{b})\\)\n' +
      '}(\\mathbf{y}_{\\text{illcat})\\(\\lambda_{\\text{fg}\\mathbf{fg}_{\\text{fg}}\\lambda_{\\text{fg}}\\lambda_{\\text{bg}}\\mathbff{g}_{\\text{g}_{\\text{bg}_{\\text{g}_{\\text{fg}):\\mathbath{ff}_{\\text{g}.\n' +
      '4: \\(E,C,D\\)도(E,C,D\\)도(E,C,D\\)도 \\(E,C,D\\)도의 모든 교차 선택 계층에 대한 4: \\(E,C,D\\)도에서 모든 교차 선택 계층에 대한 것이다.\n' +
      '5:\\((Q,K,V)\\leftarrow(W_{Q}\\cdot\\mathbf{z}_{t},W_{K}\\cdot\\mathbf{y}_{\\text{full}},W _{V}\\cdot\\mathbf{y}_{\\text{full}})\\)\n' +
      '6:\\(S\\leftarrow(QK^{T}/\\sqrt{d})\\)\\(\\triangleright\\)\\(S\\in\\mathbb{R}^{i\\times j}\\)\n' +
      '7:\\(J\\leftarrow\\mathbf{1}^{i\\)의\\(J\\)를 모든 매트릭스(j-2N)로 구분한다.\n' +
      '8:\\(M) 자작나무 갈매기{Reshape}\\),\\(\\mathrm{Flatten}),\\(M)\\(\\matholdbb{B},^{{i\\i\\)\n' +
      '9:\\(M^{\\prime}\\leftarrow\\mathrm{concat}(J,\\varphi(M),1-\\varphi(M))\\)\n' +
      '10:\\(S^{\\prime} 경쟁자 M^{\\prime}\\)\n' +
      '11:\\(\\mathbf{z}_{t}\\leftarrow\\mathrm{softmax}(S^{\\prime})\\cdot V\\)\n' +
      '12:endfor\n' +
      '```\n' +
      '\n' +
      'I_{s}\\(I_{s}\\)의 단일 훈련 시간표(I_{b}\\)를 생성하기 위해 \\(I_{b},I_{f},I_{b}, M\\})에 \\(I_{b}\\)을 사용하여 표적 프롬시를 위해 특별히 훈련된 SD의 변이체를 사용하여 "빈경치, 고도로 상세하지 않은 사람"으로 설정한다. 또한 널리 채택된 인포팅 모델인 라마(수보로프 등 2022년)를 테스트하고 \\(I_{b}\\) 깊이 맵의 품질을 중심으로 인포팅 모듈로서의 적합성을 측정합니다. 그림 9에서 라마에서 생성된 \\(I_{b}\\)가 파이프라인의 요구 사항과 잘 정렬되지 않을 수 있는 특정 유물을 나타낸다는 것을 관찰했다. 라마의 주목할 만한 특징은 \\(I_{b}\\)의 깊이 맵이 종종 염기성 물체의 모양을 유지하여 로컬 퓨저로 중계된 정보에 영향을 미칠 수 있다는 것이다. 한편, SD 인포팅 모듈은 \\(I_{b}\\)의 생성에 대한 접착을 증명한다. 그림 9의 1열 \\(I_{b}\\)를 중심으로 \\(I_{s}\\)에 한 번 존재하지 않는 특정 객체가 생성되었음을 알 수 있다. SD의 인포팅 모듈의 이러한 속성은 깊이 있는 무력화 훈련으로 레버리지에 매력적이라고 생각하는데, 두드러진 물체의 상대적 배치에 대한 정보를 증류하기 위해서는 우리의 모델이 훈련 중에 두드러진 객체에 의해 폐색된 _see_ 오브젝트가 효과적으로 유지되도록 하는 것이 중요하다. 합성 이미지 트리플트 생성 파이프라인의 시각화를 위해 그림 8을 확인할 수 있다.\n' +
      '\n' +
      '### Additional Results\n' +
      '\n' +
      '보다 정량적 결과는 표 3의 Pick-a-Pic 검증 세트에 대한 추가 정량적 결과를 제공하고 있으며, COCO-Stuff 검증 세트에 대한 경향에 따라 깊이 전용 실험의 FID 및 IS 값을 제외하고 모든 메트릭에서 다른 모델에 비해 적절한 모델을 제공한다. 흥미로운 사실은 표 1에 나타난 COCO-Stuff 검증 결과를 비교할 때 각 모델의 성능 순위가 크게 일치함을 관찰했다. 그러나 FID 및 IS 메트릭에 대한 특정 값은 크게 악화되는 반면 CLIP 스코어는 주목할만한 개선을 보여준다. 이러한 경향의 한 가지 잠재적인 이유는 이러한 메트릭에 사용된 인셉션-V3(Szegedy et al, 2016)과 같은 미리 학습된 모델의 기본 특성과 관련이 있다. 이 실험에서 비교되는 두 이미지 세트는 합성이지만 이러한 모델은 실제 이미지, 본질적으로 실제 이미지 특징 및 패턴을 캡처하는 실제 이미지 상에서 훈련된다. Pick-a-Pic 이미지의 합성 특성은 이러한 실제 기대에서 상당히 분기될 수 있으며, 따라서 인플루언서가 나타날 수 있다.\n' +
      '\n' +
      '그림 8: 합성 이미지 트리플트를 생성하는 프로세스입니다.\n' +
      '\n' +
      '그림 9: 인포팅에 대한 라마 및 SD의 비교 및 해당 깊이 맵이다. 라마에 의해 침투된 이미지는 두드러진 물체를 제거하는 것처럼 보이지만, 그들의 대응하는 깊이 맵에는 두드러진 물체의 유물이 포함되어 있다.\n' +
      '\n' +
      'FID 점수를 매길 수 있습니다. 더욱이 비교 중인 두 데이터 세트가 합성이라고 하더라도 합성 Pick-a-Pic 데이터세트에서의 특징의 분산과 분포는 일반적인 실제 데이터 세트와 충분히 구별되어 FID 및 IS 점수의 관찰된 차이를 초래할 수 있다. 이는 합성 데이터 세트 대 실제 데이터 세트에 대한 모델을 평가하는 것과 관련된 뉘앙스를 강조하며 그러한 평가에서 결론을 도출할 때 신중한 고려가 필요함을 강조한다.\n' +
      '\n' +
      'Fig. 10에서 우리는 유니 컨트롤넷에 대한 지역 조건의 사용을 통해 다른 조건에서 물체를 배치할 수 있는 모델의 능력을 비교한다. 유니 컨트롤넷은 7개의 지역 조건에서 취할 수 있으며 그림 10에 나열된 로컬 조건 쌍이 상충되는 조건인 _i._i._2개의 중복된 물체를 처리하는 데 가장 강력하다고 보고한다. 일부 샘플은 상대방에 놓인 전경 국부 상태를 보여주지만 유니 컨트롤넷은 종종 샘플에서 깊이감을 전달하지 못하여 동일한 z축에서 두 개체가 생성될 수 있다. 한편, 조건화된 두 깊이 맵이 상대적으로 동일한 깊이 값을 가지더라도 우리의 모델은 배경 깊이 맵의 겹치는 부분을 일관되게 제압할 수 있다.\n' +
      '\n' +
      '그림 11에서 재구성 실험에 대한 추가 세부 정보는 섹션 4.2에서 자세히 추출한 깊이 맵의 추가 샘플을 제공하지만, MiDaS에서 생성된 깊이 맵은 물체의 실제 메트릭 깊이를 반영하지 않지만, 훈련 중 자신에게 노출된 이미지와 깊이 맵을 얼마나 잘 반영하는지에 대한 지상 진리 이미지의 깊이 맵과 재구성된 이미지를 비교한다. 기준선 모델의 재구성된 깊이 맵은 물체의 전체 형태를 유지하지만, 우리의 모델은 두드러진 객체에 대한 영역의 상대적 깊이를 캡처하는 데 성공함을 알 수 있다. 또한 MAE를 재구성 품질을 가늠하기 위한 메트릭으로 선택하는 데 있어 우리의 선택을 설명한다. USDaS에 의해 생성된 깊이 맵은 위에서 언급한 바와 같이 메트릭 깊이를 예측하지 않지만, 우리의 모델 및 기준선 모델은 이미지 심층 맵 쌍에 기초하여 이미지를 생성하기 위해 훈련되었다. 깊이 지도는\n' +
      '\n' +
      '그림 10: Uni-대조군Net에 대한 국부적 조건의 주문 능력을 비교한다. 유니 컨트롤넷은 열거된 조합이 7개의 지역 조건의 다른 조합에 대해 가장 효과적이라고 보고한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c c|c c c|c c c} Model/Condition & \\multicolumn{3}{c|}{Depth} & \\multicolumn{3}{c|}{Semantics} & \\multicolumn{3}{c}{Depth+Semantics} \\\\  & FID (\\(\\downarrow\\)) & IS (\\(\\uparrow\\)) & \\multicolumn{2}{c|}{CLIP} & \\multicolumn{2}{c|}{FID (\\(\\downarrow\\))} & IS (\\(\\uparrow\\)) & \\multicolumn{2}{c|}{CLIP} & \\multicolumn{2}{c}{FID (\\(\\downarrow\\))} & IS(\\(\\uparrow\\)) & \\multicolumn{2}{c}{CLIP} \\\\  & FID (\\(\\downarrow\\)) & IS (\\(\\uparrow\\)) & \\multicolumn{2}{c|}{Score (\\(\\uparrow\\))} & \\multicolumn{2}{c|}{FID (\\(\\downarrow\\))} & \\multicolumn{2}{c|}{Score (\\(\\uparrow\\))} & \\multicolumn{2}{c}{FID (\\(\\downarrow\\))} & \\multicolumn{2}{c}{IS(\\(\\uparrow\\))} & \\multicolumn{2}{c}{Score (\\(\\uparrow\\))} \\\\ \\hline GLIGEN & 22.540 & 12.733 & 28.227 & - & - & - & - & - & - \\\\ ControlNet & **21.183** & **13.685** & 28.112 & - & - & - & - & - & - \\\\ Uni-ControlNet & 24.561 & 13.260 & 28.053 & 28.964 & 12.809 & 25.245 & 22.808 & 12.006 & 26.722 \\\\ T2I-Adapter & 26.262 & 13.309 & 28.017 & 47.996 & 11.408 & 25.033 & 34.698 & 10.745 & 26.583 \\\\ \\hline Cnc & 28.192 & 11.460 & 27.347 & 36.272 & 10.353 & 24.301 & 25.524 & 11.131 & 27.109 \\\\ CnC Finetuned & 32.155 & 11.512 & **28.274** & **26.042** & **12.838** & **27.681** & **22.484** & **12.602** & **28.094** \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: Pick-a-Pic 밸브 세트에 대한 평가 메트릭. 우리는 이러한 조건을 지원하지 않는 모델로 인해 GLIGEN과 ControlNet에서 의미론적 및 깊이+제학 결과를 생략한다. 가장 큰 결과는 **bold***입니다.\n' +
      '\n' +
      '지상 진리 깊이 맵이 주어진 모델 "예측자" 깊이 지도가 얼마나 잘 되는지 생각해 볼 수 있으며, 이는 다시 모델이 이미지와 깊이 맵 간의 관계를 얼마나 잘 학습했는지 나타낸다. 그림 12에서 우리는 MAE 측면에서 그라운드 진리 깊이 맵이 재구성된 깊이 맵과 얼마나 유사한지 간의 관계를 시각화한다. 각 세트는 가장 낮은/가장 낮은 MAE 값을 갖는 상위 50쌍에서 무작위로 선택되었다. 가장 낮은 깊이 맵(MAE) 점수를 가진 쌍은 복원된 이미지가 그라운드 진리 이미지에 존재하는 상대 깊이를 충실히 묘사하는 등 재구성 품질을 직접적으로 초래한다는 것을 알 수 있다. 반면, MAE 점수가 가장 높은 쌍은 하위 비교 재구성된 이미지를 초래한다. 그림 12(b)의 두 번째 행을 예로 들면, 복원된 이미지는 지상 진리 이미지에 존재하는 나무와 사람의 상대적 깊이를 포착하는 데 실패함을 알 수 있다.\n' +
      '\n' +
      '### Ablation Study\n' +
      '\n' +
      '다양한 공간 조건에서 물체를 공간 영역으로 효과적으로 주문하는 우리의 모델의 능력은 공간적 정보의 공간적 정보가 증류된 깊이 무력화 훈련에서 비롯되며, 배후에 있는 것은 로컬 퓨저의 각각의 하천으로 증류된다. 이를 위해 해당 조건이 이미지의 공간 정보를 보유하고 있다는 점을 감안할 때, 우리의 모델은 다양한 유형의 지역 조건에 대해 학습될 수 있음을 알 수 있다. 우리는 로컬 퓨저의 능력을 탐색하고 그림 13의 깊이 맵과 비교하여 캐니 모서리에 대한 훈련의 영향을 보여주는데, 이 가장자리의 값이 바이너리인 방식으로 깊이 맵과 다른 특성과 편향을 보유하며 더 미세한 등급이 매겨진 디테일로 깊이를 나타내는 능력을 차단한다. 이러한 특성 때문에 DDT는 캐니 모서리에도 물체의 상대적 배치를 배우는 반면, 캐니 모서리를 사용하는 것은 고유한 장단점을 가지고 있음을 알 수 있다. 그림 13(a)와 (c)는 깊이 지도를 사용하는 것이 선호되는 경우를 보고하고, (b)와 (d)는 반대 의견을 보고한다. 우리는 사과가 비교적 평평해 보이는 경우(c)와 같이 깊이의 감각을 생성하는 데 종종 실패한다는 것을 알게 된다. 그러나, 이 속성은 평평하게 시작하는 베이스 이미지를 레버링할 때 선호될 수 있다. 그림 13(b)와 (d)는 이러한 사례를 보여주는데, 여기서 평탄한 베이스 이미지들의 깊이 맵들( 포스터 및 벡터 그래픽들 등)은 공간 정보를 캡처하지 못하여 하위-파라 이미지를 생성한다. DDT가 쇠약함 또는 깊이 지도가든 주어진 표현의 유도적 편향을 효과적으로 레버리지할 수 있고 특별한 경우 DDT가 주어진 표현의 변이체를 효과적으로 레버리지할 수 있다는 것을 발견했다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c c|c c c}  & \\multicolumn{3}{c|}{COCO-Stuff} & \\multicolumn{3}{c}{Pick-a-Pic} \\\\ Model/Condition & FID (\\(\\downarrow\\)) & IS (\\(\\uparrow\\)) & CLIPScore (\\(\\uparrow\\)) & FID (\\(\\downarrow\\)) & IS (\\(\\uparrow\\)) & CLIPScore (\\(\\uparrow\\)) \\\\ \\hline Uni-ControlNet (Canny Edge) & **17.119** & **30.440** & 25.726 & 21.955 & **12.469** & 28.517 \\\\ T2I-Adapter (Canny Edge) & 20.051 & 28.449 & 25.850 & 30.547 & 12.230 & 28.412 \\\\ \\hline\n' +
      '**CnC (Canny Edge, Ours)** & 17.745 & 29.809 & **26.283** & **20.501** & 12.215 & **28.786** \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: COCO-Stuff 및 Pick-a-Pic 밸브 세트에 대한 캐니 에지 평가 메트릭. 가장 큰 결과는 **bold***입니다.\n' +
      '\n' +
      '그림 11: 재구성된 이미지에서 추출한 깊이 맵의 정성적 비교는 그림이다.\n' +
      '\n' +
      '그림 12: 깊이 맵 쌍의 정성적 비교는 각 데이터 세트에서 가장 낮은/가장 높은 MAE 값을 나타낸다. 각 세트는 각각 COCO-Stuff 및 Pick-a-Pic의 가장 낮은/가장 높은 MAE 값의 상위 50쌍에서 무작위로 선택되었다.\n' +
      '\n' +
      '그림 13: 로컬 퓨저의 표현으로서 캐니 엣지에 대한 구조 연구는 다음과 같다. (a)와 (c)는 깊이 맵이 더 나은 이미지를 생성하는 경우를 보고하고 (b)와 (d)는 캐니 모서리가 선호될 수 있는 사례를 보고한다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:20]\n' +
      '\n' +
      '그림 15: 갈등 의미론. 전경 글로벌 시맨틱 이미지는 용암이 흐르는 이미지이고, 배경 글로벌 시맨틱 이미지는 눈밭의 이미지이다. 우리는 텍스트 프롬프트를 "화산"으로 수정하고 하이퍼파라미터 \\(\\lambda_{\\text{fg}}\\)와 \\(\\lambda_{\\text{bg}}\\)의 효과를 보여준다.\n' +
      '\n' +
      '그림 16: 상충되는 의미와의 소프트 지도의 효과와 각각의 평균 코사인 유사성 점수에 대한 추가 결과는 그림 16이다. 우리는 로컬 퓨저 내의 각 스트림에 대해 동일한 깊이 이미지를 조건화하고 신속한 컨디셔닝 없이 샘플을 생성한다.\n' +
      '\n' +
      '그림 17: 제11 맵 표현. 우리는 우리의 모델이 다양한 버전의 깊이 맵과 잘 일반화된다는 것을 발견한다. Version 1은 \\(I_{s}\\)에서 추출한 깊이 맵을 의미한다. Version 2는 \\(I_{f}\\)에서 추출한 깊이 맵을 의미한다. Version 3은 \\(M\\otep\\mathrm{ 심층맵}(I_{f})\\에서 추출한 깊이 지도를 의미한다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:23]\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>