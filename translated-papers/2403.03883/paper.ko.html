<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '#SaulLM-7B: 법을 위한 선구적인 대규모 언어 모델\n' +
      '\n' +
      '피에르 콜롬보\\({}^{1,2,}\\) 텔모 페소아 피레스\\({}^{1,}\\) 말릭 부디아프\\({}^{1,}\\)\n' +
      '\n' +
      '도미닉 컬버\\({}^{1,*}\\) 루이 멜로\\({}^{1,*}\\) 카이오 코로\\({}^{3}\\) 안드레 F. T. 마르틴\\({}^{4}\\) 파브리치오 에스포시토\\({}^{5}\\) 베라 루시아 라포소\\({}^{5}\\) 소피아 모르가도\\({}^{1}\\) 마이클 데사\\({}^{1}\\)\n' +
      '\n' +
      'Equall.ai, New York, Paris, Lisbon, Lisbon\n' +
      '\n' +
      'Universite Paris-Saclay의 MICS, CentraleSupelec\n' +
      '\n' +
      'Sorbonne Universite, CNRS, ISIR, Paris\n' +
      '\n' +
      '유니버시다드 드 리스보아\n' +
      '\n' +
      '리스보아 NOVA 법학전문대학원\n' +
      '\n' +
      'firstname@equall.ai\n' +
      '\n' +
      'Equal contribution.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '본 논문에서는 법률 영역에 맞춘 LLM(Large Language Model)인 SaulLM-7B를 소개한다. 70억 개의 매개변수로 SaulLM-7B는 법률 텍스트 이해 및 생성을 위해 명시적으로 설계된 최초의 LLM이다. Mistrat 7B 아키텍처를 기반으로 SaulLM-7B는 300억 토큰 이상의 영어 법률 코퍼스에 대해 교육을 받습니다. SaulLM-7B는 법률 문서를 이해하고 처리하는 데 최첨단 능력을 보여준다. 또한, 법적 작업에서 SaulLM-7B의 성능을 더욱 향상시키기 위해 법적 데이터 세트를 활용하는 새로운 교육 미세 조정 방법을 제시한다. SaulLM-7B는 MIT 라이센스로 출시되었다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '급속하게 진화하는 인공 지능의 풍경에서 대형 언어 모델(LLM)[1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]의 응용은 번역[23], 의료[20], 코드 생성[11, 12]과 같은 다양한 도메인에 걸쳐 큰 발전을 목격했다. 자연어 처리에서 기계 번역에 이르기까지 이러한 모델은 인간과 유사한 텍스트를 이해하고 생성하는 데 탁월한 능력을 발휘했다[21, 13, 15]. 그러나 이 변형 기술의 완전한 이점을 아직 경험하지 못한 한 분야는 법적 영역[16, 17]이다. 법조인들이 끊임없이 증가하는 복잡한 문서의 양과 씨름함에 따라, 법률 자료를 탐색하고 해석하는 데 도움이 될 수 있는 전용 LLM에 대한 필요성이 증가하고 있다[23, 24, 25].\n' +
      '\n' +
      '이 논문에서는 공개적으로 사용할 수 있는 최초의 법적 LLM을 개발하기 위한 선구적인 이니셔티브를 제시한다. 독특한 구문 및 전문 어휘를 특징으로 하는 법률 텍스트는 뚜렷한 언어적 도전을 제시한다[13, 14]. 우리의 접근법은 미국, 캐나다, 영국, 유럽과 같은 영어권 관할 구역의 전용 법률 코퍼스를 사용하여 광범위한 사전 훈련[16, 20]에 중점을 둔다[15, 17]. 우리 팀은 물론 이전 문헌에서 긁어낸 크고 다양한 법률 데이터 세트에 대한 사전 교육을 활용하면 LLM인 SaulLM-7B는 법률 문서의 복잡성을 이해할 뿐만 아니라 진화하는 법률 담론의 특성에 적응하는 것을 목표로 한다.\n' +
      '\n' +
      '법률 실무자의 요구에 초점을 맞추고 전용 법률 코퍼스에 대한 사전 훈련의 힘을 활용함으로써 우리의 작업은 법률 영역의 고유한 요구를 충족하기 위한 중요한 단계를 나타낸다. 우리는 법률에 대한 첫 번째 LLM을 도입하면 법률 전문가에게 권한을 부여할 뿐만 아니라 인공 지능과 법 커뮤니티의 교차점에서 추가 혁신을 촉진하여 법적 언어 이해와 적용에 상당한 기여를 할 것으로 기대한다[18]. 이 작업의 기여도를 요약하면 다음과 같다.\n' +
      '\n' +
      '기여 1: 법적 LLM의 패밀리.본 논문에서는 법적 도메인 내에서 직면하는 독특한 문제를 해결하기 위해 세심하게 제작된 법적 언어 모델 모음인 SaulLM-7B의 패밀리를 소개한다. 우리는 법률 텍스트에 특별히 맞춘 70억 매개 언어 모델인 SaulLM-7B를 공개합니다. 전문 교육 요법으로 SaulLM-7B는 일반 모델에 비해 법적 언어의 뉘앙스에 대한 우수한 이해도를 보여준다. 또한 다양한 법적 작업 1에서 미스트랄 또는 라마와 같은 기존 모델을 능가하도록 신중하게 설계된 명령어 조정 변형인 SaulLM-7B-인스트럭션을 출시한다.\n' +
      '\n' +
      '각주 1: 모델은 [https://huggingface.co/equall](https://huggingface.co/equall)에서 이용 가능하다.\n' +
      '\n' +
      '기여 2: 법률 LLMs에 대한 개선된 평가 프로토콜과 동시에, 우리는 법률 벤치 구하 외(2022, 2023)2의 보충 반복인 법률 벤치-인스트럭션을 소개하며, 언어 모델의 법적 숙련도를 더 잘 측정하고 개선하도록 제작되었으며, 이는 향후 법률 영역에서 연구 발전에 기여하기를 바란다. 법적 맥락에서 모델의 능력을 더욱 풍부하게 하기 위해 특히 국제법, 전문법 3 및 법학에 초점을 맞춘 인기 MMLU 벤치마크 헨드릭 등(2020)의 법적 작업도 평가 프로토콜에 포함한다.\n' +
      '\n' +
      '각주 3: Hendrycks et al.(2020)에서 정의한 바와 같이 여기서 "전문법"이라는 용어를 사용한다.\n' +
      '\n' +
      '기여 3: 모델, 평가 코드 및 라이선싱.광범위한 채택을 촉진하고 혁신을 촉진하기 위해 SaulLM-7B 및 SaulLM-7B-인스트럭션과 MIT 라이선스에 따른 평가 코드를 공개한다. 이러한 개방형 라이선스 접근 방식은 법적 영역 및 그 이상의 광범위한 상업적 및 연구 노력으로 공동 개발 및 채택을 장려한다.\n' +
      '\n' +
      '##2 SaulLM-7B: 언어모델의 법적 능력 확장\n' +
      '\n' +
      'Pythia Biderman et al.(2023)과 같은 백만 개의 매개변수 모델에서 팔콘 Almazrouei et al.(2023)과 같은 180억 개의 매개변수 모델에 이르는 광범위한 오픈 소스 대규모 언어 모델이 백본에 사용할 수 있다. 이 연구에서는 Mistral 7B 모델, 즉 벤치마크 및 작업 장 등(2023)에서 높은 성능을 달성하는 70억 개의 매개변수 오픈 소스 모델을 선택한다.\n' +
      '\n' +
      '그림 1에 표시된 우리의 방법론은 아래에서 설명하는 두 단계 과정을 포함한다.\n' +
      '\n' +
      '미스트랄의 법적 역량 강화\n' +
      '\n' +
      '일반 모델 Touvron et al. (2023); Taylor et al. (2022); Zhang et al. (2022); Gu and Dao (2023); Almazrouei et al. (2023); Zhang et al. (2024); Faysse et al. (2024)는 그들의 훈련 동안 법적 데이터에 약간의 노출을 얻는 반면, 이는 전형적으로 전체 데이터의 작은 부분만을 나타낸다. 법률 업무에 대한 성과를 높이기 위한 간단한 방법은 법률 자료를 중심으로 추가 교육을 수행하는 것이다. 특히 디코더 모델에 초점을 맞춘 이 접근법은 의학 Chen et al. (2023); Ji et al. (2023), 번역 Xu et al. (2023); Wu et al. (2024), 및 코딩 Roziere et al. (2023)과 같은 다양한 분야에서 성공적으로 사용되어 왔다. 이 접근법의 주요 이점은 훈련 데이터의 특정 특성으로부터의 확장성 및 독립성이다. 도메인 적응에 대한 다른 연구는 구실 과제를 통해 언어 모델을 전문화하려고 시도했다. 그러나, 이러한 노력들은 종종 Niklaus 및 Giofre(2023)의 더 작은-스케일 접근법들에 의존하며, 계산적으로 비싼 Vu 등(2020); Lu 등(2023), 또는 확장성이 결여된 Cheng 등(2023); Cui 등(2023); Nishida 등(2019).\n' +
      '\n' +
      '이러한 이유와 웹에서 대규모 법률 코퍼라의 가용성을 위해 우리는 _연속 사전 훈련_에 초점을 맞추기로 결정했다. 다양한 법률 콘텐츠 리포지토리에서 조달한 고품질 데이터 세트를 세심하게 큐레이션합니다. Penedo et al. (2023) 및 중복제거 Mou et al. (2023); Kocetkov et al. (2023)은 엄격한 필터링 후에, 계속된 프리트레이닝을 위한 견고한 기초로서 작용하는 \\(30\\)억 토큰의 코퍼스를 갖게 된다.\n' +
      '\n' +
      '### 법적 지침의 개선\n' +
      '\n' +
      '사용자 요청 및 대화 상호 작용을 지원하기 위해 LLM은 일반적으로 감독된 대화 쌍에 대한 교육을 포함하는 중요한 프로세스인 명령어 튜닝을 거친다. 이 단계는 사용자 질의들 Wang 등(2023); Wei 등(2021); Chung 등(2022); Faysse 등(2023); Ding 등(2023); Wang 등(2023).\n' +
      '\n' +
      '범용 언어 모델의 경우, 다양성과 수업의 질은 Cao et al. (2023); Zhou et al. (2023). 그러나 전문 영역에서 성과를 향상시키기 위해서는 과제별 및 전문화된 프롬프트를 통합하는 것이 중요하다. 우리의 지침 미세 조정 단계는 일반적인(즉, 비합법적) 및 법적 지침의 주요 구성 요소를 포함한다. 전자는 명령에 대한 모델의 이해와 팔로우를 향상시키는 데 도움이 되며 코딩, 수학, 일반 대화 등 다양한 영역의 데이터를 포함한다. 후자의 경우 법적 질문 답변 및 요약 등을 포함하여 법적 도메인의 뉘앙스에 맞춘 광범위한 데이터 세트를 사용한다. 수업 데이터에 대한 이러한 미묘한 미세 조정을 통해, 우리의 모델인 SaulLM-7B-Instruct는 광범위한 관련 작업에서 법적 복잡성을 파악하고 탁월할 수 있다.\n' +
      '\n' +
      '**Remark**: _많은 일반적인 LLMs Tunstall et al. (2023)은 모델을 인간 선호도 Rafailov et al. (2023); Munos et al. (2023); von Werra et al. (2020). 우리의 경우 초기 실험은 성능에 유의미한 향상을 나타내지 않았기 때문에 본 논문을 위해 이 길을 추구하지 않기로 결정했다._\n' +
      '\n' +
      '## 3 Data\n' +
      '\n' +
      '이 섹션에서는 데이터 수집 및 청소 계획에 대해 설명합니다.\n' +
      '\n' +
      '합법적인 사전 훈련 코라\n' +
      '\n' +
      '법경관은 과학, 의학 등의 분야와 달리 국가 및 관할 지역에 따라 크게 다르며, 관습법 대 민법 헨더슨 등(2022)과 같이 지방법뿐만 아니라 법적 전통에서도 차이를 반영한다. 따라서 우리는 전 세계적으로 법적 맥락에서 널리 사용되기 때문에 영어에 중점을 두고 다양한 관할 구역의 법률 텍스트를 수집했다. 우리의 컬렉션에는 다양한 법적 시스템을 다루는 미국 투게너 외(2020), 유럽 칼키디스 외(2019), 호주 버틀러(2023)의 데이터가 포함된다. 이 철저한 큐레이션 과정과 공격적인 청소(섹션 3.1.2 참조)를 통해 우리는 300억 토큰의 코퍼스로 끝나 지역 전반에 걸쳐 법률 언어의 복잡성을 포착한다.\n' +
      '\n' +
      '데이터 집합 구성 3.1.1\n' +
      '\n' +
      'Legal SourcesWe combines the FreeLaw subset of The Pile Gao et al.(2020) and MultiLegal Pile Niklaus et al.(2023)과 같은 이전에 사용 가능한 데이터 세트와 웹에서 공개적으로 사용 가능한 소스에서 긁어낸 데이터를 결합한다. 우리는 표 1에 다양한 데이터 소스를 나열한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c} \\hline \\hline Name & Tokens \\\\ \\hline FreeLaw4  & \\(15\\)B \\\\ EDGAR5  & \\(5\\)B \\\\ English MultiLegal Pile6  & \\(5\\)B \\\\ English EuroParl Koehn (2005) & \\(6\\)B \\\\ GovInfo7  & \\(11\\)B \\\\ Law Stack Exchange8  & \\(19\\)M \\\\ Commercial Open Australian Legal Corpus9  & \\(0.5\\)B \\\\ EU Legislation10  & \\(315\\)M \\\\ UK Legislation11  & \\(190\\)M \\\\ Court Transcripts12  & \\(350\\)M \\\\ UPSTO13  & \\(4.7\\)B \\\\ Total & \\(94\\)B \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: **법률 사전 훈련 데이터의 출처.** 이러한 출처는 노이즈 및 심하게 중복된 문서를 포함하며, 이를 필터링하고 중복 해제하여 300억 개의 토큰 데이터 세트를 생성했다.\n' +
      '\n' +
      '그림 1: SaulLM-7B 구축을 위한 **절차.** 리플레이 데이터로 증강된 법률 데이터 세트와 지침 데이터 세트에 의존한다. 세부 조정을 위해 우리는 법률 지침으로 세부 조정 데이터 세트를 더욱 풍부하게 한다.\n' +
      '\n' +
      '서로 다른 소스 간에 상당히 많은 중복이 있으며 섹션 3.1.2에 설명된 매우 공격적인 청소 및 중복 제거 단계를 실행합니다.\n' +
      '\n' +
      '계속된 사전 훈련 동안 맥클로스키와 코헨(1989)을 망각하는 치명적인 위험을 줄이기 위해, 우리는 선행 문헌 Chen et al.(2023); Sun et al.(2020)에 따라 선행 훈련 분포로부터 데이터를 통합한다. 그러나 미스트랄에 대한 훈련 데이터는 공개되지 않았기 때문에 최종 훈련 믹스의 대략 \\(2\\%\\)으로 구성된 위키피디아, 스택익스체인지 및 GitHub에서 일반적으로 사용할 수 있는 "일반" 데이터를 소개한다. 이들 데이터 세트는 SlimPajama Shen et al.(2023); Computer (2023); Soboleva et al.(2023)로부터 샘플링된다.\n' +
      '\n' +
      '또한 사전 교육 중에 대화 데이터를 포함하는 것이 유익하다는 것을 발견했습니다. 이것은 번역에서 LLM의 강력한 능력이 훈련 코퍼스 Anil 등(2023); Briakou 등(2023)에서 우발적인 병렬 데이터의 존재로 인한 것임을 강조하는 신경 기계 번역의 최근 발전에 의해 영감을 받았다. 구체적으로, 이는 프리 트레이닝 동안 Super Natural Instruction Wang et al.(2022) 및 FLAN 수집 Longpre et al.(2023)을 포함한다는 것을 의미한다.\n' +
      '\n' +
      '###### 3.1.2 데이터 클리닝\n' +
      '\n' +
      '수집된 데이터의 상당 부분은 PDF 파일 또는 PDF14에서 추출된 텍스트이다. 이는 텍스트가 i) 문장 중간에 페이지 번호, ii) 줄 번호, iii) 정규화되지 않은 유니코드 문자, iv) 텍스트의 파선, v) 반복되는 문자: 새로운 줄, 대시 등, vi) 다른 아티팩트를 포함하는 일부 아티팩트를 갖는다는 것을 의미한다. 우리는 데이터를 필터링하기 위해 규칙과 휴리스틱의 조합을 사용하여 이러한 문제를 해결했다.\n' +
      '\n' +
      '각주 14: PDF 파일에서 텍스트 추출을 위해 Poppler를 사용했다.\n' +
      '\n' +
      'Text Normalization Unicodedata Python 패키지를 통해 사용 가능한 NFKC 방법으로 모든 유니코드를 정규화한다.\n' +
      '\n' +
      'Elazar et al. (2023)에 따른 규칙 필터들은 데이터 세트에서 가장 일반적인 10-그램을 발견하였고, 대부분 반복되는 문자인 원하지 않는 것을 제거하기 위해 정규식을 사용하였다. 구체적으로, 원본 데이터에서 상위 \\(10\\) 10-그램 중 \\(8\\)은 반복되는 문자, 예를 들어, "- - -" 또는 "* * * * * * * * * * * 및 이상한 문자, 즉 인코딩 이슈였다. 또한 반복된 공백(공간, 새 라인 및 탭)과 파이프라인을 통과한 HTML 태그를 제거했습니다.\n' +
      '\n' +
      '복잡성 필터링은 신중하게 검사한 법적 데이터의 작은 하위 집합에 대해 KenLM 모델 Heafield(2011)를 훈련하고 높은 복잡성 문단을 필터링하는 데 사용했다. 이것은 데이터에 존재하는 대부분의 "이상한" 유니코드 시퀀스뿐만 아니라 비영어 텍스트를 제거했다. 표 2에서 필터링된 데이터에서 가장 일반적인 \\(10\\)-그램 중 일부를 보여준다.\n' +
      '\n' +
      '###### 3.1.3 데이터 중복제거\n' +
      '\n' +
      'Kocetkov et al. (2023); Lee et al. (2021)에 의해 영감을 받아, 우리는 기본 파라미터들과 함께 Mou et al. (2023)을 사용하여 트레이닝 데이터로부터 복제 및 근-복제들을 제거하였고, 그 후 우리는 고품질 텍스트의 대략 \\(30\\)B 토큰들과 함께 남겨졌다.\n' +
      '\n' +
      '### 명령어 핀튜닝 믹스\n' +
      '\n' +
      '명령어 미세 조정은 다양한 작업에 걸쳐 사전 훈련된 디코더 모델에서 최상의 성능을 얻기 위해 중요하다. 우리는 일반 지침과 법적 지침의 혼합을 사용하여 법적 전문성에 중점을 두고 지침을 잘 이해하고 따르도록 모델을 훈련한다.\n' +
      '\n' +
      '일반적인 지침은 네 가지 주요 출처에서 수집한다.\n' +
      '\n' +
      '1. **SlimOrca** FLAN 컬렉션의 이러한 서브세트는 일반 명령어들을 포함하며, 다양한 태스크들을 위한 집중된 리소스를 제공한다 Mukherjee et al.(2023); Lian et al.(2023).\n' +
      '2. **Meta Math Question Answering Instructions** 수학적 탐구를 위해 디자인된, 이 데이터세트15는 수학적 질문의 범위를 제시하며, 수학 기반 자연어 처리 Yu 등(2023)에서 연구를 용이하게 한다. 각주 15: 메타-math/MetaMathQA 접근 가능\n' +
      '3. **UltraChat**로부터의 일반 대화, 다양한 대화 맥락 포착,\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c} \\hline \\hline Common 10-grams \\\\ \\hline have been obvious to one of ordinary skill in the \\\\ before the effective filing date of the claimed invention \\\\ rejected under 35 U.S.C. 103 as being unpatentable over \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: **사전 훈련 데이터세트에서 가장 일반적인 10-그램.**이 GPT 유래 데이터세트는 자연어 이해 및 생성 시스템 Ding 등(2023)을 향상시키는 데 기여한다.\n' +
      '4. **Glaive Code Assistant v21** Training on code의 **Code Instructions from glaive Code Assistant v21** Training on code is shown to increase the reasoning ability of models Ma et al.(2023)\n' +
      '\n' +
      '각주 16: [https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2](https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2)에서 이용가능\n' +
      '\n' +
      '이 모든 데이터를 세심하게 필터링, 중복 제거 및 큐레이션하여 \\(600\\)K 지침으로 구성된 정제된 데이터 세트를 생성했다.\n' +
      '\n' +
      'Legal Instruction ConstructionWe synthetically generate the comprehensive conversation addressing fundamental legal competencies across multiple legal document types Ding et al.(2023) 우리는 메타데이터로 증강된 법률 텍스트를 일관된 대화로 변환하기 위해 Mistral-7B 지침을 활용합니다. 방법론은 (1) 사용자가 법률 문서와 관련된 요청을 아티큘레이션하고, (2) 어시스턴트가 메타데이터(예를 들어, 문서 유형, 날짜, 판사의 이름)를 다시 표현함으로써 응답하고, (3) 사용자가 어시스턴트에게 자신의 추론에 대해 상세히 설명하도록 프롬프트한다. 이어서, 일련의 회전을 통해 대화를 확장하는데, 여기서 사용자 모델은 어시스턴트의 추론을 파악하기 위해 점진적으로 더 구체적인 질문을 제기한다. 동시에 어시스턴트 모델은 심층적인 통찰력을 제공합니다. 예시적인 예가 그림 2에 나와 있으며, 특히 기존 벤치마크에서 테스트 세트를 제외한다.\n' +
      '\n' +
      '##4 법률지식의 평가\n' +
      '\n' +
      '모델의 법적 능력을 평가하기 위해 벤치마크를 사용하여 (i)\\(5\\) 유형의 법적 문서에 대한 백본의 복잡성을 비교하고, (ii) 보다 심층적인 평가를 위해 LegalBench와 LegalBench-Instruct를 강화하며, (iii) 추가적인 통찰력을 위해 MMLU의 법적 섹션에 의존한다.\n' +
      '\n' +
      '복잡성 측정 법률 문서에 대한 백본의 적응성을 평가하기 위해 계약, 사법 결정, 의견 텍스트 및 법률_의 4가지 별개의 법률 영역에 걸쳐 있는 벤치마크 데이터 세트를 사용하여 복잡성을 평가한다. 우리는 데이터 세트가 최신이며 LLM 데이터의 수집 차단 날짜 이후에 조달되는지 확인합니다. 구체적으로, 계약 데이터는 EDGAR(2024년 1분기), 2023년 10월 이후에 발표된 ICSID 법원 결정의 법적 결정, 법률은 2023년 10월 이후 하원 또는 상원에 제출된 미국 법안, 정당 제출은 2023년 10월 이후에 제출된 텍사스 브리핑을 포함한다.\n' +
      '\n' +
      '조사하는 동안 우리는 법률 벤치의 원래 프롬프트에서 상당한 한계를 발견했다. 이러한 프롬프트의 복잡한 특성은 지침을 준수할 때, 특히 형식화를 처리할 때 오픈 소스 LLM이 직면하는 문제와 결합되어 (정확도에 의해 측정된) 상당한 성능 저하를 초래한다. 생성된 문장들은 종종 장황하고 구문 분석하기가 어려워, 법적 벤치를 현재의 형태로 너무 엄격하게 만들고 작업에 대한 개선을 정확하게 측정하지 못한다.\n' +
      '\n' +
      '예를 들어, 일부 태스크에서는 모델이 예측하는 첫 번째 단어에 의해 성능이 평가되며, 이 단어는 _Yes/No_가 될 것으로 예상된다. 이는 반응이 다소 장황하면 사람이 정답으로 분류하더라도 오답으로 계산된다는 것을 의미한다. 이러한 단점을 개선하기 위해 1) 산만한 소수의 예제를 제거하고 2) 모델을 사용하여 태그를 생성하는 특정 명령으로 결론을 내림으로써 프롬프트를 개선한다(표 3 참조).\n' +
      '\n' +
      'MMLU (Massive Multitask Language Understanding) The MMLU 벤치마크 Hendrycks et al. (2020)은 MMLU 벤치마크 Hendrycks et al. (2020)을 측정하기 위해 널리 사용되어 왔다.\n' +
      '\n' +
      '도 2: **메타데이터가 있는 데이터세트를 대화로 전환.** Reddit 포스트 분류의 예를 들어, 레이블이 붙은 예를 전환한다 {_My employer fired me because...Are it legal?_, _“employment”_} 질의와 답변을 자연스러운 대화로 재구성하는 것만으로 대화의 처음 세 번을 하드 코딩한다. 그런 다음 진행 중인 대화에서 관련 질문을 계속 생성하는 작업을 수행하는 _user_ 모델(파란색 점선)과 답변을 제공하는 _assistant_ 모델을 사용하여 대화를 완료한다. _assistant_ 및 _user_ 모델 모두 Mistral-7B-instruct이다.\n' +
      '\n' +
      'LLM 공연의 발전 우리 연구에서 우리는 국제법_, _전문법_ 및 _jurisprudence_에 특정한 초점을 두고 법적 영역에 대한 분석을 중점을 둔다. 이러한 작업은 각각 \\(120\\), \\(1500\\) 및 \\(110\\)의 예를 포함한다.\n' +
      '\n' +
      '### Metrics\n' +
      '\n' +
      '우리는 원래의 LegalBench Guha et al.(2023) 논문: 균형 잡힌 정확도와 동일한 메트릭을 사용한다. 균형 잡힌 정확도는 두 벤치마크에 제시된 것과 같이 균형 잡힌 분류 작업을 더 잘 처리할 수 있다. 또한 MMLU의 법적 작업에 균형 잡힌 정확도를 사용합니다. 달리 명시되지 않는 한, 이 섹션 전체에 걸쳐 보고된 모든 점수는 균형 잡힌 정확도를 나타낸다.\n' +
      '\n' +
      '## 5 실험 설정\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      '우리는 SaulLM-7B 계열을 다른 최첨단 \\(7\\)B 및 \\(13\\)B 오픈 소스 모델과 비교한다. 구체적으로, Mistral-7B Jiang et al. (2023): Mistral-7B-Instruct-v0.1, Mistral-7B-Instruct-v0.2, 뿐만 아니라 zephyr-7b-beta17. 또한 Llama2 Touvron et al. (2023) 패밀리, 보다 구체적으로 Llama2-7b-Chatand Llama2-13b-Chat를 평가한다.\n' +
      '\n' +
      '각주 17: [https://huggingface.co/HuggingFaceH4/zephyr-7b-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)\n' +
      '\n' +
      '### Implementation Details\n' +
      '\n' +
      'CodebaseOur codebase는 Open-source frameworks Shoeybi et al. (2019); Wolf et al. (2019); Lhoest et al. (2021) utilizing DeepSpeed with Flash attention Dao et al. (2022); Dao (2023). PyTorch Paszke et al.(2019)에 구축되었으며, 우리의 모델은 Huggingface 허브에서 사용할 수 있다.\n' +
      '\n' +
      'ComputeContinuous Preraining은 \\(256\\) MI250 AMD GPU를 활용한다. 명령어 미세 조정을 위해 16개의 MI250에 걸쳐 워크로드 분배가 발생하며, 단일 MI250에서 평가 절차가 원활하게 수행된다.\n' +
      '\n' +
      '## 6 Results\n' +
      '\n' +
      '이 섹션에서는 주요 실험 결과와 결과에 대해 논의한다.\n' +
      '\n' +
      '### LegalBench-Instruct\n' +
      '\n' +
      '그림 3과 4는 법률 벤치 지침에 대한 우리의 결과를 요약한다. 아래에서 논의되는 \\(3\\) 주요 테이크아웃이 있습니다.\n' +
      '\n' +
      '그림 3: **LegalBench-Instruct 상의 기본 모델의 성능. 흥미롭게도 세밀하게 조정되지는 않았지만 SaulLM-7B는 SaulLM-7B의 초기 체크포인트(미스트랄-7B)를 포함한 다른 기본 모델에 비해 벤치마크에서 여전히 인상적인 개선을 달성할 수 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l} \\hline \\hline\n' +
      '**Original Prompt** \\\\ \\hline The Telemarketing Sales Rule is provided by 16 C.F.R. § 310.3(a)(2). \\\\ \\multicolumn{2}{l}{**Question:** Acme Toys is a telemarketer subject to the Telemarketing Sales Rule. Acme Toys told a customer that is fribeses cost $10 each, when in fact the fribes cost $12 each. The customer agreed to the sale and was charged $12. Is this a violation of the Telemarketing Sales Rule? \\\\ \\hline\n' +
      '**Answer:** Yes \\\\ \\hline\n' +
      '**Question:** Acme Toys is a telemarketer subject to the Telemarketing Sales Rule. Acme Toys told a customer that is fribeses cost $10 each, when in fact the fribeses did cost $10, but Acme Toys did not disclose that shipping would cost an additional $5. The customer agreed to the sale. Is this a violation of the Telemarketing Sales Sales Rule? \\\\ \\hline\n' +
      '**Answer:** No \\\\ \\hline\n' +
      '**Question:** Acme Industrial Products is a telemarketer subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that is would sell them 4 brooms for $10 and that shipping would be $5. Then, the customer agreed to the sale. Is this a violation of the Telemarketing Sales Sales Rule? \\\\ \\hline\n' +
      '**Answer:** No \\\\ \\hline\n' +
      '**Question:** \\{text\\}\n' +
      '**Question:** Acme Industrial Products is a telemarketer subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that it would sell them 4 brooms for $510 and that shipping would be $5. Then, the customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule? \\\\ \\hline\n' +
      '**Answer:** No \\\\ \\hline\n' +
      '**Question:** \\{text\\}\n' +
      '**Question:** \\{text\\}\n' +
      '**Question:** \\{text\\}\n' +
      '**Question:** \\{text\\}\n' +
      '**Question:** \\{text\\}\n' +
      '**Question:** \\{text\\}\n' +
      '**Question:** \\{text\\}\n' +
      '질문:**\\{text\\}{text\\}{text\\}{text\\I} 법적 지속 사전 훈련은 제안된 지속 사전 훈련의 영향을 분석하는 것으로부터 상당한 개선을 가져온다. 그림 3에서 볼 수 있듯이 SaulLM-7B는 강력한 독립형 모델이다. 3.1.1절에서 언급한 바와 같이 사전 훈련 데이터에 지시가 통합되었기 때문에 성능이 우수하다고 추측하지만, 전용 지시 미세 조정 단계가 없어도 SaulLM-7B는 Llama2-7B-chat(\\(0.38\\) v.s. \\(0.39\\))과 동등하게 수행한다는 점에 여전히 주목한다. 더 중요한 것은 SaulLM-7B는 강력한 법적 능력을 가진 IFT 모델을 구축하기 위한 강력한 기반 모델 역할을 한다는 것이다. 일반 명령 미세 조정과 결합하면 그림 4에서 볼 수 있듯이 최상의 오픈 소스 명령 모델인 Mistral-7B-Instruct-v0.1에 대해 \\(0.59\\), 즉 \\(4\\) 절대 개선점을 강력하게 달성한다.\n' +
      '\n' +
      'II. 법률적 지침은 그림 2에서 볼 수 있듯이 일반 지침과 법률 지침(SaulLM-7B-Instruct) 모두에서 SaulLM-7B를 세부적으로 조정하는 것은 법률 벤치마크에서 새로운 최신 기술을 확립하며, 평균 점수는 \\(0.61\\), 즉 최상의 오픈 소스 지침 모델에 비해 \\(11\\)% 상대적 개선이다(그림 5). 마지막으로 DPO 정렬 모델은 일반적인 정렬이 법률 벤치 지침에 존재하는 것과 같은 외부 배포 작업에 적합하지 않다는 사실로 설명될 수 있다. 현재 작업의 범위를 벗어나지만 흥미로운 연구 방향은 법적 특정 DPO가 어떻게 도움이 될 수 있는지 탐구하는 것이다.\n' +
      '\n' +
      'III. 여전히 상당한 개선의 여지가 있다. 다음으로, 우리는 원래의 법률 벤치를 따른다\n' +
      '\n' +
      '그림 4: **기본 모델의 영향.** 기본 모델 SaulLM-7B에서 명령어 미세 조정을 시작하면 미스트랄-7B에 비해 눈에 띄는 개선이 있다. 실제로, 일반 IFT 믹스(합법적이지 않음)에서도 SaulLM-7B(Gen.)는 Mistral-Instruct 대응보다 훨씬 우수하다. IFT 믹스에 법적 지침을 추가하면 결과가 더욱 향상됩니다.\n' +
      '\n' +
      '그림 5: **법률 벤치-명령어에 대한 지시 모델의 비교. SaulLM-7B-Instruct는 최첨단의 Mistral-Instruct 모델을 상당한 6개의 절대점만큼 능가하여 수립한다.\n' +
      '\n' +
      '그림 6: **Legal-MMLU에 대한 명령어 모델.** LegalBench-Instruct에 대한 에코링 발견, SaulLM-7B-Instruct는 Mistral-7B-Instruct-v0.1에 대해 평균 5점의 절대 개선으로 Legal-MMLU의 세 가지 작업 모두에서 우수한 성능을 나타낸다.\n' +
      '\n' +
      'SaulLM-7B-Instruct의 성과에 대한 보다 세분화된 이해를 얻기 위한 분류[14]는 과제들을 이슈 스포팅, 규칙-리콜, 해석, 수사학 이해, 규칙-결론의 핵심 법률 능력으로 나누어진다. 그 결과 SaulLM-7B-Instruct가 가장 많은 법적 전문성을 요구하는 4가지 영역(이슈, 규칙, 해석 및 이해)에서 가장 우수한 비법적 경쟁자\\(\\mathtt{Mistral-7B-Instruct-v0.1}\\)보다 뚜렷한 우월한 성과를 보였다. 한편, 결론과제에 있어서는 실제 법률지식보다 훨씬 더 순수한 연역적 추론을 필요로 하는 \\(\\mathtt{Mistral-7B-Instruct-v0.1}\\)에 미치지 못한다. 우리는 수학 데이터 세트를 포함하지만 이에 국한되지 않는 더 연역적인 추론 콘텐츠로 사전 훈련 및 미세 조정 말뭉치를 증강하면 격차를 줄이고 SaulLM-7B-인스트럭션의 잠재력을 완전히 해제할 수 있다고 추측한다.\n' +
      '\n' +
      '### 법률-MMLU에 대한 결과\n' +
      '\n' +
      '또한, SaulLM-7B-Instruct가 Non-legal instruction-tuned model에 비해 일관된 우월성을 보이며, 세 가지 작업에서 가장 우수한 7B 오픈소스 경쟁자에게 \\(3\\)과 \\(4\\)의 절대점 차이를 보여 SaulM-7B-Instruct가 법적 워크플로우에 맞는 모델을 구축할 수 있는 강력한 기반이라는 추가 증거를 제공한다.\n' +
      '\n' +
      '### Perplexity Analysis\n' +
      '\n' +
      'SaulLM-7B 백본의 법적 영역에 대한 적응을 평가하기 위해 계약, 법적 결정, 입법 및 당사자 제출의 4가지 문서 유형에 걸쳐 복잡성 점수를 제시한다. 결과는 그림 8을 참조하십시오. 우리의 모델인 SaulLM-7B는 모든 범주에서 일관되게 \\(\\mathtt{Mistral-7B}\\)을 능가하여 분산이 감소하면서 더 낮은 평균 당혹성 점수를 나타낸다. 흥미롭게도, \\(\\mathtt{Llama2-7B}\\)은 특히 법률 문서에서 더 낮은 당혹감을 보여주며, 이는 관련 말뭉치에서 \\(\\mathtt{Mistral-7B}\\)에 비해 잠재적으로 더 높은 입법 텍스트 비율을 시사한다.\n' +
      '\n' +
      '전반적으로, \\(\\mathtt{Mistral-7B}\\)에 비해, 본 모델은 \\(\\mathtt{Llama2-7B}\\)에 비해 법적 말뭉치에서 3%, 11%의 중앙값 복잡도 감소를 보여준다.\n' +
      '\n' +
      '##7 결론과 미래 전망\n' +
      '\n' +
      '본 논문에서는 7B 모델과 비교하여 최신 성능을 제공하는 오픈소스 디코더 모델인 SaulLM-7B를 법률 도메인 내에서 소개한다. 우리의 접근 방식은 합성 데이터 세트에 대한 세부 조정 지침과 함께 법률 데이터를 세부 조정하는 것을 수반한다. 또한, 클리닝된 버전의 LegalBench를 제공하고 복잡도 측정을 위한 새로운 문서 세트를 도입함으로써 기여합니다. MIT 라이선스로 출시된 저희 모델이 오픈소스 생태계와 커뮤니티에 기여하기를 바랍니다.\n' +
      '\n' +
      '그림 8: **사전 훈련된 백본에 대한 법률 문서에 대한 복잡성.** SaulLM-7B-인스트럭션은 대부분의 법률 문서에 대해 다른 사전 훈련된 백본보다 우수하지만, 입법에 대해서는 \\(\\mathtt{Llama2-7B}\\)에 의해 능가한다. SaulLM-7B-Instruct는 \\(8.69\\)의 중간당도를 보였으며 \\(\\mathtt{Mistral-7B}\\)에 비해 \\(5.5\\)% 감소, \\(9.20\\) 및 \\(10.8\\)% 감소, \\(9.74\\)의 중간당도를 보였다.\n' +
      '\n' +
      'Figure 7: **Per-task performance breakdown.** SaulLM-7B-Instruct는 대부분 법률적 특정지식을 필요로 하지만 결론과제에 있어서는 \\(\\mathtt{Mistral-Instruct}\\)에 의해 성능이 향상되어 보다 연역적인 추론이 필요하다.\n' +
      '\n' +
      '## Acknowledgments\n' +
      '\n' +
      '우리는 GENCI가 우리에게 최첨단 컴퓨팅 자원에 대한 접근을 너그럽게 허락해 준 것에 감사한다. 우리의 모델인 SaulLM-7B는 장자이에 대해 수행된 초기 실험과 함께 ADASTRA에 대해 훈련되었다. HPC 자원의 활용은 장자이 보조금 101838, 103256, 103298과 아다스트라 보조금 C1615122, CAD14770, CAD15031을 통해 가능해졌다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 기술보고서; _ arXiv preprint arXiv:2303.08774_.\n' +
      '* Aletras et al. (2016) Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel Preotiuc-Pietro, and Vasileios Lampos. 2016. 유럽인권법원의 사법 결정 예측: 자연어 처리 관점. _ PeerJ 컴퓨터 과학_, 2:e93.\n' +
      '* Almazrorouei et al. (2023) Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, Daniele Mazzotta, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. 오픈 언어 모델의 매 시리즈.\n' +
      '* Anil et al. (2023) Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. 2023. Palm 2 technical report. _ arXiv preprint arXiv:2305.10403_.\n' +
      '*Bai et al. (2023) Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Biyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chenguang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jusheng Yang, Yang Yao, Jonxuan Zhang, Yichang Zhang, Hongyi Zhou, Ziaohuan Zhou, Zianhang Zhu. 2023. Qwen 기술 보고서.\n' +
      '* 바이더만 et al. (2023) Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O\'Brien, Eric Hallahan, Mohammad Afah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al. 2023. Pythia: 훈련 및 스케일링에 걸친 대규모 언어 모델을 분석하기 위한 스위트. _International Conference on Machine Learning_, pages 2397-2430. PMLR.\n' +
      '* Briakou et al.(2023) Eleftheria Briakou, Colin Cherry, and George Foster. 2023. 건초더미에서 바늘 찾기: 손바닥의 번역능력에서 부수적인 이중언어주의의 역할에 관하여 arXiv preprint arXiv:2305.10266_.\n' +
      '* 버틀러(2023) 우마르 버틀러. 2023년 오스트레일리아 법률 코퍼스를 열어요\n' +
      '* Cao et al. (2023) Yihan Cao, Yanbin Kang, and Lichao Sun. 2023. 명령어 마이닝: 대용량 언어 모델에 대한 고품질 명령어 데이터 선택_ arXiv preprint arXiv:2307.06290_.\n' +
      '* Chalkidis et al. (2019) Ilias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. 2019. 영문에서의 신경법적 판단 예측_ arXiv preprint arXiv:1906.02059_.\n' +
      '* Chalkidis et al. (2020) Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. 2020. Legal-bert: The muppets directly out of law school. _ arXiv preprint arXiv:2010.02559_.\n' +
      '* Chen et al. (2023) Zeming Chen, Alejandro Hernandez Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, Francesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Kopf, Amrikeivan Mohtashami, et al. 2023. Meditron-70b: 대형 언어 모델에 대한 스케일링 의료 사전 훈련; _ arXiv preprint arXiv:2311.16079_.\n' +
      '* Cheng et al. (2023) Daixuan Cheng, Shaohan Huang, and Furu Wei. 2023. 독해력을 통한 대용량 언어 모델 적응. _ arXiv preprint arXiv:2309.09530_.\n' +
      '* Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. _ arXiv preprint arXiv:2210.11416_.\n' +
      '* 컴퓨터(2023) 함께 컴퓨터. 2023. Redpajama: 대규모 언어 모델을 훈련시키기 위한 오픈 데이터세트.\n' +
      '* Cui et al. (2023) Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li Yuan. 2023. Chatlaw: Open-source legal large language model with integrated external knowledge base. _ arXiv preprint arXiv:2306.16092_.\n' +
      '* Dao(2023) Tri Dao. 2023. 플래시 어텐션-2: 더 나은 병렬성과 작업 분할로 더 빠른 주의력 _ arXiv preprint arXiv:2307.08691_.\n' +
      '* Dao et al. (2022) Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Re. 2022. 플래시 어텐션: io-awareness와 함께 빠르고 메모리 효율적인 정확한 주의력 _ 신경 정보 처리 시스템_, 35:16344-16359에서의 발전.\n' +
      '* Ding et al. (2023) Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023. 고품질 교육 대화를 스케일링하여 채팅 언어 모델을 향상시킴. _ arXiv preprint arXiv:2305.14233_.\n' +
      '* Elazar et al. (2023) Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hanna Hajishirzi, Noah A. Smith, and Jesse Dodge. 2023. 제 빅데이터에 뭐가 있죠? Manuel Faysse, Patrick Fernandes, Nuno Guerreiro, Antonio Loison, Duarte Alves, Caio Corro, Nicolas Boizard, Joao Alves, Ricardo Rei, Pedro Martins et al. 2024. Croissantllm: truly bilingual french-english language model. _ arXiv preprint arXiv:2402.00786_.\n' +
      '* Faysse et al. (2023) Manuel Faysse, Gautier Viaud, Celine Hudelot, and Pierre Colombo. 2023. Revisiting instruction fine-tuned model evaluation to guide industrial applications. In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_. 컴퓨터 언어학과의 연관성\n' +
      '* Gao et al. (2020) Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020. The pile: 800gb dataset of various text for language modeling.\n' +
      '* 구와 다오(2023) 알버트 구와 트리 다오. 2023. Mamba: 선택적 상태 공간을 갖는 선형-시간 시퀀스 모델링 _ arXiv preprint arXiv:2312.00752_.\n' +
      '* Guha et al. (2022) Neel Guha, Daniel E Ho, Julian Nyarko, and Christopher Re. 2022. 법률 벤치: 법적 추론을 위한 협력 벤치마크를 프로토타이핑한다. _ arXiv preprint arXiv:2209.06120_.\n' +
      '* Guha et al. (2023) Neel Guha, Julian Nyarko, Daniel E Ho, Christopher Re, Adam Chilton, Aditya Narayana, Alex Chohlas-Wood, Austin Peters, Brandon Waldon, Daniel N Rockmore, et al. 2023. Legalbench: Collaborative built benchmark for measuring legal reasoning in large language models. _ arXiv preprint arXiv:2308.11462_.\n' +
      '* Gururangan et al. (2020) Suchin Gururangan, Ana Marasovic, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A Smith. 2020. 사전 훈련 중단하지 않음: 언어 모델을 도메인 및 태스크에 적응 arXiv preprint arXiv:2004.10964_.\n' +
      '* Gutierrez-Fandino et al. (2021) Asier Gutierrez-Fandino, Jordi Armengol-Estape, Aitor Gonzalez-Agirre, and Marta Villegas. 2021. 스페인어 법률어 언어 모델과 말뭉치_ arXiv preprint arXiv:2110.12201_.\n' +
      '* Heafield (2011) Kenneth Heafield. 2011. KenLM: 더 빠르고 더 작은 언어 모델 쿼리. [Proceedings of the Sixth Workshop on Statistical Machine Translation_, pages 187-197, Edinburgh, Scotland]. 컴퓨터 언어학과의 연관성\n' +
      '* Henderson et al. (2022) Peter Henderson, Mark Krass, Lucia Zheng, Neel Guha, Christopher D Manning, Dan Jurafsky, and Daniel Ho. 2022. Pile of law: Learning responsible data filtering from the law and 256gb open-source legal dataset. _ 신경 정보 처리 시스템_, 35:29217-29234에서의 발전.\n' +
      '* Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. 대용량 멀티태스크 언어 이해도 측정. _ arXiv preprint arXiv:2009.03300_.\n' +
      '* Islam et al. (2023) Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin Tasnim Raya, Monowara Tabassum Maisha, and Dewan Md Farid. 2023. 인간 생성 텍스트를 기계 학습을 이용하여 채팅트 생성 텍스트와 구별. _ arXiv preprint arXiv:2306.01761_.\n' +
      '* Ji et al. (2023) Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria, and Jorg Tiedemann. 2023. 정신 건강에서 긴 컨텍스트를 캡처하기 위한 언어 모델의 도메인-특정 연속 프리트레이닝. _ arXiv preprint arXiv:2304.10447_.\n' +
      '* Jiang et al. (2023) Albert Q. 장, 알렉산드르 사블레이롤, 아서 멘쉬, 크리스 뱀포드, 데벤드라 싱 채플롯, 디에고 데 라스 카사스, 플로리안 브레산드, 지아나 령겔, 기욤 옴플, 루실 사울니에, 릴리오 레나르 라바우, 마리안 라초, 피에르 스톡, 테븐 르 스카오, 티보트 라브릴, 토마스 왕, 티모티 라크루아, 윌리엄 엘 사예드. 2023. 미스트랄 7b.\n' +
      '* Jiang et al. (2024) Albert Q. 장, 알렉산드르 사블레이롤, 안토인 루, 아서 멘쉬, 블랑체 사바리, 크리스 뱀포드, 데벤드라 싱 채플롯, 디에고 데 라스 카사스, 엠마 부 한나, 플로리안 브레산드, 지아나 령겔, 기욤 부르, 기욤 샘플, 릴리오 레나르 라바우, 루실 사울니에, 마리안 나르 라초, 피에르 스톡, 산데프 서브라마니안, 소피아 양, 지몬 안토니아크, 테벤 르 스카오, 시오필 게르베트, 티보트 라브릴, 토마스 왕, 티모티 라크루아, 윌리엄 엘 사예드. 2024년, 전문가들의 혼합\n' +
      '* Katz et al. (2023) Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. 2023. Gpt-4는 변호사 시험에 합격한다. _ SSRN 4389233_에서 사용할 수 있습니다.\n' +
      '* Koetkov et al. (2023) Denis Koetkov, Raymond Li, Loubna Ben Allal, Jia LI, Chenghao Mou, Yacine Jernite, Margaret Mitchell, Carlos Munoz Ferrandis, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro Von Werra, and Harm de Vries. 2023. 스택: 허용 허가된 소스 코드의 3TB. _ 기계학습 연구에 관한 연구\n' +
      '* Koehn(2005) Philipp Koehn. 2005. Europarl: 통계 기계 번역을 위한 병렬 말뭉치. *Proceedings of Machine Translation Summit X: Papers_, pages 79-86, Phuket, Thailand.\n' +
      '* Lee et al. (2021) Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. 2021. 학습 데이터 복제가 언어 모델을 더 좋게 한다. _ arXiv preprint arXiv:2107.06499_.\n' +
      '* Lhoest et al. (2021) Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, et al. 2021. Datasets: 자연 언어 처리를 위한 커뮤니티 라이브러리. _ arXiv preprint arXiv:2109.02846_.\n' +
      '* Li et al. (2020) Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Koetkov, Chenghao Mou, Jia Liu, Evgenii Zheltonozhskii, Terry Yue Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, Joao Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Jenham Zbolkar Wang, Rudra Murthy, Siva Reddy, Daniel Fried, Dzmitry Bhattacharyya, Wenham Zocca, Manan Dey, Jashan Luccioni, Zillan Zhang, Nour Ebert, Jashan Dee, J. 2023. 스타코더: 출처가 여러분과 함께 할 수 있기를!\n' +
      '* Lian et al. (2023) Wing Lian, Guan Wang, Bleys Goodson, Eugene Pentland, Austin Cook, Chanvichet Vong, and "Teknium." 2023. Slimorca: 검증과 함께 gpt-4 증강 플란 추론 트레이스의 오픈 데이터세트.\n' +
      '* 리카리와 코만데(2022) 다니엘레 리카리와 지오반니 코만데. 2022. Italian-legal-bert: a pre-trained transformer language model for italian law. _CEUR Workshop Proceedings(Ed.), The Knowledge Management for Law Workshop(KM4LAW)_.\n' +
      '* Longpre et al. (2023) Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barrett Zoph, Jason Wei, et al. 2023. The flan collection: Designing data and methods for effective instruction tuning. _ arXiv preprint arXiv:2301.13688_.\n' +
      '* Lu et al. (2023) Keming Lu, Peter Potash, Xihui Lin, Yuwen Sun, Zihan Qian, Zheng Yuan, Tristan Naumann, Tianxi Cai, and Junwei Lu. 2023. 도메인 적응을 위한 프롬프트 판별 언어 모델. _Proceedings of the 5th Clinical Natural Language Processing Workshop_, pages 247-258.\n' +
      '* Ma et al. (2023) Yingwei Ma, Yue Liu, Yue Yu, Yuanliang Zhang, Yu Jiang, Changjian Wang, and Shanshan Li. 2023. 어느 훈련 단계에서 코드 데이터가 l1ms 추론을 돕는가?\n' +
      '* Martin et al. (2024) Lauren Martin, Nick Whitehouse, Stephanie Yiu, Lizzie Catterson, and Rivindu Perera. 2024. 큰 언어 모델을 변호사와 비교하는 gpt를 호출하는 것이 좋다. _ arXiv preprint arXiv:2401.16212_.\n' +
      '* McCloskey and Cohen (1989) Michael McCloskey and Neal J. Cohen. 1989. 연결주의 네트워크에서의 재앙적 간섭: 순차 학습 문제. "Psychology of Learning and Motivation_", 페이지 109-165. Academic Press.\n' +
      '* Mitchell et al. (2023) Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning, and Chelsea Finn. 2023. Detectgpt: 확률곡률을 이용한 Zero-shot machine-generated text detection _ arXiv preprint arXiv:2301.11305_.\n' +
      '* Mou et al. (2023) Chenghao Mou, Chris Ha, Kenneth Enevoldsen, and Peiyuan Liu. 2023. Chenghaomou/text-dedup: Reference 스냅샷.\n' +
      '* Mukherjee et al. (2023) Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023. Orca: gpt-4의 복잡한 설명 흔적으로부터 점진적 학습.\n' +
      '* Munos et al. (2023) Remi Munos, Michal Valko, Daniele Calandriello, Mohammad Gheshlaghi Azar, Mark Rowland, Zhaohan Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Andrea Michi, et al. 2023. Nash learning from human feedback. _ arXiv preprint arXiv:2312.00886_.\n' +
      '* Niklaus et al. (2021) Joel Niklaus, Ilias Chalkidis, and Matthias Sturmer. 2021. 스위스-판단-예측: 다국어 법률판단 예측 벤치마크_ arXiv preprint arXiv:2110.00806_.\n' +
      '* 니클라우스와 지오프레(2022) 조엘 니클라우스와 다니엘 지오프레. 2022. 예산-장구자: Sota 법률 언어 모델을 처음부터 저렴하게 사전 훈련할 수 있는가? _ arXiv preprint arXiv:2211.17135_.\n' +
      '* 니클라우스와 지오프레(2023) 조엘 니클라우스와 다니엘 지오프레. 2023. 처음부터 예산으로 소타 법률 언어 모델을 사전 훈련할 수 있습니까? 컴퓨터 언어학과의 연관성\n' +
      '* Niklaus et al. (2023) Joel Niklaus, Veton Matoshi, Matthias Sturmer, Ilias Chalkidis, and Daniel E. Ho. 2023. Multilegalpile: 689gb 다국어 법률 코퍼스.\n' +
      '*Nishida et al. (2019) Kosuke Nishida, Kyosuke Nishida, Itsumi Saito, Hisako Asano, Junji Tomita. 2019. 독해력을 위한 언어 모델의 비감독 도메인 적응. _ arXiv preprint arXiv:1911.10768_.\n' +
      '* Paszke et al. (2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Kimelshein, Luca Antiga, et al. 2019. Pytorch: An imperative style, highperformance deep learning library. _ 신경 정보 처리 시스템들_, 32에서의 진보들.\n' +
      '* Penedo et al. (2023) Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023. 매를 위한 정제된 웹 데이터세트 l1m: 웹 데이터로 큐레이션된 말뭉치를 능가하고, 웹 데이터만을 제공한다. _ arXiv preprint arXiv:2306.01116_.\n' +
      '* 프라켄(2013) 헨리 프라켄. 2013. _Logical tools for modeling legal argument: study of defeasible reasoning in law_, volume 32. Springer Science & Business Media.\n' +
      '* Radford et al. (2022) Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2022. 대규모의 약한 감독을 통한 강인한 음성 인식.\n' +
      '* Rafailov et al. (2023) Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. 2023. 직접 선호도 최적화: 당신의 언어 모델은 비밀리에 보상 모델이다. _ arXiv preprint arXiv:2305.18290_.\n' +
      '* Roziere et al. (2023) Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jeremy Rapin, et al. 2023. Code llama: code에 대한 오픈 파운데이션 모델 _ arXiv preprint arXiv:2308.12950_.\n' +
      '* Savelka et al. (2023) Jaromir Savelka, Kevin D Ashley, Morgan A Gray, Hannes Westermann, and Huihui Xu. 2023. 법률 개념을 증강된 대형 언어 모델로 설명하는 단계(gpt-4). _ arXiv preprint arXiv:2306.09525_.\n' +
      '* De Scao et al. (2022) Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagne, Alexandra Sasha Luccioni, Francois Yvon, Matthias Galle, et al. 2022. Bloom: 176b-parameter open-access multilingual language model. _ arXiv preprint arXiv:2211.05100_.\n' +
      '* Shen et al. (2023) Zhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Joel Hestness, Natalia Vassilieva, Daria Soboleva, and Eric Xing. 2023. 슬림파자마-dc: llm 트레이닝을 위한 데이터 조합의 이해도 _ arXiv preprint arXiv:2309.10818_.\n' +
      '* Shoeybi et al. (2019) Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019. 메가트론-lm: 모델 병렬성을 이용한 수십억 파라미터 언어 모델 학습. _ arXiv preprint arXiv:1909.08053_.\n' +
      '* Soboleva et al. (2023) Daria Soboleva, Faisal Al-Khateeb, Robert Myers, Jacob R Steeves, Joel Hestness, and Nolan Dey. 2023. 슬림파자마: 627b 토큰 세척 및 중복 제거 버전의 레드로자마.\n' +
      '* Sun et al. (2020) Jingyuan Sun, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. 2020. 연속 언어 학습을 위한 증류 및 재생. _Proceedings of the 28th International conference on computational linguistics_, pages 3569-3579.\n' +
      '* Taylor 등(2022) Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. 2022. Galactica: large language model for science. _ arXiv preprint arXiv:2211.09085_.\n' +
      '* Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. 개방적이고 효율적인 기초 언어 모델 arXiv preprint arXiv:2302.13971_.\n' +
      '* Touvron et al. (2020) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esibou, Jude Fernandes, Jeremy Fu, Wenyin Fu, Bynthia Kardas, Vedan Heluj Goswami, Saghar Hosseini, Rui Hou, Kenyin Fu, Bindan Kardas, Vindan Houlon Lu, Saghar Hosseini, Rushem Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, E. Michael Smith, R. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. J. 2023b. 라마 2: 오픈 파운데이션 및 미세 조정된 채팅 모델.\n' +
      '* Tuggener et al. (2020) Don Tuggener, Pius Von Daniken, Thomas Peetz, and Mark Cieliebak. 2020. Ledgar: 계약에서의 법률 조항의 텍스트 분류를 위한 대규모 다중 라벨 코퍼스. _Proceedings of the Twelfth Language Resources and Evaluation Conference_, pages 1235-1241.\n' +
      '* Tunstall et al. (2023) Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazzeen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clementine Fourrier, Nathan Habib, et al. 2023. Zephyr: Direct distillation of lm alignment. _ arXiv preprint arXiv:2310.16944_.\n' +
      '* von Werra et al. (2020) Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching, Tristan Thrush, Nathan Lambert, and Shengyi Huang. 2020. Trl: 트랜스포머 강화 학습. [https://github.com/huggingface/trl] (https://github.com/huggingface/trl).\n' +
      '* Vu et al. (2020) Thuy-Trang Vu, Dinh Phung, and Gholamreza Haffari. 2020. 적대적으로 훈련된 언어 모델과의 효과적인 비감독 도메인 적응 _ arXiv preprint arXiv:2010.01739_.\n' +
      '* Wang et al. (2023) Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavich Chandu, David Wadden, Kelsey MacMillan, Noah A Smith, Iz Beltagy, et al. 2023a. 낙타는 얼마나 멀리 갈 수 있나요? 개방형 리소스에 대한 명령어 튜닝 상태를 탐색합니다. _ arXiv preprint arXiv:2306.04751_.\n' +
      '* Wang et al. (2023) Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b. 자가 지시: 언어 모델을 자가 생성 지시와 정렬합니다.\n' +
      '* Wang et al. (2022) Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022. Super-natural instructions: Generalization via declarative instructions on 1600+nlp tasks. _ arXiv preprint arXiv:2204.07705_.\n' +
      '* Weber-Wulff et al. (2023) Debora Weber-Wulff, Alla Anohina-Naumeca, Sonja Bjelobaba, Tomas Foltynek, Jean Guerrero-Dib, Olumide Popoola, Petr Sigut, and Loma Waddington. 2023. ai-생성 텍스트에 대한 검출 툴의 테스팅. _ International Journal for Educational Integrity_, 19(1):26.\n' +
      '\n' +
      'Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, Quoc V Le. 2021. Finetuned language models is zero-shot learners. _ arXiv preprint arXiv:2109.01652_.\n' +
      '* Wolf et al. (2019) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, et al. 2019. Huggingface\'s Transformers: State-of-the-artive natural language processing. _ arXiv preprint arXiv:1910.03771_.\n' +
      '* Wu et al. (2024) Minghao Wu, Thuy-Trang Vu, Lizhen Qu, George Foster, and Gholamreza Haffari. 2024. 문서 수준 기계 번역을 위한 대규모 언어 모델 적응. _ arXiv preprint arXiv:2401.06468_.\n' +
      '* Xiao et al. (2021) Chaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, and Maosong Sun. 2021. 법률가: 중국 법률 장문의 문서에 대한 사전 훈련된 언어 모델. _ AI Open_, 2:79-84.\n' +
      '* Xu et al. (2023) Haoran Xu, Young Jin Kim, Amr Sharaf, and Hany Hassan Awadalla. 2023. 기계 번역의 패러다임 전환: 대형 언어 모델의 번역 성능 향상. _ arXiv preprint arXiv:2309.11674_.\n' +
      '* Yao et al. (2021) Yunzhi Yao, Shaohan Huang, Wenhui Wang, Li Dong, and Furu Wei. 2021. Adapt-and-distill: 도메인에 대한 작고 빠르고 효과적인 사전 훈련된 언어 모델 개발 _ arXiv preprint arXiv:2106.13474_.\n' +
      '* Yu et al. (2023) Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023. 메타매스: 큰 언어 모델에 대해 자신의 수학적 질문을 부트스트랩한다. _ arXiv preprint arXiv:2309.12284_.\n' +
      '* Zhang et al. (2024) Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu. 2024. Tinyllama: 오픈소스 소형 언어 모델 _ arXiv preprint arXiv:2401.02385_.\n' +
      '* Zhang et al. (2022) Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt: Open pre-trained transformer language models. _ arXiv preprint arXiv:2205.01068_.\n' +
      '* Zhou et al. (2023) Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2023. Lima: Lessly is more for alignment. _ arXiv preprint arXiv:2305.11206_.\n' +
      '* Zhou et al.(2021)\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>