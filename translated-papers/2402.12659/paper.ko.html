<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# The FinBen: Large Language Model을 위한 Holistic Financial Benchmark\n' +
      '\n' +
      '({}^{a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({}a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\\), ({a}\n' +
      '\n' +
      '({}^{a}\\)Fin AI, \\({}^{b}\\)Wuhan University, \\({}^{c}\\) Manchester University, \\({}^{d}\\) Florida University,\n' +
      '\n' +
      '({}^{e}\\)Columbia University, \\({}^{f}\\)Chinese University of Hong Kong, Shenzhen,\n' +
      '\n' +
      '({}^{i}\\)Stevens Technology Institute \\({}^{g}\\)Sichuan University, \\({}^{h}\\)Sichuan University, \\({}^{i}\\)Stevens Technology Institute\n' +
      '\n' +
      '({}^{j}\\)Stony Brook University, \\({}^{k}\\)Nanjin Audit University,\n' +
      '\n' +
      '장서사범대학, 서남서자오동대학교\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      'LLM은 NLP를 변형시키고 다양한 분야에서 가능성을 보여주었지만 철저한 평가의 부족과 금융 업무의 복잡성으로 인해 금융에서의 잠재력은 미궁에 빠져 있다. 이는 LLM의 급속한 발전과 함께 LLM에 대한 체계적인 재무 평가 벤치마크의 긴급한 필요성을 강조한다. 본 논문에서는 금융 영역에서 LLM의 기능을 철저히 평가하기 위해 특별히 설계된 최초의 포괄적인 개방형 평가 벤치마크인 FinBen을 소개한다. 핀벤은 귀납적 추론, 연상 기억, 정량적 추론, 결정화된 지능 등에서 LLM의 인지 능력을 평가하기 위해 캐텔-혼-캐롤 이론에서 영감을 얻은 세 가지 난이도 스펙트럼으로 구성된 23개의 금융 과제에 걸쳐 35개의 데이터 세트를 포함한다. GPT-4, ChatGPT 및 최신 제미니를 포함한 15개의 대표적인 LLM에 대한 우리의 평가는 재정 영역 내에서 그들의 강점과 한계에 대한 통찰력을 보여준다. 그 결과 GPT-4는 정량화, 추출, 수치 추론 및 주식 거래에서 선도적인 반면 제미니는 생성 및 예측에서 빛을 발하지만 복잡한 추출 및 예측과 함께 어려움을 겪으며 표적 개선의 필요성을 분명히 보여준다. 명령어 조정은 간단한 작업 수행을 향상시키지만 복잡한 추론 및 예측 능력 향상에는 미치지 못한다. 핀벤은 프로젝트 및 모델1의 정기적인 업데이트를 통해 AI 개발을 육성하면서 금융에서 LLM을 지속적으로 평가하고자 한다.\n' +
      '\n' +
      '각주 1: [https://github.com/The-FinAI/PIXIU](https://github.com/The-FinAI/PIXIU)\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '최근, ChatGPT2 및 GPT-4(OpenaAI, 2023)와 같은 LLM(Large Language Models) Brown 등(2020)은 자연어 처리 분야(NLP)를 재구성하고 수학, 코딩, 의학, 법률 및 금융 부벡 등(2023)에 걸쳐 전문 영역에서 주목할 만한 능력을 발휘했다. 모델 크기가 증가하고 사전 학습 데이터가 많아짐에 따라 LLM은 상황 내 학습을 위한 긴급 용량을 개발하여 제로 샷 및 소수 샷 설정 Wei 등(2023)에서 광범위한 도메인 특정 작업에 걸쳐 현저하게 수행할 수 있게 되었다. 금융 도메인 내에서, 최근 여러 연구들 Xie et al.(2023); Lopez-Lira and Tang (2023); Li et al.(2023); Xie et al.(2023)은 금융 텍스트 분석 및 예측 태스크들에서 GPT-4와 같은 진보된 LLMs들의 큰 잠재력을 보여주었다. 그들의 잠재력은 분명하지만, 그들의 역량과 금융에 대한 한계에 대한 포괄적인 이해는 대체로 미개척 상태로 남아 있다. 이는 광범위한 평가 연구와 벤치마크가 부족하고, 경제 활동의 전문적 성격과 관련된 내재적 복잡성에 기인한다.\n' +
      '\n' +
      '각주 2: [https://openai.com/chatgpt](https://openai.com/chatgpt)\n' +
      '\n' +
      'FLUE Shah et al. (2022), BBT-CFLEB Lu et al. (2023), 및 PIXIU Xie et al. (2023)을 포함한 기존의 금융 도메인 평가 벤치마크들은 제한된 범위를 가지며, 주로 LLM들이 이미 광범위하게 평가된 언어 이해 능력들을 대상으로 하는 금융 NLP 작업들에만 초점을 맞추고 있다. 표 1에서 보는 바와 같이, 이들은 현실적 금융 활동 해결과 함께 영역별 금융 지식을 이해하고 추출하는 등 금융 영역의 다른 중요한 요인들을 포착하지 못하고 있다. 이와 같이 LLM 성과 평가 및 이해에 대한 효능은 제한적이다.\n' +
      '\n' +
      '또한, MMLU Hendrycks et al.(2020), HELM Liang et al.(2022) 및 BIG-bench Srivastava et al.(2023)과 같은 일반 도메인에서 새롭게 출시되는 벤치마크들이 수많은 기관들에 걸쳐 방대한 태스크들을 컴파일하고 있지만, 이들은 금융 도메인까지 확장되지 않는다. LLM의 빠른 진행과 그들의 능력과 행동에 대한 불완전한 이해는 이러한 모델 전용 체계적인 재무 평가 벤치마크의 필요성을 강조한다.\n' +
      '\n' +
      '효과적인 체계적인 재무 평가 벤치마크가 어떻게 설계되어야 하는가? 첫째, 금융영역의 복잡성, 지식추출, 텍스트생성, 수치추론 등과 같은 언어적 이해와 다양한 기술을 통합하기 위한 광범위한 과제를 포괄해야 한다. 둘째, 실제 적용 지향성: 벤치마크는 주식시장 분석 및 거래를 포함한 실제 시나리오에 초점을 맞춰 LLM의 실제 적용 능력을 강조해야 한다. 셋째, 금융영역별 특성 포함: 금융의 고유한 측면, 특정 지식, 용어, 개념을 요구하는 과제 포함, LLM의 현장 숙련도를 입증해야 한다. 4) 인간 수준의 인지에 대한 고려: 인간과 유사한 인지 능력을 측정하고, 재정적 맥락 내에서 의사 결정, 문제 해결 및 추상적 추론에 대한 LLM을 평가해야 한다.\n' +
      '\n' +
      '이러한 격차를 해소하기 위해 우리는 금융 영역에서 LLM의 능력을 평가하기 위해 설계된 첫 번째 오픈 소스 3 종합 평가 벤치마크인 FinBen을 제안한다. 그림 1에서 볼 수 있듯이 핀벤은 심리학 및 교육학 분야에서 Cattell-Horn-Carroll(CHC) 이론 슈나이더 및 McGrew(2012)에서 영감을 받은 세 가지 난이도 스펙트럼으로 구성된 23개의 금융 업무에 걸친 35개의 데이터 세트를 포함하여 귀납적 추론, 연상 기억, 정량적 추론, 결정화된 지능, 유체 지능 및 일반 지능을 포함한 다양한 인지 영역에 걸친 LLM을 평가한다. 스펙트럼 I은 정량화, 추출 및 수치 이해를 포함한 기초 작업으로 구성되어 기본 인지 기술의 기반을 마련한다. 업그레이드, 스펙트럼 II는 더 복잡한 세대 및 예측 작업을 파헤치며 향상된 인지 관여를 요구한다. 정점에서 스펙트럼 III는 일반 인텔리전스의 적용을 예시하면서 정교한 주식 거래 업무에 초점을 맞춘다.\n' +
      '\n' +
      '각주 3: 우리는 모든 자원을 연구 커뮤니티에 공개할 것이다.\n' +
      '\n' +
      'FinBen은 위의 기준에 따라 기존 벤치마크와 그 적용 범위의 폭과 깊이를 구별하고, 금융 영역에 대한 고유한 맞춤형 초점: 1) **Wide 커버리지**: FinBen은 고전적인 NLP 태스크(텍스트 분석, 지식 추출, 질문 응답)를 재무 특정 과제(숫자 라벨링)와 통합하고 실제 금융 애플리케이션(주식 예측, 신용 점수)에 대한 LLM을 평가하여 혁신한다. 이 광범위한 접근법은 LLM의 무역 성과를 포괄적으로 공개한다. 2) FinBen은 뉴스, 트윗, 수익 통화, 금융 문서, 테이블 및 시계열 데이터를 포함한 다양한 데이터 형태와 텍스트 유형을 수용하여 LLM의 이해 및 금융 콘텐츠 생성에 대한 철저한 평가를 용이하게 한다. 3) **다양한 난이도**: 핀벤은 뉴스 헤드라인 분류와 같은 단순한 기본 작업에서 주식 이동 예측과 같은 고급 인지 참여 작업, 주식 거래와 같이 인간에게 도전하는 훨씬 더 복잡한 일반 지능 작업에 이르기까지 다양한 난이도의 작업을 통합한다. 이 범위는 LLM의 미묘한 평가를 가능하게 하여 금융의 강점과 약점을 완전히 매핑한다.\n' +
      '\n' +
      '우리는 15개의 대표적인 일반 LLM을 테스트한다.\n' +
      '\n' +
      '그림 1: FinBen의 평가 프레임워크.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:3]\n' +
      '\n' +
      '금융 서사에서의 감정. _ 1) 감성 분석_은 금융 텍스트에서 감성 정보를 추출하는 것에 중점을 둔다. 우리는 금융 용어 은행(FPB)(Malo et al., 2014), FiQA-SA(Maia et al., 2018) 및 TSA(Cortis et al., 2017) 데이터 세트의 두 가지 데이터 세트를 활용한다. _ 2) 뉴스 헤드라인 분류_는 2000년부터 2019년까지 "금"에 관한 뉴스 및 그들의 9개의 대응하는 태그를 포함하는 헤드라인 데이터세트(Sinha and Khandait, 2021)를 이용하여 금융 텍스트 내의 가격 움직임과 같은 부가 정보를 분석한다. _ 3) Hawkish-Dovish classification_는 FOMC(Shah et al., 2023) 데이터셋을 이용하여 금융 텍스트의 미묘한 언어와 경제적 의미를 중심으로 통화정책 텍스트로부터 문장을 \'hawkish\' 또는 \'dovish\'로 분류하는 것을 목적으로 한다. _ 4) Argument unit classification_FinArg AUC dataset(Sy et al., 2023)을 이용하여 문장들을 클레임 또는 전제로 분류한다. _ 5) Argument relation detection_는 FinArg ARC dataset(Sy et al., 2023)을 이용하여 소셜 미디어 게시물 간의 관계(공격, 지원 또는 무관)를 식별한다. _ 6) Multi-class classification_targets categorized various financial text, including analyst report, news article, and investors comments, utilizing the MultiFin dataset (Jorgensen et al., 2023). 7) 딜 완전성 분류_MA 데이터셋을 채용하여 인수합병 이벤트가 뉴스 및 트윗에 기초하여 "완료"되거나 "소문"으로 남아 있는지 예측한다(Yang et al., 2020). 8) ESG issue identification_는 MLESG dataset(Chen et al., 2023)을 이용하여 재무문서에서 ESG(Environmental, Social, and Governance) 우려를 탐지하는 것에 중점을 둔다. 모든 데이터 세트에 대해 평가는 정확도와 F1 점수를 활용한다.\n' +
      '\n' +
      '**추출.** 4개의 정보 추출 작업에서 5개의 데이터셋을 포함하는 추출 작업, 대규모 데이터셋에서 특정 금융정보를 정확하게 검색할 수 있는 LLM의 능력을 평가하는 작업, 연관메모리(Ma)와 밀접하게 연결된 프로세스. _ 1) 명명된 개체 인식_NER(Alvarado et al., 2015) 및 FINERORD(Shah et al., 2023) 데이터셋을 이용하여 금융협정 및 SEC 파일링으로부터 LOCATION, ORGANIZATION, PERSON과 같은 개체를 추출한다. 2) Relation extraction_는 FINRED dataset과 함께 금융 뉴스 및 실적 성적표에서 "product/material produced" 및 "manufacturer" 등의 관계를 식별한다(Sharma et al., 2022). _3). 인과 분류 - 금융 뉴스 및 SEC 보고서의 문장이 인과 관계를 전달하는지 여부를 식별합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l l l} \\hline \\hline\n' +
      '**Data** & **Task** & **Valid** & **Test** & **Evaluation** & **License** \\\\ \\hline FPB (Malo et al., 2014) & sentiment analysis & 775 & 970 & F1, Accuracy & CC BY-S A 3.0 \\\\ FiQA-SA (Maia et al., 2018) & sentiment analysis & 188 & 235 & F1 & Public \\\\ TSA (Cortis et al., 2017) & sentiment analysis & - & 561 & F1, Accuracy & CC BY-NC-S A 4.0 \\\\ Headlines (Sinha and Khandait, 2021) & news headline classification & 1,141 & 2,283 & Avg F1 & CC BY-S A 3.0 \\\\ FOMC (Shah et al., 2023) & hawkish-dovish classification & - & 496 & F1, Accuracy & CC BY-NC-4.0 \\\\ FinArg-ACy (Sy et al., 2023) & argument unit classification & - & 969 & F1, Accuracy & CC BY-NC-S A 4.0 \\\\ FinArg-ARC (Sy et al., 2023) & argument relation classification & - & 496 & F1, Accuracy & CC BY-NC-S A 4.0 \\\\ MultiFiz (Jorgensen et al., 2023) & multi-class classification & - & 690 & F1, Accuracy & Public \\\\ MA (Yang et al., 2020) & deal completeness classification & - & 500 & accuracy\\({}_{\\text{F1}}\\) & Public \\\\ MLESG (Chen et al., 2023) & ESG issue identification & - & 300 & accuracy\\({}_{\\text{F1}}\\) & CC BY-NC-ND \\\\ \\hline NER (Alvarado et al., 2015) & named entity recognition & 103 & 980 & Entity F1 & CC BY-NA 3.0 \\\\ FINER-ORD (Shah et al., 2023) & named entity recognition & - & 1080 & Entity F1 & CC BY-NC-4.0 \\\\ FinRED (Sharma et al., 2022) & relation extraction & - & 1,068 & F1, Entity F1 & Public \\\\ SC (Manila et al., 2020) & causal classification & - & 8,630 & F1,Failor F1 & CC BY 4.0 \\\\ CD (Marako et al., 2020) & causal detection & - & 226 & F1,Entity F1 & CC BY 4.0 \\\\ \\hline FiQA (Chen et al., 2021) & question answering & 883 & 1,147 & EM Accuracy & MIT License \\\\ TAPQA (Zhu et al., 2021) & question answering & - & 1,668 & F1,EM Accuracy & MIT License \\\\ ConFifQA (Chen et al., 2022) & question answering & - & 2,210 & 1,490 & EM Accuracy & MIT License \\\\ FNNL (Sharma et al., 2023) & numeric labeling & - & 318 & F1,EM Accuracy & Public \\\\ FSRL (Lamm et al., 2018) & token classification & - & 97 & F1, EM Accuracy & MIT License \\\\ \\hline ECTN (Mukherjee et al., 2022) & text summarization & - & 495 & ROUGE, BERTScore, BARTScore & Public \\\\ EDTSum (Zhu et al., 2021) & text summarization & - & 2000 & ROUGE, BERTScore, BARTScore & Public \\\\ \\hline BigData22 (Soun et al., 2022) & stock movement prediction & 798 & 1,470 & Accuracy, MCC & Public \\\\ ACL18 (Xu and Cohen, 2018) & stock movement prediction & 2,560 & 3,720 & Accuracy, MCC & MIT License \\\\ CIKMish (Wu et al., 2018) & stock movement prediction & 431 & 1,140 & Accuracy, MCC & Public \\\\ German (Hofmann, 1994) & credit scoring & - & 1000 & F1, MCC & CC BY 4.0 \\\\ Australian (Quinlan) & credit scoring & - & 690 & F1, MCC & CC BY 4.0 \\\\ LendingClub (Feng et al., 2023) & credit scoring & 1,344 & 2,690 & F1, MCC & CC1.0 \\\\ ccf (Feng et al., 2023) & fraud detection & 1,138 & 2,278 & F1, MCC & (DDcl) v1.0 \\\\ ccfand (Feng et al., 2023) & fraud detection & 1,907 & 2,697 & F1, MCC & Public \\\\ polish (Feng et al., 2023) & financial distress identification & 868 & 1,736 & F1, MCC & CC BY 4.0 \\\\ Taiwan (Feng et al., 2023) & financial distress identification & 681 & 1,364 & F1, MCC & CC BY 4.0 \\\\ ProtoSegur (Feng et al., 2023) & chain analysis & 1,189 & 2,381 & F1, MCC & Public \\\\ travelinsurance (Feng et al., 2023) & chain analysis & - & 3,800 & F1, MCC & (ODbl) v1.0 \\\\ fintrade (Yu et al., 2023) & stock trading & - & 3,384 & CR, SR, DV, AV, MD & MIT License \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: FinBen에 포함된 작업, 데이터 세트, 데이터 통계 및 평가 메트릭.\n' +
      '\n' +
      'SC dataseting the SC dataset (Mariko et al., 2020) _ 4) Causal detection_ identifies cause and effect span in financial text with the CD dataset (Mariko et al., 2020). 이러한 과제에 대한 평가는 F1 점수(Goutte and Gaussier, 2005)와 Entity F1 점수(Derczynski, 2016)에 초점을 맞추고 있다.\n' +
      '\n' +
      '** 이해.** 이해 작업은 4개의 수치 추론 작업에서 5개의 데이터 세트를 포함하며, 복잡한 수치 데이터를 해석하고 분석하기 위해 LLM에 도전하고 복잡한 재무 통계를 제공하며, 정량적 추론(Gq) 능력을 지원한다. _ 1) Question answering_는 FinQA(Chen et al., 2021) 및 TATQA(Zhu et al., 2021) 데이터셋을 활용하여 재무 보고서 및 표로 다단계 수치추론을 통한 문제 해결에 중점을 둔다. _ 2) Multi-turn question answering_는 ConvFinQA dataset (Chen et al., 2022). _ 3) Numeric labeling_는 FNXL 데이터셋으로 2,794개의 레이블을 이용하여 금융문서 내 숫자 스팬을 태깅하는 것을 목적으로 한다(Sharma et al., 2023). 4) Token classification_는 FSRL 데이터셋(Lamm et al., 2018)을 활용하여, 유사 프레임을 추출하여 텍스트 유사에서 공통 속성과 비교 요소를 식별하는 것을 목표로 한다. Entity F1 점수(Derczynski, 2016) 및 Exact Match Accuracy(EMAcc) 메트릭(Kim et al., 2023)은 이러한 태스크들을 평가하기 위해 사용된다.\n' +
      '\n' +
      '### 스펙트럼 II: 향상된 인지 참여\n' +
      '\n' +
      '스펙트럼 II에는 LLM의 생성(결정화된 지능) 및 예측(유체 지능) 능력을 평가하기 위해 설계된 6개 작업에 걸쳐 14개의 데이터 세트가 있어 더 깊은 인지 참여가 필요하다.\n' +
      '\n' +
      '**생성.**생성 태스크는 결정화된 지능(Gc)을 포함하는 일관성 있고, 유익하며, 관련 텍스트 출력을 생성하는 모델들의 숙련도를 측정한다. 우리는 earnings call transcript를 요약하기 위한 ECTSUM (Mukherjee et al., 2022) dataset과 금융 뉴스 기사를 간결한 요약으로 추상화하기 위한 EDTSUM (Zhou et al., 2021) dataset을 활용한 _text summarization_ task에 중점을 둔다. ROUGE 점수(Lin, 2004), BERTScore(Zhang et al., 2019) 및 BART Score(Yuan et al., 2021)를 사용하여 평가되며, 기계 생성 요약과 전문가 요약 간의 정렬, 사실적 일관성 및 정보 보유를 측정하기 위해 정량화하는 메트릭이다.\n' +
      '\n' +
      '**예측.** 예측 태스크는 유동 인텔리전스(Gf)를 활용하며, 신흥 패턴으로부터 미래 시장 및 투자자 행동을 적응적으로 예측하기 위한 도전 모델이다. 5개의 예측 작업에서 12개의 데이터 세트를 포함합니다. _ 1) 주식 움직임 예측_은 빅데이터22(Soun et al., 2022), ACL18(Xu and Cohen, 2018) 및 CIKM18(Wu et al., 2018)의 세 가지 데이터세트를 활용하여 과거 가격 및 트윗을 기반으로 주식 방향을 긍정 또는 부정 중 하나로 예측하는 것에 중점을 둔다. _ 2) Credit scoring_는 개인을 이력 고객 데이터를 이용하여 "좋음" 또는 "나쁨" 신용 위험으로 분류하며, 다음을 포함하는 데이터 세트를 채용한다: 독일어(Hofmann, 1994), 호주(Quinlan) 및 LendingClub(Feng et al., 2023). _ 3) 사기 검출_ 수반은 CCf(Feng et al., 2023) 및 ccfraud(Feng et al., 2023)의 두 데이터세트를 사용하여 트랜잭션을 "사기" 또는 "비사기"로 분류한다. _ 4) Financial distress identification_는 polish(Feng et al., 2023)와 taiwan dataset(Feng et al., 2023)을 이용하여 기업의 파산위험을 예측하는 것을 목적으로 한다. _ 5) Claim analysis_ anonymizes client data for privacy, labeling a "target" to indicate claim status, using two datasets: PortoSeguro (Feng et al., 2023) and travelinsurance (Feng et al., 2023). 이러한 과제를 평가하기 위해 F1 점수와 Matthews 상관계수(MCC)(Chicco and Jurman, 2020)를 사용한다.\n' +
      '\n' +
      '### 스펙트럼 III : 일반 지능\n' +
      '\n' +
      '스펙트럼 III에 따라 분류된 무역(Punt, 2017)의 전략적 의사 결정은 금융 LLM의 최고 과제이며, 일반 정보(g)의 사용을 강조한다. 이 과제는 재무 분석에서 가장 높은 수준의 인지 능력을 나타내는 전문가에게도 도전인 거래 전략을 수립하고 실행하기 위해 다양한 정보를 종합하는 모델의 숙련도를 평가한다. SOTA 재무 LLM 에이전트 _FinMem_(Yu et al., 2023)는 역사적 가격, 뉴스 및 감정 분석을 통해 실제 거래를 시뮬레이션하고 7개의 주요 주식을 선별한 FinTrade 데이터 세트를 기반으로 정교한 주식 결정에 대한 LLM을 평가하는 데 사용된다. 성과는 누적 수익률(CR)(Ariel, 1987), 샤프 비율(SR)(Sharpe, 1998), 데일리(DV) 및 연간 변동성(AV)(Zhou et al., 2023), 최대 인출(MD)(Magdon-Ismail and Atiya, 2004)으로 측정되며 수익성, 위험 관리 및 의사 결정 능력에 대한 포괄적인 평가를 제공한다.\n' +
      '\n' +
      'Evaluation\n' +
      '\n' +
      'FinBen 벤치마크에서 대표적인 일반 LLM과 재무 LLM 15개의 제로샷과 소샷 성능을 평가하는데, 1) ChatGPT: OpenAI에서 개발한 175B 파라미터로 명령어 추종 LLM을 포함한다. 2) GPT-4(OpenAI, 2023b): OpenAI에 의해 제안된, 대략 1T 파라미터를 갖는 강력한 명령어-추종 LLM. 3) Gemini Pro(Team et al., 2023): A multimodal AI LLM with 50T parameters, released by Google. 4) LLaMA2-70B (Touvron et al., 2023): MetaAI에 의해 개발된 70B 파라미터를 갖는 명령어-추종 LLM. 5) ChatGLM3-6B (Du et al., 2022): Zhipu AI 및 Tsinghua KEG에 의해 공동으로 출시된, 6B 파라미터를 갖는 대화식 LLM. 6) Baichuan2-6B (Baichuan, 2023): Baichuan Intelligent Technology에 의해 런칭된, 6B 파라미터를 갖는 오픈-소스 LLM. 7) InternLM-7B(Team, 2023b): SenseTime에 의해 제안된, 실제 시나리오에 맞춘 오픈소싱 7B 파라미터 베이스 모델. 9) Falcon7B (Almazrouei et al., 2023): 큐레이션된 말뭉치로 강화된 RefinedWeb의 1500B 토큰들에 대해 트레이닝된 7B 파라미터 인과 디코더-전용 LLM 모델. 10) Mixrtal 8\\(\\times\\)7B (Jiang et al., 2024): A LLM with the Sparse Mixture of Experts (SMoE) architecture. 11) Code Llama-7B (Roziere et al., 2023): An open-source LLM model for generating programming code, launched by Meta AI with 7B parameters. 12) FinGPT(Yang et al., 2023a): An 7B instruction finetuned financial LLM with sentiment analysis tasks. 13) FinMA-7B (Xie et al., 2023b): 다수의 NLP 및 예측 태스크를 갖는 7B 명령어 파인튜닝된 금융 LLM. 14) DISCFinLLM (Chen et al., 2023c): An open-sourced financial LLM, fine-tuned from Baichuan-13B-Chat (Baichuan, 2023). 15) CFGPT(Li et al., 2023a): 오픈 소스 LLM, 특히 금융 섹터를 위해 설계되고 70억 개의 파라미터를 포함하는 중국 금융 데이터세트에 대해 트레이닝된다. 모든 실험은 5개의 NVIDIA TITAN RTX 그래픽 GPU와 2개의 NVIDIA GeForce RTX 3090 GPU를 사용하여 독점적으로 수행되며 완료하는 데 약 20시간이 소요된다. 평균적으로 실험당 2개의 GPU가 할당되어 총 약 20400 GPU 시간에 달한다.\n' +
      '\n' +
      '## 4 Results\n' +
      '\n' +
      '표 3 및 표 4는 FinBen의 모든 데이터 세트에 대한 12개의 대표적인 LLM의 성능을 보여준다.\n' +
      '\n' +
      '### 기본 작업 분석\n' +
      '\n' +
      '표 3을 통해 근본적인 과제를 살펴보면 GPT-4가 가장 높은 평균 성과를 보이며 ChatGPT, Gemini 순으로 두드러짐을 알 수 있다. 모든 개방형 LLM 중 재무적 LLM FinMA-7B는 GPT-4와 같은 더 큰 모델을 능가하는 FPB와 같은 여러 분류 작업에서 우수한 성능을 보여주는데, 이는 훈련 데이터 세트에 대한 맞춤형 명령 튜닝에 기인한다. 범용 LLM의 경우 LLaMA2 70B가 큰 모델 크기로 인해 평균 성능을 이끈다. 중국어에 맞춘 모델 중 ChatGLM2-6B는 평균 성능에서 InternLM 7B를 능가하여 금융 업무를 처리하는 데 효율성을 나타낸다. 그러나, 중국 금융 데이터에 대해 미세 조정된 CFGPT sft-7B-Full은 기본 모델 InternLM 7B에 비해 몇 가지 데이터 세트에서 제한된 개선을 보이고 멀티핀과 같은 다른 데이터 세트에서도 성능이 감소한다. 이러한 경향은 언어 기반 불일치를 시사하며, 중국어 데이터로 미세 조정하면 영어 과제 수행에 부정적인 영향을 미칠 수 있음을 강조하여 모델 훈련에서 언어 간 적응의 복잡성을 강조한다.\n' +
      '\n' +
      '특히, Headline과 같은 **quantification** 데이터셋에서는 Gemini와 FinMA-7B를 포함한 기타 재정적으로 조정된 LLM과 같은 모델이 GPT-4와 동등하거나 심지어 더 나은 성능을 보인다. 그러나, FinQA 및 ConvFinQA와 같은 데이터셋에서 **이해** 태스크를 처리할 때 GPT-4와 ChatGPT는 다른 데이터셋을 크게 능가하여 Gemini와 LLaMA2-70B와 같은 모델의 제한된 수치 추론 능력을 강조한다. 문제는 FinRED, CD, FNXL 및 FSRL과 같은 복잡한 정보 추출 및 숫자 라벨링이 필요한 **추출** 데이터 세트에서 지속되며 GPT-4를 포함한 모든 모델이 부족하여 이러한 영역에서 추가 개선이 필요함을 나타낸다.\n' +
      '\n' +
      '결론적으로 GPT-4와 같은 SOTA LLM은 정량화 작업 전반에 걸쳐 강력한 성능을 나타낸다. 그러나 수치 추론과 복잡한 정보 추출 작업에는 분명한 격차가 있어 추가 개발의 필요성을 지적한다. 명령어 조정은 성능을 크게 향상시키는 것으로 나타났으며, 이는 전문 금융 업무에서 모델 기능을 개선하기 위한 귀중한 접근 방식을 제안한다. 이 결과는 언어 간 모델 조정의 복잡성과 다양한 금융 업무 전반에 걸쳐 LLM의 효율성을 향상시키는 데 신중한 언어 고려의 중요성을 강조한다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:7]\n' +
      '\n' +
      '요약 데이터 세트는 일관된 요약을 생성하는 능력을 보여줍니다. 그럼에도 불구하고, 모든 모델은 문장에 대한 정확한 라벨 시퀀스의 생성을 요구하는 추출 요약으로 어려움에 직면해 있다. ** 예측** 작업에서 Gemini는 GPT-4가 우수한 성능을 보여주는 호주 신용 점수 데이터 세트를 제외하고 대부분의 데이터 세트에서 자신을 구별한다.\n' +
      '\n' +
      '오픈소스 LLM 중 LLaMA2 70B는 텍스트 요약에서 두드러진 반면, LLaMA2-7B 채팅은 예측 작업에서 탁월하다. 빅데이터22 및 ACL18과 같은 데이터 세트를 사용한 명령어 조정에도 불구하고 FinMA 7B는 예측 성능에서 팔콘 7B와 같은 피어보다 뒤처져 있어 보다 효과적인 개선 전략의 필요성을 강조한다. CFGPT sft-7B-Full은 기반 모델인 InternLM 7B에 비해 일관되게 성능 감소를 보여준다. 예측을 위해서는 모든 LLM이 예상되는 결과를 충족하지 못하고 전통적인 방법론에 뒤처진다는 것을 인정하는 것이 중요하다. 기존 연구 [23, 24]와의 일관된 관찰은 기존 방법만큼 효과적인 고급 인지 작업을 해결하는 LLM의 능력의 현저한 결핍을 강조한다.\n' +
      '\n' +
      '이 분석은 특히 더 높은 인지 기술을 요구하는 텍스트 생성 및 예측 작업에서 GPT-4 및 제미니와 같은 업계 리더를 포함한 LLM의 개선 가능성을 보여준다.\n' +
      '\n' +
      '### General Intelligence Task Analysis\n' +
      '\n' +
      '높은 수준의 일반 지능을 요구하는 주식 거래의 복잡한 작업에 대한 다양한 LLM(Large Language Models)의 비교 분석은 표 45에 제시되어 있으며, 그 결과는 전통적인 Buy & Hold 전략보다 모든 LLM의 우수한 성능을 나타내어 보다 유리한 거래 결정을 공식화하는 데 효율성을 강조한다. 평가된 LLMs 중 GPT-4는 1을 초과하는 가장 높은 샤프 비율(SR)을 달성함으로써 자신을 구별한다. 이 성과는 GPT-4의 위험 대비 이익 최적화 숙련도를 강조하며, 이는 다른 LLMs에서 다소 감소되어 투자자를 더 적은 수익에 대해 더 높은 위험에 노출시키는 경향이 있다. 또한 GPT-4는 최소 최대 드로다운(MDD)을 보여 잠재적 손실을 상대보다 더 효과적으로 제한하여 보다 안전한 투자 방법을 제공한다.\n' +
      '\n' +
      '각주 5: 상세 거래 실적에 대해서는 부록 E를 참조\n' +
      '\n' +
      '대조적으로, ChatGPT는 상당히 낮은 성능 메트릭을 나타내어 재무적 의사 결정 능력의 한계를 나타낸다. 반면에 쌍둥이는 GPT-4에 비해 낮은 위험과 변동성을 나타내면서도 칭찬할 만한 수익을 유지하면서 두 번째로 우수한 수행자의 위치를 확보한다. 오픈 소스 모델을 고려할 때 LLaMA-70B는 변동성이 낮음에도 불구하고 LLM 중 이익이 가장 적게 산출되어 위험 관리와 수익성 간의 상충 관계가 강조되는 것으로 관찰된다.\n' +
      '\n' +
      '모수가 700억 미만인 더 작은 모델의 경우 제한된 이해, 추출 능력 및 제한된 컨텍스트 창에 기인하여 트랜잭션 전반에 걸쳐 일관되게 거래 지침을 준수할 수 없는 현저한 무능력이 주목된다. 이러한 한계는 복잡한 재무 추론과 의사 결정을 요구하는 작업에서 LLMs가 직면한 중요한 문제를 강조하여 이러한 고수준의 인지 작업을 효과적으로 해결하기 위해 보다 발전된 모델의 필요성을 강조한다.\n' +
      '\n' +
      '본질적으로 주식 거래 업무에서 LLM의 예외적 성과는 금융 영역 내에서 일반 지능을 구체화할 수 있는 능력을 조명한다. 다양한 인지 기술의 통합과 실제 금융 문제에 대한 이러한 기술의 적용에 뿌리를 둔 이 능력은 금융 분석 및 의사 결정의 새로운 시대를 예고한다. 따라서 본 연구 결과는 금융 시장의 복잡성을 탐색하는 데 LLM의 중요한 잠재력을 긍정할 뿐만 아니라 고수준의 일반 지능을 요구하는 작업에서 LLM의 추가 개발 및 적용을 위한 유망한 궤적을 제안한다.\n' +
      '\n' +
      '## 5 Conclusion\n' +
      '\n' +
      '이 작업에서는 금융 도메인에서 LLM을 평가하기 위해 특별히 설계된 포괄적인 금융 벤치마크를 소개한다. 이 벤치마크는 세 가지 난이도 스펙트럼으로 구성된 23개 작업에서 35개의 다양한 데이터 세트를 포함한다. 핀벤은 금융 영역의 이전 벤치마크와 달리 정량화, 추출, 이해, 생성, 예측을 포함한 광범위한 작업을 포함하도록 평가를 확장한다. 특히, 처음으로 대리인 기반 평가 프레임워크를 통해 직접 거래 업무를 통합한다. 15개의 대표적인 LLM에 대한 포괄적인 평가는 몇 가지 핵심 통찰력을 산출한다. 1) GPT-4는 정량화, 추출, 미도란 및 거래와 관련된 작업에서 최고 수행자로 등장하는 반면 제미니는 생성 및 예측 작업을 주도한다. 2) 기존의 LLM은 기초적인 작업에 대해 칭찬할 만한 성능을 보여주지만, 인지적으로 더 까다로운 작업과 일반 지능을 요구하는 작업에 대한 효과는 제한적인 것으로 보인다. 3) 본 연구 결과는 LLM이 거래 결정을 직접 알릴 수 있는 능력을 강조하여 향후 연구를 위한 유망한 방법을 제안한다. 앞으로 우리는 FinBen을 추가 언어와 광범위한 금융 거래 업무를 포함하도록 확장하여 금융 LLMs 분야를 발전시키는 데 벤치마크의 적용 가능성과 유용성을 더욱 넓히는 것을 목표로 한다.\n' +
      '\n' +
      '### Limitations\n' +
      '\n' +
      '핀벤을 통해 금융 영역에서 LLM을 벤치마킹하려는 획기적인 노력에도 불구하고 벤치마크의 효과와 적용 가능성에 영향을 미칠 수 있는 몇 가지 내재적 한계를 인정한다.\n' +
      '\n' +
      '**데이터 세트 크기 제한**: 핀벤의 개발에서 직면한 주요 과제는 오픈 소스 금융 데이터의 틈새 분야에서 일반적인 문제인 사용 가능한 데이터 세트의 제한된 크기이다. 이러한 한계는 모델의 금융 이해력의 깊이와 금융 컨텍스트의 전체 스펙트럼에 걸쳐 일반화하는 능력에 영향을 미칠 수 있다.\n' +
      '\n' +
      '**모델 크기 제한**: 계산 자원 제약으로 인해 우리의 평가는 LLaMA 70B 모델로 제한되었다. 이 제한은 잠재적으로 더 크거나 다르게 설계된 모델이 핀벤의 포괄적인 작업 세트에서 보여줄 수 있는 기능과 성능 뉘앙스를 간과한다. **일반화 가능성**: 업무, 특히 거래 및 예측과 관련된 업무는 주로 미국 시장 및 영어 텍스트의 데이터를 기반으로 합니다. 이러한 초점은 언어적 다양성과 독특한 시장 역동성이 중요한 역할을 하는 글로벌 금융 시장에 대한 벤치마크의 적용 가능성을 제한할 수 있다. **잠재적 부정적 영향**: 핀벤이 금융 언어 이해 분야를 발전시키는 것을 목표로 하는 반면, 금융 오정보의 전파나 시장에 대한 비윤리적 영향의 발휘와 같은 오용 가능성을 고려하는 것이 중요하다. 이러한 위험은 핀벤6으로 훈련되거나 평가된 LLM의 배치에서 책임 있는 사용의 중요성과 추가 안전 장치를 강조한다.\n' +
      '\n' +
      '각주 6: 이 작업에 대한 자세한 윤리적 및 법적 진술은 부록을 참조하십시오.\n' +
      '\n' +
      '### Ethical Statement\n' +
      '\n' +
      '저자에 의한 핀벤의 개발 및 보급은 잠재적인 권리 침해 또는 법적 문제에 대한 모든 책임을 진다. 핀벤의 건설이 프라이버시를 존중하고 확립된 윤리 지침을 준수하도록 하기 위한 근면한 노력이 착수되었다. 핀벤 내에서 컴파일된 데이터 세트는 사용자가 조건을 준수하는 데 동의할 것으로 예상되는 MIT 라이선스에 따라 공유된다.\n' +
      '\n' +
      '관련된 소스 코드, 데이터 세트 및 부록("재료")을 포함하는 이 원고는 학술 및 교육 추구를 위해 독점적으로 지정된다. 자료가 재무, 법률 또는 투자 상담 등을 제공하지 않으며, 어떠한 형태의 의사 결정의 토대로서 활용되어서는 안 된다는 점을 인정할 필요가 있다.\n' +
      '\n' +
      '저자들은 재료의 정확성과 신뢰성을 검증하기 위해 합리적인 부지런함을 발휘했지만 특정 적용에 대한 완전성 또는 적합성에 대해 명시적 또는 묵시적 보증이 확장되지 않았다. 저자는 소속 기관과 함께 고용 또는 재료에 대한 의존에서 비롯될 수 있는 직접 또는 간접이든 손실, 손상 또는 기타 결과에 대한 책임을 면제한다. 재정적, 법적 또는 투자 결정을 위한 전문적인 상담을 요청하는 것은 사용자의 의무이다.\n' +
      '\n' +
      '이 자료를 참조하거나 사용하여 개인은 해당 활용으로 인해 발생할 수 있는 청구 또는 손상에 대해 무해한 소속 기관 또는 사람과 함께 저자에 대한 면책, 방어 및 보유에 동의한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Almazrouei et al. (2023) Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, et al. 2023. Falcon series of open language models. _ arXiv preprint arXiv:2311.16867_.\n' +
      '* Alvarado et al. (2015) Julio Cesar Salinas Alvarado, Karin Verspoor, and Timothy Baldwin. 2015. Domain Adaptation of named entity recognition to support credit risk assessment. Australasian Language Technology Association Workshop 2015_의 _Proceedings에서 84-90페이지이다.\n' +
      '* Araci(2019) Dogu Araci. 2019. Finbert: 사전 훈련된 언어 모델을 사용한 금융 감정 분석.\n' +
      '* Ariel (1987) Robert Ariel. 1987. monthly effect in stock returns. _ Journal of Financial economics_, 18(1):161-174.\n' +
      '* Arizriz et al. (2017)Baichuan. 2023. 바이촨 2 : 개방형 대규모 언어 모델 _ arXiv preprint arXiv:2309.10305_.\n' +
      '* Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. 언어 모델은 소수의 학습자를 의미한다. _ 신경 정보 처리 시스템들_, 33:1877-1901의 진보들.\n' +
      '* Bubeck et al. (2023) Sebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Sparks of artificial general intelligence: Early experiments with gpt-4. _arXiv preprint arXiv:2303.12712_.\n' +
      '* Chen et al. (2023a) Chung-Chi Chen, Yu-Min Tseng, Juyeon Kang, Anais Lhuissier, Min-Yuh Day, Teng-Tsai Tu, 및 Hsin-Hsi Chen. 2023a. 다국어 에그 발급 신원 확인 금융 기술 및 자연어 처리에 관한 제5 워크숍의 진행 및 금융 예측을 위한 제2 멀티모달 AI_에서는 111-115페이지가 있다.\n' +
      '* Chen et al. (2023b) Wei Chen, Qiushi Wang, Zefei Long, Xianyin Zhang, Zhongtian Lu, Bingxuan Li, Siyuan Wang, Jiarong Xu, Xiang Bai, Xuanjing Huang, 및 Zhongyu Wei. 2023b. Disc-finllm: 여러 전문가 미세 조정을 기반으로 한 중국 금융 대형 언어 모델.\n' +
      '* Chen et al. (2023c) Wei Chen, Qiushi Wang, Zefei Long, Xianyin Zhang, Zhongtian Lu, Bingxuan Li, Siyuan Wang, Jiarong Xu, Xiang Bai, Xuanjing Huang, et al. 2023c. Disc-finllm: 여러 전문가 미세 조정을 기반으로 한 중국 금융 대형 언어 모델. _ arXiv preprint arXiv:2310.15205_.\n' +
      '* Chen et al. (2021) Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan R Routledge, et al. 2021. Finqa: 금융 데이터에 대한 수치 추론의 데이터셋. _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pages 3697-3711.\n' +
      '* Chen et al. (2022) Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, and William Yang Wang. 2022. Conv/finqa: 대화식 금융 질의 응답에서 수치추론의 연쇄를 탐색한다.\n' +
      '* Chicco and Jurman(2020) Davide Chicco and Giuseppe Jurman. 2020. The advantages of matthews correlation coefficient(mcc) over f1 score and accuracy in binary classification evaluation. _ BMC genomics_, 21(1):1-13.\n' +
      '* Cortis et al. (2017) Keith Cortis, Andre Freitas, Tobias Daudert, Manuela Huerlimann, Manel Zarrouk, Siegfried Handschuh, and Brian Davis. 2017. Semeval-2017 과제 5: 금융 마이크로 블로그 및 뉴스에 대한 세밀한 감성 분석. 제11회 국제 의미평가 워크숍(SemEval-2017)_의 _Proceedings, pages 519-535.\n' +
      '* Dai et al. (2024) Yongfu Dai, Duanyu Feng, Jimin Huang, Haochen Jia, Qianqian Xie, Yifang Zhang, Weiguang Han, Wei Tian, and Hao Wang. 2024. Liaw: 중국 법률 대형 언어 모델 벤치마크.\n' +
      '* 더진스키(2016) 레온 더진스키. 2016. Complementarity, F-score, NLP 평가. _Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\'16)_, pages 261-266, Portoroz, Slovenia. 유럽 언어 자원 협회(ELRA).\n' +
      '* Du et al. (2022) Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, 및 Jie Tang. 2022. Glm: 자기회귀 블랭크 채움으로 일반 언어 모델 사전 훈련. _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 320-335.\n' +
      '* Feng et al. (2023) Duanyu Feng, Yongfu Dai, Jimin Huang, Yifang Zhang, Qianqian Xie, Weiguang Han, Alejandro Lopez-Lira, and Hao Wang. 2023. Empowering many, biasing few: Generalist credit scoring through large language models. _ arXiv preprint arXiv:2310.00566_.\n' +
      '* Goutte and Gaussier (2005) Cyril Goutte and Eric Gaussier. 2005. A probabilistic interpretation of precision, recall and f-score, with implications for evaluation. 정보 검색에 관한 유럽 회의 345-359쪽 스프링어\n' +
      '* Han et al. (2023a) Weiguang Han, Jimmy Huang, Qianqian Xie, Boyi Zhang, Yanzhao Lai, and Min Peng. 2023a. 위험 인식 반복 강화 학습으로 페어 트레이딩을 마스터합니다.\n' +
      '* Han et al. (2023b) Weiguang Han, Boyi Zhang, Qianqian Xie, Min Peng, Yanzhao Lai, and Jimin Huang. 2023b. 선택 및 거래: 계층적 강화 학습으로 통일된 페어 트레이딩을 지향한다. _ arXiv preprint arXiv:2301.10724_.\n' +
      '* Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. 대용량 멀티태스크 언어 이해도 측정. _ arXiv preprint arXiv:2009.03300_.\n' +
      '* Hofmann (1994) Hans Hofmann. 1994. Statlog (German Credit Data). UCI 머신러닝 리포지토리. DOI:[https://doi.org/10.24432/CSNC77](https://doi.org/10.24432/CSNC77).\n' +
      '* Hongyuan et al. (2023) Dong Hongyuan, Che Wanxiang, He Xiaoyu, Zheng Guudong, and Wen Junjie. 2023. FinBART: 중국 금융 업무를 위한 사전 훈련된 seq2seq 언어 모델. _Proceedings of the 22nd Chinese National Conference on Computational Linguistics_, pages 906-917, Harbin, China. 중국 정보 처리 협회.\n' +
      '* Islam et al. (2023) Pranab Islam, Anand Kannappan, Douwe Kiela, Rebecca Qian, Nino Scherrer, and Bertie Vidgen. 2023. 금융벤치: 금융질의응답을 위한 새로운 벤치마크. _ arXiv preprint arXiv:2311.11944_.\n' +
      '* Jiang et al. (2024) Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand et al. 2024. Mixtral of experts. _ arXiv preprint arXiv:2401.04088_.\n' +
      '\n' +
      '라스무스 조겐슨, 올리버 브랜트, 마레이케 하르트만, 샹 다이, 크리스천 이글, 데스먼드 엘리엇. 2023. Multifin: 다국어 금융 nlp를 위한 데이터셋. _Findings of the Association for Computational Linguistics: EACL 2023_, pages 864-879.\n' +
      '* Kim et al. (2023) Kisub Kim, Xin Zhou, Dongsun Kim, Julia Lawall, Kui Liu, Tegawende F Bissyande, Jacques Klein, Jaekwon Lee, and David Lo. 2023. 불일치하는 메서드 이름을 어떻게 탐지하죠? 코드 검토 관점에서 본 실증적 연구. _ arXiv preprint arXiv:2308.12701_.\n' +
      '* Koncel-Kedziorski et al. (2023) Rik Koncel-Kedziorski, Michael Krumdick, Viet Lai, Varshini Reddy, Charles Lovering, and Chris Tanner. 2023. 비즈벤치: 비즈니스 및 금융에 대한 정량적 추론 벤치마크. _ arXiv preprint arXiv:2311.06602_.\n' +
      '* Lamm et al. (2018) Matthew Lamm, Arun Tejasvi Chaganty, Christopher D Manning, Dan Jurafsky, and Percy Liang. 2018. Textual analogy parsing: What\'s shared and what compared of analogous facts. _ arXiv preprint arXiv:1809.02700_.\n' +
      '* Lee et al. (2024) Jean Lee, Nicholas Stevens, Soyeon Caren Han, and Minseok Song. 2024. 금융(fnllms)의 대형 언어 모델에 대한 조사.\n' +
      '* Lei et al.(2023) Yang Lei, Jiangtong Li, Ming Jiang, Junjie Hu, Dawei Cheng, Zhijun Ding, and Changjun Jiang. 2023. Cfbenchmark: Chinese financial assistant benchmark for large language model.\n' +
      '* Li et al. (2023a) Jiangtong Li, Yuxuan Bian, Guoxuan Wang, Yang Lei, Dawei Cheng, Zhijun Ding, and Changjun Jiang. 2023a. Cfgpt: 대형 언어 모델을 가진 중국 금융 보조원.\n' +
      '* Li et al. (2023b) Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xiaomo Liu, Sameena Shah. 2023b. 채팅과 gpt-4는 금융 텍스트 분석을 위한 범용 솔루션인가요? 여러 가지 전형적인 과제에 대한 조사. _ arXiv preprint arXiv:2305.05862_.\n' +
      '* Liang et al. (2022) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar et al. 2022. Holistic evaluation of language models. _ arXiv preprint arXiv:2211.09110_.\n' +
      '* Lin(2004) Chin-Yew Lin. 2004. Rouge: 요약의 자동 평가를 위한 패키지. _텍스트 요약에서 페이지 74-81을 분기합니다.\n' +
      '* Liu et al. (2023a) Xiao-Yang Liu, Guoxuan Wang, and Daochen Zha. 2023a. Fingpt: 금융 대형 언어 모델을 위한 인터넷 규모의 데이터 민주화. _ arXiv preprint arXiv:2307.10485_.\n' +
      '* Liu et al. (2022) Xiao-Yang Liu, Ziyi Xia, Jingyang Rui, Jiechao Gao, Hongyang Yang, Ming Zhu, Christina Dan Wang, Zhaoran Wang, 및 Jian Guo. 2022. Finfl-meta: 데이터 기반 금융 강화 학습을 위한 시장 환경 및 벤치마크.\n' +
      '* Liu et al. (2023b) Xiao-Yang Liu, Ziyi Xia, Hongyang Yang, Jiechao Gao, Daochen Zha, Ming Zhu, Christina Dan Wang, Zhaoran Wang, 및 Jian Guo. 2023b. 금융 강화 학습을 위한 동적 데이터 세트 및 시장 환경.\n' +
      '* Liu et al. (2020) Zhuang Liu, Degen Huang, Kaiyu Huang, Zhuang Li, and Jun Zhao. 2020. FinBERT: 금융 텍스트 마이닝을 위한 사전 학습된 금융 언어 표현 모델. _Proceedings of the Twinth International Joint Conference on Artificial Intelligence, IJCAI-20_, pages 4513-4519. International Joint Conference on Artificial Intelligence Organization. 핀테크에서 AI에 대한 특별한 트랙.\n' +
      '* Lopez-Lira and Tang (2023) 알레한드로 Lopez-Lira and Yuehua Tang. 2023. 채팅으로 주가 움직임을 예측할 수 있습니까? return predictability and large language models. _ arXiv preprint arXiv:2304.07619_.\n' +
      '* Lu et al. (2023) Dakuan Lu, Jiaqing Liang, Yipei Xu, Qianyu He, Yipeng Geng, Mengkun Han, Yingsi Xin, Hengkui Wu, and Yanghua Xiao. 2023. Bbt-fin: 중국어 금융 도메인 사전 훈련 언어 모델, 코퍼스 및 벤치마크의 포괄적 구축. _ arXiv preprint arXiv:2302.09432_.\n' +
      '* Magdon-Ismail and Atiya (2004) Malik Magdon-Ismail and Amir F Atiya. 2004. 최대 인출. _ Risk Magazine_, 17(10):99-102.\n' +
      '* Maia et al. (2018a) Macedo Maia, Siegfried Handschuh, Andre Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur. 2018a. Www\'18 오픈 챌린지: 금융 오피니언 마이닝 및 질문 응답. 웹 컨퍼런스 2018_의 _동반 절차에서, 페이지 1941-1942.\n' +
      '* Maia et al. (2018b) Macedo Maia, Siegfried Handschuh, Andre Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur. 2018b. Www\'18 오픈 챌린지: 금융 오피니언 마이닝과 질의응답. 1941-1942 페이지.\n' +
      '* Malo et al. (2014) Pekka Malo, Ankur Sinha, Pekka Korhonen, Jyrki Wallenius, and Pyry Takala. 2014. Good debt or bad debt : 경제 텍스트에서 의미론적 지향점 검출. _ Journal of the Association for Information Science and Technology_, 65(4):782-796.\n' +
      '* Mariko et al. (2020) Dominique Mariko, Hanna Abi Akl, Estelle Labidurie, Stephane Durfort, Hugues De Mazancourt, and Mahmoud El-Haj. 2020. 금융 문서 인과 관계 탐지 공유 태스크(fincausal 2020) _ arXiv preprint arXiv:2012.02505_.\n' +
      '* McGrew (2009) Kevin S McGrew. 2009. Chc 이론과 인간의 인지 능력 프로젝트: 정신 측정 지능 연구의 거인의 어깨 위에 서 있다.\n' +
      '* Mukherjee et al. (2022) Rajdeep Mukherjee, Abhinav Bohra, Akash Banerjee, Soumya Sharma, Manjunath Hegde, Afreen Shaikh, Shivani Shrivastava, Koustuv Dasgupta, Niloy Ganguly, Saptarshi Ghosh, et al. 2022. Ectsum: long earnings call transcript의 bullet point 요약에 대한 새로운 벤치마크 데이터세트. _ arXiv preprint arXiv:2210.12467_.\n' +
      '* Maia et al. (2018)OpenAI. 2023a. Gpt-4 기술 보고서입니다\n' +
      '* OpenAI(2023) R OpenAI. 2023b. Gpt-4 기술 보고서입니다 Arxiv 2303.08774. _View in Article_, 2:13.\n' +
      '* Punt (2017) Andre E Punt. 2017. 복잡한 세계에서의 전략적 경영 의사결정: 정량화, 이해 및 절충점 활용. _ ICES Journal of Marine Science_, 74(2):499-510.\n' +
      '* Quinlan(2012) Ross Quinlan. 통계분석 회귀 분석 포아송 회귀 분석 포아송 회귀 분석 포아송 UCI 머신러닝 리포지토리. DOI:[https://doi.org/10.24432/C59012](https://doi.org/10.24432/C59012)\n' +
      '* Roziere et al. (2023) Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jeremy Rapin, et al. 2023. Code llama: code에 대한 오픈 파운데이션 모델 _ arXiv preprint arXiv:2308.12950_.\n' +
      '* Alvarado et al. (2015) Julio Cesar Salinas Alvarado, Karin Verspoor, and Timothy Baldwin. 2015. Domain Adaptation of named entity recognition to support credit risk assessment. [Proceedings of the Australasian Language Technology Association Workshop 2015_, pages 84-90, Parramatta, Australia.\n' +
      '* Schneider and McGrew (2012) W Joel Schneider and Kevin S McGrew. 2012. 지능의 캣텔-혼-캐롤 모델.\n' +
      '* Shah et al. (2023a) Agam Shah, Suvan Paturi, and Sudheer Chava. 2023a. 조 달러 단어: 새로운 금융 데이터세트, 과제 및 시장 분석. _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 6664-6679, Canada, Toronto. 컴퓨터 언어학과의 연관성\n' +
      '* Shah et al. (2023b) Agam Shah, Ruchit Vithani, Abhinav Gullapalli, and Sudheer Chava. 2023b. Finer: Financial named entity recognition dataset and weak-supervision model. _ Neural preprint arXiv:2302.11157_.\n' +
      '* Shah et al. (2022) Raj Shah, Kunal Chawla, Dheeraj Eidnani, Agam Shah, Wendi Du, Sudheer Chava, Natraj Raman, Charese Smiley, Jiaoa Chen, and Diyi Yang. 2022. 연도들이 연도들을 만났을 때: 벤치마크들 및 금융 도메인에 대한 대규모 사전 훈련된 언어 모델. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 2322-2335.\n' +
      '* Sharma et al. (2023) Soumya Sharma, Subhendu Khatuya, Manjunath Hegde, Afreen Shaikh, Koustuv Dasgupta, Pawan Goyal, and Niloy Ganguly. 2023. 금융 수치 극단적 라벨링: 데이터셋 및 벤치마킹. _Findings of the Association for Computational Linguistics: ACL 2023_, pages 3550-3561.\n' +
      '* Sharma et al. (2022) Soumya Sharma, Tapas Nayak, Arusarka Bose, Ajay Kumar Meena, Koustuv Dasgupta, Niloy Ganguly, and Pawan Goyal. 2022. Finred: 금융 도메인에서 관계 추출을 위한 데이터셋. _Companion Proceedings of the Web Conference 2022_, pages 595-597.\n' +
      '* Sharpe (1998) William F Sharpe. 1998. Sharpe ratio. _ Stetwise-the Best of the Journal of Portfolio Management_, 3:169-85.\n' +
      '* 신하와 칸다이트(2020) 앙쿠르 신하와 탄메이 칸다이트. 2020. 뉴스가 상품 시장에 미치는 영향: 데이터세트 및 결과.\n' +
      '* 신하와 칸다이트(2021) 앙쿠르 신하와 탄메이 칸다이트. 2021. 뉴스가 상품 시장에 미치는 영향: 데이터세트 및 결과. In _Advances in Information and Communication: Proceedings of the 2021 Future of Information and Communication Conference (FICC), Volume 2_, pages 589-601. Springer.\n' +
      '* Soun et al. (2022) 예준 Soun, 재민 유, 민용 조, 지형 전, 우강. 2022. 희박한 잡음 트윗으로부터 자기 지도 학습을 통한 정확한 주식 이동 예측. _2022 IEEE International Conference on Big Data(Big Data)_, pages 1691-1700. IEEE.\n' +
      '* Srivastava et al. (2023) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adria Garriga-Alonso, et al. 2023. Beyond the imitation game: Quantifying and extrapating the capabilities of language models. _ 기계학습 연구에 관한 연구\n' +
      '* Sy et al. (2023) Eugene Sy, Tzu-Cheng Peng, Shih-Hsuan Huang, Heng-Yu Lin, and Yung-Chun Chang. 2023. Fine-grained argument understanding with bert ensemble techniques: A deep dive into financial sentiment analysis. _Proceedings of the 35th Conference on Computational Linguistics and Speech Processing (ROCLING 2023)_, pages 242-249.\n' +
      '*팀(2023a) Fin-Eva팀. 2023a. 핀에바 버전 1.0\n' +
      '* Team et al. (2023) Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023. Gemini: High capable multiimodal model의 가족. _ arXiv preprint arXiv:2312.11805_.\n' +
      '*팀(2023b) InternLM팀. 2023b. 내부: 점진적으로 향상된 기능을 갖춘 다국어 언어 모델입니다.\n' +
      '* Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. 라마: 개방적이고 효율적인 기초 언어 모델들.\n' +
      '* Wang et al. (2023) Neng Wang, Hongyang Yang, and Christina Dan Wang. 2023. Fingpt: Instruction tuning benchmark for open-source large language models in financial datasets.\n' +
      '* Wei et al. (2023) Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, et al. 2023. Larger language models do in-context learning differently. _ arXiv preprint arXiv:2303.03846_.\n' +
      '* Wang et al. (2023) Huizhe Wu, Wei Zhang, Weiwei Shen, and Jun Wang. 2018. Hybrid deep sequential modeling for social text-driven stock prediction. _Proceedings of the 27th ACM international conference on information and knowledge management_, pages 1627-1630.\n' +
      '* Wu et al. (2023) Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. 2023. Bloomberggpt: 금융을 위한 큰 언어 모델.\n' +
      '* Xie et al. (2023) Qianqian Xie, Weiguang Han, Yanzhao Lai, Min Peng, and Jimin Huang. 2023a. 월 스트리트 초보자: 멀티모달 주식 이동 예측 문제에 대한 채팅의 제로 샷 분석. _ arXiv preprint arXiv:2304.05351_.\n' +
      '* Xie et al. (2023b) Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, Alejandro Lopez-Lira, and Jimin Huang. 2023b. Pixiu: 금융을 위한 대규모 언어 모델, 명령어 데이터 및 평가 벤치마크. _ arXiv preprint arXiv:2306.05443_.\n' +
      '* Xu and Cohen (2018) Yumo Xu and Shay B Cohen. 2018. 트윗 및 역사적 가격으로부터의 주식 이동 예측. _Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 1970-1979.\n' +
      '* Yang et al. (2023a) Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. 2023a. Fingpt: 오픈 소스 금융 대형 언어 모델.\n' +
      '* Yang et al. (2020a) Linyi Yang, Eoin M Kenny, Tin Lok James Ng, Yi Yang, Barry Smyth, and Ruihai Dong. 2020a. 금융 텍스트 분류에서 딥 트랜스포머에 대한 그럴듯한 반사실적 설명을 생성하는 단계 _ arXiv preprint arXiv:2010.12512_.\n' +
      '* Yang et al. (2023b) Yi Yang, Yixuan Tang, and Kar Yan Tam. 2023b. 투자: 금융 도메인 명령어 튜닝을 이용한 투자를 위한 대규모 언어 모델.\n' +
      '* Yang et al. (2020b) Yi Yang, Mark Christopher Siy UY, and Allen Huang. 2020b. 핀버트: 금융 커뮤니케이션을 위한 사전 훈련된 언어 모델.\n' +
      '* Yu et al. (2023) Yangyang Yu, Haohang Li, Zhi Chen, Yuchen Jiang, Yang Li, Denghui Zhang, Rong Liu, Jordan W. 수토우, 칼둔 카샤나 2023. Finnmem: 레이어드 메모리 및 캐릭터 디자인을 갖는 성능 강화 llm 트레이딩 에이전트.\n' +
      '* Yuan et al. (2021) Weizhe Yuan, Graham Neubig, and Pengfei Liu. 2021. 바트스코어: 생성된 텍스트를 텍스트 생성으로 평가한다. _ 신경 정보 처리 시스템_, 34:27263-27277에서의 발전.\n' +
      '* Zhang et al. (2023a) Shen규 Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, 및 Guoyin Wang. 2023a. 대형 언어 모델에 대한 지침 조정: 설문 조사입니다.\n' +
      '* Zhang et al. (2019) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. 2019. Bertscore: 텍스트 생성을 Bert로 평가 arXiv preprint arXiv:1904.09675_.\n' +
      '* Zhang et al. (2024) Xiao Zhang, Ruoyu Xiang, Chenhan Yuan, Duanyu Feng, Weiguang Han, Alejandro Lopez-Lira, Xiaofeng Liu, Sophia Ananiadou, Min Peng, Jimin Huang, and Qianqian Xie. 2024년 돌레레스? 달러? 스페인어와 영어 사이의 2개 국어의 경제적 능숙함을 풀어라.\n' +
      '* Zhang et al. (2023b) Xuanyu Zhang, Bingbing Li, and Qing Yang. 2023b. Cgce: 일반 및 금융 도메인에 대한 중국 생성 채팅 평가 벤치마크.\n' +
      '* Zhang et al. (2023c) Xuanyu Zhang, Qing Yang, and Dongliang Xu. 2023c. 슈안위안 2.0: 수천억 개의 매개 변수를 가진 중국의 대형 금융 채팅 모델.\n' +
      '* Zhou et al. (2023) Xianzheng Zhou, Hui Zhou, Huaigang Long. 2023. 지분 프리미엄 예측: 심층 신경망 모델이 작동합니까? _ 현대의 Finance_, 1(1):1-11.\n' +
      '* Zhou et al. (2021) Zhihan Zhou, Liqian Ma, and Han Liu. 2021. 이벤트를 거래: 뉴스 기반 이벤트 기반 거래를 위한 기업 이벤트 탐지.\n' +
      '* Zhu et al. (2021) Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. 2021. Tat-qa: 금융에서 표와 텍스트 내용의 하이브리드 상의 질의응답 벤치마크 _ arXiv preprint arXiv:2105.07624_.\n' +
      '\n' +
      '## 부록 A 기부금\n' +
      '\n' +
      '**과학 지도력**: 키안키안 시, 민펑, 소피아 아나냐두, 알레한드로 로페즈-리라, 하오 왕, 옌자오 라이, 벤유 왕, 샤오양 류, 강후, 지아지아 황, 지민 황. ** 출연자** 웨이구앙 한, 젠규 천, 루오위샹, 샤오장, 유에루허, 멍시샤오, 동리, 용후다이, 두안유펑, 유징슈, 하오창강, 지얀광, 첸한위안, 카일라이양, 쯔엉, 텐린장, 쯔웨이 류, 궈준생, 쯔양뎅, 유에첸장, 쯔위안요, 하항리, 양양유, 쯔앙앙, 쯔앙앙앙, 쯔앙앙앙, 쯔앙앙앙앙, 쯔앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙앙\n' +
      '\n' +
      '## 부록 B 다른 LLMs 성능\n' +
      '\n' +
      '표 5는 핀벤에서 다른 LLM의 성능을 나타낸다.\n' +
      '\n' +
      '## 부록 C 지시사항\n' +
      '\n' +
      '각 데이터 세트의 자세한 내용은 표 6 및 표 7을 참조하십시오.\n' +
      '\n' +
      '## 부록 관련 업무\n' +
      '\n' +
      '############ 금융 대언어 모델\n' +
      '\n' +
      '최근 몇 년 동안 금융-특정 LLM에 대한 연구가 상당히 급증하여, 범용 언어 모델들에 의해 마련된 토대 위에서 확대되고 있다(Lee et al., 2024; Liu et al., 2023b; Xie et al., 2023; Zhang et al., 2024; Dai et al., 2024). FinBERT(Araci, 2019; Yang et al., 2020; Liu et al., 2020)와 같은 금융 사전 훈련 언어 모델(FinPLMs)은 BERT에서 파생되었으며 ELECTRA에 기반한 FLANG(Shah et al., 2022)은 감성 분석 및 주식 예측과 같은 작업에서 향상된 성능을 위해 도메인별 데이터를 사용하여 개발되었다. 메타 AI의 LLaMA(Touvron et al., 2023)의 오픈 소스 공개는 FinMA(Xie et al., 2023), InvestLM(Yang et al., 2023) 및 Fin GPT(Wang et al., 2023; Liu et al., 2023)와 같은 모델을 사용하여 금융 애플리케이션을 위한 고급 튜닝 전략(Zhang et al., 2023)을 활용하는 금융 LLMs(FinLLMs)의 추가 혁신을 촉진했다. BloombergGPT(Wu et al., 2023)는 금융 산업에 맞춘 BLOOM 기반 폐쇄 소스 모델로 눈에 띈다. 또한 중국 금융 부문에서는 XuanYuan 2.0(Zhang et al., 2023), 광범위하고 전문화된 지식을 통합하는 모델, 금융 커뮤니케이션을 위한 FinBART(Hongyuan et al., 2023), 표적 사전 훈련 및 미세 조정을 위한 포괄적인 데이터 세트를 포함하는 CFGPT(Li et al., 2023)와 같은 모델이 출현했다.\n' +
      '\n' +
      '### 재무 평가 벤치마크\n' +
      '\n' +
      '선구적인 FLUE(Shah et al., 2022)와 같은 재무 평가 벤치마크가 있었다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l c c c} \\hline \\hline \\multirow{2}{*}{**Dataset**} & \\multirow{2}{*}{**Metrics**} & **Bialchuan** & **CodeLLaMA** & **DISC-** \\\\  & & **7B** & **7B** & **FinLLM** \\\\ \\hline \\multirow{2}{*}{FPB} & F1 & **0.36** & 0.34 & 0.29 \\\\  & Acc & 0.32 & **0.39** & 0.26 \\\\  & F1Q-SA & F1 & 0.17 & **0.66** & 0.32 \\\\  & RMSE1 & 1.07 & 0.43 & **0.32** \\\\  & Headlines & AvgF1 & **0.60** & 0.60 & 0.60 \\\\  & F1 & 0.16 & 0.14 & **0.19** \\\\  & Acc & 0.25 & 0.27 & **0.28** \\\\  & MicroF1 & **0.34** & 0.28 & 0.29 \\\\  & FinAP-ARC & MicroF1 & 0.17 & 0.25 & **0.29** \\\\  & Multirin & MicroF1 & 0.06 & 0.21 & **0.29** \\\\  & MicroF1 & 0.02 & **0.54** & 0.29 \\\\  & MLESG & MicroF1 & 0.00 & 0.10 & **0.29** \\\\ \\hline \\hline NER & Entity1 & 0.00 & 0.07 & **0.12** \\\\  & FinRep1 & **0.00** & **0.00** & 0.00 \\\\  & FinRep1 & **0.00** & 0.00 & 0.00 \\\\  & Sc & F1 & 0.57 & **0.85** & 0.00 \\\\  & F1 & **0.00** & 0.00 & 0.00 \\\\ \\hline \\hline \\multirow{2}{*}{FMQ} & EmAcc & **0.00** & 0.00 & 0.00 \\\\  & EmAcc & **0.00** & 0.00 & 0.00 \\\\  & ComFit-DA & EmAcc & **0.00** & 0.00 & 0.00 \\\\  & FNXL & EntityF1 & **0.00** & 0.00 & 0.00 \\\\  & FSRL & EntityF1 & **0.00** & 0.00 & 0.00 \\\\ \\hline \\hline \\multirow{2}{*}{EDTSUM} & Rouge-1 & **0.22** & 0.10 & 0.22 \\\\  & BertScore & 0.54 & **0.67** & 0.61 \\\\  & BartScore & -4.57 & **-3.62** & -4.13 \\\\  & Rouge-1 & **0.00** & 0.00 & 0.00 \\\\  & BertScore & **0.00** & 0.00 & 0.00 \\\\  & BartScore & **-5.18** & -5.18 & -5.18 \\\\ \\hline \\hline \\multirow{2}{*}{BigData22} & Acc & **0.53** & 0.52 & 0.44 \\\\  & MCC & **-0.01** & -0.01 & -0.05 \\\\  & Acc & 0.50 & **0.51** & 0.50 \\\\  & MCC & 0.00 & 0.00 & **0.02** \\\\  & Acc & **0.53** & 0.51 & 0.44 \\\\  & MCC & -0.05 & **0.02** & -0.03 \\\\  & F1 & 0.52 & **0.66** & 0.52 \\\\  & MCC & 0.00 & 0.00 & 0.00 \\\\  & F1 & 0.26 & **0.43** & 0.26 \\\\  & MCC & 0.00 & 0.00 & 0.00 \\\\  & MCC & 0.00 & 0.00 & 0.00 \\\\  & IndlingCub & F1 & 0.72 & **0.81** & 0.72 \\\\  & MCC & -0.01 & **0.00** & 0.00 \\\\  & F1 & **0.97** & 0.00 & 0.66 \\\\  & MCC & **0.00** & 0.00 & -0.04 \\\\  & F1 & 0.00 & 0.06 & **0.46** \\\\  & MCC & 0.00 & 0.00 & **0.02** \\\\  & F1 & 0.91 & 0.47 & **0.92** \\\\  & MCC & 0.02 & **0.04** & 0.00 \\\\  & F1 & 0.70 & 0.36 & **0.95** \\\\  & MCC & -0.02 & -0.03 & **0.00** \\\\  & F1 & 0.01 & **0.88** & 0.63 \\\\  & MCC & **0.01** & -0.01 & -0.02 \\\\  & F1 & **0.03** & 0.02 & 0.00 \\\\  & MCC & -0.09 & **0.00** & 0.00 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: FinBen 상의 다른 LLM의 제로-샷 및 소수-샷 성능.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:15]\n' +
      '\n' +
      '그림 8: NFLX에 대한 LLM 거래 전략의 누적 수익률\n' +
      '\n' +
      '그림 10: TSLA에 대한 LLM 거래전략의 누적수익률\n' +
      '\n' +
      '그림 7: MSFT에 대한 LLM 거래 전략의 누적 수익률\n' +
      '\n' +
      '그림 9: NIO에 대한 LLM 거래 전략의 누적 수익률\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l p{284.5pt}} \\hline \\hline\n' +
      '**Data** & **Prompt** \\\\ \\hline \\multirow{2}{*}{FPB} & “Analyze the sentiment of this statement extracted from a financial news article. \\\\  & Provide your answer as either negative, positive or neutral. \\\\  & For instance.” The company’s stocks plummeted following the scandal.’ would be classified as negative.” \\\\ \\hline \\multirow{2}{*}{FQA-SA} & “What is the sentiment of the following financial (category): Positive, Negative, or Neutral” \\\\ \\hline \\multirow{2}{*}{Headlines} & “Consider whether the headline mentions the price of gold. \\\\  & Is there a Price or Not in the gold commodity market indicated in the news headline? \\\\  & Please answer Yes or No.” \\\\ \\hline \\multirow{2}{*}{NER} & “In the sentences extracted from financial agreements in U.S. SEC filings, identify the named entities that represent a person (‘PER’), an organization (‘ORG’), or a location (‘LOC’). The required answer format is \'entity name, entity type’. \\\\  & For instance, in ‘Elon Music, CEO of Spocx, announced the launch from Cape Canversal’, the entities would be: ‘Elon Musk, PER; Spocx, OCR; Cape Canversal, LOC” \\\\ \\hline \\multirow{4}{*}{FNER-ORD} & “In the list of tokens, identify (‘id’) each accordingly. \\\\  & If the entity spans multiple tokens, use the prefix B-PER, B-LOC, or B-ORG for the first token, and I-PER, I-LOC, or I-ORG for the subsequent tokens of that entity. \\\\ \\cline{1-1}  & The beginning of each separate entity should always be labeled with a B-PER, B-LOC, or B-ORG prefix. If the token does not into any of the three named categories, or is not a named entity, label it as ‘O’.” \\\\ \\hline \\multirow{2}{*}{FinQA} & “Given the financial data and experts analysis, please answer this question.” \\\\ \\cline{2-2}  & “In the context of this series of interconnected finance-related queries and the additional information provided by the pretext, table data, and post text from a company’s financial filings, please provide a response to the final question. This may require extracting information from the context and performing mathematical calculations. Please take into account the information provided in the preceding questions and their answers when formulating your response.” \\\\ \\hline \\multirow{2}{*}{BigData22} & “Contemplate the data and tweets to guess whether the closing price of (\\(\\mathrm{iid}\\)) will surge or decline at (\\(\\mathrm{point}\\)). \\\\  & Please declare which either Rise or Fall.” \\\\ \\hline \\multirow{2}{*}{ACL18} & “Scrutinize the data and tweets to envisage if the closing price of (\\(\\mathrm{iid}\\)) will well or contract at (\\(\\mathrm{point}\\)). \\\\  & Respond with either Rise or Fall.” \\\\ \\hline \\multirow{2}{*}{CIRM18} & “Reflect on the provided data and tweets to anticipate if the closing price of (\\(\\mathrm{iid}\\)) is going to increase or decrease at (\\(\\mathrm{point}\\)). \\\\  & Respond with either Rise or Fall.” \\\\ \\hline \\multirow{2}{*}{ECTSem} & “Given the following article, please produce a list of 0 and 1, each separated by \\(\\,\\) - \\(\\,\\) to indicate which sentences should be included in the final summary. The article’s sentences have been split by \\(\\,\\) - \\(\\,\\) Please mark each sentence with 1 if it should be included in the summary and 0 if it should not.” \\\\ \\hline \\multirow{2}{*}{EDTSum} & “You are given a text that consists of multiple sentences. Your task is to perform abstractive summarization on this text. Use your understanding of the content to express the main ideas and crucial details in a shorter, coherent, and natural sounding text.” \\\\ \\hline \\multirow{2}{*}{German} & “Asses the creditworthiness of a customer using the following table attributes for financial states. Respond with either ‘good’ or "bad. And the table attributes including 13 categorical attributes and 7 numerical attributes are as follows.” \\\\ \\hline \\multirow{2}{*}{Australian} & “Asses the creditworthiness of a customer using the following table attributes for financial status. Respond with either ‘good’ or "bad.” And the table attributes including 13 categorical attributes and 7 numerical attributes and values have been changed to meaningless symbols to protect confidentiality of the data..” \\\\ \\hline \\multirow{2}{*}{FOMC} & “Examine the excerpt from a central bank’s release below. Classify is a HAWKISH if it advocates for a tightening of monetary policy, DVSWIFI if it suggests an easing of monetary policy, or NEUTRAL if the stance is unbiased. Your response should return only HAWKISH, DOVISI, or NEUTRAL.” \\\\ \\hline \\multirow{2}{*}{TSA} & “Given the following financial text, return a sentiment score for Ahstead as a floating-point number ranging from -1 (indicating a very negative or beurish sentiment) to 1 (indicating a very positive or bullish sentiment), with 0 designating neutral sentiment. Return only the numerical score first, follow it with a brief reasoning behind your score.” \\\\ \\hline \\multirow{2}{*}{FinArg - ACC} & “Analyze sentences from earnings conference calls and identify their argumentative function. \\\\  & Each sentence is either a premise, offering evidence or reasoning, or a claim, asserting a conclusion or viewpoint. Return only premise or claim.” \\\\ \\hline \\multirow{2}{*}{FinArg - ARC} & “In this task, you are given a pair of sentences. \\\\  & Your objective is to ascertain the type of argumentative relation between these two sentences. \\\\ \\cline{2-2}  & The relation could either be ‘NoRelation’, indicating to discernible relation between the sentences, \\\\ \\cline{2-2}  & “Superior, indicating that the first sentence supports the second, or “attack”: indicating that the first sentence disputes or contradicts the second. Return only on of the three classifications: ‘notation’, ‘superior’, or ‘attack’.” \\\\ \\hline \\multirow{4}{*}{MultiFin} & “In this task, you’re working with English headlines from the MULTIFIN dataset. \\\\  & This dataset is made of peak-world article headlines from a large accounting firm’s websites. \\\\ \\cline{2-2}  & Your objective is to categorize each headline according to its primary topic. \\\\ \\cline{2-2}  & The potential categories are \\(\\lfloor\\)category\\(\\rfloor\\). \\\\ \\cline{2-2}  & Your response should only include the category that best fits the headline.” \\\\ \\hline \\multirow{2}{*}{MA} & “In this task, you will be given Mergers and Acquisition news articles or tweets. \\\\ \\cline{2-2}  & Your task is to classify each article or tweet based on whether the mentioned deal was completed or remained a rumour. \\\\ \\cline{2-2}  & Your response should be a single word - either ‘complete’ or ‘rumour’, representing the outcome of the deal mentioned in the provided text.” \\\\ \\hline \\multirow{2}{*}{MLESG} & “You’re given English news articles related to Environmental, Social, and Corporate Governance (ESG) issues. \\\\ \\cline{2-2}  & Your task is to classify each article based on the ESG issue it pertains to, according to the MSCI ESG rating guidelines. \\\\ \\cline{2-2}  & The ESG issues include \\(\\lfloor\\)category\\(\\rfloor\\). \\\\ \\cline{2-2}  & Your output should be the most relevant ESG issue label, followed by a brief rationale based on the article content.” \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 각 데이터세트의 프롬프트.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l} \\hline \\hline\n' +
      '**Data** & **Prompt** \\\\ \\hline \\hline \\multirow{3}{*}{FinkBED} & “Given the following sentence, identify the head, tail, and relation of each triplet present in the sentence. \\\\  & The relations you should be looking for the car (category). \\\\  & If a relation exists between two entities, provide your answer in the format [category]. \\\\  & If there are multiple triplets in a sentence, provide each one on a new line.” \\\\  & “In this task, you are provided with sentences extracted from financial news and SEC data. \\\\  & Your goal is to classify each sentence into either ‘causal’ or ‘noise’ based on whether or not it indicates a causal relationship between financial events. \\\\  & Please return only the category ‘causal’ or ‘noise’.” \\\\ \\hline \\multirow{3}{*}{CD} & “Your job in this task is to perform sequence labeling on a provided text section, marking the chunks that represent the cause of an event and the effects that result from it. For each token in the text, asking a label to indicate its role in representing cause or effect. \\\\  & The labels you should use are “B-CAUSE; 1-CAUSE; 2-BEFTECT; 1-BEFTECT, and ‘O’. \\\\  & A ‘B-’ prefix is used to denote the beginning of a cause or effect sequence. \\\\  & while an ‘1:” prefix is used for continuation of a cause or effect sequence. \\\\  & If a token is not part of either a cause or effect sequence, label it as ’O’. \\\\  & Provide your answer as a sequence of ‘tokenlabel’ pairs, with each pair on a new line.” \\\\ \\hline TATQA & “Please answer the given financial question based on the context. Context: {context}[Question: What is the amount of total sales in 2019?” \\\\ \\hline \\multirow{3}{*}{FNXL} & “In the task of Financial Numeric Extreme Labelling (FNXL), \\\\  & your job is to identify and label the semantic role of each token in a sentence. \\\\  & The labels can include [category]” \\\\ \\hline \\multirow{3}{*}{FSRL} & “In the task of Textual Analogy Parsing (TAP), your job is to identify and label the semantic role of each token in a sentence. \\\\  & The labels can include [category].” \\\\ \\hline \\multirow{3}{*}{LendingClub} & “Asses the client’s loan status based on the following loan records from Lending Club. \\\\  & Respond with only ‘good’ or ‘bad’, and do not provide any additional information. \\\\  & For instance, “The client is a stable income, no previous debts, and owns a property.’ should be classified as ‘good’.” \\\\ \\hline \\multirow{3}{*}{ccf} & “Detect the credit card fraud using the following financial table attributes. \\\\  & Respond with only ‘yes’ or ‘no’, and do not provide any additional information. \\\\  & Therein, the data contains 28 numerical input variables V1, V2,... \\\\  & and V28 which are the result of a PCA transformation and 1 input variable Amount which has not been transformed with PCA. \\\\  & The feature ‘Amount’ is the transaction Amount, this feature can be used for example-dependent cost-sensitive learning. \\\\  & For instance, “The client has attributes: [category]” \\\\ \\hline \\multirow{3}{*}{ccfraud} & “Detect the credit card fraud with the following financial profile. \\\\  & Respond with only ‘good’ or ‘bad’, and do not provide any additional information. \\\\  & The client is a female, the state number is 25, the number of cards is 1, the credit balance is 7000, \\\\  & the number of transactions is 16, the number of international transactions is 0, \\\\  & the credit limit is 6.’ should be classified as ‘good.” \\\\ \\hline \\multirow{3}{*}{polish} & “Predict whether the company will face bankruptcy based on the financial profile attributes provided in the following text. \\\\  & Respond with only ‘no’ or ‘yes’, and do not provide any additional information.” \\\\ \\hline \\multirow{3}{*}{P Porto-Seguro} & “Identify whether or not to files a claim for the auto insurance policy holder using the following table attributes about individual financial profile. \\\\  & Respond with only ‘yes’ or ‘no’, and do not provide any additional information. \\\\  & And the table attributes that belong to similar groupings are tagged as such in the feature names (e.g., ind, reg, car, calc). \\\\  & In addition, feature names include the positiva bin to indicate binary features and cat to indicate categorical features. \\\\  & Features without these designations are either continuous or ordinal. \\\\  & Values of -1 indicate that the feature was missing from the observation.” \\\\ \\hline \\multirow{3}{*}{travelinsurance} & “Identify the claim status of insurance companies using the following table attributes for travel insurance status. \\\\  & Respond with only ‘yes’ or ‘no’, and do not provide any additional information. \\\\  & And the table attributes including 5 categorical attributes and 4 numerical attributes are as follows:[category]" \\\\ \\hline \\multirow{3}{*}{fintrade} & “Given the information, can you make an investment decision?” last summarize the reason of the decision. \\\\  & please consider only the available short-term information, the mid-term information, the long-term information, the \\\\  & reflection-term information. \\\\  & please consider the momentum of the historical stock price. \\\\  & When cumulative return is positive or zero, you are a risk-seeking investor. \\\\  & But when cumulative return is negative, you are a risk-exercise investor. \\\\  & please consider how much share of the stock the inverse holds now. \\\\  & You should provide exactly one of the following investment decisions: buy or sell. \\\\  & When it is really hard to make a ‘buy’-or-’sell’ decision, you could go with ‘hold’ option. \\\\  & You also need to provide the id of the information to support your decision. \\\\  & [ investment,info] \\\\  & [gropule\\_json\\_suffix,v2] \\\\  & Your output should strictly conforms the following json format without any additional contents: \\\\  & [’investment\\_decision’\\_ stringing, “summary\\_reason’: stringing, “short\\_memory\\_intax”: number, \\\\  &\'middle\\_memory\\_index’: number, “long\\_memory\\_index’: number, “reflection\\_memory\\_intax’: number]" \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: 각 데이터 세트에 대한 예제 프롬프트입니다. FiQA-SA에는 뉴스 헤드라인 및 트윗을 포함한 두 가지 유형의 텍스트가 있다. 우리는 세부 텍스트 유형을 각 데이터 샘플에 대해 {카테고리}로 채울 것이다. BigData22와 같은 주식 이동 예측 데이터에 대해서는 {tid}와 {point}를 각 데이터 샘플로부터 자세한 주식 이름과 시간으로 채울 것이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l l l l} \\hline \\hline\n' +
      '**Ticker** & **Model** & **CR (\\%)** & **SR** & **DV (\\%)** & **AV (\\%)** & **MD (\\%)** \\\\ \\hline \\multirow{6}{*}{TSLA} & Buy and Hold & -25.2137 & -0.7203 & 4.4099 & 70.0043 & 57.6765 \\\\  & GPT-4 & 68.3089 & 2.8899 & 2.9780 & 47.2739 & 10.7996 \\\\  & GPT3.5-Turbo & 25.2137 & 0.7203 & 4.4099 & 70.0043 & 51.3186 \\\\  & Ilama2-70B & -31.4144 & -1.0412 & 3.8014 & 60.3450 & 48.6173 \\\\  & gemini & -0.3790 & -0.0148 & 3.2271 & 51.2280 & 35.6707 \\\\ \\hline \\multirow{6}{*}{NFLEX} & Buy and Hold & 34.6251 & 1.3696 & 3.1852 & 50.5634 & 20.9263 \\\\  & GPT-4 & 36.4485 & 2.0088 & 2.2860 & 36.2894 & 15.8495 \\\\  & GPT3.5-Turbo & 7.9337 & 0.4610 & 2.1680 & 34.4160 & 17.9578 \\\\  & Ilama2-70B & 33.8460 & 1.4741 & 2.8928 & 45.9216 & 20.3910 \\\\  & gemini & 11.6298 & 1.0073 & 1.4546 & 23.0906 & 16.5106 \\\\ \\hline \\multirow{6}{*}{AMZN} & Buy and Hold & -16.4428 & -0.7448 & 2.7812 & 44.1508 & 33.8847 \\\\  & GPT-4 & 10.5539 & 0.4923 & 2.7012 & 42.8802 & 22.9294 \\\\  & GPT3.5-Turbo & 19.9636 & 0.9611 & 2.6171 & 41.5454 & 19.2191 \\\\  & Ilama2-70B & 8.3595 & 1.9715 & 0.5342 & 8.4804 & 0.0000 \\\\  & gemini & -2.3838 & -0.5321 & 0.5645 & 8.9605 & 6.4291 \\\\ \\hline \\multirow{6}{*}{MSFT} & Buy and Hold & 17.2161 & 0.9709 & 2.2339 & 35.4623 & 15.0097 \\\\  & GPT-4 & 25.7826 & 1.5818 & 2.0535 & 25.989 & 14.9889 \\\\  & GPT3.5-Turbo & 20.4179 & 1.3600 & 1.8915 & 30.0259 & 20.3211 \\\\  & Ilama2-70B & 27.7664 & 1.5708 & 2.2270 & 35.3524 & 15.0097 \\\\  & gemini & 21.5082 & 1.3701 & 1.9777 & 31.3957 & 17.5051 \\\\ \\hline \\multirow{6}{*}{COIN} & Buy and Hold & -18.4787 & -0.3369 & 6.9098 & 109.6904 & 60.5084 \\\\  & GPT4-4 & 25.7631 & 0.5619 & 5.7761 & 91.6934 & 35.7526 \\\\  & GPT3.5-Turbo & 25.1141 & 0.4772 & 6.6312 & 105.2669 & 53.9628 \\\\  & Ilama2-70B & 15.1836 & 0.4395 & 4.3528 & 60.0979 & 35.3249 \\\\  & gemini & 89.4782 & 1.7648 & 6.3879 & 101.4048 & 40.3246 \\\\ \\hline \\multirow{6}{*}{AAPL} & Buy and Hold & 12.7371 & 0.7759 & 2.0682 & 32.8323 & 20.6591 \\\\  & GPT4-4 & 21.2334 & 1.9274 & 1.3879 & 22.0328 & 6.4237 \\\\  & Ilama2-70B & 27.0152 & -1.9193 & 1.7734 & 28.1517 & 33.1619 \\\\  & Ilama2-70B & 11.4855 & 1.1550 & 1.2529 & 19.8855 & 92.776 \\\\  & gemini & -5.3097 & -0.3637 & 1.8392 & 29.1971 & 26.6450 \\\\ \\hline \\multirow{6}{*}{GOOG} & Buy and Hold & 6.3107 & 0.3081 & 2.5806 & 40.9660 & 21.1907 \\\\  & GPT-4 & 13.2811 & 0.9667 & 1.7308 & 27.4762 & 12.2209 \\\\  & GPT3.5-Turbo & 0.9990 & 0.0614 & 0.20490 & 32.5265 & 20.9316 \\\\  & Ilama2-70B & 17.0030 & 1.1057 & 1.9374 & 30.7546 & 13.2088 \\\\  & gemini & 38.7956 & 3.0341 & 1.6110 & 25.5732 & 13.7311 \\\\ \\hline \\multirow{6}{*}{NO} & Buy and Hold & -49.4263 & -1.1895 & 5.2351 & 83.1048 & 52.2083 \\\\  & GPT-4 & 24.7684 & 0.9438 & 3.3063 & 52.4861 & 29.3384 \\\\ \\cline{1-1}  & GPT3.5-Turbo & -28.9321 & -1.0096 & 3.6105 & 57.3149 & 39.5907 \\\\ \\cline{1-1}  & Ilama2-70B & -49.6947 & -2.7868 & 2.2466 & 35.0639 & 42.6221 \\\\ \\cline{1-1}  & gemini & 14.5673 & 0.6212 & 2.9543 & 46.8977 & 23.0110 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: 다양한 종목에 걸친 상이한 LLM에 대한 전체 거래 실적 비교. 그 결과, 크기가 큰 LLM(\\(\\geq 70B\\))만 포함되었으며, 컨텍스트가 작은 모델은 지침을 이해하고 유지하는 정적 전략을 생성하는 데 어려움이 있다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>