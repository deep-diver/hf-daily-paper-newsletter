<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# Reformatted Alignment\n' +
      '\n' +
      'Run-Ze Fan\\({}^{1,6}\\) Xuefeng Li\\({}^{1,6}\\) Haoyang Zou\\({}^{3,6}\\) Junlong Li\\({}^{1,6}\\) Shwai He\\({}^{4}\\)\n' +
      '\n' +
      'Ethan Chern\\({}^{1,6}\\) Jiewen Hu\\({}^{5,6}\\) Pengfei Liu\\({}^{1,2,6*}\\)\n' +
      '\n' +
      '상하이 자오동대 상하이동대학 상하이동정치정보연구소\n' +
      '\n' +
      '매릴랜드 대학, 파크파크\n' +
      '\n' +
      '({}^{5}\\)CMU \\({}^{6}\\)Generative AI Research Lab (GAIR)\n' +
      '\n' +
      'runze.fan@icloud.com, pengfei@sjtu.edu.cn\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '대규모 언어 모델(LLM)을 인간 가치와 정렬하기 위해서는 미세 조정 데이터의 품질이 중요하다. 데이터 품질을 개선하기 위한 현재의 방법은 노동 집약적이거나 LLM 환각으로 인한 사실적 오류가 발생하기 쉽다. 본 논문은 인간의 가치관에 더 잘 부합하기 위해 기존의 명령 데이터의 품질을 높이는 방법을 탐구하며, 명령 데이터의 응답을 미리 설정된 기준과 대조된 증거에 더 잘 부합되는 형식으로 재구성하는 ReAlign이라는 간단하고 효과적인 접근법을 도입한다. 이 접근법은 인간 주석, 환각 및 기존 정렬 기술에 직교로 남아 있는 축척의 어려움을 최소화한다. 실험적으로 ReAlign은 LLMs의 일반적인 정렬 능력, 수학 추론, 사실성 및 가독성을 크게 향상시킨다.\n' +
      '\n' +
      '고무적으로 추가 데이터 또는 고급 훈련 기술을 도입하고 응답을 재포맷하는 것만으로 GSM8K에 대한 LLaMA-2-13B의 수학적 추론 능력은 정확도에서 46.77%에서 56.63%**로 향상될 수 있다. 또한 ReAlign 데이터의 5%만이 Alpaca 데이터 세트에 의해 측정된 일반적인 정렬 능력의 67% 증가를 산출한다. 이 연구는 LLM의 _science_ 및 _mechanistic 해석 가능성에 대한 추가 연구의 필요성을 강조한다. 우리는 [https://github.com/GAIR-NLP/ReAlign](https://github.com/GAIR-NLP/ReAlign])에서 향후 연구를 지원하기 위해 관련 코드 및 데이터를 공개적으로 액세스할 수 있도록 했다.\n' +
      '\n' +
      '그림 1: LLaMA-2-13B 및 Mistral-7B 모델에 대한 GSM8K 테스트 세트의 정확도는 ReAlign 유무에 관계없이 GSM8K 및 MATH의 트레이닝 세트에서 미세 조정되었다. (a) : GSM8K에 대한 훈련 및 테스트. (b) : MATH에 대한 트레이닝 및 GSM8K에 대한 테스트(Out-of-Distribution Setting)\n' +
      '\n' +
      'Introduction\n' +
      '\n' +
      '정렬은 일반적으로 LLMs(Wang et al., 2023; Honovich et al., 2023; Peng et al., 2023; Xu et al., 2023) 또는 인간 주석이 달린 명령 데이터(Ouyang et al., 2022; Kopf et al., 2023)로부터 유도된 대량의 합성 데이터에 대해 미세 조정을 필요로 하는 큰 언어 모델(LLMs)을 인간 가치 및 인간 의도에 정렬하기 위한 효과적인 기술인 것으로 목격되었다.\n' +
      '\n' +
      '최근 연구, 특히 Zhou et al.(2023)의 연구는 이 과정에서 수업 데이터 품질의 중요한 역할을 강조한다. 수많은 작품들(Wang et al., 2023; Zhou et al., 2023; Cao et al., 2023; Chen et al., 2023; Li et al., 2023; Lu et al., 2023)은 응답의 품질뿐만 아니라 입력 질의의 다양성 및 복잡성에 초점을 맞추어 명령어 품질을 향상시키는데 기여하였다. 이러한 노력은 크게 두 가지 접근법으로 나눌 수 있다. Ouyang et al. (2022) 및 Touvron et al. (2023)에 의해 주창된 첫 번째 접근법은 고품질 데이터의 수동 생성을 포함한다. 이 방법은 복잡한 질의와 사실적으로 정확하고 판독 가능한 응답을 생성하지만, 노동 집약적이고 확장하기가 어렵다. 두 번째 접근법은 광범위한 가용성으로 인해 기존 데이터 세트로부터 고품질 명령의 자동화된 추출을 중심으로 한다(Cao et al., 2023; Chen et al., 2023; Li et al., 2023; Lu et al., 2023). 그러나, 이 방법은 사실적으로 부정확한 콘텐츠를 포함하는 것과 같은 증류된 데이터와 관련된 한계를 계승하고(지 외, 2023; 구디반데 외, 2023) 생성된 응답의 포맷 및 스타일은 종종 증류된 LLM의 선호도에 의해 결정된다.\n' +
      '\n' +
      '본 논문에서는 처음부터 명령어 데이터를 생성하는 것에 초점을 맞추는 대신, 기존의 명령어 데이터가 어떻게 더 높은 품질과 인간 가치와 더 잘 정렬될 수 있는지 조사한다. 본 논문에서는 기존의 방법들과 직교한 Realign이라는 간단하고 효과적인 방법을 제안한다. 구체적으로, Realign은 광범위한 기존의 감독 데이터세트(예를 들어, GSM8K(Cobbe et al., 2021)), 또는 다양한 방법을 통해 컴파일된 공개적으로 이용 가능한 명령 데이터(예를 들어, Self-Instruct(Wang et al., 2023b), Evol-Instruct(Xu et al., 2023), 및 Self-Alignment(Li et al., 2023b))로부터 소싱될 수 있는 베이스 명령 데이터세트를 필요로 한다. 재정렬 프로세스는 세 가지 주요 단계로 전개됩니다. 첫 번째 단계는 **기준 정의**(SS3.1)를 포함하며, 여기서 인간은 자연 언어의 형태로 다양한 시나리오에서 그들의 선호도(예를 들어, 응답의 선호된 형식)를 정의한다. 이 논문에서 우리는 46개의 별개의 시나리오에 대한 기준을 세심하게 정의한다. 두 번째 단계인 **회수 증대**(SS3.2)는 개방형 도메인 QA 및 사실 확인과 같은 지식 집약적 작업에 대한 지식 기반을 넓힙니다. 이는 추가 정보를 통합함으로써 달성되어 응답의 사실성과 정보성을 향상시킨다. 마지막 단계인 **reformatting**(SS3.3)는 응답을 미리 설정된 기준과 대조된 증거와 다시 정렬하는 것을 목표로 하여 구조화되고 입증되는 출력을 보장한다. 도 1에서 설명한 바와 같다. 2, 재정렬 응답은 더 나은 형식과 더 명확한 생각의 사슬을 제공한다.\n' +
      '\n' +
      'ReAlign의 기본 _philisophy_는 선형화 과정에서 인간과 LLM의 역할을 재조정하여 상호 보완적인 강점을 활용하는 것으로, 인간은 선호도를 명확히 하고 LLM은 증류된 LLM 지식을 직접 사용하지 않고 생성력(예: 명령어 추적 능력)을 기반으로 명령을 재구성한다. 이러한 협업 시너지를 통해 생성된 지도 데이터가 보다 맥락적으로 정확할 뿐만 아니라 인간의 선호도와 보다 밀접하게 일치할 것으로 기대한다.\n' +
      '\n' +
      '본 논문에서는 기존의 5가지 명령어 데이터(즉, Open-Platypus (Lee et al., 2023), No Robots (Rajani et al., 2023) 및 Alpaca (Taori et al., 2023))에 대해 이 개념을 동작시키고, 2가지 명령어 데이터(즉, GSM8K (Cobbe et al., 2021) 및 MATH (Hendrycks et al., 2021))에 대해 동작시킨다. Realign의 성능은 일반적인 정렬을 위한 AlpacaEval(Li et al., 2023c), MT-Bench(Zheng et al., 2023), Vicuna-Bench(Chiang et al., 2023)뿐만 아니라 수학적 추론을 위한 GSM8K 및 MATH를 포함하여 잘 확립된 다양한 벤치마크에서 검증되었다. 또한 사실성과 가독성에 대한 평가도 받아 능숙함을 입증하고 있다. 특히 ReAlign은 LLaMA-2-13B의 경우 GSM8K에서 최대 9.86%까지 수학 추론을 크게 향상시킨다. 특히, Realign 데이터의 5%만이 Alpaca 데이터 세트를 기반으로 한 전체 Realign 데이터에 비해 일반적인 정렬 능력이 67% 증가한다는 것을 발견했으며, 이는 스타일과 형식을 배우기 위해 소량의 데이터만 필요함을 나타낸다.\n' +
      '\n' +
      '##2 관련 업무\n' +
      '\n' +
      '### Instruction Creation\n' +
      '\n' +
      '교수 데이터를 생성하는 것은 전통적으로 질의 작성, 응답 초안 작성 및 선호도 표시와 같은 작업에 대한 인간 주석에 의존한다. 이 접근법은 프리미엄 오픈 소스 데이터 세트(예를 들어, Open-Platypus(Lee et al., 2023) 및 OpenAssistant(Kopf et al., 2023))를 생성하고 고급 LLMs(예를 들어, LLMA(Zhou et al., 2023) 및 LLaMA-2(Touvron et al., 2023))를 지원하는 반면, evol-instruct(Xu et al., 2023)는 명령어 데이터를 생성하기 위해 시드 데이터와 함께 GPT-3의 상황 내 학습을 활용하는 반면, LLMs(예를 들어, GPT-3(Brown et al., 2020) 및 GPT-4(OpenAI, 2023))와 같은 기술은 높은 인건비와 도메인 특정 전문 지식의 필요성으로 인해 확장하기가 어렵다. 최근, 자가 생성을 통한 훈련\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:3]\n' +
      '\n' +
      '## 3 Realign\n' +
      '\n' +
      '기본 명령 데이터세트 \\(\\mathcal{D}=\\{(q_{1},r_{1}),\\cdots,(q_{n},r_{n})\\}\\)이 주어지면, \\(q\\)과 \\(r\\)은 각각 입력 질의와 응답이며, ReAlign은 그림과 같이 응답의 품질을 3단계 향상시키는 것을 목표로 한다. 3: (1) 기준 정의: 각 태스크에 대한 태스크 및 포맷을 포함하는 기준을 정의하는 단계, (2) 검색 증강: 지식 집약적 태스크에 대한 관련 외부 정보를 검색하는 단계, (3) 수기 포맷 및 검색된 정보로 구성된 안내에 기초하여 원래 응답을 재구성하는 단계. 우리의 방법의 개요는 그림 3에 나와 있다.\n' +
      '\n' +
      '### Criteria Definition\n' +
      '\n' +
      '미리 정의된 기준들은 태스크들 및 대응하는 포맷들로 구성된다:\n' +
      '\n' +
      '작업.분명히 작업을 정의하는 것은 최적의 형식이 별개의 작업에 따라 다르기 때문에 맞춤형 형식을 후속적으로 고안하는 데 중요합니다. 본 논문에서는 Tab. 1과 같이 10개의 주요 그룹으로 분류된 46개의 다른 태스크를 정의하기 위해 Li 등(2024)을 따른다. 각 태스크에 대한 자세한 설명은 Tab. 1과 같다. 8, SSB. 또한 SSC에 자세히 설명된 작업 분류기 C를 훈련한다.\n' +
      '\n' +
      '형식.다양한 작업과 관련된 서로 다른 형식 요구조건으로 인해, 우리는 조직 구조, 섹션 내용, 출력 양식 등의 고려 사항을 포함하는 작업 정의 및 설명을 기반으로 각 작업에 대한 맞춤형 형식 \\(\\{F_{1},\\cdots,F_{N=46}\\}\\)을 세심하게 고안했다. 다양한 작업을 위해 세심하게 설계된 이 형식은 일반 형식보다 더 읽을 수 있습니다. 각 형식에는 작업 이름과 자세한 형식 설명이 있습니다. 우리는 탭에서 "이메일 생성" 형식에 대한 예를 보여준다. 도 2(전체 버전은 탭 14에 도시됨).\n' +
      '\n' +
      '이 단계에서는 범주 \\(t_{i}\\)을 획득하기 위해 태스크 분류기 C(SSC에서 상세)에 쿼리 \\(q_{i}\\)를 입력한다:\n' +
      '\n' +
      '\\[t_{i}=\\texttt{C}(q_{i}),\\]\n' +
      '\n' +
      '그런 다음 해당 형식 \\(f_{i}\\)을 얻는다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l} \\hline \\hline\n' +
      '**Group** & **Tasks** \\\\ \\hline Generation & question generation; story generation; poem generation; email generation; data generation; text-to-text translation \\\\ \\hline Brainstorming & advice giving; recommendations; how-to generation; planning \\\\ \\hline Code & code correction; code simplification; explain code; text-to-code translation; code-to-code translation; \\\\  & language learning questions; code language classification; code-to-text-translation \\\\ \\hline Rewriting & instructional rewriting; language polishing; paraphrasing; text correction \\\\ \\hline Extraction & information extraction; keywords extraction; table extraction \\\\ \\hline Summarization & title generation; text summarization; note summarization \\\\ \\hline Conversation & open qz; closed qz; fact verification; value judgment; roleplay; explain answer \\\\ \\hline Education. & natural language hotter; exam problem tutor; at tutor; math puzzles; fill in the blank \\\\ \\hline Classification & general classification; ordering; sentiment analysis; language classification; topic classification \\\\ \\hline Others & rejecting; others \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 태스크의 카테고리. “교육”은 전문화된 교육 대화를 의미한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l} \\hline \\hline\n' +
      '**Email Generation** \\\\ \\hline It is an email-writing task. Here is a general guideline for creating a well-structured and professional email: \\\\ \\hline \\(\\texttt{I}\\): Subject Line; Write a clear and concise subject line that accurately summarizes the content of your email... \\\\ \\(\\texttt{2}\\): Saluation: Begin your email with a formal solution such as “Dear [Recipient’s Name].”... \\\\ \\(\\texttt{3}\\): Interdoctoral Surt your email with a brief introduction... \\\\ \\(\\texttt{4}\\): Body: This is the main content of your email... \\\\ \\(\\texttt{5}\\): Peleness and Tone; Maintain a polite and respefential tone throughout your email. \\\\ \\(\\texttt{6}\\): Closing: Conclude your email with a closing remark, such as “Thank you,” “Best regards,” followed by your name... \\\\ \\(\\texttt{7}\\): Signature include your real turn, job title, and context information (e.g. phone number, email address)... \\\\ \\(\\texttt{8}\\): Attachment if you need to include attachments, mention them... \\\\ \\(\\texttt{9}\\): Protoreal: Before sending the email, provided it for any grammatical or spelling errors... \\\\ \\hline \\multicolumn{2}{l}{The best emails are short, direct, professional, and scannable for the recipient. Follow a formal business email structure unless you have} \\\\ \\multicolumn{2}{l}{an established casual report with the recipient.} \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: "이메일 생성" 태스크에 대한 포맷의 일례.\n' +
      '\n' +
      '### Retrieval Augmentation\n' +
      '\n' +
      '개방 도메인 QA 및 사실 검증과 같은 지식 집약 언어 작업(KILT)은 일반적으로 사실성을 보장하기 위한 증거로 크고 외부적인 지식 소스를 필요로 한다(Petroni et al., 2021). 따라서 우리는 Petroni et al.(2021)을 따라 5가지 지식 집약적 태스크를 선택하고 질의 \\(q_{i}\\)을 사용하여 관련 정보를 증거로 검색한다. 검색 증강을 위한 태스크는 Tab. 8에 제시되어 있다. 구체적으로, Chern et al.(2023)을 따르고 Google Search API를 Serper1이 제공하는 우리의 리트리버 R로 사용하여 API의 답변에 포함된 가장 관련성이 높은 검색 스니펫을 검색한다. 그런 다음 응답을 분석하여 정답 상자, 지식 그래프 및 유기적 검색 결과와 같은 다양한 유형의 스니펫을 얻는다. 마지막으로, 우리는 top-\\(k\\) 스니펫을 선택하고 이를 증거 \\(E_{i}=e_{i1},\\cdots,e_{ik}\\)로 필터링한다.\n' +
      '\n' +
      '각주 1: [https://serper.dev/](https://serper.dev/)\n' +
      '\n' +
      '\\[E_{i}=\\texttt{R}(q_{i}).\\]\n' +
      '\n' +
      '우리는 탭에서 지식 집약적 언어 과제의 예를 보여준다. 도 15에 도시된 바와 같이, 검색 증강은 응답을 보다 사실적이고 유익하게 가능하게 한다는 것을 입증한다.\n' +
      '\n' +
      '### Reformatting\n' +
      '\n' +
      '#### 3.3.1 Rewriting\n' +
      '\n' +
      '이 단계에서는 대용량 언어 모델(예: ChatGPT)을 활용하여 주어진 형식 \\(f_{i}\\)을 기반으로 응답 \\(r_{i}\\)을 다시 작성하고, 지식 집약적인 작업을 위해 증거 \\(E_{i}\\)을 검색한다. 특정 쿼리에는 추가 요구 사항(예: 특정 포맷팅 또는 지정된 정보)이 있기 때문에 적응형 재작성 전략이 사용된다. 이 접근법은 처음에 LLM을 사용하여 형식이 쿼리 요구 사항과 일치하는지 여부를 결정하는 것을 포함한다. 이어서, 일치하는 경우, LLM은 그에 따라 응답을 다시 작성한다. 우리는 작업을 두 가지 범주로 나눕니다:\n' +
      '\n' +
      '비지식 집약적 태스크에 대한 비지식 집약적 태스크는 태스크의 일부를 다시 작성하기로 결정한다. 이 결정은 특정 작업이 스토리 생성 및 시 생성과 같은 예로 예시된 표준화된 형식을 준수할 수 없다는 관찰에서 비롯된다(자세한 내용은 탭 8 참조). 우리는 탭의 프롬프트를 통해 원래 응답 \\(r_{i}\\)을 다시 쓰도록 유도하고, 질의 \\(q_{i}\\), 원래 응답 \\(r_{i}\\) 및 형식 \\(f_{i}\\)을 함께 정리한다. 11 : 제어부\n' +
      '\n' +
      '\\[\\hat{r}_{i}=\\texttt{LLM}(q_{i},r_{i},f_{i}),\\]\n' +
      '\n' +
      '여기서 \\(\\hat{r}_{i}\\)는 재포맷된 반응이다.\n' +
      '\n' +
      '지식 집약적 태스크는 지식 집약적 태스크에 비해 검색된 증거 \\(E_{i}\\)를 추가적으로 활용한다. 구체적으로, Tab의 프롬프트를 통해 LLM이 원응답 \\(r_{i}\\)을 다시 쓰도록 안내하고, 질의 \\(q_{i}\\), 원응답 \\(r_{i}\\), 형식 \\(f_{i}\\), 검색된 증거 \\(E_{i}\\)을 함께 정리한다. 12 : 제어부\n' +
      '\n' +
      '\\[\\hat{r}_{i}=\\texttt{LLM}(q_{i},r_{i},f_{i},E_{i}).\\]\n' +
      '\n' +
      '그림 3: 세 단계를 포함하여 재정렬에 대한 개요입니다. KILT는 지식 집약 언어 작업을 나타낸다.\n' +
      '\n' +
      '#### 3.3.2 Post-processing\n' +
      '\n' +
      '길이 필터링.우리는 LLMs가 때때로 재포맷에 실패하고 출력 길이가 급락하는 변경된 문장만을 출력한다는 것을 발견한다. 재포맷되지 않은 데이터를 필터링하기 위해 원래 응답 길이의 절반 미만인 재포맷된 응답을 사용하는 대신 원래 응답을 유지한다.\n' +
      '\n' +
      '작업 기반 필터링.작업 분류에서 오류 전파 문제를 완화하기 위해 특정 작업에 대한 필터링 규칙을 설계한다. (i) 코드 관련 작업(예: "코드 수정")의 경우 키워드 매칭 규칙을 사용하여 원본 버전과 재포맷된 버전이 모두 코드를 포함하는지 여부를 확인한다. 원래 응답 또는 재포맷된 응답 중 하나만 코드를 통합하면 재포맷 실패가 나타나며 원래 응답은 유지됩니다. (ii) "시험 문제 튜터" 과제에 대해, 정확한 결과를 포함하지 않는 재포맷된 응답들은 받아들여지지 않을 것이다. (iii) "계획" 태스크에 대해, 질의가 계획 관련 키워드(예를 들어, 계획 또는 계획)를 포함하지 않는 경우, 원래 답변은 유지된다.\n' +
      '\n' +
      '마지막으로, 재구성된 데이터세트\\(\\hat{\\mathcal{D}}=\\{(q_{1},\\hat{r}_{1}),\\cdots,(q_{n},\\hat{r}_{n})\\}\\) (ReAlign 데이터세트로 표기)을 획득할 수 있었다.\n' +
      '\n' +
      '## 4 Experiments\n' +
      '\n' +
      '### Datasets\n' +
      '\n' +
      '일반적 능력의 평가를 위해 2개의 고품질 수동 데이터세트와 1개의 증류 데이터세트를 선택하여 명령어 튜닝을 수행한다. (1) Open-Platypus(Lee et al., 2023)는 STEM 및 논리적 도메인에서 LLM 성능을 향상시키기 위해 신중하게 선별된 11개의 오픈 소스 데이터세트를 통합한다. 25k 문항으로 구성되어 있으며, 약 90%가 사람에 의해 작성되고 나머지는 LLM에 의해 생성된다. (2) No Robots(Rajani et al., 2023)는 숙련된 인간 주석자들에 의해 생성된 10k 명령들 및 시연들의 고품질 데이터세트이다. (3) **Alpaca**(Taori et al., 2023)는 52k개의 샘플을 포함하는 _Self-Instruct_(Wang et al., 2023b) 방법으로 text-davinci-003(Ouyang et al., 2022)로부터 생성된 오픈소스 명령어 튜닝 데이터셋이다. 또한 ReAlign (4) **GSM8K**(Cobbe et al., 2021)는 7.5k 훈련 문제와 1k 테스트 문제로 구성된 인간 문제 작성자가 만든 고품질 초등학교 수학 문제 데이터 세트인 ReAlign을 사용하여 수학 추론을 평가하기 위해 두 개의 수동 데이터 세트를 선택한다. (5) **MATR**(Hendrycks et al., 2021)는 훈련용 7.5k, 테스트용 5k를 포함하여 수학 대회 문제의 데이터셋이다.\n' +
      '\n' +
      '### Models\n' +
      '\n' +
      '우리는 미세 조정을 위해 잘 알려진 두 개의 오픈 소스 기본 모델을 선택한다: (1) **LLaMA-2-13B**(Touvron et al., 2023)은 2T 토큰을 사용하여 오픈 소스 사전 훈련된 모델이다. (2) **Mistral-7B**(Jiang et al., 2023)는 7B 파라미터 스케일에서의 현재의 최첨단 기반 언어 모델이다.\n' +
      '\n' +
      '### Evaluation\n' +
      '\n' +
      '우리는 수학 추론, 사실성, 가독성을 포함한 일반 정렬과 특정 정렬 능력에 대해 ReAlign을 평가한다.\n' +
      '\n' +
      '######4.3.1 일반 정렬\n' +
      '\n' +
      '일반적인 정렬 능력을 평가하기 위해 Wang et al. (2023a)를 따르며, 가장 널리 알려진 벤치마크를 채택한다: **AlpacaEval**(Li et al., 2023c), **MT-Bench**(Zheng et al., 2023), **Vicuna-Bench**(Chiang et al., 2023). 구체적으로, GPT-4의 비용 때문에 AlpacaEval에 대한 평가자로 GPT-3.5와 Auto-J(5D 상세)를 사용하는데, 이는 인간(Li et al., 2024; Sun et al., 2024), MT-Bench와 Vicuna-Bench에 대한 GPT-4와 매우 강한 상관관계를 갖는다.\n' +
      '\n' +
      '######4.3.2 특정 정렬\n' +
      '\n' +
      '우리는 수학 추론, 사실성, 가독성을 포함한 정렬에 대한 구체적인 관점을 평가한다.\n' +
      '\n' +
      '수학 추론.수학 추론을 평가하기 위해 GSMSK 및 MATH 훈련 데이터 세트에 각각 LLaMA-2-13B 및 Mistral-7B를 세분화하고 그 후 테스트한다. 교육 및 테스트를 위한 프롬프트 템플릿은 \'질문:\\n{입력}\\n 대답:\\n 단계적으로 생각하자.\\n\'이다. 두 데이터 세트는 동일한 스타일의 수학 문제로 구성되기 때문에 쿼리와 형식이 일치하는지 여부를 결정할 필요가 없고 오히려 재쓰기를 의무화하는 적응형 대신 강제 재쓰기를 적용한다. 우리는 응답에서 마지막 숫자를 추출하여 지상 진실과 직접 비교함으로써 정확도를 결정한다.\n' +
      '\n' +
      '사실성.모델의 사실성을 평가하기 위해, 사실 기반 질의가 풍부한 공개 Q&A 데이터셋인 NQ(Natural Questions dataset, Kwiatkowski et al., 2019)에서 100개의 사례를 무작위로 선정한다. 우리는 GPT-4를 사용하여 질문, 응답 및 근거 진실(사실성 점수라고 함)을 고려하여 이러한 사례를 사실성 척도 1에서 10까지 평가합니다. 평가 프롬프트가 탭에 표시됩니다. 17.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:7]\n' +
      '\n' +
      'MATH 데이터 세트는 LLaMA-2-13B를 기반으로 GSM8K 성능을 10.69% 증가시킬 수 있다. 한 가지 가능한 이유는 ReAlign이 더 명확하고 중간 단계와 설명을 제공하여 모델의 추론 능력을 강화할 수 있기 때문이다.\n' +
      '\n' +
      'ReAlign Can Enhance Factuality.사실성을 평가하기 위해 ReAlign to Open-Platypus, No Robots, Alpaca 데이터셋을 LLaMA-2-13B와 함께 사용하여 NQ 샘플의 Ground truth에 대한 반응을 비교한다. 도. 도 4는 ReAlign이 그 효능을 강조하면서 사실성을 높인다. 이러한 개선은 아마도 검색 증강의 추가 때문일 것이다.\n' +
      '\n' +
      'ReAlign Can Improve Readability.Response의 가독성을 평가하기 위해 가독성 평가 프롬프트를 사용한다(Tab.16 참조). GPT-4와 인간이 원래 데이터 세트에 대해 훈련된 모델과 ReAlign을 추가하여 훈련된 모델을 비교하도록 안내한다. 도 1에 도시된 바와 같다. 도 5를 참조하면, ReAlign은 특히 Open-Platypus 데이터세트에서 3개의 데이터세트의 가독성을 향상시킬 수 있음을 알 수 있다(즉, GPT-4 판결에서 18.7% 개선). 다른 작업에 대해 다른 형식을 설계하고 재포맷하면 가독성을 효과적으로 향상시킬 수 있음을 보여준다. 또한, 인간은 GPT-4에 비해 판단을 위해 더 많은 유대감을 제공하는 경향이 있다. 가능한 이유는 ReAlign이 더 나은 구조를 제공할 수 있기 때문에, GPT-4가 내용 및 깊은 구조를 무시하는 표면 포맷으로 제한된다. 대조적으로, 인간은 표면 형식에 국한되지 않고 더 주의 깊게 읽을 수 있다.\n' +
      '\n' +
      '### Analysis\n' +
      '\n' +
      '데이터세트 분석 4.5.1\n' +
      '\n' +
      '먼저, 원본 데이터 세트 간의 응답 길이(즉, 토큰 수) 변화와 ReAlign의 추가를 비교하여 Open-Platypus는 짧아지고 No Robots는 크게 변하지 않는 반면 Alpaca, GSM8K, MATH는 길어짐을 알 수 있다(탭 5 참조). 둘째, 적응형 재쓰기 방법이 편집 거리에 따라 재쓰기를 선택하는 응답의 백분율을 계산한다(결과는 탭 5에 나와 있다). 구체적으로, 단어 단위로 편집 거리(대체, 삭제, 삽입 포함)를 계산하고, 편집 거리를 원본 응답과 재작성 응답 중 가장 긴 길이의 길이로 나누어 편집률을 구하고, 최종적으로 편집률이 0.2 이상인 것을 재작성, 나머지를 재작성하지 않은 것으로 기록한다. GSM8K 및 MATH 데이터 세트의 경우 모든 데이터가 적응 재기록이 적용되지 않았기 때문에 재정렬된다.\n' +
      '\n' +
      '그림 4: 사실성 점수의 결과.\n' +
      '\n' +
      '그림 5: GPT-4와 인간에 의해 판단되는 LLaMA-2-13B를 기반으로 원본 데이터세트와 ReAlign + 원본 데이터세트의 가독성 윈레이트.\n' +
      '\n' +
      '######4.5.2 선형세\n' +
      '\n' +
      'ReAlign 데이터셋에서 모델을 미세 조정할 때, 탐색할 가치가 있는 질문은 정렬 능력이 향상되더라도 지식 능력이 떨어지는지 여부이다. 지식 능력을 평가하기 위해 Mitra et al., 2023을 사용하여 다중 선택 지식 집약적 QA 작업인 **Big Bench Hard (BBH)**(Suzgun et al., 2022) 및 **AGIEval**(Zhong et al., 2023)의 벤치마크를 채택한다. 도 1에 도시된 바와 같다. 도 6을 참조하면, ReAlign은 지식 기반 작업에 거의 영향을 미치지 않음을 알 수 있으며, 이는 우리의 접근법이 원본 데이터 세트의 지식을 손상시키지 않음을 나타낸다. 일부 경우에 ReAlign은 AGIEval에 대한 Open-Platypus와 같은 지식에 상당한 증가를 제공할 것이라는 점에 주목할 필요가 있다. 가능한 이유는 잘 정의된 포맷이 지식 기반 태스크의 정확성을 용이하게 할 수 있고(Wei et al., 2022), 외부 정보를 검색하는 것이 지식을 증가시킬 수 있기 때문이다.\n' +
      '\n' +
      '###### 4.5.3 절제 연구\n' +
      '\n' +
      '오픈 플라티푸스 데이터 세트의 두 가지 변형을 다시 작성하고 절제 연구를 위해 LLaMA-2-13B를 기반으로 훈련한다.\n' +
      '\n' +
      '(1) **W/o Retrieval Augmentation**: ReAlign에서 Retrieval Augmentation을 제거하고 증거 없이 모든 작업을 다시 쓴다. 탭에 표시된 대로입니다. 도 6을 참조하면, 일반 정렬 능력, 지식 능력, 사실성 점수(FS)가 감소하여 검색 증강의 효과를 나타낸다. 흥미롭게도 FS 메트릭은 원래 데이터 세트보다 RAG가 없으면 더 높으며, 이는 ReAlign이 사실성을 개선할 가능성도 있음을 시사한다.\n' +
      '\n' +
      '(2) **W/o Adaption**: ReAlign에서 적응적 재기입을 제거하고 force rewriting을 사용한다. 탭 도 6은 일반적인 정렬 및 지식 능력 감소를 나타낸다. 이는 강제 재작성이 응답을 보다 구조화하면서 질문의 요구 사항을 무시하여 지시-추종 능력을 약화시키기 때문일 수 있다. In\n' +
      '\n' +
      '그림 6: 빅벤치 하드(BBH)(3-shot), AGIEval(zero-shot)을 포함한 지식 능력의 결과. LLaMA-2-13B를 기반으로 Open-Platypus, No Robots 및 Alpaca 데이터 세트에 걸친 능력을 평가한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c} \\hline \\hline Dataset & Response Len. & ReAlign \\% \\\\ \\hline Open–Platypus & 224.92 & - \\\\ + ReAlign & 206.91 & 28.5\\% \\\\ \\hline No Robots & 211.99 & - \\\\ + ReAlign & 211.54 & 15.9\\% \\\\ \\hline Alpaca & 65.51 & - \\\\ + ReAlign & 72.38 & 29.9\\% \\\\ \\hline GSM8K & 130.59 & - \\\\ + ReAlign & 327.65 & 100\\% \\\\ \\hline MATH & 243.73 & - \\\\ + ReAlign & 375.35 & 100\\% \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 데이터셋 분석은 원본 데이터셋과 +ReAlign을 포함한다. 렌한테 대답해 는 응답의 평균 토큰 수입니다. 재정렬 %는 적응적 재작성 후 성공적인 재포맷의 백분율을 나타낸다.\n' +
      '\n' +
      '추가, FS는 증가했는데, 이는 아마도 강제 재작성이 더 많은 양의 재정렬 데이터로 이어져 더 많은 검색된 지식을 도입하고 사실성을 높이기 때문일 것이다.\n' +
      '\n' +
      '4.5.4 재정렬의 스케일링 법칙\n' +
      '\n' +
      '우리는 ReAlign 수의 영향을 탐구하기 위해 실험을 한다. 구체적으로 ReAlign Alpaca 데이터의 \\(k\\%\\)(\\(k=0,5,10,20\\), Full, with Full은 \\(29.9\\%\\))을 랜덤하게 샘플링하고 나머지는 원래 응답으로 채운다. 원래 Alpaca 데이터 세트는 \\(0\\%\\)에 해당한다. 흥미롭게도 ReAlign 데이터의 5%만이 전체 ReAlign 데이터에 비해 일반적인 정렬 능력이 67% 증가한다는 것을 발견했다(도 7 참조). 이는 사전 훈련 시 이미 습득한 지식과 역량을 노출시키기 위해 스타일과 형식을 익히기 위해서는 적은 양의 데이터만이 필요함을 시사한다(Zhou et al., 2023). 추가적으로, 지식 능력은 ReAlign 데이터의 양이 향상됨에 따라 계속 개선된다.\n' +
      '\n' +
      '4.5.5 사례연구\n' +
      '\n' +
      '우리는 Tab. 7의 MT-Bench 테스트 세트에서 나온 사례를 보여준다. 이 예는 ReAlign 모델에 의해 주어진 응답이 더 나은 형식을 가짐을 보여준다.\n' +
      '\n' +
      '## 5 Conclusion\n' +
      '\n' +
      '본 연구에서는 인건비와 환각을 최소화하면서 기존의 수업 데이터셋의 품질을 자동으로 향상시키는 간단하고 효과적인 정렬 방법인 ReAlign을 제안한다. Open-Platypus(Lee et al., 2023), No Robots(Rajani et al., 2023), Alpaca(Taori et al., 2023), GSM8K(Cobbe et al., 2021), MATH(Hendrycks et al., 2021) 및 고품질 수동 작성 자연어 포맷에서 5개의 새로운 고품질 데이터 세트를 생성한다. 실험은 ReAlign이 지식 능력을 손상시키지 않으면서 일반 정렬 능력, 수학 추론, 사실성 및 가독성을 유의하게 향상시킨다는 것을 보여준다. 마지막으로, 향후 연구를 용이하게 하기 위해 코드와 데이터를 공개합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c c} \\hline \\hline Dataset & General Align. & Know. Ab. & FS \\\\ \\hline Open-Platypus & 6.18 & 39.65 & 5.1 \\\\ + ReAlign & **6.24** & **41.35** & 5.5 \\\\ \\hline W/o RAG & 6.18 & 40.6 & 5.3 \\\\ W/o Adaption & 6.17 & 39.8 & **5.6** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 절제 연구 결과는 검색 증강을 제거하는 것이 ReAlign에서 “W/o RAG”로 표시되고, “W/o Adaption”에 의한 적응적 재기입을 제거하는 것을 보여준다. \'장군 얼라인\'과 \'아브\' 평균적인 결과인 일반 정렬 능력과 지식 능력을 나타낸다. FS는 사실성 점수를 나타냅니다. 대담하다는 것은 최고의 것을 의미한다.\n' +
      '\n' +
      '도 7: 일반적인 정렬 능력 및 지식 능력을 포함하는 ReAlign 데이터 백분율의 스케일링 경향. 우리는 LLaMA-2-13B를 기반으로 한 알파카 데이터 세트에서 실험을 수행한다.\n' +
      '\n' +
      '### Limitations\n' +
      '\n' +
      '먼저, 우리의 접근법은 현재 오픈 소스 모델(예를 들어, LLaMA2(Touvron et al., 2023))에서는 덜 효과적이지만 폐쇄 소스 모델(예를 들어, GPT-4(OpenAI, 2023))에서는 더 비용이 많이 드는 모델을 재포맷하는 능력에 의존한다. 둘째, 실제 질문이 더 복잡하고 여러 작업을 포함할 수 있기 때문에 우리가 정의하는 작업 범주는 실제 모든 작업을 포괄할 수 없다. 따라서 광범위하고 다양한 지역 시나리오에 대한 더 많은 작업과 형식을 정의할 필요가 있다. 마지막으로, 단일 턴 대화에만 Realign을 적용하는 것은 두 번째 턴 대화의 정렬 능력을 해칠 가능성이 있으므로 ReAlign을 다중 턴 대화로 확장하는 것도 가치가 있다.\n' +
      '\n' +
      '## Ethics Statement\n' +
      '\n' +
      '우리는 윤리적인 고려를 매우 진지하게 받아들인다. 이 논문에서는 데이터 세트와 모델을 모두 공개적으로 사용할 수 있으며 연구자에 의해 널리 채택되었다. 본 논문의 결과와 결론이 정확하고 객관적으로 보고될 수 있도록 한다.\n' +
      '\n' +
      '## Acknowledgements\n' +
      '\n' +
      '우리 논문을 검토하고 귀중한 피드백을 주신 GAIR 회원 여러분께 감사드립니다. 우리는 Wang et al. (2023)의 저자들이 훈련 코드베이스와 유용함을 제공한 것에 대해 감사한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Brown et al. (2023) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. 지글러, 제프리 우, 클레멘스 윈터, 크리스토퍼 헤세, 마크 첸, 에릭 시글러, 마테우스 리트윈, 스콧 그레이, 벤자민 체스, 잭 클락, 크리스토퍼 버너, 샘 맥캔들시, 알렉 래드포드, 일리아 서츠키버, 다리오 아모데이. 2020. 언어 모델은 소수의 학습자이다. _NeurIPS_에서.\n' +
      '* Cao et al. (2023) Yihan Cao, Yanbin Kang, and Lichao Sun. 2023. 명령어 마이닝: 대용량 언어 모델에 대한 고품질 명령어 데이터 선택_ arXiv Preprint_.\n' +
      '* Chen et al. (2023) Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, and Hongxia Jin. 2023. Alpagasus: 더 적은 데이터로 더 나은 알파카를 훈련한다. _ arXiv Preprint_.\n' +
      '* Chern et al. (2023) I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu, et al. 2023. Factool: Factool: Factuality detection in generative ai-a tool augmented framework for multi-task and multidomain scenarios. _ arXiv preprint arXiv:2307.13528_.\n' +
      '* Chiang et al. (2023) Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zhang, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: 90%* chatppt 품질로 gpt-4를 인상하는 오픈소스 챗봇.\n' +
      '* Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. 수학 단어 문제 해결을 위한 학습 검증자_ arXiv preprint arXiv:2110.14168_.\n' +
      '* Granziol et al. (2022) Diego Granziol, Stefan Zohren, and Stephen Roberts. 2022. 배치 크기의 함수로서의 학습율: 신경망 학습에 대한 랜덤 매트릭스 이론 접근법. _ J 마흐 배워 Res._ , 23:173:1-173:65.\n' +
      '* Gudibande et al. (2023) Arnav Gudibande, Eric Wallace, Charlie Snell, Xinyang Geng, Hao Liu, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. 전매특허 lms를 모방한다는 잘못된 약속 arXiv Preprint_.\n' +
      '* Hendrycks et al. (2021) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. 수학 데이터셋으로 수학 문제 풀이를 측정하는 단계. _ NeurIPS_.\n' +
      '* Honovich et al. (2023) or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2023. 부자연스러운 지시: 인간 노동력이 거의 없는(거의) 언어 모델을 튜닝하는 것. _ACL_에서, 캐나다 토론토의 14409-14428 페이지. 컴퓨터 언어학과의 연관성\n' +
      '* Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2023. 자연어 생성에서의 환각 실태 조사. _ ACM 컴퓨터. Surv._ , 55(12):248:1-248:38.\n' +
      '\n' +
      '* [12] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lelio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothee Lacroix, and William El Sayed. 2023. Mistral 7b. _arXiv preprint arXiv:2310.06825_.\n' +
      '* [13] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural questions: A benchmark for question answering research. _Transactions of the Association for Computational Linguistics_, 7:453-466.\n' +
      '* 대형 언어 모델 정렬을 민주화하는 단계; _ arXiv Preprint_.\n' +
      '* [15] Ariel N. Lee, Cole J. Hunter, and Nataniel Ruiz. 2023. Platypus: Quick, cheap, and powerful refinement of llms. _arXiv Preprint_.\n' +
      '* [16] Junlong Li, Shichao Sun, Weizhe Yuan, Run-Ze Fan, hai zhao, and Pengfei Liu. 2024. Generative judge for evaluating alignment. In _The Twelfth International Conference on Learning Representations_.\n' +
      '* [17] Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng, Jianzong Wang, Tianyi Zhou, and Jing Xiao. 2023a. From quantity to quality: Boosting llm performance with self-guided data selection for instruction tuning. _arXiv Preprint_.\n' +
      '* [18] Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy, Jason Weston, and Mike Lewis. 2023b. Self-alignment with instruction backtranslation. _arXiv Preprint_.\n' +
      '* [19] Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023c. Alpaceaval: An automatic evaluator of instruction-following models. [https://github.com/tatsu-lab/alpaca_eval](https://github.com/tatsu-lab/alpaca_eval).\n' +
      '* [20] Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, and Junxian He. 2023. What makes good data for alignment? a comprehensive study of automatic data selection in instruction tuning. _arXiv preprint arXiv:2312.15685_.\n' +
      '* [21] Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Junyang Lin, Chuanqi Tan, Chang Zhou, and Jingren Zhou. 2023. lfinstag: Instruction tagging for analyzing supervised fine-tuning of large language models. _arXiv Preprint_.\n' +
      '* [22] Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022. Cross-task generalization via natural language crowdsourcing instructions. In _ACL_, pages 3470-3487, Dublin, Ireland. Association for Computational Linguistics.\n' +
      '* [23] Arindam Mitra, Luciano Del Corro, Shweti Mahajan, Andres Codas, Clarisse Simoes, Sahaj Agarwal, Xuxi Chen, Anastasia Razdabiedina, Erik Jones, Kriti Aggarwal, Hamid Palangi, Guoqing Zheng, Corby Rosset, Hamed Khanpour, and Ahmed Awadallah. 2023. Orca 2: Teaching small language models how to reason. _arXiv preprint arXiv:2311.11045_.\n' +
      '* [24] OpenAI. 2023. Gpt-4 technical report. _arXiv Preprint_.\n' +
      '* [25] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. In _NeurIPS_.\n' +
      '* [26] Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023. Instruction tuning with gpt-4. _arXiv Preprint_.\n' +
      '* [27] Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim Rocktaschel, and Sebastian Riedel. 2021. KILT: a benchmark for knowledge intensive language tasks. In _Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, pages 2523-2544, Online. Association for Computational Linguistics.\n' +
      '* [28] Nazneen Rajani, Lewis Tunstall, Edward Beeching, Nathan Lambert, Alexander M. Rush, and Thomas Wolf. 2023. No robots. [https://huggingface.co/datasets/HuggingFaceH4/no_robots](https://huggingface.co/datasets/HuggingFaceH4/no_robots).\n' +
      '\n' +
      '* [29] Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhabulani, Nihal Nayak, Debayoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesth Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M. Rush. 2022. Multitask prompted training enables zero-shot task generalization. _arXiv Preprint_.\n' +
      '* [30] Shichao Sun, Junlong Li, Weizhe Yuan, Ruifeng Yuan, Wenjie Li, and Pengfei Liu. 2024. The critique of critique. _arXiv preprint arXiv:2401.04518_.\n' +
      '* [31] Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou,, and Jason Wei. 2022. Challenging big-bench tasks and whether chain-of-thought can solve them. _arXiv preprint arXiv:2210.09261_.\n' +
      '* [32] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. [https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca).\n' +
      '* [33] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guilleu Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenjin Fu, Brian Fuller, Cynthia Gao, Vedanu Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madan Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jens Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaqiong Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zaroro, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2: Open foundation and fine-tuned chat models. _arXiv Preprint_.\n' +
      '* [34] Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen Song, and Yang Liu. 2023a. Openchat: Advancing open-source language models with mixed-quality data. _arXiv preprint arXiv:2309.11235_.\n' +
      '* [35] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b. Self-instruct: Aligning language models with self-generated instructions. In _ACL_, pages 13484-13508, Toronto, Canada. Association for Computational Linguistics.\n' +
      '* [36] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar Pal, Mehrdor Madshahii, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Raveshaj Singh Puri, Rushang Karia, Shailaja Kewur Sampat, Savan Doshi, Siddhartha Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin Choi, Noah A. Smith, Hannaneh Hajishirzi, and Daniel Khashabi. 2022. Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. _arXiv Preprint_.\n' +
      '* [37] Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 2022a. Finetuned language models are zero-shot learners. _arXiv Preprint_.\n' +
      '* [38] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022b. Chain-of-thought prompting elicits reasoning in large language models. In _NeurIPS_.\n' +
      '* [39] Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions. _arXiv Preprint_.\n' +
      '* [40] Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Sainbayar Sukhbaatar, Jing Xu, and Jason Weston. 2024. Self-rewarding language models. _arXiv preprint arXiv:2401.10020_.\n' +
      '* [41] Liaminin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. _arXiv Preprint_.\n' +
      '* [42] Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan. 2023. Agieval: A human-centric benchmark for evaluating foundation models. _arXiv preprint arXiv:2304.06364_.\n' +
      '* [43] Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer, and Omer Levy. 2023. Lima: Less is more for alignment. _arXiv Preprint_.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:14]\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:15]\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c} \\hline \\hline\n' +
      '**Task name** & \\multicolumn{2}{c}{**Description**} & **Retricul** & **Reverting** \\\\ \\hline \\hline \\multicolumn{5}{c}{_Generation_} \\\\ \\hline question generation & Write some questions based on the given description. & ✗ & ✓ \\\\ story generation & Write a story based on the given description. & ✗ & ✗ \\\\ poem generation & Write a poem based on the given description. & ✗ & ✗ \\\\ email generation & Write an email based on the given description. & ✗ & ✓ \\\\ data generation & Generate data based on the given description. & ✗ & ✓ \\\\ text-to-text translation & Translate the given text into another language. & ✗ & ✗ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Bointnessing_} \\\\ \\hline \\hline \\multicolumn{5}{c}{_Givementation_} \\\\ \\hline \\hline \\multicolumn{5}{c}{_Givementation_} \\\\ \\hline question generation & Write some questions based on the given description. & ✗ & ✓ \\\\ story generation & Write a story based on the given description. & ✗ & ✗ \\\\ poem generation & Write a poem based on the given description. & ✗ & ✓ \\\\ email generation & Write an email based on the given description. & ✗ & ✓ \\\\ data generation & Generate data based on the given description. & ✗ & ✓ \\\\ text-to-text translation & Translate the given text into another language. & ✗ & ✗ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Bointnessing_} \\\\ \\hline \\hline \\multicolumn{5}{c}{_Abilice giving_} \\\\ recommendations & Green recommendations to users. & & ✓ \\\\ how to-generation & Grey relevant and complete answer when users ask: how to do? something. & ✓ \\\\ planning & Write a plan for an event or activity. & ✗ & ✓ \\\\ \\hline \\multicolumn{5}{c}{_Code_} \\\\ \\hline code correction & Correct the potential errors in a piece of code. & ✗ & ✓ \\\\ code simplification & Rewrite a piece of code to make it more concise and easy to understand. & ✗ & ✓ \\\\ explain code & Write an explanation for a piece of code. & ✗ & ✓ \\\\ text-to-text translation & Write a piece of code based on the given description. & ✗ & ✓ \\\\ code-to-text translation & Convert the given code into another programming language. & ✗ & ✓ \\\\ language learning questions & Write an answer for the given question about programming language learning. & ✗ & ✓ \\\\ code language classification & Clearly the programming language for the given code. & ✗ & ✓ \\\\ code-to-text translation & Write a document for the given code. & ✗ & ✓ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Reverting_} \\\\ \\hline \\hline \\multicolumn{5}{c}{_Instrucational rewriting_} \\\\ \\hline language polishing & Postulating a piece text with a specific interaction. & ✗ & ✓ \\\\ language polishing & Postulating a piece of text to make it more honest, natural, and readable. & ✗ & ✓ \\\\ paraphasing & Postulating a piece of text. & ✗ & ✗ \\\\ text correction & Correct the potential errors in a piece of text. & ✗ & ✓ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Enumication_} \\\\ \\hline \\hline \\multicolumn{5}{c}{_Information extraction_} \\\\ keywords extraction & Extract one or multiple user-specified categories of information from a piece of text attached in the user’s query. & ✗ & ✓ \\\\ keywords extraction & Extract the keywords from a piece of text. & ✗ & ✓ \\\\ table extraction & Generate a table included the key information from a piece of text attached in the user’s query. & ✗ & ✗ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Semanization_} \\\\ \\hline title generation & Generate a title for the given text or based on a description of the work. & ✗ & ✗ \\\\ text summarization & Write a summary for a piece of text. & ✗ & ✗ \\\\ note summarization & Write a note to summarize a piece of text. & ✗ & ✗ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Conversation_} \\\\ \\hline open qn & The user’s query is an open domain question with no attached language or article. & ✓ & ✓ \\\\ closed qn & Answer the questions that can be directly answered by the attached passage. & ✗ & ✓ \\\\ fact verification & Verify the given text is true or false. & ✓ & ✓ \\\\ value judgment & Provable a subject to an engine topic or statement. & ✗ & ✓ \\\\ replay & Pretard to be a specific person, character, profession or identity, and complete the required task on this basis. & ✗ & ✗ \\\\ explain answer & Explain something the user wants to know. & ✓ & ✓ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Semanization_} \\\\ \\hline natural language nator & Write an answer for the given question about manual language learning & ✗ & ✓ \\\\ exam problem tutor & Solve an even question (like all-in-the-batch, multiple choice, problem solving, etc) with no math involved. & ✗ & ✓ \\\\ is at work & Write an answer for the given question about machine learning, artificial intelligence or language model. & ✗ & ✓ \\\\ map puzzles & Write an answer with the step-by-step reasoning process for a math equation. & ✗ & ✓ \\\\ fill in the blank & Complete the missing parts with the most appropriate works to make the text coherent and meaningful. & ✗ & ✓ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Classification_} \\\\ \\hline \\hline \\multicolumn{5}{c}{_Causality_ one of multiple objects given by the user into the specified categories. & ✗ & ✓ \\\\ ordering & Sort some thing, according to some criteria. & ✗ & ✓ \\\\ sentiment analysis & Identify and categorize the subjective opinions, attitudes, and feelings of the writer towards a particular subject. & ✗ & ✓ \\\\ language classification & Classify the language for the given text. & ✗ & ✓ \\\\ topic classification & Evaluate the high-level topics or chines from a given text, i.e., what kind of topics are discussed in the text. & ✗ & ✓ \\\\ \\hline \\hline \\multicolumn{5}{c}{_Others_} \\\\ \\hline \\hline \\multicolumn{5}{c}{_rejecting_} & Reject to respond when the query is beyond capacity or it violates general ethical and legal rules. & ✗ & ✓ \\\\ others & You must choose this if none of the other scenarios match the user’s query well. & ✗ & ✓ \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: 각 태스크에 대한 상세 설명.\n' +
      '\n' +
      '\\begin{tabular}{l|c|c|l|l|l|l|l|l} \\hline task & train & test & task & train & test & task & train & test \\\\ \\hline question\\_generation & 30 & 2 & code\\_language\\_classification & 30 & 2 & roleplay & 30 & 3 \\\\ story\\_generation & 30 & 4 & code\\_a\\_b\\_text,translation & 30 & 3 & explain\\_answer & 30 & 4 \\\\ poem\\_generation & 30 & 3 & instruction\\_experiment\\_with & 30 & 4 & natural\\_language\\_learning\\_intaver & 30 & 2 \\\\ email\\_generation & 30 & 3 & language\\_polishing & 30 & 2 & exam\\_problem\\_solving\\_intaver & 31 & 2 \\\\ data\\_generation & 30 & 3 & paraphing & 30 & 2 & malt\\_language\\_model\\_intaver & 30 & 3 \\\\ text\\_a\\_b\\_text,next\\_translation & 30 & 3 & text\\_a\\_correction & 30 & 2 & man\\_uzz\\_bez & 30 & 6 \\\\ adv\\_e\\_giving & 30 & 4 & information\\_extraction & 30 & 3 & fill\\_in\\_in\\_the\\_blank & 30 & 3 \\\\ recommendations & 30 & 2 & keyword\\_extraction & 30 & 2 & general\\_classification & 30 & 4 \\\\ how\\_to\\_a\\_generation & 30 & 3 & table\\_extraction & 30 & 3 & ordering & 30 & 3 \\\\ planning & 30 & 2 & title\\_generation & 30 & 2 & sentiment\\_analysis & 30 & 3 \\\\ code\\_correction & 30 & 5 & text\\_summarization & 30 & 5 & language\\_classification & 30 & 3 \\\\ code\\_simplification & 30 & 2 & note\\_summarization & 30 & 2 & topic\\_classification & 30 & 2 \\\\ explain\\_code & 30 & 2 & open\\_a & 30 & 6 & rejecting & 30 & 3 \\\\ text\\_a\\_code\\_translation & 30 & 4 & closed\\_a & 30 & 2 & others & 43 & 8 \\\\ code\\_a\\_code\\_translation & 30 & 3 & fact\\_verification & 30 & 2 & overall & 1395 & 143 \\\\ language\\_learning\\_questions & 31 & 5 & value\\_ judgement & 30 & 2 & & \\\\ \\hline \\end{tabular}\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c|c|l|l|l|l|l} \\hline task & train & test & task & train & test & task & train & test \\\\ \\hline question\\_generation & 30 & 2 & code\\_language\\_classification & 30 & 2 & roleplay & 30 & 3 \\\\ story\\_generation & 30 & 4 & code\\_a\\_b\\_text,translation & 30 & 3 & explain\\_answer & 30 & 4 \\\\ poem\\_generation & 30 & 3 & instruction\\_experiment\\_with & 30 & 4 & natural\\_language\\_learning\\_intaver & 30 & 2 \\\\ email\\_generation & 30 & 3 & language\\_polishing & 30 & 2 & exam\\_problem\\_solving\\_intaver & 31 & 2 \\\\ data\\_generation & 30 & 3 & paraphing & 30 & 2 & malt\\_language\\_model\\_intaver & 30 & 3 \\\\ text\\_a\\_b\\_text,next\\_translation & 30 & 3 & text\\_a\\_correction & 30 & 2 & man\\_uzz\\_bez & 30 & 6 \\\\ adv\\_e\\_giving & 30 & 4 & information\\_extraction & 30 & 3 & fill\\_in\\_the\\_blank & 30 & 3 \\\\ recommendations & 30 & 2 & keyword\\_extraction & 30 & 2 & general\\_classification & 30 & 4 \\\\ how\\_to\\_a\\_generation & 30 & 3 & table\\_extraction & 30 & 3 & ordering & 30 & 3 \\\\ planning & 30 & 2 & title\\_generation & 30 & 2 & sentiment\\_analysis & 30 & 3 \\\\ code\\_correction & 30 & 5 & text\\_summarization & 30 & 5 & language\\_classification & 30 & 3 \\\\ code\\_simplification & 30 & 2 & note\\_summarization & 30 & 2 & topic\\_classification & 30 & 2 \\\\ explain\\_code & 30 & 2 & open\\_a & 30 & 6 & rejecting & 30 & 3 \\\\ text\\_a\\_code\\_translation & 30 & 4 & closed\\_a & 30 & 2 & others & 43 & 8 \\\\ code\\_a\\_to\\_code\\_translation & 30 & 3 & fact\\_verification & 30 & 2 & overall & 1395 & 143 \\\\ language\\_learning\\_questions & 31 & 5 & value\\_ judgement & 30 & 2 & & \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 9: 태스크 분류기에 대한 트레이닝 및 테스트 세트에서의 태스크 분포.\n' +
      '\n' +
      '**Classification Prompt**\n' +
      '\n' +
      '사용자의 쿼리를 받게 됩니다. 또한 아래에 미리 정의된 몇 가지 작업이 제공됩니다.\n' +
      '\n' +
      '[기존 작업 시작]\n' +
      '\n' +
      'estion_generation story_generation poem_generation email_generation data_generation alive_give_giving recommendations how_to_generation planning instructional_executing language_polishing text_correction code_extraction keyword_generation text_summarization note_summarization explain_code_simserver text_to_to_next_translation text_to_code_to_code_translation open_qa closed_qa fil_in_the_blank fick_verification math_puzzle language_learning_questions natural_language_learning_tumor exam_open_solving_store ml_1.lang_muege model_motor general_classification order sentiment_language_classification language_classification value_judgement policyplay default [ existing tasks end]\n' +
      '\n' +
      '귀하의 목표는 이 쿼리의 높은 수준의 의도를 반영할 수 있는 가장 적절한 작업을 선택하는 것입니다. 당신은 먼저 당신의 선택을 명확히 해야 합니다. 선택사항은 수정 없이 위에서 제공된 작업 이름 중 하나와 정확히 일치해야 합니다. 선택에 작업 설명을 포함하지 마십시오.\n' +
      '\n' +
      '출력은 작업 이름만 있어야 합니다.\n' +
      '\n' +
      '사용자의 질의는 다음과 같다:\n' +
      '\n' +
      '사용자의 질의 시작\n' +
      '\n' +
      'input]\n' +
      '\n' +
      '사용자의 질의 종료\n' +
      '\n' +
      'Task name:\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{p{284.5pt}} \\hline\n' +
      '**분류 프롬프트**\\\\ 사용자의 쿼리를 받게 됩니다. 또한 아래에 미리 정의된 몇 가지 작업이 제공됩니다.\n' +
      '\n' +
      '[Existing tasks start] question_generation story_generation poem_generation email_generation data_generation alive_give recommendations how_to_generation planning instructional_executing language_polishing text_correction code_correction code_simplification information_extraction keywords_extraction table_extraction title_generation text_summarization note_summarization explain_code_summarized text_to_code_translation text_to_code_translation code_to_code_translation code_to_code_translation code_to_next_translation open_qa closed_qa fil_in_the_blank fick_verification math_puzzles language_learning_questions natural_language_learning_tumor exam_open_solving_store ml_1.lang_muege model_motor general_classification ordering sentiment_analysis code_language_classification language_classification topic_classification value_judgement policyplay default [Existing tasks end] \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 10: 훈련 및 추론 단계에서 태스크 분류기에 대한 분류 프롬프트.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:19]\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l} \\hline\n' +
      '**Query** \\\\ How many positive three-digit integers less than 500 have at least two digits that are the same? \\\\ \\hline\n' +
      '**Criteria** \\\\ Task Name: math puzzles \\\\ Format: This is a ninth question. First, analyze the question and give a brief analysis in the first paragraph. Then, use a list to present the step-by-step solution. Next, give another list to output a detailed explanation. Last, give the correct result and a conclusion. \\\\ \\hline\n' +
      '**Original Response** \\\\ To solve this problem, I will count how many three-digit numbers less than 500 have at least two digits that are the same, and subtract that from the total number of three-digit numbers less than 500. The total number of three-digit numbers less than 500 is \\(4\\times 10\\times 10=400\\), since the first digit can be 1, 2, 3, or 4, and the second and third digits can be anything from 0 to 9. Now I will count how many of these 400 numbers have no digits that are the same. To have no digits that are the same, the first digit can be any of the choices, but the second digit has to be different from the first, so it has 9 choices. The third digit has to be different from both the first and the second, so it has 8 choices. \\\\ \\hline \\end{tabular} \\(\\dagger\\) on another note1 I am assuming that the second digit can be 0, since the problem does not say otherwise. Therefore, the number of three-digit numbers less than 500 that have no digits that are the same is \\(4\\times 9\\times 8=288\\). This means that the number of three-digit numbers less than 500 that have at least two digits that are the same is \\(400-288=112\\). \\\\ \\hline\n' +
      '**Reign Response (Ours)**\\\\Analysis: \\\\\\ 문제를 해결하기 위해, 우리는 500보다 작은 세 자릿수가 같은 두 자릿수 이상을 갖는 수를 세어야 한다. \\\\\\ 용액: \\\\\n' +
      '1. 500보다 작은 세자리 수의 총 수를 계산: \\(4\\times 10\\times 10=400\\). \\\\\n' +
      '2. 같은 숫자가 없는 500보다 작은 세 자리수의 수를 세라: \\(4\\times 9\\times 8=288\\). \\\\times\n' +
      '3. Subtract count of numbers with no same digits from the total to find the number of three-digit numbers less than 500 that have at least two digits that are the same: \\(400-288=112\\). \\\\ Explanation: \\\\ \\hline The first digit can be 1, 2, 3, or 4, and the second and third digits can be anything from 0 to 9. \\\\ \\(\\dagger\\). The have no digits that are the same, the first digit can be any of the 4 choices, but the second digit has to be different from the first, so it has 9 choices. The third digit has to be different from both the first and the second, so it has 8 choices. \\\\ Result: \\\\ There are 112 three-digit numbers less than 500 that have at least two digits that are the same. \\\\ Conclusion: \\\\ There are 112 positive three-digit integers less than 500 that have at least two digits that are the same. \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 13: 원본 응답 및 ReAlign 응답을 포함하는 쿼리의 완전한 예.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l} \\hline\n' +
      '**Query** \\\\ How many positive three-digit integers less than 500 have at least two digits that are the same? \\\\ \\hline\n' +
      '**Criteria** \\\\ Task Name: math puzzles \\\\ Format: This is a ninth question. First, analyze the question and give a brief analysis in the first paragraph. Then, use a list to present the step-by-step solution. Next, give another list to output a detailed explanation. Last, give the correct result and a conclusion. \\\\ \\hline\n' +
      '**Original Response** \\\\ To solve this problem, I will count how many three-digit numbers less than 500 have at least two digits that are the same, and subtract that from the total number of three-digit numbers less than 500. The total number of three-digit numbers less than 500 is \\(4\\times 10\\times 10=400\\), since the first digit can be 1, 2, 3, or 4, and the second and third digits can be anything from 0 to 9. Now I will count how many of these 400 numbers have no digits that are the same. To have no digits that are the same, the first digit can be any of the choices, but the second digit has to be different from the first, so it has 9 choices. The third digit has to be different from the first and the second, so it has 8 choices. \\\\ \\hline\n' +
      '**Reign Response (우리들)**\\\\ 문제를 해결하기 위해, 우리는 500보다 작은 세 자릿수가 같은 두 자릿수 이상을 갖는 수를 세어야 한다. \\\\ 용액: \\\\\n' +
      '1. 500보다 작은 세자리 수의 총 수를 계산: \\(4\\times 10\\times 10=400\\). \\\\\n' +
      '2. 같은 숫자가 없는 500보다 작은 세 자리수의 수를 세라: \\(4\\times 9\\times 8=288\\). \\\\times\n' +
      '3. Subtract count of numbers with no same digits from the total to find the number of three-digit numbers less than 500 that have at least two digits that are the same: \\(400-288=112\\). \\\\ Explanation: \\\\ \\hline The first digit can be 1, 2, 3, or 4, and the second and third digits can be anything from 0 to 9. \\\\ \\(\\dagger\\). The have no digits that are the same, the first digit can be any of the 4 choices, but the second digit has to be different from the first, so it has 9 choices. The third digit has to be different from both the first and the second, so it has 8 choices. \\\\ Result: \\\\ There are 112 three-digit numbers less than 500 that have at least two digits that are the same. \\\\ Conclusion: \\\\ There are 112 positive three-digit integers less than 500 that have at least two digits that are the same. \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 14: "이메일 생성" 태스크에 대한 완전한 포맷.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{p{284.5pt}} \\hline\n' +
      '**System Prompt** \\\\ Please at as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. You should choose the assistant that [follows the user’s instructions and answers the user’s question better. Your evaluation should consider the reachability including clarity, format, and ease of understanding. Well-organized, grammically correct response is better. Begin your evaluation by comparing the two responses and provide a short explanation. Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. Do not allow the length of the responses to influence your evaluation. Do not favor certain names of the assistants. Be as objective as possible. After providing your explanation, output your final verdict by strictly following this format: “[I/AI]” if assistant A is better, “[I/BI]” if assistant B is better, and “[IC]” for a tie. \\\\ \\hline\n' +
      '**User Prompt** \\\\ [User Question] \\\\ \\{question\\} \\\\ \\{The Start of Assistant A’s Answer\\} \\\\ \\{answer\\_a\\} \\\\ \\{The End of Assistant B’s Answer\\} \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 16: 가독성에 대한 평가 프롬프트.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{p{284.5pt}} \\hline\n' +
      '**Query** \\\\ It is the given statement true or false? \\\\ A robotic vacuum can clean both carpets and hard floors. \\\\ \\hline\n' +
      '**Criteria** \\\\ Task Name: fact verification \\\\ Format: This is a fact-verification task. First, give the answer. Then, give an explanation. \\\\ \\hline\n' +
      '**Retrievel Evidence** \\\\ \\hline\n' +
      '1. 로봇 진공청소기는 완전히 자율적이고 자동으로 작동한다. 그들은 핸드우드에서 카펫에 이르기까지 모든 바닥 유형에 대해 자체 대기하며 일부 모델은 청소 일정을 가지고 스마트폰 및 스마트 홈 장치에 동기화할 수 있도록 프로그래밍할 수도 있습니다. \\\\\n' +
      '2. 로봇 노옴 진공은 라미네이트 바닥재에서 작동한다. 사실 그들은 카펫에 비해 딱딱한 바닥에서 더 잘 일한다. 왜냐하면 그들의 흡입과 비터 바는...\\\\\n' +
      '3. 활엽수 바닥의 가장 좋은 진공청소기 중 우리의 최고 선택은 iRobot Roomha 694이며, iRobot은 로봇과 관련하여 최고의 선택으로 알려져 있다. \\\\\n' +
      '4. Because they lack the power to deep clean, though, robot vacuums are best for flooring other than carpet, such as tile, laminate or hardwood,... \\\\ \\hline\n' +
      '**Original Response** \\\\ True. \\\\ True. \\\\ \\hline\n' +
      '**ReLalign Response (Ours)** \\\\ True. \\\\ Robot vacuums can clean both carpets and hard floors. They are designed to self-awaigate on any flooring type, from handwoods to carpets, and some models can even be programmed to have a cleaning schedule and to sync to smartphones and smart home devices. Additionally, some specific models like the iRobot Roomha 694 are known as top choices for cleaning hardwood floors. However, it is important to note that robot vacuums may lack the power to deep clean carpets compared to hard floors. \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 15: 질의, 기준, 검색된 증거, 원본 응답 및 ReLalign 응답을 포함하는 지식 집약적 태스크의 일례. 우리는 녹색으로 더 사실적이고 지식이 풍부한 내용을 강조합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{p{284.5pt}} \\hline\n' +
      '**System Prompt** \\\\ Please at as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. You should choose the assistant that [follows the user’s instructions and answers the user’s question better. Your evaluation should consider the reachability including clarity, format, and ease of understanding. Well-organized, grammically correct response is better. Begin your evaluation by comparing the two responses and provide a short explanation. Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. Do not allow the length of the responses to influence your evaluation. Do not favor certain names of the assistants. Be as objective as possible. After providing your explanation, output your final verdict by strictly following this format: “[I/AI]” if assistant A is better, “[I/BI]” if assistant B is better, and “[IC]” for a tie. \\\\ \\hline\n' +
      '**User Prompt** \\\\ [User Question] \\\\ \\{question\\} \\\\ \\{The Start of Assistant A’s Answer\\} \\\\ \\{answer\\_a\\} \\\\ \\{The End of Assistant A’s Answer\\} \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 16: 가독성에 대한 평가 프롬프트.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>