<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '그래프 신경망을 통한 스포티파이의 개인화 오디오북 추천\n' +
      '\n' +
      '마르코 드 나다이1\n' +
      '\n' +
      ' 프란체스코 Fabbri1*\n' +
      '\n' +
      ' 폴 지골리1\n' +
      '\n' +
      ' 앨리스 왕1\n' +
      '\n' +
      ' 앙 Li1\n' +
      '\n' +
      ' 파브리지오 실베스트리1,2\n' +
      '\n' +
      ' 로라 킴원\n' +
      '\n' +
      ' 숀 린원\n' +
      '\n' +
      ' 블라단 라도사블예빅1\n' +
      '\n' +
      ' 샌딥 가엘1\n' +
      '\n' +
      ' 데이비드 니한1\n' +
      '\n' +
      ' 부샤드1 휴그스\n' +
      '\n' +
      ' 무니아 랄마스 로엘케1\n' +
      '\n' +
      ' 안드레아스 다미아누1\n' +
      '\n' +
      '1스포티, 덴마크, 스페인, 영국, 미국\n' +
      '\n' +
      '1\n' +
      '\n' +
      '###### Abstract.\n' +
      '\n' +
      '점점 진화하는 디지털 오디오 풍경에서 음악과 토크 콘텐츠로 잘 알려진 스포티파이는 최근 방대한 사용자 기반에 오디오북을 도입했다. 유망하지만, 이 움직임은 개인화된 추천에 중요한 과제를 제시한다. 음악 및 팟캐스트와 달리 처음에는 유료로 사용할 수 있는 오디오북은 구매 전에 쉽게 걷어낼 수 없으므로 권장 사항의 관련성에 대해 더 높은 지분을 제기한다. 또한, 기존 플랫폼에 새로운 콘텐츠 유형을 도입하는 것은 대부분의 사용자가 이러한 새로운 콘텐츠 유형에 익숙하지 않기 때문에 극단적인 데이터 희소성에 직면한다. 마지막으로 수백만 명의 사용자에게 콘텐츠를 추천하려면 모델이 빠르게 반응하고 확장 가능해야 한다. 이러한 문제를 해결하기 위해 팟캐스트와 음악 사용자 선호도를 활용하고, 2T-HGNN, HGNN(Heterogeneous Graph Neural Networks) 및 2T(Two Tower) 모델을 포함하는 확장 가능한 추천 시스템을 소개한다. 이 새로운 접근법은 낮은 지연 시간과 복잡성을 보장하면서 미묘한 항목 관계를 해결한다. 우리는 HGNN 그래프에서 사용자를 분리하고 혁신적인 다중 링크 이웃 샘플러를 제안한다. 이러한 선택은 2T 컴포넌트와 함께 HGNN 모델의 복잡성을 상당히 감소시킨다. 수백만 명의 사용자를 포함하는 경험적 평가는 개인화된 추천의 품질이 크게 향상되어 새로운 오디오북 시작률이 +46% 증가하고 스트리밍 속도가 +23% 증가한다. 흥미롭게도 저희 모델의 영향은 오디오북을 넘어 팟캐스트와 같은 기성 제품에 도움이 됩니다.\n' +
      '\n' +
      '그래프 신경망, 표현 학습, 개인화, 추천 시스템 +\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템\n' +
      '\n' +
      '+\n' +
      '각주 †: 저널: 물리학 저널 A: 수학 및 물리학\n' +
      '\n' +
      '## 1. Introduction\n' +
      '\n' +
      '아우디오북은 구술 스토리텔링이라는 고대 서사의 전통에 뿌리를 두고 있다. 더 넓은 도서 시장의 7%만을 대표함에도 불구하고, 그들의 연간 소비 증가율 20%(Mohammad et al., 2018)는 개인화된 추천에 대한 필요성이 증가하고 있음을 강조한다. 수억 명의 사용자를 서비스하는 대표적인 오디오 스트리밍 플랫폼인 스포티파이는 최근 수백만 개의 음악 트랙과 팟캐스트가 이미 포함된 오디오북을 광범위한 카탈로그(Mohammad et al., 2018)에 추가했다. 음악과 팟캐스트가 스포티파이에 통합되는 반면, 대부분의 사용자들은 새로운 콘텐츠 유형에 익숙하지 않다. 따라서 흩어져 있는 사용자 상호 작용을 활용하고 현재 플랫폼에 원활하게 맞는 오디오북 추천 시스템을 개발하는 것은 어렵다.\n' +
      '\n' +
      '오디오북에 관한 한 스포티파이는 네 가지 주요 도전에 직면해 있다. 첫째, 오디오북 추천은 이전에 규모 면에서 연구되지 않았다. 오디오북 콘텐츠를 가장 잘 모델링하고 다른 오디오 콘텐츠와의 관계를 이해하고 권장 사항에 사용 가능한 메타데이터를 활용하는 방법은 아직 결정되지 않았다. 둘째, 기존 플랫폼에서 새로운 콘텐츠 유형을 도입하는 것은 데이터 부족이라는 극단적인 콜드 스타트 도전에 직면해 있다. 셋째, 스포티파이는 현재 스포티파이 프리미엄 구독1의 일부로 오디오북을 포함시켰지만, 처음에는 직접 판매 모델(Mohammad et al., 2018)로 출시되었다. 이 판매 모델은 사용자에게 더 낮은 위험 내성을 갖도록 영향을 주어 오디오북 권장 사항의 관련성 및 정확성에 대한 더 높은 지분을 생성할 수 있다. 또한, 이 모델은 스트림 및 구매와 같은 명시적인 양의 상호작용 신호의 볼륨을 제한하여 상호작용 희소성을 극복하기 위해 암시적 신호의 사용을 요구한다. 마지막으로, 새로운 제품을 기존 플랫폼에 통합하려면 추천 시스템이 효율적이고 확장 가능하며 모듈화되어야 한다. 이 모델은 최소한의 대기 시간으로 수억 명의 사용자에게 서비스를 제공해야 하며 진화하는 사용자 상호 작용 및 제품 기능을 수용할 수 있을 만큼 유연해야 한다. 모듈성은 또한 모델의 컴포넌트들이 다양한 프로젝트들 및 컨텍스트들(예를 들어, 홈 페이지 및 검색 상의 개인화된 추천들)에서 적응되고 재사용될 수 있도록 보장하기 위해 중요하다.\n' +
      '\n' +
      '각주 1: 선택된 국가에서 오디북에 액세스할 수 있는 적격 프리미엄 사용자를 위한 것이다(Mohammad et al., 2018).\n' +
      '\n' +
      '이러한 문제에 대응하여, 우리는 HGNN(Heterogeneous Graph Neural Network) (Beng et al., 2018)과 2T(Two Tower) 모델(Mohammad et al., 2018)을 결합한 확장 가능하고 모듈화된 그래프 기반 추천 시스템인 2T-HGNN을 제시하여 최소한의 지연 시간만으로 모든 사용자에게 효과적인 추천을 보장한다.\n' +
      '\n' +
      '우리는 철저한 데이터 분석을 수행했으며 사용자 팟캐스트 소비가 사용자 오디오북 선호도를 이해하는 데 중요하다는 것을 발견했다. 더욱이, 데이터 분석을 통해, 우리는 "팔로우" 및 "프리뷰"와 같은 암시적 신호가 미래의 사용자 구매 및 스트림을 예측하는 데 유익하다는 우리의 직관을 확인한다. 따라서 2T-HGNN은 개인화된 추천을 수행하기 위해 여러 콘텐츠 유형에서 암시적 및 명시적 신호를 활용한다. 우리의 모델은 HGNN과 2T 모델의 장점을 결합합니다. HGNN은 콘텐츠 및 사용자 선호도에 기초하여 포괄적인 장거리 아이템 표현을 생성하는 반면, 2T 모델은 추론 동안 낮은 대기 시간으로 모든 사용자에 대한 확장 가능한 추천 및 실시간 서빙을 가능하게 한다. 우리의 솔루션은 추천 태스크를 2T 모델을 통해 아이템-아이템 컴포넌트, HGNN을 통해 사용자-아이템 컴포넌트로 분리한다. 이러한 디커플링은 항목들 사이에서만 상당히 작고 다루기 쉬운 그래프로 이어지며, 이는 우리가 _co-listening graph_라고 부른다. HGNN과 2T의 공동 청취 그래프 및 조합은 이웃 노드들을 검색하고 집계하는 HGNN의 고유한 복잡성을 감소시키고(Hamilton et al., 2017; Wang et al., 2018; Wang et al., 2019; Wang et al., 2020; Wang et al., 2021) 확장성을 보장한다. 추천 시스템의 모듈성은 귀중한 유연성을 제공합니다. 이러한 모듈형 구성 요소는 스포티파이의 기존 모델에 원활하게 통합될 수 있습니다. 또한 이 분리를 통해 직접 사용자 노출이나 심각한 중단을 일으키지 않고 HGNN에 적응 및 변경할 수 있다.\n' +
      '\n' +
      '기존 제품(팟캐스트)을 활용하여 새로운 제품(오디오북)을 모델링하는 것은 상당한 이점을 제공하지만, 사용자 상호 작용에는 기존 콘텐츠 유형을 선호하는 고유한 불균형이 있다. 이 문제를 해결하기 위해, 우리는 다수의 에지 유형들을 언더샘플링함으로써 다수의 에지 유형들에 대한 HGNN 트레이닝을 최적화하는 균형 샘플러를 소개한다. 이 그래프 샘플러는 모든 콘텐츠 유형에 대한 표현을 효과적으로 캡처하고 훈련 시간을 약 60% 단축한다.\n' +
      '\n' +
      '그림 1은 우리의 모델과 데이터 집계를 개요로 보여준다. 팟캐스트 및 오디오북 스트리밍 사용자 상호 작용에 기초하여(도 1a 참조), 공동 청취 그래프를 구성한다(도 1b 참조). 이 그래프에서 노드는 오디오북과 팟캐스트를 나타내며 적어도 하나의 사용자가 둘 다 스트리밍할 때마다 에지에 의해 연결된다. 노드들은 오디오북들 및 팟캐스트 설명들로부터 LLM(Large Language Model)에 의해 추출된 특징들로부터 콘텐츠 신호들을 통합한다. 따라서, 2T-HGNN을 사용하여 우리는 자명하지 않은 장거리 의존성을 캡처하는 임베딩을 구축하고, 콘텐츠 및 사용자 선호도 둘 다에 기초하여 추천을 수행하고(도 1C 참조), 새로운(오디오북) 및 더 확립된(팟캐스트) 콘텐츠 유형으로부터 동시에 학습한다.\n' +
      '\n' +
      '요약하자면, 우리의 주요 기여는 다음과 같습니다.\n' +
      '\n' +
      '*우리가 아는 바로는, 우리의 것은 오디오북 추천 시스템의 설계를 규모별로 깊게 조사한 첫 번째 작업이다. 일반적으로 오디오북보다 짧고 대화가 많은 팟캐스트의 소비가 사용자 오디오북 선호도를 이해하는 데 효과적으로 도움이 될 수 있음을 보여준다.\n' +
      '* HGNN과 2T 모델을 하나의 스택으로 결합하여 기존의 추천 시스템 플랫폼에 오디오북 콘텐츠를 끊김없이 통합하는 모듈형 아키텍처를 제안한다. 우리는 그래프에서 사용자를 분리하고 공동 청취 그래프에서 콘텐츠 및 사용자 선호도를 학습한다. HGNN은 그래프 내의 항목들 간의 장거리, 미묘한 관계를 학습하고, 2T 모델은 콜드 스타트 사용자를 포함한 모든 사용자에 대한 오디오북에 대한 사용자 취향을 확장 가능한 방식으로 학습한다.\n' +
      '* 데이터 분포의 불균형을 다루기 위해 먼저 HGNN에 새로운 에지 샘플러를 통합한 다음 사용자-오디오북 예측을 생성할 때 사용자 표현에 약한 신호를 통합한다.\n' +
      '* 2T-HGNN의 효율성과 효과를 입증하는 광범위한 오프라인 실험을 수행하였다. 지속적으로 대체 방법을 능가합니다. 또한 수백만 명의 사용자가 참여하는 A/B 테스트를 사용한 검증 결과 오디오북 스트림 속도가 23% 크게 증가했다. 놀랍게도, 우리는 새로운 오디오북을 시작하는 사람들의 비율이 46% 급증하는 것을 관찰했다. 그 이후 그 모델은 프로덕션에서 모든 적격 오디오북 스포티파이 사용자에게 노출되었다.\n' +
      '\n' +
      '##2. 관련업무\n' +
      '\n' +
      '**Audiobooks recommendation.**Audibooks는 인쇄된 책 및 저자와 함께 "문학 생태학"의 일부이다(Wang et al., 2019). 그러나, 그들은 또한 라디오와 팟캐스트를 포함하는 "대화 오디오" 콘텐츠에 속한다. 톡 오디오 콘텐츠는 출퇴근, 직장, 집안일 등의 멀티태스킹 중에 소비되는 경우가 많다(Wang et al., 2019). 따라서 소비 습관의 측면에서 오디오북은 책보다 라디오, 팟캐스트, 심지어 음악과 더 많은 유사성을 공유한다. 그럼에도 불구하고 오디오북 소비가 다른 오디오 콘텐츠와 어떤 관련이 있는지는 현재 알려져 있지 않다. 여기에서 팟캐스트 소비를 이해하는 것이 오디오북 권장 사항에 도움이 되는지 여부와 그 반대의지를 연구한다.\n' +
      '\n' +
      '**전통적인 추천 시스템들.** 그러한 시스템들은 협업 필터링 접근법들에 기초하며, 이는 과거 사용자-아이템 상호작용들 사이의 유사성들을 캡처하는 것에 의존한다. 이러한 방법에는 행렬 인수분해, 인수분해 기계, 심층 신경망 등이 있다(Wang et al., 2019; Wang et al., 2019; Wang et al., 2020; Wang et al., 2021; Wang et al., 2021). 그러나 대부분의 협업 접근 방식은 데이터 희소성을 다룰 때 부족합니다. 를 포함하고,\n' +
      '\n' +
      '그림 1. A) 오디오북과 팟캐스트를 포함하는 사용자의 소비 패턴; B) 우리는 적어도 하나의 사용자가 둘 다 스트리밍할 때마다 오디오북 또는 팟캐스트를 나타내는 노드와 노드를 연결하는 에지를 가진 공동 청취 그래프를 구축하고; C) 2T-HGNN이 2홉 거리 패턴을 사용하여 사소하지 않은 추천을 수행하기 때문에 오디오북 _IT_가 추천된다. Delicious_는 _Taste_와 유사하다. _ Taste_는 _Fake Doctors_와 함께 공동 청취되며, _IT_와 함께 공동 청취된다.\n' +
      '\n' +
      '이 문제를 극복하고 콘텐츠 기능 및 추가 메타데이터가 권장 사항을 개선하는 데 성공했습니다.\n' +
      '\n' +
      '산업에서 대중적이고 널리 채택된 접근법은 2T 모델이다(Wang et al., 2018). 사용자 및 항목을 위해 별도의 심층 신경망 인코더를 사용하고 사용자 및 항목 기능을 통합합니다. 2T 모델은 산업 추천 시스템(예: Wang et al., 2018; Wang et al., 2018; Wang et al., 2018) 및 (Chen et al., 2018)에서 성공을 발견했다. 우리는 추론 시간에 확장성과 빠른 서빙 성능을 보장하기 위해 2T 아키텍처를 활용합니다.\n' +
      '\n' +
      '**그래프 기반 추천.** 온라인 콘텐츠 및 상호 작용 데이터에서 광범위하게 발견되는 그래프 데이터 구조는 전통적인 쌍별 레이블을 넘어 풍부한 정보를 제공한다(Chen et al., 2018). 그래프 기반 접근법은 추천 작업에 효과적인 것으로 입증되었으며, 특히 콜드-스타트 시나리오에서의 과제를 해결하고 추천을 다양화한다(Chen et al., 2018; Wang et al., 2018). 예를 들어, DeepWalk(Wang et al., 2018)은 소셜 네트워크에 대한 의미 있는 잠재 표현을 학습하기 위해 랜덤 워크를 사용하는 반면 TwHIN(Chen et al., 2018)은 소셜 미디어에 대한 추천을 생성하기 위해 이질적인 정보 네트워크를 사용한다. 그래프 구조를 학습하는데 효율적이지만, 이러한 기법들은 전달적 성질에 의해 제한되어 보이지 않는 노드들로 일반화할 수 없다(Chen et al., 2018; Wang et al., 2018).\n' +
      '\n' +
      '추천을 위한**GNNs.** 그래프 신경망(GNNs)의 표현력은 학술 분야(Wang et al., 2018; Wang et al., 2018; Wang et al., 2018) 및 산업 분야(Wang et al., 2018; Wang et al., 2018; Wang et al., 2018) 모두에서 그들의 응용으로부터 명백하다. 현재까지, 현재의 산업용 GNN 애플리케이션들(예를 들어, Chen et al., 2018; Wang et al., 2018; Wang et al., 2018)의 대부분은 노드들 및 에지들이 단일 유형인 균질한 그래프들에 초점을 맞춘다. 그러나 추천 시나리오에서는 다양한 항목 유형 또는 양식을 처리하는 것이 중요하므로 이질적인 GNN(HGNN)이 필요하다. 그러나, HGNN은 서로 다른 이웃 노드 유형이 노드 임베딩에 다양한 영향을 미치기 때문에 문제를 제기한다(Wang et al., 2018). 이러한 불균형은 더 미묘한 유형 인식 샘플링 및 집계 전략을 필요로 한다.\n' +
      '\n' +
      '(H)GNN의 성공은 이웃(맥락) 정보를 명시적으로 사용하는 데 있다. 그러나, 이들의 대규모 채택은 이웃 집계에 내재된 복잡한 데이터 의존성에 의해 제한된다. 확장성 및 지연 문제를 완화하기 위해 실무자들은 내용 전용 표현(Wang et al., 2018), 그래프 증류(Wang et al., 2018; Wang et al., 2018; Wang et al., 2018), 추론 속도가 부족(Wang et al., 2018; Wang et al., 2018) 및 이웃 샘플링(Chen et al., 2018)을 조사했다. 그럼에도 불구하고 이러한 방법의 대부분은 간혹 상당한 추가 엔지니어링 노력이 필요하며 종종 정확도와 성능 사이의 절충이 필요하다.\n' +
      '\n' +
      '본 연구는 HGNN에서 사용자를 분리하여 더 작은 k-홉 이웃 집합이 있는 더 마른 그래프를 필요로 하는 스포티파이에서 축척으로 배치된 모듈식 추천 시스템을 제시한다. 우리의 HGNN은 2T 모델과 쌍을 이루어 입증된 확장성과 운영 속도를 활용합니다. 또한, 다중 에지 타입과 노드 타입 사이의 불균형을 해결하기 위해 Hamilton_et al._(Hamilton et al., 2018)를 기반으로 하는 균형 이웃 샘플러를 설계한다.\n' +
      '\n' +
      '## 3. Data\n' +
      '\n' +
      '음악과 팟캐스트로 잘 알려진 스포티파이에 오디오북을 도입하면 어려움이 따른다. 오디오북은 처음에 직접 판매 전략 2를 사용하여 출시되었으며 사용자는 스트리밍되기 전에 오디오북을 구매해야 한다. 따라서 이것은 상호 작용 데이터의 보급을 심각하게 제한했다. 또한 대부분의 사용자는 이 신제품에 익숙하지 않아 상호 작용이 제한되고 더 인기 있는 오디오북에 대한 잠재적인 편향이 발생한다. 본 절에서는 스포티파이 플랫폼에서 초기 사용자 인터랙션 신호를 실증적으로 분석한다. 데이터 희소성의 정도를 연구하고 콘텐츠 또는 사용자 선호도 측면에서 오디오북과 팟캐스트 간의 유사성을 관찰하여 접근 방식에 동기를 부여한다.\n' +
      '\n' +
      '각주 2: 현재 오디오북은 선택된 국가에서 오디오북에 액세스할 수 있는 적격 프리미엄 가입자에 대해 이용 가능하다(Wang et al., 2018).\n' +
      '\n' +
      '우리는 800M 이상의 고유한 스트림으로 구성된 90일의 스트리밍 데이터를 분석한다. 초기 결과 오디오북 소비가 음악 소비보다 팟캐스트 소비와 더 유사한 것으로 나타났기 때문에 분석의 복잡성을 줄이기 위해 팟캐스트와 오디오북에만 초점을 맞춘다. 도 2a는 사용자들 및 오디오북 타이틀들 간의 스트리밍된 시간의 분포를 도시한다. 특히, 사용자의 약 25%가 전체 스트리밍 시간의 75%를 차지하며, 그래프는 상위 20%의 오디오북이 전체 스트리밍 시간의 80% 이상에 기여함을 보여준다.\n' +
      '\n' +
      '**관찰 1**.: _Audiobook 스트림은 대부분 파워 유저와 인기 타이틀에 의해 지배된다._\n' +
      '\n' +
      '초기 경험적 평가는 초기 오디오북 소비자의 70% 이상이 이전에 팟캐스트에 참여했음을 보여준다. 결과적으로 팟캐스트와의 사용자 상호 작용은 오디오북 사용자 선호도를 이해하는 데 귀중한 통찰력을 제공할 수 있다. 현재 제작 중인 Spotify 팟캐스트 모델을 사용하여 개별 팟캐스트 선호도를 반영하는 사용자 임베딩을 추출한다. 이로부터 적어도 하나의 스트리밍된 오디오북을 공유하는 사용자가 서로 다른 오디오북을 스트리밍한 사용자보다 더 큰 유사성을 보이는지 여부를 판단한다. 이를 조사하기 위해 사용자 표현의 10,000쌍(u,u^{\\prime})\\(u\\)을 무작위로 샘플링하여 적어도 하나의 오디오북(u^{\\prime}\\)을 스트리밍하였다. 그리고 10,000쌍(u^{\\prime\\prime},u^{\\prime\\prime\\prime})의 사용자 표현을 랜덤하게 결합한다. 도 2b에 도시된 바와 같이, 공유 오디오북 공동청취가 있는 사용자들 간의 코사인 유사도는 랜덤하게 결합된 사용자들보다 상당히 높은 수준의 유사성을 나타낸다.\n' +
      '\n' +
      '콘텐츠 정보는 또한 사용자 소비에 대한 힌트를 제공할 수 있다. 카탈로그 내의 각 오디오북에 대해, 텍스트 메타데이터(즉, 제목 및 설명)를 사용하여 다국어 Sentence-BERT(Wang et al., 2018)를 통해 저차원 표현을 생성한다. 그런 다음 각 쌍에 대해 적어도 한 명의 사용자가 오디오북을 모두 청취한 10,000쌍의 오디오북과 무작위로 페어링된 10,000쌍의 오디오북을 선택한다. 도 2c는 공동 청취된 오디오북 쌍이 랜덤하게 결합된 쌍보다 더 높은 수준의 유사성을 제시함을 보여주며, 추천 아키텍처에서 콘텐츠 메타데이터를 고려하는 것의 중요성을 강조한다.\n' +
      '\n' +
      '**관찰 2**.: _팟캐스트 사용자 취향 및 컨텐츠 정보는 사용자의 오디오북 소비 패턴을 추론하는데 유익하다._\n' +
      '\n' +
      '팟캐스트 상호작용은 오디오북에서 사용자 취향을 포착하는 데 도움이 되며, 공동 청취된 오디오북은 공동 청취되지 않은 오디오북보다 더 높은 유사성을 갖는다. 따라서 팟캐스트 공동청취가 오디오북 유사성의 신뢰할 수 있는 지표 역할을 할 수 있는가? 이 질문에 답하기 위해, 우리는 적어도 한 명의 사용자가 공동 청취할 때마다 연결된 오디오북과 팟캐스트 노드를 사용하여 공동 청취 그래프를 구축한다. 그런 다음 공유 팟캐스트 공동 청취를 통해서만 연결된 오디오북 10,000쌍을 무작위로 샘플링한다. 그림 2D는 공유 팟캐스트를 통해 연결된 실제로 샘플링된 오디오북이 현저하게 더 강한 유사성을 나타냄을 보여준다.\n' +
      '\n' +
      '관찰 3().: _오디오북과의 팟캐스트 상호작용에 대한 회계는 사용자 선호도를 더 잘 이해하기 위해 필수적이다._\n' +
      '\n' +
      '오디오북 상호 작용은 매우 희박합니다. 이러한 희소성은 두 가지 주요 요인에 기인할 수 있다. 첫째, 대부분의 사용자들은 새로운 콘텐츠 유형에 익숙하지 않다. 둘째로, 사용자들은 콘텐츠에 액세스하려고 시도할 때 페이월을 접하게 되고, 따라서 스트림에 대한 더 높은 장벽을 제공한다. 이것은 또한 팟캐스트가 사용자가 자유롭게 액세스할 수 있기 때문에 콘텐츠 유형 간의 소비 신호의 불균형을 증가시킨다.\n' +
      '\n' +
      '사용자는 주로 홈 및 검색 페이지에서 플랫폼에서 오디오북과 상호 작용한다. 일단 사용자가 관심있는 오디오북을 선택하면, 그들은 웹페이지를 방문하고 아마도 후속(업데이트), 미리보기(즉, 30대 샘플 재생) 또는 지불 의도(즉, 완성된 구매 프로세스 없이 구매 상호작용)를 나타낸다. 우리는 이러한 수집된 신호를 약 신호_라고 한다.\n' +
      '\n' +
      '여기에서 이러한 상호 작용이 미래의 오디오북 구매 및 소비를 알릴 수 있는지 여부를 조사한다. 우리는 1억 8천 8백만 개 이상의 상호 작용을 분석하고 과거의 약한 신호로부터 미래의 사용자 스트림을 예측한다. 각 신호 유형에 대해 하나씩 다중 로지스틱 회귀를 사용합니다. 결과는 "후속" 신호의 더 높은 발생이 새로운 스트림을 시작할 확률을 유의하게 증가시키는 반면(+118%), "지불 의도"(+13%) 및 "미리보기"(+18%) 신호도 스트림 시작과 긍정적인 관련이 있음을 나타낸다. 약한 신호에 대한 보다 자세한 결과는 독자를 부록 A에 참조한다.\n' +
      '\n' +
      '관찰 4().: _ 약한 신호를 우리 모델에 통합하는 것은 미래의 스트림을 예측할 수 있고 미묘한 사용자 선호도 및 의도를 밝혀낼 수 있다._\n' +
      '\n' +
      '## 4. Model\n' +
      '\n' +
      '오디오북 추천을 위한 모듈형 및 효율적인 아키텍처인 2T-HGNN을 소개한다. HGNN과 2T 모델로 구성된 본질적으로 모듈식이다. 이러한 모듈성은 2T-HGNN이 홈 및 검색 페이지와 같은 다양한 컨텍스트에 배치된 모델에 적합한 임베딩을 생성하는 고성능, 효율성 및 유연성을 포함하여 섹션 1에 요약된 바와 같이 스포티파이의 기술적 요구 사항을 충족하도록 보장한다.\n' +
      '\n' +
      '2T-HGNN은 HGNN 모델과 오디오북 상호 작용 희소성을 다루며, 이는 희소 데이터에서 고차 항목 관계를 포착하기에 적합하다. 우리의 모델은 사용자가 둘 다 스트리밍할 때마다 콘텐츠 유형을 연결하는 공동 청취 그래프에 기반한다. 이 그래프는 팟캐스트와 콘텐츠 정보를 모두 포함하고 팟캐스트와 오디오북 사이뿐만 아니라 팟캐스트 간의 공동 청취 상호작용을 통합한다.\n' +
      '\n' +
      '2T는 수백만 명의 사용자에게 추천을 제공하기 위해 HGNN에 의해 생성된 오디오북 및 팟캐스트 표현을 기반으로 한다. HGNN과 2T는 각각 항목 중심 및 사용자 중심 구성요소로 볼 수 있으며, 스케일에서 사용자 취향 표현 학습을 달성하기 위해 함께 작동한다. 또한 2T는 약한 신호를 활용하여 명시적인 상호 작용(오디오북 스트림)의 희소성을 추가로 설명하여 권장 사항의 품질을 향상시킨다. 2T-HGNN의 시각적 설명은 그림 3을 참조한다.\n' +
      '\n' +
      '### 이기종 그래프 신경망\n' +
      '\n' +
      'HGNN은 그래프 상에 표현된 다수의 데이터 엔티티들 및 관계들에 대한 포괄적인 이해를 가능하게 한다. 그럼에도 불구하고, 그래프 내에서 콘텐츠 및 사용자 선호도를 표현하는 여러 가지 방법이 있다. 우리의 접근 방식은 콘텐츠 및 사용자 선호도에 대한 공동 청취 그래프를 사용하며, 여기서 사용자는 노드로 명시적으로 취급되지 않는다. 이 디커플링은 잠재적으로 방대한 사용자 기반을 포함하는 HGNN 이웃 집합(헨들, 2017)과 관련된 문제를 우회하는 데 도움이 된다. 이 접근 방식은 플랫폼의 확장성과 효율성을 보장하여 수백만 개의 항목과 사용자 상호 작용으로부터 콘텐츠 표현을 학습할 수 있다.\n' +
      '\n' +
      '그래프 구축 4.1.1\n' +
      '\n' +
      '카탈로그 항목 \\(c\\in\\mathcal{C}\\)(즉, 오디오북과 팟캐스트)가 노드를 구성하는 공동 청취 그래프를 구축한다. 두 항목 사이의 edge\\((c^{(i)},c^{(j)})\\in\\mathcal{E}\\)는 두 항목과 상호작용하는 사용자가 적어도 한 명이면 포함된다. 이질 그래프에서 각 노드는 특정 노드 유형\\(s\\in\\mathcal{S}=\\{a,p\\}\\), 즉 오디오북 및 팟캐스트 유형과 연관된다. 또한, 노드를 노드 유형에 매핑하는 함수\\(\\phi:\\mathcal{C}\\rightarrow\\mathcal{S}\\)와 노드를 연결하는 에지\\(\\epsilon=(c,c^{\\prime})\\(c^{\\prime})의 서로 다른 관계를 매핑하는 함수\\(\\phi:\\mathcal{C}\\rightarrow\\mathcal{S}\\)을 정의한다. 3절(관찰 2, 3)의 결과에 따라 우리는 유형 \\(r\\in\\mathcal{R}=\\{(a,a), (a,p), (p,p)\\}\\), 즉 오디오북-오디오북의 관계만을 고려한다.\n' +
      '\n' +
      '그림 2. A) 출시 시 오디오북 소비는 매우 희박하다. 사용자의 25%가 전체 스트리밍 시간의 75%를 차지한다. B) 오디오북 취향이 유사한 사용자는 랜덤으로 선택한 사용자보다 팟캐스트 선호도가 더 유사하다. C) 적어도 하나의 사용자에 의해 공동 청취된 오디오북은 유사한 콘텐츠 임베딩(오디오북의 제목 및 설명으로부터 추출된 LIM 임베딩)을 갖는다. D) 동일한 팟캐스트로 공동 청취되었지만 서로가 아닌 두 오디오북은 유사한 콘텐츠 임베딩을 갖는다.\n' +
      '\n' +
      '오디오북-팟캐스트 및 팟캐스트-팟캐스트 연결. 두 가지 콘텐츠 유형과 서로 다른 유형의 관계를 포함함으로써 오디오북과의 사용자 상호 작용이 드문 경우에도 팟캐스트와 오디오북 간의 잠재 연결을 포착하는 것을 목표로 한다.\n' +
      '\n' +
      '카탈로그 내용에 대한 이해를 높이기 위해 LLM 임베딩을 통해 노드 기능을 통합한다. 카탈로그 및 다국어 Sentence-BERT 모델(Zhou et al., 2017)의 모든 팟캐스트 및 오디오북의 제목 및 설명을 사용하여 이러한 임베딩을 생성하는데(도 3A 참조), 이는 오디오북 및 팟캐스트의 콘텐츠의 저차원 표현으로 볼 수 있다. HGNN은 콘텐츠 및 사용자 선호도에 대한 정보를 포함하는 이 그래프에서 카탈로그 항목 내의 복잡한 패턴을 학습한다.\n' +
      '\n' +
      '2. 이기종 GNN 설계 및 훈련\n' +
      '\n' +
      'HGNN 모델은 GNN 메시지 전달 패러다임에 기초한다(Zhou et al., 2017; Li et al., 2018; Li et al., 2019; Li et al., 2018). node \\(c\\)에 대한 이기종 메시지 통과는 다음과 같이 정의된다:\n' +
      '\n' +
      '\\leftarrow\\text{AGGREGATE}_{r}^{k}(\\{\\mathbf{h}_{c}^{k-1}, \\forall c^{\\prime}\\in\\mathcal{N}(c,r)\\})\\tag{1b}\\\\mathbf{h}_{c}^{k}\\leftarrow\\text{UPDATE}^{k}(\\mathbf{h}_{c}^{k-1},\\{\\mathbf{h}_{h}_{c}^{k}\\forall r})\\tag{1a}\\forall c^{\\prime}\\in\\mathcal{N}(c,r)\\forall c^{n}(c,r)\\forall c^{n}(c,r)\\forall c^{n}(c,r)\\forall\n' +
      '\n' +
      '여기서 \\(k\\)은 \\(l\\)-층의 층인 HGNN, UPDATE 및 AGREGATE는 \\(c\\)의 이웃 \\(\\mathcal{N}(c,r)\\)에 기초하여 미분가능한 함수이다. 이웃은 시드 노드(c\\(r\\), 즉 (c,c^{\\prime})\\in\\mathcal{E}\\) 및 (\\langle\\phi(c),\\phi(c^{\\prime})\\rangle=r\\)의 관계를 통해 시드 노드(c\\(c\\)와 연결된 모든 노드(c^{\\prime}\\)로 정의된다. 식 (1a) 및 식 (1b)에서, \\(\\mathbf{h}_{c}^{k}=x_{c}\\) 즉, 노드 특징들이다. 노드 임베딩은 학습을 보다 안정적으로 하고 효율적인 근사 최근접 이웃 탐색을 가능하게 하기 위해 정규화된다. \\(\\mathbf{z}_{c}=\\mathbff{h}_{c}^{l}/||\\mathbff{h}_{c}^{l}||\\)(4.3절 참조). \\(l\\)-계층 HGNN을 사용하면 최대\\(l\\)-홉 거리 노드에서 학습할 수 있다(그림 3 참조).\n' +
      '\n' +
      '구체적으로, 본 논문의 구현은 GraphSAGE (Zhou et al., 2017)를 기반으로 하며, AGREGATE와 UPDATE 연산자는 미분 가능하고 가중치 행렬 \\(\\mathbf{W}\\)로 매개변수화된다. 그러나 원래 논문과는 달리 여기서는 이러한 연산자를 이질적인 경우로 일반화한다. 구체적으로, 우리는:\n' +
      '\n' +
      '\\text{AGGREGATE}_{r}^{k} =\\max\\left(\\sigma\\left(\\mathbf{w}_{r}\\mathbf{h}_{c^{\\prime}}^{k-1}+\\mathbf{b}\\right),\\forall c^{\\prime}\\in\\mathcal{N}(c,r\\}\\right)\\tag{3}\\text{UPDATE}_{c}^{c}^{c}^{h}_{c}^{c}^{n}(c,r}}^{k}\\right),\\tag{2}\\text{UPDATE}_{c}^{c}^{c}^{h}{c}^{c}^{c}^{c}^{k}\\mathbf{h}^{c}^{n}(c,r}}^{k}\\right),\\tag{2}\\text{UPDATE}_{c}^{c}^{h}{c}^{\n' +
      '\n' +
      '여기서 \\(\\sigma\\)는 비선형 활성화 함수이고 AGREGATE 연산자는 본질적으로 신경망을 통해 변환된 모든 이웃 임베딩에 걸쳐 풀링 연산이다.\n' +
      '\n' +
      'GraphSAGE는 \\(\\mathcal{N}(c,r)\\)을 \\(\\{c\\in\\mathcal{C}:(c,v)\\in\\mathcal{E}\\}\\}\\)으로부터 고정된 크기의 균일하게 샘플링된 이웃으로 정의하며, 각 트레이닝 반복에서 샘플링된 이웃은 서로 다른 균일한 샘플로 구성된다. 이러한 샘플링은 단일 배치의 메모리 및 예상 런타임이 사용자-정의 하이퍼파라미터들(즉, 샘플링된 노드들의 수)에 의해 제한되는 것을 보장한다(Zhou et al., 2017).\n' +
      '\n' +
      'HGNN에서, 메시지 통과 및 역전파 단계들은 다수의 에포크들에 대해 반복되어, 모든 파라미터들이 트레이닝 손실에 따라 조정될 수 있다. 특히, 앵커와 양의 샘플(즉, 그래프에서 연결된 노드) 사이의 내부 곱을 최대화하는 대조 손실을 통해 HGNN을 최적화하는 동시에 앵커와 음의 샘플 사이의 내부 곱을 최소화한다. 여기서, 네거티브 샘플들은 에지에 의해 앵커와 연결되지 않은 노드들에 의해 구성된다. 연결된 노드 HGNN 임베딩과 랜덤 샘플 부정형 임베딩의 쌍을 선택할 때마다 그래프의 모든 에지를 탐색하고, 이를 최소화한다.\n' +
      '\n' +
      '\\mathcal{L}_{HGNN}(z_{a},\\mathbf{z}_{p})=\\mathbb{E}_{n-C}\\max\\{0,\\mathbf{z}_{a}\\cdot\\mathbf{z}_{n}-\\mathbf{z}_{a}\\cdot\\mathbf{z}_{z}_{p}+\\Delta\\}\\tag{4}\\mathbb{E}_{n-C}\\max\\{0,\\mathbf{z}_{a}\\cdot\\mathbf{z}_{n}-\\mathbf{z}_{a}\\cdot\\mathbf{z}_{p}+\\Delta\\}\\tag{4}\\mathbb{E}_{n-C}\\max\\{0,\\mathbf{z}_{n}-\\mathbf{z}_{a}\\cdot\\mathbf{z}_{p}+\\Del\n' +
      '\n' +
      '여기서 \\(\\Delta\\)는 마진 하이퍼-파라미터를 나타낸다. 모든 노드들은 그들의 \\(l\\)-홉 샘플링된 이웃들과 함께 샘플링된다(Hamilton et al. (2017)).\n' +
      '\n' +
      '###### 4.1.3. 균형 잡힌 다중 링크 이웃 샘플러\n' +
      '\n' +
      '우리의 공동 청취 그래프는 오디오북-오디오북 연결에 비해 팟캐스트-팟캐스트 및 오디오북-팟캐스트 가장자리가 풍부한 것을 특징으로 하는 상당한 불균형을 나타낸다. 최적화 과정에서 이러한 불균형을 고려하지 않으면 HGNN이 고품질 오디오북 임베딩을 생성하는 것과 같은 주요 작업에서 멀어질 수 있다.\n' +
      '\n' +
      '이러한 불균형을 해결하기 위해, 우리는 식 (4)에 의해 최소화된 에지 타입들의 수에 균형을 가져오는 _multi-link neighborhood sampler_를 설계하였다. 그래프에 포함된 대부분의 에지 유형의 수를 줄임으로써 그렇게 한다. 예를 들어, \\(N\\)audiobook-audiobook과 \\(M\\)audiobook-podcast 에지를 포함하는 원래 그래프에서 다중 링크 이웃 샘플러는 \\(N\\)audiobook-audiobook 연결과 \\(N\\)audiobook-podcast만을 선택한다.\n' +
      '\n' +
      '도 3. 우리 모델의 개요. A) 우리는 적어도 한 명의 사용자가 둘 다 들을 때마다 서로 연결된 두 개의 노드 유형인 오디오북과 팟캐스트를 포함하는 이종 그래프를 사용하여 오디오북-팟캐스트 관계를 나타낸다. 각 노드는 오디오북 및 팟캐스트의 제목 및 설명으로부터 추출된 LLM 임베딩 특징을 갖는다. 우리는 이 그래프 위에 2층 HGNN을 사용한다. B) 우리의 2T 모델은 HGNN 임베딩, 사용자 인구통계학적 특징(예: 국가 및 연령), 그리고 임베딩으로 표현된 역사적 사용자 상호작용(음악, 팟캐스트 및 오디오북)을 활용하여 사용자에게 오디오북을 추천한다.\n' +
      '\n' +
      '연결 샘플러는 여러 에지 유형을 동시에 언더샘플링하고 훈련 동안 데이터 세트 커버리지를 최대화하기 위해 각 에폭에서 서로 다른 균일한 샘플을 그린다.\n' +
      '\n' +
      '이 접근법은 향상된 성능을 가져오고 더 의미 있는 임베딩을 생성한다. 또한, 이 샘플링 전략은 각 훈련 에폭에 대해 예측 가능한 예상 런타임을 보장하며, 이는 \\(|\\mathcal{E}|)\\의 최악의 시나리오로 크게 확장될 것이다. 특히, 우리의 사용 사례에서, 공동 청취된 팟캐스트의 수는 필연적으로 오디오북 표현에 대한 제한된 혜택과 함께 훈련 과정과 융합을 지배할 것이다.\n' +
      '\n' +
      '### Two Tower\n' +
      '\n' +
      '2T-HGNN은 2T 모델을 사용하여 HGNN 오디오북 및 팟캐스트 표현으로부터 사용자 취향 및 새로운 오디오북 벡터를 구축한다. 2T 모델은 두 개의 피드-포워드 딥 뉴럴 네트워크(타워)로 구성되며, 하나는 사용자를 위한 것이고 하나는 오디오북을 위한 것이다(도 3b 참조). 사용자 타워는 사용자 인구 통계 정보뿐만 아니라 음악, 오디오북 및 팟캐스트와의 사용자의 역사적 상호 작용을 입력으로 한다. 특히, 음악과의 상호작용은 스포티파이에 의해 사내에서 미리 계산된 벡터로 표현된다. 구체적으로, 오디오북과 팟캐스트 상호작용은 사용자가 최근 90일 동안 상호작용한 콘텐츠에 해당하는 오디오북과 팟캐스트 HGNN 임베딩(\\(\\bar{\\mathbf{z}}_{a}\\) 및\\(\\bar{\\mathbf{z}}_{p}\\)의 평균으로 표현된다. 섹션 3의 관찰 4에 이어 다음과 같은 스트림과 약한 신호, 미리보기를 모두 사용한다. 오디오북 타워는 오디오북의 HGNN 임베딩 \\(\\mathbf{z}_{a}\\)뿐만 아니라 언어와 장르, 제목과 설명으로부터 LLM 임베딩과 같은 오디오북 메타 데이터를 사용한다.\n' +
      '\n' +
      '2T 모델은 사용자와 오디오북에 대해 각각 두 개의 출력 벡터 \\(\\mathbf{o}_{u}\\)와 \\(\\mathbf{o}_{a}\\)을 생성한다. 그런 다음 다음 손실을 최소화하여 사용자 벡터가 청취한 오디오북 벡터와 가깝고 다른 오디오북 샘플과 멀리 떨어져 있도록 권장한다.\n' +
      '\n' +
      '\\mathcal{L}_{2T}(\\mathbf{o}_{a},\\mathbf{o}_{u})=\\mathbb{E}_{n-\\mathcal{B}} \\left[\\mathbf{o}_{u}\\cdot\\mathbf{o}_{n}-\\mathbf{o}_{u}\\cdot\\mathbf{o}_{a}\\right], \\tag{5}\\w}\n' +
      '\n' +
      '여기서 \\(\\mathcal{B}\\)는 회분식 음성 오디오북 샘플이다. 우리는 인기 음수를 과도하게 샘플링하는 것을 방지하기 위해 학습 데이터 세트에서 항목이 발생할 확률에 반비례하여 손실을 가중한다.\n' +
      '\n' +
      '### 2T-HGNN Recommendations\n' +
      '\n' +
      '2T-HGNN은 일일 사용자와 오디오북 벡터를 생성하며, 여기서 오디오북 벡터 \\(\\mathbf{o}_{u}\\)는 추천될 사용자와의 내적 거리가 가깝다. 매일, 우리는 먼저 HGNN 모델을 트레이닝하고, 트레이닝을 위해 결과 팟캐스트 및 오디오북 임베딩을 2T 모델에 전달한다. 2T 모델이 학습되면 카탈로그에서 오디오북에 대한 벡터를 생성하고 온라인 서빙을 위한 최근접 이웃(NN) 인덱스를 구축한다. 사용된 오디오북의 수가 상대적으로 적기 때문에, 우리는 색인에서 후보를 검색하기 위해 무차별 강제 검색을 사용한다. 카탈로그가 증가하는 즉시 근사 k-NN 인덱스(Bang et al., 2019)를 사용하여 후보들을 보다 효율적으로 질의할 것이다. 서빙 시간에 사용자 특징을 사용자 타워에 전달하고 k-NN 인덱스에 질의하여 추천 대상 오디오북 후보를 검색함으로써 실시간으로 사용자 벡터를 생성한다. 이것은 우리가 실시간으로 사용자 임베딩을 업데이트하는 것을 방해하지 않는다는 점에 유의한다. 아이템 벡터는 미리 구축되어 인덱스에 삽입된 반면, 사용자 벡터는 실시간으로 생성되어 새로운 콜드스타트 사용자에게 반응성이 높다. 레이턴시는 100ms보다 작게 보장된다.\n' +
      '\n' +
      '우리의 HGNN은 귀납적 추론을 수행할 수 있으며(Han et al., 2017), 이는 훈련 공동 청취 그래프에서 나타나지 않는 오디오북에 대한 임베딩을 생성할 수 있음을 의미한다. 예를 들어, 스트리밍되지 않은 오디오북에 대한 임베딩은 LLM 기능만으로 생성될 수 있다. 또한, 2T-HGNN의 모듈성을 통해 2T 모델 훈련과 다른 종지에서 HGNN을 훈련할 수 있다. 예를 들어, 훈련 비용을 절약하기 위해 일주일에 한 번 HGNN을 훈련할 수 있지만 사용자 표현을 신선하게 유지하기 위해 매일 2T 모델을 훈련할 수 있다. 우리는 이 탐사와 그것이 성능에 미치는 영향을 향후 조사에 맡긴다.\n' +
      '\n' +
      '구현 세부사항####4.3.1. 구현 세부사항\n' +
      '\n' +
      'HGNN 모델은 두 개의 레이어를 가지며 GraphSAGE(Han et al., 2017)를 기반으로 한다. 이들은 PyTorch에서 구현되고 Adam(Kingma and Ba, 2014)을 사용하여 최적화된다. 우리는 PyTorch Geometric (Chen et al., 2017)을 사용하여 단일 NVIDIA T4 GPU에서 배치 크기 256, 학습률 0.001의 모든 모델을 훈련한다. 교육에는 조기 중단 기준을 가진 최대 50개의 시대가 포함되었다. 우리는 검증 세트를 기반으로 가장 성능이 좋은 모델을 저장했고 개선 없이 10개의 연속적인 에폭 후에 훈련을 중단했다.\n' +
      '\n' +
      '텐서플로우에서 구현된 2T 모델은 Adam(Kingma and Ba, 2014)과 배치 크기 128과 학습률 0.001을 활용하였다. 각 타워는 512, 256, 128 크기의 3개의 완전히 연결된 층으로 구성되며, 인텔 16 vCPU와 128GB 메모리가 있는 단일 기계에서 교육이 이루어졌다. 그 모델은 10년 동안 훈련되었다. GNN 임베딩 이외의, 사용자 타워는 임베딩의 리스트로서 표현되는 상호작용 특징(오디오북, 팟캐스트, 아티스트)뿐만 아니라 인구통계학적 특징(연령 및 국가)을 사용한다. 오디오북 타워는 Sentence-BERT(Han et al., 2017)로부터 제목 및 설명의 메타데이터 특징(즉, 언어 및 BISAC 장르 코드) 및 LLM 임베딩을 사용한다. 각 탑의 출력은 128차원 벡터이다.\n' +
      '\n' +
      '## 5. 실험 및 결과\n' +
      '\n' +
      '오프라인 메트릭과 온라인 A/B 테스트를 모두 사용하여 모델 성능을 평가하며, 오디오북 권장 사항이 플랫폼의 실제 사용자에게 노출된다.\n' +
      '\n' +
      '### 오프라인 평가 설정\n' +
      '\n' +
      '#### 5.1.1. Data\n' +
      '\n' +
      '오프라인 평가를 위해 지난 90일 동안 팟캐스트 및 오디오북과의 사용자 상호 작용을 수집하여 구축한 대규모 데이터 세트를 사용한다. 데이터 세트는 10M 사용자, 3.5M+ 팟캐스트 및 250K+ 오디오북의 하위 집합으로 구성된다. 이 평가는 지난 14일 동안 사용자의 모든 오디오북 및 팟캐스트 스트림을 포함하는 보류 데이터 세트에 대해 수행된다. 따라서, 우리는 사용자 액션들이 14일의 시간 윈도우로 단일 시점 분할로 분할되는 글로벌 타임라인 트레인/홀드-아웃 분할 스킴의 금-표준(Kang et al., 2017)에 따라 데이터를 분할한다. 열차 분할 데이터는 열차의 10%를 구성하는 HGNN-열차 및 HGNN-검증 세트에서 추가로 분할되었다. HGNN 훈련에는 조기 중지 기준이 있는 최대 50개의 시대가 포함되었다. 우리는 검증 세트를 기반으로 가장 성능이 좋은 모델을 저장했고 개선 없이 10개의 연속적인 에폭 후에 훈련을 중단했다.\n' +
      '\n' +
      '###### 5.1.2. 평가 메트릭\n' +
      '\n' +
      'HitRate@K(HR@K)의 3가지 표준 메트릭을 통해 추천 태스크의 성능을 평가하는데, 이 표준 메트릭은 \\(K=10\\), 평균 상호 순위(MRR) 및 카탈로그 커버리지이다. 자세한 내용은 부록 A를 참고한다.\n' +
      '\n' +
      '#### 5.1.3. Baselines\n' +
      '\n' +
      '우리는 오디오북 권장 사항에 대한 제안을 평가하여 세 가지 다른 기준선과 비교한다. 먼저, 사용자, 팟캐스트 및 오디오북 노드로 구성된 3자 그래프를 기반으로 HGNN을 사용한다. 각 모서리는 사용자가 스트리밍할 때마다 팟캐스트 또는 오디오북과 연결합니다. 우리는 이 모델을 HGNN-w-사용자라고 한다. 다음으로, 섹션 4.1에 따라 공동 청취 그래프를 사용하여 HGNN을 훈련한다. 이 모델은 오디오북과 사전 상호 작용을 하는 사용자를 의미하는 웜스타트 사용자에게만 오디오북을 추천할 수 있음을 유의한다. 마지막으로, 사용자 및 오디오북 타워를 사용하여 권장 사항을 생성하는 2T 모델을 평가한다. 우리는 k-NN 인덱스를 통해 사용자 아이템 예측을 한다. 또한 두 가지 간단한 기준인 Popularity(Beng et al., 2019)와 LLM-KNN에 대한 테스트를 수행한다. 전자는 지난 90일 이내에 카탈로그에서 가장 인기 있는 항목을 선택하는 반면, 후자는 지난 90일 동안 사용자가 상호작용한 오디오북 벡터(스트림 + 약한 링크)를 평균하여 사용자 표현을 구성한다.\n' +
      '\n' +
      '### Offline Results\n' +
      '\n' +
      '#### 5.2.1. Ablation\n' +
      '\n' +
      '우리는 개별 구성요소의 영향을 평가하기 위해 제안된 2T-HGNN 모델에 대한 절제 연구를 수행한다.\n' +
      '\n' +
      '먼저 균형 잡힌 다중 링크 이웃 샘플러를 제거하면 HR@10이 6% 감소한다(표 1A 참조). 보도의 증가는 추천이 더 많은 오디오북에 걸쳐 있음을 시사하지만 사용자에게 가장 관련성이 높은 콘텐츠를 추천하는 문제에 직면해 있다.\n' +
      '\n' +
      '둘째, 2T-HGNN 훈련과 추론에서 약한 신호를 제거하였다. 표 1B는 취약한 링크가 효과적인 오디오북 권장 사항에 중요하다는 것을 보여준다. HR@10 성능이 크게 감소할 뿐만 아니라 커버리지도 감소하여 섹션 3(관찰 4)에서 우리의 가정을 확인한다.\n' +
      '\n' +
      '그런 다음 표 1C-D는 고품질 권장 사항을 전달하기 위한 공동 청취 그래프에서 에지 유형의 중요성을 강조한다. 팟캐스트-팟캐스트 에지를 생략하면 HR@10이 6% 감소한다. 특히, 표 1D는 오디오북 오디오북 공동 청취 에지를 제거하면 HR@10이 11% 감소하고 커버리지가 57% 감소하는 상당한 열화를 초래한다는 것을 보여준다.\n' +
      '\n' +
      '마지막으로, 동질 그래프에만 의존하면 성능이 크게 감소한다는 것을 보여준다 (표 1E-F). 특히, 표 1F에서 우리는 포드캐스트와 포드캐스트 연결로만 구성된 동질 그래프에서 HGNN 모델을 학습하고 추론 시간에는 포드캐스트와 동일한 잠재 공간에 있는 오디오북 LLM 특징을 사용하여 모든 HGNN 임베딩을 유도적으로 예측한 다음, 2T-HGNN 모델을 학습하기 위해 사용되는 HR@10 x 16%, MRR x 12%, Coverage x 52%의 현저한 감소를 얻으며, 이러한 결과는 i) 이질적인 콘텐츠를 모델링하는 것이 필수적이라는 것을 강조한다. 두 콘텐츠 유형은 유사성을 공유하지만 사용자 선호도가 다릅니다.\n' +
      '\n' +
      '오디오북 추천은 5.2.2.2\n' +
      '\n' +
      '우리는 Table 2와 Table 3에서 웜스타트와 콜드스타트 사용자를 위한 오디오북 추천의 성능을 비교한다. 전자는 스트리밍, 미리보기, 지불 의도를 나타내거나 오디오북을 따르는 사용자이고 후자는 이전에 오디오북과 상호작용한 적이 없는 사용자이다.\n' +
      '\n' +
      '표 2는 오디오북과 적어도 한 번 상호작용한 사용자에 대한 정량적 평가를 보여준다. 인기 기준선은 제3절(관찰 1)에서 관찰된 인기 편향 문제를 강조하면서 꽤 잘 수행된다. LLM-KNN은 커버리지와 MRR에서 탁월하며 내용 기반 추천(즉, 오디오북 설명의 유사성을 통한)이 오디오북 추천에서 필수적임을 보여준다. 그러나 이 방법은 처음 10개 항목(HR@10은 0.164)에서 관련(개인화된) 콘텐츠를 제안하기 어렵다. 대조적으로, HGNN 모델은 LLM-KNN에 비해 HR 및 MRR을 각각 57% 및 10% 개선하며 커버리지(-3%)의 한계 감소만 있다. 이 결과는 HGNN이 사용자 선호도에서 미묘한 뉘앙스를 포착하는 데 능숙하며, 이는 공동 청취 간선이 효과적으로 포착할 수 있음을 시사한다. 따라서, 콘텐츠 및 사용자 선호도 모두를 동시에 모델링하는 것이 필수적이다.\n' +
      '\n' +
      'LLM-KNN을 능가했음에도 불구하고 HGNN-w-사용자는 MRR 및 커버리지에서 차선의 성능을 나타내며 HGNN 결과에서 각각 30% 및 53% 감소했다. 이러한 성능 감소는 사용자 그래프의 희소성이 높기 때문일 수 있으며, 이는 상당수의 비연결 구성 요소와 공동 청취 그래프보다 낮은 평균 정도를 특징으로 한다.\n' +
      '\n' +
      '다음으로, 모든 메트릭에서 HGNN-w-사용자 및 HGNN보다 더 나쁜 성능을 보이는 2T 모델을 비교한다. 그러나 학습 시간이 상당히 적고 추론 지연 시간이 낮아 온라인 성과와 평가 메트릭 간의 상충 관계에서 경쟁적 선택으로 포지셔닝해야 한다.\n' +
      '\n' +
      '따라서, 제안된 2T-HGNN 방법은 HR@10에서 모든 모델보다 성능이 우수하여 최상의 기준선을 36% 개선한다. MRR과 Coverage는 HGNN과 일치하지 않지만, HGNN 모델의 추천 성능과 2T-HGNN의 추론 속도의 균형을 이루어 실시간 추천에서 수백만 명의 사용자에게 서비스를 제공하기에 완벽한 후보가 된다. 특히, 이 모델은 HR@10, MRR 및 Coverage에서 각각 52%, 26% 및 5%의 2T 성능을 개선한다.\n' +
      '\n' +
      '또한 오디오북을 5개의 인기 계층으로 분류하여 롱테일 권장 사항에 대한 2T-HGNN 개선을 평가한다. 덜 인기 있는 콘텐츠를 나타내는 3, 4, 5단을 긴 꼬리로 간주한다. 결과는 HR@10 및 MRR이 커버리지를 희생하지 않고 각각 118% 및 102% 증가하는 2T-HGNN의 상당한 개선을 보여준다.\n' +
      '\n' +
      '표 3은 콜드 스타트 오디오북 권장 사항에 대한 HR@10 및 MRR에서 우리의 발견의 일관성을 확인한다. 이 표는 인기 기준선이 HR@10에서 2T 모델을 놀라울 정도로 능가함에 따라 인기 편향 문제가 악화됨을 보여준다: 가장 인기 있는 10개의 오디오북은 처음에 스트리밍된 오디오북에 대한 주요 선택으로 종종 사용자에 의해 픽업된다(도 2A 참조). 2T+GNN의 조합은 2T 모델에서 48%% 개선되는 높은 성능을 계속 나타낸다. 그러나, 상당한 대조는\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r r} \\hline \\hline \\multirow{2}{*}{**Model**} & \\multicolumn{4}{c}{**Warmstart users**} \\\\ \\cline{2-4}  & HR@10 \\(\\uparrow\\) & MRR \\(\\uparrow\\) & Coverage \\(\\uparrow\\) \\\\ \\hline\n' +
      '2T-HGNN & 0.353 & 0.218 & 22.3\\% \\\\ \\hline A) 2T-HGNN w/o multi-edge opt. & 0.332 & 0.214 & 24.1\\% \\\\ B) 2T-HGNN w/o weak signals & 0.267 & 0.182 & 17\\% \\\\ C) 2T-HGNN w/o PC-PC & 0.333 & 0.210 & 22.3\\% \\\\ D) 2T-HGNN w/o AB-AB & 0.312 & 0.198 & 9.4\\% \\\\ E) 2T-GNN (AB-AB only) & 0.329 & 0.201 & 22.1\\% \\\\ F) 2T-GNN (PC-PC only) & 0.294 & 0.192 & 10.6\\% \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1. 우리 모델의 절제 연구.\n' +
      '\n' +
      '커버리지 측면에서 모델 간에 등장합니다. HGNN-w-사용자는 6.4%의 적용 범위를 달성하여 권장 사항이 카탈로그의 작은 하위 집합으로 제한됨을 나타낸다. 2T-HGNN은 이 커버리지를 거의 12.0%로 두 배 증가시켰지만, 이와 관련하여 60% 더 나은 성능을 보이는 2T 모델에 의해 능가된다. 즉, 2T-HGNN은 정확하고 정확한 예측을 수행하는 데 탁월하지만 권장 사항은 카탈로그의 더 좁은 하위 집합으로 제한된다. 우리는 현재 이 thade-off를 주요 이슈로 간주하지 않고, 결국 미래에 다시 고려해야 할 것으로 간주한다.\n' +
      '\n' +
      '팟캐스트 추천 5.2.3\n' +
      '\n' +
      '단일 그래프 내에서 오디오북과 팟캐스트의 표현을 통합하면 콘텐츠 유사성을 배우고 두 제품에 걸쳐 사용자 선호도를 캡처할 수 있다. 이 가설을 활용하여 이전에 팟캐스트만 피처링한 기존 온라인 플랫폼에 오디오북을 통합했습니다. 결과적으로, 우리는 새롭게 제안된 2T-HGNN 모델이 팟캐스트 추천을 향상시키는지 여부를 평가한다.\n' +
      '\n' +
      '표 4는 2T-HGNN 모델이 생산에서 현재 추천 시스템인 2T 모델보다 HR@10에서 7%의 마진만큼 우수하며, 웜스타트 및 콜드스타트 사용자의 커버리지를 80% 증가시킨다는 것을 보여준다. 모델의 MRR 성능은 기존 모델과 동일하지만 표 4는 기존 제품(즉, 팟캐스트)에 대한 권장 사항이 별개의 제품(즉, 오디오북)의 데이터를 활용하여 개선되어 사용자 선호도에 대한 이해도를 심화시킬 수 있음을 보여준다.\n' +
      '\n' +
      '### 생산 A/B 실험\n' +
      '\n' +
      '모델의 온라인 성능을 더 잘 이해하기 위해 2T-HGNN을 후보 생성기로 사용하여 A/B 실험을 실행했다. 실험의 초점은 스포티파이 홈페이지의 섹션인 "Audiobook for you"로, 상위 \\(k\\) 오디오북이 개인화된 추천을 보여준다. 이 실험에는 무작위로 세 그룹으로 분할된 1,150만 명의 월간 활성 사용자의 샘플이 포함되었다. 첫 번째 그룹은 현재 생산 중인 모델에 노출되었고 두 번째 그룹은 2T 모델에서 생성된 권장 사항을 받았고 세 번째 그룹은 2T-HGNN 모델에서 권장 사항을 받았다. 우리는 2T-HGNN의 경쟁적 대안으로 2T 모델을 테스트했다. 모든 모델은 공정한 비교를 위해 동일한 날짜 범위의 데이터에 대해 훈련된다.\n' +
      '\n' +
      '표 5는 2T-HGNN이 새로운 오디오북 시작율을 유의하게 증가시키고 오디오북 스트림율을 높였다는 것을 보여준다. 대조적으로, 2T 모델은 오디오북 시작 비율의 상승률이 낮았고 스트림 비율의 통계적으로 유의한 변화를 일으키지 않았다.\n' +
      '\n' +
      '## 6. Conclusions\n' +
      '\n' +
      '본 논문에서는 Spotify에서 오디오북 추천의 개인화 기능을 지원하는 아키텍처를 소개한다. 본 논문에서는 HGNN 구조와 2T 모델의 결합을 통해 오디오북에 대한 사용자의 취향을 효과적으로 포착하는 모델인 2T-HGNN을 제안한다. 우리의 모듈식 접근법을 통해 우리는 복잡한 항목-항목 관계를 (HGNN을 통해) 분리하면서 (2T를 통해) 모든 사용자에게 확장 가능한 권장 사항을 생성할 수 있다. 우리의 결과는 오디오북과 팟캐스트에 대한 사용자 선호도 간의 강력한 연결을 보여준다. 특히, 두 콘텐츠 유형을 함께 모델링하면 두 콘텐츠 유형의 추천 품질이 향상된다. 우리의 온라인 A/B 테스트는 오디오북 권장 사항에 대해 2T-HGNN을 배포하는 성공과 기존 플랫폼에서 새로운 토크 오디오 제품에 대한 권장 사항에 전원을 공급하는 기능을 보여준다. 이 모델은 현재 생산 중이며 수백만 명의 사용자에게 노출되고 있다. 우리는 이 접근법이 온라인 사용자를 위한 더 나은 개인화된 경험으로 이어지는 다양한 콘텐츠 유형에 걸쳐 확장될 수 있다고 믿는다.\n' +
      '\n' +
      '## 7. Acknowledgments\n' +
      '\n' +
      'F.S.는 유럽 연합이 자금을 지원하는 MUR 국가 복구 및 회복 계획에 따른 FAIR(PE0000013) 및 SERICS(PE00000014)와 차세대 EU, ERC Advanced Grant 788893 AMDROMA, EC H2020RIA 프로젝트 "SoBigData++"(871042), PNRR MUR 프로젝트 IR0000013-SoBigData.it 및 프로젝트 NEREO(Neural Reasoning over Open Data) 프로젝트 NEREO(PRIN) Grant No. 2022AEFHAZ.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r r} \\hline \\hline\n' +
      '**Model** & **HR@10 \\(\\uparrow\\)** & **MRR \\(\\uparrow\\)** & **Coverage \\(\\uparrow\\)** \\\\ \\hline Popularity & 0.059 & 0.100 & 0.0\\% \\\\\n' +
      '2T & 0.114 & 0.135 & 11.4\\%\n' +
      '2T-HGNN & 0.123 & 0.138 & 20.6\\% \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4. 팟캐스트 추천 성능.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r} \\hline \\hline \\multirow{2}{*}{**Model**} & \\multicolumn{2}{c}{**Warmstart users**} \\\\ \\cline{2-3}  & HR@10 \\(\\uparrow\\) & MRR \\(\\uparrow\\) & Coverage \\(\\uparrow\\) \\\\ \\hline Popularity & 0.150 & 0.100 & 0.0\\% \\\\ LLM-KNN & 0.164 & 0.202 & 54.7\\% \\\\ HGNN & 0.258 & 0.224 & 52.8\\% \\\\ HGNN-w-users & 0.238 & 0.163 & 25.3\\% \\\\\n' +
      '2T&0.231&0.173&21.2\\%\\\\\n' +
      '2T-HGNN & 0.353 & 0.218 & 22.3\\% \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2. 웜스타트 사용자를 위한 아우디오북 추천.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r} \\hline \\hline\n' +
      '**Model** & \\multicolumn{2}{c}{**Business metric**} \\\\ \\cline{2-3}  & Stream rate & New audiobooks start rate \\\\ \\hline\n' +
      '2T & Neutral & +23.87\\% \\\\\n' +
      '2T-HGNN & +25.82\\% & +46.83\\% \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5. 온라인 A/B 테스트 결과.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '*(1) N. K. Ahmed, R. A. Rossi, R. 주재범 공, T. L. 윌케, H. 엘다디리 큰 귀납 그래프에서의 귀납적 표현 학습. _ ArXiv:1710.00471_, 2017.\n' +
      '*(2) E. Bernhardsson. 이노베이션 [https://github.com/spotify/annov] (https://github.com/spotify/annov).\n' +
      '*(3) A. Bordes, N. 우수니에, A. 가르시아-듀란, J. 웨스턴, O. 야크넨코 다중 관계 데이터를 모델링하기 위한 임베딩 변환. _ 신경 정보 처리 시스템_, 26, 2013의 발전.\n' +
      '*(4) C. Chen, W. 마민 장장 왕욱 허창왕 류승 엄마 그래프 이기종 다중 관계 추천 _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 3958-3966, 2021.\n' +
      '*(5) J. Chicaina and P. Vadivievan-Diaz. 지식 그래프 기반 추천 시스템에 대한 종합적인 조사: 기술, 개발 및 기여도. _ Information_, 12(6):232, 2021.\n' +
      '*(6) P. Cremonesi, Y. 한국, R. 터린 Top-n 추천 태스크에 대한 추천 알고리즘의 성능 [Proceedings of the fourth ACM conference on Recommender systems_, pages 39-46, 2010].\n' +
      '*(7) Z. 팬, A. Wang, Z. 낙사리 다중 소스 증분을 갖는 에피소드 디스커버리 추천. _ arXiv preprint arXiv:2301.01737_, 2023.\n' +
      '*(8) M. 페이랑 J. L. 렌슨 PyTorch Geometric을 이용한 빠른 그래프 표현 학습 그래프 및 매니폴드에 대한 표현 학습에 대한 _ICLR 워크샵, 2019.\n' +
      '*(9) Q. Guo, F. Zhuang, C. Jin, H. Zhu, X. Xie, H. Xiong, Q. 그 사람이요 지식 그래프 기반 추천 시스템에 관한 연구 IEEE Transactions on Knowledge and Data Engineering_, 34(8):3549-3568, 2020.\n' +
      '*(10) Z. 곽우 샤오상 장영 류남철 샤와 티 조 관계형 증류를 통한 링크 없는 링크 예측 _International Conference on Machine Learning_, pages 12012-12033, PMLR, 2023.\n' +
      '*(11) S. 노구루카 판시아, A. Zhai, E. Kim, S. 허승 파타사라시, C. 로젠버그, J. 레스코벡 Multibisage: pinterest에서 다중 이분 그래프를 이용한 웹 스케일 추천 시스템. _ ArXiv:2205.10662_, 2022.\n' +
      '*(12) W. 해밀턴, 지 잉, 그리고 J. 레스코벡 큰 그래프에 대한 귀납적 표현 학습 신경 정보 처리 시스템_, 30, 2017의 발전.\n' +
      '*(13) S. 한준웅, J. Pool, J. Tran, W. 달리 효율적인 신경망을 위해 가중치와 연결을 모두 학습합니다. _ 신경 정보 처리 시스템_, 28, 2015의 발전.\n' +
      '*(14) I. Hawe and B. S. Pedersen. 항보북을 읽고 있어요 미디어 보드를 넘어, 1권: 멀티모달 미디어_ 간의 국제 관계, 페이지 197-216, 2021.\n' +
      '*(15) B. Huang, Y. Bi, Z Wu, J. Wang, J. Xiao. Uber-gmm: 그래프 신경망에 기반한 사용자 기반 임베딩 추천. _ arXiv preprint arXiv:2008.02546_, 2020.\n' +
      '*(16) Z. 지승 린락 잉, J. You, J. Leskovec, A. Aiken 그래프 신경망에 대한 중복이 없는 계산 _Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, pages 997-1005, 2020.\n' +
      '*(17)M. 카빌조와 A. Ilic 10억 명 이상의 사람들에게 아이템을 추천합니다. _ Retrived May_, 2:2018, 2015.\n' +
      '*(18) D. P. Kingma and J. Ba. 아담: 확률적 최적화를 위한 방법. _ arXiv preprint arXiv:1412.6980_, 2014.\n' +
      '*(19) T. N. Kipf 및 M. 잘 지내요 그래프 컨벌루션 네트워크를 이용한 준지도 분류 ArXiv:1609.02907_, 2016.\n' +
      '*(20) J. A. Konstan, R. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl. 속수무책: 협력적 필터링을 최신 뉴스에 적용하고 있습니다. _ ACM_, 40(9):77-87, 1997의 통신.\n' +
      '*(21) J. E. 모이어. 오디오북과 전자책: 문학 리뷰. _ Reference and User Services Quarterly_, 51(4):340-354, 2012.\n' +
      '*(22) B. Perozzi, R. Al-Rfou, S. 스키나 딥워크: 사회적 표현의 온라인 학습. _Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining_, pages 701-710, 2014.\n' +
      '*(23)N. 리머스와 나 게레비치 문장-버트: siamese bert-network를 이용한 문장 임베딩. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing_. 2019년 11월 11일 컴퓨터 언어학 협회\n' +
      '*(24) S. 렌들 공장화 기계야 _2010 IEEE International conference on data mining_, pages 995-1000. IEEE, 2010.\n' +
      '*(25) R. A. Rossi, R. Zhou, N. K. Ahmed. 그래프에 대한 심층 피쳐 학습. _ ArXiv:1704.0829_, 2017.\n' +
      '*(26) A. Sankar, Y. 류준유, 그리고 N. 샤 대규모 소셜 플랫폼에서 친구 순위를 매기기 위한 그래프 신경망. _Proceedings of the Web Conference 2021_, pages 2535-2546, 2021.\n' +
      '*(27) B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. 항목 기반 협업 필터링 추천 알고리즘. _Proceedings of the 10th international conference on World Wide Web_, pages 285-295, 2001.\n' +
      '*(28) B. 샤피라, L. 로카치, J. 리치 추천인 시스템 핸드북입니다. 2022년\n' +
      '*(29) W. 샤오진 곽태 자오, E. E. 파팔렉사키스, Y. 류, N. 샤 예측을 비대비 학습과 연결합니다. _ ArXiv:2211.14394_, 2022.\n' +
      '*(30) 스포티파이. 오디오북이 오늘 U.S.를 출시하면서, 여러분이 좋아하는 모든 오디오를 위한 집을 발견하세요. [https://newsroom.spotify.com/2022-09-20/with-audibooks-launching-in-u-s-today-spotify-is-the-home-for-all-audio-you-love/] (https://newsroom.spotify.com/2022-09-20/with-audibooks-launching-in-the-u-s-today-spotify-is-the-home-for-the-audio-you-love/), 2022.\n' +
      '*(31) 스포티파이. 스포티파이 프리미엄은 150,000개 이상의 오디오북에 대한 즉각적인 액세스를 포함할 것이다. [https://newsroom.spotify.com/2023-10-03/audibooks-in-in-soptify-premium/] (https://newsroom.spotify.com/2023-10-03/audibooks-in-in-soptify-premium/), 2023.\n' +
      '*(32) P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, 및 Y. 벵지오 그래프 주의 네트워크. _ arXiv preprint arXiv:1710.10948_, 2017.\n' +
      '*(33) S. 브린치, 살라디, 몬달 유향 그래프에서 그래프 신경망을 사용하여 관련 제품을 권장합니다. 데이터베이스에서 기계 학습 및 지식 발견에 관한 유럽 연합 회의에서. 541-557 2022년 스프링어\n' +
      '*(34) Z. 우승 Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip. 그래프 신경망에 대한 종합적인 조사. _ IEEE transactions on neural networks and learning systems_, 32(1):4-24, 2020.\n' +
      '*(35) Y. 서영 장원 곽호국 탕, M. 코트 그래프셰일: 추천 시스템에 대한 그래프 구조 인식 점진적 학습. _Proceedings of the 29th ACM International Conference on Information & Knowledge Management_, pages 2861-2868, 2020.\n' +
      '*(36) B. Yan, C. Wang, G. Guo, 및 Y. 루 Tinygan: 효율적인 그래프 신경망을 학습합니다. _Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, pages 1848-1856, 2020.\n' +
      '*(37) J. Yang, X. 이덕원 홍영 이성 왕태호 Xu, E. H. Chi. 추천에서 투타워 신경망을 학습하기 위한 혼합 네거티브 샘플링이다. _Companion Proceedings of the Web Conference 2020_, pages 441-447, 2020.\n' +
      '*(38) T. 타오엑스 이덕정 진아메논 홍은희 Tjoa, J. Kang, et al. Self-supervised learning for large-scale item recommendations. _Proceedings of the 30th ACM International Conference on Information & Knowledge Management_, pages 4321-4330, 2021.\n' +
      '*(39) X. 이재양 홍동정 Held, A. Kumthekar, Z. 자오 위, E. Chi. 대용량 말뭉치 항목 추천을 위한 샘플링 편향 보정 신경망 모델링 [Proceedings of the 13th ACM Conference on Recommender Systems_, pages 269-277, 2019].\n' +
      '*(40) R. 잉룡 He, C. Chen, P. Elsombatchai, W. L. Hamilton, and J. Leskovec. 웹-스케일 추천 시스템을 위한 그래프 컨볼루션 신경망. In _Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining_, pages 974-983, 2018.\n' +
      '*(41) H. Zeng, H. Zhou, A. Srivastava, R. 캐넌과 브이 프라자나 그래프생: 그래프 샘플링 기반 귀납적 학습 방법. _ ArXiv preprint arXiv:1907.04931_, 2019.\n' +
      '*(42) C. Zhang, D. Song, C. Huang, A. Swami, and N. V. Chawla. 이질적인 그래프 신경망. In _Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining_, pages 793-803, 2019.\n' +
      '*(43) D. Zhang, X. 황진 류종 유승 송지환 지지 장룡 왕재주 Shang, et al. Aggl: scalable system for industrial purpose graph machine learning. _ arXiv preprint arXiv:2003.0254_, 2020.\n' +
      '*(44) M. 장영 첸 그래프 신경망에 기반한 링크 예측. _ 신경 정보 처리 시스템_, 31, 2018의 발전.\n' +
      '*(45) S. 장영 유영 선, N. 샤 그래프 없는 신경망: 오래된 지도를 증류를 통해 새로운 묘책을 가르치는 것. _ arXiv preprint arXiv:1710.08727_, 2021.\n' +
      '*(46) Z. 장, P. Cui, W. 주 그래프에 대한 딥 러닝: 설문조사. _ IEEE Transactions on Knowledge and Data Engineering_, 34(1):249-270, 2020.\n' +
      '*(47) Y. Zhao D. Wang D. Bates R. 멀린스, J. 잰니스, P. 리오 저 정밀 그래프 신경망을 학습했습니다. _ ArXiv preprint arXiv:2009.09232_, 2020.\n' +
      '*(48) J. Zhou, G. Cui, S. 허진 장창양 류룡 왕충리, M. 선 그래프 신경망: 방법과 응용에 대한 검토. _ AI open_, 157-81, 2020.\n' +
      '*(49) Y. 장욱 - S. 진영 - C. 후안, C-J 린 공유 메모리 시스템에서 행렬 인수분해를 위한 고속 병렬 sgd. 제7차 ACM 회의의 [Proceedings on Recommender systems_, pages 249-256, 201\\[\\text{HR@}\\beta K=\\frac{\\sum_{u\\in U}\\mathbf{1}(\\text{the relevant item is in top K})}{|U|}\\tag{6}\\]\n' +
      '\n' +
      '\\[MRR=\\frac{1}{|U|}\\sum_{u\\in U}\\frac{1}{r_{u}} \\tag{7}\\\\]\n' +
      '\n' +
      '[Coerage=\\frac{|\\cup_{u\\in U}Y_{u}|}{|\\Gamma|}\\tag{8}\\]\n' +
      '\n' +
      '여기서 \\(U\\)은 사용자 집합 \\(r_{u}\\)은 해당 항목의 순위, \\(Y_{u}\\)은 사용자에게 추천된 항목의 집합 \\(u\\) 및 \\(\\감마\\)은 전체 카탈로그이다. 성능상의 이유로, 우리는 MRR 및 Coverage를 위한 첫 번째 100개의 추천 아이템으로 추천 아이템 세트를 제한한다.\n' +
      '\n' +
      '## 부록 B 약한 신호 동시 발생\n' +
      '\n' +
      '여기서는 오디오북 구매를 완료하기 전에 수행된 사용자 동작을 나타내는 _약한 신호_의 개념을 탐구한다. 우리는 사용자가 오디오북의 업데이트를 따라갈 수 있도록 하는 "팔로우", "미리 보기", 사용자가 오디오북의 30초 샘플을 들을 수 있도록 하는 "지불 의도"와 불완전한 구매 시도를 알리는 세 가지 특정 작업에 중점을 둔다. 우리의 목표는 사용자의 초기 스트리밍 활동에 대한 상호 작용과 예측 값을 조사하여 1억 8,800만 개 이상의 상호 작용을 분석하여 이러한 약한 신호의 정보성을 평가하는 것이다.\n' +
      '\n' +
      '그림 4, 이러한 신호가 어떻게 동시에 발생하는지, 각 행은 열의 신호와 함께 신호의 분포를 나타낸다. 바플롯의 각 행은 해당 특정 신호와 관련된 상호 작용의 비율을 강조하여 전체 데이터 세트 내의 상대적 중요성에 대한 통찰력을 제공한다.\n' +
      '\n' +
      '연구 결과는 "지불 의도"를 나타내는 상호 작용이 구매와 함께 자주 발생하는 1차 스트림과 강하게 연결되어 있음을 나타낸다. "추종" 상호 작용은 덜 일반적이지만 다른 신호와 일치하지 않는 경우가 많다. 유사하게, "미리 보기" 상호작용은 빈도가 낮음에도 불구하고 다른 유형의 상호작용과 중간 정도의 동시 발생률을 보여준다. 이 분석은 사용자 참여 및 구매 행동의 지표로서 약한 신호의 가능성을 조명한다.\n' +
      '\n' +
      '그림 4. 약한 신호 중 동시 발생 패턴. 히트맵은 신호 동시발생의 분포를 나타내며, 각 \\((i,j)\\) 엔트리는 신호 총발생에 대한 신호 발생 분율 \\(j\\)을 나타낸다. 오른쪽에 있는 인접한 막대 그림은 행 내 신호의 상대적 분포에 대한 통찰력을 제공한다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>